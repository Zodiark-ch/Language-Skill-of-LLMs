[2024-07-24 10:19:46,550][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to
[2024-07-24 10:19:46,550][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Kenneth
[2024-07-24 10:19:46,550][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:19:46,550][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:19:46,550][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:19:46,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,551][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:19:46,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,551][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:19:46,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,551][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit9', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:19:46,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,553][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,554][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:19:46,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,556][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:19:46,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,556][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:19:46,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,557][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:19:46,557][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,557][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:19:46,557][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,558][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:19:46,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,558][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:19:46,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,559][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:19:46,559][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,559][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:19:46,559][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,560][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:19:46,560][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,560][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,561][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,562][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit24']
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:19:46,563][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:19:46,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,566][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,567][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,568][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit23']
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:19:46,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,570][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:19:46,571][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,573][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:19:46,575][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,576][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,577][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,578][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit12', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:19:46,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,581][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit9', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16']
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:19:46,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit13', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:19:46,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,586][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit26']
[2024-07-24 10:19:46,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit3']
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:19:46,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,591][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,593][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit24']
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:19:46,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit21']
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:19:46,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:19:46,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18']
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit10']
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit14', 'circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,600][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit12']
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:19:46,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10']
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:19:46,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit14', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5']
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit26']
[2024-07-24 10:19:46,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:19:46,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit19', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit23']
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit28']
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:19:46,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10']
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,607][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,610][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit14']
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit26']
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:19:46,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit12', 'circuit24']
[2024-07-24 10:19:46,612][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit28']
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,615][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10']
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:19:46,616][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,618][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit17', 'circuit18', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,620][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:19:46,621][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,624][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,624][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:19:46,624][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,624][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:19:46,624][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit27']
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,626][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,627][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit17']
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:19:46,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,629][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,631][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,632][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:19:46,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20']
[2024-07-24 10:19:46,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20', 'circuit25']
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit17', 'circuit20', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:19:46,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit14']
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit7', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22']
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,643][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit26']
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:19:46,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,646][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit23']
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14']
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit26']
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit12', 'circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,654][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:19:46,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit22']
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit6', 'circuit9']
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,659][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,661][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,661][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:19:46,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,662][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,665][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,666][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:19:46,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit4', 'circuit6']
[2024-07-24 10:19:46,668][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit28']
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,669][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,671][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,672][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,673][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:19:46,674][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1']
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:19:46,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:19:46,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit28']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:19:46,678][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,679][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:19:46,680][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:19:46,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:19:46,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,687][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,688][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,690][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,691][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:19:46,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,696][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,696][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit25']
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-24 10:19:46,697][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit17']
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit20']
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,700][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,701][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:19:46,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:19:46,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,705][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit17', 'circuit23']
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,706][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit17', 'circuit18']
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit22']
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17']
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:19:46,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit21']
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,710][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:19:46,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,711][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,711][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:19:46,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit25']
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:19:46,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,715][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:19:46,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,720][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,724][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,729][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,730][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,731][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:19:46,731][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,731][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,731][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,731][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,733][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5']
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,734][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,735][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit17']
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,736][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,737][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,739][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit27']
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4']
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit7', 'circuit8', 'circuit26']
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,740][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit17']
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,742][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,743][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,744][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,745][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,746][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,748][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,749][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit8', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit20', 'circuit22']
[2024-07-24 10:19:46,750][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,751][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit27']
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,752][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:19:46,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,754][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,756][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,757][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,758][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,759][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,762][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,764][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,765][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,766][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,767][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,768][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,769][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,770][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,771][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:19:46,772][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,772][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,772][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,772][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,774][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,775][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,776][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,777][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,778][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,779][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,780][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,781][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:19:46,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,783][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,784][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21']
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23']
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:19:46,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,786][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit25']
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit18', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit18', 'circuit26']
[2024-07-24 10:19:46,787][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,788][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16']
[2024-07-24 10:19:46,789][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-24 10:19:46,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22']
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,791][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,792][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit10', 'circuit11', 'circuit14', 'circuit16', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,794][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,795][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,797][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,798][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:19:46,799][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,800][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:19:46,802][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,803][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,804][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,805][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,806][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,807][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,808][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:19:46,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,809][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,809][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,809][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,809][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,809][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,810][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,811][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,812][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,814][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,815][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,816][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,816][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,816][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,816][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,816][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,816][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,817][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,819][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit18', 'circuit19', 'circuit21', 'circuit25', 'circuit27']
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,820][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,821][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,822][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,824][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,825][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,826][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,827][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,829][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,831][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,832][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,834][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,836][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,837][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,839][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:19:46,840][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15']
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,841][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,842][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,843][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,844][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,846][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,847][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,849][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,850][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,851][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,852][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:19:46,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit21', 'circuit23']
[2024-07-24 10:19:46,854][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit23', 'circuit25']
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:19:46,855][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,856][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,857][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:19:46,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,859][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:19:46,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:19:46,861][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,862][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,863][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,864][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,866][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,867][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:46,867][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:19:48,396][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:48,397][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,397][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,398][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,399][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,400][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,400][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,401][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,402][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,402][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,404][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,406][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,407][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,407][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,408][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,411][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,413][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,413][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,414][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,415][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,419][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,419][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,420][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,421][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,425][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,426][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.4173, 0.3707, 0.2120], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,427][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([6.4197e-05, 1.6158e-04, 9.9977e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,427][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.5371, 0.3989, 0.0641], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,429][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([7.0506e-03, 8.4995e-05, 9.9286e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,432][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0792, 0.0070, 0.9138], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,432][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([2.7355e-03, 5.5434e-08, 9.9726e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,433][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.3884, 0.3586, 0.2530], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,434][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.4748, 0.4104, 0.1148], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,438][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.5463, 0.2851, 0.1686], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,439][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.6007, 0.3585, 0.0409], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,439][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.4749, 0.2370, 0.2881], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,440][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.3564, 0.4021, 0.2415], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,444][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7207, 0.0816, 0.1340, 0.0637], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,445][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3032e-03, 3.9260e-02, 1.6926e-04, 9.5827e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,446][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2329, 0.1744, 0.0563, 0.5365], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,446][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1135, 0.3881, 0.0236, 0.4748], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,451][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3425, 0.1552, 0.2214, 0.2810], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,451][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1237, 0.1980, 0.0018, 0.6765], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,452][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6143, 0.0294, 0.3340, 0.0223], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,453][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2557, 0.1944, 0.2572, 0.2927], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,457][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0671, 0.4699, 0.0223, 0.4406], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,458][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4315, 0.2410, 0.1037, 0.2238], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,458][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4160, 0.3098, 0.0698, 0.2044], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,459][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4195, 0.1832, 0.1579, 0.2394], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,464][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.2151, 0.2122, 0.2869, 0.1525, 0.1332], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,466][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([9.9977e-04, 2.5571e-04, 1.1382e-02, 2.0926e-04, 9.8715e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,467][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.3843, 0.1907, 0.0517, 0.0933, 0.2800], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,468][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([1.3473e-02, 1.2132e-04, 3.6773e-02, 3.3050e-04, 9.4930e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,468][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0341, 0.0051, 0.1672, 0.0042, 0.7895], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,469][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([5.4383e-03, 1.0667e-06, 6.3798e-05, 1.6722e-07, 9.9450e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,473][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.2328, 0.1626, 0.3425, 0.0722, 0.1900], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,474][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.2178, 0.2114, 0.1259, 0.3621, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,474][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.2599, 0.2095, 0.2785, 0.1373, 0.1148], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,475][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.3357, 0.2397, 0.2231, 0.1902, 0.0113], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,479][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.2701, 0.2071, 0.1208, 0.1162, 0.2858], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,480][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.2808, 0.1903, 0.1697, 0.2198, 0.1394], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,481][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4013, 0.0353, 0.0527, 0.0351, 0.1664, 0.3092], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,481][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2175e-04, 1.6733e-03, 7.6229e-04, 2.8580e-03, 9.7965e-04, 9.9341e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,485][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4578, 0.1168, 0.0773, 0.1381, 0.0732, 0.1368], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,486][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0021, 0.0113, 0.0136, 0.9628], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,487][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2136, 0.0608, 0.0622, 0.1100, 0.0997, 0.4537], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,488][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9671e-02, 1.8512e-03, 6.4362e-04, 1.2870e-03, 3.5054e-03, 9.5304e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,492][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2737, 0.0204, 0.3720, 0.0192, 0.2872, 0.0274], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,492][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1104, 0.0860, 0.1017, 0.1996, 0.2539, 0.2483], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,493][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0926, 0.2602, 0.0267, 0.3419, 0.0670, 0.2115], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,494][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3065, 0.1848, 0.1024, 0.1904, 0.0872, 0.1287], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,498][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2446, 0.1886, 0.0785, 0.1381, 0.0503, 0.2999], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,499][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4167, 0.1392, 0.1185, 0.1736, 0.0644, 0.0877], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,500][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4599, 0.0530, 0.1367, 0.0400, 0.2088, 0.0660, 0.0355],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,500][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5630e-04, 4.3034e-03, 8.4934e-04, 4.3014e-03, 2.8980e-04, 4.6868e-04,
        9.8893e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,504][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2844, 0.1764, 0.0953, 0.2080, 0.0742, 0.1178, 0.0440],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,505][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0296, 0.0181, 0.0040, 0.0334, 0.0102, 0.1807, 0.7240],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,506][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1418, 0.0312, 0.0501, 0.0439, 0.0749, 0.4435, 0.2145],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,507][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0556, 0.1289, 0.0029, 0.0964, 0.0094, 0.0445, 0.6623],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,511][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3411, 0.0113, 0.2744, 0.0097, 0.3022, 0.0502, 0.0111],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,511][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1014, 0.0609, 0.0638, 0.1362, 0.0945, 0.2285, 0.3146],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,512][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0238, 0.1297, 0.0103, 0.1926, 0.0164, 0.1407, 0.4865],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,513][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2624, 0.1680, 0.0835, 0.1705, 0.0755, 0.1057, 0.1345],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,517][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2245, 0.1914, 0.0696, 0.1623, 0.0448, 0.0831, 0.2244],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,518][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3248, 0.1302, 0.1376, 0.1398, 0.0760, 0.0839, 0.1077],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,519][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3696, 0.0818, 0.0647, 0.0863, 0.1293, 0.0771, 0.0914, 0.0998],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,519][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.6507e-04, 1.0298e-03, 3.3897e-04, 1.2106e-03, 6.5609e-05, 1.3693e-03,
        5.0398e-04, 9.9522e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,523][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2971, 0.1148, 0.0584, 0.2053, 0.0546, 0.1526, 0.0792, 0.0380],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,524][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0774e-03, 1.2865e-04, 3.0919e-05, 2.5226e-04, 1.2203e-04, 2.0047e-03,
        1.6745e-03, 9.9471e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,525][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0462, 0.0143, 0.0074, 0.0159, 0.0246, 0.0610, 0.0718, 0.7588],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,526][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([3.2519e-03, 1.1956e-04, 1.4905e-05, 1.7791e-05, 2.1208e-05, 9.6469e-06,
        5.2877e-06, 9.9656e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,529][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.2707, 0.0585, 0.1905, 0.0341, 0.1633, 0.0387, 0.0505, 0.1937],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,530][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0874, 0.0471, 0.0522, 0.0928, 0.0915, 0.1505, 0.2782, 0.2002],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,531][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1205, 0.1464, 0.0419, 0.1353, 0.0644, 0.1104, 0.3278, 0.0534],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,532][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2503, 0.1588, 0.0623, 0.1537, 0.0752, 0.1032, 0.1324, 0.0641],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,536][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.2127, 0.1528, 0.0431, 0.1263, 0.0320, 0.0852, 0.0850, 0.2630],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,537][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4488, 0.0860, 0.1111, 0.0890, 0.0563, 0.0608, 0.0448, 0.1032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,537][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3595, 0.0565, 0.1167, 0.0407, 0.1314, 0.0742, 0.0494, 0.1402, 0.0314],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,538][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([8.9870e-04, 1.5860e-02, 9.0725e-05, 2.1564e-02, 2.7553e-05, 6.7601e-04,
        3.8736e-04, 9.5698e-05, 9.6040e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,542][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2978, 0.1411, 0.0687, 0.1311, 0.0431, 0.0759, 0.0601, 0.0835, 0.0987],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,543][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0052, 0.0030, 0.0013, 0.0070, 0.0030, 0.0454, 0.0611, 0.3737, 0.5002],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,544][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1544, 0.0211, 0.0795, 0.0251, 0.0300, 0.1111, 0.0719, 0.3331, 0.1740],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,545][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0226, 0.0912, 0.0015, 0.1070, 0.0020, 0.0656, 0.2355, 0.0072, 0.4674],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,548][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2335, 0.0199, 0.2206, 0.0176, 0.1992, 0.0455, 0.0183, 0.2329, 0.0125],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,549][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0547, 0.0265, 0.0287, 0.0554, 0.0415, 0.1095, 0.1853, 0.2751, 0.2232],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,550][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0229, 0.1175, 0.0080, 0.1837, 0.0124, 0.1238, 0.3536, 0.0216, 0.1565],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,551][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2045, 0.1336, 0.0636, 0.1368, 0.0618, 0.0857, 0.1115, 0.0798, 0.1228],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,555][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1700, 0.1576, 0.0450, 0.1490, 0.0267, 0.0769, 0.0915, 0.0594, 0.2240],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,556][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2523, 0.1097, 0.1355, 0.1293, 0.0713, 0.0754, 0.0814, 0.0968, 0.0483],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,556][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2642, 0.1065, 0.0547, 0.0978, 0.0850, 0.0372, 0.0934, 0.1037, 0.0575,
        0.0999], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,557][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4104e-04, 4.5772e-05, 1.2953e-04, 3.7553e-05, 1.6474e-04, 2.0446e-05,
        1.1359e-03, 8.8575e-04, 1.7998e-05, 9.9742e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,561][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1951, 0.0677, 0.0785, 0.1081, 0.0919, 0.0983, 0.0901, 0.0727, 0.0997,
        0.0979], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,562][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.4579e-04, 8.2969e-06, 9.9968e-06, 8.7112e-06, 5.4562e-05, 2.8330e-04,
        2.2894e-04, 1.8483e-03, 2.9448e-04, 9.9682e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,563][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0123, 0.0021, 0.0021, 0.0024, 0.0038, 0.0103, 0.0108, 0.0139, 0.0095,
        0.9327], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,564][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.2287e-03, 2.8179e-05, 1.7727e-06, 3.7848e-06, 1.2265e-05, 4.2787e-07,
        1.7981e-06, 1.4493e-04, 2.7550e-07, 9.9558e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,567][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1872, 0.0397, 0.2461, 0.0309, 0.1441, 0.0260, 0.0282, 0.1235, 0.0337,
        0.1404], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,568][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0899, 0.0224, 0.0030, 0.0482, 0.0732, 0.0667, 0.1332, 0.1875, 0.2519,
        0.1240], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,569][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1284, 0.1186, 0.0370, 0.1761, 0.0387, 0.1038, 0.1943, 0.0637, 0.1024,
        0.0369], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,570][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1825, 0.1115, 0.1139, 0.1065, 0.0855, 0.0801, 0.0919, 0.0744, 0.0984,
        0.0554], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,574][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1353, 0.1055, 0.0384, 0.1024, 0.0387, 0.0579, 0.0851, 0.0888, 0.0735,
        0.2744], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,575][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.3084, 0.1535, 0.0819, 0.1145, 0.0421, 0.0698, 0.0645, 0.0455, 0.0538,
        0.0660], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,576][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2599, 0.0368, 0.0849, 0.0339, 0.0769, 0.0477, 0.0531, 0.1405, 0.0331,
        0.2080, 0.0251], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,576][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.4898e-04, 1.5252e-03, 3.4484e-04, 3.7658e-03, 1.5228e-04, 1.5077e-04,
        1.4846e-03, 3.0387e-05, 4.3038e-03, 3.3105e-05, 9.8746e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,580][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1894, 0.0977, 0.0572, 0.1156, 0.0640, 0.0765, 0.0429, 0.0604, 0.1119,
        0.0762, 0.1083], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,581][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0224e-03, 3.5276e-04, 1.3402e-04, 6.9244e-04, 8.9309e-05, 4.8615e-03,
        7.4769e-03, 3.9669e-03, 3.0004e-02, 1.3052e-01, 8.2088e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,582][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0614, 0.0063, 0.0071, 0.0094, 0.0189, 0.0577, 0.0340, 0.0464, 0.0702,
        0.3754, 0.3132], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,583][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0534, 0.0226, 0.0101, 0.0095, 0.0160, 0.0355, 0.0157, 0.0012, 0.0038,
        0.0009, 0.8314], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,587][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1546, 0.0118, 0.2371, 0.0115, 0.1879, 0.0378, 0.0148, 0.1641, 0.0114,
        0.1505, 0.0184], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,587][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0364, 0.0123, 0.0095, 0.0279, 0.0249, 0.0465, 0.0816, 0.1093, 0.1258,
        0.1921, 0.3337], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,588][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0239, 0.1158, 0.0079, 0.2099, 0.0119, 0.1116, 0.1965, 0.0244, 0.1658,
        0.0260, 0.1063], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,589][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1514, 0.1056, 0.0478, 0.1143, 0.0527, 0.0791, 0.0914, 0.0703, 0.1101,
        0.0734, 0.1039], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,593][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1419, 0.1098, 0.0500, 0.1130, 0.0402, 0.0824, 0.0952, 0.0342, 0.0912,
        0.0300, 0.2121], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,594][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2545, 0.0872, 0.0880, 0.0905, 0.0471, 0.0540, 0.0472, 0.0852, 0.0474,
        0.0826, 0.1162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,595][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3830, 0.0325, 0.1117, 0.0210, 0.1115, 0.0424, 0.0186, 0.0826, 0.0186,
        0.1356, 0.0199, 0.0227], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,595][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9732e-03, 1.8198e-02, 8.3436e-04, 3.9216e-02, 3.6767e-04, 2.7133e-04,
        3.3077e-02, 8.6381e-05, 6.8708e-02, 7.4341e-05, 4.1088e-02, 7.9511e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,599][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1753, 0.0858, 0.0611, 0.0957, 0.0434, 0.0891, 0.0278, 0.0659, 0.1068,
        0.0593, 0.1615, 0.0283], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,600][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.0774e-02, 1.6535e-03, 4.9524e-04, 1.8831e-03, 1.1030e-03, 7.3249e-03,
        1.8899e-02, 1.2118e-02, 6.1558e-02, 5.5873e-02, 1.8262e-01, 6.4570e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,601][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1119, 0.0125, 0.0133, 0.0165, 0.0146, 0.0782, 0.0335, 0.0505, 0.0985,
        0.1418, 0.2326, 0.1961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,602][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0651, 0.1021, 0.0110, 0.0835, 0.0222, 0.0624, 0.2047, 0.0497, 0.0536,
        0.0111, 0.0572, 0.2774], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,606][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1763, 0.0029, 0.2168, 0.0028, 0.2353, 0.0170, 0.0032, 0.1486, 0.0024,
        0.1862, 0.0063, 0.0019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,606][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0383, 0.0090, 0.0101, 0.0178, 0.0128, 0.0231, 0.0368, 0.0578, 0.0951,
        0.0976, 0.2952, 0.3065], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,607][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0084, 0.0711, 0.0057, 0.1143, 0.0068, 0.0745, 0.2399, 0.0077, 0.0762,
        0.0134, 0.0509, 0.3311], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,608][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1659, 0.0937, 0.0588, 0.0972, 0.0544, 0.0681, 0.0777, 0.0635, 0.0903,
        0.0489, 0.0915, 0.0901], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,612][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1735, 0.1063, 0.0564, 0.1059, 0.0372, 0.0541, 0.1111, 0.0413, 0.0637,
        0.0299, 0.0732, 0.1475], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,613][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1929, 0.0777, 0.1013, 0.0814, 0.0619, 0.0503, 0.0842, 0.0741, 0.0308,
        0.0771, 0.0767, 0.0915], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,614][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.1499, 0.0679, 0.1689, 0.0499, 0.1281, 0.0258, 0.0682, 0.0380, 0.0521,
        0.0964, 0.0519, 0.0754, 0.0275], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,615][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ office] are: tensor([1.2614e-04, 6.3072e-04, 7.1261e-03, 3.3055e-04, 1.3844e-03, 1.5447e-04,
        4.0673e-05, 1.0780e-05, 4.6931e-04, 4.3145e-05, 1.1909e-04, 5.0509e-05,
        9.8951e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,618][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.2200, 0.0851, 0.0552, 0.0757, 0.0269, 0.0628, 0.0672, 0.0489, 0.0827,
        0.0766, 0.0735, 0.0669, 0.0585], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,619][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ office] are: tensor([3.8891e-03, 3.9018e-05, 1.3494e-05, 4.6023e-05, 5.3534e-05, 1.9756e-04,
        1.2956e-04, 1.4334e-03, 1.2288e-03, 4.7061e-03, 3.2428e-03, 4.5327e-03,
        9.8049e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,620][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.1146, 0.0028, 0.0117, 0.0032, 0.0032, 0.0075, 0.0046, 0.0155, 0.0075,
        0.0524, 0.0300, 0.0224, 0.7244], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,621][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ office] are: tensor([6.0645e-03, 7.5198e-06, 9.0542e-04, 1.5512e-06, 4.6836e-04, 2.5546e-06,
        9.8955e-07, 1.0095e-05, 7.9307e-08, 3.3565e-06, 4.4915e-07, 2.5063e-07,
        9.9253e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,625][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.1857, 0.0291, 0.2336, 0.0248, 0.1497, 0.0190, 0.0205, 0.0424, 0.0163,
        0.0860, 0.0229, 0.0169, 0.1533], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,626][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0245, 0.0148, 0.0015, 0.0167, 0.0017, 0.0347, 0.0344, 0.0638, 0.0543,
        0.0609, 0.2239, 0.3079, 0.1608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,626][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.1020, 0.0652, 0.0467, 0.1077, 0.0133, 0.0679, 0.0746, 0.0950, 0.0829,
        0.0786, 0.0825, 0.1430, 0.0404], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,628][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.1656, 0.0915, 0.0570, 0.0839, 0.0569, 0.0730, 0.0721, 0.0553, 0.0757,
        0.0815, 0.0700, 0.0813, 0.0362], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,631][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.1021, 0.0725, 0.0681, 0.0789, 0.0435, 0.0528, 0.0585, 0.0295, 0.0730,
        0.0218, 0.0529, 0.0569, 0.2892], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,632][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.2854, 0.0977, 0.0756, 0.0798, 0.0491, 0.0360, 0.0353, 0.0627, 0.0706,
        0.0641, 0.0726, 0.0308, 0.0403], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,633][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4358, 0.0137, 0.1051, 0.0113, 0.0716, 0.0474, 0.0213, 0.0770, 0.0087,
        0.1060, 0.0165, 0.0363, 0.0393, 0.0099], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,634][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.9675e-03, 2.9778e-02, 2.5162e-04, 5.5129e-03, 1.2830e-04, 1.1796e-04,
        2.6027e-04, 2.2076e-04, 2.5136e-03, 7.6673e-05, 1.1375e-03, 2.5240e-04,
        1.4873e-04, 9.5663e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,637][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3268, 0.0417, 0.0473, 0.0357, 0.0626, 0.1829, 0.0165, 0.0441, 0.0786,
        0.0349, 0.0486, 0.0203, 0.0177, 0.0423], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,638][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.3471e-02, 1.6016e-03, 4.9936e-04, 1.5518e-03, 1.4266e-03, 4.8388e-03,
        5.2162e-03, 2.1195e-02, 2.0295e-02, 2.1559e-02, 6.9743e-02, 1.8944e-01,
        1.3316e-01, 5.1600e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,639][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0304, 0.0102, 0.0097, 0.0196, 0.0072, 0.0212, 0.0181, 0.0449, 0.0599,
        0.0679, 0.1386, 0.1186, 0.1231, 0.3305], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,641][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1034, 0.1645, 0.0156, 0.1054, 0.0123, 0.0729, 0.0791, 0.0331, 0.0520,
        0.0110, 0.0549, 0.0637, 0.0205, 0.2117], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,644][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2182, 0.0056, 0.2225, 0.0042, 0.1239, 0.0115, 0.0056, 0.0848, 0.0034,
        0.1790, 0.0073, 0.0037, 0.1278, 0.0027], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,644][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0190, 0.0046, 0.0055, 0.0085, 0.0104, 0.0128, 0.0194, 0.0318, 0.0331,
        0.0703, 0.0988, 0.1527, 0.1090, 0.4242], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,645][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0142, 0.1259, 0.0065, 0.1003, 0.0042, 0.0224, 0.0839, 0.0064, 0.0602,
        0.0048, 0.0397, 0.1357, 0.0138, 0.3819], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,650][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1424, 0.0796, 0.0529, 0.0827, 0.0526, 0.0631, 0.0637, 0.0601, 0.0666,
        0.0595, 0.0698, 0.0718, 0.0474, 0.0876], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,653][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1051, 0.0887, 0.0455, 0.0955, 0.0380, 0.0722, 0.0592, 0.0621, 0.0741,
        0.0520, 0.0732, 0.0594, 0.0501, 0.1249], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,653][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2109, 0.0735, 0.0914, 0.0698, 0.0492, 0.0493, 0.0426, 0.0680, 0.0347,
        0.0620, 0.0735, 0.0330, 0.0506, 0.0914], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:48,654][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1219, 0.0892, 0.1840, 0.0680, 0.0816, 0.0119, 0.0405, 0.0104, 0.0621,
        0.0180, 0.0565, 0.0534, 0.0341, 0.0661, 0.1023], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,655][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([5.2879e-04, 5.4731e-05, 3.4888e-03, 5.3686e-05, 4.9864e-01, 3.5456e-05,
        3.8551e-05, 3.6641e-05, 1.6873e-05, 9.5048e-05, 1.1380e-04, 3.4251e-05,
        7.6875e-05, 4.7834e-06, 4.9678e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,660][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.1486, 0.0616, 0.0243, 0.0394, 0.1452, 0.0456, 0.0563, 0.0227, 0.0632,
        0.0341, 0.0306, 0.0763, 0.0659, 0.0312, 0.1550], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,660][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([8.0323e-04, 5.6715e-07, 1.1850e-04, 5.7214e-07, 2.9742e-03, 6.7313e-06,
        1.7667e-06, 5.2546e-06, 1.8713e-05, 2.9181e-04, 7.1268e-05, 5.4284e-05,
        1.4930e-03, 1.0166e-04, 9.9406e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,661][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([4.5081e-03, 3.8343e-04, 9.0170e-03, 2.4401e-04, 3.9117e-02, 1.9936e-04,
        2.1767e-04, 5.4339e-04, 1.0765e-03, 3.8523e-04, 2.2125e-03, 1.7651e-03,
        2.1594e-03, 6.0040e-03, 9.3217e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,662][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([1.0272e-03, 1.5153e-07, 1.8638e-05, 2.5449e-08, 6.0434e-01, 4.4389e-07,
        1.7419e-08, 6.2247e-08, 5.4542e-09, 3.4185e-08, 1.3583e-07, 1.1220e-08,
        8.0339e-07, 2.5816e-09, 3.9461e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,666][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1212, 0.0725, 0.2464, 0.0368, 0.1482, 0.0126, 0.0218, 0.0223, 0.0226,
        0.0250, 0.0144, 0.0276, 0.0359, 0.0401, 0.1528], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,667][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0557, 0.0169, 0.0093, 0.0220, 0.0043, 0.0247, 0.0365, 0.0259, 0.0486,
        0.0489, 0.1217, 0.1742, 0.0147, 0.3177, 0.0788], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,668][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.1284, 0.0911, 0.1704, 0.0696, 0.0724, 0.0236, 0.0531, 0.0182, 0.0511,
        0.0225, 0.0427, 0.0699, 0.0440, 0.0689, 0.0740], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,672][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.1401, 0.1019, 0.1247, 0.0859, 0.0058, 0.0525, 0.0658, 0.0345, 0.0710,
        0.0465, 0.0644, 0.0756, 0.0426, 0.0834, 0.0054], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,673][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0861, 0.0670, 0.0675, 0.0559, 0.2459, 0.0390, 0.0359, 0.0150, 0.0373,
        0.0149, 0.0376, 0.0330, 0.0177, 0.0385, 0.2087], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,674][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0991, 0.0643, 0.0618, 0.0650, 0.0560, 0.0620, 0.0492, 0.0682, 0.0380,
        0.0791, 0.0859, 0.0407, 0.0665, 0.0877, 0.0766], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:48,676][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1992, 0.0196, 0.0172, 0.0236, 0.0774, 0.0977, 0.0187, 0.0475, 0.0230,
        0.0381, 0.0188, 0.0174, 0.0661, 0.0156, 0.1051, 0.2150],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,678][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.7427e-04, 5.8106e-04, 1.0030e-03, 1.2635e-03, 1.1328e-03, 6.5241e-03,
        1.4090e-04, 3.2773e-04, 7.6414e-04, 1.2305e-04, 3.5717e-04, 1.7539e-04,
        1.4835e-04, 5.0769e-05, 9.0896e-04, 9.8612e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,679][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1694, 0.0424, 0.0310, 0.0511, 0.0259, 0.0762, 0.0440, 0.0573, 0.0730,
        0.0642, 0.0721, 0.0541, 0.0657, 0.0719, 0.0259, 0.0759],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,680][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.5568e-04, 4.5844e-06, 1.1032e-06, 3.9827e-06, 1.2409e-05, 4.5409e-05,
        1.1757e-05, 3.8497e-05, 4.6983e-05, 2.9122e-04, 1.4064e-04, 2.0578e-04,
        4.7920e-04, 6.4977e-04, 4.6592e-03, 9.9255e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,683][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0825, 0.0064, 0.0059, 0.0064, 0.0070, 0.0106, 0.0074, 0.0101, 0.0188,
        0.0225, 0.0391, 0.0213, 0.0359, 0.0426, 0.0759, 0.6073],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,685][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.9475e-02, 2.1578e-05, 5.5456e-04, 2.1839e-05, 8.1511e-04, 1.8011e-03,
        1.2748e-05, 7.0304e-06, 5.9544e-06, 5.3177e-05, 1.5010e-05, 7.0688e-06,
        7.9174e-06, 1.0690e-06, 3.3270e-04, 9.5687e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,686][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0757, 0.0095, 0.1285, 0.0093, 0.1527, 0.0113, 0.0135, 0.0610, 0.0070,
        0.1170, 0.0082, 0.0105, 0.1234, 0.0097, 0.2395, 0.0233],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,687][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0183, 0.0041, 0.0062, 0.0060, 0.0061, 0.0060, 0.0116, 0.0135, 0.0149,
        0.0236, 0.0546, 0.0752, 0.0456, 0.3010, 0.1943, 0.2189],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,691][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0721, 0.0712, 0.0145, 0.0902, 0.0189, 0.0390, 0.1026, 0.0353, 0.0794,
        0.0639, 0.0740, 0.1244, 0.0564, 0.0966, 0.0263, 0.0352],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,692][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1096, 0.0601, 0.0394, 0.0638, 0.0535, 0.0594, 0.0533, 0.0533, 0.0589,
        0.0724, 0.0533, 0.0574, 0.0534, 0.0864, 0.0673, 0.0586],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,693][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0787, 0.0555, 0.0406, 0.0626, 0.0368, 0.1043, 0.0510, 0.0304, 0.0537,
        0.0337, 0.0555, 0.0490, 0.0274, 0.0659, 0.0375, 0.2174],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,694][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2196, 0.0775, 0.0550, 0.0926, 0.0412, 0.0407, 0.0372, 0.0469, 0.0393,
        0.0454, 0.0688, 0.0334, 0.0252, 0.0835, 0.0391, 0.0547],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:48,697][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2233, 0.0176, 0.0646, 0.0136, 0.0964, 0.0284, 0.0123, 0.0544, 0.0116,
        0.0939, 0.0114, 0.0216, 0.0462, 0.0161, 0.1534, 0.1162, 0.0188],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,698][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3931e-04, 1.1436e-03, 2.3232e-04, 1.2521e-03, 9.7012e-05, 1.3496e-04,
        4.3330e-01, 1.8446e-04, 1.1690e-03, 9.9730e-04, 3.4123e-03, 1.4676e-02,
        1.0477e-04, 2.8413e-04, 6.8384e-05, 1.1750e-04, 5.4238e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,699][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0984, 0.0503, 0.0380, 0.0767, 0.0299, 0.0461, 0.0156, 0.0583, 0.0773,
        0.0435, 0.1172, 0.0182, 0.0272, 0.1631, 0.0354, 0.0872, 0.0176],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,700][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.6271e-03, 2.7563e-04, 2.9102e-05, 1.7645e-04, 4.5692e-05, 3.7953e-04,
        1.3217e-03, 5.5957e-04, 1.7627e-03, 1.7712e-03, 4.8148e-03, 1.9680e-02,
        3.4863e-03, 2.9212e-02, 9.1363e-03, 1.3344e-01, 7.9028e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,704][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0230, 0.0027, 0.0028, 0.0029, 0.0031, 0.0191, 0.0076, 0.0071, 0.0115,
        0.0266, 0.0251, 0.0192, 0.0317, 0.0223, 0.0420, 0.5573, 0.1960],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,705][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0165, 0.0525, 0.0014, 0.0461, 0.0052, 0.0247, 0.4136, 0.0038, 0.0248,
        0.0043, 0.0313, 0.1007, 0.0039, 0.0131, 0.0021, 0.0038, 0.2522],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,705][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1072, 0.0025, 0.1024, 0.0024, 0.1189, 0.0157, 0.0027, 0.1023, 0.0026,
        0.1296, 0.0054, 0.0021, 0.1138, 0.0023, 0.2150, 0.0710, 0.0041],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,710][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0146, 0.0027, 0.0024, 0.0042, 0.0021, 0.0037, 0.0042, 0.0077, 0.0100,
        0.0126, 0.0316, 0.0370, 0.0278, 0.2102, 0.0683, 0.2887, 0.2722],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,711][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0068, 0.0336, 0.0032, 0.0589, 0.0055, 0.0458, 0.1354, 0.0064, 0.0433,
        0.0111, 0.0352, 0.1939, 0.0113, 0.0992, 0.0096, 0.0232, 0.2777],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,712][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1048, 0.0641, 0.0399, 0.0705, 0.0384, 0.0474, 0.0551, 0.0465, 0.0651,
        0.0410, 0.0644, 0.0663, 0.0516, 0.0696, 0.0454, 0.0596, 0.0702],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,714][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0742, 0.0577, 0.0322, 0.0681, 0.0278, 0.0451, 0.1262, 0.0339, 0.0540,
        0.0387, 0.0696, 0.0815, 0.0347, 0.0549, 0.0270, 0.0360, 0.1385],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,716][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1756, 0.0658, 0.0706, 0.0629, 0.0415, 0.0427, 0.0482, 0.0557, 0.0276,
        0.0541, 0.0549, 0.0356, 0.0394, 0.0710, 0.0404, 0.0667, 0.0473],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:48,717][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1610, 0.0541, 0.0880, 0.0416, 0.0589, 0.0386, 0.0236, 0.0319, 0.0322,
        0.0591, 0.0434, 0.0219, 0.0808, 0.0395, 0.0734, 0.0474, 0.0312, 0.0733],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,718][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([2.0766e-04, 5.1517e-04, 4.2581e-04, 2.9635e-04, 1.1465e-04, 1.2987e-04,
        1.1766e-04, 3.4879e-05, 3.3232e-04, 1.1597e-04, 1.3725e-04, 2.4393e-04,
        6.0137e-04, 1.9933e-04, 7.2040e-05, 3.9593e-05, 8.1969e-05, 9.9633e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,722][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1461, 0.0405, 0.0265, 0.0530, 0.0326, 0.0398, 0.0583, 0.0339, 0.0477,
        0.0477, 0.0615, 0.0678, 0.0545, 0.0579, 0.0317, 0.0465, 0.0604, 0.0937],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,723][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([1.0685e-04, 9.6983e-08, 5.0251e-06, 1.6220e-07, 9.3372e-07, 1.5826e-06,
        5.8609e-07, 4.1695e-06, 1.9184e-06, 5.3877e-05, 9.8505e-06, 1.4126e-05,
        3.1835e-04, 1.9266e-05, 2.1428e-04, 8.2438e-04, 3.0895e-04, 9.9812e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,724][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([2.3356e-02, 1.7002e-03, 2.3950e-03, 9.4288e-04, 7.7054e-04, 8.6606e-04,
        1.4403e-03, 1.2441e-03, 1.8253e-03, 5.7473e-03, 3.7954e-03, 4.4143e-03,
        4.3127e-03, 8.5070e-03, 6.0027e-03, 1.6405e-02, 2.3877e-02, 8.9240e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,726][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([2.5155e-03, 3.1047e-05, 2.7624e-04, 4.6625e-06, 2.7509e-05, 2.9957e-06,
        1.2455e-05, 2.4856e-06, 1.1832e-06, 5.1673e-06, 1.6073e-06, 7.4269e-06,
        1.6002e-05, 4.3832e-07, 7.9909e-06, 9.6665e-08, 4.5531e-06, 9.9708e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,729][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1043, 0.0254, 0.0779, 0.0141, 0.0887, 0.0153, 0.0138, 0.0343, 0.0147,
        0.0886, 0.0143, 0.0112, 0.1274, 0.0217, 0.0906, 0.0246, 0.0140, 0.2190],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,730][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0367, 0.0044, 0.0021, 0.0067, 0.0024, 0.0043, 0.0060, 0.0042, 0.0112,
        0.0089, 0.0278, 0.0403, 0.0750, 0.1308, 0.0463, 0.2333, 0.2614, 0.0982],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,731][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0987, 0.0527, 0.0261, 0.0567, 0.0221, 0.0292, 0.0404, 0.0380, 0.0576,
        0.1122, 0.0474, 0.0708, 0.0843, 0.0516, 0.0271, 0.0282, 0.0533, 0.1034],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,735][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1076, 0.0622, 0.0444, 0.0573, 0.0614, 0.0421, 0.0575, 0.0354, 0.0492,
        0.0462, 0.0487, 0.0621, 0.0510, 0.0646, 0.0734, 0.0519, 0.0712, 0.0139],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,736][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0909, 0.0531, 0.0279, 0.0555, 0.0227, 0.0440, 0.0487, 0.0222, 0.0459,
        0.0237, 0.0401, 0.0595, 0.0366, 0.0519, 0.0216, 0.0296, 0.0497, 0.2762],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,737][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.2189, 0.0852, 0.0528, 0.0676, 0.0315, 0.0332, 0.0250, 0.0486, 0.0569,
        0.0522, 0.0668, 0.0232, 0.0304, 0.0634, 0.0303, 0.0527, 0.0243, 0.0369],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:48,740][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2146, 0.0188, 0.0408, 0.0157, 0.0635, 0.0524, 0.0167, 0.0539, 0.0173,
        0.0595, 0.0160, 0.0251, 0.0278, 0.0173, 0.0987, 0.1403, 0.0271, 0.0793,
        0.0151], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,742][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.0641e-03, 8.9848e-03, 3.0073e-05, 2.6123e-02, 6.3293e-05, 2.3095e-04,
        1.0627e-03, 3.7216e-05, 2.5760e-02, 1.8241e-04, 1.4921e-02, 1.4073e-03,
        9.7394e-05, 6.9820e-03, 4.7528e-05, 6.6511e-04, 9.9164e-04, 5.2953e-05,
        9.0830e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,743][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1033, 0.0421, 0.0169, 0.0613, 0.0224, 0.0377, 0.0156, 0.0450, 0.0662,
        0.0349, 0.0903, 0.0185, 0.0188, 0.1855, 0.0248, 0.0530, 0.0174, 0.0221,
        0.1241], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,743][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2054e-03, 6.3570e-05, 1.7259e-06, 3.0482e-05, 4.3399e-06, 7.2739e-05,
        1.0142e-04, 3.0248e-05, 3.9510e-04, 2.6530e-04, 6.0020e-04, 2.4388e-03,
        3.8687e-04, 4.4172e-03, 7.1844e-04, 2.5236e-01, 7.1720e-02, 1.5258e-02,
        6.4993e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,746][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.9783e-02, 1.0584e-03, 3.1994e-04, 1.5708e-03, 5.6557e-04, 1.0583e-02,
        2.8465e-03, 4.4374e-03, 3.8783e-03, 2.5358e-02, 9.9336e-03, 7.4047e-03,
        2.7171e-02, 1.2098e-02, 6.9872e-03, 3.5562e-01, 7.9812e-02, 1.6667e-01,
        2.6390e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,748][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0297, 0.0436, 0.0004, 0.0587, 0.0014, 0.0250, 0.1856, 0.0075, 0.0395,
        0.0096, 0.0167, 0.1356, 0.0008, 0.0165, 0.0006, 0.0049, 0.1147, 0.0036,
        0.3059], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,749][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0853, 0.0038, 0.0262, 0.0033, 0.0460, 0.0115, 0.0031, 0.0366, 0.0046,
        0.1042, 0.0166, 0.0026, 0.0572, 0.0046, 0.0866, 0.0553, 0.0050, 0.1473,
        0.3003], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,750][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0154, 0.0022, 0.0021, 0.0030, 0.0020, 0.0027, 0.0032, 0.0045, 0.0040,
        0.0117, 0.0117, 0.0193, 0.0252, 0.0962, 0.0444, 0.1272, 0.1674, 0.1672,
        0.2907], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,754][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0054, 0.0388, 0.0019, 0.0695, 0.0030, 0.0315, 0.0852, 0.0057, 0.0495,
        0.0058, 0.0338, 0.1521, 0.0080, 0.1174, 0.0049, 0.0175, 0.1676, 0.0106,
        0.1919], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,755][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0905, 0.0538, 0.0281, 0.0609, 0.0353, 0.0414, 0.0516, 0.0410, 0.0551,
        0.0437, 0.0551, 0.0592, 0.0420, 0.0621, 0.0420, 0.0543, 0.0662, 0.0348,
        0.0828], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,756][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0706, 0.0540, 0.0221, 0.0695, 0.0260, 0.0544, 0.0626, 0.0343, 0.0619,
        0.0395, 0.0625, 0.0625, 0.0350, 0.0668, 0.0268, 0.0546, 0.0696, 0.0300,
        0.0974], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,760][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1578, 0.0608, 0.0623, 0.0614, 0.0380, 0.0452, 0.0398, 0.0484, 0.0286,
        0.0473, 0.0573, 0.0285, 0.0294, 0.0610, 0.0353, 0.0632, 0.0370, 0.0413,
        0.0573], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:48,776][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:48,777][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,777][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,779][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,782][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,782][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,783][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,784][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,786][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,786][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,787][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,788][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,788][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:48,789][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,790][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,790][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,794][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,795][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,795][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,796][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,799][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,801][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,801][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,802][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,803][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:48,807][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.4173, 0.3707, 0.2120], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,807][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([6.4197e-05, 1.6158e-04, 9.9977e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,808][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.5371, 0.3989, 0.0641], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,809][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([7.0506e-03, 8.4995e-05, 9.9286e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,813][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0792, 0.0070, 0.9138], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,814][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([2.7355e-03, 5.5434e-08, 9.9726e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,814][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.3884, 0.3586, 0.2530], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,815][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.4748, 0.4104, 0.1148], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,819][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.5463, 0.2851, 0.1686], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,820][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.6007, 0.3585, 0.0409], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,821][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.4749, 0.2370, 0.2881], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,821][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.3564, 0.4021, 0.2415], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:48,825][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7207, 0.0816, 0.1340, 0.0637], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,826][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3032e-03, 3.9260e-02, 1.6926e-04, 9.5827e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,827][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2329, 0.1744, 0.0563, 0.5365], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,828][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1135, 0.3881, 0.0236, 0.4748], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,832][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3425, 0.1552, 0.2214, 0.2810], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,833][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1237, 0.1980, 0.0018, 0.6765], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,833][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6143, 0.0294, 0.3340, 0.0223], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,834][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2557, 0.1944, 0.2572, 0.2927], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,838][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0671, 0.4699, 0.0223, 0.4406], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,839][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4315, 0.2410, 0.1037, 0.2238], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,840][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4160, 0.3098, 0.0698, 0.2044], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,840][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4195, 0.1832, 0.1579, 0.2394], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:48,844][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.2151, 0.2122, 0.2869, 0.1525, 0.1332], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,845][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9977e-04, 2.5571e-04, 1.1382e-02, 2.0926e-04, 9.8715e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,846][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.3843, 0.1907, 0.0517, 0.0933, 0.2800], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,847][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([1.3473e-02, 1.2132e-04, 3.6773e-02, 3.3050e-04, 9.4930e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,851][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0341, 0.0051, 0.1672, 0.0042, 0.7895], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,854][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([5.4383e-03, 1.0667e-06, 6.3798e-05, 1.6722e-07, 9.9450e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,854][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.2328, 0.1626, 0.3425, 0.0722, 0.1900], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,855][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.2178, 0.2114, 0.1259, 0.3621, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,856][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.2599, 0.2095, 0.2785, 0.1373, 0.1148], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,857][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.3357, 0.2397, 0.2231, 0.1902, 0.0113], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,861][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.2701, 0.2071, 0.1208, 0.1162, 0.2858], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,861][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.2808, 0.1903, 0.1697, 0.2198, 0.1394], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:48,862][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4013, 0.0353, 0.0527, 0.0351, 0.1664, 0.3092], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,863][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2175e-04, 1.6733e-03, 7.6229e-04, 2.8580e-03, 9.7965e-04, 9.9341e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,867][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4578, 0.1168, 0.0773, 0.1381, 0.0732, 0.1368], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,868][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0021, 0.0113, 0.0136, 0.9628], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,868][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2136, 0.0608, 0.0622, 0.1100, 0.0997, 0.4537], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,869][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9671e-02, 1.8512e-03, 6.4362e-04, 1.2870e-03, 3.5054e-03, 9.5304e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,873][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2737, 0.0204, 0.3720, 0.0192, 0.2872, 0.0274], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,874][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1104, 0.0860, 0.1017, 0.1996, 0.2539, 0.2483], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,874][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0926, 0.2602, 0.0267, 0.3419, 0.0670, 0.2115], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,875][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3065, 0.1848, 0.1024, 0.1904, 0.0872, 0.1287], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,879][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2446, 0.1886, 0.0785, 0.1381, 0.0503, 0.2999], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,880][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4167, 0.1392, 0.1185, 0.1736, 0.0644, 0.0877], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:48,881][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4599, 0.0530, 0.1367, 0.0400, 0.2088, 0.0660, 0.0355],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,881][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5630e-04, 4.3034e-03, 8.4934e-04, 4.3014e-03, 2.8980e-04, 4.6868e-04,
        9.8893e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,885][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2844, 0.1764, 0.0953, 0.2080, 0.0742, 0.1178, 0.0440],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,886][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0296, 0.0181, 0.0040, 0.0334, 0.0102, 0.1807, 0.7240],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,887][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1418, 0.0312, 0.0501, 0.0439, 0.0749, 0.4435, 0.2145],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,888][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0556, 0.1289, 0.0029, 0.0964, 0.0094, 0.0445, 0.6623],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,892][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3411, 0.0113, 0.2744, 0.0097, 0.3022, 0.0502, 0.0111],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,892][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1014, 0.0609, 0.0638, 0.1362, 0.0945, 0.2285, 0.3146],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,893][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0238, 0.1297, 0.0103, 0.1926, 0.0164, 0.1407, 0.4865],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,894][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2624, 0.1680, 0.0835, 0.1705, 0.0755, 0.1057, 0.1345],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,898][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2245, 0.1914, 0.0696, 0.1623, 0.0448, 0.0831, 0.2244],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,899][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3248, 0.1302, 0.1376, 0.1398, 0.0760, 0.0839, 0.1077],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:48,899][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3696, 0.0818, 0.0647, 0.0863, 0.1293, 0.0771, 0.0914, 0.0998],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,900][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.6507e-04, 1.0298e-03, 3.3897e-04, 1.2106e-03, 6.5609e-05, 1.3693e-03,
        5.0398e-04, 9.9522e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,904][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2971, 0.1148, 0.0584, 0.2053, 0.0546, 0.1526, 0.0792, 0.0380],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,905][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0774e-03, 1.2865e-04, 3.0919e-05, 2.5226e-04, 1.2203e-04, 2.0047e-03,
        1.6745e-03, 9.9471e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,906][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0462, 0.0143, 0.0074, 0.0159, 0.0246, 0.0610, 0.0718, 0.7588],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,906][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.2519e-03, 1.1956e-04, 1.4905e-05, 1.7791e-05, 2.1208e-05, 9.6469e-06,
        5.2877e-06, 9.9656e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,910][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2707, 0.0585, 0.1905, 0.0341, 0.1633, 0.0387, 0.0505, 0.1937],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,911][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0874, 0.0471, 0.0522, 0.0928, 0.0915, 0.1505, 0.2782, 0.2002],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,912][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1205, 0.1464, 0.0419, 0.1353, 0.0644, 0.1104, 0.3278, 0.0534],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,913][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2503, 0.1588, 0.0623, 0.1537, 0.0752, 0.1032, 0.1324, 0.0641],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,917][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2127, 0.1528, 0.0431, 0.1263, 0.0320, 0.0852, 0.0850, 0.2630],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,918][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.4488, 0.0860, 0.1111, 0.0890, 0.0563, 0.0608, 0.0448, 0.1032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:48,918][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3595, 0.0565, 0.1167, 0.0407, 0.1314, 0.0742, 0.0494, 0.1402, 0.0314],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,919][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([8.9870e-04, 1.5860e-02, 9.0725e-05, 2.1564e-02, 2.7553e-05, 6.7601e-04,
        3.8736e-04, 9.5698e-05, 9.6040e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,923][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2978, 0.1411, 0.0687, 0.1311, 0.0431, 0.0759, 0.0601, 0.0835, 0.0987],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,924][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0052, 0.0030, 0.0013, 0.0070, 0.0030, 0.0454, 0.0611, 0.3737, 0.5002],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,925][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1544, 0.0211, 0.0795, 0.0251, 0.0300, 0.1111, 0.0719, 0.3331, 0.1740],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,926][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0226, 0.0912, 0.0015, 0.1070, 0.0020, 0.0656, 0.2355, 0.0072, 0.4674],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,929][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2335, 0.0199, 0.2206, 0.0176, 0.1992, 0.0455, 0.0183, 0.2329, 0.0125],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,930][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0547, 0.0265, 0.0287, 0.0554, 0.0415, 0.1095, 0.1853, 0.2751, 0.2232],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,931][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0229, 0.1175, 0.0080, 0.1837, 0.0124, 0.1238, 0.3536, 0.0216, 0.1565],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,932][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2045, 0.1336, 0.0636, 0.1368, 0.0618, 0.0857, 0.1115, 0.0798, 0.1228],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,936][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1700, 0.1576, 0.0450, 0.1490, 0.0267, 0.0769, 0.0915, 0.0594, 0.2240],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,937][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2523, 0.1097, 0.1355, 0.1293, 0.0713, 0.0754, 0.0814, 0.0968, 0.0483],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:48,937][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2642, 0.1065, 0.0547, 0.0978, 0.0850, 0.0372, 0.0934, 0.1037, 0.0575,
        0.0999], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,938][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.4104e-04, 4.5772e-05, 1.2953e-04, 3.7553e-05, 1.6474e-04, 2.0446e-05,
        1.1359e-03, 8.8575e-04, 1.7998e-05, 9.9742e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,942][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1951, 0.0677, 0.0785, 0.1081, 0.0919, 0.0983, 0.0901, 0.0727, 0.0997,
        0.0979], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,943][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.4579e-04, 8.2969e-06, 9.9968e-06, 8.7112e-06, 5.4562e-05, 2.8330e-04,
        2.2894e-04, 1.8483e-03, 2.9448e-04, 9.9682e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,944][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0123, 0.0021, 0.0021, 0.0024, 0.0038, 0.0103, 0.0108, 0.0139, 0.0095,
        0.9327], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,945][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([4.2287e-03, 2.8179e-05, 1.7727e-06, 3.7848e-06, 1.2265e-05, 4.2787e-07,
        1.7981e-06, 1.4493e-04, 2.7550e-07, 9.9558e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,949][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1872, 0.0397, 0.2461, 0.0309, 0.1441, 0.0260, 0.0282, 0.1235, 0.0337,
        0.1404], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,949][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0899, 0.0224, 0.0030, 0.0482, 0.0732, 0.0667, 0.1332, 0.1875, 0.2519,
        0.1240], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,950][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1284, 0.1186, 0.0370, 0.1761, 0.0387, 0.1038, 0.1943, 0.0637, 0.1024,
        0.0369], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,951][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1825, 0.1115, 0.1139, 0.1065, 0.0855, 0.0801, 0.0919, 0.0744, 0.0984,
        0.0554], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,955][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1353, 0.1055, 0.0384, 0.1024, 0.0387, 0.0579, 0.0851, 0.0888, 0.0735,
        0.2744], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,956][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.3084, 0.1535, 0.0819, 0.1145, 0.0421, 0.0698, 0.0645, 0.0455, 0.0538,
        0.0660], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:48,957][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2599, 0.0368, 0.0849, 0.0339, 0.0769, 0.0477, 0.0531, 0.1405, 0.0331,
        0.2080, 0.0251], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,957][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.4898e-04, 1.5252e-03, 3.4484e-04, 3.7658e-03, 1.5228e-04, 1.5077e-04,
        1.4846e-03, 3.0387e-05, 4.3038e-03, 3.3105e-05, 9.8746e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,961][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1894, 0.0977, 0.0572, 0.1156, 0.0640, 0.0765, 0.0429, 0.0604, 0.1119,
        0.0762, 0.1083], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,962][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0224e-03, 3.5276e-04, 1.3402e-04, 6.9244e-04, 8.9309e-05, 4.8615e-03,
        7.4769e-03, 3.9669e-03, 3.0004e-02, 1.3052e-01, 8.2088e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,963][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0614, 0.0063, 0.0071, 0.0094, 0.0189, 0.0577, 0.0340, 0.0464, 0.0702,
        0.3754, 0.3132], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,964][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0534, 0.0226, 0.0101, 0.0095, 0.0160, 0.0355, 0.0157, 0.0012, 0.0038,
        0.0009, 0.8314], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,968][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1546, 0.0118, 0.2371, 0.0115, 0.1879, 0.0378, 0.0148, 0.1641, 0.0114,
        0.1505, 0.0184], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,969][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0364, 0.0123, 0.0095, 0.0279, 0.0249, 0.0465, 0.0816, 0.1093, 0.1258,
        0.1921, 0.3337], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,969][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0239, 0.1158, 0.0079, 0.2099, 0.0119, 0.1116, 0.1965, 0.0244, 0.1658,
        0.0260, 0.1063], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,970][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1514, 0.1056, 0.0478, 0.1143, 0.0527, 0.0791, 0.0914, 0.0703, 0.1101,
        0.0734, 0.1039], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,974][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1419, 0.1098, 0.0500, 0.1130, 0.0402, 0.0824, 0.0952, 0.0342, 0.0912,
        0.0300, 0.2121], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,975][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2545, 0.0872, 0.0880, 0.0905, 0.0471, 0.0540, 0.0472, 0.0852, 0.0474,
        0.0826, 0.1162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:48,976][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3830, 0.0325, 0.1117, 0.0210, 0.1115, 0.0424, 0.0186, 0.0826, 0.0186,
        0.1356, 0.0199, 0.0227], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,977][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9732e-03, 1.8198e-02, 8.3436e-04, 3.9216e-02, 3.6767e-04, 2.7133e-04,
        3.3077e-02, 8.6381e-05, 6.8708e-02, 7.4341e-05, 4.1088e-02, 7.9511e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,980][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1753, 0.0858, 0.0611, 0.0957, 0.0434, 0.0891, 0.0278, 0.0659, 0.1068,
        0.0593, 0.1615, 0.0283], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,981][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0774e-02, 1.6535e-03, 4.9524e-04, 1.8831e-03, 1.1030e-03, 7.3249e-03,
        1.8899e-02, 1.2118e-02, 6.1558e-02, 5.5873e-02, 1.8262e-01, 6.4570e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,982][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1119, 0.0125, 0.0133, 0.0165, 0.0146, 0.0782, 0.0335, 0.0505, 0.0985,
        0.1418, 0.2326, 0.1961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,983][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0651, 0.1021, 0.0110, 0.0835, 0.0222, 0.0624, 0.2047, 0.0497, 0.0536,
        0.0111, 0.0572, 0.2774], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,987][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1763, 0.0029, 0.2168, 0.0028, 0.2353, 0.0170, 0.0032, 0.1486, 0.0024,
        0.1862, 0.0063, 0.0019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,988][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0383, 0.0090, 0.0101, 0.0178, 0.0128, 0.0231, 0.0368, 0.0578, 0.0951,
        0.0976, 0.2952, 0.3065], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,988][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0084, 0.0711, 0.0057, 0.1143, 0.0068, 0.0745, 0.2399, 0.0077, 0.0762,
        0.0134, 0.0509, 0.3311], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,989][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1659, 0.0937, 0.0588, 0.0972, 0.0544, 0.0681, 0.0777, 0.0635, 0.0903,
        0.0489, 0.0915, 0.0901], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,993][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1735, 0.1063, 0.0564, 0.1059, 0.0372, 0.0541, 0.1111, 0.0413, 0.0637,
        0.0299, 0.0732, 0.1475], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,994][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1929, 0.0777, 0.1013, 0.0814, 0.0619, 0.0503, 0.0842, 0.0741, 0.0308,
        0.0771, 0.0767, 0.0915], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:48,995][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.1499, 0.0679, 0.1689, 0.0499, 0.1281, 0.0258, 0.0682, 0.0380, 0.0521,
        0.0964, 0.0519, 0.0754, 0.0275], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:48,996][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([1.2614e-04, 6.3072e-04, 7.1261e-03, 3.3055e-04, 1.3844e-03, 1.5447e-04,
        4.0673e-05, 1.0780e-05, 4.6931e-04, 4.3145e-05, 1.1909e-04, 5.0509e-05,
        9.8951e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,000][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.2200, 0.0851, 0.0552, 0.0757, 0.0269, 0.0628, 0.0672, 0.0489, 0.0827,
        0.0766, 0.0735, 0.0669, 0.0585], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,000][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([3.8891e-03, 3.9018e-05, 1.3494e-05, 4.6023e-05, 5.3534e-05, 1.9756e-04,
        1.2956e-04, 1.4334e-03, 1.2288e-03, 4.7061e-03, 3.2428e-03, 4.5327e-03,
        9.8049e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,001][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1146, 0.0028, 0.0117, 0.0032, 0.0032, 0.0075, 0.0046, 0.0155, 0.0075,
        0.0524, 0.0300, 0.0224, 0.7244], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,002][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([6.0645e-03, 7.5198e-06, 9.0542e-04, 1.5512e-06, 4.6836e-04, 2.5546e-06,
        9.8955e-07, 1.0095e-05, 7.9307e-08, 3.3565e-06, 4.4915e-07, 2.5063e-07,
        9.9253e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,006][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.1857, 0.0291, 0.2336, 0.0248, 0.1497, 0.0190, 0.0205, 0.0424, 0.0163,
        0.0860, 0.0229, 0.0169, 0.1533], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,007][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0245, 0.0148, 0.0015, 0.0167, 0.0017, 0.0347, 0.0344, 0.0638, 0.0543,
        0.0609, 0.2239, 0.3079, 0.1608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,008][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.1020, 0.0652, 0.0467, 0.1077, 0.0133, 0.0679, 0.0746, 0.0950, 0.0829,
        0.0786, 0.0825, 0.1430, 0.0404], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,010][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.1656, 0.0915, 0.0570, 0.0839, 0.0569, 0.0730, 0.0721, 0.0553, 0.0757,
        0.0815, 0.0700, 0.0813, 0.0362], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,012][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.1021, 0.0725, 0.0681, 0.0789, 0.0435, 0.0528, 0.0585, 0.0295, 0.0730,
        0.0218, 0.0529, 0.0569, 0.2892], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,013][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.2854, 0.0977, 0.0756, 0.0798, 0.0491, 0.0360, 0.0353, 0.0627, 0.0706,
        0.0641, 0.0726, 0.0308, 0.0403], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,014][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4358, 0.0137, 0.1051, 0.0113, 0.0716, 0.0474, 0.0213, 0.0770, 0.0087,
        0.1060, 0.0165, 0.0363, 0.0393, 0.0099], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,015][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.9675e-03, 2.9778e-02, 2.5162e-04, 5.5129e-03, 1.2830e-04, 1.1796e-04,
        2.6027e-04, 2.2076e-04, 2.5136e-03, 7.6673e-05, 1.1375e-03, 2.5240e-04,
        1.4873e-04, 9.5663e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,019][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3268, 0.0417, 0.0473, 0.0357, 0.0626, 0.1829, 0.0165, 0.0441, 0.0786,
        0.0349, 0.0486, 0.0203, 0.0177, 0.0423], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,019][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.3471e-02, 1.6016e-03, 4.9936e-04, 1.5518e-03, 1.4266e-03, 4.8388e-03,
        5.2162e-03, 2.1195e-02, 2.0295e-02, 2.1559e-02, 6.9743e-02, 1.8944e-01,
        1.3316e-01, 5.1600e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,020][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0304, 0.0102, 0.0097, 0.0196, 0.0072, 0.0212, 0.0181, 0.0449, 0.0599,
        0.0679, 0.1386, 0.1186, 0.1231, 0.3305], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,022][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1034, 0.1645, 0.0156, 0.1054, 0.0123, 0.0729, 0.0791, 0.0331, 0.0520,
        0.0110, 0.0549, 0.0637, 0.0205, 0.2117], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,025][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2182, 0.0056, 0.2225, 0.0042, 0.1239, 0.0115, 0.0056, 0.0848, 0.0034,
        0.1790, 0.0073, 0.0037, 0.1278, 0.0027], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,026][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0190, 0.0046, 0.0055, 0.0085, 0.0104, 0.0128, 0.0194, 0.0318, 0.0331,
        0.0703, 0.0988, 0.1527, 0.1090, 0.4242], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,027][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0142, 0.1259, 0.0065, 0.1003, 0.0042, 0.0224, 0.0839, 0.0064, 0.0602,
        0.0048, 0.0397, 0.1357, 0.0138, 0.3819], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,030][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1424, 0.0796, 0.0529, 0.0827, 0.0526, 0.0631, 0.0637, 0.0601, 0.0666,
        0.0595, 0.0698, 0.0718, 0.0474, 0.0876], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,031][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1051, 0.0887, 0.0455, 0.0955, 0.0380, 0.0722, 0.0592, 0.0621, 0.0741,
        0.0520, 0.0732, 0.0594, 0.0501, 0.1249], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,032][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2109, 0.0735, 0.0914, 0.0698, 0.0492, 0.0493, 0.0426, 0.0680, 0.0347,
        0.0620, 0.0735, 0.0330, 0.0506, 0.0914], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,033][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.1219, 0.0892, 0.1840, 0.0680, 0.0816, 0.0119, 0.0405, 0.0104, 0.0621,
        0.0180, 0.0565, 0.0534, 0.0341, 0.0661, 0.1023], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,035][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([5.2879e-04, 5.4731e-05, 3.4888e-03, 5.3686e-05, 4.9864e-01, 3.5456e-05,
        3.8551e-05, 3.6641e-05, 1.6873e-05, 9.5048e-05, 1.1380e-04, 3.4251e-05,
        7.6875e-05, 4.7834e-06, 4.9678e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,040][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.1486, 0.0616, 0.0243, 0.0394, 0.1452, 0.0456, 0.0563, 0.0227, 0.0632,
        0.0341, 0.0306, 0.0763, 0.0659, 0.0312, 0.1550], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,041][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([8.0323e-04, 5.6715e-07, 1.1850e-04, 5.7214e-07, 2.9742e-03, 6.7313e-06,
        1.7667e-06, 5.2546e-06, 1.8713e-05, 2.9181e-04, 7.1268e-05, 5.4284e-05,
        1.4930e-03, 1.0166e-04, 9.9406e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,042][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([4.5081e-03, 3.8343e-04, 9.0170e-03, 2.4401e-04, 3.9117e-02, 1.9936e-04,
        2.1767e-04, 5.4339e-04, 1.0765e-03, 3.8523e-04, 2.2125e-03, 1.7651e-03,
        2.1594e-03, 6.0040e-03, 9.3217e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,043][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([1.0272e-03, 1.5153e-07, 1.8638e-05, 2.5449e-08, 6.0434e-01, 4.4389e-07,
        1.7419e-08, 6.2247e-08, 5.4542e-09, 3.4185e-08, 1.3583e-07, 1.1220e-08,
        8.0339e-07, 2.5816e-09, 3.9461e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,047][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.1212, 0.0725, 0.2464, 0.0368, 0.1482, 0.0126, 0.0218, 0.0223, 0.0226,
        0.0250, 0.0144, 0.0276, 0.0359, 0.0401, 0.1528], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,048][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0557, 0.0169, 0.0093, 0.0220, 0.0043, 0.0247, 0.0365, 0.0259, 0.0486,
        0.0489, 0.1217, 0.1742, 0.0147, 0.3177, 0.0788], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,049][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1284, 0.0911, 0.1704, 0.0696, 0.0724, 0.0236, 0.0531, 0.0182, 0.0511,
        0.0225, 0.0427, 0.0699, 0.0440, 0.0689, 0.0740], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,053][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1401, 0.1019, 0.1247, 0.0859, 0.0058, 0.0525, 0.0658, 0.0345, 0.0710,
        0.0465, 0.0644, 0.0756, 0.0426, 0.0834, 0.0054], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,054][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0861, 0.0670, 0.0675, 0.0559, 0.2459, 0.0390, 0.0359, 0.0150, 0.0373,
        0.0149, 0.0376, 0.0330, 0.0177, 0.0385, 0.2087], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,055][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0991, 0.0643, 0.0618, 0.0650, 0.0560, 0.0620, 0.0492, 0.0682, 0.0380,
        0.0791, 0.0859, 0.0407, 0.0665, 0.0877, 0.0766], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,060][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1992, 0.0196, 0.0172, 0.0236, 0.0774, 0.0977, 0.0187, 0.0475, 0.0230,
        0.0381, 0.0188, 0.0174, 0.0661, 0.0156, 0.1051, 0.2150],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,060][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.7427e-04, 5.8106e-04, 1.0030e-03, 1.2635e-03, 1.1328e-03, 6.5241e-03,
        1.4090e-04, 3.2773e-04, 7.6414e-04, 1.2305e-04, 3.5717e-04, 1.7539e-04,
        1.4835e-04, 5.0769e-05, 9.0896e-04, 9.8612e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,061][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1694, 0.0424, 0.0310, 0.0511, 0.0259, 0.0762, 0.0440, 0.0573, 0.0730,
        0.0642, 0.0721, 0.0541, 0.0657, 0.0719, 0.0259, 0.0759],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,063][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.5568e-04, 4.5844e-06, 1.1032e-06, 3.9827e-06, 1.2409e-05, 4.5409e-05,
        1.1757e-05, 3.8497e-05, 4.6983e-05, 2.9122e-04, 1.4064e-04, 2.0578e-04,
        4.7920e-04, 6.4977e-04, 4.6592e-03, 9.9255e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,066][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0825, 0.0064, 0.0059, 0.0064, 0.0070, 0.0106, 0.0074, 0.0101, 0.0188,
        0.0225, 0.0391, 0.0213, 0.0359, 0.0426, 0.0759, 0.6073],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,067][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9475e-02, 2.1578e-05, 5.5456e-04, 2.1839e-05, 8.1511e-04, 1.8011e-03,
        1.2748e-05, 7.0304e-06, 5.9544e-06, 5.3177e-05, 1.5010e-05, 7.0688e-06,
        7.9174e-06, 1.0690e-06, 3.3270e-04, 9.5687e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,068][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0757, 0.0095, 0.1285, 0.0093, 0.1527, 0.0113, 0.0135, 0.0610, 0.0070,
        0.1170, 0.0082, 0.0105, 0.1234, 0.0097, 0.2395, 0.0233],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,071][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0183, 0.0041, 0.0062, 0.0060, 0.0061, 0.0060, 0.0116, 0.0135, 0.0149,
        0.0236, 0.0546, 0.0752, 0.0456, 0.3010, 0.1943, 0.2189],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,073][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0721, 0.0712, 0.0145, 0.0902, 0.0189, 0.0390, 0.1026, 0.0353, 0.0794,
        0.0639, 0.0740, 0.1244, 0.0564, 0.0966, 0.0263, 0.0352],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,073][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1096, 0.0601, 0.0394, 0.0638, 0.0535, 0.0594, 0.0533, 0.0533, 0.0589,
        0.0724, 0.0533, 0.0574, 0.0534, 0.0864, 0.0673, 0.0586],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,074][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0787, 0.0555, 0.0406, 0.0626, 0.0368, 0.1043, 0.0510, 0.0304, 0.0537,
        0.0337, 0.0555, 0.0490, 0.0274, 0.0659, 0.0375, 0.2174],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,079][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2196, 0.0775, 0.0550, 0.0926, 0.0412, 0.0407, 0.0372, 0.0469, 0.0393,
        0.0454, 0.0688, 0.0334, 0.0252, 0.0835, 0.0391, 0.0547],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,080][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2233, 0.0176, 0.0646, 0.0136, 0.0964, 0.0284, 0.0123, 0.0544, 0.0116,
        0.0939, 0.0114, 0.0216, 0.0462, 0.0161, 0.1534, 0.1162, 0.0188],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,080][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3931e-04, 1.1436e-03, 2.3232e-04, 1.2521e-03, 9.7012e-05, 1.3496e-04,
        4.3330e-01, 1.8446e-04, 1.1690e-03, 9.9730e-04, 3.4123e-03, 1.4676e-02,
        1.0477e-04, 2.8413e-04, 6.8384e-05, 1.1750e-04, 5.4238e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,083][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0984, 0.0503, 0.0380, 0.0767, 0.0299, 0.0461, 0.0156, 0.0583, 0.0773,
        0.0435, 0.1172, 0.0182, 0.0272, 0.1631, 0.0354, 0.0872, 0.0176],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,085][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.6271e-03, 2.7563e-04, 2.9102e-05, 1.7645e-04, 4.5692e-05, 3.7953e-04,
        1.3217e-03, 5.5957e-04, 1.7627e-03, 1.7712e-03, 4.8148e-03, 1.9680e-02,
        3.4863e-03, 2.9212e-02, 9.1363e-03, 1.3344e-01, 7.9028e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,086][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0230, 0.0027, 0.0028, 0.0029, 0.0031, 0.0191, 0.0076, 0.0071, 0.0115,
        0.0266, 0.0251, 0.0192, 0.0317, 0.0223, 0.0420, 0.5573, 0.1960],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,087][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0165, 0.0525, 0.0014, 0.0461, 0.0052, 0.0247, 0.4136, 0.0038, 0.0248,
        0.0043, 0.0313, 0.1007, 0.0039, 0.0131, 0.0021, 0.0038, 0.2522],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,091][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1072, 0.0025, 0.1024, 0.0024, 0.1189, 0.0157, 0.0027, 0.1023, 0.0026,
        0.1296, 0.0054, 0.0021, 0.1138, 0.0023, 0.2150, 0.0710, 0.0041],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,092][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0146, 0.0027, 0.0024, 0.0042, 0.0021, 0.0037, 0.0042, 0.0077, 0.0100,
        0.0126, 0.0316, 0.0370, 0.0278, 0.2102, 0.0683, 0.2887, 0.2722],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,093][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0068, 0.0336, 0.0032, 0.0589, 0.0055, 0.0458, 0.1354, 0.0064, 0.0433,
        0.0111, 0.0352, 0.1939, 0.0113, 0.0992, 0.0096, 0.0232, 0.2777],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,096][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1048, 0.0641, 0.0399, 0.0705, 0.0384, 0.0474, 0.0551, 0.0465, 0.0651,
        0.0410, 0.0644, 0.0663, 0.0516, 0.0696, 0.0454, 0.0596, 0.0702],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,098][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0742, 0.0577, 0.0322, 0.0681, 0.0278, 0.0451, 0.1262, 0.0339, 0.0540,
        0.0387, 0.0696, 0.0815, 0.0347, 0.0549, 0.0270, 0.0360, 0.1385],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,099][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1756, 0.0658, 0.0706, 0.0629, 0.0415, 0.0427, 0.0482, 0.0557, 0.0276,
        0.0541, 0.0549, 0.0356, 0.0394, 0.0710, 0.0404, 0.0667, 0.0473],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,100][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1610, 0.0541, 0.0880, 0.0416, 0.0589, 0.0386, 0.0236, 0.0319, 0.0322,
        0.0591, 0.0434, 0.0219, 0.0808, 0.0395, 0.0734, 0.0474, 0.0312, 0.0733],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,102][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([2.0766e-04, 5.1517e-04, 4.2581e-04, 2.9635e-04, 1.1465e-04, 1.2987e-04,
        1.1766e-04, 3.4879e-05, 3.3232e-04, 1.1597e-04, 1.3725e-04, 2.4393e-04,
        6.0137e-04, 1.9933e-04, 7.2040e-05, 3.9593e-05, 8.1969e-05, 9.9633e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,104][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1461, 0.0405, 0.0265, 0.0530, 0.0326, 0.0398, 0.0583, 0.0339, 0.0477,
        0.0477, 0.0615, 0.0678, 0.0545, 0.0579, 0.0317, 0.0465, 0.0604, 0.0937],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,105][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([1.0685e-04, 9.6983e-08, 5.0251e-06, 1.6220e-07, 9.3372e-07, 1.5826e-06,
        5.8609e-07, 4.1695e-06, 1.9184e-06, 5.3877e-05, 9.8505e-06, 1.4126e-05,
        3.1835e-04, 1.9266e-05, 2.1428e-04, 8.2438e-04, 3.0895e-04, 9.9812e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,106][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([2.3356e-02, 1.7002e-03, 2.3950e-03, 9.4288e-04, 7.7054e-04, 8.6606e-04,
        1.4403e-03, 1.2441e-03, 1.8253e-03, 5.7473e-03, 3.7954e-03, 4.4143e-03,
        4.3127e-03, 8.5070e-03, 6.0027e-03, 1.6405e-02, 2.3877e-02, 8.9240e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,108][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.5155e-03, 3.1047e-05, 2.7624e-04, 4.6625e-06, 2.7509e-05, 2.9957e-06,
        1.2455e-05, 2.4856e-06, 1.1832e-06, 5.1673e-06, 1.6073e-06, 7.4269e-06,
        1.6002e-05, 4.3832e-07, 7.9909e-06, 9.6665e-08, 4.5531e-06, 9.9708e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,110][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1043, 0.0254, 0.0779, 0.0141, 0.0887, 0.0153, 0.0138, 0.0343, 0.0147,
        0.0886, 0.0143, 0.0112, 0.1274, 0.0217, 0.0906, 0.0246, 0.0140, 0.2190],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,111][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0367, 0.0044, 0.0021, 0.0067, 0.0024, 0.0043, 0.0060, 0.0042, 0.0112,
        0.0089, 0.0278, 0.0403, 0.0750, 0.1308, 0.0463, 0.2333, 0.2614, 0.0982],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,112][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0987, 0.0527, 0.0261, 0.0567, 0.0221, 0.0292, 0.0404, 0.0380, 0.0576,
        0.1122, 0.0474, 0.0708, 0.0843, 0.0516, 0.0271, 0.0282, 0.0533, 0.1034],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,117][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1076, 0.0622, 0.0444, 0.0573, 0.0614, 0.0421, 0.0575, 0.0354, 0.0492,
        0.0462, 0.0487, 0.0621, 0.0510, 0.0646, 0.0734, 0.0519, 0.0712, 0.0139],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,118][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0909, 0.0531, 0.0279, 0.0555, 0.0227, 0.0440, 0.0487, 0.0222, 0.0459,
        0.0237, 0.0401, 0.0595, 0.0366, 0.0519, 0.0216, 0.0296, 0.0497, 0.2762],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,119][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.2189, 0.0852, 0.0528, 0.0676, 0.0315, 0.0332, 0.0250, 0.0486, 0.0569,
        0.0522, 0.0668, 0.0232, 0.0304, 0.0634, 0.0303, 0.0527, 0.0243, 0.0369],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,121][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2146, 0.0188, 0.0408, 0.0157, 0.0635, 0.0524, 0.0167, 0.0539, 0.0173,
        0.0595, 0.0160, 0.0251, 0.0278, 0.0173, 0.0987, 0.1403, 0.0271, 0.0793,
        0.0151], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,123][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.0641e-03, 8.9848e-03, 3.0073e-05, 2.6123e-02, 6.3293e-05, 2.3095e-04,
        1.0627e-03, 3.7216e-05, 2.5760e-02, 1.8241e-04, 1.4921e-02, 1.4073e-03,
        9.7394e-05, 6.9820e-03, 4.7528e-05, 6.6511e-04, 9.9164e-04, 5.2953e-05,
        9.0830e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,124][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1033, 0.0421, 0.0169, 0.0613, 0.0224, 0.0377, 0.0156, 0.0450, 0.0662,
        0.0349, 0.0903, 0.0185, 0.0188, 0.1855, 0.0248, 0.0530, 0.0174, 0.0221,
        0.1241], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,125][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2054e-03, 6.3570e-05, 1.7259e-06, 3.0482e-05, 4.3399e-06, 7.2739e-05,
        1.0142e-04, 3.0248e-05, 3.9510e-04, 2.6530e-04, 6.0020e-04, 2.4388e-03,
        3.8687e-04, 4.4172e-03, 7.1844e-04, 2.5236e-01, 7.1720e-02, 1.5258e-02,
        6.4993e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,128][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.9783e-02, 1.0584e-03, 3.1994e-04, 1.5708e-03, 5.6557e-04, 1.0583e-02,
        2.8465e-03, 4.4374e-03, 3.8783e-03, 2.5358e-02, 9.9336e-03, 7.4047e-03,
        2.7171e-02, 1.2098e-02, 6.9872e-03, 3.5562e-01, 7.9812e-02, 1.6667e-01,
        2.6390e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,129][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0297, 0.0436, 0.0004, 0.0587, 0.0014, 0.0250, 0.1856, 0.0075, 0.0395,
        0.0096, 0.0167, 0.1356, 0.0008, 0.0165, 0.0006, 0.0049, 0.1147, 0.0036,
        0.3059], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,130][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0853, 0.0038, 0.0262, 0.0033, 0.0460, 0.0115, 0.0031, 0.0366, 0.0046,
        0.1042, 0.0166, 0.0026, 0.0572, 0.0046, 0.0866, 0.0553, 0.0050, 0.1473,
        0.3003], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,131][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0154, 0.0022, 0.0021, 0.0030, 0.0020, 0.0027, 0.0032, 0.0045, 0.0040,
        0.0117, 0.0117, 0.0193, 0.0252, 0.0962, 0.0444, 0.1272, 0.1674, 0.1672,
        0.2907], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,135][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0054, 0.0388, 0.0019, 0.0695, 0.0030, 0.0315, 0.0852, 0.0057, 0.0495,
        0.0058, 0.0338, 0.1521, 0.0080, 0.1174, 0.0049, 0.0175, 0.1676, 0.0106,
        0.1919], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,136][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0905, 0.0538, 0.0281, 0.0609, 0.0353, 0.0414, 0.0516, 0.0410, 0.0551,
        0.0437, 0.0551, 0.0592, 0.0420, 0.0621, 0.0420, 0.0543, 0.0662, 0.0348,
        0.0828], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,137][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0706, 0.0540, 0.0221, 0.0695, 0.0260, 0.0544, 0.0626, 0.0343, 0.0619,
        0.0395, 0.0625, 0.0625, 0.0350, 0.0668, 0.0268, 0.0546, 0.0696, 0.0300,
        0.0974], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,142][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1578, 0.0608, 0.0623, 0.0614, 0.0380, 0.0452, 0.0398, 0.0484, 0.0286,
        0.0473, 0.0573, 0.0285, 0.0294, 0.0610, 0.0353, 0.0632, 0.0370, 0.0413,
        0.0573], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,145][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:49,149][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9429],
        [19685],
        [    1],
        [21827],
        [14962],
        [18388],
        [33380],
        [16288],
        [12691],
        [41898],
        [34799],
        [40044],
        [28221],
        [ 9707],
        [22255],
        [23243],
        [32198],
        [42647],
        [19568]], device='cuda:0')
[2024-07-24 10:19:49,151][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[44533],
        [41573],
        [    1],
        [42117],
        [ 7480],
        [40661],
        [35465],
        [44145],
        [40080],
        [44011],
        [36224],
        [28199],
        [22615],
        [38910],
        [ 3040],
        [32358],
        [23815],
        [28350],
        [32653]], device='cuda:0')
[2024-07-24 10:19:49,152][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 4692],
        [ 4602],
        [ 6888],
        [ 4930],
        [ 9246],
        [ 4900],
        [ 5474],
        [ 4504],
        [ 4585],
        [ 5586],
        [ 6051],
        [ 5356],
        [ 7916],
        [ 5209],
        [10428],
        [ 7328],
        [ 7628],
        [ 9876],
        [ 7158]], device='cuda:0')
[2024-07-24 10:19:49,155][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[37125],
        [18878],
        [ 1301],
        [34753],
        [ 3322],
        [31215],
        [47000],
        [11965],
        [20952],
        [39248],
        [24978],
        [47606],
        [ 3431],
        [ 8306],
        [ 2838],
        [14654],
        [46500],
        [31894],
        [22508]], device='cuda:0')
[2024-07-24 10:19:49,157][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19100],
        [18992],
        [18482],
        [26588],
        [20667],
        [24087],
        [25958],
        [27928],
        [28361],
        [28380],
        [30856],
        [32481],
        [30304],
        [31232],
        [34792],
        [34102],
        [37943],
        [33036],
        [40276]], device='cuda:0')
[2024-07-24 10:19:49,158][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[34216],
        [37083],
        [12351],
        [25913],
        [39972],
        [ 8497],
        [24650],
        [25664],
        [34250],
        [ 5710],
        [37584],
        [38283],
        [24039],
        [39493],
        [40443],
        [16200],
        [31162],
        [27444],
        [27612]], device='cuda:0')
[2024-07-24 10:19:49,161][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[33134],
        [32322],
        [  275],
        [ 5212],
        [11142],
        [18274],
        [22418],
        [19060],
        [13703],
        [22825],
        [23785],
        [18852],
        [29691],
        [ 5538],
        [17253],
        [24669],
        [26174],
        [35555],
        [23917]], device='cuda:0')
[2024-07-24 10:19:49,164][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[21421],
        [22126],
        [ 2263],
        [21424],
        [24557],
        [27878],
        [16862],
        [29088],
        [23611],
        [44191],
        [22883],
        [20067],
        [28508],
        [24631],
        [25981],
        [33706],
        [17672],
        [35825],
        [21245]], device='cuda:0')
[2024-07-24 10:19:49,165][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18993],
        [19173],
        [12987],
        [ 3655],
        [ 6660],
        [ 3407],
        [ 5115],
        [14896],
        [13384],
        [ 8679],
        [ 9898],
        [10566],
        [13218],
        [13241],
        [13176],
        [24543],
        [26257],
        [43099],
        [20086]], device='cuda:0')
[2024-07-24 10:19:49,167][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7493],
        [ 6646],
        [ 3394],
        [10558],
        [17567],
        [30508],
        [31285],
        [33973],
        [32085],
        [35373],
        [26665],
        [34079],
        [40551],
        [19881],
        [23119],
        [20789],
        [22225],
        [30821],
        [35753]], device='cuda:0')
[2024-07-24 10:19:49,169][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20859],
        [19034],
        [15870],
        [22407],
        [14687],
        [28761],
        [26990],
        [24050],
        [25071],
        [22940],
        [23833],
        [18742],
        [16239],
        [10502],
        [11978],
        [14137],
        [16742],
        [22926],
        [16179]], device='cuda:0')
[2024-07-24 10:19:49,171][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40695],
        [43852],
        [43864],
        [43908],
        [40848],
        [42854],
        [41626],
        [41352],
        [42516],
        [38587],
        [42054],
        [41376],
        [39741],
        [40721],
        [40475],
        [38857],
        [40388],
        [37329],
        [40360]], device='cuda:0')
[2024-07-24 10:19:49,173][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[  382],
        [  204],
        [ 3598],
        [ 1075],
        [18757],
        [ 1190],
        [ 7786],
        [ 5532],
        [ 1370],
        [17961],
        [ 1257],
        [ 7159],
        [ 6629],
        [ 2434],
        [38800],
        [ 1434],
        [12615],
        [34193],
        [ 3878]], device='cuda:0')
[2024-07-24 10:19:49,175][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39355],
        [37495],
        [28153],
        [27444],
        [23473],
        [26396],
        [25967],
        [31908],
        [25289],
        [27842],
        [25757],
        [27901],
        [29458],
        [27520],
        [22952],
        [24489],
        [22857],
        [25490],
        [21173]], device='cuda:0')
[2024-07-24 10:19:49,178][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[43782],
        [34753],
        [    8],
        [44258],
        [46752],
        [46821],
        [49757],
        [47864],
        [31799],
        [49842],
        [44951],
        [50109],
        [41454],
        [ 8850],
        [46509],
        [43334],
        [49638],
        [49658],
        [40545]], device='cuda:0')
[2024-07-24 10:19:49,180][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[46565],
        [46485],
        [35987],
        [44126],
        [30953],
        [39736],
        [43462],
        [43439],
        [44423],
        [41498],
        [44922],
        [45502],
        [37780],
        [45372],
        [34471],
        [43732],
        [45497],
        [37581],
        [43525]], device='cuda:0')
[2024-07-24 10:19:49,181][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11263],
        [14177],
        [38341],
        [10369],
        [21830],
        [23079],
        [ 4625],
        [20008],
        [19772],
        [16446],
        [17388],
        [ 4996],
        [27698],
        [27975],
        [21380],
        [23147],
        [ 4843],
        [13906],
        [ 8554]], device='cuda:0')
[2024-07-24 10:19:49,183][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[46789],
        [43781],
        [42214],
        [47301],
        [46834],
        [46696],
        [47186],
        [47806],
        [47106],
        [47188],
        [45925],
        [45593],
        [47281],
        [46553],
        [47987],
        [47034],
        [46089],
        [46954],
        [44830]], device='cuda:0')
[2024-07-24 10:19:49,186][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1541],
        [  775],
        [ 6049],
        [17949],
        [13671],
        [ 9938],
        [17001],
        [16355],
        [16829],
        [23544],
        [26386],
        [23693],
        [16241],
        [19949],
        [19805],
        [16657],
        [21560],
        [12020],
        [28138]], device='cuda:0')
[2024-07-24 10:19:49,187][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 1296],
        [ 1501],
        [12568],
        [10114],
        [34088],
        [ 8720],
        [ 6228],
        [41935],
        [14311],
        [32334],
        [13771],
        [ 7335],
        [24790],
        [22007],
        [34683],
        [ 7167],
        [ 6235],
        [17860],
        [14779]], device='cuda:0')
[2024-07-24 10:19:49,189][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12352],
        [12268],
        [10218],
        [17321],
        [10971],
        [ 2239],
        [11106],
        [ 1211],
        [ 7478],
        [  292],
        [ 9655],
        [ 9626],
        [ 2478],
        [10277],
        [ 9209],
        [ 1407],
        [ 9243],
        [  552],
        [ 7948]], device='cuda:0')
[2024-07-24 10:19:49,193][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[48858],
        [48783],
        [35819],
        [40672],
        [27640],
        [34829],
        [36545],
        [32722],
        [34540],
        [38562],
        [39253],
        [40965],
        [34217],
        [42344],
        [28569],
        [39912],
        [42380],
        [25905],
        [43262]], device='cuda:0')
[2024-07-24 10:19:49,194][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[36917],
        [35782],
        [26302],
        [26284],
        [24576],
        [26769],
        [29776],
        [33444],
        [36061],
        [39355],
        [36764],
        [32120],
        [28126],
        [41313],
        [42161],
        [37527],
        [38607],
        [36132],
        [24539]], device='cuda:0')
[2024-07-24 10:19:49,196][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33535],
        [23863],
        [28587],
        [27849],
        [31600],
        [34074],
        [32033],
        [34182],
        [29238],
        [33315],
        [30041],
        [25423],
        [32107],
        [18199],
        [31255],
        [29889],
        [27852],
        [34283],
        [25596]], device='cuda:0')
[2024-07-24 10:19:49,198][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30661],
        [29814],
        [29565],
        [30468],
        [29348],
        [32277],
        [32528],
        [33715],
        [34584],
        [34467],
        [35600],
        [35291],
        [35085],
        [34230],
        [33240],
        [34731],
        [34815],
        [34151],
        [34635]], device='cuda:0')
[2024-07-24 10:19:49,200][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[50127],
        [50235],
        [50142],
        [50228],
        [50063],
        [50102],
        [50027],
        [50100],
        [50097],
        [49973],
        [50023],
        [49962],
        [49958],
        [50106],
        [49593],
        [50028],
        [49573],
        [49620],
        [49923]], device='cuda:0')
[2024-07-24 10:19:49,202][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6568],
        [14325],
        [49967],
        [49039],
        [49948],
        [49039],
        [49721],
        [41627],
        [49811],
        [49730],
        [49249],
        [49260],
        [49302],
        [48976],
        [48298],
        [49111],
        [48439],
        [49040],
        [48515]], device='cuda:0')
[2024-07-24 10:19:49,204][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1249],
        [ 996],
        [1621],
        [1124],
        [1834],
        [2227],
        [2172],
        [1325],
        [1486],
        [1342],
        [1615],
        [2016],
        [1600],
        [1185],
        [2675],
        [1859],
        [2282],
        [2892],
        [2105]], device='cuda:0')
[2024-07-24 10:19:49,207][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4782],
        [13201],
        [50217],
        [ 4783],
        [ 2754],
        [ 3223],
        [  354],
        [ 1570],
        [14875],
        [  338],
        [ 3969],
        [  128],
        [ 7534],
        [38546],
        [ 2945],
        [ 6308],
        [  426],
        [  740],
        [ 7995]], device='cuda:0')
[2024-07-24 10:19:49,209][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973],
        [24973]], device='cuda:0')
[2024-07-24 10:19:49,238][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:49,240][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,240][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,241][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,242][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,242][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,243][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,244][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,247][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,250][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,251][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,251][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,252][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,253][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2837, 0.7163], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,255][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9333, 0.0667], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,257][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5666, 0.4334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,258][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5668, 0.4332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,259][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9264, 0.0736], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,260][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2804, 0.7196], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,262][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9309, 0.0691], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,264][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9771, 0.0229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,265][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8694, 0.1306], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,265][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2117, 0.7883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,266][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0241, 0.9759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,270][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6688, 0.3312], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,271][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0125, 0.2826, 0.7049], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,272][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.8949, 0.0614, 0.0438], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,272][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.4036, 0.2942, 0.3022], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,276][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.3755, 0.2697, 0.3548], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,277][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.7851, 0.1193, 0.0956], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,278][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.1693, 0.7953, 0.0354], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,279][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.6731, 0.2685, 0.0584], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,283][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.7796, 0.1523, 0.0681], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,283][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.6461, 0.3426, 0.0113], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,284][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0575, 0.8065, 0.1360], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,285][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0272, 0.4690, 0.5039], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,289][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.0040, 0.0045, 0.9915], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,290][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0236, 0.1968, 0.6246, 0.1550], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,290][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7913, 0.0553, 0.0491, 0.1043], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,291][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3044, 0.2281, 0.2381, 0.2294], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,295][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2724, 0.1918, 0.2551, 0.2808], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,296][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6209, 0.0915, 0.1554, 0.1321], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,297][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1134, 0.6856, 0.0033, 0.1977], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,298][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3621, 0.1618, 0.2826, 0.1935], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,302][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4962, 0.0602, 0.2607, 0.1829], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,302][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7037, 0.1400, 0.0323, 0.1240], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,303][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1051, 0.1550, 0.2075, 0.5324], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,304][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0183, 0.3040, 0.4326, 0.2451], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,308][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1652, 0.2099, 0.0445, 0.5804], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,309][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0046, 0.0960, 0.6549, 0.0922, 0.1523], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,310][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.7803, 0.0500, 0.0361, 0.1058, 0.0279], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,310][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.2560, 0.1805, 0.1842, 0.1810, 0.1983], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,314][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.2206, 0.1572, 0.2088, 0.2300, 0.1834], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,315][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.5688, 0.1168, 0.0775, 0.1276, 0.1093], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,316][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0539, 0.1872, 0.5693, 0.1293, 0.0602], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,317][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.3805, 0.1216, 0.1713, 0.1380, 0.1886], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,321][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.5415, 0.1611, 0.0522, 0.2037, 0.0415], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,322][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.5295, 0.3160, 0.0122, 0.1079, 0.0345], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,322][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0721, 0.3734, 0.1964, 0.3181, 0.0400], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,323][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0156, 0.2658, 0.2550, 0.2043, 0.2593], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,325][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([1.9094e-03, 1.9187e-03, 1.5795e-02, 6.8971e-04, 9.7969e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,327][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0281, 0.0914, 0.2729, 0.1128, 0.1733, 0.3214], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,328][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.7148, 0.0524, 0.0427, 0.0975, 0.0321, 0.0605], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,329][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2086, 0.1541, 0.1595, 0.1543, 0.1712, 0.1524], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,330][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1792, 0.1250, 0.1656, 0.1876, 0.1485, 0.1942], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,334][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4722, 0.0932, 0.0872, 0.0983, 0.1116, 0.1376], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,334][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0515, 0.7125, 0.0116, 0.0246, 0.0093, 0.1905], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,335][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3825, 0.0967, 0.1159, 0.2267, 0.0220, 0.1563], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,336][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.3813, 0.0428, 0.1088, 0.1150, 0.1543, 0.1977], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,340][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4282, 0.2490, 0.0350, 0.0884, 0.0726, 0.1267], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,341][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1329, 0.1857, 0.2571, 0.2755, 0.1080, 0.0409], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,341][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0086, 0.1956, 0.2367, 0.1363, 0.2314, 0.1915], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,342][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.1863e-03, 3.9402e-03, 3.4757e-04, 1.8011e-03, 2.5204e-04, 9.9247e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,346][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0063, 0.0484, 0.1523, 0.0569, 0.0780, 0.4681, 0.1900],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,347][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6615, 0.0470, 0.0391, 0.0865, 0.0293, 0.0557, 0.0808],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,348][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1828, 0.1335, 0.1381, 0.1334, 0.1486, 0.1319, 0.1316],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,348][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1585, 0.1100, 0.1456, 0.1642, 0.1301, 0.1706, 0.1211],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,352][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3752, 0.0858, 0.0839, 0.0980, 0.0917, 0.1209, 0.1444],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,353][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1275, 0.5726, 0.0145, 0.0672, 0.0249, 0.1589, 0.0345],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,354][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1308, 0.0983, 0.3806, 0.1506, 0.1560, 0.0417, 0.0419],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,355][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2677, 0.0469, 0.1395, 0.0917, 0.1631, 0.1705, 0.1206],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,359][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2850, 0.0963, 0.0154, 0.0499, 0.0360, 0.0578, 0.4597],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,360][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1110, 0.1512, 0.2308, 0.3056, 0.0971, 0.0375, 0.0667],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,360][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0108, 0.1562, 0.2210, 0.1240, 0.2071, 0.1571, 0.1238],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,361][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.4811e-04, 1.4318e-03, 5.6272e-04, 6.0238e-04, 1.3871e-04, 7.6491e-04,
        9.9565e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,365][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0025, 0.0187, 0.0731, 0.0236, 0.0691, 0.0850, 0.4868, 0.2411],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,366][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.6382, 0.0445, 0.0360, 0.0855, 0.0274, 0.0553, 0.0809, 0.0323],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,367][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1638, 0.1163, 0.1181, 0.1160, 0.1265, 0.1144, 0.1141, 0.1307],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,367][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1427, 0.0967, 0.1283, 0.1438, 0.1155, 0.1489, 0.1077, 0.1165],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,371][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.3909, 0.0740, 0.0653, 0.0859, 0.0736, 0.0987, 0.1136, 0.0981],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,372][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0556, 0.6448, 0.0040, 0.0393, 0.0016, 0.0440, 0.0383, 0.1724],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,373][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.3568, 0.0702, 0.0280, 0.2055, 0.0366, 0.0984, 0.1208, 0.0839],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,374][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.4176, 0.0507, 0.0655, 0.1002, 0.0834, 0.1543, 0.0945, 0.0337],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,378][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1953, 0.0779, 0.0110, 0.0492, 0.0312, 0.0966, 0.5157, 0.0230],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,379][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0781, 0.2533, 0.1604, 0.2898, 0.0496, 0.0506, 0.1036, 0.0146],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,379][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0102, 0.1316, 0.2021, 0.1022, 0.1943, 0.1248, 0.1002, 0.1346],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,380][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.5495e-04, 1.4055e-03, 1.1078e-04, 2.5784e-04, 4.1442e-05, 3.6584e-04,
        1.5746e-04, 9.9751e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,384][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0010, 0.0098, 0.0976, 0.0151, 0.0486, 0.0454, 0.2045, 0.5706, 0.0075],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,385][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.5745, 0.0436, 0.0371, 0.0768, 0.0277, 0.0493, 0.0732, 0.0307, 0.0870],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,386][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1451, 0.1039, 0.1071, 0.1035, 0.1149, 0.1022, 0.1018, 0.1180, 0.1036],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,386][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1270, 0.0868, 0.1141, 0.1291, 0.1020, 0.1338, 0.0958, 0.1038, 0.1076],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,390][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.2704, 0.0744, 0.0797, 0.0860, 0.0897, 0.1016, 0.1161, 0.0638, 0.1184],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,391][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([9.4504e-04, 4.1928e-04, 3.7483e-05, 3.0121e-04, 1.7079e-05, 1.9858e-04,
        6.5861e-04, 7.8787e-04, 9.9663e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,392][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0935, 0.1437, 0.2159, 0.1633, 0.0252, 0.0352, 0.0630, 0.1368, 0.1234],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,393][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2582, 0.0854, 0.0749, 0.1001, 0.1084, 0.1123, 0.0942, 0.0523, 0.1142],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,397][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2691, 0.0561, 0.0134, 0.0494, 0.0367, 0.0450, 0.4542, 0.0322, 0.0438],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,398][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1135, 0.0964, 0.2227, 0.2823, 0.1012, 0.0344, 0.0696, 0.0243, 0.0556],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,398][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0090, 0.1269, 0.1771, 0.0996, 0.1657, 0.1343, 0.0874, 0.1353, 0.0646],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,399][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0142, 0.0454, 0.0124, 0.0318, 0.0032, 0.0212, 0.2039, 0.0301, 0.6380],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,403][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0006, 0.0120, 0.0401, 0.0187, 0.0385, 0.1462, 0.2040, 0.4433, 0.0165,
        0.0801], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,404][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.5881, 0.0391, 0.0273, 0.0740, 0.0207, 0.0484, 0.0694, 0.0279, 0.0900,
        0.0153], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,405][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1367, 0.0929, 0.0939, 0.0927, 0.1007, 0.0913, 0.0912, 0.1044, 0.0927,
        0.1034], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,406][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1130, 0.0765, 0.1005, 0.1148, 0.0906, 0.1171, 0.0852, 0.0913, 0.0959,
        0.1152], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,409][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.3074, 0.0681, 0.0486, 0.0766, 0.0581, 0.0797, 0.0818, 0.0686, 0.1069,
        0.1042], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,410][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0341, 0.2404, 0.0052, 0.0592, 0.0009, 0.0441, 0.0742, 0.1622, 0.0943,
        0.2855], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,411][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.2394, 0.0466, 0.1265, 0.0626, 0.0178, 0.0867, 0.0739, 0.2540, 0.0379,
        0.0546], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,412][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.2649, 0.0582, 0.0650, 0.0891, 0.0769, 0.2122, 0.0834, 0.0741, 0.0632,
        0.0128], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,416][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1836, 0.0950, 0.0221, 0.0524, 0.0595, 0.1023, 0.4019, 0.0294, 0.0347,
        0.0189], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,417][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0819, 0.1556, 0.1752, 0.3386, 0.0632, 0.0369, 0.0745, 0.0249, 0.0346,
        0.0146], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,417][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0089, 0.1197, 0.1402, 0.0910, 0.1388, 0.1099, 0.0821, 0.1103, 0.0520,
        0.1470], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,418][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([1.2947e-03, 1.6178e-03, 4.0917e-04, 1.1421e-03, 2.9145e-04, 8.0806e-04,
        1.7704e-03, 1.4780e-03, 2.6621e-03, 9.8853e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,422][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0035, 0.0295, 0.0974, 0.0349, 0.0368, 0.1176, 0.1313, 0.4107, 0.0318,
        0.0855, 0.0210], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,423][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.5385, 0.0404, 0.0330, 0.0732, 0.0251, 0.0467, 0.0689, 0.0283, 0.0832,
        0.0162, 0.0465], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,424][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1209, 0.0848, 0.0872, 0.0848, 0.0937, 0.0836, 0.0835, 0.0963, 0.0848,
        0.0965, 0.0838], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,425][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1024, 0.0703, 0.0929, 0.1058, 0.0831, 0.1086, 0.0775, 0.0832, 0.0871,
        0.1065, 0.0827], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,428][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1937, 0.0545, 0.0517, 0.0659, 0.0601, 0.0757, 0.0848, 0.0576, 0.0970,
        0.0940, 0.1649], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,429][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([8.5666e-04, 2.3781e-03, 5.6207e-05, 4.9390e-04, 8.7747e-05, 2.6502e-04,
        1.2067e-03, 1.7845e-03, 3.1563e-03, 1.0042e-03, 9.8871e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,430][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0462, 0.0308, 0.4260, 0.0721, 0.0724, 0.0316, 0.0200, 0.0143, 0.1106,
        0.1554, 0.0205], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,431][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1564, 0.0292, 0.0885, 0.0769, 0.1061, 0.2308, 0.0634, 0.0497, 0.0676,
        0.0601, 0.0713], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,436][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2513, 0.0845, 0.0165, 0.0325, 0.0422, 0.0635, 0.3876, 0.0296, 0.0274,
        0.0261, 0.0387], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,438][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1219, 0.0865, 0.2171, 0.2282, 0.0934, 0.0492, 0.0874, 0.0273, 0.0428,
        0.0250, 0.0211], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,439][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0086, 0.0988, 0.1365, 0.0794, 0.1269, 0.0965, 0.0689, 0.1108, 0.0441,
        0.1365, 0.0930], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,439][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.0726e-04, 1.7513e-03, 2.4269e-03, 6.3454e-04, 1.9439e-04, 1.6072e-03,
        1.0952e-03, 4.6705e-04, 1.3580e-03, 5.1572e-04, 9.8974e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,440][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0040, 0.0250, 0.0862, 0.0323, 0.0500, 0.1418, 0.1618, 0.2722, 0.0353,
        0.0746, 0.0540, 0.0627], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,445][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.5249, 0.0373, 0.0307, 0.0670, 0.0233, 0.0435, 0.0625, 0.0266, 0.0777,
        0.0155, 0.0443, 0.0468], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,445][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1118, 0.0783, 0.0808, 0.0781, 0.0871, 0.0772, 0.0770, 0.0891, 0.0783,
        0.0895, 0.0776, 0.0752], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,446][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0942, 0.0654, 0.0860, 0.0983, 0.0768, 0.1008, 0.0717, 0.0774, 0.0805,
        0.0985, 0.0761, 0.0744], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,447][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1610, 0.0496, 0.0476, 0.0561, 0.0522, 0.0621, 0.0788, 0.0575, 0.0764,
        0.0891, 0.1309, 0.1386], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,451][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0324, 0.3144, 0.0070, 0.0129, 0.0212, 0.0286, 0.0100, 0.1175, 0.2143,
        0.0163, 0.2198, 0.0056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,452][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0642, 0.0342, 0.2680, 0.1136, 0.0970, 0.0315, 0.0267, 0.0516, 0.1052,
        0.0634, 0.1156, 0.0290], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,452][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1314, 0.0227, 0.0557, 0.0570, 0.1053, 0.1320, 0.0745, 0.0377, 0.0627,
        0.0704, 0.0741, 0.1766], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,455][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1578, 0.0541, 0.0146, 0.0218, 0.0305, 0.0316, 0.3091, 0.0264, 0.0187,
        0.0249, 0.0292, 0.2814], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,457][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0935, 0.0473, 0.2458, 0.2645, 0.1010, 0.0259, 0.0497, 0.0475, 0.0253,
        0.0261, 0.0111, 0.0624], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,458][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0080, 0.0881, 0.1240, 0.0709, 0.1200, 0.0931, 0.0716, 0.1017, 0.0393,
        0.1302, 0.0780, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,459][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([7.8188e-04, 1.5414e-03, 2.4460e-03, 1.0276e-03, 1.0779e-03, 1.2510e-03,
        9.1267e-03, 7.5302e-04, 9.0994e-03, 2.5918e-03, 4.3909e-03, 9.6591e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,461][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0006, 0.0212, 0.0974, 0.0295, 0.0602, 0.1091, 0.1793, 0.2118, 0.0263,
        0.0926, 0.0598, 0.0850, 0.0273], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,463][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.5355, 0.0343, 0.0247, 0.0642, 0.0185, 0.0426, 0.0614, 0.0248, 0.0788,
        0.0137, 0.0426, 0.0469, 0.0121], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,464][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.1046, 0.0718, 0.0732, 0.0719, 0.0787, 0.0711, 0.0711, 0.0808, 0.0721,
        0.0804, 0.0712, 0.0692, 0.0839], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,465][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0857, 0.0598, 0.0788, 0.0891, 0.0705, 0.0914, 0.0657, 0.0702, 0.0737,
        0.0891, 0.0703, 0.0684, 0.0872], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,469][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.2072, 0.0480, 0.0367, 0.0561, 0.0472, 0.0600, 0.0565, 0.0470, 0.0727,
        0.0730, 0.1064, 0.1011, 0.0881], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,470][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0310, 0.0984, 0.0147, 0.0257, 0.0090, 0.0401, 0.0535, 0.0334, 0.0568,
        0.0213, 0.3894, 0.0373, 0.1894], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,471][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0351, 0.0228, 0.4198, 0.0397, 0.2347, 0.0423, 0.0056, 0.0176, 0.0407,
        0.0025, 0.0262, 0.0153, 0.0977], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,472][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.1103, 0.0181, 0.0467, 0.0532, 0.0956, 0.2463, 0.0359, 0.0499, 0.0433,
        0.0704, 0.0411, 0.0715, 0.1177], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,476][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.1147, 0.0710, 0.0065, 0.0208, 0.0240, 0.1066, 0.2445, 0.0169, 0.0187,
        0.0124, 0.0327, 0.3134, 0.0177], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,477][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0865, 0.0863, 0.1769, 0.1605, 0.0995, 0.0571, 0.0611, 0.0426, 0.0272,
        0.0229, 0.0283, 0.1040, 0.0470], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,477][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0070, 0.0920, 0.1058, 0.0754, 0.1012, 0.0902, 0.0667, 0.0895, 0.0388,
        0.1134, 0.0835, 0.0585, 0.0780], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,479][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ office] are: tensor([6.6206e-04, 2.2958e-03, 1.6218e-03, 7.8146e-04, 5.0377e-04, 3.0910e-04,
        5.0733e-04, 2.7883e-04, 6.8869e-04, 1.6146e-03, 2.0540e-03, 3.9563e-04,
        9.8829e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,482][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0045, 0.0266, 0.0790, 0.0315, 0.0584, 0.0782, 0.1395, 0.2329, 0.0282,
        0.0960, 0.0380, 0.0642, 0.0544, 0.0687], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,483][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.5119, 0.0337, 0.0285, 0.0608, 0.0215, 0.0388, 0.0566, 0.0239, 0.0688,
        0.0136, 0.0392, 0.0419, 0.0123, 0.0487], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,484][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0958, 0.0661, 0.0684, 0.0660, 0.0735, 0.0652, 0.0652, 0.0752, 0.0660,
        0.0754, 0.0654, 0.0636, 0.0780, 0.0760], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,486][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0815, 0.0568, 0.0749, 0.0843, 0.0661, 0.0862, 0.0622, 0.0666, 0.0695,
        0.0845, 0.0662, 0.0649, 0.0835, 0.0529], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,488][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1418, 0.0390, 0.0464, 0.0389, 0.0528, 0.0499, 0.0494, 0.0473, 0.0527,
        0.0711, 0.0834, 0.0831, 0.1000, 0.1442], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,489][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1495, 0.1858, 0.0173, 0.0402, 0.0392, 0.1980, 0.0287, 0.1127, 0.0329,
        0.0423, 0.0528, 0.0305, 0.0183, 0.0519], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,490][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0253, 0.0104, 0.1584, 0.0307, 0.0770, 0.0111, 0.0065, 0.0146, 0.0692,
        0.0266, 0.0434, 0.0134, 0.4612, 0.0523], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,493][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1117, 0.0137, 0.0522, 0.0459, 0.0927, 0.0677, 0.0342, 0.0430, 0.0567,
        0.0730, 0.0496, 0.0827, 0.1772, 0.0998], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,495][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1648, 0.0884, 0.0180, 0.0229, 0.0351, 0.0497, 0.2431, 0.0537, 0.0130,
        0.0256, 0.0182, 0.1538, 0.0276, 0.0862], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,496][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1146, 0.0549, 0.2193, 0.1685, 0.1043, 0.0347, 0.0513, 0.0427, 0.0159,
        0.0247, 0.0111, 0.0524, 0.0391, 0.0665], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,497][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0062, 0.0818, 0.1098, 0.0654, 0.1149, 0.0812, 0.0563, 0.0842, 0.0363,
        0.1130, 0.0774, 0.0541, 0.0842, 0.0354], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,501][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0259, 0.0203, 0.0721, 0.0125, 0.0707, 0.0493, 0.0835, 0.0476, 0.0173,
        0.1839, 0.0336, 0.1542, 0.1427, 0.0865], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,502][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0012, 0.0239, 0.1530, 0.0229, 0.0340, 0.1046, 0.1905, 0.1182, 0.0254,
        0.0608, 0.0205, 0.0924, 0.0253, 0.0960, 0.0315], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,503][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.4455, 0.0328, 0.0234, 0.0658, 0.0178, 0.0441, 0.0629, 0.0252, 0.0828,
        0.0140, 0.0444, 0.0496, 0.0129, 0.0602, 0.0185], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,505][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0923, 0.0612, 0.0625, 0.0611, 0.0673, 0.0602, 0.0603, 0.0692, 0.0615,
        0.0691, 0.0610, 0.0588, 0.0720, 0.0708, 0.0725], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,507][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0763, 0.0537, 0.0720, 0.0807, 0.0633, 0.0828, 0.0592, 0.0635, 0.0663,
        0.0802, 0.0625, 0.0608, 0.0782, 0.0496, 0.0511], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,508][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1610, 0.0479, 0.0307, 0.0476, 0.0392, 0.0616, 0.0508, 0.0386, 0.0506,
        0.0587, 0.0773, 0.0765, 0.0619, 0.1172, 0.0804], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,509][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0191, 0.0497, 0.7554, 0.0503, 0.0596, 0.0032, 0.0073, 0.0039, 0.0060,
        0.0018, 0.0072, 0.0069, 0.0009, 0.0126, 0.0162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,512][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0422, 0.0334, 0.2402, 0.0409, 0.0850, 0.0159, 0.0244, 0.0460, 0.0678,
        0.0134, 0.0305, 0.0295, 0.0902, 0.1841, 0.0562], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,514][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1018, 0.0407, 0.0103, 0.0441, 0.0139, 0.1075, 0.0331, 0.0283, 0.0364,
        0.0561, 0.0384, 0.1414, 0.1182, 0.2093, 0.0203], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,515][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0727, 0.0993, 0.0015, 0.0107, 0.0065, 0.0768, 0.3107, 0.0101, 0.0096,
        0.0045, 0.0070, 0.2341, 0.0128, 0.1352, 0.0082], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,516][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0346, 0.1369, 0.2554, 0.0764, 0.0544, 0.0204, 0.0943, 0.0222, 0.0166,
        0.0186, 0.0375, 0.0863, 0.0277, 0.0718, 0.0471], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,520][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0066, 0.0880, 0.0869, 0.0714, 0.0888, 0.0820, 0.0550, 0.0756, 0.0367,
        0.0949, 0.0710, 0.0531, 0.0708, 0.0334, 0.0858], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,521][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([2.3850e-05, 1.5520e-04, 2.5368e-03, 1.6061e-05, 1.7862e-01, 8.8996e-06,
        4.8300e-05, 2.3802e-05, 7.2595e-05, 1.3271e-04, 1.0184e-04, 1.7313e-04,
        3.3063e-04, 4.4301e-03, 8.1332e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,522][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0023, 0.0205, 0.0609, 0.0212, 0.0366, 0.0834, 0.1161, 0.2111, 0.0215,
        0.0763, 0.0414, 0.0602, 0.0291, 0.0847, 0.0344, 0.1003],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,524][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.4523, 0.0342, 0.0256, 0.0628, 0.0195, 0.0397, 0.0593, 0.0242, 0.0741,
        0.0136, 0.0414, 0.0455, 0.0124, 0.0543, 0.0187, 0.0226],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,526][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0850, 0.0572, 0.0589, 0.0571, 0.0632, 0.0563, 0.0563, 0.0649, 0.0572,
        0.0651, 0.0566, 0.0549, 0.0674, 0.0658, 0.0673, 0.0668],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,527][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0719, 0.0512, 0.0681, 0.0773, 0.0605, 0.0788, 0.0567, 0.0602, 0.0631,
        0.0764, 0.0604, 0.0588, 0.0752, 0.0477, 0.0493, 0.0444],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,528][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1208, 0.0412, 0.0324, 0.0431, 0.0363, 0.0452, 0.0445, 0.0272, 0.0557,
        0.0463, 0.0779, 0.0685, 0.0522, 0.1272, 0.0765, 0.1051],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,531][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0307, 0.1080, 0.0025, 0.0174, 0.0058, 0.3378, 0.0349, 0.0260, 0.0665,
        0.0183, 0.0290, 0.0263, 0.0124, 0.0854, 0.0042, 0.1946],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,533][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0609, 0.0249, 0.0277, 0.0666, 0.0099, 0.0308, 0.0328, 0.0422, 0.0845,
        0.0424, 0.0741, 0.0430, 0.2497, 0.0918, 0.0176, 0.1011],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,534][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0740, 0.0347, 0.0170, 0.0427, 0.0479, 0.0447, 0.0416, 0.0276, 0.0466,
        0.0647, 0.0447, 0.0782, 0.2165, 0.1520, 0.0570, 0.0102],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,534][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1436, 0.0602, 0.0062, 0.0228, 0.0185, 0.0568, 0.2048, 0.0167, 0.0130,
        0.0094, 0.0193, 0.2253, 0.0164, 0.1190, 0.0226, 0.0452],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,539][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0605, 0.0809, 0.1364, 0.0747, 0.0753, 0.0492, 0.0884, 0.0188, 0.0198,
        0.0158, 0.0214, 0.1162, 0.0331, 0.0676, 0.0768, 0.0651],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,540][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0048, 0.0711, 0.0881, 0.0541, 0.0850, 0.0699, 0.0471, 0.0715, 0.0332,
        0.0904, 0.0703, 0.0459, 0.0655, 0.0302, 0.0840, 0.0889],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,541][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.3833e-04, 7.6000e-04, 6.2565e-05, 1.9572e-04, 1.6124e-04, 1.0513e-03,
        1.1140e-04, 1.0216e-03, 3.4289e-04, 6.2610e-04, 1.4952e-04, 1.6135e-04,
        3.8487e-04, 3.6404e-03, 2.8875e-04, 9.9080e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,543][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0022, 0.0157, 0.0445, 0.0188, 0.0237, 0.1555, 0.0617, 0.2439, 0.0240,
        0.0478, 0.0271, 0.0616, 0.0200, 0.0573, 0.0222, 0.1132, 0.0609],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,545][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4509, 0.0336, 0.0262, 0.0586, 0.0195, 0.0380, 0.0542, 0.0233, 0.0684,
        0.0133, 0.0384, 0.0411, 0.0121, 0.0487, 0.0184, 0.0216, 0.0337],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,546][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0778, 0.0538, 0.0558, 0.0536, 0.0600, 0.0530, 0.0529, 0.0613, 0.0537,
        0.0616, 0.0533, 0.0516, 0.0639, 0.0620, 0.0642, 0.0631, 0.0584],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,547][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0700, 0.0496, 0.0661, 0.0743, 0.0584, 0.0762, 0.0540, 0.0587, 0.0604,
        0.0747, 0.0571, 0.0560, 0.0727, 0.0460, 0.0473, 0.0423, 0.0361],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,551][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0920, 0.0325, 0.0269, 0.0348, 0.0273, 0.0384, 0.0476, 0.0318, 0.0464,
        0.0521, 0.0683, 0.0773, 0.0632, 0.1053, 0.0603, 0.0944, 0.1015],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,552][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0225, 0.0981, 0.0054, 0.0082, 0.0111, 0.0939, 0.0061, 0.0746, 0.1369,
        0.0504, 0.1426, 0.0122, 0.0162, 0.0251, 0.0037, 0.2898, 0.0032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,553][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0332, 0.0403, 0.1948, 0.0554, 0.0658, 0.0121, 0.0115, 0.0637, 0.0707,
        0.0481, 0.0486, 0.0229, 0.1614, 0.0570, 0.0584, 0.0413, 0.0149],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,556][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0766, 0.0249, 0.0322, 0.0333, 0.0612, 0.0579, 0.0386, 0.0344, 0.0432,
        0.0382, 0.0413, 0.0866, 0.1402, 0.1567, 0.0500, 0.0289, 0.0559],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,558][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1021, 0.0450, 0.0076, 0.0141, 0.0188, 0.0230, 0.2108, 0.0143, 0.0102,
        0.0121, 0.0166, 0.1356, 0.0209, 0.1020, 0.0211, 0.0250, 0.2207],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,559][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0609, 0.0381, 0.1771, 0.1103, 0.0903, 0.0315, 0.0647, 0.0321, 0.0154,
        0.0205, 0.0103, 0.0766, 0.0382, 0.0461, 0.0752, 0.0534, 0.0591],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,560][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0054, 0.0592, 0.0848, 0.0492, 0.0806, 0.0628, 0.0502, 0.0752, 0.0281,
        0.0908, 0.0552, 0.0474, 0.0697, 0.0273, 0.0808, 0.0860, 0.0473],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,561][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([6.3320e-05, 1.9436e-04, 1.2970e-04, 4.5368e-05, 4.6822e-05, 8.9090e-05,
        1.1154e-01, 1.1172e-04, 3.2910e-04, 3.8095e-04, 5.1161e-04, 8.8621e-04,
        2.8604e-04, 3.0783e-03, 7.4067e-04, 4.1639e-04, 8.8115e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,564][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0006, 0.0122, 0.0564, 0.0123, 0.0338, 0.0589, 0.1612, 0.0909, 0.0191,
        0.0599, 0.0261, 0.0472, 0.0351, 0.0538, 0.0293, 0.0998, 0.1657, 0.0376],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,565][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.4625, 0.0292, 0.0202, 0.0547, 0.0155, 0.0374, 0.0531, 0.0217, 0.0696,
        0.0121, 0.0376, 0.0421, 0.0108, 0.0512, 0.0159, 0.0224, 0.0353, 0.0088],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,566][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0766, 0.0506, 0.0514, 0.0505, 0.0552, 0.0497, 0.0497, 0.0570, 0.0505,
        0.0566, 0.0500, 0.0482, 0.0590, 0.0579, 0.0590, 0.0588, 0.0545, 0.0648],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,570][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0669, 0.0475, 0.0622, 0.0696, 0.0552, 0.0709, 0.0513, 0.0551, 0.0572,
        0.0702, 0.0548, 0.0538, 0.0689, 0.0444, 0.0458, 0.0408, 0.0353, 0.0499],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,571][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.1005, 0.0324, 0.0268, 0.0377, 0.0276, 0.0393, 0.0413, 0.0263, 0.0470,
        0.0418, 0.0669, 0.0609, 0.0478, 0.1105, 0.0587, 0.0829, 0.0853, 0.0660],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,572][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0433, 0.1426, 0.0071, 0.0132, 0.0162, 0.0428, 0.0321, 0.0783, 0.0444,
        0.0144, 0.1541, 0.0453, 0.1756, 0.0496, 0.0040, 0.0174, 0.0170, 0.1027],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,575][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0852, 0.0287, 0.0433, 0.0314, 0.0807, 0.0263, 0.0095, 0.0350, 0.0333,
        0.0051, 0.0532, 0.0116, 0.2076, 0.0208, 0.0742, 0.0129, 0.0153, 0.2259],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,577][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.1022, 0.0505, 0.0362, 0.0561, 0.0563, 0.0285, 0.0363, 0.0780, 0.0646,
        0.0456, 0.0506, 0.0716, 0.0654, 0.1206, 0.0497, 0.0320, 0.0431, 0.0129],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,578][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0887, 0.0275, 0.0041, 0.0144, 0.0157, 0.0595, 0.1629, 0.0124, 0.0115,
        0.0073, 0.0225, 0.1560, 0.0168, 0.1254, 0.0228, 0.0571, 0.1816, 0.0137],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,579][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0477, 0.0501, 0.1636, 0.0823, 0.1291, 0.0321, 0.0477, 0.0240, 0.0100,
        0.0194, 0.0136, 0.0719, 0.0399, 0.0330, 0.1139, 0.0691, 0.0379, 0.0147],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,583][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0049, 0.0621, 0.0804, 0.0480, 0.0786, 0.0605, 0.0431, 0.0598, 0.0280,
        0.0787, 0.0554, 0.0396, 0.0629, 0.0278, 0.0773, 0.0766, 0.0397, 0.0766],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,584][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([1.4585e-03, 3.0969e-03, 2.6515e-04, 8.5459e-04, 5.2162e-04, 1.6620e-03,
        6.1208e-04, 3.6580e-04, 2.0383e-03, 1.8992e-03, 2.7042e-03, 1.0765e-03,
        4.2087e-03, 1.2407e-02, 1.4579e-03, 7.3247e-04, 1.7385e-03, 9.6290e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,585][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0016, 0.0118, 0.0185, 0.0118, 0.0197, 0.1297, 0.0761, 0.1808, 0.0223,
        0.0672, 0.0282, 0.0362, 0.0214, 0.0461, 0.0173, 0.1994, 0.0765, 0.0306,
        0.0047], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,588][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4368, 0.0317, 0.0255, 0.0553, 0.0193, 0.0360, 0.0524, 0.0223, 0.0646,
        0.0127, 0.0366, 0.0393, 0.0116, 0.0461, 0.0182, 0.0205, 0.0326, 0.0099,
        0.0286], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,590][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0681, 0.0474, 0.0494, 0.0475, 0.0531, 0.0469, 0.0469, 0.0540, 0.0476,
        0.0544, 0.0472, 0.0458, 0.0565, 0.0549, 0.0567, 0.0558, 0.0518, 0.0622,
        0.0538], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,590][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0633, 0.0453, 0.0589, 0.0665, 0.0522, 0.0675, 0.0486, 0.0526, 0.0547,
        0.0676, 0.0524, 0.0516, 0.0661, 0.0422, 0.0437, 0.0389, 0.0335, 0.0476,
        0.0469], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,591][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0751, 0.0240, 0.0223, 0.0269, 0.0244, 0.0322, 0.0358, 0.0209, 0.0393,
        0.0338, 0.0619, 0.0579, 0.0467, 0.0890, 0.0509, 0.0862, 0.0797, 0.0723,
        0.1208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,594][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.4374e-04, 1.1359e-04, 3.9967e-04, 1.0390e-04, 6.8481e-05, 5.0655e-04,
        1.0724e-04, 2.8925e-05, 4.3448e-04, 7.9757e-05, 5.1891e-04, 1.1362e-04,
        6.6190e-05, 8.5149e-05, 1.3222e-05, 5.8480e-04, 1.3245e-04, 2.0037e-03,
        9.9450e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,596][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0447, 0.0132, 0.0342, 0.0590, 0.0114, 0.0159, 0.0231, 0.0340, 0.0597,
        0.0290, 0.0497, 0.0176, 0.1252, 0.0451, 0.0118, 0.2021, 0.0370, 0.1549,
        0.0325], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,597][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0789, 0.0240, 0.0328, 0.0332, 0.0562, 0.0540, 0.0367, 0.0209, 0.0416,
        0.0298, 0.0394, 0.0627, 0.0870, 0.1290, 0.0443, 0.0291, 0.0492, 0.0973,
        0.0538], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,598][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0852, 0.0396, 0.0082, 0.0090, 0.0227, 0.0330, 0.2309, 0.0125, 0.0061,
        0.0101, 0.0124, 0.1148, 0.0198, 0.0711, 0.0236, 0.0253, 0.2334, 0.0294,
        0.0128], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,602][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0766, 0.0274, 0.1871, 0.1041, 0.0844, 0.0261, 0.0723, 0.0416, 0.0089,
        0.0245, 0.0078, 0.0906, 0.0389, 0.0273, 0.0497, 0.0539, 0.0549, 0.0195,
        0.0044], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,603][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0047, 0.0561, 0.0755, 0.0428, 0.0757, 0.0580, 0.0416, 0.0601, 0.0267,
        0.0753, 0.0569, 0.0396, 0.0583, 0.0246, 0.0753, 0.0769, 0.0392, 0.0739,
        0.0389], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,604][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0120, 0.0184, 0.0082, 0.0119, 0.0055, 0.0091, 0.0308, 0.0033, 0.0193,
        0.0151, 0.0297, 0.0125, 0.0067, 0.1451, 0.0283, 0.0155, 0.1048, 0.0289,
        0.4949], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,622][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:49,624][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,624][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,625][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,625][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,626][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,626][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,626][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,627][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,627][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,628][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,628][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,628][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,628][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9169, 0.0831], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,629][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,629][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9843, 0.0157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,629][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3981, 0.6019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,630][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9513, 0.0487], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,630][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6595, 0.3405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,630][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9919, 0.0081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,631][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9845, 0.0155], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,631][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8008, 0.1992], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,631][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2100, 0.7900], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,632][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2389, 0.7611], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,632][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8281, 0.1719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,632][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.0059, 0.0668, 0.9273], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,633][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([9.9948e-01, 3.4938e-04, 1.7008e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,633][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.8241, 0.1088, 0.0671], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,633][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.4743, 0.3082, 0.2175], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,634][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.8298, 0.0962, 0.0740], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,634][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.3034, 0.6458, 0.0507], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,634][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.5885, 0.3577, 0.0538], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,636][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.8221, 0.0929, 0.0850], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,636][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.6734, 0.3179, 0.0088], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,636][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0985, 0.8190, 0.0825], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,637][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.1404, 0.3989, 0.4607], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,637][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0449, 0.0239, 0.9311], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,637][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0073, 0.0328, 0.9454, 0.0145], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,638][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9952, 0.0019, 0.0011, 0.0018], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,638][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5604, 0.0627, 0.0632, 0.3138], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,643][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4709, 0.1682, 0.1820, 0.1788], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,645][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7459, 0.0637, 0.0965, 0.0939], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,645][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2979, 0.5803, 0.0159, 0.1059], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,645][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6913, 0.0556, 0.1224, 0.1308], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,645][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6093, 0.0467, 0.2332, 0.1108], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,646][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3356, 0.4402, 0.0761, 0.1481], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,646][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1579, 0.2614, 0.2103, 0.3705], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,646][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1005, 0.2909, 0.3628, 0.2458], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,647][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4343, 0.1060, 0.0102, 0.4495], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,647][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([4.7828e-04, 6.8318e-03, 9.5855e-01, 6.4492e-03, 2.7694e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,647][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9988e-01, 4.5658e-05, 2.3897e-05, 5.0860e-05, 3.4603e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,647][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.4903, 0.0728, 0.0468, 0.3179, 0.0721], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,648][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.4102, 0.1551, 0.1321, 0.1606, 0.1420], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,651][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.6156, 0.1011, 0.0675, 0.1068, 0.1089], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,652][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.1860, 0.3168, 0.3238, 0.1086, 0.0648], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,652][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.3895, 0.1106, 0.1282, 0.1928, 0.1791], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,652][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.6551, 0.0918, 0.0667, 0.1273, 0.0591], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,653][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.4634, 0.1700, 0.0035, 0.1475, 0.2156], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,653][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1307, 0.3841, 0.1220, 0.3232, 0.0400], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,653][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0775, 0.2215, 0.2509, 0.1843, 0.2658], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,653][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0239, 0.0102, 0.0158, 0.0049, 0.9452], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,654][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0731, 0.0328, 0.5104, 0.0699, 0.1797, 0.1340], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,656][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([9.9936e-01, 2.3347e-04, 1.1546e-04, 2.1140e-04, 2.2165e-05, 5.5992e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,658][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3570, 0.0733, 0.0624, 0.2252, 0.0844, 0.1977], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,658][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3947, 0.1132, 0.1155, 0.1186, 0.1278, 0.1303], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,658][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.5779, 0.0671, 0.0623, 0.0776, 0.0989, 0.1162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,658][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1943, 0.5701, 0.0444, 0.0434, 0.0367, 0.1110], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,659][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3638, 0.0651, 0.0563, 0.1987, 0.0132, 0.3030], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,659][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.4581, 0.0457, 0.1193, 0.0874, 0.1457, 0.1437], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,659][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0672, 0.1467, 0.0038, 0.0364, 0.1152, 0.6306], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,660][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2016, 0.2178, 0.1656, 0.2359, 0.0978, 0.0812], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,662][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0577, 0.1796, 0.2168, 0.1471, 0.2287, 0.1701], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,664][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([2.0735e-02, 1.7269e-02, 7.8026e-04, 1.5722e-02, 9.5938e-04, 9.4453e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,664][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0011, 0.0052, 0.1606, 0.0090, 0.0228, 0.7652, 0.0363],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,664][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9640e-01, 8.5872e-04, 5.1427e-04, 8.2764e-04, 1.3575e-04, 3.0394e-04,
        9.5721e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,664][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2957, 0.0633, 0.0524, 0.1841, 0.0689, 0.1470, 0.1887],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,665][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3863, 0.0921, 0.0985, 0.1011, 0.1040, 0.1069, 0.1111],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,665][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5084, 0.0603, 0.0590, 0.0752, 0.0901, 0.1012, 0.1057],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,665][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2654, 0.4603, 0.0380, 0.0828, 0.0477, 0.0593, 0.0465],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,666][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1636, 0.0727, 0.2940, 0.1730, 0.1169, 0.0775, 0.1023],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,666][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3758, 0.0455, 0.1346, 0.0712, 0.1492, 0.1265, 0.0971],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,670][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0359, 0.0613, 0.0032, 0.0146, 0.1626, 0.5069, 0.2156],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,670][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1272, 0.2110, 0.1860, 0.2454, 0.0989, 0.0641, 0.0674],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,670][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0527, 0.1531, 0.1895, 0.1285, 0.1987, 0.1463, 0.1310],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,671][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.4556e-02, 4.0061e-03, 9.9166e-04, 4.3923e-03, 4.4258e-04, 1.7534e-03,
        9.7386e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,671][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([3.9882e-04, 2.6695e-04, 2.8991e-02, 7.4445e-04, 3.2519e-02, 4.4539e-03,
        9.1914e-01, 1.3487e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,671][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([9.9855e-01, 3.2488e-04, 1.6976e-04, 3.2400e-04, 3.7199e-05, 9.9182e-05,
        3.7107e-04, 1.2799e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,672][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2670, 0.0625, 0.0457, 0.1792, 0.0595, 0.1320, 0.1661, 0.0880],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,672][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.3627, 0.0772, 0.0839, 0.0965, 0.0952, 0.0988, 0.0986, 0.0870],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,672][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.4475, 0.0553, 0.0555, 0.0709, 0.0826, 0.0921, 0.1021, 0.0940],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,676][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.2133, 0.4921, 0.0217, 0.0595, 0.0121, 0.0357, 0.0697, 0.0958],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,676][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2385, 0.0772, 0.0073, 0.1763, 0.0107, 0.1379, 0.2625, 0.0895],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,677][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.4754, 0.0449, 0.0734, 0.0740, 0.0890, 0.1094, 0.0829, 0.0509],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,677][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1211, 0.1548, 0.0017, 0.1154, 0.0510, 0.2457, 0.2956, 0.0148],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,677][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.1125, 0.2818, 0.0963, 0.2671, 0.0457, 0.0835, 0.0971, 0.0160],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,678][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0458, 0.1309, 0.1649, 0.1087, 0.1739, 0.1234, 0.1117, 0.1406],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,678][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([4.5662e-03, 1.0214e-02, 3.1335e-04, 3.5373e-03, 2.0218e-04, 1.3306e-03,
        7.7481e-04, 9.7906e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,678][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([6.2052e-06, 3.8373e-05, 7.1880e-02, 1.2969e-04, 9.7395e-03, 6.8209e-04,
        4.8537e-02, 8.6898e-01, 1.0521e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,679][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([9.9609e-01, 7.1555e-04, 4.1140e-04, 6.7204e-04, 1.0052e-04, 2.4200e-04,
        8.6766e-04, 3.3216e-04, 5.7211e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,682][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.2141, 0.0526, 0.0438, 0.1417, 0.0585, 0.1186, 0.1378, 0.0647, 0.1681],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,683][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.3751, 0.0631, 0.0776, 0.0800, 0.0881, 0.0882, 0.0816, 0.0705, 0.0757],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,683][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.3859, 0.0578, 0.0602, 0.0665, 0.0913, 0.0924, 0.0913, 0.0629, 0.0918],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,683][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0243, 0.0167, 0.0021, 0.0068, 0.0012, 0.0024, 0.0165, 0.0072, 0.9226],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,684][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1543, 0.0701, 0.0773, 0.1413, 0.0093, 0.0611, 0.1688, 0.1914, 0.1265],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,684][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.3330, 0.0543, 0.0916, 0.0661, 0.1165, 0.0915, 0.0810, 0.0761, 0.0900],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,684][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0800, 0.0846, 0.0028, 0.0296, 0.1275, 0.3741, 0.1971, 0.0364, 0.0680],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,685][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.1340, 0.1495, 0.1996, 0.2159, 0.1076, 0.0588, 0.0701, 0.0232, 0.0413],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,686][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0406, 0.1190, 0.1500, 0.0995, 0.1579, 0.1149, 0.0994, 0.1309, 0.0877],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,689][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0412, 0.0184, 0.0032, 0.0314, 0.0015, 0.0067, 0.0535, 0.0084, 0.8357],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,689][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([2.6541e-05, 2.5553e-04, 1.4790e-02, 1.6975e-03, 2.3818e-02, 9.6207e-02,
        1.9408e-01, 6.4055e-01, 1.4401e-03, 2.7136e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,689][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([9.9830e-01, 3.1664e-04, 1.6073e-04, 3.0216e-04, 3.4017e-05, 8.9561e-05,
        3.4129e-04, 1.2499e-04, 2.3159e-04, 1.0345e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,690][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1750, 0.0583, 0.0377, 0.1470, 0.0467, 0.1075, 0.1193, 0.0617, 0.1701,
        0.0766], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,690][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.3227, 0.0647, 0.0670, 0.0860, 0.0789, 0.0811, 0.0812, 0.0685, 0.0737,
        0.0762], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,690][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.3726, 0.0519, 0.0441, 0.0617, 0.0627, 0.0738, 0.0764, 0.0685, 0.0846,
        0.1038], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,691][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.1503, 0.3193, 0.0157, 0.0829, 0.0055, 0.0338, 0.0973, 0.0813, 0.0676,
        0.1463], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,691][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1200, 0.0469, 0.0454, 0.0661, 0.0061, 0.1269, 0.1066, 0.2930, 0.0449,
        0.1441], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,695][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.2926, 0.0520, 0.0794, 0.0732, 0.0868, 0.1505, 0.0767, 0.0971, 0.0628,
        0.0289], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,695][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0927, 0.1327, 0.0029, 0.0530, 0.1276, 0.2183, 0.2441, 0.0135, 0.0793,
        0.0359], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,696][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1139, 0.2100, 0.1378, 0.2803, 0.0660, 0.0549, 0.0624, 0.0257, 0.0352,
        0.0137], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,696][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0373, 0.1070, 0.1286, 0.0884, 0.1356, 0.1000, 0.0895, 0.1118, 0.0757,
        0.1261], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,696][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.4299e-02, 7.2537e-03, 5.7836e-04, 7.4334e-03, 6.5592e-04, 1.6186e-03,
        3.5181e-03, 2.7519e-03, 2.6427e-02, 9.3546e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,697][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0010, 0.0069, 0.1912, 0.0095, 0.0148, 0.0436, 0.0478, 0.6518, 0.0054,
        0.0249, 0.0033], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,697][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([9.9471e-01, 7.7285e-04, 4.3432e-04, 7.3526e-04, 1.0860e-04, 2.7430e-04,
        9.1122e-04, 3.6610e-04, 6.4701e-04, 3.3177e-04, 7.0901e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,697][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1582, 0.0463, 0.0363, 0.1053, 0.0478, 0.0908, 0.1033, 0.0532, 0.1204,
        0.0646, 0.1739], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,701][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3215, 0.0527, 0.0632, 0.0704, 0.0716, 0.0739, 0.0679, 0.0586, 0.0615,
        0.0741, 0.0845], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,702][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2972, 0.0466, 0.0440, 0.0524, 0.0661, 0.0706, 0.0695, 0.0632, 0.0764,
        0.0985, 0.1157], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,702][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0312, 0.0474, 0.0026, 0.0109, 0.0058, 0.0031, 0.0228, 0.0140, 0.0289,
        0.0083, 0.8251], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,702][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0381, 0.0218, 0.1914, 0.0813, 0.0409, 0.0416, 0.0333, 0.0070, 0.0917,
        0.4343, 0.0188], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,703][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2279, 0.0308, 0.0940, 0.0572, 0.1017, 0.1484, 0.0613, 0.0732, 0.0589,
        0.0796, 0.0672], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,703][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0391, 0.0375, 0.0043, 0.0077, 0.2683, 0.3836, 0.1065, 0.0359, 0.0351,
        0.0746, 0.0074], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,703][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1410, 0.1289, 0.1892, 0.1943, 0.0966, 0.0715, 0.0757, 0.0262, 0.0318,
        0.0200, 0.0247], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,704][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0335, 0.0948, 0.1191, 0.0794, 0.1249, 0.0902, 0.0790, 0.1048, 0.0681,
        0.1173, 0.0889], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,705][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.7409e-03, 3.3098e-03, 2.4134e-03, 3.1367e-03, 4.0513e-04, 2.1883e-03,
        1.9722e-03, 7.4023e-04, 1.3436e-02, 1.2039e-03, 9.6845e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,708][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0013, 0.0045, 0.1829, 0.0115, 0.0384, 0.1392, 0.1460, 0.2970, 0.0173,
        0.0196, 0.1149, 0.0276], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,708][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.8375e-01, 1.6013e-03, 1.0061e-03, 1.7756e-03, 3.1748e-04, 8.1183e-04,
        2.0699e-03, 9.6725e-04, 1.7042e-03, 9.4790e-04, 2.0041e-03, 3.0427e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,709][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1351, 0.0418, 0.0319, 0.0903, 0.0421, 0.0789, 0.0949, 0.0518, 0.1010,
        0.0631, 0.1406, 0.1285], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,709][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3200, 0.0487, 0.0610, 0.0620, 0.0654, 0.0630, 0.0648, 0.0546, 0.0543,
        0.0642, 0.0694, 0.0725], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,709][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2581, 0.0422, 0.0403, 0.0462, 0.0576, 0.0592, 0.0635, 0.0623, 0.0635,
        0.0929, 0.0966, 0.1178], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,710][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1104, 0.3019, 0.0280, 0.0362, 0.0623, 0.0187, 0.0305, 0.0593, 0.1772,
        0.0187, 0.1316, 0.0251], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,710][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0620, 0.0175, 0.1264, 0.1532, 0.0622, 0.0632, 0.0552, 0.0423, 0.0913,
        0.1703, 0.1283, 0.0279], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,710][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2190, 0.0265, 0.0653, 0.0475, 0.1011, 0.1018, 0.0670, 0.0614, 0.0540,
        0.0880, 0.0674, 0.1011], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,714][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0209, 0.0258, 0.0022, 0.0055, 0.1701, 0.2766, 0.0873, 0.0284, 0.0284,
        0.0530, 0.0058, 0.2961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,715][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1149, 0.0767, 0.2512, 0.1782, 0.1148, 0.0434, 0.0448, 0.0388, 0.0198,
        0.0224, 0.0172, 0.0778], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,715][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0310, 0.0871, 0.1096, 0.0731, 0.1159, 0.0842, 0.0747, 0.0966, 0.0626,
        0.1092, 0.0808, 0.0753], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,715][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0075, 0.0030, 0.0026, 0.0056, 0.0019, 0.0020, 0.0132, 0.0012, 0.0791,
        0.0053, 0.0120, 0.8666], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,716][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([8.0434e-05, 2.9991e-03, 3.7548e-01, 6.5864e-03, 1.4840e-01, 3.4554e-02,
        6.9277e-02, 5.6699e-02, 5.8248e-03, 5.5930e-02, 1.8251e-01, 5.0992e-02,
        1.0677e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,716][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([9.9737e-01, 3.0002e-04, 1.6537e-04, 2.9311e-04, 3.5437e-05, 9.2828e-05,
        3.2559e-04, 1.3156e-04, 2.2948e-04, 1.1162e-04, 2.7485e-04, 5.4860e-04,
        1.2554e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,716][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.1222, 0.0391, 0.0284, 0.0959, 0.0387, 0.0819, 0.0854, 0.0454, 0.1098,
        0.0542, 0.1410, 0.1092, 0.0489], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,717][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.2749, 0.0421, 0.0533, 0.0637, 0.0606, 0.0622, 0.0650, 0.0543, 0.0588,
        0.0657, 0.0777, 0.0648, 0.0570], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,721][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.2687, 0.0451, 0.0348, 0.0485, 0.0506, 0.0569, 0.0544, 0.0478, 0.0599,
        0.0681, 0.0790, 0.0945, 0.0915], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,721][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0708, 0.1670, 0.0255, 0.0384, 0.0365, 0.0184, 0.0796, 0.0226, 0.0668,
        0.0201, 0.2269, 0.0620, 0.1655], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,721][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0278, 0.0241, 0.1730, 0.0816, 0.1757, 0.1182, 0.0108, 0.0121, 0.0591,
        0.0031, 0.0355, 0.0210, 0.2581], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,722][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.1820, 0.0207, 0.0553, 0.0440, 0.0984, 0.1538, 0.0401, 0.0706, 0.0425,
        0.0882, 0.0451, 0.0536, 0.1056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,722][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0434, 0.0407, 0.0007, 0.0286, 0.0734, 0.1241, 0.0808, 0.0077, 0.0452,
        0.0133, 0.0189, 0.4924, 0.0309], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,722][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.1264, 0.1041, 0.1302, 0.1606, 0.0808, 0.0773, 0.0518, 0.0382, 0.0246,
        0.0179, 0.0343, 0.1063, 0.0475], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,723][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0294, 0.0823, 0.0977, 0.0685, 0.1026, 0.0765, 0.0692, 0.0861, 0.0580,
        0.0965, 0.0747, 0.0682, 0.0903], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,723][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([8.3112e-03, 1.1367e-02, 2.6783e-03, 7.8497e-03, 1.4789e-03, 9.8562e-04,
        1.7872e-03, 9.0906e-04, 1.4113e-02, 5.5351e-03, 9.0587e-03, 1.8411e-03,
        9.3409e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,727][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0023, 0.0063, 0.1696, 0.0146, 0.1025, 0.0221, 0.1506, 0.2302, 0.0136,
        0.1029, 0.0526, 0.0541, 0.0577, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,727][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([9.5749e-01, 2.4073e-03, 1.7035e-03, 2.8785e-03, 6.8013e-04, 1.5509e-03,
        3.1675e-03, 1.6826e-03, 2.7953e-03, 1.7664e-03, 3.3861e-03, 5.1018e-03,
        2.0713e-03, 1.3315e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,728][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1107, 0.0323, 0.0294, 0.0678, 0.0384, 0.0685, 0.0699, 0.0413, 0.0790,
        0.0541, 0.1053, 0.0912, 0.0496, 0.1624], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,728][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.2980, 0.0409, 0.0542, 0.0499, 0.0563, 0.0501, 0.0491, 0.0432, 0.0461,
        0.0526, 0.0593, 0.0500, 0.0560, 0.0944], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,728][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2041, 0.0345, 0.0372, 0.0323, 0.0502, 0.0454, 0.0411, 0.0497, 0.0454,
        0.0721, 0.0692, 0.0740, 0.1124, 0.1324], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,729][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.2645, 0.1734, 0.0409, 0.0390, 0.0748, 0.0531, 0.0442, 0.0390, 0.0420,
        0.0257, 0.0465, 0.0465, 0.0345, 0.0760], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,729][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0333, 0.0053, 0.0636, 0.0290, 0.0458, 0.0252, 0.0053, 0.0084, 0.0266,
        0.0352, 0.0196, 0.0034, 0.6475, 0.0516], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,730][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1833, 0.0181, 0.0631, 0.0401, 0.0935, 0.0639, 0.0369, 0.0664, 0.0461,
        0.0864, 0.0468, 0.0550, 0.1352, 0.0652], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,733][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0172, 0.0226, 0.0016, 0.0056, 0.1142, 0.2968, 0.0664, 0.0282, 0.0242,
        0.0370, 0.0041, 0.2028, 0.1099, 0.0693], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,734][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1254, 0.0825, 0.2388, 0.1339, 0.1134, 0.0506, 0.0369, 0.0307, 0.0113,
        0.0197, 0.0151, 0.0525, 0.0492, 0.0400], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,734][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0260, 0.0749, 0.0940, 0.0626, 0.1011, 0.0714, 0.0630, 0.0817, 0.0537,
        0.0932, 0.0704, 0.0627, 0.0884, 0.0569], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,735][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0839, 0.0274, 0.0225, 0.0294, 0.0327, 0.0257, 0.0446, 0.0253, 0.0722,
        0.0997, 0.0337, 0.0895, 0.0606, 0.3527], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,735][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([2.9362e-04, 4.9141e-03, 6.6845e-01, 4.8633e-03, 1.8453e-02, 6.5593e-02,
        8.2477e-02, 1.3899e-02, 4.7710e-03, 1.5959e-02, 4.7243e-03, 5.3347e-02,
        9.4401e-03, 2.1953e-02, 3.0862e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,735][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9857e-01, 9.4293e-05, 4.6502e-05, 1.0484e-04, 7.0664e-06, 2.3484e-05,
        9.8932e-05, 3.0696e-05, 6.2654e-05, 2.5323e-05, 6.7239e-05, 1.6440e-04,
        3.0351e-05, 6.6594e-04, 7.9344e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,736][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0988, 0.0338, 0.0193, 0.0711, 0.0279, 0.0681, 0.0659, 0.0388, 0.0821,
        0.0493, 0.1170, 0.0919, 0.0425, 0.1378, 0.0556], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,736][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.2419, 0.0399, 0.0448, 0.0536, 0.0490, 0.0579, 0.0524, 0.0439, 0.0441,
        0.0528, 0.0593, 0.0556, 0.0492, 0.1060, 0.0494], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,740][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.1940, 0.0488, 0.0318, 0.0424, 0.0433, 0.0551, 0.0477, 0.0388, 0.0419,
        0.0543, 0.0635, 0.0699, 0.0701, 0.1121, 0.0864], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,740][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0622, 0.1346, 0.3288, 0.0620, 0.0821, 0.0065, 0.0271, 0.0094, 0.0307,
        0.0043, 0.0155, 0.0413, 0.0096, 0.0801, 0.1056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,741][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0689, 0.0263, 0.1580, 0.0527, 0.0825, 0.0630, 0.0303, 0.0619, 0.0499,
        0.0265, 0.0242, 0.0160, 0.0741, 0.2316, 0.0341], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,741][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1640, 0.0399, 0.0190, 0.0419, 0.0257, 0.0987, 0.0379, 0.0510, 0.0397,
        0.0821, 0.0446, 0.0927, 0.1209, 0.1171, 0.0250], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,741][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0450, 0.0189, 0.0004, 0.0059, 0.0965, 0.1006, 0.0470, 0.0063, 0.0133,
        0.0156, 0.0043, 0.2236, 0.0535, 0.0746, 0.2943], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,742][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0520, 0.1527, 0.1776, 0.1041, 0.0538, 0.0392, 0.0728, 0.0249, 0.0195,
        0.0166, 0.0478, 0.0919, 0.0378, 0.0528, 0.0566], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,742][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0255, 0.0717, 0.0827, 0.0598, 0.0878, 0.0668, 0.0578, 0.0733, 0.0496,
        0.0820, 0.0632, 0.0577, 0.0782, 0.0516, 0.0922], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,743][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([2.1798e-04, 3.9100e-04, 2.5174e-03, 1.3610e-04, 1.8148e-01, 2.4147e-05,
        1.2305e-04, 5.6328e-05, 1.0736e-03, 3.4863e-04, 4.3084e-04, 5.1654e-04,
        6.2486e-04, 4.4739e-02, 7.6732e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,746][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0018, 0.0085, 0.1666, 0.0093, 0.0512, 0.0580, 0.0909, 0.2327, 0.0065,
        0.0509, 0.0581, 0.0423, 0.0163, 0.0537, 0.0719, 0.0813],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,747][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.9335e-01, 4.3112e-04, 2.2915e-04, 4.5076e-04, 5.2191e-05, 1.4474e-04,
        4.6017e-04, 1.7738e-04, 3.2414e-04, 1.5832e-04, 3.7177e-04, 7.4389e-04,
        1.8396e-04, 2.6588e-03, 6.4586e-05, 2.0208e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,747][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0880, 0.0433, 0.0283, 0.0651, 0.0343, 0.0587, 0.0556, 0.0337, 0.0711,
        0.0437, 0.0943, 0.0679, 0.0433, 0.1271, 0.0587, 0.0868],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,747][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.2477, 0.0335, 0.0415, 0.0442, 0.0506, 0.0507, 0.0438, 0.0384, 0.0417,
        0.0497, 0.0575, 0.0456, 0.0451, 0.1007, 0.0520, 0.0574],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,748][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1784, 0.0350, 0.0299, 0.0364, 0.0404, 0.0400, 0.0374, 0.0273, 0.0396,
        0.0463, 0.0547, 0.0597, 0.0597, 0.1187, 0.0932, 0.1035],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,748][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1413, 0.1670, 0.0156, 0.0381, 0.0298, 0.1388, 0.0555, 0.0274, 0.0648,
        0.0176, 0.0367, 0.0360, 0.0240, 0.0988, 0.0254, 0.0833],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,748][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0262, 0.0179, 0.0126, 0.0548, 0.0035, 0.0347, 0.0324, 0.0393, 0.0697,
        0.0983, 0.0735, 0.0243, 0.2879, 0.1174, 0.0053, 0.1022],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,752][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1254, 0.0353, 0.0283, 0.0395, 0.0597, 0.0488, 0.0436, 0.0493, 0.0448,
        0.0847, 0.0472, 0.0576, 0.1665, 0.0945, 0.0446, 0.0302],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,753][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0151, 0.0135, 0.0006, 0.0044, 0.0765, 0.1217, 0.0420, 0.0068, 0.0211,
        0.0157, 0.0052, 0.2449, 0.0550, 0.0759, 0.2258, 0.0756],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,753][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0744, 0.0949, 0.1243, 0.0939, 0.0749, 0.0684, 0.0590, 0.0208, 0.0174,
        0.0141, 0.0270, 0.0966, 0.0390, 0.0458, 0.0691, 0.0805],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,754][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0214, 0.0636, 0.0784, 0.0526, 0.0828, 0.0601, 0.0524, 0.0686, 0.0456,
        0.0774, 0.0594, 0.0524, 0.0731, 0.0479, 0.0875, 0.0767],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,754][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([2.6862e-03, 2.3105e-03, 1.1743e-04, 1.4460e-03, 3.9383e-04, 1.8972e-03,
        3.4323e-04, 1.9407e-03, 4.9371e-03, 1.7353e-03, 7.2101e-04, 6.3211e-04,
        9.1093e-04, 4.7426e-02, 6.3397e-04, 9.3187e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,754][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([3.1799e-04, 1.7398e-03, 4.6826e-02, 3.3408e-03, 7.3288e-03, 2.6392e-01,
        1.2090e-02, 3.4655e-01, 6.1992e-03, 1.0391e-02, 1.9455e-02, 3.5863e-02,
        2.8177e-03, 1.0823e-02, 1.1414e-02, 2.0077e-01, 2.0155e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,755][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.5350e-01, 2.3895e-03, 1.4979e-03, 2.6257e-03, 5.0291e-04, 1.1763e-03,
        2.4574e-03, 1.3166e-03, 2.3529e-03, 1.3797e-03, 2.6979e-03, 4.4859e-03,
        1.5914e-03, 1.3689e-02, 7.6903e-04, 1.9835e-03, 5.5822e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,757][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0754, 0.0365, 0.0257, 0.0506, 0.0315, 0.0524, 0.0587, 0.0341, 0.0560,
        0.0441, 0.0793, 0.0690, 0.0445, 0.1070, 0.0561, 0.0834, 0.0959],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,759][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2695, 0.0315, 0.0385, 0.0399, 0.0404, 0.0437, 0.0474, 0.0371, 0.0381,
        0.0428, 0.0493, 0.0478, 0.0424, 0.0894, 0.0427, 0.0525, 0.0469],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,759][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1536, 0.0279, 0.0227, 0.0283, 0.0296, 0.0324, 0.0341, 0.0305, 0.0344,
        0.0494, 0.0479, 0.0600, 0.0677, 0.1066, 0.0803, 0.0991, 0.0955],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,760][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1032, 0.1666, 0.0291, 0.0294, 0.0459, 0.0404, 0.0218, 0.0410, 0.1179,
        0.0334, 0.0990, 0.0371, 0.0389, 0.0672, 0.0453, 0.0676, 0.0162],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,760][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0374, 0.0182, 0.0937, 0.0479, 0.0317, 0.0180, 0.0197, 0.0545, 0.0551,
        0.1099, 0.0496, 0.0167, 0.3423, 0.0483, 0.0161, 0.0282, 0.0127],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,761][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1452, 0.0290, 0.0435, 0.0318, 0.0668, 0.0554, 0.0398, 0.0563, 0.0389,
        0.0558, 0.0412, 0.0570, 0.1152, 0.0874, 0.0358, 0.0554, 0.0456],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,761][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0073, 0.0063, 0.0008, 0.0013, 0.1329, 0.1559, 0.0319, 0.0145, 0.0138,
        0.0323, 0.0020, 0.1362, 0.1509, 0.0431, 0.1880, 0.0608, 0.0218],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,761][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0708, 0.0546, 0.1714, 0.0929, 0.0979, 0.0491, 0.0484, 0.0272, 0.0123,
        0.0164, 0.0150, 0.0760, 0.0458, 0.0291, 0.0762, 0.0786, 0.0383],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,765][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0212, 0.0590, 0.0739, 0.0497, 0.0778, 0.0568, 0.0506, 0.0660, 0.0425,
        0.0738, 0.0546, 0.0501, 0.0700, 0.0449, 0.0827, 0.0733, 0.0531],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,766][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([6.8657e-04, 3.4613e-04, 1.7290e-04, 3.1232e-04, 1.0387e-04, 1.7417e-04,
        9.7398e-02, 2.1088e-04, 4.1481e-03, 8.8450e-04, 1.7194e-03, 2.2173e-03,
        5.4191e-04, 3.4491e-02, 1.1986e-03, 1.0168e-03, 8.5438e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,766][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([5.6497e-05, 9.6968e-04, 1.2395e-01, 1.2004e-03, 6.4376e-02, 1.4300e-02,
        1.3936e-01, 8.4758e-03, 5.6033e-03, 3.5814e-02, 2.4532e-02, 2.4334e-02,
        8.9040e-02, 1.0294e-02, 1.0410e-01, 5.6879e-02, 2.7359e-01, 2.3123e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,766][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([9.9854e-01, 7.9173e-05, 4.5174e-05, 7.9256e-05, 7.1017e-06, 1.9561e-05,
        8.3979e-05, 2.7719e-05, 5.2125e-05, 2.3288e-05, 5.6830e-05, 1.4360e-04,
        2.8285e-05, 5.9532e-04, 7.5075e-06, 2.8426e-05, 1.6908e-04, 1.2546e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,767][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0765, 0.0344, 0.0243, 0.0542, 0.0293, 0.0508, 0.0509, 0.0307, 0.0596,
        0.0412, 0.0776, 0.0616, 0.0388, 0.1071, 0.0517, 0.0771, 0.0822, 0.0520],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,767][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.2280, 0.0284, 0.0383, 0.0400, 0.0447, 0.0476, 0.0421, 0.0365, 0.0367,
        0.0446, 0.0488, 0.0437, 0.0428, 0.0916, 0.0457, 0.0565, 0.0405, 0.0436],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,768][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1429, 0.0291, 0.0253, 0.0311, 0.0316, 0.0342, 0.0344, 0.0257, 0.0334,
        0.0386, 0.0475, 0.0529, 0.0525, 0.1001, 0.0747, 0.0819, 0.0847, 0.0794],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,772][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0932, 0.1517, 0.0144, 0.0169, 0.0483, 0.0177, 0.0385, 0.0407, 0.0368,
        0.0105, 0.0941, 0.0562, 0.1793, 0.0663, 0.0353, 0.0087, 0.0289, 0.0625],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,772][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0454, 0.0277, 0.0187, 0.0465, 0.0345, 0.0244, 0.0083, 0.0308, 0.0253,
        0.0034, 0.0481, 0.0050, 0.2640, 0.0117, 0.0218, 0.0046, 0.0091, 0.3706],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,772][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.1631, 0.0408, 0.0398, 0.0430, 0.0590, 0.0330, 0.0360, 0.0887, 0.0501,
        0.0600, 0.0466, 0.0492, 0.0680, 0.0712, 0.0364, 0.0548, 0.0376, 0.0227],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,773][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0143, 0.0083, 0.0004, 0.0079, 0.0530, 0.0572, 0.0277, 0.0059, 0.0250,
        0.0108, 0.0083, 0.1982, 0.0313, 0.0833, 0.2409, 0.0689, 0.0612, 0.0975],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,773][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0733, 0.0625, 0.1585, 0.0977, 0.1273, 0.0448, 0.0311, 0.0244, 0.0108,
        0.0165, 0.0175, 0.0538, 0.0452, 0.0252, 0.1017, 0.0698, 0.0224, 0.0175],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,774][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0199, 0.0565, 0.0687, 0.0465, 0.0723, 0.0530, 0.0470, 0.0593, 0.0401,
        0.0668, 0.0512, 0.0466, 0.0638, 0.0423, 0.0767, 0.0667, 0.0489, 0.0736],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,774][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([7.9121e-03, 4.3573e-03, 2.2944e-04, 2.8679e-03, 5.8093e-04, 1.5394e-03,
        7.7199e-04, 4.4285e-04, 1.1981e-02, 2.4232e-03, 4.4696e-03, 1.6117e-03,
        3.7019e-03, 7.0549e-02, 1.2802e-03, 1.0317e-03, 2.4912e-03, 8.8176e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,775][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.9394e-04, 3.7116e-04, 2.6355e-03, 2.6671e-04, 3.6725e-03, 1.0297e-01,
        1.0588e-02, 5.4403e-02, 2.7319e-03, 2.0126e-02, 1.1399e-02, 4.4729e-03,
        1.8625e-03, 2.3356e-03, 6.0559e-03, 7.5309e-01, 1.9843e-02, 2.9681e-03,
        1.9970e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,778][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.2866e-01, 2.9300e-03, 1.8046e-03, 3.5555e-03, 6.7793e-04, 1.8416e-03,
        3.6235e-03, 1.9459e-03, 3.0713e-03, 1.9790e-03, 3.9081e-03, 5.4118e-03,
        2.2975e-03, 1.7666e-02, 1.0782e-03, 2.8489e-03, 7.3529e-03, 1.7630e-03,
        7.5813e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,778][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0609, 0.0331, 0.0244, 0.0394, 0.0292, 0.0451, 0.0444, 0.0270, 0.0473,
        0.0349, 0.0650, 0.0545, 0.0367, 0.0888, 0.0499, 0.0790, 0.0753, 0.0544,
        0.1108], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,779][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2674, 0.0290, 0.0350, 0.0353, 0.0384, 0.0404, 0.0381, 0.0311, 0.0352,
        0.0379, 0.0453, 0.0390, 0.0369, 0.0802, 0.0402, 0.0466, 0.0370, 0.0413,
        0.0458], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,779][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1274, 0.0233, 0.0192, 0.0215, 0.0257, 0.0274, 0.0261, 0.0211, 0.0270,
        0.0325, 0.0392, 0.0449, 0.0496, 0.0815, 0.0684, 0.0905, 0.0780, 0.0839,
        0.1128], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,780][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0297, 0.0146, 0.0435, 0.0097, 0.0196, 0.0120, 0.0147, 0.0023, 0.0207,
        0.0040, 0.0175, 0.0136, 0.0073, 0.0133, 0.0115, 0.0085, 0.0148, 0.0454,
        0.6972], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,780][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0367, 0.0081, 0.0120, 0.0517, 0.0043, 0.0199, 0.0408, 0.0280, 0.0512,
        0.0617, 0.0464, 0.0116, 0.1846, 0.0341, 0.0029, 0.2014, 0.0376, 0.1524,
        0.0146], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,781][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1341, 0.0261, 0.0402, 0.0291, 0.0590, 0.0478, 0.0359, 0.0377, 0.0365,
        0.0455, 0.0386, 0.0445, 0.0844, 0.0741, 0.0317, 0.0547, 0.0404, 0.0902,
        0.0495], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,784][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0050, 0.0033, 0.0007, 0.0007, 0.1315, 0.1218, 0.0193, 0.0093, 0.0075,
        0.0267, 0.0011, 0.0942, 0.1427, 0.0287, 0.1684, 0.0597, 0.0146, 0.1642,
        0.0007], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,785][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0852, 0.0432, 0.2065, 0.0810, 0.0991, 0.0414, 0.0501, 0.0324, 0.0069,
        0.0190, 0.0112, 0.0776, 0.0450, 0.0164, 0.0541, 0.0754, 0.0319, 0.0198,
        0.0041], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,785][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0184, 0.0521, 0.0653, 0.0433, 0.0696, 0.0500, 0.0441, 0.0569, 0.0379,
        0.0644, 0.0494, 0.0441, 0.0613, 0.0397, 0.0739, 0.0648, 0.0465, 0.0721,
        0.0463], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,785][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0209, 0.0058, 0.0015, 0.0097, 0.0015, 0.0022, 0.0076, 0.0010, 0.0337,
        0.0049, 0.0127, 0.0047, 0.0019, 0.2375, 0.0058, 0.0051, 0.0302, 0.0155,
        0.5976], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:49,786][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:49,788][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10890],
        [ 3478],
        [    3],
        [ 3825],
        [16939],
        [ 3776],
        [10862],
        [ 8710],
        [ 2241],
        [14592],
        [ 7180],
        [10296],
        [18755],
        [ 3181],
        [18488],
        [ 4760],
        [10763],
        [15701],
        [ 3497]], device='cuda:0')
[2024-07-24 10:19:49,790][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7662],
        [23782],
        [    1],
        [27514],
        [25301],
        [19535],
        [30939],
        [14041],
        [ 9469],
        [42344],
        [35361],
        [36675],
        [32242],
        [12494],
        [33638],
        [23213],
        [28406],
        [40880],
        [15785]], device='cuda:0')
[2024-07-24 10:19:49,792][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 4005],
        [ 5096],
        [12343],
        [11711],
        [14536],
        [ 6179],
        [ 5217],
        [12425],
        [ 7386],
        [ 6049],
        [ 5828],
        [ 5775],
        [ 6859],
        [ 6398],
        [ 7246],
        [ 4721],
        [ 3587],
        [ 8799],
        [ 3628]], device='cuda:0')
[2024-07-24 10:19:49,793][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20124],
        [19594],
        [19377],
        [18636],
        [18494],
        [18028],
        [17513],
        [17514],
        [16968],
        [17084],
        [16785],
        [16622],
        [16707],
        [16322],
        [15833],
        [15938],
        [15926],
        [16006],
        [15790]], device='cuda:0')
[2024-07-24 10:19:49,794][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18742],
        [19971],
        [21561],
        [21831],
        [22738],
        [22865],
        [23319],
        [23326],
        [23630],
        [23837],
        [24275],
        [24653],
        [25012],
        [25476],
        [25876],
        [26057],
        [26396],
        [26642],
        [26884]], device='cuda:0')
[2024-07-24 10:19:49,796][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2613],
        [2676],
        [3107],
        [3045],
        [3072],
        [2491],
        [2399],
        [2459],
        [2494],
        [2571],
        [2597],
        [2624],
        [2621],
        [2739],
        [2789],
        [2788],
        [2791],
        [2767],
        [2743]], device='cuda:0')
[2024-07-24 10:19:49,799][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3743],
        [ 3930],
        [ 3932],
        [ 4942],
        [ 5863],
        [ 5804],
        [ 8485],
        [ 8056],
        [11538],
        [11898],
        [15180],
        [17595],
        [17022],
        [21149],
        [18219],
        [20271],
        [22255],
        [20538],
        [21215]], device='cuda:0')
[2024-07-24 10:19:49,800][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 9284],
        [11696],
        [14224],
        [10893],
        [44524],
        [16186],
        [14993],
        [10543],
        [15939],
        [ 7346],
        [ 1340],
        [ 6023],
        [ 5993],
        [14104],
        [47221],
        [17697],
        [ 6721],
        [10578],
        [12927]], device='cuda:0')
[2024-07-24 10:19:49,801][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44882],
        [45843],
        [43552],
        [31002],
        [42118],
        [37667],
        [25820],
        [38107],
        [30098],
        [16930],
        [25631],
        [36730],
        [26268],
        [36627],
        [26399],
        [38750],
        [33363],
        [41513],
        [35138]], device='cuda:0')
[2024-07-24 10:19:49,802][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25199],
        [24902],
        [ 9419],
        [ 1554],
        [15633],
        [ 1657],
        [ 1287],
        [ 4962],
        [ 4404],
        [ 5226],
        [ 3717],
        [ 5965],
        [ 5982],
        [ 7300],
        [12821],
        [ 9971],
        [ 6951],
        [ 8256],
        [ 6763]], device='cuda:0')
[2024-07-24 10:19:49,805][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7552],
        [ 7356],
        [ 8657],
        [ 8101],
        [ 9158],
        [13164],
        [16294],
        [15478],
        [15868],
        [17970],
        [17116],
        [18387],
        [15682],
        [16052],
        [14580],
        [16046],
        [21024],
        [19030],
        [21798]], device='cuda:0')
[2024-07-24 10:19:49,807][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39623],
        [21068],
        [20710],
        [27649],
        [25240],
        [29931],
        [30015],
        [28563],
        [28982],
        [28263],
        [30512],
        [30055],
        [28896],
        [28874],
        [26821],
        [30931],
        [29891],
        [29795],
        [30396]], device='cuda:0')
[2024-07-24 10:19:49,808][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[5183],
        [2699],
        [1313],
        [1297],
        [1336],
        [1280],
        [ 938],
        [ 864],
        [ 941],
        [ 941],
        [ 817],
        [ 805],
        [ 800],
        [ 854],
        [ 868],
        [ 892],
        [ 793],
        [ 837],
        [ 841]], device='cuda:0')
[2024-07-24 10:19:49,809][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 1849],
        [ 2737],
        [43638],
        [ 4155],
        [40691],
        [25353],
        [17095],
        [24966],
        [ 2575],
        [16946],
        [ 7219],
        [10733],
        [ 8952],
        [10381],
        [34744],
        [10876],
        [18645],
        [ 8054],
        [ 5017]], device='cuda:0')
[2024-07-24 10:19:49,811][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15978],
        [10157],
        [ 2642],
        [14914],
        [23858],
        [23345],
        [17504],
        [37436],
        [ 8508],
        [35828],
        [12719],
        [11995],
        [31438],
        [ 7943],
        [33833],
        [14132],
        [18669],
        [18308],
        [13522]], device='cuda:0')
[2024-07-24 10:19:49,814][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[43661],
        [45099],
        [43888],
        [44109],
        [44026],
        [44982],
        [46994],
        [21804],
        [36129],
        [34750],
        [37766],
        [39529],
        [37016],
        [25995],
        [43236],
        [34952],
        [45264],
        [ 9548],
        [44722]], device='cuda:0')
[2024-07-24 10:19:49,815][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[6910],
        [6912],
        [6910],
        [6929],
        [6910],
        [6910],
        [6923],
        [6914],
        [6927],
        [6918],
        [6939],
        [7016],
        [6924],
        [7180],
        [6916],
        [6948],
        [7219],
        [6916],
        [7389]], device='cuda:0')
[2024-07-24 10:19:49,816][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10723],
        [10426],
        [ 6840],
        [ 4976],
        [ 4193],
        [ 4240],
        [ 4438],
        [ 4395],
        [ 3746],
        [ 3704],
        [ 4017],
        [ 4749],
        [ 4624],
        [ 6525],
        [ 6430],
        [ 6868],
        [ 8422],
        [ 8627],
        [ 9786]], device='cuda:0')
[2024-07-24 10:19:49,817][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1468],
        [5571],
        [5683],
        [5385],
        [5678],
        [5256],
        [5144],
        [4968],
        [4932],
        [4918],
        [4965],
        [4999],
        [5174],
        [5101],
        [5155],
        [5197],
        [5114],
        [5166],
        [5149]], device='cuda:0')
[2024-07-24 10:19:49,819][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25155],
        [26376],
        [26365],
        [24633],
        [21401],
        [20171],
        [18651],
        [17101],
        [15995],
        [14455],
        [12957],
        [11520],
        [11222],
        [ 7822],
        [ 8042],
        [ 6197],
        [ 5015],
        [ 4971],
        [ 3770]], device='cuda:0')
[2024-07-24 10:19:49,821][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19259],
        [17077],
        [10927],
        [11286],
        [12058],
        [12474],
        [14395],
        [17261],
        [25789],
        [18376],
        [36481],
        [17328],
        [16617],
        [18845],
        [22857],
        [20897],
        [15984],
        [19253],
        [20583]], device='cuda:0')
[2024-07-24 10:19:49,822][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[33363],
        [33008],
        [20970],
        [32942],
        [26160],
        [34488],
        [27492],
        [35865],
        [33409],
        [38219],
        [41736],
        [36520],
        [18326],
        [11661],
        [21607],
        [21899],
        [18463],
        [16476],
        [24375]], device='cuda:0')
[2024-07-24 10:19:49,823][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10503],
        [11133],
        [26824],
        [34183],
        [24861],
        [30328],
        [36579],
        [33246],
        [35784],
        [37359],
        [39893],
        [40437],
        [44395],
        [45951],
        [42352],
        [45175],
        [45485],
        [43623],
        [44667]], device='cuda:0')
[2024-07-24 10:19:49,825][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15066],
        [10377],
        [ 7518],
        [ 3537],
        [ 6693],
        [ 5252],
        [ 5583],
        [ 4741],
        [ 6067],
        [ 5994],
        [ 6881],
        [ 6583],
        [ 6856],
        [ 6135],
        [ 9710],
        [ 8959],
        [ 7966],
        [10713],
        [ 9851]], device='cuda:0')
[2024-07-24 10:19:49,828][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9226],
        [10735],
        [ 9460],
        [ 5515],
        [ 5959],
        [ 4262],
        [ 4083],
        [ 5448],
        [ 3434],
        [ 5190],
        [ 3131],
        [ 2933],
        [ 3933],
        [ 3177],
        [ 2632],
        [ 2954],
        [ 3003],
        [ 2959],
        [ 3420]], device='cuda:0')
[2024-07-24 10:19:49,829][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[12899],
        [13719],
        [15130],
        [15217],
        [15591],
        [15693],
        [15638],
        [15755],
        [15836],
        [16044],
        [16110],
        [15997],
        [16087],
        [16050],
        [16129],
        [16158],
        [16124],
        [16178],
        [16074]], device='cuda:0')
[2024-07-24 10:19:49,830][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[48813],
        [49041],
        [12810],
        [48887],
        [ 9034],
        [ 8914],
        [ 9898],
        [ 7450],
        [48801],
        [ 7779],
        [ 7456],
        [13504],
        [ 9916],
        [48751],
        [13508],
        [11123],
        [12608],
        [25588],
        [48292]], device='cuda:0')
[2024-07-24 10:19:49,831][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21775],
        [19155],
        [40304],
        [34932],
        [41515],
        [39617],
        [41478],
        [42546],
        [30774],
        [40162],
        [36711],
        [38425],
        [44650],
        [43436],
        [39704],
        [42753],
        [43344],
        [46140],
        [36520]], device='cuda:0')
[2024-07-24 10:19:49,834][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[20914],
        [29400],
        [49375],
        [28026],
        [30786],
        [30934],
        [31518],
        [27156],
        [40563],
        [12287],
        [35770],
        [38284],
        [32114],
        [41041],
        [23015],
        [37153],
        [32001],
        [32890],
        [31623]], device='cuda:0')
[2024-07-24 10:19:49,837][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430],
        [36430]], device='cuda:0')
[2024-07-24 10:19:49,843][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:49,844][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,844][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,844][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,845][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,845][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,845][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,846][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,846][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,846][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,846][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,847][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,847][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:49,847][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9999e-01, 6.5615e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,851][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9835, 0.0165], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,851][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2577, 0.7423], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,851][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9348, 0.0652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,852][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5485, 0.4515], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,852][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9913e-01, 8.7395e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,852][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5930, 0.4070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,852][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8031, 0.1969], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,853][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,854][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3490, 0.6510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,857][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4404, 0.5596], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,857][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4026, 0.5974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:49,857][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.9247, 0.0166, 0.0587], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,858][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([9.9976e-01, 2.4245e-04, 2.8333e-07], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,858][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.1116, 0.6765, 0.2119], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,858][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.5518, 0.4116, 0.0366], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,859][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.2842, 0.6043, 0.1115], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,859][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.9700, 0.0023, 0.0277], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,859][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.2673, 0.2036, 0.5291], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,860][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.4485, 0.1529, 0.3986], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,863][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.9741, 0.0084, 0.0174], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,863][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.1245, 0.4773, 0.3982], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,864][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.3547, 0.1461, 0.4992], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,864][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.2221, 0.3249, 0.4530], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:49,864][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.4972e-01, 7.1262e-04, 3.9953e-02, 9.6116e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,865][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.9495e-01, 3.9907e-03, 3.4256e-05, 1.0221e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,865][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0502, 0.2190, 0.5020, 0.2288], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,865][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7562, 0.1826, 0.0575, 0.0037], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,865][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2191, 0.4082, 0.1001, 0.2726], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,866][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.4767e-01, 6.4070e-04, 1.3964e-02, 3.7723e-02], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,870][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1777, 0.1078, 0.3476, 0.3669], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,870][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1605, 0.1077, 0.1277, 0.6040], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,870][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9838, 0.0024, 0.0051, 0.0087], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,870][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0695, 0.2443, 0.4775, 0.2088], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,871][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2950, 0.0643, 0.2118, 0.4290], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,871][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1732, 0.2497, 0.3458, 0.2314], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:49,871][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.6006, 0.0255, 0.2259, 0.0742, 0.0739], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,872][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([9.9922e-01, 6.6478e-04, 1.4298e-06, 8.7850e-05, 2.2134e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,872][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0503, 0.1592, 0.1695, 0.2908, 0.3302], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,872][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.7713, 0.1435, 0.0425, 0.0414, 0.0013], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,876][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.2171, 0.3177, 0.0903, 0.3358, 0.0391], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,876][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.6234, 0.0045, 0.0436, 0.1754, 0.1531], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,877][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0785, 0.1237, 0.2363, 0.3200, 0.2415], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,877][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0773, 0.0540, 0.0731, 0.4825, 0.3131], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,877][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.9579, 0.0045, 0.0092, 0.0139, 0.0144], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,877][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0286, 0.1645, 0.3591, 0.1885, 0.2593], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,878][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.5012, 0.0333, 0.0972, 0.1623, 0.2061], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,878][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.1194, 0.1754, 0.2503, 0.1642, 0.2907], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:49,878][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.6248, 0.0075, 0.1204, 0.0720, 0.1659, 0.0093], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,879][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([9.9869e-01, 1.0207e-03, 3.5855e-06, 2.0154e-04, 4.3299e-05, 4.3977e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,882][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0153, 0.1010, 0.1080, 0.1890, 0.4998, 0.0868], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,883][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([7.2440e-01, 2.3578e-01, 5.0279e-03, 2.8472e-02, 5.7421e-03, 5.7842e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,883][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1972, 0.2280, 0.0746, 0.3285, 0.0426, 0.1291], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,883][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([7.9939e-01, 6.3374e-04, 1.0193e-02, 6.5782e-02, 1.0004e-01, 2.3962e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,883][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1195, 0.0698, 0.1792, 0.2232, 0.1921, 0.2162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,884][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2108, 0.0968, 0.0552, 0.2208, 0.1263, 0.2901], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,884][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.9116, 0.0056, 0.0044, 0.0173, 0.0136, 0.0474], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,884][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0510, 0.1498, 0.2379, 0.1494, 0.2864, 0.1255], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,885][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0564, 0.0610, 0.1724, 0.2900, 0.2593, 0.1608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,887][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1002, 0.1459, 0.2069, 0.1347, 0.2405, 0.1718], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:49,889][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7759, 0.0008, 0.0509, 0.0186, 0.0814, 0.0058, 0.0665],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,889][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9920e-01, 6.3285e-04, 1.6119e-06, 1.0631e-04, 2.1122e-05, 2.0834e-05,
        2.1131e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,889][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0123, 0.0869, 0.0956, 0.1582, 0.3583, 0.2587, 0.0299],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,890][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.7547, 0.1811, 0.0313, 0.0238, 0.0059, 0.0024, 0.0008],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,890][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1750, 0.2069, 0.0618, 0.2628, 0.0388, 0.1315, 0.1232],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,890][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.3266e-01, 1.1471e-04, 2.0990e-03, 1.6261e-02, 3.3083e-02, 5.9896e-03,
        9.7911e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,891][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1195, 0.0450, 0.1144, 0.1570, 0.1153, 0.1636, 0.2851],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,891][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1584, 0.1683, 0.0555, 0.1547, 0.0772, 0.1627, 0.2231],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,891][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.8034e-01, 1.0309e-03, 1.4530e-03, 3.2527e-03, 3.6088e-03, 9.6625e-03,
        6.5690e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,895][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0472, 0.1228, 0.1815, 0.1249, 0.2594, 0.1621, 0.1020],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,895][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1865, 0.0448, 0.1204, 0.1811, 0.2000, 0.1028, 0.1643],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,896][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0864, 0.1256, 0.1778, 0.1171, 0.2073, 0.1498, 0.1361],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:49,896][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.4041, 0.0156, 0.1063, 0.0947, 0.0999, 0.0173, 0.2009, 0.0612],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,896][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([9.9921e-01, 6.1972e-04, 1.3314e-06, 9.2336e-05, 1.8812e-05, 1.7826e-05,
        1.9254e-05, 2.3747e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,897][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0044, 0.0559, 0.0766, 0.0929, 0.4055, 0.1322, 0.1333, 0.0992],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,897][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2901, 0.3091, 0.0885, 0.0682, 0.0494, 0.1166, 0.0768, 0.0012],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,897][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.1184, 0.1733, 0.0284, 0.2020, 0.0258, 0.1181, 0.1785, 0.1554],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,898][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.5237, 0.0017, 0.0133, 0.1028, 0.1469, 0.0495, 0.1166, 0.0456],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,901][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0288, 0.0536, 0.1024, 0.1281, 0.1162, 0.1553, 0.2821, 0.1334],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,902][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1889, 0.1895, 0.0632, 0.1338, 0.0665, 0.1196, 0.1384, 0.1002],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,902][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.8008, 0.0073, 0.0075, 0.0229, 0.0161, 0.0988, 0.0064, 0.0404],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,902][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0275, 0.1054, 0.1260, 0.1227, 0.1935, 0.1676, 0.1258, 0.1315],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,903][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0131, 0.0510, 0.1449, 0.2003, 0.1715, 0.1280, 0.1712, 0.1199],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,903][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0721, 0.1048, 0.1440, 0.0977, 0.1685, 0.1248, 0.1138, 0.1743],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:49,903][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([9.7756e-01, 3.8775e-05, 6.0579e-03, 1.2534e-03, 6.6239e-03, 5.3057e-04,
        2.5742e-03, 1.5682e-03, 3.7958e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,904][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([9.8783e-01, 4.4513e-03, 3.3833e-05, 8.7863e-04, 2.4603e-04, 2.4433e-04,
        2.6026e-04, 2.9709e-04, 5.7626e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,904][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0046, 0.0224, 0.0490, 0.0436, 0.3395, 0.0857, 0.0452, 0.3848, 0.0251],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,906][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([6.5357e-01, 2.9646e-01, 8.9392e-03, 1.5786e-02, 2.6951e-03, 1.1211e-02,
        1.0306e-02, 1.0116e-03, 2.2882e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,908][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0528, 0.0935, 0.0954, 0.1167, 0.0508, 0.0598, 0.1017, 0.3568, 0.0725],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,908][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([8.8352e-01, 1.1613e-04, 2.2506e-03, 1.5551e-02, 4.1489e-02, 6.8746e-03,
        1.3606e-02, 9.9222e-03, 2.6672e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,908][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0677, 0.0250, 0.0721, 0.0907, 0.0804, 0.1072, 0.1872, 0.1254, 0.2442],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,909][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1162, 0.0839, 0.0320, 0.1148, 0.0542, 0.1277, 0.1783, 0.0930, 0.1999],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,909][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([9.7630e-01, 6.1429e-04, 1.2681e-03, 2.4159e-03, 3.0621e-03, 8.9318e-03,
        6.9322e-04, 6.3093e-03, 4.0430e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,909][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0353, 0.0872, 0.1500, 0.0944, 0.1764, 0.1287, 0.1040, 0.1647, 0.0594],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,910][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.2123, 0.0305, 0.0985, 0.1365, 0.1653, 0.0722, 0.1229, 0.0704, 0.0914],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,910][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0662, 0.0932, 0.1302, 0.0856, 0.1512, 0.1090, 0.1001, 0.1533, 0.1112],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:49,914][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.5495, 0.0044, 0.0409, 0.0315, 0.0362, 0.0075, 0.0614, 0.0260, 0.1544,
        0.0883], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,914][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([9.9860e-01, 4.0250e-04, 7.9245e-07, 6.5447e-05, 1.1918e-05, 1.2116e-05,
        1.2241e-05, 1.5688e-05, 8.6753e-04, 8.2025e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,914][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0051, 0.0320, 0.0374, 0.0598, 0.1645, 0.1365, 0.0614, 0.1608, 0.2256,
        0.1169], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,915][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.6118, 0.2229, 0.0232, 0.0346, 0.0051, 0.0179, 0.0369, 0.0447, 0.0021,
        0.0008], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,915][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0730, 0.1238, 0.0247, 0.1070, 0.0205, 0.1581, 0.1155, 0.2144, 0.1237,
        0.0393], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,915][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.4547, 0.0013, 0.0104, 0.0702, 0.1054, 0.0367, 0.0841, 0.0547, 0.1638,
        0.0187], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,916][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0545, 0.0307, 0.0559, 0.0813, 0.0654, 0.0887, 0.1542, 0.1052, 0.1890,
        0.1752], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,916][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1467, 0.0968, 0.0340, 0.1045, 0.0505, 0.1027, 0.1393, 0.0818, 0.1683,
        0.0753], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,918][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.8968, 0.0039, 0.0087, 0.0087, 0.0098, 0.0427, 0.0037, 0.0208, 0.0021,
        0.0028], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,920][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0221, 0.0843, 0.1308, 0.0798, 0.1815, 0.1040, 0.0903, 0.1550, 0.0568,
        0.0954], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,921][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.2139, 0.0364, 0.0881, 0.1080, 0.1299, 0.0649, 0.0974, 0.0624, 0.0781,
        0.1209], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,921][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0565, 0.0803, 0.1109, 0.0742, 0.1281, 0.0943, 0.0859, 0.1310, 0.0950,
        0.1440], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:49,921][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.4161, 0.0006, 0.0242, 0.0080, 0.0303, 0.0019, 0.0263, 0.0092, 0.0658,
        0.0921, 0.3254], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,922][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([9.9739e-01, 7.7649e-04, 2.0992e-06, 1.2532e-04, 2.6070e-05, 2.5518e-05,
        2.6950e-05, 3.3491e-05, 1.4309e-03, 2.0572e-05, 1.4196e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,922][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0118, 0.0354, 0.0433, 0.0477, 0.1907, 0.0984, 0.0522, 0.1631, 0.1229,
        0.2046, 0.0299], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,922][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([8.9166e-01, 6.8184e-02, 9.0478e-03, 8.3333e-03, 4.4050e-04, 9.6937e-03,
        8.7455e-03, 2.8793e-03, 6.0345e-04, 4.0352e-04, 1.2094e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,923][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0729, 0.1402, 0.0346, 0.1424, 0.0228, 0.0612, 0.1048, 0.1508, 0.1434,
        0.0574, 0.0694], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,924][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([8.8407e-01, 9.8670e-05, 1.5770e-03, 1.2236e-02, 3.0854e-02, 4.8772e-03,
        9.9153e-03, 8.6888e-03, 2.0023e-02, 2.9685e-03, 2.4685e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,927][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0673, 0.0158, 0.0439, 0.0565, 0.0500, 0.0671, 0.1059, 0.0746, 0.1445,
        0.1626, 0.2118], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,927][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1245, 0.0617, 0.0237, 0.0881, 0.0400, 0.0946, 0.1485, 0.0709, 0.1637,
        0.0605, 0.1239], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,927][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([9.7764e-01, 4.8109e-04, 1.6940e-03, 1.9899e-03, 2.4633e-03, 8.2228e-03,
        6.7466e-04, 5.3160e-03, 4.2612e-04, 7.1921e-04, 3.7715e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,928][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0202, 0.0659, 0.1228, 0.0637, 0.1315, 0.0980, 0.0833, 0.1472, 0.0476,
        0.1791, 0.0406], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,928][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2004, 0.0282, 0.0741, 0.0994, 0.1194, 0.0575, 0.0906, 0.0580, 0.0712,
        0.1185, 0.0827], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,928][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0524, 0.0730, 0.1029, 0.0667, 0.1185, 0.0848, 0.0778, 0.1189, 0.0862,
        0.1320, 0.0867], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:49,929][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([5.0419e-01, 1.0091e-04, 7.1160e-03, 1.9376e-03, 7.4055e-03, 6.1873e-04,
        4.4772e-03, 2.9496e-03, 1.3471e-02, 3.2930e-02, 1.0763e-01, 3.1717e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,929][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.9747e-01, 6.8786e-04, 2.0756e-06, 1.3426e-04, 2.6024e-05, 2.7455e-05,
        2.7804e-05, 3.2847e-05, 1.3936e-03, 1.9381e-05, 1.4020e-04, 3.6961e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,933][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0026, 0.0225, 0.0346, 0.0427, 0.1786, 0.0921, 0.0244, 0.1626, 0.1333,
        0.2171, 0.0744, 0.0150], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,933][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([8.0472e-01, 1.7246e-01, 5.3674e-03, 8.7852e-03, 6.5147e-04, 2.2498e-03,
        3.3690e-03, 1.6426e-03, 1.0970e-04, 3.9103e-04, 1.3893e-04, 1.1399e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,934][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0903, 0.1196, 0.0387, 0.1332, 0.0342, 0.0598, 0.0916, 0.0948, 0.1099,
        0.0536, 0.0814, 0.0927], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,934][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([8.9922e-01, 4.2890e-05, 1.0277e-03, 7.4285e-03, 2.1757e-02, 2.4250e-03,
        4.5946e-03, 4.3565e-03, 1.0326e-02, 1.4550e-03, 1.4458e-02, 3.2909e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,934][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0609, 0.0091, 0.0343, 0.0401, 0.0378, 0.0505, 0.0747, 0.0571, 0.1083,
        0.1249, 0.1635, 0.2389], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,935][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1301, 0.0883, 0.0312, 0.0765, 0.0404, 0.0732, 0.1044, 0.0550, 0.1186,
        0.0526, 0.0923, 0.1373], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,935][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.8985e-01, 2.7922e-04, 8.4856e-04, 9.4084e-04, 1.3347e-03, 2.9471e-03,
        2.7474e-04, 2.5242e-03, 1.9296e-04, 3.8598e-04, 1.8841e-04, 2.3007e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,935][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0300, 0.0615, 0.0928, 0.0615, 0.1338, 0.0887, 0.0549, 0.1384, 0.0575,
        0.1576, 0.0651, 0.0582], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,939][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.4520, 0.0192, 0.0457, 0.0561, 0.0791, 0.0318, 0.0519, 0.0329, 0.0442,
        0.0737, 0.0498, 0.0636], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,939][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0466, 0.0659, 0.0944, 0.0605, 0.1100, 0.0779, 0.0712, 0.1103, 0.0793,
        0.1236, 0.0802, 0.0802], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:49,940][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.1756, 0.0011, 0.0163, 0.0091, 0.0130, 0.0014, 0.0093, 0.0069, 0.0466,
        0.0352, 0.1730, 0.4949, 0.0176], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,940][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ office] are: tensor([9.9821e-01, 5.0904e-04, 1.1979e-06, 7.1164e-05, 1.6567e-05, 1.4546e-05,
        1.4380e-05, 2.0183e-05, 9.7178e-04, 1.0183e-05, 8.1534e-05, 1.9217e-05,
        6.0443e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,941][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0037, 0.0250, 0.0223, 0.0437, 0.1684, 0.0701, 0.0810, 0.1303, 0.1822,
        0.1192, 0.0615, 0.0724, 0.0204], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,941][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ office] are: tensor([6.6047e-01, 2.4534e-01, 1.8587e-02, 2.8585e-02, 2.1397e-03, 1.9250e-02,
        1.1423e-02, 5.7939e-03, 6.4529e-04, 4.0281e-03, 4.3537e-04, 3.2566e-03,
        4.1798e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,941][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0449, 0.1238, 0.0157, 0.1197, 0.0177, 0.0690, 0.1066, 0.0649, 0.1394,
        0.0461, 0.0837, 0.1527, 0.0158], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,942][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ office] are: tensor([4.4320e-01, 3.2043e-04, 3.2600e-03, 2.6514e-02, 4.5376e-02, 1.4496e-02,
        3.0654e-02, 2.6111e-02, 6.2387e-02, 9.4814e-03, 8.9180e-02, 2.2717e-01,
        2.1847e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,945][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0404, 0.0141, 0.0300, 0.0415, 0.0308, 0.0480, 0.0712, 0.0454, 0.0958,
        0.1062, 0.1367, 0.1980, 0.1419], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,946][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.1238, 0.0667, 0.0218, 0.0774, 0.0297, 0.0653, 0.1038, 0.0574, 0.1317,
        0.0517, 0.0951, 0.1245, 0.0512], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,946][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ office] are: tensor([9.4862e-01, 2.1179e-03, 5.0653e-03, 4.0469e-03, 4.4523e-03, 1.5632e-02,
        1.4072e-03, 1.0321e-02, 9.7210e-04, 1.4969e-03, 9.3362e-04, 1.3122e-03,
        3.6268e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,947][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0161, 0.0668, 0.1023, 0.0702, 0.1308, 0.0875, 0.0824, 0.1165, 0.0451,
        0.1102, 0.0576, 0.0742, 0.0405], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,947][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.2411, 0.0264, 0.0617, 0.0778, 0.0960, 0.0424, 0.0663, 0.0424, 0.0563,
        0.0866, 0.0620, 0.0753, 0.0656], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,947][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0422, 0.0605, 0.0830, 0.0558, 0.0963, 0.0710, 0.0646, 0.0986, 0.0717,
        0.1082, 0.0717, 0.0717, 0.1046], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:49,948][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([7.6317e-01, 5.1615e-05, 7.2321e-03, 8.2573e-04, 3.4701e-03, 3.8726e-04,
        1.0723e-03, 1.8352e-03, 3.2300e-03, 1.5838e-02, 2.6962e-02, 5.9114e-02,
        8.8855e-03, 1.0792e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,948][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([9.8253e-01, 3.3935e-03, 3.6694e-05, 1.0391e-03, 2.7148e-04, 3.1627e-04,
        3.0446e-04, 3.1329e-04, 5.8724e-03, 2.1689e-04, 1.0508e-03, 3.7456e-04,
        7.1948e-04, 3.5658e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,952][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0026, 0.0121, 0.0252, 0.0224, 0.1716, 0.0733, 0.0430, 0.1819, 0.0584,
        0.2381, 0.0486, 0.0302, 0.0683, 0.0244], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,952][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([6.7130e-01, 2.8873e-01, 1.7583e-02, 9.0343e-03, 6.1575e-04, 8.9165e-03,
        1.9580e-03, 9.6223e-04, 9.7425e-05, 2.9331e-04, 6.1090e-05, 3.4243e-04,
        7.4568e-05, 3.2462e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,953][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0613, 0.0890, 0.0358, 0.0956, 0.0262, 0.0488, 0.1055, 0.0980, 0.1021,
        0.0444, 0.0695, 0.1317, 0.0179, 0.0742], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,953][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([8.2964e-01, 5.7581e-05, 1.6122e-03, 8.5442e-03, 2.7562e-02, 3.0897e-03,
        5.8543e-03, 5.5458e-03, 1.1593e-02, 1.8029e-03, 1.5134e-02, 4.2921e-02,
        4.6456e-03, 4.1999e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,953][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0453, 0.0062, 0.0193, 0.0239, 0.0223, 0.0282, 0.0416, 0.0377, 0.0656,
        0.0765, 0.1052, 0.1489, 0.1199, 0.2594], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,954][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1382, 0.0861, 0.0322, 0.0647, 0.0358, 0.0597, 0.0776, 0.0493, 0.0911,
        0.0476, 0.0719, 0.1015, 0.0534, 0.0908], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,954][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([9.8190e-01, 4.7877e-04, 1.7052e-03, 1.2405e-03, 2.7864e-03, 3.8443e-03,
        4.7469e-04, 3.2098e-03, 3.2840e-04, 8.8095e-04, 3.8005e-04, 5.0020e-04,
        1.8820e-03, 3.8570e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,954][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0205, 0.0455, 0.0751, 0.0534, 0.0914, 0.0789, 0.0579, 0.1219, 0.0472,
        0.1259, 0.0599, 0.0642, 0.0904, 0.0678], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,958][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.5695, 0.0116, 0.0285, 0.0379, 0.0553, 0.0195, 0.0338, 0.0203, 0.0295,
        0.0505, 0.0331, 0.0443, 0.0381, 0.0281], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,958][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0405, 0.0558, 0.0779, 0.0505, 0.0904, 0.0642, 0.0590, 0.0902, 0.0654,
        0.1006, 0.0664, 0.0664, 0.0966, 0.0763], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:49,959][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([4.7113e-01, 2.7706e-04, 1.1102e-02, 1.7083e-03, 4.5207e-03, 8.9635e-04,
        2.1932e-03, 5.1061e-03, 6.4302e-03, 2.1343e-02, 4.5767e-02, 1.0234e-01,
        1.4996e-02, 2.2711e-01, 8.5075e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,959][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([9.9754e-01, 5.7727e-04, 1.0187e-06, 8.0597e-05, 1.7177e-05, 1.5558e-05,
        1.7367e-05, 1.9323e-05, 1.0700e-03, 1.2019e-05, 9.0111e-05, 2.2919e-05,
        6.6875e-05, 4.5789e-04, 1.4560e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,959][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0081, 0.0258, 0.0263, 0.0424, 0.0439, 0.0795, 0.0620, 0.1433, 0.1560,
        0.1592, 0.0530, 0.0556, 0.0473, 0.0490, 0.0485], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,960][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([8.5030e-01, 8.7392e-02, 1.0974e-02, 9.0732e-03, 2.7147e-04, 1.3496e-02,
        9.4767e-03, 1.0490e-02, 8.7676e-04, 3.7184e-03, 9.1972e-04, 1.9982e-03,
        6.5666e-04, 3.0739e-04, 4.5227e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,960][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0671, 0.1043, 0.0257, 0.1081, 0.0107, 0.0491, 0.0865, 0.0708, 0.1422,
        0.0415, 0.0573, 0.1119, 0.0216, 0.0934, 0.0096], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,961][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([5.5643e-01, 5.2922e-04, 4.3619e-03, 2.0684e-02, 3.2309e-02, 8.7075e-03,
        1.4711e-02, 1.7148e-02, 2.5887e-02, 6.3192e-03, 3.8747e-02, 8.5653e-02,
        1.6760e-02, 8.8335e-02, 8.3415e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,964][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0116, 0.0091, 0.0206, 0.0249, 0.0229, 0.0296, 0.0514, 0.0290, 0.0647,
        0.0650, 0.0858, 0.1215, 0.0921, 0.2487, 0.1232], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,965][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0341, 0.0279, 0.0155, 0.0809, 0.0431, 0.1018, 0.1227, 0.0483, 0.1240,
        0.0377, 0.0783, 0.1070, 0.0337, 0.0687, 0.0762], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,965][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([9.8879e-01, 2.0786e-04, 1.0723e-03, 6.6132e-04, 1.0676e-03, 1.9897e-03,
        3.7829e-04, 1.6414e-03, 2.7443e-04, 5.9737e-04, 3.4932e-04, 5.2058e-04,
        1.4570e-03, 3.8213e-04, 6.1198e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,966][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0099, 0.0449, 0.0948, 0.0536, 0.0666, 0.0727, 0.0701, 0.1061, 0.0337,
        0.1205, 0.0460, 0.0639, 0.0702, 0.0624, 0.0844], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,966][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.9033, 0.0025, 0.0051, 0.0058, 0.0110, 0.0032, 0.0056, 0.0035, 0.0057,
        0.0094, 0.0060, 0.0080, 0.0071, 0.0057, 0.0180], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,966][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0327, 0.0475, 0.0703, 0.0440, 0.0818, 0.0569, 0.0518, 0.0821, 0.0579,
        0.0932, 0.0584, 0.0589, 0.0899, 0.0678, 0.1068], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:49,967][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2319, 0.0003, 0.0153, 0.0021, 0.0092, 0.0010, 0.0029, 0.0057, 0.0096,
        0.0260, 0.0736, 0.1737, 0.0189, 0.2395, 0.1255, 0.0650],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,968][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.9618e-01, 8.3941e-04, 2.5665e-06, 1.4582e-04, 3.1157e-05, 3.1402e-05,
        3.2776e-05, 3.9920e-05, 1.5946e-03, 2.3092e-05, 1.6290e-04, 4.2707e-05,
        1.1315e-04, 6.3487e-04, 2.4361e-05, 1.0116e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,971][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0056, 0.0264, 0.0293, 0.0442, 0.0980, 0.0631, 0.0311, 0.1140, 0.0899,
        0.1281, 0.0574, 0.0498, 0.0471, 0.0549, 0.1309, 0.0302],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,971][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.4501e-01, 9.2553e-02, 4.9818e-03, 7.8038e-03, 2.1333e-03, 2.6102e-03,
        4.8643e-03, 2.4392e-02, 1.1315e-03, 8.0085e-03, 5.1483e-04, 3.9791e-03,
        8.0549e-04, 8.1751e-04, 3.8123e-04, 1.4838e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,971][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0659, 0.0974, 0.0199, 0.1119, 0.0184, 0.0549, 0.0767, 0.0479, 0.1378,
        0.0477, 0.0716, 0.0985, 0.0162, 0.1055, 0.0161, 0.0135],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,972][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([5.5367e-01, 2.8793e-04, 2.6043e-03, 1.7144e-02, 3.5188e-02, 6.5819e-03,
        1.2681e-02, 9.3392e-03, 2.4271e-02, 3.7546e-03, 3.1648e-02, 8.9213e-02,
        9.9734e-03, 8.7701e-02, 9.6799e-02, 1.9146e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,972][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0395, 0.0085, 0.0218, 0.0239, 0.0222, 0.0272, 0.0412, 0.0274, 0.0512,
        0.0646, 0.0699, 0.1003, 0.0861, 0.1889, 0.0955, 0.1320],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,973][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1223, 0.0381, 0.0128, 0.0553, 0.0242, 0.0504, 0.0923, 0.0411, 0.1148,
        0.0379, 0.0862, 0.0920, 0.0431, 0.0772, 0.0693, 0.0430],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,973][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([9.8586e-01, 5.0056e-04, 1.5409e-03, 9.5992e-04, 1.8830e-03, 2.2441e-03,
        3.3871e-04, 1.0293e-03, 2.5742e-04, 6.4964e-04, 3.8525e-04, 4.7183e-04,
        1.3871e-03, 4.7907e-04, 6.0635e-04, 1.4099e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,977][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0164, 0.0467, 0.0661, 0.0483, 0.0900, 0.0601, 0.0660, 0.0825, 0.0389,
        0.0830, 0.0617, 0.0584, 0.0639, 0.0726, 0.1122, 0.0332],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,977][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.3770, 0.0179, 0.0393, 0.0447, 0.0623, 0.0262, 0.0398, 0.0288, 0.0345,
        0.0575, 0.0393, 0.0474, 0.0437, 0.0295, 0.0743, 0.0376],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,978][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0312, 0.0443, 0.0646, 0.0405, 0.0752, 0.0524, 0.0480, 0.0755, 0.0536,
        0.0850, 0.0541, 0.0541, 0.0819, 0.0622, 0.0973, 0.0799],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:49,978][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([4.0824e-01, 5.4537e-05, 6.7111e-03, 5.5448e-04, 2.5211e-03, 3.0904e-04,
        6.0614e-04, 1.8668e-03, 2.8430e-03, 1.2561e-02, 2.7781e-02, 5.4767e-02,
        8.6334e-03, 1.1300e-01, 4.7546e-02, 8.7086e-02, 2.2492e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,978][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9144e-01, 1.6657e-03, 8.7662e-06, 3.5793e-04, 8.3662e-05, 9.0809e-05,
        9.1315e-05, 1.0385e-04, 2.9156e-03, 6.6069e-05, 3.8370e-04, 1.1616e-04,
        2.6689e-04, 1.3812e-03, 6.6718e-05, 2.4321e-04, 7.1437e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,979][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0037, 0.0260, 0.0252, 0.0440, 0.0946, 0.0744, 0.0079, 0.1179, 0.1070,
        0.1278, 0.0618, 0.0302, 0.0606, 0.0412, 0.1034, 0.0688, 0.0055],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,979][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.2190e-01, 1.5129e-01, 1.3591e-02, 6.8029e-03, 1.5657e-03, 5.8944e-04,
        1.9573e-04, 1.0707e-03, 1.1040e-04, 1.2010e-03, 9.6518e-05, 1.0614e-03,
        1.4628e-04, 1.0421e-04, 1.3015e-04, 9.6359e-05, 3.9276e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,983][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0773, 0.0954, 0.0244, 0.1209, 0.0150, 0.0547, 0.0579, 0.0881, 0.0982,
        0.0349, 0.0614, 0.0984, 0.0159, 0.0828, 0.0117, 0.0191, 0.0438],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,984][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([8.5523e-01, 4.7379e-05, 1.1780e-03, 5.9335e-03, 1.8421e-02, 1.6844e-03,
        2.5096e-03, 3.0147e-03, 6.0659e-03, 9.8833e-04, 7.4460e-03, 2.1470e-02,
        2.4571e-03, 2.4839e-02, 3.1482e-02, 6.6446e-03, 1.0587e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,984][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0472, 0.0038, 0.0136, 0.0159, 0.0136, 0.0168, 0.0258, 0.0206, 0.0377,
        0.0495, 0.0563, 0.0810, 0.0708, 0.1639, 0.0718, 0.1315, 0.1801],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,984][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0989, 0.0345, 0.0124, 0.0536, 0.0242, 0.0538, 0.0951, 0.0403, 0.1019,
        0.0332, 0.0707, 0.0942, 0.0365, 0.0726, 0.0592, 0.0363, 0.0825],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,985][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.8918e-01, 3.2500e-04, 1.1153e-03, 7.3856e-04, 1.5129e-03, 1.5056e-03,
        1.9481e-04, 1.2910e-03, 1.7311e-04, 5.0693e-04, 2.2376e-04, 2.6526e-04,
        1.0293e-03, 2.3592e-04, 3.7727e-04, 9.9066e-04, 3.3736e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,985][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0220, 0.0433, 0.0581, 0.0434, 0.0829, 0.0565, 0.0358, 0.0872, 0.0396,
        0.0884, 0.0468, 0.0450, 0.0693, 0.0702, 0.1140, 0.0642, 0.0332],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,986][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7679, 0.0066, 0.0120, 0.0132, 0.0216, 0.0080, 0.0122, 0.0093, 0.0117,
        0.0199, 0.0130, 0.0161, 0.0150, 0.0108, 0.0295, 0.0134, 0.0200],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,990][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0289, 0.0413, 0.0600, 0.0382, 0.0703, 0.0496, 0.0452, 0.0711, 0.0506,
        0.0798, 0.0511, 0.0513, 0.0766, 0.0591, 0.0921, 0.0761, 0.0587],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:49,990][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1970, 0.0005, 0.0151, 0.0028, 0.0071, 0.0012, 0.0026, 0.0060, 0.0077,
        0.0239, 0.0466, 0.0808, 0.0135, 0.1451, 0.0679, 0.1097, 0.2115, 0.0611],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,990][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([9.8804e-01, 1.8736e-03, 1.2924e-05, 4.3106e-04, 1.2510e-04, 1.2366e-04,
        1.2550e-04, 1.4694e-04, 3.4971e-03, 9.4062e-05, 5.1762e-04, 1.6096e-04,
        3.7831e-04, 1.8350e-03, 9.9608e-05, 3.4197e-04, 9.8380e-04, 1.2117e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,991][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0021, 0.0145, 0.0269, 0.0262, 0.1318, 0.0734, 0.0305, 0.0925, 0.0835,
        0.1356, 0.0484, 0.0320, 0.0386, 0.0265, 0.1316, 0.0740, 0.0188, 0.0131],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,991][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.3947, 0.2940, 0.0960, 0.0463, 0.0103, 0.0372, 0.0379, 0.0230, 0.0027,
        0.0133, 0.0015, 0.0053, 0.0012, 0.0010, 0.0017, 0.0150, 0.0179, 0.0011],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,992][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0364, 0.0932, 0.0181, 0.0882, 0.0178, 0.0554, 0.0874, 0.0620, 0.1230,
        0.0388, 0.0644, 0.0873, 0.0144, 0.0739, 0.0153, 0.0213, 0.0679, 0.0353],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,992][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([4.6948e-01, 1.6606e-04, 1.7498e-03, 1.4206e-02, 2.7518e-02, 7.0901e-03,
        1.1908e-02, 1.2584e-02, 2.4973e-02, 4.2548e-03, 3.5885e-02, 8.8487e-02,
        9.9939e-03, 7.9068e-02, 1.1219e-01, 3.7803e-02, 5.8492e-02, 4.1518e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,996][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0252, 0.0065, 0.0166, 0.0188, 0.0172, 0.0219, 0.0303, 0.0223, 0.0395,
        0.0439, 0.0555, 0.0771, 0.0628, 0.1278, 0.0762, 0.1036, 0.1481, 0.1069],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,996][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0530, 0.0736, 0.0279, 0.0783, 0.0446, 0.0589, 0.0786, 0.0453, 0.0877,
        0.0359, 0.0608, 0.0766, 0.0363, 0.0553, 0.0601, 0.0320, 0.0622, 0.0327],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,997][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([9.6636e-01, 8.8266e-04, 3.3730e-03, 1.7177e-03, 3.6181e-03, 4.9293e-03,
        7.4685e-04, 3.2811e-03, 6.1305e-04, 1.4672e-03, 8.4554e-04, 1.0746e-03,
        3.4771e-03, 6.6491e-04, 1.2994e-03, 2.9783e-03, 1.2189e-03, 1.4495e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,997][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0080, 0.0413, 0.0713, 0.0413, 0.0894, 0.0593, 0.0532, 0.0825, 0.0266,
        0.1092, 0.0398, 0.0505, 0.0535, 0.0495, 0.1110, 0.0504, 0.0331, 0.0302],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,997][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.8544, 0.0046, 0.0073, 0.0071, 0.0125, 0.0045, 0.0067, 0.0055, 0.0067,
        0.0110, 0.0072, 0.0084, 0.0083, 0.0058, 0.0167, 0.0074, 0.0107, 0.0152],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,998][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0273, 0.0388, 0.0550, 0.0357, 0.0642, 0.0460, 0.0417, 0.0653, 0.0466,
        0.0726, 0.0468, 0.0467, 0.0700, 0.0541, 0.0824, 0.0689, 0.0533, 0.0844],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:49,998][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.7371e-01, 2.3495e-05, 3.7673e-03, 3.2676e-04, 1.2559e-03, 1.5135e-04,
        2.4953e-04, 7.9691e-04, 8.5676e-04, 5.0010e-03, 7.4025e-03, 1.1380e-02,
        3.4519e-03, 2.4639e-02, 1.1660e-02, 1.7265e-02, 5.3317e-02, 2.7391e-02,
        5.7350e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,000][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.6983e-01, 1.3339e-02, 2.8269e-04, 3.9920e-03, 1.3455e-03, 1.5432e-03,
        1.6157e-03, 1.6320e-03, 1.6422e-02, 1.3678e-03, 4.3050e-03, 1.8997e-03,
        3.1324e-03, 1.1370e-02, 1.2648e-03, 3.0126e-03, 6.6054e-03, 7.5915e-03,
        4.9447e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,002][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0030, 0.0146, 0.0108, 0.0245, 0.1372, 0.0496, 0.0248, 0.0903, 0.0585,
        0.1610, 0.0380, 0.0288, 0.0490, 0.0234, 0.1735, 0.0596, 0.0212, 0.0284,
        0.0036], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,003][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.6484e-01, 2.2268e-01, 2.8569e-03, 3.7210e-03, 1.5030e-04, 8.6659e-04,
        2.1770e-03, 1.1060e-03, 1.3708e-04, 2.1883e-04, 2.7238e-05, 3.5748e-04,
        8.1581e-05, 7.2657e-05, 9.9033e-06, 1.4569e-04, 3.7558e-04, 1.7820e-04,
        2.1814e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,003][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0518, 0.0698, 0.0148, 0.0834, 0.0239, 0.0664, 0.0642, 0.0495, 0.0941,
        0.0376, 0.0638, 0.0737, 0.0143, 0.0764, 0.0216, 0.0449, 0.0542, 0.0290,
        0.0665], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,004][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.8632e-01, 5.6223e-05, 1.2067e-03, 4.5053e-03, 1.6826e-02, 1.2297e-03,
        1.8855e-03, 2.2745e-03, 3.5653e-03, 7.3477e-04, 4.2356e-03, 1.1367e-02,
        1.4379e-03, 1.2510e-02, 1.9914e-02, 3.7573e-03, 5.9284e-03, 3.8959e-04,
        2.1859e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,004][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0418, 0.0024, 0.0099, 0.0103, 0.0103, 0.0118, 0.0179, 0.0141, 0.0253,
        0.0366, 0.0361, 0.0533, 0.0508, 0.1167, 0.0487, 0.0944, 0.1277, 0.0952,
        0.1968], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,004][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0666, 0.0284, 0.0107, 0.0545, 0.0262, 0.0559, 0.0956, 0.0360, 0.1013,
        0.0303, 0.0669, 0.0765, 0.0304, 0.0596, 0.0567, 0.0278, 0.0627, 0.0275,
        0.0865], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,005][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.8690e-01, 3.6889e-04, 1.7606e-03, 6.7670e-04, 1.5586e-03, 1.3404e-03,
        2.1375e-04, 9.9324e-04, 1.8851e-04, 5.3206e-04, 2.6990e-04, 3.3336e-04,
        1.2195e-03, 2.6752e-04, 3.9682e-04, 1.1479e-03, 4.3067e-04, 5.2957e-04,
        8.7345e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,009][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0214, 0.0418, 0.0601, 0.0390, 0.0662, 0.0487, 0.0501, 0.0787, 0.0341,
        0.0858, 0.0378, 0.0502, 0.0617, 0.0567, 0.0878, 0.0559, 0.0472, 0.0593,
        0.0177], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,009][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.9013, 0.0020, 0.0037, 0.0044, 0.0079, 0.0023, 0.0040, 0.0029, 0.0039,
        0.0070, 0.0043, 0.0057, 0.0051, 0.0037, 0.0115, 0.0045, 0.0074, 0.0112,
        0.0073], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,010][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0258, 0.0363, 0.0522, 0.0337, 0.0613, 0.0429, 0.0396, 0.0612, 0.0440,
        0.0691, 0.0446, 0.0447, 0.0664, 0.0518, 0.0799, 0.0655, 0.0510, 0.0810,
        0.0490], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,024][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:50,026][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,027][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,027][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,027][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,028][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,028][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,028][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,029][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,030][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,033][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,036][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,036][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,036][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9925e-01, 7.5421e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,037][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9949, 0.0051], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,037][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3559, 0.6441], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,037][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3249, 0.6751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,038][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9894, 0.0106], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,038][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6752, 0.3248], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,038][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3569, 0.6431], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,039][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7248, 0.2752], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,039][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8807, 0.1193], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,041][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9820, 0.0180], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,043][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9821, 0.0179], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,044][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6863, 0.3137], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,044][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.6549, 0.2312, 0.1139], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,044][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([9.9999e-01, 1.1945e-05, 7.6865e-09], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,045][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.1517, 0.4737, 0.3746], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,045][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.1140, 0.4108, 0.4752], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,045][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.8972, 0.0450, 0.0578], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,046][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.3764, 0.5858, 0.0378], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,048][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.1913, 0.3740, 0.4348], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,050][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.3950, 0.1829, 0.4221], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,050][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.9216, 0.0518, 0.0265], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,051][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([9.9802e-01, 1.7827e-03, 1.9275e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,051][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.9762, 0.0079, 0.0159], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,051][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.6797, 0.2808, 0.0395], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,051][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6709, 0.0198, 0.2967, 0.0125], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,052][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9883e-01, 7.4865e-04, 4.4987e-06, 4.1215e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,052][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0315, 0.0871, 0.6828, 0.1986], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,052][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1013, 0.2682, 0.3770, 0.2535], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,054][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.8538, 0.0165, 0.0492, 0.0805], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,056][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4853, 0.3099, 0.1139, 0.0910], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,057][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1619, 0.3005, 0.3300, 0.2076], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,057][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3615, 0.1758, 0.3322, 0.1305], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,057][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8902, 0.0501, 0.0264, 0.0333], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,058][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.9448e-01, 3.4306e-03, 5.1302e-04, 1.5786e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,058][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9472, 0.0055, 0.0067, 0.0406], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,058][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7876, 0.0587, 0.0165, 0.1371], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,058][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.1888, 0.3110, 0.1820, 0.2288, 0.0894], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,059][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9986e-01, 8.5218e-05, 1.8928e-07, 4.3512e-05, 8.1417e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,063][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0293, 0.0844, 0.2982, 0.4719, 0.1162], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,063][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0555, 0.1747, 0.2501, 0.2022, 0.3175], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,063][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.7461, 0.0289, 0.0378, 0.1337, 0.0535], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,063][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.2888, 0.2626, 0.2037, 0.2265, 0.0184], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,064][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0966, 0.2120, 0.2155, 0.1410, 0.3349], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,064][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.2521, 0.1439, 0.2683, 0.1215, 0.2143], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,064][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.9003, 0.0371, 0.0187, 0.0242, 0.0197], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,065][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([9.9798e-01, 1.3425e-03, 1.1746e-04, 4.9357e-04, 6.7590e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,065][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.8251, 0.0106, 0.0170, 0.0946, 0.0527], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,067][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.6489, 0.0639, 0.0210, 0.2314, 0.0348], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,069][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6778, 0.0929, 0.1065, 0.0457, 0.0476, 0.0295], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,069][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([9.9982e-01, 9.8125e-05, 2.3658e-07, 5.6102e-05, 7.5294e-06, 1.3576e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,070][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0148, 0.0888, 0.1376, 0.3953, 0.2589, 0.1046], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,070][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0675, 0.1561, 0.1641, 0.1635, 0.2934, 0.1554], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,070][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.7419, 0.0154, 0.0359, 0.0824, 0.0775, 0.0469], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,070][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4122, 0.2958, 0.0888, 0.1470, 0.0338, 0.0224], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,071][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0855, 0.1640, 0.1826, 0.1084, 0.2896, 0.1699], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,071][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2712, 0.1189, 0.2506, 0.0811, 0.1729, 0.1053], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,071][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8800, 0.0338, 0.0167, 0.0218, 0.0180, 0.0297], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,073][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([9.9500e-01, 2.2514e-03, 2.4972e-04, 9.6501e-04, 1.7849e-04, 1.3577e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,075][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.7673, 0.0092, 0.0100, 0.0636, 0.0338, 0.1161], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,076][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.7650, 0.0253, 0.0068, 0.0666, 0.0127, 0.1235], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,076][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4922, 0.1207, 0.1525, 0.0605, 0.0926, 0.0554, 0.0261],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,076][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9990e-01, 5.7200e-05, 1.0086e-07, 2.9424e-05, 3.6053e-06, 6.7236e-06,
        2.0866e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,076][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0189, 0.0327, 0.1087, 0.2732, 0.1226, 0.4324, 0.0115],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,077][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0466, 0.1211, 0.1499, 0.1349, 0.2184, 0.1447, 0.1845],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,077][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8036, 0.0088, 0.0271, 0.0491, 0.0515, 0.0294, 0.0305],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,077][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3704, 0.2504, 0.0791, 0.1311, 0.0698, 0.0864, 0.0128],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,078][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0797, 0.1477, 0.1653, 0.1073, 0.2237, 0.1630, 0.1133],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,081][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2346, 0.1093, 0.2203, 0.0803, 0.1590, 0.1028, 0.0937],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,082][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8999, 0.0248, 0.0114, 0.0150, 0.0124, 0.0208, 0.0157],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,082][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.9704e-01, 1.3929e-03, 1.1509e-04, 4.8012e-04, 7.4489e-05, 7.1744e-04,
        1.7617e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,082][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5278, 0.0193, 0.0216, 0.1048, 0.0506, 0.1513, 0.1245],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,083][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6909, 0.0086, 0.0072, 0.0479, 0.0123, 0.1132, 0.1199],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,083][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.7509, 0.0639, 0.0628, 0.0221, 0.0227, 0.0169, 0.0127, 0.0481],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,083][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([9.9993e-01, 3.8487e-05, 6.2537e-08, 2.1828e-05, 2.7129e-06, 5.1172e-06,
        1.6642e-06, 1.6018e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,084][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0058, 0.0272, 0.1160, 0.1451, 0.2080, 0.2585, 0.1235, 0.1159],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,084][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0204, 0.0789, 0.1110, 0.0898, 0.1766, 0.1422, 0.1981, 0.1831],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,088][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.5851, 0.0170, 0.0323, 0.0714, 0.0485, 0.0448, 0.0467, 0.1542],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,088][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.2746, 0.3168, 0.1032, 0.1697, 0.0355, 0.0681, 0.0243, 0.0078],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,088][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0564, 0.0988, 0.1248, 0.0746, 0.2204, 0.1276, 0.0860, 0.2114],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,089][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.2342, 0.0994, 0.2126, 0.0644, 0.1444, 0.0846, 0.0770, 0.0834],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,089][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.8098, 0.0352, 0.0182, 0.0230, 0.0187, 0.0299, 0.0231, 0.0422],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,089][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([9.9076e-01, 2.8684e-03, 3.5437e-04, 1.1966e-03, 2.2766e-04, 1.5963e-03,
        4.6715e-04, 2.5295e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,090][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.3584, 0.0333, 0.0326, 0.0933, 0.0686, 0.1730, 0.1490, 0.0918],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,090][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.6213, 0.0112, 0.0061, 0.0453, 0.0121, 0.0952, 0.1194, 0.0893],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,090][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([9.0275e-01, 5.6358e-04, 4.3084e-02, 5.9284e-04, 4.6169e-02, 1.7798e-03,
        1.6702e-03, 3.1658e-03, 2.2126e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,092][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([9.9510e-01, 9.4211e-04, 6.7878e-06, 5.2389e-04, 1.0584e-04, 1.7389e-04,
        7.3719e-05, 6.8875e-05, 3.0017e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,094][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0042, 0.0066, 0.0635, 0.0497, 0.1421, 0.1306, 0.0266, 0.5742, 0.0026],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,094][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0373, 0.0863, 0.1030, 0.0857, 0.1602, 0.1058, 0.1591, 0.1683, 0.0944],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,095][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.7601, 0.0049, 0.0169, 0.0300, 0.0329, 0.0190, 0.0201, 0.0887, 0.0274],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,095][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.4773, 0.1898, 0.0533, 0.1005, 0.0503, 0.0499, 0.0307, 0.0199, 0.0283],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,095][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0574, 0.1043, 0.1199, 0.0807, 0.1680, 0.1152, 0.0926, 0.1850, 0.0769],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,096][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1901, 0.0962, 0.1890, 0.0733, 0.1357, 0.0943, 0.0839, 0.0868, 0.0507],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,096][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.7367, 0.0330, 0.0183, 0.0225, 0.0192, 0.0299, 0.0241, 0.0452, 0.0711],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,096][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([9.8026e-01, 4.4730e-03, 5.8019e-04, 1.8791e-03, 3.5955e-04, 2.5748e-03,
        8.2795e-04, 4.0701e-03, 4.9769e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,100][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.4265, 0.0171, 0.0206, 0.0723, 0.0504, 0.1333, 0.1117, 0.0598, 0.1082],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,101][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.5433, 0.0061, 0.0049, 0.0375, 0.0090, 0.0866, 0.1058, 0.0816, 0.1252],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,101][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.7478, 0.0667, 0.0496, 0.0270, 0.0172, 0.0155, 0.0080, 0.0346, 0.0283,
        0.0054], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,101][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([9.9962e-01, 4.5261e-05, 8.2202e-08, 2.7551e-05, 3.1808e-06, 6.1315e-06,
        1.8798e-06, 1.8400e-06, 2.8875e-04, 1.2049e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,102][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0067, 0.0140, 0.0603, 0.0892, 0.0922, 0.2850, 0.0527, 0.2147, 0.1354,
        0.0497], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,102][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0175, 0.0571, 0.0775, 0.0604, 0.1226, 0.0865, 0.1405, 0.2064, 0.0825,
        0.1492], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,102][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.2275, 0.0172, 0.0229, 0.0678, 0.0332, 0.0478, 0.0564, 0.1757, 0.0680,
        0.2835], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,103][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.3429, 0.2459, 0.0670, 0.1062, 0.0528, 0.0294, 0.0309, 0.0382, 0.0666,
        0.0201], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,105][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0435, 0.0832, 0.0994, 0.0507, 0.1626, 0.1002, 0.0603, 0.1846, 0.0555,
        0.1600], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,107][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.1643, 0.0933, 0.1603, 0.0708, 0.1198, 0.0906, 0.0773, 0.0862, 0.0492,
        0.0882], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,107][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.7852, 0.0247, 0.0117, 0.0151, 0.0124, 0.0209, 0.0160, 0.0322, 0.0557,
        0.0261], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,107][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([9.9411e-01, 1.3994e-03, 1.1997e-04, 4.8718e-04, 7.2216e-05, 6.5262e-04,
        1.6658e-04, 1.1450e-03, 1.6890e-03, 1.6022e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,108][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.3100, 0.0209, 0.0248, 0.0776, 0.0522, 0.1295, 0.1140, 0.0808, 0.1139,
        0.0764], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,108][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.4785, 0.0089, 0.0053, 0.0447, 0.0097, 0.0876, 0.0961, 0.0789, 0.1172,
        0.0732], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,108][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.7073, 0.0646, 0.0647, 0.0212, 0.0243, 0.0157, 0.0087, 0.0374, 0.0259,
        0.0085, 0.0217], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,109][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([9.9944e-01, 6.7967e-05, 1.5052e-07, 4.1528e-05, 5.7062e-06, 9.7827e-06,
        2.8509e-06, 3.0649e-06, 4.0110e-04, 2.1698e-06, 2.7449e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,109][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0061, 0.0270, 0.0901, 0.0976, 0.1395, 0.1955, 0.0540, 0.2189, 0.0553,
        0.1098, 0.0063], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,113][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0223, 0.0569, 0.0786, 0.0600, 0.1076, 0.0811, 0.1201, 0.1520, 0.0862,
        0.1600, 0.0752], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,113][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.4732, 0.0070, 0.0173, 0.0352, 0.0325, 0.0229, 0.0254, 0.0963, 0.0345,
        0.2204, 0.0353], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,114][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.4293, 0.1773, 0.0509, 0.0872, 0.0327, 0.0496, 0.0323, 0.0466, 0.0536,
        0.0292, 0.0113], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,114][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0465, 0.0832, 0.0972, 0.0591, 0.1343, 0.0993, 0.0629, 0.1786, 0.0541,
        0.1319, 0.0530], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,114][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1516, 0.0775, 0.1813, 0.0574, 0.1294, 0.0751, 0.0681, 0.0729, 0.0391,
        0.0818, 0.0658], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,115][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.7796, 0.0220, 0.0105, 0.0135, 0.0110, 0.0184, 0.0145, 0.0298, 0.0510,
        0.0240, 0.0257], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,115][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([9.9163e-01, 1.9071e-03, 1.7665e-04, 6.8051e-04, 1.0423e-04, 9.1362e-04,
        2.5424e-04, 1.5821e-03, 2.1466e-03, 2.4116e-04, 3.5885e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,115][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.4446, 0.0092, 0.0148, 0.0574, 0.0355, 0.1029, 0.0813, 0.0425, 0.0716,
        0.0484, 0.0917], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,119][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.4792, 0.0046, 0.0038, 0.0304, 0.0064, 0.0661, 0.0801, 0.0650, 0.1028,
        0.0605, 0.1011], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,120][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7762, 0.0189, 0.0711, 0.0085, 0.0414, 0.0101, 0.0051, 0.0274, 0.0087,
        0.0077, 0.0203, 0.0044], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,120][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.9958e-01, 4.8558e-05, 9.5306e-08, 3.1009e-05, 3.9248e-06, 7.1048e-06,
        2.1678e-06, 2.1146e-06, 3.0392e-04, 1.4623e-06, 1.9880e-05, 1.5265e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,120][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0052, 0.0117, 0.0729, 0.0998, 0.1028, 0.2350, 0.0188, 0.2285, 0.0792,
        0.1012, 0.0417, 0.0031], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,121][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0227, 0.0535, 0.0612, 0.0557, 0.0907, 0.0645, 0.0984, 0.1321, 0.0755,
        0.1602, 0.0972, 0.0881], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,121][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4311, 0.0051, 0.0154, 0.0319, 0.0330, 0.0197, 0.0221, 0.0976, 0.0318,
        0.2388, 0.0339, 0.0397], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,121][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.4257, 0.1847, 0.0374, 0.0998, 0.0271, 0.0529, 0.0225, 0.0400, 0.0377,
        0.0350, 0.0209, 0.0163], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,122][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0435, 0.0768, 0.0905, 0.0579, 0.1273, 0.0963, 0.0607, 0.1517, 0.0592,
        0.1251, 0.0572, 0.0538], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,125][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1035, 0.0724, 0.1597, 0.0596, 0.1246, 0.0744, 0.0648, 0.0725, 0.0411,
        0.0871, 0.0620, 0.0784], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,126][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.7876, 0.0177, 0.0083, 0.0108, 0.0089, 0.0157, 0.0122, 0.0254, 0.0468,
        0.0218, 0.0239, 0.0210], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,126][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.9314e-01, 1.3864e-03, 1.2006e-04, 5.0727e-04, 7.2931e-05, 7.2636e-04,
        1.9662e-04, 1.2357e-03, 1.8883e-03, 2.0036e-04, 3.0431e-04, 2.2129e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,127][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2804, 0.0145, 0.0171, 0.0579, 0.0372, 0.1088, 0.0846, 0.0491, 0.0780,
        0.0568, 0.1071, 0.1085], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,127][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.4050, 0.0022, 0.0028, 0.0199, 0.0056, 0.0517, 0.0700, 0.0525, 0.0844,
        0.0633, 0.1011, 0.1417], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,127][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.7628, 0.0520, 0.0435, 0.0249, 0.0150, 0.0101, 0.0043, 0.0237, 0.0291,
        0.0049, 0.0183, 0.0072, 0.0041], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,128][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([9.9967e-01, 2.7155e-05, 5.1929e-08, 1.5867e-05, 2.5628e-06, 4.5646e-06,
        1.2206e-06, 1.4124e-06, 2.4429e-04, 8.3314e-07, 1.3035e-05, 7.6157e-07,
        1.7840e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,128][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0039, 0.0112, 0.0426, 0.0700, 0.1184, 0.1416, 0.0821, 0.2696, 0.0956,
        0.0792, 0.0255, 0.0350, 0.0256], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,132][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.0131, 0.0465, 0.0627, 0.0491, 0.0950, 0.0665, 0.0956, 0.1201, 0.0667,
        0.1544, 0.0803, 0.0942, 0.0557], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,132][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1788, 0.0151, 0.0171, 0.0520, 0.0296, 0.0383, 0.0411, 0.1017, 0.0491,
        0.2108, 0.0499, 0.0610, 0.1555], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,133][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.3178, 0.1804, 0.0294, 0.0784, 0.0200, 0.0447, 0.0483, 0.0565, 0.0662,
        0.0527, 0.0423, 0.0528, 0.0106], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,133][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0325, 0.0618, 0.0786, 0.0416, 0.1231, 0.0896, 0.0482, 0.1532, 0.0438,
        0.1249, 0.0440, 0.0452, 0.1133], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,133][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.1424, 0.0660, 0.1615, 0.0461, 0.1130, 0.0621, 0.0542, 0.0611, 0.0308,
        0.0692, 0.0557, 0.0683, 0.0695], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,134][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.7242, 0.0229, 0.0114, 0.0143, 0.0114, 0.0189, 0.0144, 0.0284, 0.0484,
        0.0229, 0.0257, 0.0223, 0.0348], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,134][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([9.9003e-01, 2.0396e-03, 2.0336e-04, 7.2039e-04, 1.1199e-04, 9.2741e-04,
        2.5363e-04, 1.6073e-03, 2.3261e-03, 2.4384e-04, 4.0168e-04, 2.8674e-04,
        8.4297e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,134][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.2497, 0.0121, 0.0132, 0.0708, 0.0315, 0.1090, 0.0904, 0.0470, 0.0784,
        0.0467, 0.1029, 0.1102, 0.0380], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,138][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.3684, 0.0020, 0.0023, 0.0186, 0.0041, 0.0416, 0.0614, 0.0483, 0.0838,
        0.0595, 0.0907, 0.1373, 0.0822], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,139][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.1657e-01, 5.5354e-04, 4.4026e-02, 1.2308e-04, 1.9955e-02, 1.5605e-03,
        4.5987e-04, 5.5235e-03, 1.8612e-04, 3.2713e-03, 4.2907e-03, 2.9599e-04,
        3.1689e-03, 1.5453e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,139][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([9.9782e-01, 3.0513e-04, 1.8066e-06, 2.0230e-04, 3.5670e-05, 6.2472e-05,
        2.1344e-05, 1.9422e-05, 1.1013e-03, 1.3374e-05, 1.2720e-04, 1.5273e-05,
        1.2349e-04, 1.4957e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,139][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0023, 0.0037, 0.0457, 0.0303, 0.1127, 0.1492, 0.0486, 0.3088, 0.0227,
        0.1447, 0.0241, 0.0113, 0.0928, 0.0031], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,140][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0176, 0.0472, 0.0598, 0.0448, 0.0817, 0.0645, 0.0830, 0.1083, 0.0673,
        0.1415, 0.0790, 0.0844, 0.0763, 0.0445], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,140][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3767, 0.0046, 0.0136, 0.0260, 0.0243, 0.0174, 0.0187, 0.0832, 0.0253,
        0.1799, 0.0277, 0.0327, 0.1152, 0.0546], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,140][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.4454, 0.1316, 0.0249, 0.0732, 0.0229, 0.0407, 0.0259, 0.0329, 0.0463,
        0.0193, 0.0282, 0.0306, 0.0289, 0.0494], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,141][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0333, 0.0640, 0.0721, 0.0465, 0.1024, 0.0736, 0.0522, 0.1167, 0.0496,
        0.0985, 0.0473, 0.0464, 0.1074, 0.0900], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,144][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1033, 0.0686, 0.1333, 0.0547, 0.1007, 0.0679, 0.0586, 0.0643, 0.0378,
        0.0723, 0.0548, 0.0659, 0.0715, 0.0462], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,145][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.7574, 0.0157, 0.0072, 0.0097, 0.0078, 0.0143, 0.0107, 0.0231, 0.0432,
        0.0200, 0.0215, 0.0190, 0.0294, 0.0209], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,145][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([9.9356e-01, 1.1614e-03, 1.0031e-04, 4.2105e-04, 5.9445e-05, 6.2212e-04,
        1.6720e-04, 9.9757e-04, 1.6100e-03, 1.6858e-04, 2.5185e-04, 1.8010e-04,
        6.1097e-04, 8.8517e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,146][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.2050, 0.0109, 0.0099, 0.0325, 0.0235, 0.0602, 0.0609, 0.0470, 0.0693,
        0.0487, 0.0864, 0.1011, 0.0492, 0.1953], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,146][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.4406, 0.0032, 0.0021, 0.0142, 0.0034, 0.0262, 0.0366, 0.0309, 0.0507,
        0.0349, 0.0502, 0.0765, 0.0511, 0.1796], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,146][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.5619, 0.0435, 0.0752, 0.0518, 0.0774, 0.0210, 0.0194, 0.0269, 0.0219,
        0.0085, 0.0257, 0.0150, 0.0069, 0.0049, 0.0402], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,147][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9977e-01, 1.8674e-05, 1.8554e-08, 9.7765e-06, 1.3660e-06, 2.1984e-06,
        6.7346e-07, 6.2236e-07, 1.6922e-04, 4.4518e-07, 7.1800e-06, 4.0921e-07,
        9.2039e-06, 6.9275e-06, 3.8661e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,147][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0051, 0.0164, 0.0537, 0.0913, 0.0211, 0.1659, 0.0717, 0.2327, 0.0983,
        0.1078, 0.0189, 0.0275, 0.0647, 0.0122, 0.0125], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,151][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0096, 0.0338, 0.0465, 0.0347, 0.0586, 0.0576, 0.0838, 0.1216, 0.0565,
        0.1402, 0.0781, 0.0782, 0.0630, 0.0343, 0.1036], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,151][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.2935, 0.0071, 0.0093, 0.0410, 0.0151, 0.0228, 0.0287, 0.0763, 0.0439,
        0.1510, 0.0393, 0.0458, 0.1215, 0.0856, 0.0191], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,151][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.2020, 0.1291, 0.0921, 0.0858, 0.0088, 0.0476, 0.0443, 0.0720, 0.0506,
        0.0549, 0.0408, 0.0435, 0.0490, 0.0675, 0.0121], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,152][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0275, 0.0601, 0.0618, 0.0403, 0.0956, 0.0834, 0.0424, 0.1209, 0.0386,
        0.1108, 0.0412, 0.0363, 0.0928, 0.0718, 0.0767], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,152][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0778, 0.0581, 0.1057, 0.0530, 0.0898, 0.0687, 0.0562, 0.0639, 0.0393,
        0.0749, 0.0528, 0.0635, 0.0692, 0.0484, 0.0787], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,153][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.6881, 0.0212, 0.0100, 0.0131, 0.0104, 0.0185, 0.0135, 0.0271, 0.0470,
        0.0231, 0.0247, 0.0209, 0.0334, 0.0239, 0.0251], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,153][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([9.9408e-01, 1.2444e-03, 1.0972e-04, 3.9375e-04, 5.6720e-05, 5.0667e-04,
        1.3058e-04, 8.8607e-04, 1.4190e-03, 1.2893e-04, 2.2575e-04, 1.4879e-04,
        5.3636e-04, 7.7552e-05, 5.2921e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,155][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.1559, 0.0101, 0.0146, 0.0701, 0.0365, 0.1092, 0.0724, 0.0268, 0.0589,
        0.0358, 0.0835, 0.0780, 0.0305, 0.1498, 0.0679], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,157][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.2891, 0.0017, 0.0018, 0.0168, 0.0029, 0.0428, 0.0409, 0.0303, 0.0530,
        0.0378, 0.0662, 0.0797, 0.0500, 0.2457, 0.0413], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,157][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.8246, 0.0218, 0.0425, 0.0087, 0.0214, 0.0087, 0.0034, 0.0205, 0.0070,
        0.0034, 0.0131, 0.0052, 0.0041, 0.0010, 0.0122, 0.0023],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,158][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.9953e-01, 4.4543e-05, 7.6157e-08, 2.5867e-05, 3.2546e-06, 6.8842e-06,
        1.9716e-06, 2.1171e-06, 3.2135e-04, 1.3410e-06, 1.9058e-05, 1.2051e-06,
        2.2769e-05, 1.6391e-05, 1.1904e-07, 2.4948e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,158][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0047, 0.0226, 0.0536, 0.1036, 0.0840, 0.1153, 0.0342, 0.1920, 0.0611,
        0.0996, 0.0267, 0.0297, 0.0621, 0.0237, 0.0624, 0.0246],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,159][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0130, 0.0364, 0.0395, 0.0365, 0.0691, 0.0460, 0.0734, 0.1135, 0.0544,
        0.1253, 0.0627, 0.0768, 0.0589, 0.0375, 0.1124, 0.0449],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,159][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1764, 0.0078, 0.0155, 0.0350, 0.0345, 0.0254, 0.0271, 0.0785, 0.0359,
        0.1868, 0.0390, 0.0400, 0.1298, 0.0673, 0.0513, 0.0496],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,159][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.2327, 0.1741, 0.0384, 0.0792, 0.0370, 0.0185, 0.0305, 0.0256, 0.0448,
        0.0335, 0.0305, 0.0556, 0.0384, 0.1038, 0.0494, 0.0079],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,163][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0276, 0.0516, 0.0630, 0.0346, 0.0939, 0.0691, 0.0385, 0.1114, 0.0341,
        0.0926, 0.0362, 0.0350, 0.0998, 0.0659, 0.0779, 0.0688],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,164][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1175, 0.0546, 0.1361, 0.0386, 0.0940, 0.0518, 0.0466, 0.0506, 0.0259,
        0.0564, 0.0462, 0.0567, 0.0586, 0.0330, 0.0879, 0.0456],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,164][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.6376, 0.0229, 0.0116, 0.0144, 0.0117, 0.0189, 0.0147, 0.0285, 0.0465,
        0.0230, 0.0245, 0.0219, 0.0333, 0.0232, 0.0266, 0.0405],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,164][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([9.8715e-01, 2.3612e-03, 2.6341e-04, 8.2795e-04, 1.5264e-04, 1.0438e-03,
        2.9129e-04, 1.7656e-03, 2.6800e-03, 3.0270e-04, 5.2159e-04, 3.3460e-04,
        1.1012e-03, 1.9055e-04, 1.4494e-04, 8.7071e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,165][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2339, 0.0068, 0.0080, 0.0379, 0.0228, 0.0689, 0.0553, 0.0278, 0.0519,
        0.0343, 0.0631, 0.0686, 0.0283, 0.1554, 0.0506, 0.0864],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,165][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3592, 0.0014, 0.0012, 0.0102, 0.0024, 0.0211, 0.0293, 0.0248, 0.0415,
        0.0306, 0.0435, 0.0617, 0.0427, 0.1655, 0.0278, 0.1373],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,166][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.9020e-01, 1.4088e-02, 9.0142e-02, 9.8575e-03, 7.6184e-02, 1.2726e-02,
        4.8274e-03, 2.2515e-02, 4.5773e-03, 8.3498e-03, 1.3247e-02, 3.8386e-03,
        6.1232e-03, 5.9345e-04, 3.4595e-02, 5.0344e-03, 3.1029e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,167][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9901e-01, 1.2058e-04, 3.1565e-07, 6.9656e-05, 9.6452e-06, 1.9114e-05,
        5.6400e-06, 5.7190e-06, 5.7606e-04, 4.0587e-06, 4.6504e-05, 3.9631e-06,
        4.8664e-05, 4.8097e-05, 4.6029e-07, 6.7082e-06, 2.2109e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,170][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0075, 0.0132, 0.0439, 0.1192, 0.0613, 0.1538, 0.0044, 0.1929, 0.0723,
        0.0791, 0.0317, 0.0116, 0.0753, 0.0096, 0.0344, 0.0882, 0.0016],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,170][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0148, 0.0371, 0.0443, 0.0386, 0.0655, 0.0421, 0.0522, 0.0843, 0.0506,
        0.1136, 0.0596, 0.0702, 0.0595, 0.0377, 0.1094, 0.0650, 0.0556],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,170][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2512, 0.0051, 0.0146, 0.0250, 0.0308, 0.0174, 0.0165, 0.0723, 0.0236,
        0.1780, 0.0259, 0.0291, 0.1283, 0.0538, 0.0419, 0.0488, 0.0377],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,171][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3170, 0.1521, 0.0486, 0.0705, 0.0387, 0.0424, 0.0078, 0.0187, 0.0332,
        0.0227, 0.0169, 0.0292, 0.0376, 0.0852, 0.0440, 0.0234, 0.0121],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,171][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0279, 0.0534, 0.0607, 0.0386, 0.0821, 0.0630, 0.0401, 0.1076, 0.0379,
        0.0859, 0.0380, 0.0364, 0.0880, 0.0645, 0.0665, 0.0716, 0.0378],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,172][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0777, 0.0489, 0.1373, 0.0373, 0.1015, 0.0484, 0.0428, 0.0491, 0.0245,
        0.0627, 0.0428, 0.0552, 0.0571, 0.0332, 0.0942, 0.0415, 0.0458],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,172][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6678, 0.0183, 0.0089, 0.0112, 0.0092, 0.0154, 0.0113, 0.0235, 0.0394,
        0.0198, 0.0203, 0.0177, 0.0280, 0.0189, 0.0215, 0.0343, 0.0347],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,173][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.8546e-01, 2.5628e-03, 2.9361e-04, 8.8339e-04, 1.6385e-04, 1.0959e-03,
        3.2690e-04, 1.7989e-03, 2.5901e-03, 3.3799e-04, 5.0827e-04, 3.4407e-04,
        1.0965e-03, 1.9453e-04, 1.5467e-04, 9.3519e-04, 1.2528e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,176][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1832, 0.0090, 0.0112, 0.0582, 0.0259, 0.0803, 0.0601, 0.0233, 0.0458,
        0.0288, 0.0629, 0.0555, 0.0229, 0.1147, 0.0362, 0.0644, 0.1175],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,176][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3603, 0.0006, 0.0009, 0.0065, 0.0015, 0.0174, 0.0242, 0.0201, 0.0291,
        0.0227, 0.0339, 0.0470, 0.0367, 0.1201, 0.0198, 0.1149, 0.1445],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,177][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.5335, 0.0497, 0.0763, 0.0282, 0.0505, 0.0235, 0.0112, 0.0453, 0.0243,
        0.0199, 0.0304, 0.0243, 0.0093, 0.0064, 0.0331, 0.0179, 0.0123, 0.0038],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,177][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([9.9874e-01, 1.1613e-04, 4.6928e-07, 7.4403e-05, 1.5447e-05, 2.3202e-05,
        7.5783e-06, 7.6575e-06, 6.6601e-04, 5.4572e-06, 6.1567e-05, 5.2931e-06,
        7.1370e-05, 5.9399e-05, 7.5931e-07, 9.7409e-06, 3.2502e-05, 9.8962e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,178][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0029, 0.0073, 0.0591, 0.0390, 0.1118, 0.1256, 0.0257, 0.1774, 0.0415,
        0.1029, 0.0230, 0.0122, 0.0600, 0.0061, 0.0670, 0.1137, 0.0130, 0.0117],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,178][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0060, 0.0283, 0.0424, 0.0299, 0.0591, 0.0493, 0.0661, 0.0925, 0.0421,
        0.1109, 0.0532, 0.0585, 0.0428, 0.0272, 0.1050, 0.0706, 0.0653, 0.0508],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,178][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1278, 0.0081, 0.0100, 0.0337, 0.0192, 0.0237, 0.0293, 0.0736, 0.0397,
        0.1395, 0.0363, 0.0457, 0.1032, 0.0696, 0.0252, 0.0504, 0.0662, 0.0990],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,182][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.2110, 0.1719, 0.0240, 0.0764, 0.0280, 0.0360, 0.0297, 0.0372, 0.0432,
        0.0346, 0.0325, 0.0298, 0.0175, 0.0839, 0.0342, 0.0587, 0.0446, 0.0069],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,183][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0238, 0.0468, 0.0572, 0.0304, 0.0851, 0.0648, 0.0309, 0.1041, 0.0291,
        0.0853, 0.0297, 0.0286, 0.0840, 0.0532, 0.0691, 0.0738, 0.0296, 0.0743],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,183][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0672, 0.0498, 0.1070, 0.0412, 0.0848, 0.0535, 0.0439, 0.0524, 0.0281,
        0.0628, 0.0423, 0.0510, 0.0569, 0.0355, 0.0745, 0.0430, 0.0431, 0.0630],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,184][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.6516, 0.0174, 0.0083, 0.0107, 0.0086, 0.0151, 0.0108, 0.0224, 0.0390,
        0.0193, 0.0198, 0.0171, 0.0275, 0.0179, 0.0208, 0.0330, 0.0329, 0.0280],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,184][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([9.9064e-01, 1.6924e-03, 1.7077e-04, 5.6786e-04, 8.8796e-05, 6.7491e-04,
        1.8767e-04, 1.0769e-03, 1.7584e-03, 1.8857e-04, 2.9934e-04, 2.0302e-04,
        6.8806e-04, 1.0601e-04, 7.5823e-05, 5.3538e-04, 7.7077e-04, 2.7895e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,184][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1346, 0.0107, 0.0079, 0.0388, 0.0205, 0.0566, 0.0475, 0.0245, 0.0416,
        0.0287, 0.0610, 0.0625, 0.0240, 0.1261, 0.0449, 0.0679, 0.1605, 0.0416],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,185][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.2633, 0.0009, 0.0008, 0.0070, 0.0017, 0.0151, 0.0219, 0.0183, 0.0312,
        0.0240, 0.0346, 0.0546, 0.0320, 0.1239, 0.0209, 0.1133, 0.1600, 0.0764],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,186][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.0426e-01, 5.3826e-04, 2.9322e-02, 6.4134e-04, 3.7728e-02, 1.4582e-03,
        1.1694e-03, 2.8079e-03, 2.1489e-04, 2.1166e-03, 2.9203e-03, 4.8849e-04,
        1.6130e-03, 2.0543e-05, 1.2741e-02, 4.6558e-04, 8.9970e-04, 4.9683e-04,
        9.8977e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,189][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.4547e-01, 3.7577e-03, 6.0203e-05, 2.4570e-03, 6.1265e-04, 1.0196e-03,
        4.5332e-04, 3.9985e-04, 8.6459e-03, 4.1283e-04, 1.8805e-03, 3.4896e-04,
        1.5499e-03, 2.0726e-03, 7.6119e-05, 4.7261e-04, 1.0833e-03, 2.2799e-03,
        2.6944e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,189][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0027, 0.0069, 0.0154, 0.0372, 0.1386, 0.1162, 0.0250, 0.1775, 0.0234,
        0.1244, 0.0115, 0.0113, 0.0828, 0.0046, 0.0925, 0.0900, 0.0136, 0.0256,
        0.0010], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,190][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0149, 0.0354, 0.0381, 0.0345, 0.0509, 0.0397, 0.0591, 0.0770, 0.0492,
        0.0932, 0.0515, 0.0577, 0.0530, 0.0352, 0.0804, 0.0690, 0.0636, 0.0701,
        0.0274], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,190][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1534, 0.0053, 0.0136, 0.0270, 0.0254, 0.0179, 0.0202, 0.0672, 0.0246,
        0.1526, 0.0314, 0.0341, 0.1031, 0.0572, 0.0340, 0.0487, 0.0426, 0.0838,
        0.0580], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,190][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3792, 0.1142, 0.0356, 0.0666, 0.0182, 0.0387, 0.0172, 0.0323, 0.0428,
        0.0161, 0.0189, 0.0243, 0.0293, 0.0401, 0.0194, 0.0319, 0.0240, 0.0292,
        0.0221], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,191][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0279, 0.0463, 0.0513, 0.0385, 0.0687, 0.0555, 0.0401, 0.0906, 0.0345,
        0.0789, 0.0353, 0.0358, 0.0812, 0.0624, 0.0542, 0.0602, 0.0384, 0.0732,
        0.0272], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,191][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0692, 0.0468, 0.1213, 0.0357, 0.0902, 0.0461, 0.0397, 0.0465, 0.0233,
        0.0582, 0.0390, 0.0491, 0.0528, 0.0307, 0.0809, 0.0382, 0.0403, 0.0623,
        0.0296], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,195][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4876, 0.0224, 0.0130, 0.0153, 0.0129, 0.0195, 0.0150, 0.0280, 0.0421,
        0.0247, 0.0239, 0.0215, 0.0317, 0.0210, 0.0254, 0.0365, 0.0360, 0.0312,
        0.0924], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,195][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.2080e-01, 9.7377e-03, 2.0421e-03, 4.1925e-03, 1.0747e-03, 4.5887e-03,
        1.8781e-03, 6.4012e-03, 8.1329e-03, 1.7166e-03, 2.2737e-03, 1.7459e-03,
        4.2004e-03, 1.0141e-03, 9.1329e-04, 3.7449e-03, 4.4227e-03, 2.0438e-03,
        1.9077e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,196][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1704, 0.0092, 0.0095, 0.0353, 0.0239, 0.0601, 0.0472, 0.0175, 0.0378,
        0.0268, 0.0480, 0.0467, 0.0203, 0.0933, 0.0353, 0.0583, 0.0948, 0.0301,
        0.1353], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,196][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3192, 0.0005, 0.0008, 0.0054, 0.0013, 0.0129, 0.0186, 0.0141, 0.0227,
        0.0179, 0.0262, 0.0363, 0.0263, 0.0866, 0.0150, 0.0837, 0.1040, 0.0699,
        0.1384], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,197][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:50,198][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13397],
        [ 9532],
        [    9],
        [ 9878],
        [16579],
        [11472],
        [19067],
        [16367],
        [ 9702],
        [25531],
        [18032],
        [21477],
        [25115],
        [10209],
        [17618],
        [13728],
        [21011],
        [15078],
        [10600]], device='cuda:0')
[2024-07-24 10:19:50,201][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12064],
        [ 6244],
        [    2],
        [ 5834],
        [18885],
        [ 4876],
        [14362],
        [ 9927],
        [ 3253],
        [14747],
        [ 9104],
        [13160],
        [21239],
        [ 4154],
        [21575],
        [ 5128],
        [14514],
        [16028],
        [ 5042]], device='cuda:0')
[2024-07-24 10:19:50,203][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[6137],
        [6137],
        [4757],
        [5242],
        [1679],
        [1995],
        [2994],
        [2566],
        [5725],
        [2681],
        [2561],
        [2688],
        [3058],
        [3527],
        [2678],
        [2931],
        [2579],
        [2654],
        [3730]], device='cuda:0')
[2024-07-24 10:19:50,204][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[7746],
        [7752],
        [7747],
        [7762],
        [7748],
        [7751],
        [7748],
        [7748],
        [7873],
        [7754],
        [7767],
        [7768],
        [7760],
        [7844],
        [7757],
        [7761],
        [7783],
        [7785],
        [8715]], device='cuda:0')
[2024-07-24 10:19:50,205][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9278],
        [ 5226],
        [ 6753],
        [10356],
        [13401],
        [19563],
        [19150],
        [19419],
        [13139],
        [12024],
        [15126],
        [14313],
        [12279],
        [16131],
        [11157],
        [14222],
        [13219],
        [16580],
        [18730]], device='cuda:0')
[2024-07-24 10:19:50,207][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 2068],
        [ 2989],
        [15411],
        [ 6226],
        [ 5397],
        [ 8011],
        [ 6341],
        [21132],
        [10720],
        [11574],
        [ 3272],
        [ 5656],
        [ 9354],
        [ 9948],
        [ 3849],
        [ 4232],
        [ 5029],
        [19673],
        [ 7164]], device='cuda:0')
[2024-07-24 10:19:50,210][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7934],
        [12197],
        [12967],
        [14490],
        [14750],
        [15387],
        [15842],
        [14373],
        [10561],
        [14991],
        [16415],
        [17473],
        [19939],
        [18151],
        [19128],
        [19677],
        [17860],
        [18867],
        [18905]], device='cuda:0')
[2024-07-24 10:19:50,211][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 7095],
        [ 7087],
        [ 7415],
        [ 7588],
        [11160],
        [ 8967],
        [ 7634],
        [13494],
        [ 8289],
        [15586],
        [ 8266],
        [ 7989],
        [14796],
        [ 8977],
        [13622],
        [13705],
        [ 8806],
        [15493],
        [ 8368]], device='cuda:0')
[2024-07-24 10:19:50,212][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[47132],
        [48146],
        [40926],
        [42108],
        [43123],
        [42701],
        [42828],
        [43082],
        [42705],
        [43238],
        [41848],
        [41214],
        [40909],
        [41330],
        [40859],
        [40541],
        [40446],
        [40876],
        [40362]], device='cuda:0')
[2024-07-24 10:19:50,213][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39336],
        [41882],
        [42071],
        [37321],
        [38359],
        [37417],
        [35256],
        [36685],
        [32661],
        [34044],
        [32830],
        [33589],
        [33311],
        [34747],
        [33102],
        [33631],
        [33284],
        [34827],
        [32851]], device='cuda:0')
[2024-07-24 10:19:50,215][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[47965],
        [47952],
        [47864],
        [47873],
        [47703],
        [47170],
        [47840],
        [44768],
        [47828],
        [47033],
        [47840],
        [47908],
        [47616],
        [47864],
        [47894],
        [47883],
        [47896],
        [47755],
        [47888]], device='cuda:0')
[2024-07-24 10:19:50,217][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31573],
        [32970],
        [29760],
        [30127],
        [30329],
        [30476],
        [30971],
        [30884],
        [30461],
        [29770],
        [28954],
        [29305],
        [29512],
        [28852],
        [28769],
        [29369],
        [29186],
        [29009],
        [29546]], device='cuda:0')
[2024-07-24 10:19:50,218][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13338],
        [14047],
        [16373],
        [17353],
        [16530],
        [19594],
        [19362],
        [20190],
        [18368],
        [18842],
        [19391],
        [17021],
        [18946],
        [15740],
        [12792],
        [17279],
        [12882],
        [12391],
        [12361]], device='cuda:0')
[2024-07-24 10:19:50,219][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23211],
        [23243],
        [27238],
        [27211],
        [28917],
        [28545],
        [28123],
        [27744],
        [27283],
        [28016],
        [27984],
        [27921],
        [28515],
        [28710],
        [29515],
        [29815],
        [29723],
        [30629],
        [30586]], device='cuda:0')
[2024-07-24 10:19:50,221][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13040],
        [34805],
        [31502],
        [32306],
        [21889],
        [41087],
        [33919],
        [40665],
        [46677],
        [40913],
        [48947],
        [46912],
        [43459],
        [43417],
        [28426],
        [49055],
        [44050],
        [19798],
        [46859]], device='cuda:0')
[2024-07-24 10:19:50,224][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[31401],
        [31419],
        [38182],
        [28148],
        [10090],
        [36922],
        [20986],
        [36680],
        [33026],
        [36772],
        [36556],
        [35098],
        [36075],
        [32780],
        [24224],
        [34261],
        [31470],
        [18007],
        [32668]], device='cuda:0')
[2024-07-24 10:19:50,227][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[24382],
        [24622],
        [24382],
        [24452],
        [24385],
        [24387],
        [24384],
        [24384],
        [24693],
        [24408],
        [24427],
        [24414],
        [24408],
        [24556],
        [24402],
        [24423],
        [24465],
        [24498],
        [28159]], device='cuda:0')
[2024-07-24 10:19:50,228][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33495],
        [43282],
        [39034],
        [35889],
        [44444],
        [44958],
        [46401],
        [44325],
        [43960],
        [45402],
        [44846],
        [45574],
        [44954],
        [45117],
        [45220],
        [44899],
        [45588],
        [44640],
        [44633]], device='cuda:0')
[2024-07-24 10:19:50,229][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24000],
        [26381],
        [28831],
        [28317],
        [27080],
        [27563],
        [24657],
        [22959],
        [22539],
        [21201],
        [20736],
        [19789],
        [20122],
        [20375],
        [20029],
        [20425],
        [20120],
        [19676],
        [19549]], device='cuda:0')
[2024-07-24 10:19:50,230][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19219],
        [19328],
        [19237],
        [19486],
        [19897],
        [19869],
        [19844],
        [20816],
        [20946],
        [19870],
        [20628],
        [20696],
        [21451],
        [21645],
        [22309],
        [21450],
        [21349],
        [22322],
        [21810]], device='cuda:0')
[2024-07-24 10:19:50,232][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6871],
        [7520],
        [8535],
        [7523],
        [7146],
        [7379],
        [7453],
        [7573],
        [7230],
        [7442],
        [7484],
        [7466],
        [7567],
        [7338],
        [7761],
        [7395],
        [7346],
        [7424],
        [7291]], device='cuda:0')
[2024-07-24 10:19:50,234][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[6029],
        [5318],
        [4030],
        [4227],
        [4254],
        [4844],
        [5038],
        [5283],
        [5307],
        [5493],
        [5519],
        [5657],
        [5553],
        [5531],
        [5510],
        [5590],
        [5652],
        [5621],
        [5631]], device='cuda:0')
[2024-07-24 10:19:50,236][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[7517],
        [8522],
        [9706],
        [9755],
        [9537],
        [9393],
        [9325],
        [9242],
        [9205],
        [9091],
        [9096],
        [9024],
        [9016],
        [9003],
        [9010],
        [9063],
        [9077],
        [9010],
        [8987]], device='cuda:0')
[2024-07-24 10:19:50,237][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11726],
        [11700],
        [11698],
        [11671],
        [11662],
        [11629],
        [11668],
        [11611],
        [11622],
        [11637],
        [11640],
        [11681],
        [11647],
        [11714],
        [11682],
        [11679],
        [11767],
        [11815],
        [11828]], device='cuda:0')
[2024-07-24 10:19:50,238][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32582],
        [32551],
        [32580],
        [32582],
        [32581],
        [32585],
        [32585],
        [32595],
        [32583],
        [32585],
        [32590],
        [32587],
        [32591],
        [32585],
        [32585],
        [32593],
        [32594],
        [32596],
        [32601]], device='cuda:0')
[2024-07-24 10:19:50,240][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[37916],
        [38724],
        [38748],
        [39741],
        [41289],
        [40318],
        [36668],
        [30936],
        [31709],
        [28064],
        [30098],
        [26846],
        [26933],
        [25681],
        [25358],
        [24519],
        [26270],
        [25166],
        [24412]], device='cuda:0')
[2024-07-24 10:19:50,243][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 1302],
        [11243],
        [ 8870],
        [ 2684],
        [ 2668],
        [ 2005],
        [ 1565],
        [ 1422],
        [ 1324],
        [ 1202],
        [ 1168],
        [ 1183],
        [ 1223],
        [ 2216],
        [ 2036],
        [ 2194],
        [ 2387],
        [ 2277],
        [ 2271]], device='cuda:0')
[2024-07-24 10:19:50,244][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22083],
        [17607],
        [17327],
        [20492],
        [21337],
        [18115],
        [21282],
        [19850],
        [20400],
        [20272],
        [20304],
        [20888],
        [20554],
        [20787],
        [22099],
        [20376],
        [21007],
        [23306],
        [20735]], device='cuda:0')
[2024-07-24 10:19:50,245][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[43997],
        [40834],
        [45146],
        [36414],
        [40655],
        [31290],
        [30231],
        [27602],
        [22966],
        [29654],
        [25554],
        [23344],
        [26370],
        [23564],
        [30920],
        [25268],
        [26093],
        [34965],
        [22346]], device='cuda:0')
[2024-07-24 10:19:50,247][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070],
        [44070]], device='cuda:0')
[2024-07-24 10:19:50,264][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:50,265][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,266][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,269][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,269][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,269][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,270][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,270][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,270][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,271][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,271][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,271][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,273][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,276][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5660, 0.4340], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,276][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5145, 0.4855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,276][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6946, 0.3054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,277][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([5.5880e-04, 9.9944e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,277][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3669, 0.6331], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,277][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9173, 0.0827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,278][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9245, 0.0755], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,278][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([3.3161e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,278][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9835, 0.0165], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,287][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0773, 0.9227], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,289][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4413, 0.5587], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,289][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3840, 0.6160], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,289][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.4184, 0.3084, 0.2732], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,290][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.4571, 0.4709, 0.0719], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,290][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.4855, 0.2252, 0.2893], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,290][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([2.1869e-04, 6.9875e-01, 3.0103e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,291][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.2376, 0.3378, 0.4246], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,291][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.3841, 0.4956, 0.1203], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,292][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([9.0739e-01, 5.9419e-04, 9.2016e-02], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,295][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([1.3808e-07, 5.5713e-01, 4.4287e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,295][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.4638, 0.5307, 0.0055], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,295][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0138, 0.9697, 0.0164], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,296][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.3114, 0.3344, 0.3542], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,296][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.2497, 0.3729, 0.3773], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,296][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3930, 0.2314, 0.1935, 0.1822], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,296][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3577, 0.4594, 0.0775, 0.1054], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,297][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3983, 0.1840, 0.2294, 0.1883], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,297][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([3.9779e-04, 9.9057e-01, 5.2841e-04, 8.4995e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,299][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1684, 0.2367, 0.2870, 0.3079], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,301][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5732, 0.0973, 0.2868, 0.0426], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,301][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.4095e-01, 1.0084e-04, 3.9632e-02, 1.9319e-02], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,302][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([4.2678e-08, 7.7405e-03, 2.0054e-02, 9.7221e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,302][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6165, 0.0617, 0.2608, 0.0610], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,302][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0422, 0.8937, 0.0277, 0.0363], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,302][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2484, 0.2490, 0.2587, 0.2439], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,303][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1520, 0.2713, 0.3390, 0.2377], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,303][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.3087, 0.1985, 0.1709, 0.1619, 0.1600], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,303][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.3805, 0.3834, 0.0481, 0.0800, 0.1081], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,307][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.3304, 0.1511, 0.1875, 0.1594, 0.1716], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,307][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([8.2934e-05, 4.2966e-01, 1.5104e-03, 5.6841e-01, 3.3680e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,308][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1273, 0.1769, 0.2170, 0.2304, 0.2483], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,308][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.4143, 0.1693, 0.1473, 0.0717, 0.1974], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,308][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([9.6670e-01, 7.2080e-06, 4.1766e-03, 1.7339e-02, 1.1782e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,309][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([4.8358e-08, 1.0384e-02, 8.3862e-03, 9.6274e-01, 1.8487e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,309][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.4488, 0.3299, 0.0046, 0.2117, 0.0050], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,309][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0155, 0.9148, 0.0213, 0.0310, 0.0174], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,309][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.1943, 0.1949, 0.2020, 0.1904, 0.2184], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,312][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.1296, 0.2275, 0.2633, 0.2159, 0.1637], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,313][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2522, 0.1750, 0.1490, 0.1473, 0.1414, 0.1350], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,314][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.3203, 0.2900, 0.0566, 0.0863, 0.1338, 0.1129], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,314][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2898, 0.1335, 0.1641, 0.1357, 0.1498, 0.1269], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,314][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9757e-03, 4.0642e-01, 1.1888e-03, 4.4401e-01, 4.3629e-04, 1.4297e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,315][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0920, 0.1396, 0.1766, 0.1905, 0.2068, 0.1944], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,315][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2549, 0.0775, 0.2554, 0.0523, 0.2131, 0.1467], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,315][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([9.3766e-01, 5.1294e-06, 1.2919e-03, 2.1519e-03, 6.3468e-03, 5.2546e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,316][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([4.7205e-07, 1.1340e-03, 2.4022e-03, 9.7811e-02, 1.2752e-02, 8.8590e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,316][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4083, 0.4218, 0.0121, 0.0966, 0.0083, 0.0529], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,320][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0237, 0.8278, 0.0394, 0.0391, 0.0299, 0.0401], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,320][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1687, 0.1653, 0.1703, 0.1604, 0.1846, 0.1506], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,320][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1223, 0.1855, 0.2155, 0.1821, 0.1423, 0.1522], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,321][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2338, 0.1571, 0.1296, 0.1283, 0.1224, 0.1142, 0.1146],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,321][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2887, 0.2581, 0.0539, 0.0786, 0.1068, 0.1097, 0.1041],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,321][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2418, 0.1183, 0.1421, 0.1208, 0.1299, 0.1132, 0.1338],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,321][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.3596e-05, 7.8823e-04, 4.2174e-07, 1.4798e-01, 9.8437e-05, 8.0035e-01,
        5.0749e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,322][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0761, 0.1147, 0.1432, 0.1577, 0.1695, 0.1627, 0.1761],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,322][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2386, 0.1001, 0.1880, 0.0387, 0.2212, 0.1943, 0.0191],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,323][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([8.9762e-01, 2.7301e-07, 1.1081e-04, 2.5879e-03, 1.6994e-03, 7.2801e-02,
        2.5181e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,326][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.9871e-08, 5.1981e-04, 7.1061e-04, 7.9869e-02, 4.0406e-03, 8.8539e-01,
        2.9468e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,326][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1272, 0.6308, 0.0020, 0.1905, 0.0026, 0.0359, 0.0110],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,327][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0241, 0.7207, 0.0591, 0.0620, 0.0395, 0.0565, 0.0381],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,327][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1441, 0.1409, 0.1457, 0.1369, 0.1577, 0.1286, 0.1460],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,327][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0961, 0.1749, 0.1987, 0.1571, 0.1306, 0.1415, 0.1012],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,327][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.2413, 0.1462, 0.1132, 0.1147, 0.1060, 0.0991, 0.0982, 0.0812],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,328][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.2650, 0.1892, 0.0490, 0.0798, 0.1125, 0.0897, 0.0943, 0.1204],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,328][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2119, 0.1020, 0.1249, 0.1068, 0.1154, 0.1011, 0.1195, 0.1185],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,328][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([3.0851e-04, 1.3697e-03, 1.1399e-06, 1.2678e-01, 1.3338e-03, 3.9887e-01,
        2.4723e-01, 2.2411e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,332][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0597, 0.0937, 0.1259, 0.1377, 0.1503, 0.1404, 0.1525, 0.1399],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,333][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.2169, 0.0623, 0.0788, 0.0917, 0.1413, 0.2346, 0.0520, 0.1223],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,333][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([9.2678e-01, 3.6729e-08, 3.8966e-05, 1.6279e-04, 4.0666e-04, 1.1869e-02,
        1.7535e-02, 4.3204e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,333][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([1.2917e-08, 2.9602e-03, 4.9570e-03, 2.8945e-01, 9.2156e-03, 6.3397e-01,
        5.7405e-02, 2.0433e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,333][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.3299, 0.5748, 0.0027, 0.0471, 0.0008, 0.0125, 0.0096, 0.0226],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,334][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0203, 0.7083, 0.0548, 0.0497, 0.0375, 0.0472, 0.0335, 0.0487],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,334][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1324, 0.1196, 0.1260, 0.1212, 0.1378, 0.1145, 0.1292, 0.1193],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,334][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0867, 0.1381, 0.1485, 0.1330, 0.1005, 0.1180, 0.1204, 0.1549],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,335][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2634, 0.1287, 0.1012, 0.0977, 0.0921, 0.0835, 0.0834, 0.0679, 0.0820],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,338][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1932, 0.1727, 0.0453, 0.0506, 0.0849, 0.0695, 0.0810, 0.1088, 0.1940],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,339][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1874, 0.0930, 0.1121, 0.0949, 0.1029, 0.0891, 0.1055, 0.1045, 0.1107],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,339][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([3.2771e-05, 4.3534e-04, 1.3737e-06, 1.5564e-02, 2.0422e-05, 5.7217e-02,
        1.2042e-02, 3.8036e-01, 5.3432e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,339][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0518, 0.0825, 0.1104, 0.1210, 0.1323, 0.1227, 0.1350, 0.1222, 0.1221],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,340][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.2941, 0.0167, 0.1732, 0.0178, 0.3121, 0.0717, 0.0112, 0.0987, 0.0046],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,340][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([3.4657e-01, 2.0905e-08, 9.7388e-06, 5.1225e-05, 9.9950e-05, 6.9488e-03,
        1.3883e-02, 5.7576e-01, 5.6681e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,340][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([1.0443e-07, 9.9805e-04, 1.7974e-03, 1.1094e-01, 5.9770e-03, 7.8466e-01,
        5.6780e-02, 3.5488e-03, 3.5298e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,341][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.6102, 0.0182, 0.0431, 0.0122, 0.0116, 0.1142, 0.0541, 0.1172, 0.0191],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,341][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0237, 0.6745, 0.0428, 0.0374, 0.0285, 0.0440, 0.0341, 0.0475, 0.0675],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,345][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1174, 0.1118, 0.1154, 0.1086, 0.1242, 0.1018, 0.1147, 0.1040, 0.1021],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,345][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0677, 0.1241, 0.1653, 0.1142, 0.1009, 0.1027, 0.0930, 0.1362, 0.0960],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,345][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1996, 0.1237, 0.0954, 0.0974, 0.0897, 0.0833, 0.0832, 0.0687, 0.0856,
        0.0732], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,346][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1827, 0.1303, 0.0320, 0.0489, 0.0764, 0.0616, 0.0670, 0.0904, 0.2079,
        0.1028], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,346][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1639, 0.0790, 0.0973, 0.0853, 0.0914, 0.0813, 0.0961, 0.0967, 0.1021,
        0.1067], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,346][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.5020e-04, 5.6677e-04, 3.0584e-07, 3.8194e-02, 5.7885e-05, 1.1166e-01,
        1.3743e-02, 2.2968e-01, 3.7751e-01, 2.2814e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,347][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0438, 0.0719, 0.0994, 0.1091, 0.1191, 0.1100, 0.1195, 0.1089, 0.1072,
        0.1111], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,347][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.1770, 0.0930, 0.1015, 0.0877, 0.1500, 0.2299, 0.0282, 0.0797, 0.0098,
        0.0431], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,348][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([5.2518e-01, 6.3424e-09, 1.4422e-05, 2.1154e-05, 6.8603e-05, 6.4269e-03,
        1.2222e-02, 4.2205e-01, 2.3165e-02, 1.0850e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,351][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([1.8374e-07, 4.7669e-03, 5.1052e-03, 2.9603e-01, 1.2211e-02, 5.8662e-01,
        5.6949e-02, 3.0680e-03, 2.8986e-02, 6.2624e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,351][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2277, 0.5738, 0.0014, 0.0244, 0.0009, 0.0093, 0.0084, 0.0394, 0.1080,
        0.0066], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,352][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0157, 0.5728, 0.0627, 0.0572, 0.0428, 0.0525, 0.0394, 0.0514, 0.0736,
        0.0319], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,352][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1061, 0.0979, 0.1028, 0.0979, 0.1110, 0.0929, 0.1054, 0.0965, 0.0926,
        0.0968], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,352][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0701, 0.1004, 0.1263, 0.1045, 0.0896, 0.0855, 0.0922, 0.1306, 0.1046,
        0.0962], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,353][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1938, 0.1132, 0.0885, 0.0903, 0.0833, 0.0782, 0.0776, 0.0638, 0.0785,
        0.0668, 0.0659], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,353][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1517, 0.1498, 0.0333, 0.0444, 0.0685, 0.0567, 0.0604, 0.0800, 0.1747,
        0.0933, 0.0873], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,353][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1570, 0.0765, 0.0917, 0.0769, 0.0832, 0.0715, 0.0851, 0.0845, 0.0901,
        0.0917, 0.0916], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,355][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.7395e-04, 2.9188e-03, 1.0667e-06, 2.2965e-02, 1.4834e-05, 1.8495e-02,
        5.1686e-03, 7.7105e-02, 4.3999e-01, 2.9333e-01, 1.3984e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,357][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0434, 0.0667, 0.0879, 0.0962, 0.1048, 0.0987, 0.1073, 0.0989, 0.0974,
        0.1008, 0.0977], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,358][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.1126, 0.0218, 0.0767, 0.0372, 0.1532, 0.1498, 0.0230, 0.0794, 0.0137,
        0.3170, 0.0156], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,358][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([8.0170e-01, 3.8243e-08, 2.4074e-05, 4.4720e-05, 1.4247e-04, 6.6031e-03,
        8.8390e-03, 9.9016e-02, 1.4985e-02, 8.9514e-03, 5.9692e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,358][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([3.7239e-07, 1.5017e-03, 2.0243e-03, 1.2229e-01, 7.9232e-03, 7.2625e-01,
        5.2046e-02, 3.8939e-03, 3.3780e-02, 1.1694e-02, 3.8594e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,358][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([9.7388e-02, 5.3307e-01, 3.9256e-04, 1.4207e-01, 3.7868e-04, 1.1625e-02,
        1.0442e-02, 8.7571e-03, 1.8782e-01, 3.7406e-03, 4.3180e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,359][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0154, 0.5837, 0.0604, 0.0504, 0.0363, 0.0462, 0.0329, 0.0457, 0.0720,
        0.0310, 0.0260], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,359][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1014, 0.0942, 0.0960, 0.0893, 0.1014, 0.0835, 0.0943, 0.0848, 0.0835,
        0.0854, 0.0862], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,360][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0569, 0.1001, 0.1124, 0.0946, 0.0690, 0.0895, 0.0723, 0.1167, 0.0891,
        0.1063, 0.0932], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,363][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1292, 0.1044, 0.0873, 0.0879, 0.0836, 0.0770, 0.0770, 0.0650, 0.0785,
        0.0673, 0.0669, 0.0761], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,364][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1500, 0.1090, 0.0242, 0.0337, 0.0563, 0.0502, 0.0553, 0.0787, 0.1789,
        0.0921, 0.0856, 0.0861], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,364][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1361, 0.0690, 0.0828, 0.0699, 0.0751, 0.0647, 0.0771, 0.0772, 0.0817,
        0.0841, 0.0829, 0.0992], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,364][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([6.8469e-04, 7.8640e-05, 1.1958e-08, 8.4980e-04, 9.6657e-07, 2.0770e-03,
        9.5331e-05, 3.5938e-03, 9.6601e-03, 2.1031e-02, 4.3575e-02, 9.1835e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,365][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0323, 0.0560, 0.0812, 0.0899, 0.1010, 0.0920, 0.1011, 0.0905, 0.0892,
        0.0936, 0.0912, 0.0819], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,365][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1762, 0.0433, 0.1006, 0.0358, 0.2194, 0.1115, 0.0089, 0.0826, 0.0123,
        0.1742, 0.0242, 0.0110], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,365][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.0369e-01, 3.1676e-09, 4.8937e-06, 3.1580e-05, 6.2247e-05, 6.9903e-03,
        1.3653e-02, 2.0343e-01, 4.3409e-02, 1.4204e-02, 3.8575e-01, 2.8771e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,366][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.0551e-06, 6.7325e-04, 8.7544e-04, 7.3246e-02, 5.2749e-03, 7.1836e-01,
        3.5345e-02, 3.0644e-03, 2.4547e-02, 1.0564e-02, 3.4226e-02, 9.3828e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,370][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0768, 0.3761, 0.0022, 0.1349, 0.0029, 0.0436, 0.0129, 0.0347, 0.2238,
        0.0624, 0.0154, 0.0143], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,370][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0190, 0.5302, 0.0595, 0.0507, 0.0400, 0.0492, 0.0362, 0.0514, 0.0692,
        0.0331, 0.0288, 0.0328], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,370][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0900, 0.0900, 0.0908, 0.0825, 0.0948, 0.0767, 0.0868, 0.0772, 0.0755,
        0.0778, 0.0773, 0.0804], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,371][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0499, 0.0914, 0.1058, 0.0878, 0.0672, 0.0796, 0.0674, 0.0922, 0.0842,
        0.0976, 0.1012, 0.0756], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,371][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.1638, 0.0985, 0.0770, 0.0793, 0.0731, 0.0684, 0.0678, 0.0568, 0.0707,
        0.0598, 0.0587, 0.0681, 0.0581], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,371][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.1356, 0.1042, 0.0271, 0.0420, 0.0607, 0.0497, 0.0540, 0.0676, 0.1488,
        0.0782, 0.0784, 0.0790, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,372][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.1274, 0.0610, 0.0743, 0.0635, 0.0682, 0.0593, 0.0709, 0.0709, 0.0753,
        0.0774, 0.0770, 0.0932, 0.0816], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,372][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ office] are: tensor([7.6439e-03, 7.8019e-04, 1.8060e-08, 3.6017e-04, 1.9288e-06, 3.4524e-04,
        9.6203e-05, 2.6531e-03, 2.0257e-03, 4.4416e-03, 3.0701e-03, 2.9027e-01,
        6.8831e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,376][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0320, 0.0530, 0.0781, 0.0835, 0.0943, 0.0845, 0.0917, 0.0835, 0.0804,
        0.0849, 0.0828, 0.0741, 0.0774], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,376][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.1621, 0.0717, 0.0741, 0.0461, 0.1209, 0.2065, 0.0148, 0.0189, 0.0054,
        0.1571, 0.0247, 0.0295, 0.0683], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,377][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ office] are: tensor([8.7788e-01, 1.6721e-09, 3.0669e-06, 7.2084e-06, 1.9460e-05, 1.9539e-03,
        1.8877e-03, 2.9452e-02, 3.7191e-03, 1.3728e-03, 3.7919e-02, 3.5752e-03,
        4.2209e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,377][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ office] are: tensor([5.9483e-07, 4.6833e-03, 6.5715e-03, 3.3348e-01, 8.3541e-03, 4.6629e-01,
        6.7357e-02, 5.6855e-03, 3.2761e-02, 8.1633e-03, 2.4972e-02, 4.0024e-02,
        1.6579e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,377][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.5431, 0.1847, 0.0044, 0.0242, 0.0023, 0.0241, 0.0198, 0.0548, 0.0822,
        0.0130, 0.0233, 0.0191, 0.0050], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,378][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0156, 0.5728, 0.0478, 0.0475, 0.0354, 0.0404, 0.0324, 0.0441, 0.0621,
        0.0269, 0.0235, 0.0285, 0.0230], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,378][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0932, 0.0786, 0.0795, 0.0754, 0.0855, 0.0717, 0.0815, 0.0713, 0.0710,
        0.0727, 0.0747, 0.0801, 0.0647], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,378][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0483, 0.0752, 0.0937, 0.0764, 0.0638, 0.0765, 0.0662, 0.0868, 0.0757,
        0.0846, 0.1017, 0.0832, 0.0680], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,382][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1637, 0.0952, 0.0731, 0.0738, 0.0681, 0.0625, 0.0624, 0.0513, 0.0639,
        0.0544, 0.0528, 0.0634, 0.0529, 0.0625], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,383][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1361, 0.0573, 0.0145, 0.0195, 0.0402, 0.0399, 0.0513, 0.0814, 0.1594,
        0.0905, 0.0720, 0.0779, 0.0848, 0.0752], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,383][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1170, 0.0580, 0.0697, 0.0591, 0.0636, 0.0550, 0.0655, 0.0654, 0.0694,
        0.0713, 0.0705, 0.0849, 0.0753, 0.0753], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,383][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([2.8023e-03, 2.0620e-06, 2.0074e-11, 2.4770e-07, 2.2714e-10, 3.1074e-07,
        5.4024e-08, 5.9940e-06, 2.1135e-06, 1.5762e-05, 8.1911e-06, 2.7921e-04,
        4.4555e-03, 9.9243e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,384][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0304, 0.0501, 0.0707, 0.0766, 0.0853, 0.0774, 0.0853, 0.0773, 0.0759,
        0.0799, 0.0777, 0.0710, 0.0733, 0.0692], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,384][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1592, 0.0213, 0.0839, 0.0201, 0.1136, 0.1525, 0.0173, 0.0540, 0.0053,
        0.2647, 0.0089, 0.0193, 0.0592, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,384][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([7.3753e-01, 1.0620e-09, 2.0709e-07, 3.5988e-07, 2.3587e-06, 4.6051e-05,
        3.1788e-04, 8.4591e-02, 3.8943e-03, 2.5905e-03, 2.6386e-02, 2.1624e-03,
        1.0085e-01, 4.1634e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,385][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([6.3176e-06, 1.2219e-03, 1.3166e-03, 8.8946e-02, 6.1289e-03, 5.5497e-01,
        3.8606e-02, 3.9954e-03, 3.2452e-02, 1.3562e-02, 4.0117e-02, 1.0690e-01,
        9.8872e-03, 1.0189e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,388][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.4220, 0.0108, 0.0589, 0.0010, 0.0065, 0.0253, 0.0090, 0.1830, 0.0063,
        0.1321, 0.0524, 0.0183, 0.0676, 0.0067], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,389][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0190, 0.5467, 0.0509, 0.0389, 0.0321, 0.0413, 0.0297, 0.0446, 0.0604,
        0.0292, 0.0260, 0.0301, 0.0244, 0.0268], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,389][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0785, 0.0768, 0.0782, 0.0714, 0.0820, 0.0669, 0.0758, 0.0675, 0.0669,
        0.0686, 0.0685, 0.0718, 0.0581, 0.0691], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,389][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0468, 0.0758, 0.0944, 0.0688, 0.0582, 0.0648, 0.0611, 0.0858, 0.0666,
        0.0750, 0.0866, 0.0742, 0.0689, 0.0731], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,390][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1388, 0.0863, 0.0702, 0.0689, 0.0657, 0.0600, 0.0601, 0.0502, 0.0604,
        0.0526, 0.0508, 0.0604, 0.0513, 0.0594, 0.0648], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,390][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.1560, 0.0779, 0.0156, 0.0268, 0.0346, 0.0376, 0.0402, 0.0622, 0.1387,
        0.0700, 0.0613, 0.0639, 0.0686, 0.0593, 0.0874], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,391][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.1031, 0.0518, 0.0623, 0.0552, 0.0574, 0.0520, 0.0614, 0.0616, 0.0653,
        0.0663, 0.0661, 0.0787, 0.0686, 0.0697, 0.0806], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,391][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([1.0630e-07, 6.0421e-09, 1.7512e-13, 5.5803e-08, 2.0818e-11, 1.2952e-07,
        2.0990e-08, 2.4533e-07, 1.2006e-06, 8.4253e-07, 1.7210e-06, 1.6347e-04,
        2.0276e-03, 9.9780e-01, 6.1421e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,395][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0271, 0.0459, 0.0660, 0.0715, 0.0803, 0.0726, 0.0793, 0.0722, 0.0701,
        0.0752, 0.0729, 0.0657, 0.0687, 0.0646, 0.0679], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,395][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1361, 0.0530, 0.0480, 0.0261, 0.0616, 0.2590, 0.0263, 0.0449, 0.0193,
        0.0805, 0.0445, 0.0317, 0.0679, 0.0429, 0.0582], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,395][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([6.5729e-01, 3.3314e-09, 1.0963e-06, 4.2907e-06, 5.5811e-06, 5.4416e-04,
        1.9782e-03, 6.0421e-02, 5.3298e-03, 1.6563e-03, 7.3722e-02, 3.4794e-03,
        1.2324e-01, 6.4129e-02, 8.1992e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,396][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([1.2075e-07, 6.2726e-03, 5.6559e-03, 4.0351e-01, 7.3592e-03, 3.7353e-01,
        6.7406e-02, 3.2842e-03, 2.7286e-02, 6.2414e-03, 2.4837e-02, 4.7679e-02,
        1.8259e-03, 2.4752e-02, 3.5750e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,396][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.5154, 0.0327, 0.0121, 0.0258, 0.0056, 0.0622, 0.0488, 0.0796, 0.0273,
        0.0525, 0.0427, 0.0422, 0.0312, 0.0185, 0.0033], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,396][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0156, 0.5282, 0.0463, 0.0494, 0.0355, 0.0408, 0.0306, 0.0420, 0.0608,
        0.0251, 0.0219, 0.0263, 0.0229, 0.0270, 0.0276], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,397][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0801, 0.0671, 0.0694, 0.0663, 0.0748, 0.0627, 0.0709, 0.0635, 0.0621,
        0.0643, 0.0650, 0.0691, 0.0577, 0.0662, 0.0610], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,398][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0414, 0.0698, 0.0809, 0.0669, 0.0499, 0.0633, 0.0556, 0.0826, 0.0704,
        0.0793, 0.0902, 0.0693, 0.0650, 0.0664, 0.0489], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,401][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1658, 0.0860, 0.0632, 0.0657, 0.0588, 0.0549, 0.0542, 0.0441, 0.0566,
        0.0471, 0.0456, 0.0547, 0.0455, 0.0541, 0.0584, 0.0453],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,401][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1203, 0.0690, 0.0169, 0.0260, 0.0409, 0.0370, 0.0422, 0.0587, 0.1204,
        0.0667, 0.0587, 0.0625, 0.0644, 0.0670, 0.0968, 0.0523],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,402][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1027, 0.0503, 0.0608, 0.0513, 0.0551, 0.0478, 0.0567, 0.0563, 0.0598,
        0.0607, 0.0609, 0.0730, 0.0646, 0.0646, 0.0753, 0.0603],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,402][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([3.3551e-04, 3.4291e-06, 3.1765e-11, 6.5890e-07, 6.4643e-10, 3.8624e-07,
        6.8177e-08, 2.5885e-06, 6.5782e-06, 1.7541e-05, 4.2479e-06, 3.7820e-04,
        4.2045e-03, 9.7672e-01, 1.5618e-05, 1.8307e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,402][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0266, 0.0437, 0.0612, 0.0662, 0.0741, 0.0675, 0.0739, 0.0669, 0.0660,
        0.0699, 0.0679, 0.0624, 0.0643, 0.0615, 0.0641, 0.0638],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,403][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1499, 0.0542, 0.0780, 0.0374, 0.1245, 0.1062, 0.0146, 0.0299, 0.0128,
        0.0575, 0.0294, 0.0260, 0.0475, 0.0696, 0.1079, 0.0545],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,403][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([3.7083e-01, 4.0117e-09, 9.6883e-07, 2.8634e-06, 9.5115e-06, 3.1903e-04,
        1.2157e-03, 5.7778e-02, 5.4351e-03, 3.8931e-03, 7.7074e-02, 6.1935e-03,
        1.8098e-01, 2.1866e-01, 3.0290e-02, 4.7317e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,405][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([6.5377e-07, 5.4306e-03, 6.9801e-03, 2.9106e-01, 1.1472e-02, 3.9592e-01,
        7.4985e-02, 5.2160e-03, 4.0199e-02, 1.0486e-02, 3.8271e-02, 6.7246e-02,
        3.3640e-03, 4.6735e-02, 7.1776e-04, 1.9204e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,407][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4617, 0.2142, 0.0056, 0.0332, 0.0032, 0.0285, 0.0191, 0.0626, 0.0534,
        0.0259, 0.0208, 0.0189, 0.0129, 0.0307, 0.0033, 0.0061],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,407][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0163, 0.5215, 0.0445, 0.0366, 0.0302, 0.0363, 0.0291, 0.0412, 0.0551,
        0.0275, 0.0238, 0.0274, 0.0230, 0.0238, 0.0245, 0.0392],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,408][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0808, 0.0658, 0.0664, 0.0620, 0.0703, 0.0588, 0.0662, 0.0582, 0.0581,
        0.0592, 0.0610, 0.0662, 0.0530, 0.0632, 0.0561, 0.0547],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,408][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0408, 0.0667, 0.0747, 0.0647, 0.0481, 0.0610, 0.0517, 0.0793, 0.0678,
        0.0713, 0.0868, 0.0670, 0.0660, 0.0676, 0.0469, 0.0396],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,409][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1296, 0.0808, 0.0625, 0.0638, 0.0587, 0.0541, 0.0537, 0.0442, 0.0556,
        0.0465, 0.0455, 0.0539, 0.0452, 0.0532, 0.0578, 0.0451, 0.0498],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,409][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1137, 0.0596, 0.0141, 0.0219, 0.0327, 0.0349, 0.0393, 0.0592, 0.1164,
        0.0675, 0.0582, 0.0613, 0.0645, 0.0620, 0.0882, 0.0496, 0.0568],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,409][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0942, 0.0477, 0.0572, 0.0483, 0.0516, 0.0446, 0.0531, 0.0529, 0.0561,
        0.0572, 0.0568, 0.0679, 0.0602, 0.0603, 0.0707, 0.0565, 0.0647],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,411][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.2150e-06, 2.0547e-08, 8.6423e-14, 4.4632e-08, 2.4287e-11, 1.3926e-07,
        2.8947e-09, 9.4278e-07, 8.6752e-07, 7.9453e-07, 1.1350e-06, 8.4731e-05,
        2.0564e-03, 8.2467e-01, 3.6060e-06, 1.6893e-01, 4.2490e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,416][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0235, 0.0399, 0.0578, 0.0623, 0.0706, 0.0637, 0.0696, 0.0627, 0.0617,
        0.0656, 0.0640, 0.0581, 0.0604, 0.0575, 0.0610, 0.0608, 0.0609],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,416][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0937, 0.0699, 0.0842, 0.0288, 0.0962, 0.0790, 0.0134, 0.0959, 0.0143,
        0.1092, 0.0288, 0.0327, 0.0499, 0.0622, 0.0821, 0.0452, 0.0145],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,417][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([4.4865e-01, 5.5508e-09, 7.0247e-07, 6.4972e-06, 1.0492e-05, 3.6379e-04,
        3.3767e-04, 3.1487e-02, 5.2857e-03, 3.0537e-03, 2.0943e-02, 2.1947e-03,
        7.9374e-02, 1.3232e-01, 1.6329e-02, 1.7557e-01, 8.4083e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,417][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.2639e-06, 2.5139e-03, 2.9054e-03, 1.6545e-01, 8.5230e-03, 5.6902e-01,
        4.6600e-02, 3.9208e-03, 2.8233e-02, 9.3851e-03, 3.1262e-02, 6.5180e-02,
        5.1676e-03, 5.3398e-02, 8.3683e-04, 3.5622e-03, 4.0421e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,418][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2317, 0.1380, 0.0132, 0.0495, 0.0077, 0.0646, 0.0137, 0.1099, 0.0414,
        0.1508, 0.0227, 0.0143, 0.0281, 0.0782, 0.0019, 0.0231, 0.0112],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,418][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0158, 0.4820, 0.0446, 0.0396, 0.0302, 0.0392, 0.0281, 0.0431, 0.0584,
        0.0273, 0.0225, 0.0252, 0.0207, 0.0229, 0.0229, 0.0404, 0.0373],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,418][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0739, 0.0654, 0.0651, 0.0594, 0.0680, 0.0556, 0.0629, 0.0546, 0.0540,
        0.0555, 0.0564, 0.0611, 0.0479, 0.0582, 0.0517, 0.0494, 0.0609],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,419][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0384, 0.0685, 0.0789, 0.0626, 0.0512, 0.0588, 0.0410, 0.0747, 0.0604,
        0.0689, 0.0723, 0.0591, 0.0632, 0.0669, 0.0510, 0.0437, 0.0407],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,419][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1334, 0.0773, 0.0596, 0.0602, 0.0554, 0.0511, 0.0504, 0.0412, 0.0520,
        0.0432, 0.0423, 0.0508, 0.0423, 0.0498, 0.0542, 0.0419, 0.0465, 0.0484],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,423][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0919, 0.0419, 0.0102, 0.0181, 0.0260, 0.0324, 0.0363, 0.0572, 0.1187,
        0.0700, 0.0581, 0.0638, 0.0633, 0.0574, 0.0822, 0.0443, 0.0524, 0.0760],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,423][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0848, 0.0421, 0.0511, 0.0448, 0.0471, 0.0420, 0.0501, 0.0502, 0.0532,
        0.0549, 0.0539, 0.0648, 0.0566, 0.0573, 0.0677, 0.0537, 0.0616, 0.0639],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,424][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([1.5398e-02, 4.9599e-06, 6.6674e-11, 1.7713e-06, 8.7541e-09, 9.5442e-07,
        9.2065e-08, 1.9000e-06, 1.7136e-06, 6.7482e-06, 7.2477e-06, 2.3289e-04,
        5.0283e-03, 5.8960e-01, 3.6896e-05, 2.6412e-01, 1.6494e-02, 1.0906e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,424][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0242, 0.0389, 0.0551, 0.0587, 0.0663, 0.0599, 0.0647, 0.0590, 0.0574,
        0.0610, 0.0595, 0.0539, 0.0561, 0.0537, 0.0563, 0.0564, 0.0559, 0.0631],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,424][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0888, 0.0837, 0.0631, 0.0156, 0.1029, 0.0937, 0.0183, 0.0176, 0.0052,
        0.0835, 0.0167, 0.0569, 0.0538, 0.0301, 0.1431, 0.0875, 0.0249, 0.0145],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,425][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([8.5514e-01, 1.3978e-09, 4.0679e-06, 1.7448e-06, 1.2752e-05, 1.2043e-04,
        4.8498e-04, 1.2166e-02, 4.4826e-04, 6.4004e-04, 1.3923e-02, 9.7315e-04,
        3.5767e-02, 5.7693e-03, 8.1146e-03, 1.5442e-02, 4.0164e-02, 1.0829e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,425][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([1.6262e-06, 9.9806e-03, 1.1295e-02, 4.2536e-01, 1.6752e-02, 3.3930e-01,
        6.1115e-02, 4.5801e-03, 2.8370e-02, 7.3686e-03, 2.5675e-02, 3.8155e-02,
        2.2180e-03, 2.4040e-02, 8.4858e-04, 1.6464e-03, 2.6766e-03, 6.1012e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,429][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.3750, 0.0951, 0.0073, 0.0156, 0.0085, 0.0390, 0.0190, 0.0980, 0.0356,
        0.0921, 0.0254, 0.0196, 0.0200, 0.0692, 0.0128, 0.0226, 0.0358, 0.0095],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,429][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0125, 0.5094, 0.0481, 0.0420, 0.0301, 0.0333, 0.0218, 0.0364, 0.0506,
        0.0212, 0.0172, 0.0212, 0.0203, 0.0227, 0.0222, 0.0352, 0.0326, 0.0233],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,430][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0695, 0.0593, 0.0599, 0.0555, 0.0633, 0.0524, 0.0589, 0.0514, 0.0507,
        0.0524, 0.0533, 0.0577, 0.0463, 0.0548, 0.0494, 0.0469, 0.0574, 0.0611],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,430][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0343, 0.0559, 0.0759, 0.0594, 0.0460, 0.0555, 0.0501, 0.0649, 0.0574,
        0.0605, 0.0767, 0.0604, 0.0580, 0.0567, 0.0459, 0.0446, 0.0488, 0.0492],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,430][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1476, 0.0753, 0.0583, 0.0572, 0.0527, 0.0479, 0.0472, 0.0374, 0.0468,
        0.0391, 0.0384, 0.0471, 0.0391, 0.0453, 0.0504, 0.0383, 0.0429, 0.0444,
        0.0447], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,431][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0909, 0.0449, 0.0163, 0.0191, 0.0269, 0.0317, 0.0382, 0.0576, 0.0815,
        0.0589, 0.0482, 0.0497, 0.0540, 0.0485, 0.0734, 0.0465, 0.0497, 0.0663,
        0.0977], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,431][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0824, 0.0415, 0.0500, 0.0423, 0.0454, 0.0393, 0.0469, 0.0469, 0.0495,
        0.0509, 0.0501, 0.0600, 0.0533, 0.0533, 0.0628, 0.0500, 0.0573, 0.0606,
        0.0574], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,433][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2839e-05, 2.3915e-09, 1.4087e-14, 6.0653e-09, 1.3821e-11, 9.9397e-09,
        3.7064e-09, 2.5025e-07, 2.3341e-07, 1.5578e-06, 1.7417e-07, 9.5172e-05,
        1.2107e-03, 4.2950e-01, 4.1747e-06, 5.3014e-02, 9.6550e-03, 2.6685e-01,
        2.3966e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,435][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0194, 0.0342, 0.0515, 0.0547, 0.0627, 0.0558, 0.0611, 0.0546, 0.0540,
        0.0576, 0.0564, 0.0510, 0.0535, 0.0509, 0.0549, 0.0553, 0.0555, 0.0633,
        0.0534], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,435][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1282, 0.0713, 0.0956, 0.0284, 0.0784, 0.0747, 0.0167, 0.0677, 0.0114,
        0.0777, 0.0146, 0.0276, 0.0416, 0.0534, 0.0645, 0.0642, 0.0205, 0.0523,
        0.0111], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,436][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([3.2893e-01, 1.8393e-09, 2.7034e-07, 7.9215e-07, 2.8163e-06, 8.4390e-05,
        8.1814e-04, 2.3386e-02, 2.5935e-03, 2.4457e-03, 3.3603e-02, 5.0714e-03,
        6.0963e-02, 6.4458e-02, 1.1671e-02, 9.4288e-02, 2.2621e-01, 9.0241e-02,
        5.5238e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,436][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.3257e-06, 2.7070e-03, 3.6592e-03, 1.6815e-01, 9.2379e-03, 5.0028e-01,
        5.5916e-02, 5.3116e-03, 3.1566e-02, 1.1195e-02, 3.7308e-02, 7.9435e-02,
        7.2241e-03, 6.8683e-02, 1.1259e-03, 4.5757e-03, 6.0504e-03, 1.9911e-03,
        5.5821e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,437][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4292, 0.0141, 0.0436, 0.0032, 0.0055, 0.0440, 0.0166, 0.1271, 0.0077,
        0.0571, 0.0653, 0.0354, 0.0479, 0.0051, 0.0077, 0.0385, 0.0357, 0.0082,
        0.0081], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,437][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0161, 0.4845, 0.0435, 0.0311, 0.0244, 0.0305, 0.0245, 0.0397, 0.0514,
        0.0237, 0.0198, 0.0227, 0.0182, 0.0204, 0.0184, 0.0336, 0.0342, 0.0213,
        0.0418], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,437][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0684, 0.0594, 0.0582, 0.0534, 0.0603, 0.0490, 0.0552, 0.0477, 0.0478,
        0.0488, 0.0499, 0.0543, 0.0420, 0.0518, 0.0451, 0.0429, 0.0537, 0.0565,
        0.0556], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,441][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0352, 0.0586, 0.0708, 0.0566, 0.0458, 0.0501, 0.0428, 0.0646, 0.0516,
        0.0644, 0.0647, 0.0520, 0.0529, 0.0587, 0.0448, 0.0402, 0.0417, 0.0554,
        0.0491], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,457][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:50,458][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,459][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,459][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,459][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,460][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,460][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,460][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,461][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,461][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,461][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,462][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,462][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,462][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7147, 0.2853], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,462][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8612, 0.1388], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,463][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2363, 0.7637], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,466][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2367, 0.7633], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,466][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6610, 0.3390], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,467][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6522, 0.3478], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,467][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4119, 0.5881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,467][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4984, 0.5016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,468][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6331, 0.3669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,468][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4796, 0.5204], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,468][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8213, 0.1787], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,469][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4194, 0.5806], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,473][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.6358, 0.1997, 0.1645], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,473][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.7978, 0.1267, 0.0755], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,473][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.1775, 0.5678, 0.2547], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,473][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.0580, 0.8362, 0.1057], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,474][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.7746, 0.1617, 0.0637], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,474][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.5021, 0.2618, 0.2360], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,474][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.2861, 0.4113, 0.3026], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,474][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.3363, 0.3765, 0.2872], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,475][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.4274, 0.5103, 0.0623], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,475][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.2942, 0.3519, 0.3539], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,477][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.5672, 0.0949, 0.3379], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,479][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.2867, 0.3233, 0.3900], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,480][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4678, 0.1867, 0.1172, 0.2284], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,480][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5343, 0.2350, 0.1697, 0.0610], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,480][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0989, 0.3916, 0.2218, 0.2877], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,480][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0100, 0.2480, 0.7028, 0.0391], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,481][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4613, 0.2400, 0.1093, 0.1894], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,481][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3817, 0.2066, 0.1995, 0.2122], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,481][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2328, 0.3249, 0.2620, 0.1803], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,482][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3387, 0.2643, 0.2016, 0.1954], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,485][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6206, 0.2362, 0.1021, 0.0411], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,486][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2228, 0.2551, 0.2640, 0.2581], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,486][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6620, 0.0583, 0.1089, 0.1708], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,486][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2069, 0.2627, 0.3377, 0.1927], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,487][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.4839, 0.1404, 0.0877, 0.1591, 0.1289], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,487][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.4747, 0.2059, 0.1267, 0.0259, 0.1668], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,487][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0896, 0.3288, 0.1548, 0.3015, 0.1253], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,488][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0080, 0.2516, 0.5639, 0.1449, 0.0316], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,488][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.6050, 0.1517, 0.0745, 0.1386, 0.0302], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,492][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.3224, 0.1720, 0.1597, 0.1750, 0.1709], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,492][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.1935, 0.2723, 0.2050, 0.1653, 0.1640], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,492][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.2403, 0.2195, 0.1689, 0.1687, 0.2027], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,493][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.3458, 0.3104, 0.1292, 0.1720, 0.0426], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,493][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1666, 0.2094, 0.2020, 0.2110, 0.2110], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,493][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.5826, 0.0243, 0.1107, 0.0707, 0.2117], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,494][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.1560, 0.1639, 0.1512, 0.0901, 0.4388], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,494][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3565, 0.1304, 0.0719, 0.1560, 0.1000, 0.1852], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,494][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2607, 0.1352, 0.1157, 0.0365, 0.3808, 0.0710], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,498][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0807, 0.2527, 0.1494, 0.2436, 0.1423, 0.1313], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,498][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0184, 0.3917, 0.3810, 0.1765, 0.0187, 0.0135], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,499][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.4387, 0.1721, 0.0923, 0.1305, 0.0473, 0.1190], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,499][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2626, 0.1426, 0.1433, 0.1494, 0.1512, 0.1508], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,499][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1615, 0.2265, 0.1976, 0.1337, 0.1535, 0.1271], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,499][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1933, 0.1996, 0.1517, 0.1491, 0.1882, 0.1181], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,500][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3914, 0.3012, 0.0537, 0.1219, 0.0736, 0.0583], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,500][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1539, 0.1767, 0.1590, 0.1733, 0.1938, 0.1433], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,500][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.6181, 0.0146, 0.0366, 0.0580, 0.0661, 0.2066], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,504][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1244, 0.1247, 0.1234, 0.0827, 0.3594, 0.1854], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,505][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3096, 0.1097, 0.0699, 0.1293, 0.0862, 0.1272, 0.1679],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,505][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2440, 0.1316, 0.1115, 0.0375, 0.2758, 0.0682, 0.1312],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,505][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0621, 0.2117, 0.1401, 0.1956, 0.1026, 0.1408, 0.1471],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,505][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0474, 0.4436, 0.1546, 0.0979, 0.0856, 0.1241, 0.0468],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,506][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3526, 0.1545, 0.0809, 0.1265, 0.0451, 0.1145, 0.1258],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,506][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2233, 0.1262, 0.1251, 0.1296, 0.1296, 0.1317, 0.1345],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,506][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1561, 0.2095, 0.1574, 0.1280, 0.1344, 0.1197, 0.0948],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,507][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1490, 0.1727, 0.1331, 0.1299, 0.1623, 0.1053, 0.1478],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,510][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4375, 0.2089, 0.0604, 0.0807, 0.0800, 0.1176, 0.0150],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,511][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1372, 0.1461, 0.1446, 0.1444, 0.1594, 0.1268, 0.1414],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,511][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5202, 0.0135, 0.0272, 0.0364, 0.0369, 0.1692, 0.1966],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,511][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1018, 0.0899, 0.0754, 0.0545, 0.2456, 0.1310, 0.3018],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,512][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.2678, 0.0974, 0.0597, 0.1165, 0.0792, 0.1160, 0.1344, 0.1290],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,512][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.2738, 0.0862, 0.0700, 0.0348, 0.2212, 0.0477, 0.1401, 0.1262],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,512][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0790, 0.1753, 0.0904, 0.1820, 0.0852, 0.1098, 0.2065, 0.0718],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,513][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0464, 0.2996, 0.0998, 0.1348, 0.0278, 0.0359, 0.3296, 0.0261],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,513][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.3077, 0.1252, 0.0786, 0.1060, 0.0461, 0.1043, 0.1140, 0.1182],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,517][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1983, 0.1101, 0.1067, 0.1162, 0.1135, 0.1179, 0.1198, 0.1175],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,517][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.1293, 0.1726, 0.1377, 0.1085, 0.1050, 0.1049, 0.0932, 0.1489],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,517][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1044, 0.1563, 0.1196, 0.1204, 0.1493, 0.0938, 0.1309, 0.1253],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,518][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.2684, 0.1610, 0.0828, 0.1247, 0.0471, 0.2325, 0.0468, 0.0367],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,518][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.1146, 0.1363, 0.1234, 0.1362, 0.1429, 0.1043, 0.1388, 0.1035],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,518][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2809, 0.0153, 0.0193, 0.0387, 0.0282, 0.1690, 0.1351, 0.3134],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,519][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0867, 0.0741, 0.0550, 0.0455, 0.1676, 0.0951, 0.2026, 0.2733],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,519][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.2314, 0.0925, 0.0609, 0.1064, 0.0739, 0.1036, 0.1183, 0.0911, 0.1220],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,519][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.2285, 0.1166, 0.0892, 0.0332, 0.1583, 0.0414, 0.0932, 0.0940, 0.1455],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,523][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0416, 0.1578, 0.0918, 0.1604, 0.0791, 0.0980, 0.1851, 0.0895, 0.0967],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,523][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0016, 0.0313, 0.3927, 0.0123, 0.0462, 0.0126, 0.0177, 0.4823, 0.0033],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,523][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.2576, 0.1152, 0.0700, 0.0960, 0.0401, 0.0882, 0.1006, 0.1008, 0.1315],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,524][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.1752, 0.0989, 0.0985, 0.1023, 0.1041, 0.1033, 0.1053, 0.1053, 0.1071],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,524][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1174, 0.1618, 0.1239, 0.0955, 0.1015, 0.0876, 0.0847, 0.1416, 0.0860],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,524][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1395, 0.1258, 0.0948, 0.0952, 0.1147, 0.0731, 0.1033, 0.0977, 0.1559],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,525][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.4816, 0.1173, 0.0289, 0.0458, 0.0602, 0.1542, 0.0571, 0.0176, 0.0374],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,525][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0993, 0.1171, 0.1121, 0.1185, 0.1273, 0.0936, 0.1228, 0.0957, 0.1137],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,527][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1600, 0.0044, 0.0147, 0.0141, 0.0208, 0.1238, 0.1537, 0.2442, 0.2643],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,529][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0515, 0.0549, 0.0520, 0.0344, 0.1344, 0.0726, 0.1429, 0.1912, 0.2661],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,529][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2512, 0.0845, 0.0476, 0.0984, 0.0584, 0.0892, 0.1082, 0.0836, 0.1147,
        0.0642], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,530][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1728, 0.0900, 0.0730, 0.0263, 0.1656, 0.0343, 0.0884, 0.0835, 0.1528,
        0.1133], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,530][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0521, 0.1394, 0.0722, 0.1463, 0.0715, 0.0846, 0.1752, 0.0808, 0.1271,
        0.0508], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,530][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0216, 0.2606, 0.0909, 0.1790, 0.0177, 0.1429, 0.0546, 0.1664, 0.0591,
        0.0072], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,531][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.2211, 0.1072, 0.0684, 0.0890, 0.0374, 0.0834, 0.0913, 0.0929, 0.1156,
        0.0936], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,531][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.1610, 0.0904, 0.0891, 0.0952, 0.0953, 0.0965, 0.0969, 0.0938, 0.0958,
        0.0859], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,532][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1045, 0.1424, 0.1115, 0.0906, 0.0908, 0.0914, 0.0758, 0.1384, 0.0902,
        0.0644], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,535][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0848, 0.1151, 0.0884, 0.0877, 0.1107, 0.0686, 0.0997, 0.0946, 0.1494,
        0.1010], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,536][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1213, 0.0783, 0.0551, 0.0717, 0.0863, 0.1033, 0.0300, 0.0864, 0.3634,
        0.0042], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,536][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0915, 0.1086, 0.1003, 0.1059, 0.1017, 0.0889, 0.1111, 0.0858, 0.1104,
        0.0959], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,536][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.2281, 0.0041, 0.0072, 0.0112, 0.0183, 0.0402, 0.1371, 0.2999, 0.1082,
        0.1456], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,537][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0459, 0.0400, 0.0248, 0.0199, 0.0803, 0.0438, 0.0960, 0.1439, 0.2712,
        0.2343], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,537][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1975, 0.0798, 0.0497, 0.0925, 0.0579, 0.0858, 0.0964, 0.0740, 0.1065,
        0.0516, 0.1083], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,537][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1318, 0.0866, 0.0713, 0.0207, 0.1576, 0.0339, 0.0810, 0.0822, 0.1364,
        0.1173, 0.0813], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,538][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0409, 0.1244, 0.0760, 0.1300, 0.0714, 0.0857, 0.1566, 0.0679, 0.1041,
        0.0689, 0.0740], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,542][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0105, 0.2342, 0.2093, 0.0584, 0.0716, 0.0466, 0.0431, 0.1278, 0.0772,
        0.1047, 0.0166], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,542][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.2213, 0.0907, 0.0570, 0.0766, 0.0306, 0.0713, 0.0795, 0.0832, 0.1052,
        0.0850, 0.0997], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,542][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1523, 0.0813, 0.0816, 0.0849, 0.0875, 0.0868, 0.0873, 0.0855, 0.0882,
        0.0855, 0.0791], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,543][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1046, 0.1351, 0.1044, 0.0790, 0.0896, 0.0800, 0.0728, 0.1289, 0.0806,
        0.0753, 0.0498], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,543][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0866, 0.1033, 0.0768, 0.0750, 0.0944, 0.0580, 0.0852, 0.0831, 0.1326,
        0.0901, 0.1148], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,543][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2627, 0.1569, 0.0447, 0.0531, 0.0659, 0.1807, 0.0550, 0.0590, 0.0745,
        0.0254, 0.0222], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,544][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0779, 0.0980, 0.0864, 0.0965, 0.1041, 0.0816, 0.1048, 0.0777, 0.0959,
        0.0930, 0.0842], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,544][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2619, 0.0050, 0.0106, 0.0230, 0.0160, 0.0810, 0.1011, 0.1121, 0.1083,
        0.1066, 0.1745], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,548][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0315, 0.0360, 0.0295, 0.0196, 0.0832, 0.0408, 0.0905, 0.1216, 0.1963,
        0.1988, 0.1523], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,548][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1803, 0.0685, 0.0470, 0.0808, 0.0547, 0.0776, 0.0910, 0.0720, 0.0911,
        0.0511, 0.0754, 0.1104], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,549][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1155, 0.0625, 0.0562, 0.0172, 0.1553, 0.0311, 0.0739, 0.0762, 0.1381,
        0.1146, 0.0829, 0.0766], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,549][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0346, 0.1156, 0.0730, 0.1110, 0.0642, 0.0783, 0.1009, 0.0650, 0.1014,
        0.0654, 0.0901, 0.1005], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,549][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0154, 0.1269, 0.2078, 0.0490, 0.1770, 0.0449, 0.0213, 0.1788, 0.0334,
        0.0770, 0.0465, 0.0222], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,550][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1751, 0.0828, 0.0535, 0.0705, 0.0321, 0.0665, 0.0732, 0.0743, 0.0932,
        0.0777, 0.0896, 0.1116], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,550][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1360, 0.0762, 0.0751, 0.0786, 0.0800, 0.0800, 0.0804, 0.0798, 0.0830,
        0.0761, 0.0757, 0.0791], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,550][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0945, 0.1298, 0.0980, 0.0769, 0.0834, 0.0732, 0.0651, 0.1205, 0.0797,
        0.0674, 0.0517, 0.0598], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,554][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0674, 0.0905, 0.0666, 0.0635, 0.0815, 0.0487, 0.0750, 0.0751, 0.1170,
        0.0797, 0.0985, 0.1366], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,554][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2766, 0.0857, 0.0383, 0.0471, 0.0633, 0.1570, 0.0279, 0.0972, 0.1032,
        0.0455, 0.0523, 0.0060], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,555][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0809, 0.0873, 0.0859, 0.0857, 0.0931, 0.0711, 0.0817, 0.0708, 0.0887,
        0.0877, 0.0766, 0.0906], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,555][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2152, 0.0029, 0.0086, 0.0112, 0.0149, 0.0822, 0.1003, 0.0882, 0.1023,
        0.0788, 0.1240, 0.1714], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,556][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0240, 0.0224, 0.0155, 0.0102, 0.0555, 0.0252, 0.0630, 0.0995, 0.1888,
        0.1722, 0.1331, 0.1906], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,556][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.1924, 0.0624, 0.0439, 0.0744, 0.0508, 0.0645, 0.0819, 0.0585, 0.0843,
        0.0390, 0.0707, 0.0991, 0.0782], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,556][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.1345, 0.0654, 0.0554, 0.0225, 0.1360, 0.0319, 0.0710, 0.0668, 0.1131,
        0.0939, 0.0722, 0.0689, 0.0685], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,557][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0330, 0.1038, 0.0607, 0.1007, 0.0559, 0.0712, 0.1175, 0.0601, 0.0948,
        0.0458, 0.0855, 0.1264, 0.0446], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,560][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.0144, 0.0608, 0.4042, 0.0611, 0.0536, 0.0617, 0.0457, 0.1305, 0.0294,
        0.0385, 0.0551, 0.0332, 0.0120], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,561][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1801, 0.0695, 0.0498, 0.0609, 0.0264, 0.0586, 0.0647, 0.0700, 0.0849,
        0.0692, 0.0809, 0.1046, 0.0803], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,561][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.1278, 0.0696, 0.0683, 0.0722, 0.0728, 0.0748, 0.0743, 0.0702, 0.0747,
        0.0702, 0.0697, 0.0751, 0.0802], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,561][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0866, 0.1203, 0.0879, 0.0747, 0.0744, 0.0758, 0.0627, 0.1080, 0.0740,
        0.0594, 0.0527, 0.0568, 0.0666], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,562][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0541, 0.0846, 0.0627, 0.0607, 0.0764, 0.0453, 0.0678, 0.0655, 0.1052,
        0.0700, 0.0890, 0.1226, 0.0960], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,562][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.1675, 0.0750, 0.0387, 0.0615, 0.0349, 0.1339, 0.0429, 0.0754, 0.2264,
        0.0287, 0.1011, 0.0106, 0.0035], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,563][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0656, 0.0815, 0.0803, 0.0803, 0.0823, 0.0620, 0.0873, 0.0631, 0.0761,
        0.0769, 0.0736, 0.0880, 0.0827], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,563][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.2048, 0.0030, 0.0043, 0.0103, 0.0137, 0.0412, 0.0796, 0.1238, 0.0719,
        0.0968, 0.1290, 0.1086, 0.1131], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,567][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.0229, 0.0239, 0.0178, 0.0138, 0.0562, 0.0279, 0.0628, 0.0814, 0.1475,
        0.1393, 0.1165, 0.1748, 0.1151], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,567][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1415, 0.0601, 0.0403, 0.0699, 0.0511, 0.0696, 0.0783, 0.0598, 0.0751,
        0.0456, 0.0657, 0.0882, 0.0623, 0.0923], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,567][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1077, 0.0390, 0.0393, 0.0116, 0.1190, 0.0249, 0.0771, 0.0845, 0.1203,
        0.1189, 0.0696, 0.0743, 0.0815, 0.0324], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,568][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0309, 0.0989, 0.0601, 0.0912, 0.0486, 0.0605, 0.1112, 0.0598, 0.0746,
        0.0570, 0.0807, 0.1160, 0.0541, 0.0563], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,568][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0063, 0.0729, 0.2799, 0.0187, 0.0282, 0.0369, 0.0525, 0.1592, 0.0254,
        0.1903, 0.0152, 0.0343, 0.0724, 0.0079], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,568][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1525, 0.0700, 0.0443, 0.0569, 0.0252, 0.0548, 0.0604, 0.0620, 0.0776,
        0.0639, 0.0733, 0.0931, 0.0729, 0.0932], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,569][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1179, 0.0644, 0.0641, 0.0667, 0.0680, 0.0697, 0.0701, 0.0679, 0.0702,
        0.0666, 0.0637, 0.0687, 0.0745, 0.0676], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,569][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0904, 0.1170, 0.0854, 0.0683, 0.0694, 0.0639, 0.0609, 0.1000, 0.0653,
        0.0562, 0.0446, 0.0579, 0.0665, 0.0543], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,573][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0666, 0.0720, 0.0540, 0.0520, 0.0665, 0.0403, 0.0615, 0.0605, 0.0924,
        0.0642, 0.0804, 0.1126, 0.0873, 0.0896], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,573][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.5447, 0.0967, 0.0450, 0.0250, 0.0181, 0.0577, 0.0559, 0.0536, 0.0282,
        0.0054, 0.0200, 0.0104, 0.0164, 0.0230], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,573][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0651, 0.0723, 0.0707, 0.0725, 0.0788, 0.0567, 0.0761, 0.0625, 0.0708,
        0.0702, 0.0634, 0.0814, 0.0806, 0.0788], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,574][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.5218, 0.0023, 0.0026, 0.0022, 0.0019, 0.0065, 0.0192, 0.0443, 0.0229,
        0.0285, 0.0348, 0.0365, 0.0714, 0.2051], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,574][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0159, 0.0148, 0.0111, 0.0076, 0.0399, 0.0188, 0.0470, 0.0738, 0.1349,
        0.1295, 0.0923, 0.1450, 0.1039, 0.1654], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,575][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.1855, 0.0546, 0.0345, 0.0615, 0.0506, 0.0547, 0.0645, 0.0472, 0.0732,
        0.0332, 0.0573, 0.0830, 0.0516, 0.0905, 0.0581], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,575][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.1722, 0.0583, 0.0411, 0.0142, 0.0767, 0.0216, 0.0478, 0.0677, 0.1028,
        0.0881, 0.0549, 0.0508, 0.0612, 0.0207, 0.1221], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,577][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0298, 0.0934, 0.0459, 0.0905, 0.0391, 0.0654, 0.1146, 0.0525, 0.0923,
        0.0435, 0.0794, 0.1246, 0.0390, 0.0616, 0.0283], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,579][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0072, 0.0761, 0.2583, 0.0717, 0.0148, 0.0187, 0.0626, 0.0925, 0.0857,
        0.0947, 0.0867, 0.0226, 0.0780, 0.0201, 0.0103], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,579][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.1478, 0.0547, 0.0389, 0.0504, 0.0201, 0.0501, 0.0553, 0.0605, 0.0719,
        0.0608, 0.0692, 0.0900, 0.0707, 0.0889, 0.0706], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,580][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.1155, 0.0607, 0.0577, 0.0621, 0.0611, 0.0657, 0.0665, 0.0632, 0.0676,
        0.0590, 0.0623, 0.0657, 0.0693, 0.0652, 0.0584], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,580][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0776, 0.1045, 0.0772, 0.0623, 0.0614, 0.0626, 0.0540, 0.1037, 0.0685,
        0.0510, 0.0482, 0.0522, 0.0642, 0.0573, 0.0552], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,581][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0368, 0.0697, 0.0533, 0.0521, 0.0644, 0.0397, 0.0577, 0.0569, 0.0874,
        0.0603, 0.0740, 0.0966, 0.0775, 0.0798, 0.0935], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,581][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1068, 0.0707, 0.0411, 0.0638, 0.0131, 0.1206, 0.0423, 0.0618, 0.2078,
        0.0220, 0.0892, 0.0155, 0.0184, 0.1218, 0.0050], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,581][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0551, 0.0676, 0.0629, 0.0688, 0.0677, 0.0544, 0.0735, 0.0532, 0.0688,
        0.0649, 0.0613, 0.0759, 0.0751, 0.0778, 0.0730], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,585][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0717, 0.0028, 0.0054, 0.0061, 0.0132, 0.0332, 0.0376, 0.0408, 0.0321,
        0.0582, 0.0712, 0.0457, 0.1106, 0.3892, 0.0822], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,586][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0158, 0.0107, 0.0071, 0.0057, 0.0264, 0.0158, 0.0390, 0.0639, 0.1139,
        0.1068, 0.0794, 0.1137, 0.0943, 0.1199, 0.1875], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,586][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1539, 0.0531, 0.0298, 0.0636, 0.0399, 0.0615, 0.0702, 0.0509, 0.0711,
        0.0368, 0.0576, 0.0765, 0.0510, 0.0858, 0.0446, 0.0535],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,586][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1126, 0.0438, 0.0372, 0.0146, 0.0855, 0.0229, 0.0562, 0.0599, 0.0924,
        0.0801, 0.0521, 0.0549, 0.0580, 0.0280, 0.1466, 0.0552],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,587][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0250, 0.0827, 0.0510, 0.0815, 0.0495, 0.0480, 0.1133, 0.0519, 0.0787,
        0.0433, 0.0780, 0.1288, 0.0419, 0.0608, 0.0373, 0.0283],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,587][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0303, 0.1228, 0.1307, 0.1270, 0.0145, 0.0178, 0.0324, 0.0595, 0.1494,
        0.0479, 0.1366, 0.0276, 0.0499, 0.0409, 0.0107, 0.0020],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,587][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1464, 0.0541, 0.0352, 0.0461, 0.0190, 0.0452, 0.0500, 0.0544, 0.0683,
        0.0571, 0.0639, 0.0845, 0.0665, 0.0843, 0.0673, 0.0578],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,591][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1063, 0.0576, 0.0566, 0.0600, 0.0607, 0.0615, 0.0609, 0.0585, 0.0623,
        0.0557, 0.0573, 0.0607, 0.0648, 0.0618, 0.0573, 0.0580],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,592][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0698, 0.1014, 0.0790, 0.0595, 0.0639, 0.0568, 0.0556, 0.0860, 0.0610,
        0.0471, 0.0458, 0.0524, 0.0697, 0.0545, 0.0561, 0.0414],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,592][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0428, 0.0659, 0.0497, 0.0469, 0.0592, 0.0347, 0.0517, 0.0502, 0.0787,
        0.0533, 0.0663, 0.0928, 0.0723, 0.0762, 0.0878, 0.0715],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,593][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2014, 0.0801, 0.0331, 0.0466, 0.0235, 0.1328, 0.0210, 0.0528, 0.1259,
        0.0209, 0.0474, 0.0102, 0.0541, 0.1360, 0.0083, 0.0059],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,593][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0547, 0.0681, 0.0567, 0.0650, 0.0659, 0.0548, 0.0678, 0.0547, 0.0655,
        0.0591, 0.0558, 0.0747, 0.0707, 0.0754, 0.0710, 0.0401],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,593][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2920, 0.0038, 0.0047, 0.0051, 0.0052, 0.0185, 0.0248, 0.0631, 0.0238,
        0.0500, 0.0518, 0.0431, 0.0475, 0.2144, 0.0286, 0.1235],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,594][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0145, 0.0132, 0.0097, 0.0075, 0.0316, 0.0161, 0.0380, 0.0544, 0.0951,
        0.0919, 0.0691, 0.1085, 0.0752, 0.1200, 0.1658, 0.0895],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,598][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1320, 0.0477, 0.0312, 0.0567, 0.0381, 0.0554, 0.0733, 0.0495, 0.0652,
        0.0367, 0.0549, 0.0746, 0.0484, 0.0777, 0.0413, 0.0409, 0.0764],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,598][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0923, 0.0395, 0.0337, 0.0128, 0.0739, 0.0232, 0.0491, 0.0624, 0.0911,
        0.0854, 0.0574, 0.0544, 0.0612, 0.0268, 0.1284, 0.0515, 0.0570],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,598][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0272, 0.0853, 0.0590, 0.0836, 0.0456, 0.0609, 0.0634, 0.0410, 0.0758,
        0.0503, 0.0729, 0.0939, 0.0540, 0.0610, 0.0347, 0.0440, 0.0474],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,599][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0304, 0.1029, 0.0939, 0.0401, 0.0534, 0.0445, 0.0157, 0.2511, 0.0275,
        0.0457, 0.0580, 0.0256, 0.1174, 0.0316, 0.0335, 0.0198, 0.0089],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,599][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1280, 0.0546, 0.0343, 0.0452, 0.0189, 0.0437, 0.0483, 0.0512, 0.0633,
        0.0523, 0.0601, 0.0770, 0.0608, 0.0771, 0.0609, 0.0542, 0.0700],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,600][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0989, 0.0542, 0.0542, 0.0557, 0.0567, 0.0575, 0.0581, 0.0576, 0.0588,
        0.0542, 0.0543, 0.0578, 0.0610, 0.0571, 0.0536, 0.0543, 0.0560],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,600][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0764, 0.0997, 0.0717, 0.0588, 0.0607, 0.0554, 0.0429, 0.0903, 0.0603,
        0.0482, 0.0367, 0.0439, 0.0600, 0.0546, 0.0524, 0.0487, 0.0392],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,604][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0359, 0.0595, 0.0437, 0.0404, 0.0513, 0.0300, 0.0461, 0.0470, 0.0719,
        0.0489, 0.0591, 0.0819, 0.0639, 0.0673, 0.0818, 0.0636, 0.1076],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,604][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2727, 0.0903, 0.0369, 0.0436, 0.0520, 0.0719, 0.0079, 0.0832, 0.0946,
        0.0263, 0.0335, 0.0042, 0.0244, 0.1139, 0.0189, 0.0226, 0.0033],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,605][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0549, 0.0608, 0.0583, 0.0599, 0.0641, 0.0502, 0.0568, 0.0500, 0.0607,
        0.0608, 0.0549, 0.0627, 0.0668, 0.0665, 0.0683, 0.0453, 0.0590],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,608][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3169, 0.0022, 0.0046, 0.0040, 0.0046, 0.0152, 0.0214, 0.0299, 0.0174,
        0.0162, 0.0307, 0.0368, 0.0521, 0.1663, 0.0290, 0.1038, 0.1488],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,608][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0121, 0.0099, 0.0071, 0.0054, 0.0246, 0.0131, 0.0312, 0.0473, 0.0836,
        0.0822, 0.0618, 0.0931, 0.0690, 0.1027, 0.1480, 0.0794, 0.1294],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,609][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1487, 0.0469, 0.0280, 0.0564, 0.0382, 0.0475, 0.0564, 0.0440, 0.0635,
        0.0298, 0.0502, 0.0758, 0.0495, 0.0811, 0.0440, 0.0335, 0.0607, 0.0458],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,609][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0667, 0.0310, 0.0267, 0.0106, 0.0572, 0.0236, 0.0476, 0.0701, 0.0878,
        0.1008, 0.0592, 0.0576, 0.0606, 0.0262, 0.1166, 0.0479, 0.0530, 0.0567],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,610][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0270, 0.0820, 0.0450, 0.0789, 0.0434, 0.0498, 0.0968, 0.0498, 0.0684,
        0.0361, 0.0691, 0.0986, 0.0358, 0.0499, 0.0308, 0.0339, 0.0693, 0.0354],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,610][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0091, 0.0631, 0.3741, 0.0398, 0.1055, 0.0109, 0.0389, 0.0475, 0.0399,
        0.0325, 0.0555, 0.0181, 0.0693, 0.0110, 0.0504, 0.0096, 0.0161, 0.0088],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,610][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1311, 0.0471, 0.0328, 0.0424, 0.0172, 0.0415, 0.0440, 0.0494, 0.0598,
        0.0487, 0.0565, 0.0748, 0.0569, 0.0737, 0.0602, 0.0518, 0.0673, 0.0448],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,611][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0958, 0.0512, 0.0505, 0.0516, 0.0551, 0.0549, 0.0553, 0.0518, 0.0545,
        0.0514, 0.0510, 0.0554, 0.0585, 0.0542, 0.0522, 0.0532, 0.0539, 0.0495],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,611][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0666, 0.0909, 0.0731, 0.0573, 0.0600, 0.0535, 0.0468, 0.0790, 0.0571,
        0.0472, 0.0404, 0.0431, 0.0587, 0.0466, 0.0495, 0.0496, 0.0422, 0.0385],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,615][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0224, 0.0546, 0.0405, 0.0377, 0.0477, 0.0277, 0.0430, 0.0432, 0.0654,
        0.0449, 0.0538, 0.0723, 0.0563, 0.0591, 0.0733, 0.0558, 0.0937, 0.1086],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,615][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1568, 0.0496, 0.0548, 0.0489, 0.0203, 0.0815, 0.0443, 0.0642, 0.1526,
        0.0166, 0.0758, 0.0110, 0.0147, 0.1012, 0.0069, 0.0713, 0.0249, 0.0045],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,616][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0480, 0.0574, 0.0572, 0.0571, 0.0575, 0.0421, 0.0592, 0.0469, 0.0548,
        0.0547, 0.0477, 0.0631, 0.0654, 0.0652, 0.0627, 0.0370, 0.0611, 0.0630],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,616][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.2603, 0.0040, 0.0047, 0.0044, 0.0103, 0.0150, 0.0172, 0.0412, 0.0192,
        0.0298, 0.0258, 0.0184, 0.0426, 0.0816, 0.0463, 0.0831, 0.0528, 0.2434],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,616][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0106, 0.0067, 0.0039, 0.0032, 0.0156, 0.0090, 0.0233, 0.0392, 0.0747,
        0.0697, 0.0502, 0.0723, 0.0599, 0.0807, 0.1231, 0.0656, 0.1094, 0.1829],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,617][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1121, 0.0453, 0.0295, 0.0518, 0.0382, 0.0513, 0.0572, 0.0431, 0.0591,
        0.0333, 0.0513, 0.0658, 0.0450, 0.0704, 0.0421, 0.0394, 0.0594, 0.0362,
        0.0695], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,617][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0953, 0.0448, 0.0363, 0.0163, 0.0520, 0.0226, 0.0437, 0.0554, 0.0679,
        0.0683, 0.0431, 0.0446, 0.0506, 0.0268, 0.0938, 0.0469, 0.0502, 0.0518,
        0.0894], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,621][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0232, 0.0753, 0.0488, 0.0713, 0.0439, 0.0495, 0.0816, 0.0440, 0.0566,
        0.0456, 0.0563, 0.0930, 0.0471, 0.0481, 0.0339, 0.0411, 0.0615, 0.0483,
        0.0309], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,621][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0131, 0.0433, 0.0437, 0.0223, 0.1312, 0.0412, 0.0419, 0.1114, 0.0204,
        0.1680, 0.0123, 0.0471, 0.0975, 0.0320, 0.0869, 0.0272, 0.0232, 0.0332,
        0.0040], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,622][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1129, 0.0490, 0.0311, 0.0399, 0.0173, 0.0396, 0.0429, 0.0459, 0.0570,
        0.0466, 0.0533, 0.0679, 0.0538, 0.0673, 0.0543, 0.0486, 0.0619, 0.0427,
        0.0681], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,622][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0884, 0.0488, 0.0482, 0.0499, 0.0500, 0.0518, 0.0517, 0.0514, 0.0531,
        0.0490, 0.0484, 0.0517, 0.0548, 0.0512, 0.0478, 0.0499, 0.0505, 0.0493,
        0.0542], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,622][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0696, 0.0941, 0.0706, 0.0524, 0.0549, 0.0514, 0.0465, 0.0781, 0.0496,
        0.0440, 0.0340, 0.0432, 0.0544, 0.0460, 0.0460, 0.0414, 0.0413, 0.0380,
        0.0443], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,623][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0304, 0.0452, 0.0330, 0.0309, 0.0389, 0.0227, 0.0348, 0.0347, 0.0521,
        0.0367, 0.0436, 0.0617, 0.0486, 0.0515, 0.0617, 0.0492, 0.0835, 0.0991,
        0.1414], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,623][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2555, 0.1081, 0.0726, 0.0436, 0.0268, 0.1509, 0.0317, 0.0547, 0.0433,
        0.0106, 0.0116, 0.0157, 0.0275, 0.0569, 0.0078, 0.0297, 0.0139, 0.0320,
        0.0071], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,627][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0485, 0.0553, 0.0481, 0.0532, 0.0570, 0.0421, 0.0548, 0.0424, 0.0522,
        0.0499, 0.0456, 0.0602, 0.0580, 0.0613, 0.0622, 0.0398, 0.0576, 0.0562,
        0.0554], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,627][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2432, 0.0025, 0.0035, 0.0018, 0.0049, 0.0070, 0.0164, 0.0267, 0.0076,
        0.0145, 0.0187, 0.0191, 0.0370, 0.0755, 0.0290, 0.0588, 0.0768, 0.2145,
        0.1424], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,628][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0097, 0.0094, 0.0083, 0.0060, 0.0237, 0.0135, 0.0282, 0.0365, 0.0545,
        0.0618, 0.0470, 0.0755, 0.0550, 0.0811, 0.1090, 0.0600, 0.0923, 0.1474,
        0.0811], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,629][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:50,630][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13688],
        [ 9532],
        [ 1986],
        [ 4724],
        [13153],
        [ 2587],
        [ 6878],
        [ 4176],
        [ 3517],
        [15508],
        [11038],
        [16481],
        [13854],
        [ 6251],
        [16137],
        [ 7457],
        [13249],
        [ 8070],
        [ 7796]], device='cuda:0')
[2024-07-24 10:19:50,632][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13218],
        [ 8993],
        [ 1873],
        [11477],
        [19558],
        [12982],
        [18957],
        [15314],
        [ 9955],
        [27447],
        [16660],
        [20841],
        [25691],
        [10461],
        [20639],
        [14284],
        [20209],
        [13504],
        [ 9497]], device='cuda:0')
[2024-07-24 10:19:50,635][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38021],
        [37165],
        [39273],
        [40189],
        [40764],
        [41805],
        [42401],
        [42816],
        [42896],
        [43506],
        [43776],
        [44258],
        [44277],
        [44231],
        [44346],
        [44315],
        [44545],
        [44561],
        [44447]], device='cuda:0')
[2024-07-24 10:19:50,636][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[7226],
        [3736],
        [3582],
        [3572],
        [3853],
        [3998],
        [4095],
        [4127],
        [3836],
        [3870],
        [3829],
        [3973],
        [4133],
        [4246],
        [4201],
        [4216],
        [4245],
        [4349],
        [4229]], device='cuda:0')
[2024-07-24 10:19:50,637][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[8840],
        [7840],
        [7297],
        [7417],
        [7335],
        [7348],
        [7353],
        [7278],
        [7381],
        [7285],
        [7322],
        [7335],
        [7209],
        [7206],
        [7242],
        [7240],
        [7259],
        [7260],
        [7263]], device='cuda:0')
[2024-07-24 10:19:50,639][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13654],
        [ 2241],
        [ 2022],
        [ 2242],
        [ 2743],
        [ 2351],
        [ 3287],
        [ 1654],
        [ 9312],
        [11612],
        [22277],
        [ 5490],
        [24025],
        [12976],
        [12950],
        [12592],
        [ 9555],
        [ 8265],
        [12792]], device='cuda:0')
[2024-07-24 10:19:50,641][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[39226],
        [38894],
        [38280],
        [38103],
        [37476],
        [37542],
        [37603],
        [37702],
        [38028],
        [38002],
        [38336],
        [38595],
        [38851],
        [39114],
        [39205],
        [39413],
        [39615],
        [39664],
        [39872]], device='cuda:0')
[2024-07-24 10:19:50,642][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[41455],
        [38910],
        [23989],
        [14926],
        [13563],
        [ 6948],
        [ 8271],
        [17576],
        [ 8984],
        [17416],
        [36426],
        [25782],
        [24022],
        [33385],
        [19428],
        [16651],
        [24318],
        [19759],
        [23712]], device='cuda:0')
[2024-07-24 10:19:50,643][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28480],
        [27525],
        [26520],
        [27637],
        [28433],
        [26948],
        [25391],
        [27896],
        [28646],
        [29267],
        [26765],
        [19641],
        [26719],
        [26474],
        [24468],
        [22529],
        [20230],
        [25689],
        [17169]], device='cuda:0')
[2024-07-24 10:19:50,645][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[26280],
        [24691],
        [21844],
        [14685],
        [14656],
        [14296],
        [14519],
        [14744],
        [15151],
        [15134],
        [15334],
        [16168],
        [15910],
        [17259],
        [16125],
        [16831],
        [16421],
        [16098],
        [17005]], device='cuda:0')
[2024-07-24 10:19:50,648][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9718],
        [ 9290],
        [ 4060],
        [10496],
        [ 3693],
        [ 3963],
        [ 5212],
        [ 4384],
        [ 8999],
        [ 4595],
        [ 4898],
        [ 5801],
        [ 4380],
        [21850],
        [ 9976],
        [ 4397],
        [10454],
        [ 8267],
        [15279]], device='cuda:0')
[2024-07-24 10:19:50,649][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[13622],
        [18993],
        [19205],
        [18632],
        [18571],
        [17548],
        [16023],
        [15805],
        [15136],
        [13750],
        [13846],
        [12944],
        [13487],
        [13168],
        [12739],
        [12511],
        [11818],
        [12332],
        [12080]], device='cuda:0')
[2024-07-24 10:19:50,650][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33333],
        [32852],
        [33040],
        [31041],
        [30110],
        [29356],
        [27461],
        [27002],
        [26766],
        [25900],
        [25822],
        [25218],
        [24855],
        [24263],
        [23689],
        [23512],
        [23162],
        [22831],
        [23124]], device='cuda:0')
[2024-07-24 10:19:50,651][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[20297],
        [19495],
        [18158],
        [17914],
        [17276],
        [16557],
        [17525],
        [17220],
        [17068],
        [16762],
        [16462],
        [17198],
        [17069],
        [17312],
        [17089],
        [17088],
        [17347],
        [17836],
        [17962]], device='cuda:0')
[2024-07-24 10:19:50,653][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26153],
        [17186],
        [16689],
        [ 4668],
        [37395],
        [ 4692],
        [21841],
        [16085],
        [18508],
        [12805],
        [21533],
        [23732],
        [  851],
        [ 6489],
        [31162],
        [ 5747],
        [17019],
        [ 7699],
        [20548]], device='cuda:0')
[2024-07-24 10:19:50,656][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18992],
        [20351],
        [20970],
        [21166],
        [21146],
        [20653],
        [21187],
        [20106],
        [20724],
        [20135],
        [20315],
        [20467],
        [20535],
        [21132],
        [21402],
        [21043],
        [21285],
        [21324],
        [21325]], device='cuda:0')
[2024-07-24 10:19:50,657][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17438],
        [18445],
        [19329],
        [22481],
        [23352],
        [25408],
        [23879],
        [23317],
        [24199],
        [24390],
        [24744],
        [24431],
        [23923],
        [23581],
        [22806],
        [22523],
        [22456],
        [22228],
        [22394]], device='cuda:0')
[2024-07-24 10:19:50,658][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[41821],
        [43574],
        [43135],
        [42988],
        [43513],
        [43843],
        [42806],
        [41966],
        [41246],
        [41072],
        [41315],
        [42314],
        [42636],
        [42564],
        [42556],
        [42760],
        [42724],
        [42523],
        [42647]], device='cuda:0')
[2024-07-24 10:19:50,659][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[44718],
        [43888],
        [45430],
        [49982],
        [49848],
        [49160],
        [47173],
        [45154],
        [49764],
        [44536],
        [48143],
        [49017],
        [49683],
        [48571],
        [48072],
        [45136],
        [46322],
        [49772],
        [43828]], device='cuda:0')
[2024-07-24 10:19:50,662][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30331],
        [31073],
        [32412],
        [31760],
        [32776],
        [32452],
        [32350],
        [32783],
        [32997],
        [33005],
        [33684],
        [34466],
        [35191],
        [35610],
        [36226],
        [36472],
        [36777],
        [37131],
        [37433]], device='cuda:0')
[2024-07-24 10:19:50,663][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6589],
        [5330],
        [4857],
        [5554],
        [6093],
        [6363],
        [5884],
        [4841],
        [4430],
        [4312],
        [4015],
        [3932],
        [4173],
        [4177],
        [4334],
        [4266],
        [4162],
        [4494],
        [4331]], device='cuda:0')
[2024-07-24 10:19:50,664][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25060],
        [30685],
        [33337],
        [31886],
        [32847],
        [33190],
        [33248],
        [33416],
        [33093],
        [33558],
        [32747],
        [32651],
        [32077],
        [32821],
        [33135],
        [33000],
        [33241],
        [33121],
        [33296]], device='cuda:0')
[2024-07-24 10:19:50,666][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 4746],
        [ 9231],
        [15648],
        [15457],
        [23862],
        [27043],
        [29920],
        [31815],
        [29152],
        [32210],
        [31684],
        [32423],
        [32989],
        [31982],
        [33845],
        [33187],
        [33329],
        [34306],
        [33753]], device='cuda:0')
[2024-07-24 10:19:50,668][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20705],
        [30263],
        [27450],
        [29369],
        [22886],
        [25807],
        [28555],
        [18474],
        [26689],
        [10381],
        [20718],
        [25660],
        [12342],
        [27984],
        [ 4805],
        [10138],
        [18538],
        [ 7466],
        [20778]], device='cuda:0')
[2024-07-24 10:19:50,670][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17262],
        [19094],
        [22058],
        [20911],
        [19450],
        [18372],
        [17728],
        [17123],
        [16646],
        [16302],
        [15868],
        [15827],
        [15932],
        [15986],
        [15639],
        [15745],
        [15716],
        [15425],
        [15638]], device='cuda:0')
[2024-07-24 10:19:50,671][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8046],
        [ 2828],
        [16120],
        [ 7616],
        [14943],
        [18458],
        [17691],
        [28103],
        [28257],
        [26735],
        [21060],
        [19804],
        [22160],
        [16321],
        [20998],
        [16384],
        [15688],
        [19461],
        [23839]], device='cuda:0')
[2024-07-24 10:19:50,672][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10239],
        [10952],
        [11105],
        [11317],
        [10348],
        [10445],
        [10654],
        [11241],
        [10819],
        [10457],
        [10174],
        [ 9915],
        [ 9941],
        [ 9773],
        [ 9494],
        [ 9555],
        [ 9559],
        [ 9609],
        [ 9671]], device='cuda:0')
[2024-07-24 10:19:50,674][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28687],
        [23301],
        [17065],
        [16029],
        [13619],
        [12358],
        [12559],
        [14444],
        [12695],
        [16359],
        [14374],
        [13097],
        [13532],
        [12846],
        [14635],
        [15155],
        [13958],
        [13199],
        [13355]], device='cuda:0')
[2024-07-24 10:19:50,677][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33864],
        [36818],
        [27963],
        [35260],
        [27750],
        [36377],
        [34257],
        [21764],
        [25772],
        [25795],
        [29071],
        [34618],
        [35969],
        [42294],
        [35439],
        [41922],
        [40129],
        [39623],
        [39215]], device='cuda:0')
[2024-07-24 10:19:50,678][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145],
        [11145]], device='cuda:0')
[2024-07-24 10:19:50,686][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:50,687][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,688][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,688][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,688][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,689][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,689][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,689][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,690][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,690][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,690][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,690][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,691][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,692][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7001, 0.2999], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,694][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7024, 0.2976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,694][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4082, 0.5918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,695][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1625, 0.8375], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,695][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1470, 0.8530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,695][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4014, 0.5986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,696][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4886, 0.5114], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,696][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0964, 0.9036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,696][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6985, 0.3015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,698][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1287, 0.8713], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,700][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0779, 0.9221], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,701][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0023, 0.9977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,701][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0928, 0.7218, 0.1854], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,701][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.2552, 0.6240, 0.1209], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,701][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.5669, 0.3812, 0.0519], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,702][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0907, 0.4539, 0.4555], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,702][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0577, 0.6640, 0.2783], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,702][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.1766, 0.5961, 0.2273], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,703][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.2810, 0.2428, 0.4762], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,703][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0483, 0.4740, 0.4776], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,707][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.6565, 0.2040, 0.1395], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,707][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0575, 0.4975, 0.4450], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,707][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0438, 0.4874, 0.4688], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,707][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([1.1902e-05, 8.5079e-01, 1.4920e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,708][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3777, 0.2931, 0.2592, 0.0700], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,708][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2892, 0.3340, 0.2300, 0.1468], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,708][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3451, 0.3475, 0.1594, 0.1480], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,709][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0544, 0.3214, 0.3211, 0.3030], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,709][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0458, 0.3765, 0.1864, 0.3913], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,711][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1900, 0.3644, 0.1285, 0.3170], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,713][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1872, 0.1629, 0.3643, 0.2857], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,713][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0305, 0.3198, 0.3250, 0.3247], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,714][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4871, 0.1896, 0.1446, 0.1787], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,714][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0443, 0.3261, 0.3000, 0.3296], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,714][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0313, 0.2803, 0.2923, 0.3961], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,714][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0017, 0.5507, 0.1338, 0.3138], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,715][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0262, 0.4112, 0.1812, 0.3205, 0.0609], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,715][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.2716, 0.3072, 0.1172, 0.1979, 0.1061], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,715][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.5446, 0.2526, 0.0371, 0.0583, 0.1074], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,719][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0542, 0.2420, 0.2426, 0.2284, 0.2328], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,719][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0253, 0.3136, 0.1283, 0.3204, 0.2123], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,720][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1096, 0.2910, 0.1562, 0.3525, 0.0907], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,720][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1439, 0.1397, 0.2816, 0.2469, 0.1881], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,720][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0216, 0.2435, 0.2485, 0.2442, 0.2422], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,721][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.4764, 0.1471, 0.1104, 0.1361, 0.1300], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,721][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0287, 0.2607, 0.2308, 0.2590, 0.2207], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,721][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0259, 0.1989, 0.2027, 0.2538, 0.3186], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,722][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([1.3201e-04, 5.7112e-01, 1.1957e-01, 2.8697e-01, 2.2208e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,725][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0433, 0.3685, 0.1807, 0.2563, 0.0795, 0.0718], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,726][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2953, 0.2130, 0.1098, 0.2061, 0.0847, 0.0911], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,726][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3789, 0.3096, 0.0449, 0.0732, 0.1345, 0.0588], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,726][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0311, 0.2008, 0.2000, 0.1898, 0.1918, 0.1866], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,727][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0264, 0.2730, 0.1145, 0.2685, 0.1736, 0.1441], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,727][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1654, 0.1544, 0.1090, 0.3659, 0.1183, 0.0870], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,727][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1141, 0.1066, 0.2363, 0.2036, 0.1518, 0.1876], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,728][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0137, 0.1973, 0.2027, 0.2022, 0.1987, 0.1855], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,728][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4197, 0.1315, 0.1013, 0.1232, 0.1118, 0.1126], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,732][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0253, 0.2097, 0.1882, 0.2093, 0.1804, 0.1871], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,732][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0219, 0.1347, 0.1326, 0.1809, 0.2081, 0.3217], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,732][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0007, 0.4081, 0.0952, 0.2490, 0.0193, 0.2277], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,733][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2437, 0.2660, 0.1501, 0.0883, 0.0669, 0.1409, 0.0442],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,733][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3039, 0.2004, 0.0670, 0.1006, 0.1339, 0.1526, 0.0416],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,733][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4451, 0.2399, 0.0302, 0.0529, 0.0904, 0.0440, 0.0974],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,733][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0252, 0.1684, 0.1684, 0.1589, 0.1624, 0.1566, 0.1600],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,734][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0191, 0.2362, 0.0946, 0.2414, 0.1565, 0.1225, 0.1296],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,734][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1354, 0.1511, 0.1226, 0.2637, 0.1444, 0.0995, 0.0834],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,738][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0931, 0.0868, 0.2069, 0.1683, 0.1288, 0.1690, 0.1471],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,738][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0137, 0.1657, 0.1701, 0.1680, 0.1657, 0.1534, 0.1634],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,739][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4266, 0.1140, 0.0832, 0.1057, 0.0969, 0.0920, 0.0816],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,739][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0193, 0.1762, 0.1582, 0.1762, 0.1510, 0.1574, 0.1618],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,739][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0218, 0.1128, 0.1089, 0.1467, 0.1636, 0.2260, 0.2202],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,739][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0007, 0.1656, 0.0404, 0.1024, 0.0077, 0.1077, 0.5755],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,740][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0583, 0.2378, 0.1742, 0.1539, 0.0378, 0.1899, 0.1072, 0.0410],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,740][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1902, 0.2267, 0.0495, 0.1751, 0.0571, 0.0936, 0.1230, 0.0848],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,740][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.3460, 0.2737, 0.0291, 0.0590, 0.0831, 0.0390, 0.0863, 0.0837],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,744][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0254, 0.1451, 0.1434, 0.1355, 0.1363, 0.1335, 0.1359, 0.1449],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,744][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0207, 0.2013, 0.0884, 0.2007, 0.1324, 0.1108, 0.1131, 0.1326],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,745][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.1383, 0.1391, 0.0981, 0.2230, 0.1125, 0.0617, 0.0966, 0.1307],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,745][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0973, 0.0756, 0.1707, 0.1404, 0.1048, 0.1309, 0.1239, 0.1564],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,745][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0126, 0.1409, 0.1446, 0.1426, 0.1404, 0.1297, 0.1382, 0.1510],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,746][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.4069, 0.1089, 0.0780, 0.0993, 0.0928, 0.0872, 0.0771, 0.0499],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,746][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0194, 0.1491, 0.1345, 0.1493, 0.1298, 0.1339, 0.1384, 0.1457],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,746][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0206, 0.0872, 0.0871, 0.1152, 0.1358, 0.1804, 0.1791, 0.1948],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,747][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([8.5870e-05, 2.5327e-01, 4.4198e-02, 9.7056e-02, 6.7746e-03, 8.2950e-02,
        4.8861e-01, 2.7053e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,750][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2375, 0.1558, 0.1613, 0.0560, 0.1336, 0.0950, 0.0828, 0.0293, 0.0487],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,750][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.2828, 0.0698, 0.0580, 0.0478, 0.1037, 0.0764, 0.0467, 0.2965, 0.0182],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,751][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1294, 0.1604, 0.0580, 0.0669, 0.1100, 0.0594, 0.1104, 0.1132, 0.1923],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,751][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0273, 0.1275, 0.1253, 0.1185, 0.1209, 0.1165, 0.1190, 0.1278, 0.1173],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,751][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0230, 0.1478, 0.0802, 0.1535, 0.1134, 0.0921, 0.0953, 0.1067, 0.1880],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,752][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.1541, 0.1164, 0.0853, 0.2271, 0.0686, 0.0651, 0.1036, 0.1109, 0.0690],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,752][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1124, 0.0665, 0.1442, 0.1090, 0.0879, 0.1036, 0.0930, 0.1270, 0.1565],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,752][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0162, 0.1236, 0.1255, 0.1232, 0.1215, 0.1127, 0.1195, 0.1283, 0.1296],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,755][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.3395, 0.1065, 0.0763, 0.0981, 0.0811, 0.0864, 0.0750, 0.0519, 0.0851],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,756][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0197, 0.1275, 0.1178, 0.1275, 0.1128, 0.1151, 0.1186, 0.1245, 0.1364],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,757][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0191, 0.0802, 0.0790, 0.0935, 0.1128, 0.1487, 0.1440, 0.1488, 0.1739],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,757][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0013, 0.1757, 0.0460, 0.0908, 0.0072, 0.0927, 0.5277, 0.0370, 0.0215],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,757][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0215, 0.1216, 0.0905, 0.0963, 0.0278, 0.0882, 0.0796, 0.0266, 0.4375,
        0.0104], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,758][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.2401, 0.1074, 0.0774, 0.0706, 0.0553, 0.0552, 0.0573, 0.1985, 0.1142,
        0.0241], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,758][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.3369, 0.1525, 0.0127, 0.0246, 0.0425, 0.0193, 0.0454, 0.0577, 0.2261,
        0.0825], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,758][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0205, 0.1148, 0.1127, 0.1064, 0.1067, 0.1043, 0.1061, 0.1133, 0.1041,
        0.1110], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,759][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0139, 0.1450, 0.0629, 0.1454, 0.0945, 0.0794, 0.0804, 0.0963, 0.1946,
        0.0875], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,763][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0655, 0.0995, 0.0989, 0.1956, 0.0819, 0.0715, 0.0606, 0.1061, 0.1457,
        0.0746], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,763][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0755, 0.0525, 0.1248, 0.1052, 0.0801, 0.0972, 0.0986, 0.1178, 0.1511,
        0.0972], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,763][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0103, 0.1098, 0.1112, 0.1093, 0.1070, 0.0988, 0.1052, 0.1141, 0.1159,
        0.1183], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,764][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.4161, 0.0962, 0.0658, 0.0843, 0.0785, 0.0694, 0.0599, 0.0377, 0.0665,
        0.0255], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,764][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0140, 0.1149, 0.1035, 0.1146, 0.0994, 0.1032, 0.1058, 0.1132, 0.1255,
        0.1060], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,764][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0164, 0.0710, 0.0700, 0.0864, 0.1014, 0.1173, 0.1202, 0.1328, 0.1425,
        0.1420], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,765][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([4.7092e-05, 2.4751e-01, 4.4087e-02, 8.4753e-02, 5.2019e-03, 9.1303e-02,
        4.8754e-01, 2.3330e-02, 1.5049e-02, 1.1752e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,765][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0497, 0.1264, 0.0469, 0.0544, 0.0717, 0.1201, 0.1460, 0.0647, 0.1933,
        0.0628, 0.0640], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,769][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0967, 0.0717, 0.0527, 0.0588, 0.0793, 0.1180, 0.0458, 0.2188, 0.0541,
        0.1884, 0.0157], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,769][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2024, 0.1706, 0.0191, 0.0361, 0.0547, 0.0253, 0.0589, 0.0618, 0.2051,
        0.0901, 0.0758], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,770][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0159, 0.1020, 0.1003, 0.0952, 0.0966, 0.0936, 0.0960, 0.1031, 0.0962,
        0.1014, 0.0998], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,770][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0129, 0.1326, 0.0579, 0.1323, 0.0883, 0.0731, 0.0746, 0.0877, 0.1776,
        0.0799, 0.0831], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,770][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0732, 0.0801, 0.0363, 0.2325, 0.0935, 0.0450, 0.0772, 0.1051, 0.0931,
        0.1395, 0.0245], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,771][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0809, 0.0512, 0.1155, 0.0897, 0.0713, 0.0833, 0.0768, 0.1004, 0.1277,
        0.0835, 0.1197], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,771][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0091, 0.0985, 0.0997, 0.0976, 0.0958, 0.0888, 0.0950, 0.1029, 0.1048,
        0.1067, 0.1011], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,771][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3817, 0.0912, 0.0633, 0.0837, 0.0743, 0.0694, 0.0595, 0.0378, 0.0649,
        0.0248, 0.0496], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,775][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0133, 0.1037, 0.0935, 0.1033, 0.0897, 0.0930, 0.0953, 0.1017, 0.1125,
        0.0957, 0.0983], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,775][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0158, 0.0602, 0.0608, 0.0775, 0.0896, 0.1057, 0.1033, 0.1088, 0.1281,
        0.1238, 0.1265], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,776][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([3.1484e-04, 1.8119e-01, 4.4348e-02, 8.5782e-02, 6.4083e-03, 9.6681e-02,
        5.2001e-01, 3.4789e-02, 2.0338e-02, 2.0575e-03, 8.0871e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,776][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1695, 0.0992, 0.0757, 0.0384, 0.0617, 0.0714, 0.0181, 0.0343, 0.1555,
        0.0278, 0.2311, 0.0172], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,776][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1458, 0.1007, 0.0623, 0.0495, 0.0967, 0.1215, 0.0198, 0.1425, 0.0459,
        0.1736, 0.0226, 0.0194], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,777][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2494, 0.1092, 0.0118, 0.0206, 0.0374, 0.0185, 0.0445, 0.0622, 0.1978,
        0.0888, 0.0699, 0.0898], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,777][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0146, 0.0924, 0.0910, 0.0865, 0.0886, 0.0856, 0.0873, 0.0944, 0.0873,
        0.0931, 0.0916, 0.0875], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,778][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0114, 0.1205, 0.0528, 0.1226, 0.0817, 0.0668, 0.0691, 0.0808, 0.1627,
        0.0733, 0.0768, 0.0815], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,781][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0635, 0.0680, 0.0718, 0.1716, 0.0746, 0.0387, 0.0514, 0.0899, 0.0861,
        0.1355, 0.0571, 0.0919], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,782][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0604, 0.0438, 0.0994, 0.0807, 0.0632, 0.0779, 0.0713, 0.0962, 0.1196,
        0.0800, 0.1142, 0.0934], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,782][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0083, 0.0892, 0.0908, 0.0889, 0.0880, 0.0814, 0.0869, 0.0936, 0.0951,
        0.0971, 0.0921, 0.0886], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,782][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3621, 0.0875, 0.0575, 0.0809, 0.0662, 0.0664, 0.0574, 0.0365, 0.0638,
        0.0235, 0.0483, 0.0498], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,783][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0120, 0.0939, 0.0851, 0.0940, 0.0819, 0.0847, 0.0870, 0.0925, 0.1022,
        0.0871, 0.0896, 0.0900], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,783][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0129, 0.0517, 0.0523, 0.0601, 0.0743, 0.0902, 0.0912, 0.0976, 0.1092,
        0.1104, 0.1104, 0.1399], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,783][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0024, 0.1537, 0.0419, 0.0856, 0.0062, 0.1055, 0.5176, 0.0345, 0.0195,
        0.0015, 0.0074, 0.0242], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,784][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0270, 0.0418, 0.0660, 0.0309, 0.0212, 0.0283, 0.0310, 0.0194, 0.2073,
        0.0152, 0.4727, 0.0333, 0.0058], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,788][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.1254, 0.0503, 0.0352, 0.0563, 0.0310, 0.0414, 0.0531, 0.1867, 0.1268,
        0.1126, 0.0576, 0.0713, 0.0524], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,788][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.2009, 0.1404, 0.0150, 0.0264, 0.0415, 0.0204, 0.0472, 0.0518, 0.1697,
        0.0791, 0.0597, 0.0852, 0.0628], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,788][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0149, 0.0857, 0.0843, 0.0796, 0.0809, 0.0786, 0.0800, 0.0856, 0.0790,
        0.0841, 0.0839, 0.0800, 0.0834], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,789][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0110, 0.1106, 0.0491, 0.1111, 0.0751, 0.0620, 0.0635, 0.0755, 0.1508,
        0.0683, 0.0713, 0.0757, 0.0759], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,789][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.1304, 0.0807, 0.0479, 0.1809, 0.0589, 0.0438, 0.0297, 0.0320, 0.0955,
        0.0655, 0.0609, 0.0555, 0.1183], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,789][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0532, 0.0378, 0.0886, 0.0766, 0.0607, 0.0733, 0.0751, 0.0887, 0.1118,
        0.0732, 0.1096, 0.0886, 0.0629], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,790][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0094, 0.0816, 0.0826, 0.0814, 0.0802, 0.0738, 0.0789, 0.0848, 0.0869,
        0.0880, 0.0840, 0.0811, 0.0874], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,790][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.3252, 0.0829, 0.0577, 0.0759, 0.0700, 0.0652, 0.0576, 0.0363, 0.0638,
        0.0245, 0.0499, 0.0516, 0.0395], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,794][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0110, 0.0871, 0.0775, 0.0865, 0.0747, 0.0777, 0.0798, 0.0849, 0.0943,
        0.0797, 0.0819, 0.0823, 0.0826], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,794][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0107, 0.0466, 0.0459, 0.0566, 0.0649, 0.0780, 0.0805, 0.0901, 0.0953,
        0.1008, 0.0978, 0.1220, 0.1107], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,794][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ office] are: tensor([2.7286e-04, 2.6242e-01, 4.8873e-02, 9.1561e-02, 6.0868e-03, 8.5653e-02,
        4.2851e-01, 2.9243e-02, 1.6975e-02, 1.9119e-03, 6.5296e-03, 2.1589e-02,
        3.7090e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,795][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.2046, 0.0642, 0.1320, 0.0194, 0.0553, 0.0334, 0.0839, 0.0447, 0.0805,
        0.0446, 0.1296, 0.0695, 0.0281, 0.0102], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,795][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0876, 0.0500, 0.0442, 0.0215, 0.0486, 0.0666, 0.0454, 0.2134, 0.0285,
        0.1746, 0.0226, 0.0487, 0.1304, 0.0178], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,796][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1356, 0.0783, 0.0132, 0.0186, 0.0372, 0.0179, 0.0428, 0.0551, 0.1423,
        0.0838, 0.0609, 0.0889, 0.0688, 0.1566], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,796][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0085, 0.0776, 0.0777, 0.0730, 0.0753, 0.0723, 0.0741, 0.0811, 0.0754,
        0.0801, 0.0789, 0.0747, 0.0786, 0.0727], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,796][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0123, 0.0932, 0.0469, 0.0942, 0.0671, 0.0557, 0.0569, 0.0666, 0.1224,
        0.0613, 0.0636, 0.0675, 0.0683, 0.1239], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,801][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0643, 0.0713, 0.0439, 0.1284, 0.0594, 0.0203, 0.0479, 0.0462, 0.0626,
        0.0699, 0.0344, 0.0638, 0.2451, 0.0424], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,803][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0436, 0.0338, 0.0814, 0.0644, 0.0519, 0.0649, 0.0583, 0.0878, 0.1037,
        0.0775, 0.1028, 0.0853, 0.0638, 0.0805], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,803][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0071, 0.0752, 0.0769, 0.0754, 0.0745, 0.0688, 0.0738, 0.0796, 0.0807,
        0.0824, 0.0780, 0.0752, 0.0805, 0.0719], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,803][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2919, 0.0815, 0.0549, 0.0755, 0.0591, 0.0649, 0.0550, 0.0364, 0.0641,
        0.0230, 0.0494, 0.0526, 0.0374, 0.0542], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,804][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0100, 0.0790, 0.0714, 0.0792, 0.0689, 0.0715, 0.0737, 0.0782, 0.0870,
        0.0737, 0.0761, 0.0768, 0.0770, 0.0775], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,804][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0086, 0.0389, 0.0387, 0.0525, 0.0622, 0.0719, 0.0713, 0.0776, 0.0853,
        0.0846, 0.0828, 0.1067, 0.0964, 0.1225], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,804][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([8.3514e-04, 1.3260e-01, 3.4417e-02, 7.6862e-02, 5.7737e-03, 9.6396e-02,
        5.5544e-01, 4.3644e-02, 1.8899e-02, 1.6662e-03, 7.1610e-03, 2.2949e-02,
        5.4178e-04, 2.8168e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,805][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0031, 0.0617, 0.0259, 0.0580, 0.0097, 0.0301, 0.0754, 0.0136, 0.3292,
        0.0080, 0.2791, 0.0611, 0.0100, 0.0262, 0.0088], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,805][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0784, 0.0562, 0.0267, 0.0431, 0.0259, 0.0828, 0.0464, 0.2182, 0.0627,
        0.1304, 0.0319, 0.0632, 0.0485, 0.0572, 0.0282], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,806][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.2228, 0.0699, 0.0078, 0.0133, 0.0245, 0.0134, 0.0295, 0.0445, 0.1381,
        0.0593, 0.0495, 0.0556, 0.0504, 0.1136, 0.1079], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,810][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0147, 0.0743, 0.0736, 0.0688, 0.0704, 0.0679, 0.0688, 0.0739, 0.0672,
        0.0724, 0.0713, 0.0679, 0.0711, 0.0663, 0.0716], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,810][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0074, 0.0896, 0.0387, 0.0941, 0.0628, 0.0500, 0.0519, 0.0610, 0.1253,
        0.0549, 0.0580, 0.0608, 0.0609, 0.1195, 0.0650], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,810][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0566, 0.0574, 0.0473, 0.0944, 0.0353, 0.0462, 0.0396, 0.0532, 0.0777,
        0.0871, 0.0413, 0.0559, 0.2000, 0.0573, 0.0506], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,811][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0416, 0.0374, 0.0768, 0.0671, 0.0505, 0.0629, 0.0611, 0.0771, 0.0932,
        0.0691, 0.0937, 0.0783, 0.0590, 0.0859, 0.0462], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,811][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0078, 0.0708, 0.0724, 0.0697, 0.0695, 0.0635, 0.0679, 0.0733, 0.0737,
        0.0755, 0.0717, 0.0691, 0.0743, 0.0661, 0.0746], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,811][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.3361, 0.0774, 0.0522, 0.0732, 0.0650, 0.0588, 0.0501, 0.0305, 0.0559,
        0.0199, 0.0414, 0.0417, 0.0320, 0.0434, 0.0225], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,812][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0090, 0.0734, 0.0656, 0.0737, 0.0637, 0.0668, 0.0684, 0.0735, 0.0815,
        0.0693, 0.0707, 0.0716, 0.0727, 0.0724, 0.0678], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,816][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0077, 0.0361, 0.0371, 0.0495, 0.0579, 0.0615, 0.0616, 0.0730, 0.0754,
        0.0807, 0.0745, 0.0955, 0.0889, 0.1093, 0.0912], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,816][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([4.6585e-04, 1.8167e-01, 3.9090e-02, 8.6968e-02, 5.1156e-03, 8.8813e-02,
        4.9384e-01, 3.8425e-02, 2.0693e-02, 2.3340e-03, 9.3285e-03, 2.9275e-02,
        5.9655e-04, 3.3278e-03, 5.0900e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:50,816][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0021, 0.0692, 0.0230, 0.0554, 0.0137, 0.0385, 0.0635, 0.0182, 0.3223,
        0.0100, 0.2546, 0.0661, 0.0093, 0.0328, 0.0139, 0.0074],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,817][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0639, 0.0581, 0.0360, 0.0648, 0.0248, 0.0441, 0.0319, 0.1794, 0.0634,
        0.0680, 0.0450, 0.0426, 0.1539, 0.0727, 0.0284, 0.0230],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,817][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1296, 0.1046, 0.0116, 0.0206, 0.0321, 0.0155, 0.0351, 0.0373, 0.1143,
        0.0550, 0.0421, 0.0616, 0.0441, 0.1219, 0.1073, 0.0673],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,817][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0102, 0.0696, 0.0688, 0.0642, 0.0655, 0.0626, 0.0639, 0.0695, 0.0638,
        0.0683, 0.0674, 0.0636, 0.0671, 0.0623, 0.0681, 0.0651],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,818][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0098, 0.0807, 0.0393, 0.0822, 0.0573, 0.0477, 0.0489, 0.0572, 0.1078,
        0.0521, 0.0545, 0.0581, 0.0584, 0.1069, 0.0593, 0.0799],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,822][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0354, 0.0490, 0.0311, 0.1069, 0.0447, 0.0228, 0.0412, 0.0438, 0.0990,
        0.0657, 0.0390, 0.0630, 0.1735, 0.0808, 0.0872, 0.0169],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,822][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0381, 0.0341, 0.0728, 0.0643, 0.0482, 0.0587, 0.0578, 0.0745, 0.0920,
        0.0641, 0.0902, 0.0748, 0.0544, 0.0796, 0.0465, 0.0500],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,822][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0075, 0.0651, 0.0663, 0.0649, 0.0642, 0.0594, 0.0635, 0.0681, 0.0694,
        0.0703, 0.0670, 0.0648, 0.0694, 0.0623, 0.0694, 0.0684],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,823][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2716, 0.0737, 0.0551, 0.0685, 0.0625, 0.0601, 0.0507, 0.0331, 0.0570,
        0.0220, 0.0450, 0.0473, 0.0352, 0.0479, 0.0257, 0.0447],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,823][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0086, 0.0695, 0.0619, 0.0694, 0.0600, 0.0627, 0.0645, 0.0686, 0.0765,
        0.0645, 0.0664, 0.0669, 0.0671, 0.0679, 0.0625, 0.0631],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,823][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0088, 0.0335, 0.0344, 0.0457, 0.0489, 0.0572, 0.0580, 0.0661, 0.0657,
        0.0703, 0.0654, 0.0821, 0.0777, 0.0963, 0.0800, 0.1099],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,824][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([2.4030e-04, 1.7835e-01, 4.6554e-02, 7.9877e-02, 6.7005e-03, 9.3749e-02,
        4.8565e-01, 4.1563e-02, 2.0800e-02, 2.8816e-03, 9.3994e-03, 2.9321e-02,
        7.0730e-04, 3.9222e-03, 7.2998e-05, 2.0690e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:50,828][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0770, 0.1053, 0.0594, 0.0378, 0.0294, 0.0572, 0.0160, 0.0317, 0.1524,
        0.0164, 0.2194, 0.0301, 0.0193, 0.0361, 0.0300, 0.0700, 0.0125],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,828][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1131, 0.0724, 0.0262, 0.0424, 0.0514, 0.0610, 0.0144, 0.1398, 0.0482,
        0.1195, 0.0294, 0.0221, 0.0618, 0.0422, 0.0620, 0.0795, 0.0147],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,829][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1179, 0.0780, 0.0105, 0.0179, 0.0274, 0.0147, 0.0326, 0.0366, 0.1045,
        0.0534, 0.0400, 0.0570, 0.0430, 0.1073, 0.0987, 0.0661, 0.0944],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,829][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0084, 0.0640, 0.0635, 0.0595, 0.0616, 0.0587, 0.0599, 0.0655, 0.0605,
        0.0644, 0.0636, 0.0602, 0.0633, 0.0591, 0.0652, 0.0621, 0.0605],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,829][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0080, 0.0733, 0.0353, 0.0769, 0.0535, 0.0436, 0.0453, 0.0523, 0.1005,
        0.0473, 0.0502, 0.0534, 0.0531, 0.0990, 0.0556, 0.0735, 0.0791],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,830][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0453, 0.0406, 0.0379, 0.0796, 0.0520, 0.0251, 0.0206, 0.0539, 0.0645,
        0.0765, 0.0329, 0.0556, 0.1747, 0.0861, 0.0955, 0.0362, 0.0231],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,830][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0349, 0.0312, 0.0698, 0.0600, 0.0460, 0.0578, 0.0526, 0.0736, 0.0880,
        0.0631, 0.0842, 0.0705, 0.0524, 0.0737, 0.0446, 0.0492, 0.0483],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,834][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0069, 0.0606, 0.0623, 0.0610, 0.0607, 0.0560, 0.0598, 0.0642, 0.0648,
        0.0663, 0.0631, 0.0612, 0.0653, 0.0587, 0.0652, 0.0640, 0.0601],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,834][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2683, 0.0699, 0.0496, 0.0664, 0.0569, 0.0559, 0.0491, 0.0314, 0.0541,
        0.0204, 0.0422, 0.0437, 0.0323, 0.0444, 0.0226, 0.0400, 0.0527],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,835][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0078, 0.0650, 0.0582, 0.0653, 0.0562, 0.0589, 0.0604, 0.0647, 0.0717,
        0.0607, 0.0623, 0.0627, 0.0632, 0.0634, 0.0586, 0.0595, 0.0613],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,835][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0108, 0.0333, 0.0331, 0.0402, 0.0456, 0.0500, 0.0521, 0.0619, 0.0612,
        0.0643, 0.0600, 0.0741, 0.0711, 0.0830, 0.0730, 0.0966, 0.0899],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,836][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.3880e-04, 1.5063e-01, 3.9643e-02, 8.2386e-02, 5.9258e-03, 9.7622e-02,
        5.1562e-01, 4.2760e-02, 2.0566e-02, 2.1257e-03, 8.2546e-03, 2.7053e-02,
        6.4095e-04, 3.3723e-03, 5.1349e-05, 1.8857e-04, 2.2173e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:50,836][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0075, 0.0364, 0.0447, 0.0287, 0.0096, 0.0158, 0.0184, 0.0060, 0.2034,
        0.0042, 0.5509, 0.0148, 0.0046, 0.0140, 0.0096, 0.0068, 0.0141, 0.0106],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,836][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0819, 0.0540, 0.0511, 0.0533, 0.0321, 0.0813, 0.0318, 0.1092, 0.1003,
        0.0519, 0.0492, 0.0486, 0.0782, 0.0466, 0.0340, 0.0565, 0.0309, 0.0090],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,840][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1362, 0.0528, 0.0063, 0.0104, 0.0191, 0.0104, 0.0238, 0.0323, 0.0943,
        0.0479, 0.0340, 0.0446, 0.0396, 0.0881, 0.0899, 0.0617, 0.0885, 0.1202],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,841][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0083, 0.0613, 0.0606, 0.0568, 0.0584, 0.0561, 0.0573, 0.0619, 0.0568,
        0.0608, 0.0596, 0.0568, 0.0592, 0.0555, 0.0611, 0.0580, 0.0565, 0.0550],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,841][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0064, 0.0704, 0.0309, 0.0739, 0.0504, 0.0400, 0.0418, 0.0481, 0.0990,
        0.0435, 0.0461, 0.0486, 0.0481, 0.0932, 0.0515, 0.0677, 0.0732, 0.0671],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,841][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0382, 0.0656, 0.0516, 0.1145, 0.0614, 0.0168, 0.0205, 0.0352, 0.0753,
        0.0433, 0.0505, 0.0295, 0.0971, 0.0756, 0.1009, 0.0193, 0.0209, 0.0836],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,842][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0304, 0.0272, 0.0611, 0.0565, 0.0426, 0.0541, 0.0554, 0.0705, 0.0850,
        0.0605, 0.0859, 0.0676, 0.0500, 0.0717, 0.0401, 0.0437, 0.0466, 0.0511],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,842][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0064, 0.0574, 0.0590, 0.0575, 0.0572, 0.0527, 0.0564, 0.0606, 0.0612,
        0.0627, 0.0594, 0.0575, 0.0616, 0.0553, 0.0616, 0.0603, 0.0564, 0.0569],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,843][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.3159, 0.0695, 0.0488, 0.0606, 0.0602, 0.0501, 0.0441, 0.0263, 0.0479,
        0.0176, 0.0359, 0.0366, 0.0280, 0.0351, 0.0204, 0.0348, 0.0450, 0.0234],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,847][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0070, 0.0619, 0.0546, 0.0617, 0.0527, 0.0555, 0.0568, 0.0614, 0.0683,
        0.0574, 0.0587, 0.0593, 0.0599, 0.0597, 0.0552, 0.0561, 0.0577, 0.0563],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,847][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0104, 0.0299, 0.0310, 0.0356, 0.0416, 0.0422, 0.0465, 0.0559, 0.0550,
        0.0608, 0.0517, 0.0671, 0.0659, 0.0739, 0.0676, 0.0859, 0.0819, 0.0972],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,847][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([3.5356e-04, 2.3842e-01, 4.2849e-02, 9.2947e-02, 4.8944e-03, 8.4483e-02,
        4.4336e-01, 3.5347e-02, 1.8120e-02, 1.9201e-03, 7.3729e-03, 2.4329e-02,
        4.6294e-04, 3.0367e-03, 3.5513e-05, 1.3835e-04, 1.8789e-03, 4.9228e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:50,848][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0739, 0.0398, 0.0401, 0.0175, 0.0633, 0.0396, 0.0723, 0.0533, 0.0523,
        0.0393, 0.0597, 0.0825, 0.0309, 0.0142, 0.0676, 0.0797, 0.0641, 0.1038,
        0.0060], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,848][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0862, 0.0275, 0.0221, 0.0198, 0.0667, 0.0228, 0.0257, 0.1318, 0.0212,
        0.2111, 0.0177, 0.0262, 0.0909, 0.0233, 0.0735, 0.0220, 0.0280, 0.0686,
        0.0149], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,848][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0509, 0.0576, 0.0190, 0.0233, 0.0353, 0.0207, 0.0389, 0.0388, 0.0650,
        0.0514, 0.0421, 0.0577, 0.0440, 0.0768, 0.0794, 0.0549, 0.0714, 0.0888,
        0.0839], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,849][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0119, 0.0587, 0.0569, 0.0533, 0.0548, 0.0519, 0.0533, 0.0573, 0.0528,
        0.0562, 0.0553, 0.0531, 0.0555, 0.0526, 0.0576, 0.0553, 0.0544, 0.0532,
        0.0559], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,853][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0100, 0.0572, 0.0343, 0.0620, 0.0481, 0.0387, 0.0412, 0.0443, 0.0733,
        0.0417, 0.0431, 0.0460, 0.0467, 0.0774, 0.0500, 0.0605, 0.0649, 0.0620,
        0.0987], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,853][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0790, 0.0302, 0.0245, 0.0751, 0.0428, 0.0168, 0.0339, 0.0496, 0.0392,
        0.0594, 0.0208, 0.0521, 0.1525, 0.0376, 0.0710, 0.0171, 0.0386, 0.1433,
        0.0164], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,854][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0514, 0.0316, 0.0672, 0.0534, 0.0421, 0.0504, 0.0474, 0.0594, 0.0764,
        0.0493, 0.0724, 0.0597, 0.0436, 0.0636, 0.0396, 0.0433, 0.0440, 0.0450,
        0.0600], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,854][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0084, 0.0545, 0.0558, 0.0545, 0.0541, 0.0501, 0.0533, 0.0567, 0.0570,
        0.0583, 0.0557, 0.0545, 0.0578, 0.0526, 0.0577, 0.0570, 0.0539, 0.0544,
        0.0538], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,854][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2283, 0.0654, 0.0450, 0.0609, 0.0496, 0.0527, 0.0453, 0.0306, 0.0522,
        0.0197, 0.0409, 0.0426, 0.0308, 0.0425, 0.0206, 0.0379, 0.0501, 0.0254,
        0.0597], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,855][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0088, 0.0580, 0.0525, 0.0581, 0.0505, 0.0523, 0.0538, 0.0567, 0.0624,
        0.0536, 0.0551, 0.0553, 0.0554, 0.0560, 0.0517, 0.0527, 0.0542, 0.0528,
        0.0600], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,855][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0122, 0.0297, 0.0296, 0.0371, 0.0420, 0.0418, 0.0438, 0.0531, 0.0531,
        0.0530, 0.0488, 0.0617, 0.0568, 0.0671, 0.0586, 0.0748, 0.0722, 0.0800,
        0.0846], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,857][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.4870e-03, 1.5877e-01, 4.4606e-02, 8.8614e-02, 6.5811e-03, 9.7767e-02,
        4.9413e-01, 4.6010e-02, 2.0440e-02, 1.9259e-03, 8.1138e-03, 2.2465e-02,
        6.4149e-04, 2.7646e-03, 4.6861e-05, 1.9330e-04, 2.0096e-03, 7.8854e-05,
        3.5531e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:50,876][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:50,879][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,880][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,880][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,880][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,881][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,881][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,881][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,882][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,882][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,883][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,883][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,884][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:50,884][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9186e-04, 9.9901e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,884][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0988, 0.9012], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,885][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5042, 0.4958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,885][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3428, 0.6572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,885][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9850, 0.0150], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,886][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1697, 0.8303], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,886][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1917, 0.8083], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,886][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4239, 0.5761], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,887][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6470, 0.3530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,887][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2431, 0.7569], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,887][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9947, 0.0053], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,888][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.0000e+00, 8.3868e-09], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:50,888][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.0069, 0.2513, 0.7418], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,888][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0468, 0.4908, 0.4624], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,889][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.3452, 0.5977, 0.0571], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,889][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.1080, 0.3509, 0.5412], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,889][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([9.9703e-01, 2.6772e-03, 2.9697e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,890][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.0562, 0.4727, 0.4711], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,890][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0821, 0.5318, 0.3861], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,890][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.2620, 0.3637, 0.3742], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,891][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.4441, 0.2668, 0.2891], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,900][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.1574, 0.3462, 0.4964], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,900][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.9694, 0.0260, 0.0047], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,901][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([9.9964e-01, 4.0835e-08, 3.5881e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:50,901][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.2567e-05, 5.4489e-01, 3.9946e-01, 5.5640e-02], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,901][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0335, 0.3499, 0.3404, 0.2761], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,902][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0158, 0.8604, 0.1143, 0.0095], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,902][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1326, 0.2393, 0.4324, 0.1957], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,903][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9633, 0.0165, 0.0029, 0.0173], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,903][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0437, 0.3160, 0.2588, 0.3815], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,905][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0561, 0.3334, 0.3090, 0.3014], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,907][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1921, 0.2672, 0.2741, 0.2667], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,907][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3373, 0.2075, 0.2248, 0.2305], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,908][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0962, 0.2433, 0.3994, 0.2611], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,908][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9760, 0.0148, 0.0058, 0.0035], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,908][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.4022e-03, 1.1277e-11, 9.9627e-01, 1.3321e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:50,909][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0027, 0.0388, 0.2909, 0.0242, 0.6434], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,909][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0236, 0.2348, 0.2269, 0.2013, 0.3134], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,909][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.2204, 0.6418, 0.1069, 0.0056, 0.0253], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,909][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0510, 0.1612, 0.2654, 0.1985, 0.3239], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,913][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.9770, 0.0089, 0.0014, 0.0100, 0.0027], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,914][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0297, 0.2220, 0.2347, 0.3434, 0.1703], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,914][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0370, 0.2633, 0.2313, 0.2561, 0.2123], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,914][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1502, 0.2088, 0.2147, 0.2083, 0.2180], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,915][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.2836, 0.1646, 0.1788, 0.1846, 0.1884], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,915][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1035, 0.2075, 0.2610, 0.1959, 0.2320], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,915][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.9486, 0.0327, 0.0089, 0.0056, 0.0042], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,916][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([9.4546e-01, 7.2530e-15, 1.5352e-05, 2.6372e-06, 5.4522e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:50,916][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([5.7041e-05, 2.8177e-01, 2.0792e-01, 4.8156e-02, 4.2077e-01, 4.1327e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,920][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0189, 0.1923, 0.1626, 0.1398, 0.2287, 0.2577], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,920][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0139, 0.8450, 0.0920, 0.0120, 0.0281, 0.0090], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,920][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1026, 0.1269, 0.2600, 0.1298, 0.2929, 0.0878], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,921][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9671, 0.0114, 0.0017, 0.0130, 0.0032, 0.0036], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,921][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0315, 0.1707, 0.1719, 0.3275, 0.1473, 0.1511], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,921][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0349, 0.2083, 0.1858, 0.1966, 0.2211, 0.1534], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,922][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1258, 0.1718, 0.1764, 0.1715, 0.1783, 0.1761], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,922][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2453, 0.1382, 0.1523, 0.1566, 0.1582, 0.1493], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,922][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0659, 0.1484, 0.2280, 0.1586, 0.2254, 0.1736], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,924][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([9.7077e-01, 1.6564e-02, 4.9909e-03, 1.7980e-03, 5.3018e-04, 5.3431e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,926][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([3.4506e-05, 4.4516e-20, 1.7259e-06, 6.5109e-12, 6.7020e-01, 3.2976e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:50,927][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0009, 0.0119, 0.0829, 0.0073, 0.1485, 0.1412, 0.6074],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,927][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0162, 0.1458, 0.1184, 0.1110, 0.1734, 0.2000, 0.2351],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,927][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0846, 0.7110, 0.0979, 0.0170, 0.0383, 0.0134, 0.0378],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,928][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0660, 0.1374, 0.2034, 0.1465, 0.2492, 0.1125, 0.0851],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,928][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9760, 0.0078, 0.0010, 0.0098, 0.0020, 0.0021, 0.0013],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,928][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0178, 0.1683, 0.1364, 0.2189, 0.1224, 0.0993, 0.2369],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,929][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0279, 0.1793, 0.1588, 0.1732, 0.1787, 0.1471, 0.1350],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,930][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1079, 0.1435, 0.1480, 0.1437, 0.1505, 0.1480, 0.1585],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,933][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2168, 0.1167, 0.1285, 0.1333, 0.1368, 0.1270, 0.1408],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,933][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0682, 0.1389, 0.1799, 0.1380, 0.1760, 0.1454, 0.1535],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,933][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.8613e-01, 5.2370e-03, 1.7645e-03, 6.2060e-04, 4.9105e-04, 1.2879e-03,
        4.4670e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,934][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.9090e-07, 1.1937e-27, 9.8329e-15, 2.9193e-19, 1.0413e-09, 3.6752e-06,
        1.0000e+00], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:50,934][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0016, 0.0008, 0.0145, 0.0008, 0.0146, 0.0273, 0.1506, 0.7899],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,934][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0143, 0.1124, 0.0809, 0.0767, 0.1161, 0.1399, 0.1757, 0.2839],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,935][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.5148, 0.3204, 0.0457, 0.0084, 0.0352, 0.0076, 0.0270, 0.0409],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,935][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0737, 0.1172, 0.1705, 0.1455, 0.2324, 0.1180, 0.1072, 0.0355],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,937][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.9251, 0.0204, 0.0037, 0.0287, 0.0071, 0.0070, 0.0036, 0.0043],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,939][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0152, 0.1009, 0.0877, 0.1999, 0.0773, 0.0774, 0.2612, 0.1804],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,939][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0245, 0.1541, 0.1385, 0.1475, 0.1497, 0.1340, 0.1280, 0.1236],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,940][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0922, 0.1251, 0.1280, 0.1244, 0.1292, 0.1278, 0.1360, 0.1372],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,940][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1911, 0.1049, 0.1151, 0.1187, 0.1184, 0.1124, 0.1222, 0.1171],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,940][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0523, 0.1109, 0.1521, 0.1218, 0.1588, 0.1235, 0.1304, 0.1501],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,941][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([9.9455e-01, 1.8800e-03, 5.5032e-04, 3.9798e-04, 2.3508e-04, 2.5417e-04,
        1.7515e-03, 3.8069e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,941][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([7.0329e-11, 1.9482e-36, 1.3599e-22, 2.7474e-29, 2.2501e-18, 1.8331e-15,
        2.5618e-06, 1.0000e+00], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:50,941][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([5.7986e-05, 6.0516e-04, 1.7735e-02, 3.7242e-04, 3.5580e-02, 1.2354e-02,
        1.6695e-01, 6.4929e-01, 1.1706e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,945][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0101, 0.0837, 0.0725, 0.0627, 0.1104, 0.1211, 0.1519, 0.2686, 0.1189],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,946][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1047, 0.6530, 0.0607, 0.0165, 0.0394, 0.0155, 0.0309, 0.0569, 0.0224],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,946][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0477, 0.1001, 0.1782, 0.1013, 0.2504, 0.0964, 0.0917, 0.0548, 0.0793],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,946][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.6004, 0.0704, 0.0271, 0.0970, 0.0316, 0.0331, 0.0221, 0.0181, 0.1003],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,947][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0162, 0.0851, 0.0800, 0.1465, 0.0585, 0.0621, 0.2408, 0.1631, 0.1478],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,947][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0231, 0.1351, 0.1148, 0.1276, 0.1378, 0.1157, 0.1166, 0.1097, 0.1196],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,947][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0805, 0.1112, 0.1136, 0.1105, 0.1149, 0.1136, 0.1210, 0.1218, 0.1129],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,948][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.1596, 0.0953, 0.1026, 0.1054, 0.1058, 0.1011, 0.1090, 0.1060, 0.1151],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,952][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0534, 0.1001, 0.1341, 0.0948, 0.1239, 0.1018, 0.1063, 0.1414, 0.1442],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,952][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([9.8689e-01, 2.3451e-03, 6.8818e-04, 4.9066e-04, 3.0600e-04, 4.1407e-04,
        1.4575e-03, 3.1833e-04, 7.0887e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,952][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([2.3665e-17, 3.3399e-40, 4.3371e-27, 1.8190e-32, 3.2560e-22, 2.4660e-18,
        3.4146e-11, 1.0000e+00, 1.3116e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:50,953][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([7.5266e-04, 2.5061e-04, 1.7194e-03, 4.5523e-05, 2.1543e-03, 2.2005e-03,
        2.4819e-02, 2.0892e-01, 2.6480e-02, 7.3266e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,953][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0091, 0.0756, 0.0574, 0.0519, 0.0814, 0.0930, 0.1228, 0.2143, 0.1015,
        0.1930], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,953][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.4562, 0.2644, 0.0350, 0.0051, 0.0204, 0.0061, 0.0177, 0.0503, 0.0118,
        0.1330], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,954][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0354, 0.0843, 0.1781, 0.0960, 0.2152, 0.0727, 0.1144, 0.0340, 0.1042,
        0.0656], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,954][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.9003, 0.0161, 0.0023, 0.0211, 0.0039, 0.0047, 0.0024, 0.0030, 0.0399,
        0.0063], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,958][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0124, 0.0698, 0.0702, 0.1148, 0.0608, 0.0584, 0.1680, 0.1638, 0.2339,
        0.0479], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,958][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0163, 0.1218, 0.1049, 0.1173, 0.1245, 0.1060, 0.0994, 0.0970, 0.1176,
        0.0951], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,959][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0716, 0.0996, 0.1015, 0.0989, 0.1025, 0.1020, 0.1085, 0.1094, 0.1011,
        0.1050], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,959][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1490, 0.0838, 0.0913, 0.0940, 0.0935, 0.0897, 0.0967, 0.0937, 0.1027,
        0.1056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,959][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0561, 0.0955, 0.1074, 0.0875, 0.1088, 0.0894, 0.0945, 0.1148, 0.1344,
        0.1117], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,960][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([9.5468e-01, 1.3204e-02, 1.0410e-03, 3.1076e-03, 7.3643e-04, 6.2895e-04,
        3.7196e-03, 1.4891e-03, 1.7810e-02, 3.5816e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,960][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.5062e-12, 9.5942e-37, 1.2336e-24, 6.7341e-29, 1.8372e-20, 4.7663e-16,
        3.8430e-08, 9.9965e-01, 2.9726e-05, 3.1980e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:50,960][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.3289e-05, 1.2613e-04, 2.8733e-04, 1.8010e-05, 2.4611e-04, 2.2426e-04,
        4.0005e-03, 2.5980e-02, 1.2026e-02, 9.5417e-01, 2.8981e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,964][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0081, 0.0642, 0.0513, 0.0467, 0.0743, 0.0848, 0.1085, 0.1892, 0.0913,
        0.1755, 0.1061], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,965][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0580, 0.5530, 0.0651, 0.0178, 0.0380, 0.0161, 0.0348, 0.0396, 0.0199,
        0.1314, 0.0263], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,965][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0341, 0.0733, 0.1293, 0.0813, 0.2035, 0.0735, 0.0741, 0.0431, 0.0752,
        0.1686, 0.0439], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,966][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.8698, 0.0176, 0.0039, 0.0250, 0.0063, 0.0070, 0.0037, 0.0040, 0.0429,
        0.0078, 0.0119], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,966][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0124, 0.0695, 0.0483, 0.1395, 0.0660, 0.0498, 0.1890, 0.1363, 0.1602,
        0.0672, 0.0618], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,966][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0165, 0.1070, 0.0964, 0.1019, 0.1119, 0.0951, 0.0945, 0.0874, 0.1025,
        0.1037, 0.0831], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,967][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0660, 0.0897, 0.0921, 0.0896, 0.0934, 0.0924, 0.0986, 0.0988, 0.0917,
        0.0949, 0.0928], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,967][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1360, 0.0758, 0.0826, 0.0851, 0.0858, 0.0813, 0.0885, 0.0850, 0.0931,
        0.0956, 0.0912], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,971][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0376, 0.0771, 0.0999, 0.0742, 0.1026, 0.0792, 0.0842, 0.1026, 0.1187,
        0.1013, 0.1227], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,971][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([9.7079e-01, 6.1183e-03, 1.0296e-03, 1.0933e-03, 5.1846e-04, 7.2536e-04,
        2.1986e-03, 5.3507e-04, 7.1949e-03, 2.2732e-03, 7.5237e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,971][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([3.0145e-17, 7.5635e-40, 1.1686e-27, 9.4611e-32, 8.3838e-22, 1.1036e-17,
        2.5501e-10, 9.7953e-01, 1.1376e-06, 2.0463e-02, 9.3505e-07],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:50,972][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.2302e-04, 7.2680e-06, 9.5396e-05, 2.6679e-06, 1.7416e-04, 1.6679e-04,
        1.7425e-03, 2.9266e-02, 1.1976e-02, 4.4123e-01, 3.8410e-02, 4.7681e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,972][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0073, 0.0549, 0.0447, 0.0415, 0.0668, 0.0763, 0.0956, 0.1642, 0.0829,
        0.1589, 0.1012, 0.1058], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,973][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1014, 0.4664, 0.0585, 0.0122, 0.0285, 0.0115, 0.0303, 0.0429, 0.0222,
        0.1702, 0.0306, 0.0253], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,973][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0249, 0.0799, 0.1135, 0.0868, 0.1799, 0.0751, 0.0725, 0.0356, 0.0874,
        0.1275, 0.0596, 0.0573], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,973][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.9400, 0.0078, 0.0012, 0.0116, 0.0023, 0.0024, 0.0012, 0.0014, 0.0229,
        0.0026, 0.0042, 0.0023], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,977][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0077, 0.0679, 0.0546, 0.1086, 0.0460, 0.0419, 0.1459, 0.1270, 0.1445,
        0.0548, 0.0872, 0.1137], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,978][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0148, 0.0988, 0.0852, 0.0946, 0.0999, 0.0837, 0.0858, 0.0823, 0.0917,
        0.0922, 0.0828, 0.0882], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,978][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0609, 0.0820, 0.0842, 0.0817, 0.0852, 0.0841, 0.0896, 0.0901, 0.0837,
        0.0865, 0.0846, 0.0876], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,978][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1280, 0.0688, 0.0755, 0.0781, 0.0787, 0.0742, 0.0809, 0.0775, 0.0855,
        0.0874, 0.0837, 0.0817], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,979][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0478, 0.0709, 0.0824, 0.0621, 0.0854, 0.0665, 0.0733, 0.0910, 0.1045,
        0.0884, 0.1064, 0.1213], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,979][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.7922e-01, 2.1548e-03, 5.2587e-04, 5.2012e-04, 2.8847e-04, 5.7935e-04,
        1.8674e-03, 2.3108e-04, 6.7265e-03, 6.4930e-04, 4.1582e-03, 3.0812e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,979][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([6.6293e-13, 4.8513e-42, 6.1427e-28, 1.8687e-32, 1.0581e-22, 1.1645e-17,
        3.9546e-11, 9.9700e-01, 5.5516e-06, 2.2504e-03, 1.5735e-04, 5.9138e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:50,980][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([7.9590e-05, 1.1766e-06, 4.0424e-05, 8.5989e-07, 5.3444e-05, 2.3896e-05,
        1.1731e-03, 2.5309e-02, 3.4588e-03, 1.5202e-01, 1.3484e-02, 4.0472e-01,
        3.9963e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,983][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0085, 0.0489, 0.0400, 0.0363, 0.0579, 0.0647, 0.0849, 0.1453, 0.0709,
        0.1379, 0.0882, 0.0948, 0.1214], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,984][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.1733, 0.3498, 0.0683, 0.0111, 0.0333, 0.0151, 0.0447, 0.0425, 0.0223,
        0.1524, 0.0358, 0.0343, 0.0172], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,984][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.0350, 0.0646, 0.1043, 0.0726, 0.1543, 0.0514, 0.0905, 0.0350, 0.0714,
        0.0915, 0.0610, 0.0894, 0.0789], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,985][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.7977, 0.0234, 0.0059, 0.0375, 0.0107, 0.0103, 0.0048, 0.0062, 0.0549,
        0.0102, 0.0157, 0.0092, 0.0135], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,985][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0084, 0.0588, 0.0445, 0.1166, 0.0388, 0.0415, 0.1174, 0.0886, 0.2128,
        0.0323, 0.1168, 0.0968, 0.0266], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,985][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0110, 0.0927, 0.0759, 0.0873, 0.0894, 0.0797, 0.0783, 0.0741, 0.0897,
        0.0874, 0.0774, 0.0841, 0.0732], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,986][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0547, 0.0756, 0.0773, 0.0753, 0.0782, 0.0776, 0.0828, 0.0832, 0.0770,
        0.0798, 0.0780, 0.0809, 0.0794], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,988][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.1190, 0.0638, 0.0699, 0.0722, 0.0718, 0.0686, 0.0740, 0.0715, 0.0787,
        0.0807, 0.0775, 0.0752, 0.0770], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,990][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0389, 0.0655, 0.0739, 0.0610, 0.0790, 0.0610, 0.0666, 0.0773, 0.0959,
        0.0788, 0.1002, 0.1144, 0.0874], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,990][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([9.5473e-01, 5.4820e-03, 5.8389e-04, 1.3708e-03, 4.8463e-04, 4.0825e-04,
        3.7509e-03, 9.2979e-04, 1.0857e-02, 1.6630e-03, 1.0938e-02, 4.9974e-03,
        3.8014e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,991][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([5.6294e-11, 9.3467e-43, 1.7176e-29, 3.1395e-33, 9.3437e-25, 6.6910e-19,
        2.5468e-10, 3.6627e-01, 2.6635e-07, 1.7364e-04, 3.6317e-06, 5.3107e-03,
        6.2825e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:50,991][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([2.2136e-05, 4.2452e-05, 7.0845e-05, 1.7979e-06, 6.9055e-05, 5.2551e-05,
        8.4444e-04, 1.3232e-02, 2.4215e-03, 2.9343e-01, 4.9893e-03, 1.9758e-01,
        4.0403e-01, 8.3216e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,991][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0065, 0.0466, 0.0392, 0.0342, 0.0560, 0.0592, 0.0790, 0.1357, 0.0657,
        0.1312, 0.0830, 0.0883, 0.1160, 0.0595], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,992][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1509, 0.4266, 0.0561, 0.0099, 0.0265, 0.0096, 0.0229, 0.0344, 0.0182,
        0.1508, 0.0267, 0.0196, 0.0097, 0.0382], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,992][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0225, 0.0535, 0.1034, 0.0588, 0.1470, 0.0564, 0.0747, 0.0361, 0.0692,
        0.1190, 0.0392, 0.0705, 0.0948, 0.0548], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,994][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.8447, 0.0165, 0.0038, 0.0231, 0.0056, 0.0057, 0.0030, 0.0037, 0.0380,
        0.0061, 0.0100, 0.0056, 0.0090, 0.0253], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,996][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0113, 0.0564, 0.0501, 0.0852, 0.0505, 0.0377, 0.1568, 0.1025, 0.1144,
        0.0459, 0.0670, 0.1100, 0.0408, 0.0714], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,997][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0137, 0.0849, 0.0719, 0.0769, 0.0821, 0.0714, 0.0722, 0.0682, 0.0770,
        0.0764, 0.0690, 0.0758, 0.0758, 0.0847], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,997][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0509, 0.0703, 0.0720, 0.0699, 0.0727, 0.0719, 0.0765, 0.0769, 0.0714,
        0.0739, 0.0722, 0.0749, 0.0734, 0.0729], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,997][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1036, 0.0602, 0.0651, 0.0672, 0.0670, 0.0640, 0.0689, 0.0670, 0.0733,
        0.0752, 0.0718, 0.0703, 0.0720, 0.0745], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,998][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0367, 0.0581, 0.0683, 0.0507, 0.0685, 0.0546, 0.0616, 0.0796, 0.0868,
        0.0775, 0.0874, 0.0995, 0.0835, 0.0872], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,998][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([9.6255e-01, 4.1487e-03, 6.5875e-04, 4.7395e-04, 3.0270e-04, 1.1352e-03,
        2.0540e-03, 4.5353e-04, 7.4706e-03, 1.0741e-03, 4.9774e-03, 3.6854e-03,
        2.3965e-03, 8.6188e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,998][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([3.8535e-16, 7.6371e-43, 1.3343e-29, 9.8416e-36, 3.1479e-25, 3.6928e-22,
        7.4942e-13, 2.2064e-02, 7.6161e-09, 4.1187e-05, 8.7937e-08, 1.4451e-04,
        9.7775e-01, 8.6034e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:50,999][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([3.2950e-04, 1.0778e-06, 3.2970e-05, 5.3158e-07, 4.3141e-05, 8.9332e-06,
        1.1971e-03, 5.4676e-03, 1.8835e-03, 5.0920e-02, 3.6705e-03, 2.7230e-01,
        4.5450e-01, 9.4228e-02, 1.1542e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,004][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0053, 0.0401, 0.0327, 0.0317, 0.0477, 0.0566, 0.0723, 0.1199, 0.0626,
        0.1147, 0.0735, 0.0821, 0.1037, 0.0583, 0.0990], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,005][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.5967, 0.1453, 0.0323, 0.0023, 0.0085, 0.0028, 0.0091, 0.0130, 0.0068,
        0.0591, 0.0107, 0.0098, 0.0131, 0.0200, 0.0705], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,006][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0175, 0.0486, 0.0814, 0.0594, 0.1059, 0.0528, 0.0772, 0.0336, 0.0788,
        0.0672, 0.0730, 0.0613, 0.0848, 0.0595, 0.0991], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,006][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.8591, 0.0123, 0.0029, 0.0193, 0.0059, 0.0053, 0.0022, 0.0034, 0.0370,
        0.0048, 0.0088, 0.0044, 0.0073, 0.0214, 0.0060], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,006][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0058, 0.0451, 0.0418, 0.0641, 0.0320, 0.0452, 0.1162, 0.0911, 0.1714,
        0.0412, 0.0962, 0.0988, 0.0403, 0.0852, 0.0257], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,007][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0097, 0.0784, 0.0665, 0.0749, 0.0626, 0.0741, 0.0654, 0.0625, 0.0773,
        0.0709, 0.0672, 0.0712, 0.0711, 0.0830, 0.0652], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,007][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0469, 0.0644, 0.0661, 0.0643, 0.0671, 0.0664, 0.0712, 0.0711, 0.0659,
        0.0683, 0.0669, 0.0694, 0.0681, 0.0671, 0.0769], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,008][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1035, 0.0545, 0.0600, 0.0622, 0.0631, 0.0590, 0.0650, 0.0613, 0.0680,
        0.0689, 0.0665, 0.0652, 0.0662, 0.0688, 0.0678], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,008][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0434, 0.0572, 0.0547, 0.0491, 0.0597, 0.0508, 0.0548, 0.0672, 0.0820,
        0.0654, 0.0813, 0.0941, 0.0763, 0.0804, 0.0838], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,008][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.8993, 0.0094, 0.0021, 0.0024, 0.0011, 0.0045, 0.0079, 0.0014, 0.0129,
        0.0017, 0.0074, 0.0124, 0.0035, 0.0283, 0.0057], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,011][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([2.0552e-10, 2.9936e-38, 6.2745e-27, 1.1676e-30, 3.5861e-24, 5.9586e-18,
        3.4331e-10, 3.3749e-02, 1.2456e-06, 6.6951e-05, 8.2474e-06, 3.6352e-03,
        9.6170e-01, 8.1526e-04, 2.3241e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,012][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([5.0596e-04, 5.5609e-05, 1.4646e-04, 3.2819e-06, 1.6690e-04, 3.7454e-05,
        1.0319e-03, 6.8456e-03, 1.5764e-03, 6.2788e-02, 7.7839e-03, 2.0503e-01,
        2.0662e-01, 8.3848e-02, 2.1317e-01, 2.1040e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,013][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0056, 0.0416, 0.0315, 0.0275, 0.0440, 0.0502, 0.0660, 0.1097, 0.0531,
        0.1057, 0.0642, 0.0714, 0.0944, 0.0518, 0.0896, 0.0938],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,013][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0931, 0.3914, 0.0467, 0.0104, 0.0256, 0.0103, 0.0208, 0.0237, 0.0145,
        0.1088, 0.0260, 0.0172, 0.0152, 0.0463, 0.1069, 0.0431],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,013][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0213, 0.0485, 0.1044, 0.0458, 0.1384, 0.0422, 0.0516, 0.0278, 0.0595,
        0.0519, 0.0545, 0.0545, 0.0846, 0.0630, 0.1305, 0.0215],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,014][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.6637, 0.0290, 0.0089, 0.0496, 0.0139, 0.0130, 0.0066, 0.0078, 0.0613,
        0.0131, 0.0193, 0.0131, 0.0182, 0.0488, 0.0133, 0.0204],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,014][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0048, 0.0481, 0.0369, 0.0785, 0.0365, 0.0355, 0.1217, 0.0867, 0.1672,
        0.0314, 0.0765, 0.1014, 0.0332, 0.0933, 0.0299, 0.0183],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,015][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0104, 0.0732, 0.0650, 0.0695, 0.0725, 0.0614, 0.0611, 0.0592, 0.0688,
        0.0691, 0.0588, 0.0649, 0.0676, 0.0767, 0.0739, 0.0477],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,018][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0432, 0.0607, 0.0619, 0.0604, 0.0626, 0.0623, 0.0664, 0.0667, 0.0617,
        0.0640, 0.0625, 0.0649, 0.0636, 0.0629, 0.0716, 0.0645],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,019][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0917, 0.0523, 0.0567, 0.0582, 0.0581, 0.0557, 0.0600, 0.0586, 0.0640,
        0.0658, 0.0626, 0.0612, 0.0628, 0.0650, 0.0629, 0.0644],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,019][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0288, 0.0480, 0.0574, 0.0451, 0.0624, 0.0471, 0.0518, 0.0606, 0.0718,
        0.0621, 0.0749, 0.0858, 0.0709, 0.0740, 0.0848, 0.0745],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,019][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([9.5101e-01, 3.7848e-03, 6.7691e-04, 6.4483e-04, 2.1908e-04, 1.5133e-03,
        1.5873e-03, 6.1176e-04, 8.7460e-03, 1.0157e-03, 8.1100e-03, 3.1180e-03,
        3.1708e-03, 8.5148e-03, 1.2084e-03, 6.0657e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,020][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.2079e-16, 2.9176e-41, 3.9031e-28, 1.0428e-34, 3.3052e-23, 1.1887e-21,
        5.1246e-13, 6.6090e-03, 2.8223e-09, 7.8836e-06, 1.2185e-08, 4.1610e-05,
        9.9270e-01, 4.4136e-06, 6.3274e-04, 1.6930e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,020][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([4.4601e-05, 5.7084e-07, 1.9923e-05, 1.4426e-07, 1.3288e-05, 1.0617e-05,
        4.7339e-05, 7.7792e-04, 3.1815e-04, 1.9293e-02, 1.0305e-03, 1.7299e-02,
        4.8576e-02, 2.9664e-02, 3.0801e-02, 6.7567e-01, 1.7643e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,021][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0057, 0.0369, 0.0311, 0.0279, 0.0435, 0.0481, 0.0573, 0.0978, 0.0504,
        0.0948, 0.0615, 0.0648, 0.0844, 0.0483, 0.0814, 0.0891, 0.0769],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,024][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1115, 0.3639, 0.0502, 0.0100, 0.0211, 0.0082, 0.0197, 0.0273, 0.0173,
        0.1021, 0.0260, 0.0169, 0.0115, 0.0511, 0.0874, 0.0311, 0.0448],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,025][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0201, 0.0584, 0.0826, 0.0678, 0.1055, 0.0508, 0.0399, 0.0240, 0.0639,
        0.0836, 0.0557, 0.0444, 0.0777, 0.0647, 0.0950, 0.0333, 0.0325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,025][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6925, 0.0215, 0.0068, 0.0408, 0.0117, 0.0106, 0.0062, 0.0066, 0.0561,
        0.0108, 0.0189, 0.0115, 0.0156, 0.0442, 0.0122, 0.0160, 0.0179],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,026][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0039, 0.0543, 0.0430, 0.0746, 0.0446, 0.0345, 0.0842, 0.0909, 0.1227,
        0.0414, 0.0626, 0.0968, 0.0333, 0.0992, 0.0382, 0.0293, 0.0465],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,026][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0102, 0.0695, 0.0598, 0.0656, 0.0684, 0.0561, 0.0525, 0.0562, 0.0636,
        0.0613, 0.0581, 0.0633, 0.0657, 0.0739, 0.0712, 0.0511, 0.0535],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,026][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0416, 0.0565, 0.0580, 0.0564, 0.0588, 0.0580, 0.0619, 0.0621, 0.0576,
        0.0597, 0.0584, 0.0605, 0.0594, 0.0588, 0.0670, 0.0602, 0.0651],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,027][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0882, 0.0483, 0.0529, 0.0547, 0.0553, 0.0522, 0.0570, 0.0546, 0.0601,
        0.0613, 0.0587, 0.0575, 0.0587, 0.0608, 0.0597, 0.0602, 0.0596],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,031][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0299, 0.0467, 0.0512, 0.0407, 0.0536, 0.0426, 0.0473, 0.0576, 0.0668,
        0.0577, 0.0683, 0.0777, 0.0635, 0.0667, 0.0763, 0.0695, 0.0838],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,031][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.7076e-01, 1.8908e-03, 4.5913e-04, 2.9974e-04, 1.8915e-04, 4.8462e-04,
        1.3356e-03, 1.6457e-04, 5.0111e-03, 5.0155e-04, 3.0816e-03, 2.1090e-03,
        1.0607e-03, 4.6453e-03, 1.6624e-03, 2.0331e-03, 4.3134e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,032][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.4102e-11, 2.7339e-42, 8.4200e-29, 2.4379e-34, 2.9670e-24, 9.0418e-20,
        2.7888e-13, 1.6993e-02, 5.9208e-08, 1.8817e-05, 1.4319e-06, 7.6807e-06,
        6.1814e-01, 1.0274e-04, 4.0059e-05, 4.8800e-04, 3.6421e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,032][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([2.4476e-04, 1.2578e-06, 2.1541e-05, 1.4759e-07, 2.2585e-05, 4.3940e-06,
        1.3709e-04, 1.6018e-03, 2.9860e-04, 1.1176e-02, 1.9145e-03, 4.1560e-02,
        5.5477e-02, 1.8184e-02, 8.0867e-02, 2.0509e-01, 4.3491e-01, 1.4850e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,032][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0054, 0.0352, 0.0273, 0.0246, 0.0374, 0.0432, 0.0560, 0.0935, 0.0468,
        0.0907, 0.0581, 0.0612, 0.0778, 0.0426, 0.0750, 0.0854, 0.0755, 0.0642],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,033][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1081, 0.3225, 0.0360, 0.0054, 0.0219, 0.0054, 0.0152, 0.0244, 0.0075,
        0.1092, 0.0151, 0.0136, 0.0135, 0.0360, 0.1154, 0.0644, 0.0485, 0.0378],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,033][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0416, 0.0420, 0.0661, 0.0499, 0.0964, 0.0347, 0.0693, 0.0250, 0.0538,
        0.0568, 0.0469, 0.0655, 0.0717, 0.0465, 0.0824, 0.0296, 0.0611, 0.0607],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,037][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.7608, 0.0206, 0.0044, 0.0284, 0.0086, 0.0078, 0.0044, 0.0046, 0.0466,
        0.0079, 0.0137, 0.0075, 0.0110, 0.0294, 0.0085, 0.0109, 0.0126, 0.0123],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,038][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0041, 0.0493, 0.0430, 0.0811, 0.0437, 0.0279, 0.0819, 0.0825, 0.1580,
        0.0268, 0.0857, 0.0733, 0.0287, 0.0894, 0.0374, 0.0209, 0.0449, 0.0214],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,038][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0080, 0.0660, 0.0531, 0.0617, 0.0662, 0.0576, 0.0547, 0.0502, 0.0614,
        0.0593, 0.0544, 0.0562, 0.0578, 0.0672, 0.0664, 0.0497, 0.0547, 0.0555],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,038][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0380, 0.0526, 0.0539, 0.0526, 0.0549, 0.0544, 0.0584, 0.0583, 0.0539,
        0.0561, 0.0549, 0.0568, 0.0559, 0.0549, 0.0631, 0.0566, 0.0612, 0.0634],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,039][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0837, 0.0457, 0.0500, 0.0517, 0.0522, 0.0493, 0.0537, 0.0516, 0.0568,
        0.0577, 0.0555, 0.0543, 0.0553, 0.0572, 0.0560, 0.0567, 0.0561, 0.0567],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,039][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0319, 0.0395, 0.0382, 0.0324, 0.0424, 0.0353, 0.0410, 0.0518, 0.0618,
        0.0534, 0.0635, 0.0743, 0.0630, 0.0647, 0.0727, 0.0679, 0.0846, 0.0816],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,040][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([9.0522e-01, 8.5845e-03, 8.1070e-04, 1.1347e-03, 6.6839e-04, 4.9265e-04,
        4.0518e-03, 7.2307e-04, 6.2393e-03, 1.2191e-03, 5.7314e-03, 4.8662e-03,
        5.1994e-03, 2.0995e-02, 4.1912e-03, 2.9390e-03, 1.4460e-02, 1.2475e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,041][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([4.9857e-13, 4.3440e-44, 2.6135e-32, 1.5018e-36, 4.8102e-28, 3.0651e-23,
        1.7120e-12, 1.1640e-04, 6.5211e-11, 2.7354e-08, 4.4443e-10, 4.6905e-06,
        2.9371e-04, 4.2802e-08, 1.4471e-07, 7.8236e-08, 9.9958e-01, 9.1099e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,044][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.0014e-04, 2.3520e-06, 1.0418e-05, 8.9234e-08, 7.1013e-06, 2.6663e-06,
        7.5830e-05, 7.6228e-04, 1.2153e-04, 2.6121e-02, 2.1003e-04, 1.9567e-02,
        3.5230e-02, 1.3403e-02, 1.8359e-02, 2.7126e-01, 2.0135e-01, 9.8746e-02,
        3.1447e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,044][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0046, 0.0345, 0.0272, 0.0243, 0.0373, 0.0422, 0.0523, 0.0880, 0.0448,
        0.0847, 0.0545, 0.0565, 0.0727, 0.0403, 0.0704, 0.0782, 0.0680, 0.0583,
        0.0611], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,044][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1429, 0.3248, 0.0401, 0.0094, 0.0168, 0.0080, 0.0175, 0.0270, 0.0178,
        0.0750, 0.0263, 0.0156, 0.0108, 0.0406, 0.0612, 0.0305, 0.0406, 0.0438,
        0.0512], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,045][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0156, 0.0443, 0.0655, 0.0448, 0.1009, 0.0411, 0.0494, 0.0225, 0.0591,
        0.0838, 0.0350, 0.0472, 0.0739, 0.0457, 0.0954, 0.0302, 0.0424, 0.0749,
        0.0286], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,045][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2019, 0.0510, 0.0310, 0.0780, 0.0374, 0.0291, 0.0213, 0.0191, 0.0625,
        0.0300, 0.0355, 0.0375, 0.0370, 0.0804, 0.0413, 0.0350, 0.0420, 0.0402,
        0.0898], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,046][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0062, 0.0432, 0.0314, 0.0756, 0.0417, 0.0259, 0.1085, 0.0877, 0.1093,
        0.0465, 0.0478, 0.0858, 0.0411, 0.0744, 0.0354, 0.0210, 0.0597, 0.0416,
        0.0172], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,046][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0099, 0.0615, 0.0530, 0.0578, 0.0585, 0.0516, 0.0503, 0.0479, 0.0559,
        0.0554, 0.0530, 0.0551, 0.0564, 0.0616, 0.0589, 0.0464, 0.0508, 0.0635,
        0.0524], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,050][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0364, 0.0502, 0.0515, 0.0500, 0.0521, 0.0516, 0.0550, 0.0551, 0.0512,
        0.0530, 0.0518, 0.0537, 0.0527, 0.0522, 0.0593, 0.0534, 0.0577, 0.0594,
        0.0539], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,050][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0754, 0.0439, 0.0476, 0.0490, 0.0490, 0.0468, 0.0505, 0.0491, 0.0536,
        0.0551, 0.0525, 0.0514, 0.0527, 0.0544, 0.0530, 0.0539, 0.0531, 0.0536,
        0.0555], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,051][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0236, 0.0351, 0.0422, 0.0309, 0.0440, 0.0344, 0.0391, 0.0512, 0.0552,
        0.0517, 0.0588, 0.0666, 0.0574, 0.0569, 0.0702, 0.0607, 0.0736, 0.0741,
        0.0740], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,051][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.7019e-01, 1.7402e-03, 2.8472e-04, 2.7999e-04, 1.8217e-04, 2.9531e-04,
        1.2989e-03, 2.4531e-04, 2.5596e-03, 4.4476e-04, 2.5069e-03, 1.6911e-03,
        8.8140e-04, 3.9044e-03, 1.0999e-03, 7.1059e-04, 3.9214e-03, 3.5646e-04,
        7.4024e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,051][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.0026e-10, 2.6457e-42, 1.3789e-28, 1.5003e-36, 1.5363e-24, 2.3277e-22,
        6.9556e-13, 6.6930e-03, 7.5258e-11, 1.9328e-06, 9.6072e-10, 5.2002e-06,
        3.2404e-01, 5.7169e-07, 2.0473e-05, 7.0266e-07, 1.3821e-01, 7.0884e-02,
        4.6015e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,052][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:51,054][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13254],
        [ 5777],
        [  154],
        [ 2554],
        [ 1462],
        [ 1755],
        [ 2215],
        [ 2344],
        [ 4549],
        [ 6383],
        [ 7888],
        [ 5063],
        [ 3899],
        [ 1200],
        [ 1864],
        [  499],
        [ 3874],
        [ 2072],
        [ 5262]], device='cuda:0')
[2024-07-24 10:19:51,056][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13318],
        [ 9415],
        [ 2133],
        [ 8037],
        [ 8498],
        [ 3851],
        [11057],
        [ 5090],
        [ 2862],
        [18931],
        [16267],
        [19993],
        [13231],
        [ 3893],
        [ 7612],
        [ 4611],
        [13316],
        [ 4904],
        [ 5509]], device='cuda:0')
[2024-07-24 10:19:51,058][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3649],
        [21848],
        [36031],
        [31201],
        [38508],
        [39221],
        [38433],
        [41109],
        [40573],
        [42335],
        [43639],
        [40191],
        [39869],
        [41505],
        [41639],
        [41859],
        [41505],
        [39416],
        [44754]], device='cuda:0')
[2024-07-24 10:19:51,059][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[47125],
        [43110],
        [28366],
        [28984],
        [30347],
        [33224],
        [32359],
        [33482],
        [40209],
        [37804],
        [36957],
        [35674],
        [35272],
        [32706],
        [34696],
        [29560],
        [32152],
        [29679],
        [29166]], device='cuda:0')
[2024-07-24 10:19:51,060][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2158],
        [1338],
        [1312],
        [ 993],
        [1308],
        [1327],
        [1378],
        [1446],
        [2223],
        [1702],
        [2098],
        [2360],
        [2477],
        [3692],
        [4140],
        [4687],
        [5422],
        [6270],
        [6286]], device='cuda:0')
[2024-07-24 10:19:51,062][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12390],
        [11889],
        [11567],
        [11439],
        [10854],
        [10667],
        [10402],
        [ 9971],
        [ 9935],
        [ 9742],
        [ 9715],
        [ 9669],
        [ 9523],
        [ 9190],
        [ 9056],
        [ 8847],
        [ 8702],
        [ 8692],
        [ 8683]], device='cuda:0')
[2024-07-24 10:19:51,065][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[33819],
        [32556],
        [31058],
        [27676],
        [25113],
        [26165],
        [25437],
        [26716],
        [28201],
        [28490],
        [28755],
        [28847],
        [28569],
        [28245],
        [27616],
        [27503],
        [27075],
        [26525],
        [27045]], device='cuda:0')
[2024-07-24 10:19:51,066][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[21455],
        [35799],
        [32688],
        [34562],
        [33562],
        [32617],
        [32535],
        [35258],
        [34803],
        [33691],
        [35019],
        [32053],
        [28373],
        [25384],
        [25189],
        [24944],
        [24230],
        [27257],
        [26874]], device='cuda:0')
[2024-07-24 10:19:51,067][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18878],
        [23029],
        [23602],
        [24186],
        [24240],
        [25109],
        [25505],
        [25833],
        [26360],
        [25843],
        [25565],
        [25553],
        [24828],
        [24828],
        [24585],
        [24575],
        [24445],
        [23975],
        [23884]], device='cuda:0')
[2024-07-24 10:19:51,068][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[46232],
        [41930],
        [40865],
        [41030],
        [41310],
        [41569],
        [41667],
        [41845],
        [42161],
        [42194],
        [42288],
        [42277],
        [42219],
        [42134],
        [42026],
        [41967],
        [41879],
        [41726],
        [41766]], device='cuda:0')
[2024-07-24 10:19:51,071][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11015],
        [10891],
        [11460],
        [10677],
        [10930],
        [11133],
        [10932],
        [10901],
        [10710],
        [10769],
        [10772],
        [10873],
        [11122],
        [11334],
        [11392],
        [11720],
        [11838],
        [11870],
        [12542]], device='cuda:0')
[2024-07-24 10:19:51,073][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[47131],
        [47022],
        [47300],
        [47482],
        [47419],
        [47465],
        [47356],
        [47463],
        [47590],
        [47592],
        [47582],
        [47588],
        [47520],
        [47458],
        [47400],
        [47394],
        [47371],
        [47304],
        [47354]], device='cuda:0')
[2024-07-24 10:19:51,074][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27703],
        [13769],
        [12455],
        [ 9561],
        [ 8849],
        [ 7529],
        [ 7276],
        [ 7536],
        [ 7328],
        [ 7705],
        [ 7064],
        [ 6726],
        [ 6746],
        [ 6277],
        [ 6469],
        [ 6287],
        [ 6306],
        [ 6429],
        [ 6255]], device='cuda:0')
[2024-07-24 10:19:51,075][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[823],
        [795],
        [765],
        [736],
        [743],
        [648],
        [520],
        [559],
        [533],
        [555],
        [536],
        [539],
        [567],
        [541],
        [550],
        [550],
        [546],
        [563],
        [542]], device='cuda:0')
[2024-07-24 10:19:51,077][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25188],
        [30993],
        [12311],
        [21745],
        [20834],
        [12070],
        [10369],
        [23089],
        [29322],
        [ 8262],
        [15741],
        [ 7134],
        [14200],
        [ 7641],
        [17774],
        [ 1365],
        [ 5723],
        [16247],
        [25895]], device='cuda:0')
[2024-07-24 10:19:51,080][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9250],
        [24547],
        [ 9894],
        [16276],
        [ 7847],
        [10698],
        [ 4736],
        [ 1921],
        [ 2329],
        [ 4408],
        [ 8513],
        [ 3492],
        [ 2936],
        [ 3372],
        [ 4789],
        [ 6816],
        [24618],
        [ 6829],
        [15124]], device='cuda:0')
[2024-07-24 10:19:51,081][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[32856],
        [45484],
        [44475],
        [44657],
        [44453],
        [44903],
        [44343],
        [42977],
        [42506],
        [42481],
        [42450],
        [42399],
        [42396],
        [42395],
        [42429],
        [42372],
        [42391],
        [42251],
        [42180]], device='cuda:0')
[2024-07-24 10:19:51,082][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14159],
        [24584],
        [23371],
        [24260],
        [21778],
        [24120],
        [23084],
        [18399],
        [23154],
        [15667],
        [20796],
        [19397],
        [17337],
        [19259],
        [11068],
        [16011],
        [16576],
        [14794],
        [17468]], device='cuda:0')
[2024-07-24 10:19:51,083][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8317],
        [11328],
        [14087],
        [13047],
        [11130],
        [11491],
        [11868],
        [12055],
        [12688],
        [13439],
        [13580],
        [14115],
        [15816],
        [16373],
        [15868],
        [15288],
        [15500],
        [16722],
        [16625]], device='cuda:0')
[2024-07-24 10:19:51,085][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18648],
        [17651],
        [18465],
        [17129],
        [17643],
        [17308],
        [17592],
        [16115],
        [ 8800],
        [14335],
        [13324],
        [15672],
        [10939],
        [11403],
        [11811],
        [ 6552],
        [ 6556],
        [ 7918],
        [ 3281]], device='cuda:0')
[2024-07-24 10:19:51,087][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18493],
        [ 9002],
        [ 7521],
        [ 7366],
        [ 6985],
        [ 7620],
        [ 6054],
        [ 4067],
        [ 4165],
        [ 4162],
        [ 4424],
        [ 4631],
        [ 5227],
        [ 4473],
        [ 4776],
        [ 4645],
        [ 4375],
        [ 4564],
        [ 4141]], device='cuda:0')
[2024-07-24 10:19:51,088][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[39657],
        [38520],
        [37455],
        [37140],
        [37145],
        [38896],
        [39568],
        [39427],
        [39643],
        [40003],
        [40015],
        [39874],
        [40033],
        [39873],
        [39854],
        [39913],
        [39984],
        [40231],
        [40148]], device='cuda:0')
[2024-07-24 10:19:51,089][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22687],
        [20793],
        [20572],
        [20388],
        [20163],
        [19907],
        [19838],
        [19704],
        [19643],
        [19473],
        [19430],
        [19399],
        [19309],
        [19364],
        [19310],
        [19260],
        [19291],
        [19296],
        [19305]], device='cuda:0')
[2024-07-24 10:19:51,091][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15232],
        [12019],
        [11590],
        [11487],
        [11346],
        [11249],
        [11147],
        [11115],
        [11000],
        [10930],
        [10932],
        [10898],
        [10775],
        [10761],
        [10786],
        [10905],
        [10938],
        [10901],
        [10910]], device='cuda:0')
[2024-07-24 10:19:51,094][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34519],
        [37598],
        [35398],
        [37137],
        [38280],
        [38177],
        [38409],
        [37415],
        [36989],
        [37052],
        [37124],
        [36873],
        [36926],
        [36879],
        [36267],
        [36235],
        [36216],
        [36115],
        [36208]], device='cuda:0')
[2024-07-24 10:19:51,095][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15996],
        [15947],
        [15903],
        [16122],
        [16379],
        [15923],
        [16409],
        [16194],
        [16446],
        [17119],
        [16720],
        [16763],
        [17364],
        [16750],
        [18217],
        [16728],
        [16862],
        [17448],
        [16823]], device='cuda:0')
[2024-07-24 10:19:51,096][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[41196],
        [41196],
        [41187],
        [16085],
        [40719],
        [35895],
        [45547],
        [32762],
        [32762],
        [32764],
        [32727],
        [32764],
        [30760],
        [26304],
        [26503],
        [26107],
        [30371],
        [37983],
        [31555]], device='cuda:0')
[2024-07-24 10:19:51,097][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28820],
        [24083],
        [27591],
        [29078],
        [29198],
        [27386],
        [28527],
        [34950],
        [34801],
        [32126],
        [29642],
        [32152],
        [32562],
        [32315],
        [32746],
        [32964],
        [28169],
        [31396],
        [30388]], device='cuda:0')
[2024-07-24 10:19:51,100][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[13389],
        [ 7572],
        [16850],
        [12082],
        [ 9063],
        [22785],
        [20030],
        [ 8747],
        [11052],
        [23411],
        [18410],
        [18518],
        [ 9492],
        [23059],
        [ 4845],
        [29883],
        [19129],
        [ 8219],
        [ 7411]], device='cuda:0')
[2024-07-24 10:19:51,102][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344],
        [8344]], device='cuda:0')
[2024-07-24 10:19:51,134][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:51,135][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,135][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,135][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,136][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,136][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,136][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,137][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,137][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,139][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,141][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,141][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,142][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,142][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5671, 0.4329], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,142][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0598, 0.9402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,143][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0293, 0.9707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,143][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0469, 0.9531], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,143][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6837, 0.3163], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,144][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1247, 0.8753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,146][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5005, 0.4995], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,148][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5742, 0.4258], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,148][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0818, 0.9182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,149][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5706, 0.4294], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,149][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,149][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2017, 0.7983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,150][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.3677, 0.3046, 0.3277], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,150][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0219, 0.4905, 0.4876], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,150][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.0152, 0.4887, 0.4961], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,152][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0249, 0.4947, 0.4804], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,155][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.4700, 0.3766, 0.1534], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,155][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0611, 0.5620, 0.3769], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,155][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.4256, 0.2763, 0.2981], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,156][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0581, 0.1755, 0.7664], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,156][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.0393, 0.4733, 0.4873], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,156][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.4067, 0.3022, 0.2912], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,157][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.9958, 0.0016, 0.0026], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,157][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.1281, 0.4018, 0.4700], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,157][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2374, 0.2355, 0.2510, 0.2761], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,161][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0086, 0.2079, 0.4321, 0.3514], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,161][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0086, 0.3209, 0.3306, 0.3399], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,161][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0159, 0.3274, 0.3202, 0.3365], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,162][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3827, 0.3222, 0.2274, 0.0677], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,162][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0454, 0.3714, 0.2632, 0.3199], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,162][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0262, 0.4716, 0.4719, 0.0303], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,163][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1493, 0.1856, 0.4595, 0.2055], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,163][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0181, 0.2338, 0.5307, 0.2173], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,163][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3225, 0.2382, 0.2294, 0.2099], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,163][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9836, 0.0061, 0.0074, 0.0029], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,167][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0792, 0.2860, 0.3406, 0.2942], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,168][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.2051, 0.1795, 0.1905, 0.2113, 0.2135], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,168][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0130, 0.1501, 0.1582, 0.2097, 0.4689], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,168][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0066, 0.2415, 0.2471, 0.2557, 0.2491], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,168][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0127, 0.2444, 0.2378, 0.2496, 0.2555], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,169][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.3808, 0.3380, 0.1414, 0.0641, 0.0758], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,169][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0314, 0.3007, 0.2033, 0.2536, 0.2110], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,169][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.3130, 0.1468, 0.3557, 0.0375, 0.1470], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,170][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0101, 0.0796, 0.3291, 0.2075, 0.3738], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,171][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0200, 0.2154, 0.3088, 0.2681, 0.1877], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,174][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.2642, 0.1952, 0.1867, 0.1713, 0.1826], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,174][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.9791, 0.0054, 0.0048, 0.0016, 0.0092], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,174][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0677, 0.2123, 0.2509, 0.2178, 0.2513], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,175][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1724, 0.1464, 0.1593, 0.1771, 0.1783, 0.1665], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,175][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0037, 0.1206, 0.1306, 0.1669, 0.2188, 0.3595], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,175][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0046, 0.1929, 0.1998, 0.2055, 0.2005, 0.1968], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,175][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0088, 0.1972, 0.1931, 0.2029, 0.2085, 0.1895], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,176][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2651, 0.3437, 0.1841, 0.0730, 0.0875, 0.0466], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,176][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0248, 0.2426, 0.1632, 0.2053, 0.1700, 0.1941], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,180][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0641, 0.1553, 0.4131, 0.0231, 0.2312, 0.1132], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,180][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0392, 0.1503, 0.2797, 0.2906, 0.1520, 0.0882], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,181][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0187, 0.1694, 0.2726, 0.1852, 0.2247, 0.1294], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,181][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2350, 0.1698, 0.1625, 0.1467, 0.1595, 0.1265], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,181][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.9848, 0.0018, 0.0038, 0.0011, 0.0050, 0.0035], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,182][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0552, 0.1712, 0.2013, 0.1765, 0.2011, 0.1948], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,182][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1586, 0.1247, 0.1339, 0.1519, 0.1501, 0.1434, 0.1375],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,182][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0052, 0.0963, 0.0762, 0.1458, 0.0978, 0.2013, 0.3775],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,182][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0038, 0.1601, 0.1669, 0.1711, 0.1679, 0.1645, 0.1657],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,186][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0071, 0.1622, 0.1594, 0.1684, 0.1724, 0.1576, 0.1728],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,187][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3474, 0.2756, 0.1550, 0.0627, 0.0811, 0.0439, 0.0344],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,187][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0217, 0.2070, 0.1384, 0.1730, 0.1438, 0.1639, 0.1522],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,187][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3760, 0.0430, 0.1589, 0.0116, 0.2024, 0.1735, 0.0345],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,188][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0551, 0.1232, 0.2965, 0.1492, 0.2074, 0.1090, 0.0596],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,188][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0149, 0.1404, 0.2458, 0.1666, 0.1974, 0.1654, 0.0696],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,188][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2158, 0.1527, 0.1457, 0.1318, 0.1426, 0.1127, 0.0986],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,189][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9525e-01, 4.2037e-04, 6.9952e-04, 2.2313e-04, 1.1785e-03, 9.2954e-04,
        1.3006e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,189][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0484, 0.1432, 0.1664, 0.1469, 0.1665, 0.1608, 0.1678],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,193][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.1380, 0.1090, 0.1182, 0.1333, 0.1326, 0.1258, 0.1212, 0.1221],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,193][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0013, 0.0217, 0.0302, 0.0239, 0.0377, 0.0418, 0.0869, 0.7564],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,193][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0038, 0.1356, 0.1404, 0.1441, 0.1406, 0.1393, 0.1410, 0.1552],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,194][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0070, 0.1392, 0.1364, 0.1432, 0.1464, 0.1336, 0.1466, 0.1477],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,194][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.3021, 0.2695, 0.1578, 0.0663, 0.0822, 0.0428, 0.0375, 0.0418],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,194][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0215, 0.1740, 0.1208, 0.1484, 0.1255, 0.1409, 0.1327, 0.1363],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,195][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([3.0707e-01, 5.5924e-03, 1.4956e-02, 5.2462e-04, 1.3088e-02, 2.1497e-02,
        1.5621e-02, 6.2165e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,195][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0485, 0.1149, 0.2134, 0.2307, 0.1551, 0.1116, 0.0844, 0.0414],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,195][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0152, 0.1226, 0.2081, 0.1702, 0.1427, 0.1546, 0.0931, 0.0935],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,199][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2039, 0.1426, 0.1348, 0.1211, 0.1312, 0.1024, 0.0892, 0.0749],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,202][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([9.9392e-01, 4.4485e-04, 1.3429e-03, 2.5283e-04, 1.3598e-03, 6.8831e-04,
        1.4068e-03, 5.8283e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,202][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0430, 0.1227, 0.1432, 0.1259, 0.1430, 0.1377, 0.1435, 0.1409],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,203][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.1139, 0.0985, 0.1061, 0.1186, 0.1180, 0.1114, 0.1070, 0.1087, 0.1178],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,203][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0049, 0.0549, 0.0660, 0.0878, 0.0713, 0.0760, 0.1374, 0.3080, 0.1938],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,203][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0033, 0.1181, 0.1217, 0.1245, 0.1212, 0.1193, 0.1207, 0.1339, 0.1372],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,204][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0056, 0.1207, 0.1182, 0.1246, 0.1268, 0.1162, 0.1269, 0.1284, 0.1325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,204][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1962, 0.2633, 0.1804, 0.0736, 0.0956, 0.0454, 0.0397, 0.0409, 0.0648],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,204][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0251, 0.1433, 0.1063, 0.1270, 0.1108, 0.1216, 0.1159, 0.1185, 0.1315],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,205][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([1.4506e-02, 2.1947e-03, 4.4295e-03, 2.8975e-04, 3.8678e-03, 3.8256e-03,
        4.5492e-03, 9.6263e-01, 3.7053e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,205][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0349, 0.0923, 0.2672, 0.1199, 0.1672, 0.0624, 0.0501, 0.0972, 0.1089],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,205][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0103, 0.1002, 0.2346, 0.0978, 0.1689, 0.1141, 0.0792, 0.1289, 0.0660],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,209][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1901, 0.1321, 0.1252, 0.1126, 0.1222, 0.0960, 0.0832, 0.0708, 0.0676],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,209][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.9571e-01, 4.4164e-04, 3.9393e-04, 1.6205e-04, 6.2949e-04, 4.1878e-04,
        6.5169e-04, 4.4408e-04, 1.1531e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,210][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0339, 0.1086, 0.1286, 0.1119, 0.1281, 0.1234, 0.1290, 0.1254, 0.1110],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,210][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1003, 0.0895, 0.0955, 0.1056, 0.1058, 0.0992, 0.0953, 0.0971, 0.1050,
        0.1066], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,210][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0066, 0.0329, 0.0091, 0.0222, 0.0058, 0.0082, 0.0193, 0.0143, 0.0270,
        0.8545], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,211][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0027, 0.1026, 0.1058, 0.1093, 0.1055, 0.1058, 0.1068, 0.1183, 0.1218,
        0.1213], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,211][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0045, 0.1079, 0.1052, 0.1110, 0.1133, 0.1036, 0.1140, 0.1149, 0.1199,
        0.1055], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,211][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.3118, 0.2307, 0.1251, 0.0590, 0.0661, 0.0376, 0.0333, 0.0396, 0.0672,
        0.0296], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,212][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0149, 0.1385, 0.0925, 0.1156, 0.0968, 0.1092, 0.1022, 0.1057, 0.1234,
        0.1012], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,216][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([1.8405e-02, 1.4652e-03, 2.2818e-03, 1.8729e-04, 1.5287e-03, 7.0244e-03,
        8.6368e-03, 8.7545e-01, 1.3219e-02, 7.1801e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,216][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0201, 0.0649, 0.2121, 0.1635, 0.1140, 0.0334, 0.2101, 0.0279, 0.1346,
        0.0194], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,216][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0106, 0.0951, 0.1756, 0.1164, 0.1274, 0.1249, 0.0800, 0.0882, 0.1025,
        0.0794], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,217][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1750, 0.1237, 0.1165, 0.1059, 0.1137, 0.0893, 0.0778, 0.0661, 0.0641,
        0.0680], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,217][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([9.7972e-01, 2.3266e-03, 1.8062e-03, 5.2997e-04, 1.6707e-03, 3.8904e-03,
        2.8615e-03, 8.7829e-04, 5.5898e-03, 7.2410e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,217][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0342, 0.0969, 0.1116, 0.0987, 0.1116, 0.1078, 0.1123, 0.1098, 0.0982,
        0.1187], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,218][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0889, 0.0806, 0.0857, 0.0955, 0.0954, 0.0901, 0.0863, 0.0878, 0.0945,
        0.0957, 0.0996], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,218][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([8.0076e-04, 6.8463e-03, 4.1929e-03, 6.3548e-03, 3.4933e-03, 3.4213e-03,
        7.5780e-03, 2.3667e-02, 1.6322e-02, 8.6027e-01, 6.7054e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,220][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0022, 0.0924, 0.0959, 0.0981, 0.0958, 0.0940, 0.0950, 0.1065, 0.1089,
        0.1097, 0.1016], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,222][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0038, 0.0958, 0.0943, 0.1000, 0.1020, 0.0936, 0.1027, 0.1038, 0.1084,
        0.0958, 0.0997], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,222][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1967, 0.2610, 0.1563, 0.0674, 0.0781, 0.0388, 0.0330, 0.0374, 0.0641,
        0.0289, 0.0383], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,223][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0143, 0.1224, 0.0838, 0.1050, 0.0882, 0.0984, 0.0931, 0.0956, 0.1111,
        0.0924, 0.0957], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,223][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([4.3639e-02, 2.0247e-03, 2.3025e-03, 3.0539e-04, 4.5317e-03, 1.2299e-02,
        7.4168e-03, 4.9360e-01, 9.0452e-03, 4.1510e-01, 9.7344e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,223][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0131, 0.0597, 0.1483, 0.1427, 0.2287, 0.0697, 0.0894, 0.0730, 0.0976,
        0.0258, 0.0518], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,224][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0068, 0.0757, 0.1522, 0.0916, 0.1308, 0.1096, 0.0777, 0.1116, 0.0726,
        0.1222, 0.0492], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,224][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1621, 0.1151, 0.1090, 0.0986, 0.1064, 0.0837, 0.0732, 0.0623, 0.0601,
        0.0644, 0.0653], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,224][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.7694e-01, 8.6359e-04, 1.1864e-03, 4.6908e-04, 1.4187e-03, 1.3922e-03,
        1.9880e-03, 1.4206e-03, 3.3784e-03, 1.0680e-03, 9.8703e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,228][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0305, 0.0867, 0.1006, 0.0886, 0.1002, 0.0968, 0.1010, 0.0986, 0.0889,
        0.1070, 0.1011], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,229][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0903, 0.0714, 0.0775, 0.0867, 0.0858, 0.0813, 0.0779, 0.0797, 0.0865,
        0.0867, 0.0915, 0.0849], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,229][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.0163e-04, 2.8744e-03, 1.1316e-03, 2.0582e-03, 6.2768e-04, 1.0585e-03,
        4.1486e-03, 1.2355e-02, 6.8669e-03, 7.3845e-01, 3.5050e-02, 1.9528e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,229][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0019, 0.0836, 0.0867, 0.0890, 0.0864, 0.0854, 0.0864, 0.0966, 0.0989,
        0.0994, 0.0926, 0.0930], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,230][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0039, 0.0874, 0.0857, 0.0905, 0.0921, 0.0846, 0.0924, 0.0934, 0.0969,
        0.0864, 0.0898, 0.0970], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,230][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2048, 0.2458, 0.1537, 0.0592, 0.0769, 0.0358, 0.0303, 0.0359, 0.0599,
        0.0279, 0.0366, 0.0330], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,230][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0129, 0.1136, 0.0775, 0.0961, 0.0806, 0.0903, 0.0845, 0.0874, 0.1013,
        0.0839, 0.0877, 0.0843], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,231][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([3.2093e-02, 3.8164e-04, 1.0558e-03, 1.0209e-04, 1.4985e-03, 3.8160e-03,
        2.3710e-03, 6.2679e-01, 1.4368e-02, 2.6311e-01, 4.0028e-02, 1.4384e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,235][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0334, 0.0830, 0.1329, 0.1224, 0.1218, 0.0549, 0.0349, 0.0485, 0.1928,
        0.0282, 0.0679, 0.0793], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,235][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0089, 0.0819, 0.1318, 0.0925, 0.0985, 0.1011, 0.0587, 0.1059, 0.0785,
        0.1192, 0.0766, 0.0464], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,235][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1639, 0.1124, 0.1053, 0.0946, 0.1023, 0.0789, 0.0680, 0.0568, 0.0548,
        0.0587, 0.0597, 0.0445], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,236][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9499e-01, 1.6673e-04, 2.3218e-04, 9.2127e-05, 3.2155e-04, 2.5026e-04,
        3.8716e-04, 3.0329e-04, 6.6579e-04, 1.4140e-04, 1.9003e-03, 5.4866e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,236][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0283, 0.0783, 0.0906, 0.0804, 0.0906, 0.0878, 0.0915, 0.0894, 0.0804,
        0.0965, 0.0905, 0.0957], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,236][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0785, 0.0657, 0.0715, 0.0798, 0.0803, 0.0751, 0.0724, 0.0737, 0.0805,
        0.0809, 0.0854, 0.0793, 0.0768], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,237][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0027, 0.0272, 0.0066, 0.0182, 0.0037, 0.0046, 0.0223, 0.0125, 0.0185,
        0.5643, 0.0159, 0.0659, 0.2376], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,237][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0020, 0.0754, 0.0782, 0.0807, 0.0783, 0.0784, 0.0791, 0.0874, 0.0899,
        0.0900, 0.0847, 0.0853, 0.0906], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,241][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0037, 0.0799, 0.0784, 0.0822, 0.0839, 0.0767, 0.0840, 0.0850, 0.0882,
        0.0786, 0.0819, 0.0882, 0.0894], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,241][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.1496, 0.2635, 0.1448, 0.0679, 0.0701, 0.0379, 0.0308, 0.0364, 0.0656,
        0.0279, 0.0397, 0.0371, 0.0287], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,242][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0113, 0.1039, 0.0709, 0.0883, 0.0740, 0.0833, 0.0783, 0.0808, 0.0938,
        0.0777, 0.0805, 0.0773, 0.0798], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,242][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ office] are: tensor([5.5164e-02, 3.3779e-04, 7.2004e-04, 8.2231e-05, 1.0809e-03, 4.0753e-03,
        2.6296e-03, 4.2065e-01, 9.5752e-03, 2.3316e-01, 3.0650e-02, 2.6947e-02,
        2.1493e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,242][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0160, 0.0494, 0.1968, 0.1222, 0.1098, 0.0409, 0.0546, 0.0403, 0.1564,
        0.0165, 0.0723, 0.0854, 0.0395], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,243][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.0054, 0.0704, 0.0970, 0.0913, 0.0804, 0.1081, 0.0617, 0.0934, 0.0775,
        0.0968, 0.0662, 0.0621, 0.0895], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,243][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.1492, 0.1050, 0.0989, 0.0885, 0.0962, 0.0749, 0.0652, 0.0552, 0.0534,
        0.0569, 0.0581, 0.0438, 0.0548], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,243][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ office] are: tensor([9.8863e-01, 4.0415e-04, 4.7113e-04, 1.1694e-04, 4.3717e-04, 8.2352e-04,
        7.2383e-04, 3.0595e-04, 1.2518e-03, 1.3526e-04, 4.0862e-03, 1.0201e-03,
        1.5952e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,247][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0251, 0.0714, 0.0840, 0.0737, 0.0834, 0.0805, 0.0834, 0.0822, 0.0730,
        0.0878, 0.0829, 0.0873, 0.0853], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,248][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0696, 0.0629, 0.0672, 0.0750, 0.0743, 0.0702, 0.0677, 0.0694, 0.0750,
        0.0748, 0.0788, 0.0734, 0.0701, 0.0717], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,248][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.4232e-04, 2.2752e-03, 4.2135e-03, 3.2550e-03, 4.7005e-03, 3.3473e-03,
        5.9302e-03, 1.4877e-02, 5.7291e-03, 3.7990e-01, 3.4519e-02, 1.8572e-01,
        3.4794e-01, 7.4378e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,248][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0014, 0.0698, 0.0724, 0.0744, 0.0727, 0.0716, 0.0722, 0.0814, 0.0828,
        0.0841, 0.0774, 0.0782, 0.0846, 0.0769], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,249][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0029, 0.0722, 0.0713, 0.0756, 0.0771, 0.0710, 0.0776, 0.0787, 0.0818,
        0.0728, 0.0757, 0.0819, 0.0832, 0.0783], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,249][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2024, 0.2539, 0.1297, 0.0546, 0.0661, 0.0307, 0.0260, 0.0324, 0.0549,
        0.0259, 0.0321, 0.0285, 0.0246, 0.0382], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,250][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0100, 0.0977, 0.0659, 0.0820, 0.0687, 0.0770, 0.0723, 0.0749, 0.0879,
        0.0722, 0.0753, 0.0727, 0.0740, 0.0695], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,250][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([5.6202e-02, 7.2174e-04, 1.6009e-03, 1.3095e-04, 1.1294e-03, 2.6041e-03,
        2.4050e-03, 3.7897e-01, 6.0419e-03, 1.4845e-01, 1.3463e-02, 1.7191e-02,
        2.5809e-01, 1.1300e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,254][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0244, 0.0586, 0.1412, 0.0852, 0.0836, 0.0350, 0.0601, 0.0599, 0.0957,
        0.0181, 0.0531, 0.1062, 0.0997, 0.0793], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,254][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0077, 0.0556, 0.1199, 0.0657, 0.0924, 0.0789, 0.0599, 0.0871, 0.0567,
        0.1020, 0.0605, 0.0563, 0.1145, 0.0429], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,254][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1471, 0.1008, 0.0952, 0.0847, 0.0928, 0.0716, 0.0619, 0.0519, 0.0494,
        0.0536, 0.0546, 0.0408, 0.0515, 0.0443], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,255][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.6713e-01, 7.1399e-04, 6.5000e-04, 3.2648e-04, 9.3978e-04, 1.5198e-03,
        1.9523e-03, 1.7260e-03, 2.6954e-03, 1.0894e-03, 9.6136e-03, 2.4796e-03,
        5.6672e-03, 3.5010e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,255][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0217, 0.0659, 0.0772, 0.0679, 0.0768, 0.0746, 0.0773, 0.0757, 0.0673,
        0.0818, 0.0771, 0.0812, 0.0793, 0.0760], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,255][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0634, 0.0585, 0.0623, 0.0690, 0.0690, 0.0644, 0.0621, 0.0641, 0.0696,
        0.0697, 0.0729, 0.0677, 0.0660, 0.0668, 0.0746], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,256][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0052, 0.0154, 0.0053, 0.0101, 0.0044, 0.0038, 0.0119, 0.0093, 0.0080,
        0.2378, 0.0092, 0.0390, 0.1559, 0.0111, 0.4736], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,256][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0016, 0.0640, 0.0664, 0.0688, 0.0670, 0.0671, 0.0675, 0.0756, 0.0769,
        0.0784, 0.0724, 0.0732, 0.0788, 0.0723, 0.0699], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,260][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0032, 0.0680, 0.0666, 0.0703, 0.0713, 0.0656, 0.0717, 0.0727, 0.0751,
        0.0671, 0.0698, 0.0752, 0.0763, 0.0726, 0.0744], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,260][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.2135, 0.2153, 0.1125, 0.0531, 0.0564, 0.0332, 0.0273, 0.0358, 0.0603,
        0.0275, 0.0352, 0.0323, 0.0283, 0.0388, 0.0305], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,261][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0100, 0.0920, 0.0622, 0.0773, 0.0645, 0.0731, 0.0686, 0.0703, 0.0819,
        0.0674, 0.0707, 0.0681, 0.0703, 0.0656, 0.0581], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,261][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([9.0061e-02, 1.0173e-03, 2.1329e-03, 1.8661e-04, 1.1585e-03, 1.6589e-03,
        3.0177e-03, 2.0108e-01, 8.6811e-03, 1.4758e-01, 1.4001e-02, 2.6211e-02,
        2.4093e-01, 2.2761e-01, 3.4665e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,261][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0028, 0.0212, 0.0959, 0.0595, 0.1290, 0.0236, 0.1072, 0.0289, 0.1078,
        0.0142, 0.0398, 0.1135, 0.0631, 0.0587, 0.1348], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,262][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0055, 0.0649, 0.0943, 0.0788, 0.0558, 0.1001, 0.0591, 0.0841, 0.0673,
        0.0779, 0.0673, 0.0543, 0.0758, 0.0703, 0.0445], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,262][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.1352, 0.0946, 0.0892, 0.0804, 0.0869, 0.0677, 0.0593, 0.0500, 0.0484,
        0.0516, 0.0527, 0.0398, 0.0496, 0.0432, 0.0513], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,262][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([9.5814e-01, 8.6902e-04, 7.9679e-04, 3.8668e-04, 2.2510e-03, 1.7856e-03,
        2.0976e-03, 1.4511e-03, 3.0073e-03, 7.2752e-04, 1.0421e-02, 3.3957e-03,
        2.1492e-03, 3.3411e-03, 9.1784e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,266][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0205, 0.0615, 0.0724, 0.0630, 0.0717, 0.0689, 0.0717, 0.0704, 0.0622,
        0.0759, 0.0714, 0.0749, 0.0737, 0.0700, 0.0717], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,267][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0623, 0.0535, 0.0578, 0.0653, 0.0639, 0.0606, 0.0574, 0.0597, 0.0655,
        0.0651, 0.0684, 0.0633, 0.0612, 0.0628, 0.0689, 0.0643],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,267][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0035, 0.0186, 0.0104, 0.0149, 0.0048, 0.0068, 0.0161, 0.0129, 0.0155,
        0.2961, 0.0253, 0.0675, 0.1999, 0.0238, 0.2130, 0.0711],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,267][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0013, 0.0600, 0.0627, 0.0646, 0.0630, 0.0624, 0.0629, 0.0706, 0.0721,
        0.0729, 0.0676, 0.0683, 0.0736, 0.0669, 0.0652, 0.0660],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,268][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0028, 0.0633, 0.0622, 0.0655, 0.0668, 0.0613, 0.0670, 0.0679, 0.0703,
        0.0627, 0.0652, 0.0705, 0.0717, 0.0677, 0.0696, 0.0656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,268][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1511, 0.2279, 0.1313, 0.0558, 0.0610, 0.0335, 0.0271, 0.0318, 0.0559,
        0.0252, 0.0351, 0.0336, 0.0271, 0.0443, 0.0299, 0.0295],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,268][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0090, 0.0877, 0.0581, 0.0732, 0.0605, 0.0690, 0.0646, 0.0663, 0.0780,
        0.0638, 0.0670, 0.0641, 0.0658, 0.0616, 0.0541, 0.0572],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,269][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([3.2771e-02, 7.7973e-04, 2.1460e-03, 5.7744e-05, 1.5982e-03, 2.3883e-03,
        2.0274e-03, 3.2551e-01, 4.1843e-03, 9.2164e-02, 1.0249e-02, 2.3949e-02,
        2.7157e-01, 9.2191e-02, 3.9348e-02, 9.9066e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,273][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0065, 0.0391, 0.0765, 0.0831, 0.0766, 0.0453, 0.0630, 0.0714, 0.1348,
        0.0274, 0.0606, 0.0723, 0.0553, 0.1056, 0.0726, 0.0099],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,273][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0055, 0.0555, 0.1113, 0.0676, 0.0741, 0.0647, 0.0477, 0.0684, 0.0569,
        0.0725, 0.0700, 0.0502, 0.0866, 0.0607, 0.0620, 0.0463],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,273][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1302, 0.0911, 0.0854, 0.0770, 0.0832, 0.0646, 0.0562, 0.0476, 0.0461,
        0.0494, 0.0503, 0.0379, 0.0472, 0.0410, 0.0490, 0.0436],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,274][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([9.6126e-01, 1.0328e-03, 9.8881e-04, 3.4198e-04, 1.9362e-03, 9.0356e-04,
        1.6861e-03, 9.8918e-04, 1.9223e-03, 6.2599e-04, 7.6202e-03, 1.5799e-03,
        5.8666e-03, 3.4039e-03, 7.0886e-03, 2.7571e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,274][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0189, 0.0578, 0.0674, 0.0594, 0.0672, 0.0651, 0.0672, 0.0657, 0.0583,
        0.0704, 0.0663, 0.0702, 0.0682, 0.0655, 0.0665, 0.0661],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,274][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0615, 0.0498, 0.0539, 0.0607, 0.0600, 0.0571, 0.0543, 0.0563, 0.0609,
        0.0613, 0.0643, 0.0596, 0.0573, 0.0586, 0.0651, 0.0609, 0.0585],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,275][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0007, 0.0144, 0.0048, 0.0133, 0.0019, 0.0067, 0.0145, 0.0176, 0.0185,
        0.3348, 0.0309, 0.1391, 0.1064, 0.0371, 0.0563, 0.0804, 0.1225],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,277][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0011, 0.0560, 0.0587, 0.0606, 0.0591, 0.0584, 0.0588, 0.0667, 0.0678,
        0.0688, 0.0634, 0.0640, 0.0694, 0.0631, 0.0615, 0.0620, 0.0605],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,279][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0025, 0.0586, 0.0579, 0.0611, 0.0623, 0.0573, 0.0624, 0.0635, 0.0658,
        0.0588, 0.0611, 0.0659, 0.0673, 0.0633, 0.0652, 0.0615, 0.0655],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,279][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1876, 0.2069, 0.1289, 0.0473, 0.0623, 0.0294, 0.0252, 0.0272, 0.0467,
        0.0224, 0.0313, 0.0285, 0.0247, 0.0420, 0.0285, 0.0260, 0.0352],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,280][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0085, 0.0828, 0.0552, 0.0691, 0.0573, 0.0651, 0.0608, 0.0632, 0.0737,
        0.0602, 0.0632, 0.0607, 0.0621, 0.0581, 0.0516, 0.0541, 0.0545],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,280][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([3.9945e-02, 2.2756e-04, 4.5785e-04, 4.7351e-05, 4.2717e-04, 1.5869e-03,
        4.0853e-04, 2.6786e-01, 5.5296e-03, 7.0809e-02, 1.2024e-02, 5.3682e-03,
        1.5357e-01, 1.2895e-01, 9.9996e-03, 2.8802e-01, 1.4770e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,280][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0145, 0.0612, 0.1388, 0.0778, 0.0889, 0.0616, 0.0237, 0.0376, 0.0979,
        0.0150, 0.0412, 0.0600, 0.0474, 0.0983, 0.0815, 0.0404, 0.0142],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,281][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0051, 0.0548, 0.0965, 0.0656, 0.0797, 0.0711, 0.0290, 0.0705, 0.0560,
        0.0718, 0.0580, 0.0394, 0.0881, 0.0551, 0.0698, 0.0681, 0.0212],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,281][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1299, 0.0892, 0.0835, 0.0748, 0.0811, 0.0624, 0.0538, 0.0451, 0.0435,
        0.0467, 0.0476, 0.0354, 0.0448, 0.0387, 0.0466, 0.0412, 0.0356],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,283][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9246e-01, 9.1340e-05, 1.2319e-04, 5.3944e-05, 2.4791e-04, 2.0848e-04,
        3.2170e-04, 2.3967e-04, 4.8134e-04, 1.0054e-04, 1.8214e-03, 3.8013e-04,
        6.7846e-04, 5.0340e-04, 1.0015e-03, 6.9861e-04, 5.8620e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,285][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0193, 0.0540, 0.0627, 0.0554, 0.0626, 0.0606, 0.0629, 0.0613, 0.0550,
        0.0656, 0.0621, 0.0656, 0.0634, 0.0610, 0.0619, 0.0611, 0.0654],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,286][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0555, 0.0481, 0.0508, 0.0570, 0.0567, 0.0539, 0.0514, 0.0527, 0.0569,
        0.0575, 0.0602, 0.0563, 0.0543, 0.0549, 0.0612, 0.0575, 0.0553, 0.0596],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,286][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0023, 0.0081, 0.0056, 0.0057, 0.0027, 0.0019, 0.0048, 0.0027, 0.0038,
        0.2612, 0.0041, 0.0140, 0.1417, 0.0073, 0.3652, 0.0093, 0.0239, 0.1357],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,286][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0012, 0.0525, 0.0548, 0.0569, 0.0550, 0.0553, 0.0556, 0.0620, 0.0635,
        0.0638, 0.0596, 0.0603, 0.0645, 0.0590, 0.0570, 0.0582, 0.0570, 0.0638],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,287][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0024, 0.0556, 0.0546, 0.0575, 0.0586, 0.0538, 0.0587, 0.0596, 0.0618,
        0.0549, 0.0573, 0.0617, 0.0630, 0.0594, 0.0612, 0.0577, 0.0614, 0.0607],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,287][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.2091, 0.1989, 0.1021, 0.0431, 0.0525, 0.0261, 0.0224, 0.0272, 0.0484,
        0.0223, 0.0292, 0.0260, 0.0228, 0.0356, 0.0265, 0.0246, 0.0341, 0.0490],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,288][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0077, 0.0785, 0.0524, 0.0657, 0.0546, 0.0616, 0.0582, 0.0600, 0.0702,
        0.0573, 0.0601, 0.0575, 0.0591, 0.0549, 0.0485, 0.0512, 0.0518, 0.0508],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,289][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([8.8574e-02, 1.0162e-03, 1.3431e-03, 9.2361e-05, 8.7996e-04, 1.7435e-03,
        4.1059e-03, 3.0134e-01, 5.3315e-03, 6.5852e-02, 8.1811e-03, 2.1977e-02,
        1.2960e-01, 7.7564e-02, 3.1879e-02, 1.2653e-01, 7.7664e-02, 5.6325e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,292][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0054, 0.0324, 0.1582, 0.0587, 0.1056, 0.0119, 0.0507, 0.0343, 0.1026,
        0.0189, 0.0717, 0.0531, 0.0852, 0.0577, 0.1027, 0.0046, 0.0260, 0.0204],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,292][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0041, 0.0513, 0.0861, 0.0627, 0.0588, 0.0811, 0.0439, 0.0651, 0.0595,
        0.0618, 0.0516, 0.0453, 0.0786, 0.0466, 0.0497, 0.0756, 0.0332, 0.0451],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,292][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1177, 0.0832, 0.0781, 0.0707, 0.0760, 0.0596, 0.0518, 0.0441, 0.0427,
        0.0454, 0.0464, 0.0352, 0.0438, 0.0382, 0.0454, 0.0406, 0.0354, 0.0459],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,293][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([9.8265e-01, 4.3883e-04, 2.1564e-04, 1.1507e-04, 4.1242e-04, 6.5416e-04,
        7.4314e-04, 4.0710e-04, 1.1772e-03, 1.7580e-04, 2.4614e-03, 9.4241e-04,
        1.8180e-03, 1.5663e-03, 1.7045e-03, 2.0188e-03, 1.6902e-03, 8.0703e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,293][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0176, 0.0503, 0.0586, 0.0517, 0.0585, 0.0566, 0.0585, 0.0576, 0.0512,
        0.0616, 0.0582, 0.0612, 0.0599, 0.0573, 0.0583, 0.0575, 0.0614, 0.0640],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,294][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0541, 0.0448, 0.0483, 0.0546, 0.0539, 0.0512, 0.0486, 0.0500, 0.0541,
        0.0545, 0.0572, 0.0530, 0.0512, 0.0523, 0.0582, 0.0540, 0.0522, 0.0565,
        0.0511], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,294][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.0106, 0.0087, 0.0143, 0.0051, 0.0080, 0.0139, 0.0189, 0.0178,
        0.1174, 0.0476, 0.1824, 0.1318, 0.0315, 0.0511, 0.0496, 0.1038, 0.1571,
        0.0294], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,298][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0013, 0.0500, 0.0523, 0.0537, 0.0522, 0.0517, 0.0521, 0.0584, 0.0591,
        0.0600, 0.0556, 0.0562, 0.0608, 0.0554, 0.0540, 0.0545, 0.0533, 0.0602,
        0.0593], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,298][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0023, 0.0522, 0.0514, 0.0543, 0.0552, 0.0509, 0.0554, 0.0563, 0.0581,
        0.0518, 0.0538, 0.0581, 0.0593, 0.0558, 0.0575, 0.0543, 0.0577, 0.0574,
        0.0583], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,298][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0792, 0.1837, 0.1394, 0.0523, 0.0663, 0.0293, 0.0249, 0.0241, 0.0395,
        0.0207, 0.0280, 0.0276, 0.0229, 0.0461, 0.0285, 0.0237, 0.0336, 0.0527,
        0.0774], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,299][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0101, 0.0699, 0.0501, 0.0613, 0.0525, 0.0581, 0.0552, 0.0564, 0.0641,
        0.0543, 0.0562, 0.0541, 0.0555, 0.0517, 0.0467, 0.0488, 0.0493, 0.0482,
        0.0575], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,299][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([7.5539e-02, 5.3803e-04, 8.1747e-04, 2.3124e-05, 4.7209e-04, 7.1229e-04,
        1.2147e-03, 3.0098e-01, 1.7057e-03, 6.0876e-02, 3.4296e-03, 9.2986e-03,
        1.5584e-01, 6.2192e-02, 1.3754e-02, 1.0470e-01, 2.3681e-02, 1.2227e-01,
        6.1966e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,300][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0174, 0.0418, 0.0913, 0.0545, 0.1327, 0.0236, 0.0443, 0.0418, 0.0680,
        0.0135, 0.0357, 0.0878, 0.0615, 0.0748, 0.1169, 0.0143, 0.0277, 0.0265,
        0.0257], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,300][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0032, 0.0407, 0.0923, 0.0500, 0.0668, 0.0597, 0.0405, 0.0684, 0.0430,
        0.0810, 0.0447, 0.0424, 0.0849, 0.0364, 0.0591, 0.0587, 0.0311, 0.0720,
        0.0249], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,304][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1218, 0.0832, 0.0778, 0.0693, 0.0754, 0.0579, 0.0496, 0.0416, 0.0400,
        0.0431, 0.0438, 0.0324, 0.0411, 0.0354, 0.0428, 0.0379, 0.0326, 0.0433,
        0.0311], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,304][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9160e-01, 1.2743e-04, 1.0048e-04, 5.2842e-05, 1.8421e-04, 1.9319e-04,
        3.8101e-04, 1.5978e-04, 4.3922e-04, 7.0608e-05, 1.4996e-03, 2.7087e-04,
        6.7386e-04, 6.9899e-04, 1.0611e-03, 6.9486e-04, 7.4564e-04, 6.1805e-05,
        9.7965e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,305][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0151, 0.0471, 0.0562, 0.0486, 0.0557, 0.0535, 0.0555, 0.0547, 0.0479,
        0.0586, 0.0554, 0.0583, 0.0568, 0.0543, 0.0553, 0.0548, 0.0586, 0.0614,
        0.0523], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,325][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:51,326][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,327][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,327][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,327][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,328][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,328][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,328][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,329][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,329][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,329][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,330][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,330][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,330][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6506, 0.3494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,331][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4953, 0.5047], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,331][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8931, 0.1069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,331][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6144, 0.3856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,332][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6582, 0.3418], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,332][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9250, 0.0750], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,332][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0192, 0.9808], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,333][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3255, 0.6745], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,333][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0289, 0.9711], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,333][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8344, 0.1656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,333][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9432, 0.0568], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,334][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3317, 0.6683], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,334][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.6330, 0.2306, 0.1365], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,334][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.3610, 0.3489, 0.2902], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,335][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.3534, 0.2152, 0.4314], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,335][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.4124, 0.3189, 0.2687], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,335][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.3338, 0.3569, 0.3093], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,336][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.9141, 0.0480, 0.0379], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,336][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0097, 0.4716, 0.5187], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,336][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.1175, 0.3248, 0.5577], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,337][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.0122, 0.5190, 0.4688], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,339][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.7932, 0.1525, 0.0543], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,339][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.9848, 0.0100, 0.0052], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,340][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.1561, 0.3232, 0.5206], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,340][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5506, 0.2264, 0.1287, 0.0943], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,340][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2853, 0.2705, 0.2208, 0.2235], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,341][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.2881e-04, 1.9802e-02, 9.8006e-01, 4.0808e-06], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,341][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3736, 0.2030, 0.2284, 0.1951], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,341][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2523, 0.1916, 0.3358, 0.2203], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,345][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7414, 0.0356, 0.1990, 0.0240], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,345][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0048, 0.3192, 0.3500, 0.3259], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,346][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1175, 0.2604, 0.3537, 0.2685], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,346][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0066, 0.3559, 0.3193, 0.3182], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,346][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4208, 0.2662, 0.1042, 0.2088], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,347][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5595, 0.1217, 0.0785, 0.2402], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,349][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1457, 0.1958, 0.1235, 0.5349], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,351][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.4896, 0.1784, 0.1042, 0.0927, 0.1351], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,351][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.2197, 0.2075, 0.1817, 0.1773, 0.2137], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,352][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([1.8845e-02, 1.2240e-01, 8.4756e-01, 6.4856e-05, 1.1134e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,352][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.2886, 0.2033, 0.1830, 0.1765, 0.1486], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,352][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.1508, 0.2025, 0.1593, 0.3880, 0.0994], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,353][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.7546, 0.0597, 0.1180, 0.0494, 0.0183], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,353][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0052, 0.2399, 0.2619, 0.2450, 0.2480], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,353][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0404, 0.1626, 0.2940, 0.2212, 0.2818], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,354][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0045, 0.2666, 0.2384, 0.2380, 0.2526], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,358][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.3884, 0.1865, 0.0782, 0.1673, 0.1796], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,358][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.9247, 0.0217, 0.0111, 0.0284, 0.0140], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,358][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.1447, 0.1595, 0.1985, 0.1944, 0.3029], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,359][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6655, 0.1360, 0.0578, 0.0430, 0.0665, 0.0312], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,359][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1986, 0.1861, 0.1469, 0.1432, 0.1736, 0.1517], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,360][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.5411e-05, 1.9437e-02, 9.6071e-01, 3.8769e-06, 1.9834e-02, 2.4373e-07],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,360][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.2519, 0.1692, 0.1586, 0.1474, 0.1279, 0.1449], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,360][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1555, 0.1589, 0.1516, 0.2985, 0.1553, 0.0801], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,364][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.5015, 0.0660, 0.1625, 0.0996, 0.1380, 0.0324], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,364][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0033, 0.1916, 0.2092, 0.1949, 0.1985, 0.2026], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,365][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0448, 0.1879, 0.2373, 0.2216, 0.1889, 0.1195], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,365][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0032, 0.2162, 0.1922, 0.1929, 0.2062, 0.1893], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,366][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2520, 0.1589, 0.0945, 0.1596, 0.1422, 0.1929], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,366][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5983, 0.0660, 0.0520, 0.1064, 0.0407, 0.1366], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,370][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2178, 0.0546, 0.0419, 0.0635, 0.0662, 0.5560], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,370][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7201, 0.1118, 0.0395, 0.0357, 0.0580, 0.0263, 0.0084],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,371][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1847, 0.1616, 0.1250, 0.1251, 0.1551, 0.1336, 0.1149],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,371][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.3117e-04, 2.3939e-02, 9.4211e-01, 1.5282e-05, 3.3712e-02, 2.3049e-06,
        8.5339e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,371][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2325, 0.1411, 0.1367, 0.1318, 0.1193, 0.1318, 0.1069],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,372][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1394, 0.1305, 0.1687, 0.2148, 0.1789, 0.1003, 0.0674],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,372][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6330, 0.0476, 0.1003, 0.0696, 0.0707, 0.0385, 0.0403],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,372][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0024, 0.1582, 0.1740, 0.1619, 0.1658, 0.1688, 0.1688],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,373][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0821, 0.1492, 0.2128, 0.1559, 0.1948, 0.1154, 0.0898],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,377][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0026, 0.1815, 0.1617, 0.1636, 0.1720, 0.1602, 0.1585],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,377][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2104, 0.1287, 0.0771, 0.1254, 0.1161, 0.1768, 0.1655],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,378][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4572, 0.0576, 0.0389, 0.1004, 0.0270, 0.0844, 0.2345],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,378][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1113, 0.1046, 0.1298, 0.1061, 0.1639, 0.1986, 0.1857],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,378][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.6817, 0.1238, 0.0555, 0.0365, 0.0576, 0.0222, 0.0071, 0.0156],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,379][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.1805, 0.1484, 0.1172, 0.1202, 0.1536, 0.1194, 0.0985, 0.0623],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,380][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([6.8638e-04, 3.4060e-02, 9.0921e-01, 1.2980e-05, 5.5574e-02, 1.6673e-06,
        2.2080e-04, 2.3226e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,383][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.2052, 0.1367, 0.1221, 0.1227, 0.1043, 0.1178, 0.1014, 0.0900],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,383][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.1588, 0.1024, 0.0916, 0.2234, 0.1388, 0.1116, 0.1322, 0.0411],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,383][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.7363, 0.0244, 0.0822, 0.0249, 0.0548, 0.0174, 0.0457, 0.0143],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,384][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0024, 0.1363, 0.1485, 0.1384, 0.1409, 0.1437, 0.1446, 0.1453],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,384][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0516, 0.1441, 0.1700, 0.1646, 0.1577, 0.1141, 0.0901, 0.1078],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,385][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0028, 0.1554, 0.1374, 0.1380, 0.1458, 0.1354, 0.1353, 0.1499],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,385][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2075, 0.1164, 0.0637, 0.1062, 0.0885, 0.1554, 0.1493, 0.1130],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,385][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.4367, 0.0408, 0.0392, 0.0785, 0.0302, 0.0924, 0.1967, 0.0855],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,386][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0386, 0.0485, 0.0408, 0.0608, 0.0532, 0.1774, 0.0503, 0.5303],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,389][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.6382, 0.1290, 0.0562, 0.0390, 0.0706, 0.0269, 0.0093, 0.0169, 0.0140],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,390][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1627, 0.1363, 0.1089, 0.1040, 0.1291, 0.1081, 0.0922, 0.0642, 0.0943],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,390][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([1.4362e-03, 6.5318e-02, 8.7473e-01, 1.9035e-05, 5.7449e-02, 7.2207e-06,
        2.9173e-04, 4.0464e-04, 3.4522e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,390][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1779, 0.1194, 0.1238, 0.1127, 0.0963, 0.1140, 0.0916, 0.0841, 0.0801],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,391][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1467, 0.0835, 0.1354, 0.1378, 0.1901, 0.0734, 0.1137, 0.0428, 0.0765],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,391][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.5713, 0.0211, 0.1314, 0.0237, 0.0947, 0.0357, 0.0567, 0.0584, 0.0069],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,392][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0024, 0.1170, 0.1273, 0.1188, 0.1210, 0.1231, 0.1237, 0.1249, 0.1416],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,396][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0539, 0.1098, 0.1668, 0.1193, 0.1728, 0.0847, 0.0686, 0.1124, 0.1117],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,396][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0028, 0.1339, 0.1191, 0.1199, 0.1260, 0.1166, 0.1169, 0.1289, 0.1360],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,396][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.1597, 0.1126, 0.0637, 0.0925, 0.0842, 0.1423, 0.1429, 0.1088, 0.0934],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,397][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.2935, 0.0583, 0.0445, 0.0727, 0.0305, 0.0608, 0.1563, 0.0871, 0.1963],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,397][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1113, 0.0559, 0.0545, 0.0896, 0.0585, 0.1879, 0.0383, 0.2768, 0.1272],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,398][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.7045, 0.1110, 0.0415, 0.0334, 0.0565, 0.0207, 0.0062, 0.0116, 0.0092,
        0.0054], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,398][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1557, 0.1330, 0.1000, 0.0987, 0.1260, 0.1006, 0.0819, 0.0523, 0.0825,
        0.0693], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,400][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([2.9236e-03, 4.5083e-02, 9.0845e-01, 1.4336e-05, 4.1218e-02, 2.5472e-06,
        2.1771e-04, 4.9593e-04, 6.9387e-04, 8.9706e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,402][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.1629, 0.1168, 0.1084, 0.1038, 0.0922, 0.1048, 0.0882, 0.0773, 0.0827,
        0.0629], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,403][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0644, 0.0972, 0.1139, 0.2095, 0.1022, 0.0767, 0.1309, 0.0507, 0.1351,
        0.0193], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,403][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.4093, 0.0318, 0.2196, 0.0336, 0.0598, 0.0512, 0.0754, 0.0394, 0.0444,
        0.0355], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,403][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0019, 0.1031, 0.1126, 0.1049, 0.1068, 0.1093, 0.1100, 0.1111, 0.1276,
        0.1128], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,404][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0363, 0.0953, 0.1672, 0.1243, 0.1413, 0.0637, 0.1039, 0.0732, 0.1197,
        0.0751], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,404][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0020, 0.1191, 0.1046, 0.1049, 0.1105, 0.1022, 0.1021, 0.1132, 0.1215,
        0.1199], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,405][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1670, 0.1015, 0.0559, 0.0839, 0.0751, 0.1290, 0.1287, 0.0951, 0.0831,
        0.0806], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,409][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.4543, 0.0287, 0.0188, 0.0346, 0.0168, 0.0779, 0.0921, 0.0446, 0.1836,
        0.0485], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,411][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1151, 0.0501, 0.0740, 0.0631, 0.0555, 0.1209, 0.0250, 0.2285, 0.0621,
        0.2058], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,412][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.6808, 0.1123, 0.0444, 0.0323, 0.0633, 0.0237, 0.0074, 0.0136, 0.0105,
        0.0061, 0.0056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,412][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1480, 0.1287, 0.0927, 0.0914, 0.1143, 0.0959, 0.0732, 0.0478, 0.0751,
        0.0637, 0.0692], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,413][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.2855e-04, 5.2819e-02, 9.1920e-01, 1.2705e-05, 2.6209e-02, 2.2440e-06,
        9.8144e-05, 2.4744e-04, 2.8602e-04, 7.0517e-04, 2.9570e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,413][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1431, 0.1069, 0.1019, 0.0986, 0.0872, 0.0978, 0.0822, 0.0730, 0.0767,
        0.0622, 0.0704], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,413][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1055, 0.0781, 0.1254, 0.1419, 0.1056, 0.0789, 0.1233, 0.0431, 0.1036,
        0.0493, 0.0453], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,414][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.4856, 0.0200, 0.0673, 0.0338, 0.0903, 0.0328, 0.0734, 0.0781, 0.0218,
        0.0882, 0.0086], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,414][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0015, 0.0932, 0.1016, 0.0945, 0.0970, 0.0985, 0.0990, 0.0997, 0.1145,
        0.1019, 0.0985], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,415][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0315, 0.0840, 0.1384, 0.1073, 0.1860, 0.0714, 0.0667, 0.0942, 0.0900,
        0.0706, 0.0597], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,418][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0017, 0.1059, 0.0936, 0.0944, 0.0992, 0.0920, 0.0920, 0.1016, 0.1086,
        0.1076, 0.1035], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,419][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1314, 0.0950, 0.0513, 0.0757, 0.0677, 0.1312, 0.1229, 0.0916, 0.0772,
        0.0775, 0.0784], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,419][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2584, 0.0338, 0.0311, 0.0542, 0.0206, 0.0458, 0.1127, 0.0587, 0.1598,
        0.0672, 0.1577], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,420][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0452, 0.0444, 0.0473, 0.0709, 0.0792, 0.1373, 0.0636, 0.1704, 0.0508,
        0.0739, 0.2171], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,420][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([8.0433e-01, 8.3257e-02, 2.5861e-02, 1.9131e-02, 3.6343e-02, 1.2342e-02,
        3.1846e-03, 6.0148e-03, 4.5569e-03, 2.4183e-03, 2.1273e-03, 4.3526e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,421][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1494, 0.1224, 0.0864, 0.0841, 0.1054, 0.0874, 0.0694, 0.0462, 0.0736,
        0.0571, 0.0626, 0.0561], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,421][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([3.9726e-04, 8.7234e-02, 8.9715e-01, 3.1463e-06, 1.4394e-02, 5.6208e-07,
        4.2219e-05, 1.1912e-04, 9.1735e-05, 1.9342e-04, 1.0256e-04, 2.7080e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,425][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1569, 0.1005, 0.0994, 0.0904, 0.0822, 0.0910, 0.0745, 0.0661, 0.0674,
        0.0564, 0.0632, 0.0520], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,425][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0842, 0.0756, 0.1144, 0.1237, 0.1247, 0.0794, 0.0695, 0.0474, 0.1081,
        0.0439, 0.0670, 0.0622], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,426][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5885, 0.0234, 0.0597, 0.0300, 0.0303, 0.0269, 0.0405, 0.0488, 0.0320,
        0.0744, 0.0346, 0.0108], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,426][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0014, 0.0841, 0.0921, 0.0856, 0.0876, 0.0891, 0.0896, 0.0902, 0.1040,
        0.0920, 0.0898, 0.0947], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,426][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0450, 0.0924, 0.1233, 0.0971, 0.1383, 0.0665, 0.0487, 0.0741, 0.1073,
        0.0696, 0.0627, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,427][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0018, 0.0960, 0.0853, 0.0852, 0.0891, 0.0830, 0.0825, 0.0915, 0.0981,
        0.0970, 0.0942, 0.0963], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,427][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1154, 0.0921, 0.0520, 0.0739, 0.0644, 0.1105, 0.1069, 0.0837, 0.0725,
        0.0734, 0.0740, 0.0812], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,431][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1997, 0.0307, 0.0225, 0.0449, 0.0161, 0.0370, 0.0958, 0.0504, 0.1207,
        0.0498, 0.1179, 0.2146], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,431][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0466, 0.0568, 0.0480, 0.0475, 0.0697, 0.1418, 0.0615, 0.1914, 0.0457,
        0.0590, 0.0825, 0.1495], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,432][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.7452, 0.1035, 0.0312, 0.0235, 0.0440, 0.0191, 0.0047, 0.0099, 0.0077,
        0.0044, 0.0039, 0.0010, 0.0019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,432][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.1448, 0.1166, 0.0783, 0.0786, 0.1016, 0.0834, 0.0673, 0.0417, 0.0683,
        0.0526, 0.0595, 0.0541, 0.0533], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,433][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([2.2321e-05, 5.4848e-02, 9.2073e-01, 9.1326e-06, 2.1305e-02, 2.2803e-06,
        1.2294e-04, 2.0557e-04, 2.2532e-04, 4.9214e-04, 2.7465e-04, 1.7283e-03,
        3.5791e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,433][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1356, 0.0945, 0.0895, 0.0873, 0.0782, 0.0875, 0.0744, 0.0636, 0.0678,
        0.0559, 0.0620, 0.0530, 0.0507], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,434][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0718, 0.0578, 0.0753, 0.1316, 0.0542, 0.0747, 0.1134, 0.0527, 0.1278,
        0.0269, 0.0888, 0.0962, 0.0289], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,437][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.2000, 0.0334, 0.0499, 0.0326, 0.0369, 0.0977, 0.0557, 0.1283, 0.0422,
        0.2320, 0.0415, 0.0330, 0.0168], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,438][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0015, 0.0776, 0.0842, 0.0784, 0.0796, 0.0817, 0.0820, 0.0825, 0.0953,
        0.0843, 0.0824, 0.0872, 0.0831], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,438][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0383, 0.0724, 0.1312, 0.0915, 0.1224, 0.0520, 0.0541, 0.0696, 0.0973,
        0.0602, 0.0642, 0.0703, 0.0765], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,439][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0015, 0.0871, 0.0773, 0.0776, 0.0818, 0.0755, 0.0754, 0.0832, 0.0899,
        0.0879, 0.0857, 0.0885, 0.0887], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,439][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.1172, 0.0868, 0.0489, 0.0640, 0.0541, 0.1051, 0.1017, 0.0784, 0.0672,
        0.0666, 0.0673, 0.0741, 0.0685], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,439][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.2909, 0.0287, 0.0183, 0.0279, 0.0166, 0.0544, 0.0619, 0.0394, 0.1101,
        0.0419, 0.0995, 0.1539, 0.0564], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,440][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.1263, 0.0414, 0.0857, 0.0319, 0.0912, 0.1762, 0.0205, 0.0863, 0.0340,
        0.0572, 0.0533, 0.0424, 0.1537], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,444][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([8.6954e-01, 5.6668e-02, 1.2903e-02, 1.2707e-02, 2.6257e-02, 8.6334e-03,
        2.2096e-03, 3.9753e-03, 2.9265e-03, 1.5484e-03, 1.4592e-03, 2.8421e-04,
        6.6867e-04, 2.2318e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,444][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1401, 0.1154, 0.0760, 0.0771, 0.0974, 0.0781, 0.0625, 0.0395, 0.0654,
        0.0484, 0.0545, 0.0498, 0.0482, 0.0476], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,444][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([4.0343e-04, 1.4841e-01, 8.3834e-01, 9.0040e-06, 1.1561e-02, 1.2242e-06,
        4.7441e-05, 1.3806e-04, 1.1822e-04, 2.4012e-04, 9.8025e-05, 5.2180e-04,
        1.6857e-05, 9.4640e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,445][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1157, 0.0832, 0.0912, 0.0801, 0.0765, 0.0864, 0.0719, 0.0632, 0.0612,
        0.0556, 0.0607, 0.0523, 0.0499, 0.0522], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,445][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0568, 0.0614, 0.0952, 0.0902, 0.0800, 0.0530, 0.1194, 0.0392, 0.0879,
        0.0413, 0.0535, 0.1107, 0.0538, 0.0575], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,446][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.5370, 0.0118, 0.0855, 0.0231, 0.0637, 0.0335, 0.0415, 0.0548, 0.0169,
        0.0550, 0.0199, 0.0196, 0.0265, 0.0112], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,448][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0011, 0.0720, 0.0782, 0.0728, 0.0741, 0.0758, 0.0763, 0.0765, 0.0889,
        0.0780, 0.0762, 0.0808, 0.0773, 0.0722], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,450][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0327, 0.0746, 0.1012, 0.0785, 0.0995, 0.0519, 0.0525, 0.0691, 0.0849,
        0.0542, 0.0531, 0.0732, 0.0945, 0.0800], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,450][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0013, 0.0812, 0.0713, 0.0720, 0.0755, 0.0699, 0.0698, 0.0765, 0.0827,
        0.0817, 0.0794, 0.0817, 0.0817, 0.0754], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,451][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1004, 0.0862, 0.0504, 0.0690, 0.0565, 0.0941, 0.0880, 0.0706, 0.0619,
        0.0621, 0.0627, 0.0684, 0.0639, 0.0657], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,451][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0979, 0.0269, 0.0172, 0.0426, 0.0105, 0.0359, 0.1037, 0.0449, 0.1128,
        0.0463, 0.1091, 0.2145, 0.0548, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,452][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0398, 0.0698, 0.0431, 0.1041, 0.0795, 0.1259, 0.0247, 0.1710, 0.0586,
        0.0777, 0.0459, 0.0331, 0.0863, 0.0406], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,452][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([7.3263e-01, 9.8129e-02, 3.4172e-02, 2.6353e-02, 5.5066e-02, 2.2145e-02,
        4.6999e-03, 8.5955e-03, 6.3389e-03, 3.6712e-03, 3.3047e-03, 7.1203e-04,
        1.7097e-03, 5.3562e-04, 1.9412e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,456][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.1444, 0.1087, 0.0714, 0.0717, 0.0954, 0.0749, 0.0603, 0.0356, 0.0598,
        0.0456, 0.0501, 0.0465, 0.0456, 0.0446, 0.0454], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,457][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([6.8069e-04, 1.7041e-01, 8.0643e-01, 6.3039e-05, 1.9080e-02, 5.4777e-06,
        1.7371e-04, 3.0246e-04, 2.6974e-04, 9.0415e-04, 3.9992e-04, 8.8275e-04,
        6.1053e-05, 2.5617e-04, 8.3056e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,457][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.1202, 0.0789, 0.0745, 0.0762, 0.0683, 0.0779, 0.0682, 0.0572, 0.0633,
        0.0521, 0.0580, 0.0511, 0.0486, 0.0601, 0.0453], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,458][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0431, 0.0601, 0.0526, 0.1338, 0.0345, 0.0710, 0.1244, 0.0641, 0.1055,
        0.0291, 0.0633, 0.0936, 0.0376, 0.0639, 0.0234], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,458][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.4117, 0.0292, 0.0609, 0.0220, 0.0091, 0.0573, 0.0542, 0.0704, 0.0246,
        0.1000, 0.0561, 0.0290, 0.0427, 0.0228, 0.0101], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,458][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0016, 0.0675, 0.0725, 0.0683, 0.0688, 0.0708, 0.0710, 0.0713, 0.0822,
        0.0728, 0.0710, 0.0752, 0.0717, 0.0676, 0.0677], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,461][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0143, 0.0525, 0.1045, 0.0697, 0.1071, 0.0393, 0.0660, 0.0620, 0.0743,
        0.0491, 0.0497, 0.0673, 0.0691, 0.0631, 0.1121], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,463][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0010, 0.0744, 0.0657, 0.0657, 0.0698, 0.0649, 0.0647, 0.0715, 0.0771,
        0.0763, 0.0741, 0.0761, 0.0766, 0.0715, 0.0705], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,463][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1223, 0.0833, 0.0421, 0.0643, 0.0547, 0.0895, 0.0892, 0.0616, 0.0542,
        0.0544, 0.0554, 0.0593, 0.0547, 0.0600, 0.0550], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,464][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.5631, 0.0088, 0.0052, 0.0110, 0.0075, 0.0327, 0.0266, 0.0229, 0.0878,
        0.0203, 0.0642, 0.0853, 0.0219, 0.0205, 0.0222], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,464][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0334, 0.0350, 0.0585, 0.0389, 0.0722, 0.2248, 0.0410, 0.0807, 0.0456,
        0.0647, 0.0640, 0.0729, 0.0810, 0.0193, 0.0679], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,464][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([7.6153e-01, 8.4484e-02, 2.9477e-02, 2.2433e-02, 4.5048e-02, 1.8273e-02,
        4.8608e-03, 9.5797e-03, 7.6878e-03, 4.4389e-03, 3.9868e-03, 9.5004e-04,
        1.8327e-03, 6.7664e-04, 1.9530e-03, 2.7934e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,465][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0979, 0.0924, 0.0698, 0.0685, 0.0789, 0.0714, 0.0601, 0.0430, 0.0612,
        0.0500, 0.0556, 0.0510, 0.0487, 0.0474, 0.0424, 0.0618],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,466][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.6660e-05, 1.0753e-01, 8.7338e-01, 1.8963e-05, 1.6171e-02, 1.9402e-06,
        5.2778e-05, 1.1128e-04, 1.5677e-04, 3.4730e-04, 1.8758e-04, 1.4598e-03,
        3.9546e-05, 4.2949e-04, 8.9087e-05, 5.6263e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,469][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1009, 0.0814, 0.0704, 0.0717, 0.0618, 0.0748, 0.0653, 0.0568, 0.0602,
        0.0506, 0.0560, 0.0502, 0.0488, 0.0569, 0.0424, 0.0518],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,470][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0379, 0.0587, 0.0808, 0.1349, 0.0480, 0.0419, 0.0949, 0.0354, 0.1158,
        0.0198, 0.0687, 0.0986, 0.0447, 0.0726, 0.0322, 0.0151],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,470][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.3378, 0.0308, 0.1191, 0.0302, 0.0325, 0.0243, 0.0450, 0.0449, 0.0165,
        0.0993, 0.0512, 0.0323, 0.0486, 0.0352, 0.0373, 0.0150],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,470][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0010, 0.0628, 0.0683, 0.0634, 0.0650, 0.0662, 0.0668, 0.0672, 0.0777,
        0.0686, 0.0668, 0.0709, 0.0679, 0.0633, 0.0639, 0.0600],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,471][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0150, 0.0637, 0.0822, 0.0757, 0.0858, 0.0478, 0.0481, 0.0662, 0.0803,
        0.0530, 0.0496, 0.0597, 0.0660, 0.0819, 0.0891, 0.0359],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,471][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0010, 0.0698, 0.0617, 0.0615, 0.0659, 0.0601, 0.0602, 0.0670, 0.0717,
        0.0716, 0.0690, 0.0709, 0.0715, 0.0662, 0.0660, 0.0657],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,475][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0994, 0.0780, 0.0444, 0.0651, 0.0470, 0.0847, 0.0783, 0.0616, 0.0525,
        0.0531, 0.0534, 0.0577, 0.0540, 0.0570, 0.0560, 0.0579],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,476][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2057, 0.0235, 0.0163, 0.0305, 0.0135, 0.0317, 0.0640, 0.0351, 0.1014,
        0.0320, 0.0927, 0.1462, 0.0551, 0.0542, 0.0243, 0.0738],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,476][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0411, 0.0368, 0.0388, 0.0439, 0.0568, 0.1999, 0.0355, 0.0605, 0.0237,
        0.0493, 0.0468, 0.0509, 0.0633, 0.0161, 0.0583, 0.1783],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,477][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([8.2489e-01, 6.2572e-02, 1.9870e-02, 1.7849e-02, 3.2835e-02, 1.3409e-02,
        3.8758e-03, 7.7414e-03, 5.5008e-03, 3.0412e-03, 2.5293e-03, 5.7113e-04,
        1.3319e-03, 3.6520e-04, 1.2502e-03, 1.5716e-03, 7.9737e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,477][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0988, 0.0884, 0.0658, 0.0661, 0.0783, 0.0672, 0.0580, 0.0389, 0.0571,
        0.0459, 0.0512, 0.0474, 0.0452, 0.0432, 0.0408, 0.0583, 0.0494],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,478][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.1000e-05, 1.2269e-01, 8.4420e-01, 3.7608e-05, 2.7126e-02, 8.5782e-06,
        1.1671e-04, 3.4453e-04, 3.5343e-04, 6.3136e-04, 3.6995e-04, 1.9497e-03,
        6.6304e-05, 1.0446e-03, 2.7258e-04, 3.0393e-05, 7.0073e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,480][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1012, 0.0749, 0.0679, 0.0678, 0.0604, 0.0729, 0.0599, 0.0554, 0.0582,
        0.0503, 0.0549, 0.0468, 0.0479, 0.0530, 0.0412, 0.0497, 0.0377],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,482][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0575, 0.0551, 0.0836, 0.0937, 0.0904, 0.0467, 0.0334, 0.0355, 0.0821,
        0.0324, 0.0489, 0.0619, 0.0688, 0.0861, 0.0718, 0.0243, 0.0276],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,482][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3562, 0.0268, 0.0594, 0.0369, 0.0427, 0.0249, 0.0247, 0.0488, 0.0241,
        0.0891, 0.0296, 0.0184, 0.0296, 0.0273, 0.0501, 0.0804, 0.0311],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,483][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0008, 0.0590, 0.0644, 0.0597, 0.0614, 0.0624, 0.0628, 0.0631, 0.0733,
        0.0644, 0.0628, 0.0665, 0.0640, 0.0598, 0.0604, 0.0566, 0.0586],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,483][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0319, 0.0622, 0.0884, 0.0648, 0.0868, 0.0485, 0.0338, 0.0531, 0.0670,
        0.0419, 0.0435, 0.0526, 0.0657, 0.0716, 0.0956, 0.0553, 0.0374],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,484][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0009, 0.0654, 0.0578, 0.0586, 0.0617, 0.0570, 0.0565, 0.0629, 0.0677,
        0.0674, 0.0653, 0.0669, 0.0675, 0.0627, 0.0621, 0.0627, 0.0570],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,484][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0907, 0.0747, 0.0446, 0.0625, 0.0481, 0.0802, 0.0720, 0.0567, 0.0488,
        0.0502, 0.0508, 0.0535, 0.0507, 0.0532, 0.0534, 0.0552, 0.0549],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,488][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1214, 0.0224, 0.0173, 0.0366, 0.0122, 0.0275, 0.0778, 0.0371, 0.0844,
        0.0347, 0.0939, 0.1614, 0.0445, 0.0577, 0.0156, 0.0523, 0.1032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,489][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0374, 0.0346, 0.0529, 0.0360, 0.0636, 0.0734, 0.0753, 0.0984, 0.0230,
        0.0749, 0.0760, 0.0582, 0.0787, 0.0173, 0.0565, 0.0702, 0.0735],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,489][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.7737, 0.0707, 0.0218, 0.0243, 0.0392, 0.0168, 0.0053, 0.0105, 0.0085,
        0.0056, 0.0049, 0.0013, 0.0030, 0.0012, 0.0030, 0.0033, 0.0014, 0.0054],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,490][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.1089, 0.0878, 0.0616, 0.0620, 0.0814, 0.0613, 0.0550, 0.0324, 0.0516,
        0.0402, 0.0449, 0.0417, 0.0413, 0.0384, 0.0400, 0.0569, 0.0462, 0.0485],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,490][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.6903e-04, 1.8249e-01, 8.0146e-01, 2.2569e-05, 1.0206e-02, 4.6158e-06,
        9.7823e-05, 2.8208e-04, 2.3760e-04, 3.6878e-04, 1.8665e-04, 1.3603e-03,
        3.6671e-05, 5.3716e-04, 1.3414e-04, 1.6740e-05, 5.7597e-04, 1.8124e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,491][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1007, 0.0715, 0.0687, 0.0656, 0.0606, 0.0719, 0.0577, 0.0524, 0.0555,
        0.0467, 0.0504, 0.0428, 0.0443, 0.0476, 0.0406, 0.0485, 0.0364, 0.0381],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,495][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0499, 0.0572, 0.0620, 0.1284, 0.0460, 0.0560, 0.0841, 0.0391, 0.1039,
        0.0224, 0.0849, 0.0592, 0.0292, 0.0496, 0.0280, 0.0200, 0.0614, 0.0186],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,495][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.1468, 0.0206, 0.1001, 0.0237, 0.0211, 0.0706, 0.0570, 0.0996, 0.0411,
        0.0540, 0.0339, 0.0266, 0.0321, 0.0167, 0.0215, 0.1604, 0.0638, 0.0104],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,496][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0009, 0.0565, 0.0611, 0.0567, 0.0580, 0.0591, 0.0594, 0.0596, 0.0694,
        0.0611, 0.0591, 0.0631, 0.0604, 0.0564, 0.0570, 0.0534, 0.0556, 0.0531],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,496][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0182, 0.0490, 0.0968, 0.0578, 0.0814, 0.0253, 0.0442, 0.0554, 0.0699,
        0.0481, 0.0575, 0.0482, 0.0737, 0.0616, 0.0892, 0.0257, 0.0452, 0.0528],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,497][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0007, 0.0617, 0.0542, 0.0548, 0.0580, 0.0533, 0.0534, 0.0588, 0.0639,
        0.0631, 0.0615, 0.0632, 0.0632, 0.0593, 0.0583, 0.0590, 0.0540, 0.0594],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,497][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0880, 0.0664, 0.0369, 0.0521, 0.0412, 0.0825, 0.0742, 0.0556, 0.0480,
        0.0491, 0.0490, 0.0525, 0.0489, 0.0514, 0.0506, 0.0549, 0.0541, 0.0449],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,501][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.3442, 0.0190, 0.0094, 0.0169, 0.0094, 0.0359, 0.0404, 0.0271, 0.0756,
        0.0239, 0.0641, 0.0966, 0.0303, 0.0274, 0.0205, 0.0815, 0.0609, 0.0169],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,501][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0923, 0.0369, 0.0420, 0.0252, 0.0374, 0.0980, 0.0290, 0.0686, 0.0278,
        0.0540, 0.0461, 0.0613, 0.0904, 0.0148, 0.0372, 0.0933, 0.0261, 0.1195],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,502][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.0421e-01, 6.9788e-02, 2.3150e-02, 1.7500e-02, 3.8538e-02, 1.4230e-02,
        3.5247e-03, 7.1405e-03, 5.3299e-03, 3.2655e-03, 2.7881e-03, 6.2695e-04,
        1.5403e-03, 4.6193e-04, 1.4158e-03, 1.6144e-03, 8.5729e-04, 2.9835e-03,
        1.0329e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,502][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0891, 0.0791, 0.0592, 0.0592, 0.0699, 0.0591, 0.0508, 0.0346, 0.0512,
        0.0415, 0.0466, 0.0427, 0.0404, 0.0386, 0.0366, 0.0535, 0.0446, 0.0452,
        0.0582], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,503][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.2272e-04, 2.4270e-01, 7.2194e-01, 1.0185e-04, 1.9626e-02, 2.4553e-05,
        2.0302e-04, 4.6159e-04, 5.0280e-04, 8.4387e-04, 4.1885e-04, 2.4926e-03,
        1.1311e-04, 1.2300e-03, 3.3753e-04, 5.6975e-05, 1.0964e-03, 4.6085e-03,
        3.0137e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,503][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0977, 0.0697, 0.0674, 0.0655, 0.0578, 0.0684, 0.0569, 0.0505, 0.0510,
        0.0440, 0.0482, 0.0414, 0.0417, 0.0460, 0.0384, 0.0452, 0.0356, 0.0377,
        0.0367], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,507][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0480, 0.0438, 0.0905, 0.0861, 0.0726, 0.0417, 0.0626, 0.0331, 0.0592,
        0.0352, 0.0367, 0.0656, 0.0520, 0.0590, 0.0551, 0.0215, 0.0540, 0.0509,
        0.0326], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,508][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3766, 0.0130, 0.0579, 0.0176, 0.0432, 0.0275, 0.0475, 0.0576, 0.0088,
        0.0713, 0.0119, 0.0233, 0.0284, 0.0135, 0.0439, 0.0501, 0.0552, 0.0441,
        0.0087], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,508][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0010, 0.0539, 0.0580, 0.0538, 0.0548, 0.0557, 0.0563, 0.0565, 0.0645,
        0.0572, 0.0554, 0.0593, 0.0567, 0.0534, 0.0538, 0.0504, 0.0526, 0.0506,
        0.0562], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,509][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0249, 0.0514, 0.0657, 0.0537, 0.0826, 0.0391, 0.0364, 0.0494, 0.0583,
        0.0399, 0.0381, 0.0532, 0.0640, 0.0618, 0.0922, 0.0432, 0.0415, 0.0498,
        0.0549], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,509][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0010, 0.0592, 0.0521, 0.0525, 0.0551, 0.0508, 0.0508, 0.0560, 0.0598,
        0.0591, 0.0574, 0.0593, 0.0596, 0.0554, 0.0549, 0.0552, 0.0508, 0.0558,
        0.0551], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,510][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0732, 0.0573, 0.0299, 0.0472, 0.0334, 0.0738, 0.0690, 0.0554, 0.0477,
        0.0483, 0.0481, 0.0549, 0.0497, 0.0551, 0.0503, 0.0556, 0.0566, 0.0450,
        0.0495], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,514][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0902, 0.0240, 0.0145, 0.0334, 0.0101, 0.0268, 0.0787, 0.0316, 0.0834,
        0.0291, 0.0875, 0.1423, 0.0392, 0.0565, 0.0152, 0.0519, 0.1075, 0.0119,
        0.0660], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,514][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0285, 0.0417, 0.0262, 0.0540, 0.0601, 0.0814, 0.0281, 0.1146, 0.0206,
        0.0389, 0.0514, 0.0293, 0.0339, 0.0195, 0.0596, 0.0817, 0.0284, 0.0477,
        0.1543], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,516][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:51,517][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14917],
        [10851],
        [ 2696],
        [ 3930],
        [ 1369],
        [ 4621],
        [ 3121],
        [ 2303],
        [ 4567],
        [ 6341],
        [ 8842],
        [ 5769],
        [ 3183],
        [  634],
        [ 2259],
        [  608],
        [ 3114],
        [ 1732],
        [ 2413]], device='cuda:0')
[2024-07-24 10:19:51,519][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14583],
        [18227],
        [ 9134],
        [18035],
        [ 2570],
        [10597],
        [12255],
        [ 6790],
        [16512],
        [15254],
        [28253],
        [17071],
        [14168],
        [ 4729],
        [ 2852],
        [ 3780],
        [15099],
        [ 4755],
        [15858]], device='cuda:0')
[2024-07-24 10:19:51,521][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12559],
        [ 8183],
        [10413],
        [ 9283],
        [ 9857],
        [ 9053],
        [ 8418],
        [ 7967],
        [ 7729],
        [ 7207],
        [ 7233],
        [ 7337],
        [ 7340],
        [ 7528],
        [ 7757],
        [ 7701],
        [ 7735],
        [ 7537],
        [ 7534]], device='cuda:0')
[2024-07-24 10:19:51,523][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13489],
        [ 4190],
        [ 3133],
        [ 2645],
        [ 3840],
        [ 3453],
        [ 3572],
        [ 4199],
        [ 3408],
        [ 3529],
        [ 3592],
        [ 2630],
        [ 2661],
        [ 2078],
        [ 6001],
        [ 3051],
        [ 2024],
        [ 4935],
        [ 1674]], device='cuda:0')
[2024-07-24 10:19:51,524][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19797],
        [22572],
        [21566],
        [22613],
        [22298],
        [22119],
        [22176],
        [22541],
        [22402],
        [22297],
        [22122],
        [21987],
        [21893],
        [21778],
        [21675],
        [21661],
        [21667],
        [21771],
        [21876]], device='cuda:0')
[2024-07-24 10:19:51,526][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[20752],
        [23655],
        [24233],
        [24117],
        [24409],
        [24622],
        [24693],
        [24711],
        [24827],
        [24718],
        [24786],
        [24800],
        [24826],
        [24844],
        [24759],
        [24684],
        [24623],
        [24551],
        [24563]], device='cuda:0')
[2024-07-24 10:19:51,528][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7522],
        [ 3918],
        [ 9319],
        [12960],
        [13089],
        [15596],
        [15420],
        [16701],
        [18438],
        [16612],
        [17975],
        [18136],
        [18479],
        [17701],
        [18409],
        [18955],
        [18543],
        [17950],
        [19213]], device='cuda:0')
[2024-07-24 10:19:51,529][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43176],
        [40302],
        [40136],
        [39776],
        [39828],
        [39719],
        [39638],
        [39473],
        [39425],
        [39004],
        [38734],
        [38677],
        [38421],
        [38341],
        [38443],
        [38487],
        [38395],
        [38298],
        [38301]], device='cuda:0')
[2024-07-24 10:19:51,531][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[32156],
        [42976],
        [40112],
        [38734],
        [34438],
        [32518],
        [30484],
        [30366],
        [29487],
        [29696],
        [29949],
        [30403],
        [26705],
        [26906],
        [28788],
        [27717],
        [32200],
        [29324],
        [31111]], device='cuda:0')
[2024-07-24 10:19:51,533][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 9979],
        [32188],
        [ 8983],
        [18796],
        [26904],
        [28586],
        [24478],
        [28370],
        [24510],
        [26162],
        [29825],
        [29378],
        [26271],
        [26104],
        [28850],
        [30029],
        [28409],
        [27159],
        [29866]], device='cuda:0')
[2024-07-24 10:19:51,535][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[48081],
        [30083],
        [29336],
        [30147],
        [31626],
        [31354],
        [31195],
        [30864],
        [30631],
        [30184],
        [30019],
        [29971],
        [29988],
        [29862],
        [29899],
        [30124],
        [30038],
        [29799],
        [29776]], device='cuda:0')
[2024-07-24 10:19:51,536][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24675],
        [24978],
        [25938],
        [26476],
        [26673],
        [26515],
        [26729],
        [26939],
        [27163],
        [27432],
        [27625],
        [27804],
        [28089],
        [28257],
        [28462],
        [28603],
        [28749],
        [28918],
        [29003]], device='cuda:0')
[2024-07-24 10:19:51,538][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 9750],
        [ 9760],
        [ 9907],
        [10511],
        [10454],
        [10659],
        [10073],
        [10107],
        [ 9969],
        [10907],
        [10910],
        [ 9969],
        [10354],
        [11547],
        [11133],
        [11375],
        [10076],
        [10528],
        [10113]], device='cuda:0')
[2024-07-24 10:19:51,540][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24659],
        [24022],
        [18719],
        [18764],
        [19694],
        [19342],
        [18845],
        [19330],
        [19532],
        [20078],
        [19989],
        [20080],
        [19666],
        [19567],
        [19845],
        [19728],
        [19467],
        [19384],
        [19442]], device='cuda:0')
[2024-07-24 10:19:51,542][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[38872],
        [13852],
        [ 7847],
        [10889],
        [ 8389],
        [15573],
        [ 4008],
        [ 6981],
        [ 6713],
        [ 6930],
        [ 7396],
        [ 7680],
        [ 4175],
        [ 6285],
        [10900],
        [ 3805],
        [ 6386],
        [ 9103],
        [ 5178]], device='cuda:0')
[2024-07-24 10:19:51,543][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20247],
        [22744],
        [23404],
        [24505],
        [26264],
        [24228],
        [23708],
        [24057],
        [24591],
        [23836],
        [24126],
        [22648],
        [23281],
        [21923],
        [23541],
        [23209],
        [22497],
        [23060],
        [22719]], device='cuda:0')
[2024-07-24 10:19:51,545][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17919],
        [18438],
        [17992],
        [17265],
        [17053],
        [16488],
        [16345],
        [16178],
        [15891],
        [15693],
        [15535],
        [15417],
        [15394],
        [15425],
        [15489],
        [15179],
        [15144],
        [15190],
        [15040]], device='cuda:0')
[2024-07-24 10:19:51,548][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[16766],
        [13291],
        [18226],
        [20805],
        [20612],
        [20560],
        [20400],
        [20172],
        [20146],
        [20304],
        [20497],
        [20627],
        [20545],
        [20684],
        [20580],
        [20615],
        [20454],
        [20687],
        [20528]], device='cuda:0')
[2024-07-24 10:19:51,549][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14082],
        [21592],
        [24996],
        [24782],
        [26321],
        [27001],
        [27924],
        [28763],
        [29507],
        [29739],
        [30152],
        [30152],
        [30591],
        [30924],
        [31591],
        [31836],
        [32257],
        [32577],
        [32728]], device='cuda:0')
[2024-07-24 10:19:51,550][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24094],
        [17685],
        [31818],
        [30816],
        [26833],
        [28964],
        [29710],
        [25771],
        [29037],
        [27150],
        [29389],
        [31816],
        [29540],
        [30222],
        [27438],
        [29138],
        [30003],
        [26853],
        [28963]], device='cuda:0')
[2024-07-24 10:19:51,551][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[43778],
        [44021],
        [44534],
        [45922],
        [45349],
        [43499],
        [43930],
        [44685],
        [43316],
        [41482],
        [40948],
        [42371],
        [33410],
        [42360],
        [38762],
        [39188],
        [38562],
        [32685],
        [38550]], device='cuda:0')
[2024-07-24 10:19:51,554][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36355],
        [44475],
        [44229],
        [44591],
        [44507],
        [44696],
        [44798],
        [44631],
        [44657],
        [44615],
        [44611],
        [44645],
        [44587],
        [44653],
        [44636],
        [44613],
        [44657],
        [44673],
        [44703]], device='cuda:0')
[2024-07-24 10:19:51,556][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[42067],
        [ 6215],
        [ 5432],
        [ 7839],
        [19966],
        [17544],
        [18543],
        [14575],
        [13663],
        [13478],
        [13731],
        [12001],
        [12929],
        [13369],
        [18171],
        [15666],
        [16279],
        [16921],
        [17425]], device='cuda:0')
[2024-07-24 10:19:51,557][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34747],
        [38050],
        [37031],
        [35923],
        [34823],
        [34866],
        [34585],
        [34601],
        [34958],
        [34842],
        [34995],
        [35050],
        [35137],
        [35006],
        [34834],
        [34867],
        [34834],
        [34677],
        [34618]], device='cuda:0')
[2024-07-24 10:19:51,558][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 5140],
        [ 8128],
        [ 8321],
        [14060],
        [14011],
        [16184],
        [16790],
        [16345],
        [16960],
        [16632],
        [17672],
        [17973],
        [18224],
        [18721],
        [18308],
        [19007],
        [19465],
        [20185],
        [21062]], device='cuda:0')
[2024-07-24 10:19:51,561][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38749],
        [36535],
        [38385],
        [21428],
        [34062],
        [21628],
        [20059],
        [19887],
        [19458],
        [19469],
        [18001],
        [17373],
        [17204],
        [17366],
        [17420],
        [17265],
        [17227],
        [17304],
        [17334]], device='cuda:0')
[2024-07-24 10:19:51,563][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22283],
        [16205],
        [ 1266],
        [11441],
        [ 3119],
        [ 9750],
        [ 5727],
        [10351],
        [10159],
        [20642],
        [ 9268],
        [10744],
        [ 8929],
        [10781],
        [ 8549],
        [ 9645],
        [10631],
        [12245],
        [10349]], device='cuda:0')
[2024-07-24 10:19:51,564][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 9420],
        [13100],
        [13358],
        [12844],
        [ 9973],
        [12424],
        [12554],
        [12877],
        [13092],
        [12882],
        [14255],
        [13604],
        [16066],
        [13360],
        [14334],
        [13996],
        [13806],
        [15026],
        [13915]], device='cuda:0')
[2024-07-24 10:19:51,565][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[13629],
        [35037],
        [40351],
        [25907],
        [39766],
        [29031],
        [37840],
        [35665],
        [31415],
        [37169],
        [30565],
        [33506],
        [36232],
        [29042],
        [32684],
        [33705],
        [31453],
        [36041],
        [26644]], device='cuda:0')
[2024-07-24 10:19:51,567][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076],
        [32076]], device='cuda:0')
[2024-07-24 10:19:51,599][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:51,599][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,599][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,600][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,601][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,601][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,602][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,602][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,602][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,603][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,603][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,603][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,603][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,604][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0939, 0.9061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,604][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6702, 0.3298], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,604][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4389, 0.5611], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,605][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9914, 0.0086], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,605][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9851, 0.0149], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,605][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6772, 0.3228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,606][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0524, 0.9476], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,606][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3673, 0.6327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,606][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9613, 0.0387], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,607][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0296, 0.9704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,607][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.0000e+00, 2.9837e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,607][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2245, 0.7755], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,608][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0426, 0.5046, 0.4529], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,608][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.4346, 0.2172, 0.3482], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,608][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.1535, 0.2434, 0.6031], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,609][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.9916, 0.0054, 0.0030], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,609][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([9.9818e-01, 1.4443e-03, 3.7876e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,609][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.3293, 0.1022, 0.5684], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,612][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0372, 0.4633, 0.4996], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,612][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.2324, 0.3843, 0.3834], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,612][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.9562, 0.0223, 0.0216], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,613][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0199, 0.4666, 0.5134], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,613][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([1.0000e+00, 4.0289e-07, 2.6697e-09], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,613][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.1215, 0.4226, 0.4559], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,614][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0250, 0.3634, 0.3395, 0.2721], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,614][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4051, 0.2240, 0.3407, 0.0302], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,616][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0855, 0.2330, 0.6221, 0.0594], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,621][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9829, 0.0085, 0.0053, 0.0033], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,621][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9906, 0.0050, 0.0018, 0.0026], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,622][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1111, 0.0937, 0.7332, 0.0620], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,622][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0179, 0.3325, 0.3641, 0.2855], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,622][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1653, 0.2809, 0.2981, 0.2557], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,623][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9281, 0.0252, 0.0258, 0.0209], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,623][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0115, 0.3265, 0.3755, 0.2866], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,623][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.0000e+00, 1.2027e-06, 1.0457e-08, 5.7457e-08], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,624][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0598, 0.3135, 0.3516, 0.2750], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,624][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0184, 0.2773, 0.2542, 0.2075, 0.2426], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,625][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.2198, 0.2007, 0.4062, 0.0542, 0.1191], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,628][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0691, 0.1919, 0.5783, 0.0428, 0.1179], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,629][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.9869, 0.0058, 0.0032, 0.0022, 0.0019], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,629][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([9.9692e-01, 1.4821e-03, 3.5515e-04, 6.1129e-04, 6.2712e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,629][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1520, 0.0718, 0.4204, 0.0842, 0.2716], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,630][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0183, 0.2470, 0.2637, 0.2131, 0.2580], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,630][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1219, 0.2244, 0.2284, 0.2037, 0.2216], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,630][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.9226, 0.0206, 0.0207, 0.0179, 0.0182], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,631][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0091, 0.2316, 0.2549, 0.1990, 0.3054], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,632][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([1.0000e+00, 7.0278e-07, 5.2924e-09, 3.1611e-08, 1.3239e-08],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,635][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0427, 0.2350, 0.2738, 0.2026, 0.2459], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,635][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0133, 0.2325, 0.2148, 0.1705, 0.2044, 0.1645], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,635][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1438, 0.2282, 0.2719, 0.0395, 0.2407, 0.0759], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,636][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0935, 0.1956, 0.4088, 0.0806, 0.1502, 0.0712], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,636][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.9724, 0.0096, 0.0064, 0.0037, 0.0040, 0.0038], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,636][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([9.9595e-01, 1.5365e-03, 3.9710e-04, 6.4375e-04, 6.9220e-04, 7.8212e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,637][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0552, 0.0583, 0.4615, 0.0862, 0.2712, 0.0676], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,637][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0122, 0.2029, 0.2167, 0.1752, 0.2114, 0.1816], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,641][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0977, 0.1842, 0.1888, 0.1654, 0.1898, 0.1742], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,641][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.8705, 0.0281, 0.0286, 0.0236, 0.0255, 0.0237], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,642][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0064, 0.1786, 0.2055, 0.1653, 0.2540, 0.1902], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,642][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.9999e-01, 5.6493e-06, 7.7891e-08, 3.1580e-07, 1.4005e-07, 1.4941e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,642][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0211, 0.1871, 0.2316, 0.1804, 0.2336, 0.1463], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,643][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0102, 0.1988, 0.1836, 0.1463, 0.1761, 0.1418, 0.1433],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,643][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0758, 0.1117, 0.4562, 0.0373, 0.2626, 0.0359, 0.0206],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,643][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1044, 0.1486, 0.3037, 0.0936, 0.1489, 0.0880, 0.1127],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,647][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.9789, 0.0071, 0.0043, 0.0025, 0.0026, 0.0026, 0.0019],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,647][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.9677e-01, 9.9225e-04, 2.3456e-04, 4.0006e-04, 4.1453e-04, 5.1432e-04,
        6.7207e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,648][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0548, 0.0520, 0.4310, 0.0503, 0.2858, 0.0494, 0.0767],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,648][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0121, 0.1697, 0.1817, 0.1463, 0.1761, 0.1516, 0.1625],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,648][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0794, 0.1551, 0.1610, 0.1431, 0.1644, 0.1555, 0.1415],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,649][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8832, 0.0206, 0.0207, 0.0180, 0.0191, 0.0187, 0.0195],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,649][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0049, 0.1519, 0.1701, 0.1421, 0.2095, 0.1603, 0.1612],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,650][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9999e-01, 6.0073e-06, 9.6602e-08, 3.9249e-07, 1.8229e-07, 1.8379e-06,
        1.8929e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,653][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0147, 0.1609, 0.2130, 0.1560, 0.2086, 0.1303, 0.1165],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,654][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0118, 0.1697, 0.1550, 0.1254, 0.1470, 0.1203, 0.1227, 0.1481],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,654][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.3473, 0.1096, 0.2859, 0.0233, 0.1344, 0.0284, 0.0126, 0.0585],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,654][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1050, 0.1148, 0.2218, 0.0886, 0.1445, 0.0879, 0.1150, 0.1224],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,655][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.9709, 0.0085, 0.0051, 0.0033, 0.0032, 0.0033, 0.0025, 0.0033],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,655][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([9.9532e-01, 1.1267e-03, 2.3265e-04, 3.8572e-04, 4.0169e-04, 4.4951e-04,
        6.4788e-04, 1.4361e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,656][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.1220, 0.0695, 0.3386, 0.0521, 0.1860, 0.0528, 0.0823, 0.0966],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,658][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0093, 0.1468, 0.1595, 0.1259, 0.1533, 0.1307, 0.1406, 0.1340],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,660][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0794, 0.1374, 0.1365, 0.1257, 0.1363, 0.1294, 0.1274, 0.1278],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,660][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.8658, 0.0200, 0.0196, 0.0169, 0.0178, 0.0177, 0.0196, 0.0226],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,660][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0046, 0.1309, 0.1451, 0.1156, 0.1782, 0.1345, 0.1454, 0.1457],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,661][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([9.9994e-01, 1.7098e-05, 3.6938e-07, 1.2700e-06, 6.4650e-07, 5.2112e-06,
        5.6114e-06, 2.9078e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,661][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0193, 0.1442, 0.1829, 0.1355, 0.1775, 0.1120, 0.1051, 0.1236],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,662][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0100, 0.1456, 0.1353, 0.1084, 0.1286, 0.1044, 0.1065, 0.1289, 0.1323],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,662][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0324, 0.1048, 0.5048, 0.0194, 0.2187, 0.0225, 0.0138, 0.0773, 0.0062],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,666][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0986, 0.1335, 0.2013, 0.0804, 0.0960, 0.0763, 0.0973, 0.1116, 0.1050],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,666][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.9780, 0.0064, 0.0037, 0.0022, 0.0022, 0.0022, 0.0016, 0.0022, 0.0014],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,667][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.9652, 0.0046, 0.0012, 0.0018, 0.0017, 0.0020, 0.0027, 0.0051, 0.0157],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,667][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0724, 0.0403, 0.3493, 0.0458, 0.2384, 0.0487, 0.0755, 0.0839, 0.0456],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,668][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0085, 0.1285, 0.1394, 0.1107, 0.1344, 0.1150, 0.1234, 0.1173, 0.1227],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,668][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0615, 0.1174, 0.1223, 0.1078, 0.1271, 0.1198, 0.1105, 0.1135, 0.1201],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,668][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.7896, 0.0272, 0.0272, 0.0239, 0.0246, 0.0249, 0.0264, 0.0312, 0.0249],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,671][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0042, 0.1131, 0.1296, 0.1046, 0.1588, 0.1186, 0.1264, 0.1303, 0.1144],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,672][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.9999e-01, 3.0387e-06, 3.0638e-08, 1.4593e-07, 5.8753e-08, 6.8763e-07,
        7.0530e-07, 4.7982e-06, 3.7906e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,673][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0117, 0.1336, 0.1718, 0.1203, 0.1620, 0.0968, 0.0878, 0.1100, 0.1061],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,673][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0084, 0.1300, 0.1192, 0.0962, 0.1126, 0.0927, 0.0942, 0.1141, 0.1185,
        0.1141], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,674][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.3284, 0.1079, 0.2727, 0.0255, 0.1043, 0.0264, 0.0146, 0.0620, 0.0113,
        0.0469], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,674][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0881, 0.0954, 0.1889, 0.0718, 0.1076, 0.0716, 0.0922, 0.0998, 0.0947,
        0.0900], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,674][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.9729, 0.0071, 0.0041, 0.0026, 0.0026, 0.0026, 0.0019, 0.0026, 0.0017,
        0.0020], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,675][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([9.8533e-01, 1.3358e-03, 2.9830e-04, 5.1423e-04, 5.1292e-04, 6.2458e-04,
        8.2871e-04, 1.8277e-03, 7.5084e-03, 1.2204e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,679][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0936, 0.0561, 0.3102, 0.0477, 0.1440, 0.0271, 0.0637, 0.0872, 0.0533,
        0.1170], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,679][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0079, 0.1147, 0.1235, 0.0990, 0.1198, 0.1028, 0.1099, 0.1049, 0.1084,
        0.1089], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,680][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0533, 0.1090, 0.1105, 0.0970, 0.1081, 0.1053, 0.0971, 0.1033, 0.1101,
        0.1065], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,680][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.8349, 0.0188, 0.0185, 0.0160, 0.0168, 0.0166, 0.0181, 0.0220, 0.0181,
        0.0203], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,680][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0032, 0.1032, 0.1153, 0.0900, 0.1396, 0.1048, 0.1122, 0.1128, 0.1020,
        0.1169], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,681][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([9.9997e-01, 7.5044e-06, 1.1625e-07, 4.5096e-07, 2.1094e-07, 2.0296e-06,
        2.0750e-06, 1.2496e-05, 1.1329e-06, 4.5076e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,681][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0119, 0.1258, 0.1589, 0.1089, 0.1392, 0.0818, 0.0756, 0.0929, 0.0917,
        0.1134], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,685][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0070, 0.1186, 0.1089, 0.0861, 0.1034, 0.0833, 0.0844, 0.1035, 0.1076,
        0.1040, 0.0933], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,686][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0783, 0.0899, 0.3463, 0.0364, 0.1788, 0.0451, 0.0136, 0.0881, 0.0101,
        0.0883, 0.0250], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,686][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0771, 0.1028, 0.1872, 0.0662, 0.0984, 0.0602, 0.0778, 0.0879, 0.0825,
        0.0802, 0.0796], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,686][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.9723, 0.0069, 0.0040, 0.0025, 0.0025, 0.0025, 0.0018, 0.0024, 0.0016,
        0.0019, 0.0016], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,687][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([9.8750e-01, 1.1517e-03, 2.3949e-04, 3.8148e-04, 3.7104e-04, 4.3339e-04,
        6.0763e-04, 1.2943e-03, 5.5977e-03, 9.3497e-04, 1.4931e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,687][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0692, 0.0324, 0.2766, 0.0313, 0.1765, 0.0360, 0.0476, 0.0965, 0.0301,
        0.1503, 0.0536], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,688][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0072, 0.1029, 0.1112, 0.0895, 0.1077, 0.0932, 0.0994, 0.0953, 0.0983,
        0.0985, 0.0969], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,692][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0447, 0.0970, 0.0999, 0.0900, 0.1037, 0.0968, 0.0891, 0.0915, 0.0987,
        0.1029, 0.0856], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,692][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.7918, 0.0211, 0.0210, 0.0186, 0.0194, 0.0193, 0.0202, 0.0248, 0.0204,
        0.0231, 0.0202], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,692][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0033, 0.0911, 0.1039, 0.0837, 0.1270, 0.0951, 0.1001, 0.1008, 0.0901,
        0.1053, 0.0996], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,693][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.9998e-01, 4.5040e-06, 6.1203e-08, 2.4543e-07, 1.1374e-07, 1.1780e-06,
        1.2146e-06, 7.5992e-06, 6.2958e-07, 2.6556e-06, 1.2151e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,693][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0068, 0.1103, 0.1348, 0.0989, 0.1308, 0.0763, 0.0711, 0.0860, 0.0878,
        0.1099, 0.0874], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,694][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0052, 0.1077, 0.0995, 0.0791, 0.0953, 0.0768, 0.0776, 0.0961, 0.1001,
        0.0966, 0.0863, 0.0796], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,694][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1068, 0.0904, 0.3160, 0.0242, 0.2033, 0.0257, 0.0168, 0.0608, 0.0086,
        0.0898, 0.0267, 0.0309], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,698][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0728, 0.0859, 0.1432, 0.0645, 0.0838, 0.0634, 0.0797, 0.0864, 0.0857,
        0.0794, 0.0803, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,698][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.9739, 0.0064, 0.0036, 0.0022, 0.0022, 0.0022, 0.0016, 0.0021, 0.0014,
        0.0016, 0.0014, 0.0014], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,699][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([9.8974e-01, 7.3682e-04, 1.6122e-04, 2.7310e-04, 2.6903e-04, 3.3170e-04,
        4.3948e-04, 1.0134e-03, 4.3388e-03, 6.8104e-04, 1.1577e-03, 8.5933e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,699][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0612, 0.0330, 0.2823, 0.0272, 0.1617, 0.0289, 0.0475, 0.0753, 0.0245,
        0.1369, 0.0649, 0.0566], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,700][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0070, 0.0937, 0.1006, 0.0813, 0.0976, 0.0846, 0.0903, 0.0862, 0.0890,
        0.0893, 0.0874, 0.0930], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,700][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0452, 0.0878, 0.0912, 0.0818, 0.0945, 0.0885, 0.0813, 0.0851, 0.0897,
        0.0946, 0.0793, 0.0811], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,700][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8040, 0.0178, 0.0174, 0.0154, 0.0162, 0.0161, 0.0172, 0.0208, 0.0175,
        0.0194, 0.0174, 0.0210], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,704][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0028, 0.0826, 0.0933, 0.0752, 0.1137, 0.0860, 0.0887, 0.0938, 0.0833,
        0.0962, 0.0917, 0.0928], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,705][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9997e-01, 5.4159e-06, 7.5669e-08, 3.1020e-07, 1.4011e-07, 1.4497e-06,
        1.4513e-06, 9.1460e-06, 7.7663e-07, 3.1428e-06, 1.4451e-06, 1.7462e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,705][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0091, 0.1069, 0.1311, 0.0888, 0.1177, 0.0678, 0.0604, 0.0753, 0.0755,
        0.0963, 0.0767, 0.0944], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,706][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0064, 0.0984, 0.0903, 0.0729, 0.0861, 0.0708, 0.0718, 0.0870, 0.0910,
        0.0877, 0.0795, 0.0740, 0.0842], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,706][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.5334, 0.0616, 0.1581, 0.0158, 0.0648, 0.0199, 0.0144, 0.0269, 0.0050,
        0.0351, 0.0263, 0.0281, 0.0107], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,708][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0692, 0.0743, 0.1377, 0.0598, 0.0875, 0.0561, 0.0737, 0.0783, 0.0786,
        0.0734, 0.0735, 0.0681, 0.0697], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,710][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.9619, 0.0083, 0.0049, 0.0030, 0.0030, 0.0030, 0.0022, 0.0029, 0.0019,
        0.0023, 0.0020, 0.0020, 0.0026], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,711][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ office] are: tensor([9.8502e-01, 1.1195e-03, 2.1936e-04, 3.6490e-04, 3.5253e-04, 4.1618e-04,
        6.0669e-04, 1.3104e-03, 5.5568e-03, 9.1122e-04, 1.4976e-03, 1.1732e-03,
        1.4533e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,711][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0539, 0.0256, 0.2644, 0.0330, 0.1527, 0.0215, 0.0324, 0.0716, 0.0277,
        0.1535, 0.0527, 0.0412, 0.0698], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,712][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0061, 0.0867, 0.0923, 0.0749, 0.0896, 0.0777, 0.0829, 0.0791, 0.0819,
        0.0818, 0.0800, 0.0849, 0.0822], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,712][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0479, 0.0817, 0.0847, 0.0750, 0.0843, 0.0801, 0.0744, 0.0786, 0.0828,
        0.0847, 0.0728, 0.0739, 0.0793], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,712][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.7948, 0.0162, 0.0163, 0.0146, 0.0148, 0.0151, 0.0163, 0.0198, 0.0165,
        0.0187, 0.0165, 0.0207, 0.0197], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,715][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0028, 0.0746, 0.0836, 0.0646, 0.1002, 0.0761, 0.0822, 0.0852, 0.0745,
        0.0847, 0.0815, 0.0829, 0.1072], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,717][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ office] are: tensor([9.9994e-01, 1.0833e-05, 1.9526e-07, 6.8621e-07, 3.5720e-07, 3.0212e-06,
        3.1544e-06, 1.7771e-05, 1.6963e-06, 6.3009e-06, 2.9881e-06, 3.5985e-06,
        9.5048e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,717][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0098, 0.0968, 0.1135, 0.0800, 0.1027, 0.0619, 0.0555, 0.0685, 0.0695,
        0.0877, 0.0717, 0.0869, 0.0956], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,717][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0047, 0.0909, 0.0854, 0.0671, 0.0816, 0.0658, 0.0666, 0.0828, 0.0852,
        0.0831, 0.0740, 0.0681, 0.0799, 0.0647], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,718][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0919, 0.1145, 0.3610, 0.0217, 0.1296, 0.0214, 0.0158, 0.0389, 0.0082,
        0.0540, 0.0260, 0.0364, 0.0126, 0.0681], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,718][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0624, 0.0826, 0.1440, 0.0523, 0.0751, 0.0533, 0.0665, 0.0748, 0.0710,
        0.0673, 0.0674, 0.0637, 0.0642, 0.0555], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,719][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.9711, 0.0062, 0.0035, 0.0022, 0.0021, 0.0022, 0.0016, 0.0021, 0.0014,
        0.0016, 0.0014, 0.0014, 0.0019, 0.0012], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,720][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([9.7132e-01, 1.7754e-03, 4.8744e-04, 7.4521e-04, 7.3290e-04, 8.9137e-04,
        1.1314e-03, 2.4145e-03, 8.1103e-03, 1.6679e-03, 2.6038e-03, 2.0013e-03,
        2.5699e-03, 3.5486e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,723][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0447, 0.0220, 0.2600, 0.0259, 0.1191, 0.0264, 0.0492, 0.0510, 0.0226,
        0.1328, 0.0649, 0.0527, 0.1009, 0.0277], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,723][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0055, 0.0797, 0.0858, 0.0692, 0.0832, 0.0716, 0.0767, 0.0727, 0.0757,
        0.0758, 0.0740, 0.0788, 0.0759, 0.0754], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,724][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0393, 0.0754, 0.0766, 0.0683, 0.0784, 0.0750, 0.0703, 0.0727, 0.0765,
        0.0791, 0.0674, 0.0698, 0.0749, 0.0765], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,724][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.7607, 0.0190, 0.0182, 0.0158, 0.0163, 0.0160, 0.0173, 0.0213, 0.0176,
        0.0199, 0.0173, 0.0216, 0.0207, 0.0183], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,725][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0021, 0.0687, 0.0784, 0.0607, 0.0958, 0.0703, 0.0757, 0.0769, 0.0684,
        0.0778, 0.0750, 0.0763, 0.1031, 0.0708], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,725][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.9999e-01, 1.0364e-06, 7.6532e-09, 4.4205e-08, 1.6496e-08, 2.4173e-07,
        2.4761e-07, 1.8966e-06, 1.2208e-07, 5.6951e-07, 2.4145e-07, 3.0712e-07,
        9.6977e-07, 5.3600e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,726][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0045, 0.0784, 0.1015, 0.0729, 0.0972, 0.0586, 0.0521, 0.0646, 0.0647,
        0.0851, 0.0686, 0.0851, 0.1016, 0.0651], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,729][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0056, 0.0839, 0.0777, 0.0630, 0.0743, 0.0618, 0.0625, 0.0756, 0.0784,
        0.0764, 0.0685, 0.0642, 0.0733, 0.0615, 0.0733], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,730][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.3304, 0.1035, 0.1961, 0.0226, 0.0847, 0.0279, 0.0140, 0.0279, 0.0056,
        0.0273, 0.0199, 0.0360, 0.0080, 0.0653, 0.0308], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,730][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0581, 0.0587, 0.1290, 0.0464, 0.0755, 0.0490, 0.0669, 0.0732, 0.0687,
        0.0661, 0.0661, 0.0611, 0.0631, 0.0541, 0.0639], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,731][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.9663, 0.0070, 0.0038, 0.0025, 0.0023, 0.0025, 0.0018, 0.0023, 0.0015,
        0.0018, 0.0017, 0.0016, 0.0021, 0.0015, 0.0013], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,731][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([9.8627e-01, 7.8894e-04, 1.5426e-04, 2.6652e-04, 2.3877e-04, 3.0159e-04,
        4.2366e-04, 9.5810e-04, 3.9105e-03, 6.5258e-04, 1.1403e-03, 8.0553e-04,
        1.0979e-03, 1.4960e-03, 1.4999e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,732][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0770, 0.0282, 0.1761, 0.0303, 0.1055, 0.0246, 0.0324, 0.0770, 0.0309,
        0.1419, 0.0422, 0.0377, 0.0674, 0.0211, 0.1077], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,733][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0055, 0.0745, 0.0801, 0.0640, 0.0774, 0.0665, 0.0710, 0.0678, 0.0701,
        0.0702, 0.0686, 0.0729, 0.0704, 0.0696, 0.0717], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,736][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0381, 0.0701, 0.0724, 0.0641, 0.0701, 0.0703, 0.0625, 0.0673, 0.0724,
        0.0729, 0.0642, 0.0627, 0.0701, 0.0698, 0.0727], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,736][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.7630, 0.0169, 0.0164, 0.0147, 0.0146, 0.0146, 0.0162, 0.0191, 0.0165,
        0.0185, 0.0162, 0.0203, 0.0192, 0.0171, 0.0165], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,737][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0024, 0.0649, 0.0719, 0.0554, 0.0861, 0.0658, 0.0700, 0.0723, 0.0629,
        0.0723, 0.0694, 0.0705, 0.0938, 0.0652, 0.0773], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,737][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([9.9998e-01, 3.4463e-06, 4.1549e-08, 1.8872e-07, 9.1021e-08, 9.4530e-07,
        1.0089e-06, 6.4774e-06, 4.9529e-07, 2.1323e-06, 9.5305e-07, 1.1646e-06,
        3.2319e-06, 2.0615e-07, 4.9873e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,738][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0062, 0.0673, 0.0872, 0.0667, 0.0865, 0.0553, 0.0520, 0.0631, 0.0630,
        0.0772, 0.0663, 0.0820, 0.0941, 0.0677, 0.0655], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,738][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0047, 0.0793, 0.0737, 0.0586, 0.0705, 0.0574, 0.0580, 0.0709, 0.0734,
        0.0711, 0.0638, 0.0594, 0.0686, 0.0572, 0.0691, 0.0642],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,739][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1462, 0.1378, 0.2050, 0.0204, 0.1074, 0.0201, 0.0158, 0.0516, 0.0089,
        0.0516, 0.0191, 0.0353, 0.0098, 0.1009, 0.0387, 0.0315],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,739][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0563, 0.0774, 0.1506, 0.0489, 0.0765, 0.0457, 0.0570, 0.0604, 0.0616,
        0.0560, 0.0558, 0.0523, 0.0535, 0.0461, 0.0548, 0.0473],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,743][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.9653, 0.0068, 0.0040, 0.0024, 0.0024, 0.0024, 0.0017, 0.0024, 0.0015,
        0.0018, 0.0016, 0.0016, 0.0020, 0.0014, 0.0013, 0.0014],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,743][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([9.6699e-01, 1.7268e-03, 3.7945e-04, 5.9365e-04, 5.8107e-04, 6.8894e-04,
        9.6052e-04, 2.0430e-03, 7.6062e-03, 1.4174e-03, 2.3214e-03, 1.8152e-03,
        2.2487e-03, 3.0916e-03, 3.1629e-03, 4.3686e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,744][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0265, 0.0396, 0.1625, 0.0376, 0.0790, 0.0181, 0.0381, 0.0788, 0.0312,
        0.1165, 0.0585, 0.0539, 0.0917, 0.0357, 0.0927, 0.0397],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,744][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0046, 0.0697, 0.0746, 0.0601, 0.0721, 0.0623, 0.0666, 0.0633, 0.0658,
        0.0657, 0.0642, 0.0682, 0.0658, 0.0651, 0.0669, 0.0648],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,745][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0348, 0.0655, 0.0677, 0.0602, 0.0678, 0.0643, 0.0593, 0.0638, 0.0662,
        0.0693, 0.0590, 0.0603, 0.0657, 0.0660, 0.0708, 0.0592],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,749][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.7063, 0.0199, 0.0192, 0.0166, 0.0172, 0.0168, 0.0181, 0.0219, 0.0183,
        0.0204, 0.0178, 0.0227, 0.0215, 0.0191, 0.0191, 0.0252],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,749][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0020, 0.0575, 0.0655, 0.0533, 0.0803, 0.0611, 0.0638, 0.0662, 0.0590,
        0.0674, 0.0647, 0.0656, 0.0884, 0.0617, 0.0731, 0.0703],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,749][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([9.9998e-01, 4.0426e-06, 4.7514e-08, 1.8923e-07, 8.9482e-08, 9.3550e-07,
        9.6249e-07, 6.1698e-06, 4.9814e-07, 2.0624e-06, 9.0514e-07, 1.1481e-06,
        3.2370e-06, 2.1575e-07, 4.8025e-07, 7.5948e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,750][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0055, 0.0693, 0.0869, 0.0639, 0.0848, 0.0509, 0.0473, 0.0579, 0.0586,
        0.0729, 0.0595, 0.0755, 0.0882, 0.0591, 0.0582, 0.0615],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,750][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0036, 0.0738, 0.0688, 0.0549, 0.0666, 0.0542, 0.0544, 0.0673, 0.0704,
        0.0675, 0.0606, 0.0561, 0.0651, 0.0541, 0.0655, 0.0612, 0.0559],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,751][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1268, 0.0676, 0.2491, 0.0201, 0.1312, 0.0176, 0.0092, 0.0574, 0.0077,
        0.0537, 0.0177, 0.0325, 0.0117, 0.1083, 0.0451, 0.0371, 0.0073],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,753][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0556, 0.0676, 0.1210, 0.0490, 0.0687, 0.0459, 0.0561, 0.0604, 0.0614,
        0.0555, 0.0559, 0.0522, 0.0533, 0.0458, 0.0546, 0.0471, 0.0499],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,755][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.9678, 0.0062, 0.0037, 0.0021, 0.0022, 0.0021, 0.0015, 0.0021, 0.0013,
        0.0016, 0.0014, 0.0014, 0.0018, 0.0012, 0.0012, 0.0013, 0.0012],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,756][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.7978e-01, 9.5554e-04, 1.9595e-04, 3.2402e-04, 3.0035e-04, 3.7514e-04,
        4.9496e-04, 1.0778e-03, 4.2023e-03, 7.3212e-04, 1.2203e-03, 9.1186e-04,
        1.1989e-03, 1.6520e-03, 1.6658e-03, 2.5163e-03, 2.4004e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,756][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0304, 0.0248, 0.1984, 0.0196, 0.1131, 0.0171, 0.0265, 0.0444, 0.0185,
        0.1006, 0.0545, 0.0409, 0.0833, 0.0282, 0.1284, 0.0389, 0.0325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,757][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0047, 0.0654, 0.0705, 0.0562, 0.0678, 0.0582, 0.0622, 0.0594, 0.0616,
        0.0616, 0.0604, 0.0640, 0.0618, 0.0610, 0.0627, 0.0605, 0.0621],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,757][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0282, 0.0614, 0.0638, 0.0570, 0.0658, 0.0617, 0.0559, 0.0589, 0.0630,
        0.0662, 0.0553, 0.0565, 0.0631, 0.0628, 0.0694, 0.0580, 0.0530],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,757][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6939, 0.0190, 0.0183, 0.0165, 0.0166, 0.0166, 0.0173, 0.0208, 0.0179,
        0.0197, 0.0174, 0.0218, 0.0206, 0.0189, 0.0183, 0.0251, 0.0213],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,761][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0018, 0.0548, 0.0615, 0.0502, 0.0746, 0.0567, 0.0584, 0.0629, 0.0553,
        0.0633, 0.0604, 0.0610, 0.0820, 0.0574, 0.0681, 0.0654, 0.0662],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,762][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9997e-01, 5.2596e-06, 6.9740e-08, 2.8508e-07, 1.3307e-07, 1.3702e-06,
        1.4302e-06, 8.5363e-06, 7.4671e-07, 3.0070e-06, 1.3774e-06, 1.6885e-06,
        4.5643e-06, 3.4047e-07, 6.9085e-07, 1.0908e-06, 1.7434e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,762][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0031, 0.0575, 0.0792, 0.0587, 0.0802, 0.0488, 0.0434, 0.0563, 0.0560,
        0.0730, 0.0590, 0.0744, 0.0924, 0.0572, 0.0547, 0.0612, 0.0447],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,763][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0038, 0.0694, 0.0646, 0.0522, 0.0626, 0.0515, 0.0517, 0.0635, 0.0660,
        0.0641, 0.0571, 0.0532, 0.0613, 0.0511, 0.0616, 0.0572, 0.0524, 0.0566],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,763][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.4482, 0.0546, 0.1535, 0.0089, 0.0758, 0.0106, 0.0120, 0.0311, 0.0034,
        0.0344, 0.0161, 0.0193, 0.0089, 0.0461, 0.0314, 0.0218, 0.0082, 0.0156],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,764][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0528, 0.0558, 0.1322, 0.0418, 0.0716, 0.0405, 0.0524, 0.0557, 0.0568,
        0.0517, 0.0534, 0.0488, 0.0494, 0.0429, 0.0522, 0.0437, 0.0472, 0.0512],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,768][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.9632, 0.0067, 0.0040, 0.0024, 0.0024, 0.0023, 0.0017, 0.0023, 0.0015,
        0.0017, 0.0015, 0.0015, 0.0020, 0.0013, 0.0013, 0.0014, 0.0013, 0.0015],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,768][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([9.7615e-01, 8.9396e-04, 1.9602e-04, 3.4410e-04, 3.1112e-04, 3.8129e-04,
        5.2543e-04, 1.1391e-03, 4.3144e-03, 7.7975e-04, 1.2732e-03, 9.6384e-04,
        1.2653e-03, 1.8021e-03, 1.8442e-03, 2.7317e-03, 2.6749e-03, 2.4059e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,769][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0385, 0.0297, 0.1530, 0.0278, 0.0927, 0.0180, 0.0313, 0.0564, 0.0278,
        0.0839, 0.0568, 0.0368, 0.0563, 0.0251, 0.1002, 0.0541, 0.0388, 0.0728],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,769][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0043, 0.0618, 0.0666, 0.0531, 0.0641, 0.0548, 0.0587, 0.0563, 0.0579,
        0.0582, 0.0568, 0.0603, 0.0582, 0.0573, 0.0592, 0.0570, 0.0582, 0.0573],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,770][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0342, 0.0577, 0.0611, 0.0536, 0.0616, 0.0571, 0.0541, 0.0560, 0.0595,
        0.0616, 0.0530, 0.0529, 0.0572, 0.0577, 0.0639, 0.0526, 0.0506, 0.0556],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,770][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.6998, 0.0169, 0.0166, 0.0143, 0.0150, 0.0147, 0.0162, 0.0196, 0.0165,
        0.0184, 0.0160, 0.0205, 0.0193, 0.0172, 0.0169, 0.0232, 0.0201, 0.0189],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,774][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0018, 0.0522, 0.0569, 0.0454, 0.0698, 0.0526, 0.0552, 0.0584, 0.0512,
        0.0584, 0.0565, 0.0569, 0.0754, 0.0529, 0.0631, 0.0611, 0.0624, 0.0699],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,775][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([9.9998e-01, 3.1336e-06, 3.7071e-08, 1.8303e-07, 8.1913e-08, 9.3058e-07,
        9.7592e-07, 6.0381e-06, 4.7902e-07, 2.0350e-06, 9.3123e-07, 1.1527e-06,
        3.2267e-06, 2.1268e-07, 4.7713e-07, 7.1747e-07, 1.1914e-06, 1.1817e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,775][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0039, 0.0614, 0.0814, 0.0575, 0.0788, 0.0469, 0.0427, 0.0525, 0.0518,
        0.0672, 0.0528, 0.0688, 0.0812, 0.0514, 0.0514, 0.0566, 0.0414, 0.0520],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:51,776][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0042, 0.0650, 0.0612, 0.0491, 0.0584, 0.0481, 0.0488, 0.0598, 0.0611,
        0.0599, 0.0533, 0.0496, 0.0582, 0.0476, 0.0583, 0.0540, 0.0496, 0.0539,
        0.0600], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,776][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1259, 0.0615, 0.2822, 0.0180, 0.1968, 0.0168, 0.0107, 0.0376, 0.0030,
        0.0496, 0.0117, 0.0158, 0.0088, 0.0691, 0.0474, 0.0172, 0.0056, 0.0173,
        0.0051], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,777][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0539, 0.0542, 0.0959, 0.0414, 0.0531, 0.0416, 0.0523, 0.0567, 0.0574,
        0.0517, 0.0521, 0.0497, 0.0508, 0.0437, 0.0506, 0.0458, 0.0486, 0.0499,
        0.0507], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,777][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.6745e-01, 5.9185e-03, 3.4107e-03, 2.0677e-03, 2.0311e-03, 2.0208e-03,
        1.4646e-03, 2.0053e-03, 1.2441e-03, 1.4940e-03, 1.2946e-03, 1.2910e-03,
        1.7193e-03, 1.1098e-03, 1.0717e-03, 1.1865e-03, 1.0975e-03, 1.2638e-03,
        8.6235e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,781][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.9196, 0.0038, 0.0009, 0.0013, 0.0011, 0.0013, 0.0018, 0.0032, 0.0091,
        0.0024, 0.0033, 0.0026, 0.0033, 0.0040, 0.0041, 0.0058, 0.0054, 0.0050,
        0.0217], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,782][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0370, 0.0188, 0.1391, 0.0172, 0.0949, 0.0138, 0.0309, 0.0410, 0.0145,
        0.0961, 0.0386, 0.0360, 0.0755, 0.0207, 0.1178, 0.0446, 0.0379, 0.1043,
        0.0213], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,782][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0040, 0.0576, 0.0630, 0.0498, 0.0605, 0.0516, 0.0554, 0.0529, 0.0549,
        0.0552, 0.0539, 0.0573, 0.0553, 0.0545, 0.0562, 0.0540, 0.0553, 0.0543,
        0.0546], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,783][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0267, 0.0544, 0.0570, 0.0509, 0.0582, 0.0551, 0.0512, 0.0533, 0.0559,
        0.0585, 0.0490, 0.0510, 0.0556, 0.0555, 0.0613, 0.0524, 0.0485, 0.0561,
        0.0493], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,783][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6540, 0.0190, 0.0182, 0.0163, 0.0166, 0.0162, 0.0175, 0.0210, 0.0177,
        0.0195, 0.0172, 0.0216, 0.0205, 0.0186, 0.0180, 0.0242, 0.0212, 0.0211,
        0.0218], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,787][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0016, 0.0489, 0.0547, 0.0435, 0.0668, 0.0496, 0.0529, 0.0545, 0.0483,
        0.0552, 0.0528, 0.0536, 0.0724, 0.0502, 0.0601, 0.0574, 0.0589, 0.0663,
        0.0523], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,787][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9998e-01, 3.3086e-06, 3.5282e-08, 1.5909e-07, 7.1984e-08, 7.8836e-07,
        8.4163e-07, 5.2782e-06, 4.2223e-07, 1.7250e-06, 7.7844e-07, 9.7342e-07,
        2.6609e-06, 1.8205e-07, 3.8825e-07, 6.1025e-07, 1.0018e-06, 9.4901e-07,
        9.3067e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,788][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0026, 0.0507, 0.0717, 0.0520, 0.0741, 0.0437, 0.0401, 0.0511, 0.0501,
        0.0669, 0.0521, 0.0679, 0.0837, 0.0533, 0.0520, 0.0554, 0.0415, 0.0558,
        0.0353], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:51,832][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:51,834][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,836][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,836][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,837][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,837][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,837][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,838][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,838][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,838][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,839][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,840][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,843][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:51,843][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.0000e+00, 3.9267e-09], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,844][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0932, 0.9068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,844][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3056, 0.6944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,844][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7166, 0.2834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,845][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9960e-01, 4.0203e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,845][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3806, 0.6194], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,845][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9734, 0.0266], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,846][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4816, 0.5184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,849][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9466, 0.0534], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,849][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0695, 0.9305], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,850][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2909, 0.7091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,850][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0110, 0.9890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:51,850][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([1.0000e+00, 7.8685e-09, 3.0500e-08], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,851][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0484, 0.4813, 0.4703], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,851][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.1783, 0.4338, 0.3879], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,851][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.6535, 0.1509, 0.1956], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,853][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.9944, 0.0041, 0.0015], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,856][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.2749, 0.3615, 0.3636], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,856][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.9550, 0.0166, 0.0284], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,856][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.3048, 0.3318, 0.3635], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,857][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.8914, 0.0534, 0.0552], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,857][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0702, 0.5602, 0.3695], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,857][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.4874, 0.2684, 0.2442], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,858][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0017, 0.0069, 0.9914], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:51,858][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.0000e+00, 2.1607e-09, 1.9888e-08, 2.1794e-10], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,862][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0296, 0.3104, 0.3006, 0.3594], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,862][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1520, 0.2956, 0.2759, 0.2765], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,862][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1838, 0.2807, 0.4878, 0.0477], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,863][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9718e-01, 1.8768e-03, 6.8609e-04, 2.5497e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,863][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1654, 0.2848, 0.3133, 0.2365], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,863][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9864, 0.0054, 0.0040, 0.0041], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,864][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2268, 0.2485, 0.2729, 0.2518], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,864][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8454, 0.0520, 0.0563, 0.0463], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,868][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0350, 0.3326, 0.2787, 0.3538], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,868][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2224, 0.2562, 0.2748, 0.2466], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,869][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0006, 0.0127, 0.4767, 0.5100], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:51,869][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([1.0000e+00, 2.5664e-08, 8.2006e-08, 1.2394e-08, 5.6673e-08],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,870][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0279, 0.2247, 0.2194, 0.2719, 0.2560], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,870][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0711, 0.2560, 0.2422, 0.2504, 0.1804], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,870][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.4254, 0.1088, 0.2796, 0.0380, 0.1482], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,871][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.9880, 0.0084, 0.0014, 0.0013, 0.0010], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,874][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.1490, 0.2262, 0.2309, 0.1793, 0.2146], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,875][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.9482, 0.0097, 0.0102, 0.0041, 0.0277], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,875][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1791, 0.1940, 0.2129, 0.1963, 0.2176], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,876][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.8301, 0.0433, 0.0461, 0.0391, 0.0414], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,876][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0342, 0.2566, 0.2071, 0.3088, 0.1934], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,876][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.2892, 0.1823, 0.1739, 0.1661, 0.1885], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,877][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([2.2095e-04, 2.9485e-03, 1.7498e-01, 1.9003e-01, 6.3182e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:51,877][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([1.0000e+00, 2.1535e-09, 1.6487e-08, 4.6090e-10, 1.0189e-08, 1.3196e-09],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,881][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0179, 0.1783, 0.1696, 0.2097, 0.2024, 0.2221], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,881][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0876, 0.2271, 0.1653, 0.2071, 0.1459, 0.1670], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,882][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1189, 0.0971, 0.4328, 0.0340, 0.1910, 0.1262], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,882][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([9.9408e-01, 2.4873e-03, 9.9858e-04, 4.1862e-04, 8.3296e-04, 1.1863e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,882][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0994, 0.1900, 0.2041, 0.1559, 0.1876, 0.1629], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,883][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.9877, 0.0022, 0.0022, 0.0012, 0.0044, 0.0023], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,883][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1487, 0.1620, 0.1773, 0.1635, 0.1812, 0.1672], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,883][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7357, 0.0504, 0.0549, 0.0466, 0.0515, 0.0608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,887][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0155, 0.2047, 0.1724, 0.2375, 0.1716, 0.1983], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,888][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2136, 0.1580, 0.1384, 0.1474, 0.1537, 0.1890], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,888][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([2.4333e-04, 2.5028e-03, 1.1949e-01, 9.4773e-02, 5.3225e-01, 2.5073e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:51,888][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.0000e+00, 4.0256e-09, 2.6427e-08, 7.8705e-10, 1.4595e-08, 1.9058e-09,
        7.8165e-09], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,889][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0171, 0.1434, 0.1385, 0.1710, 0.1645, 0.1794, 0.1862],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,889][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0697, 0.1528, 0.1575, 0.1444, 0.1470, 0.1425, 0.1862],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,889][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3333, 0.0381, 0.1168, 0.0158, 0.0680, 0.1328, 0.2953],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,890][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9837e-01, 4.7999e-04, 1.7476e-04, 8.1213e-05, 1.7097e-04, 2.9109e-04,
        4.3647e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,894][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0942, 0.1609, 0.1703, 0.1352, 0.1609, 0.1435, 0.1350],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,894][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.8808e-01, 2.0314e-03, 1.6593e-03, 8.8094e-04, 3.3416e-03, 1.0517e-03,
        2.9581e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,894][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1291, 0.1372, 0.1501, 0.1392, 0.1535, 0.1425, 0.1483],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,895][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7066, 0.0426, 0.0444, 0.0399, 0.0423, 0.0525, 0.0717],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,895][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0189, 0.1667, 0.1378, 0.2117, 0.1434, 0.1823, 0.1393],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,895][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2189, 0.1326, 0.1109, 0.1176, 0.1216, 0.1529, 0.1455],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,896][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.7636e-04, 1.7212e-03, 6.4831e-02, 9.0070e-02, 4.0039e-01, 3.1690e-01,
        1.2591e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:51,896][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([1.0000e+00, 5.7701e-09, 3.3482e-08, 1.7654e-09, 1.8225e-08, 3.1775e-09,
        3.3317e-08, 1.2368e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,900][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0166, 0.1173, 0.1092, 0.1376, 0.1298, 0.1477, 0.1524, 0.1893],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,900][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0902, 0.1411, 0.1284, 0.1342, 0.1048, 0.1213, 0.1495, 0.1306],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,901][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.4333, 0.0142, 0.0564, 0.0032, 0.0181, 0.0328, 0.0913, 0.3507],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,901][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([9.9636e-01, 4.4438e-04, 5.1987e-04, 1.0126e-04, 4.8097e-04, 3.3839e-04,
        7.0344e-04, 1.0557e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,901][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1044, 0.1382, 0.1383, 0.1115, 0.1279, 0.1174, 0.1148, 0.1475],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,902][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.9416, 0.0050, 0.0042, 0.0026, 0.0077, 0.0029, 0.0049, 0.0311],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,902][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1134, 0.1193, 0.1293, 0.1197, 0.1318, 0.1225, 0.1284, 0.1356],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,904][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.6972, 0.0308, 0.0319, 0.0284, 0.0306, 0.0379, 0.0632, 0.0800],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,906][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0166, 0.1372, 0.1215, 0.1743, 0.1270, 0.1543, 0.1343, 0.1348],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,907][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.1051, 0.1207, 0.1107, 0.1179, 0.1153, 0.1485, 0.1422, 0.1395],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,907][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.2453e-04, 1.8603e-03, 5.3011e-02, 6.3939e-02, 3.4248e-01, 2.5802e-01,
        1.6404e-01, 1.1653e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:51,908][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([1.0000e+00, 2.7288e-09, 1.9009e-08, 5.9912e-10, 1.1010e-08, 1.6995e-09,
        1.5450e-08, 9.1203e-09, 2.4347e-09], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,908][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0125, 0.0967, 0.0939, 0.1148, 0.1119, 0.1225, 0.1295, 0.1590, 0.1591],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,908][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0600, 0.1281, 0.1135, 0.1161, 0.1157, 0.1109, 0.1415, 0.1083, 0.1060],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,909][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1510, 0.0108, 0.0413, 0.0041, 0.0144, 0.0338, 0.1266, 0.3828, 0.2353],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,910][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([9.9759e-01, 3.1308e-04, 1.1788e-04, 3.9496e-05, 9.2079e-05, 1.3309e-04,
        2.7471e-04, 6.9223e-04, 7.4335e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,913][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0713, 0.1225, 0.1291, 0.1024, 0.1217, 0.1086, 0.1049, 0.1360, 0.1036],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,913][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.8549, 0.0080, 0.0092, 0.0046, 0.0196, 0.0041, 0.0100, 0.0249, 0.0647],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,914][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0999, 0.1054, 0.1146, 0.1064, 0.1170, 0.1089, 0.1135, 0.1204, 0.1139],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,914][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.7365, 0.0229, 0.0235, 0.0214, 0.0222, 0.0305, 0.0438, 0.0634, 0.0358],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,914][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0250, 0.1187, 0.1167, 0.1580, 0.1210, 0.1292, 0.1069, 0.1065, 0.1181],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,915][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0393, 0.1061, 0.1277, 0.1116, 0.1243, 0.1349, 0.1346, 0.1161, 0.1054],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,915][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([4.7332e-04, 1.9455e-03, 3.3487e-02, 2.7756e-02, 1.4440e-01, 8.1730e-02,
        4.1781e-02, 5.7054e-02, 6.1137e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:51,917][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([1.0000e+00, 3.1738e-09, 1.4700e-08, 1.2116e-09, 7.4252e-09, 2.1113e-09,
        2.2769e-08, 1.1128e-08, 8.2324e-09, 8.6154e-10], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,919][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0121, 0.0822, 0.0793, 0.0983, 0.0940, 0.1063, 0.1113, 0.1392, 0.1410,
        0.1363], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,920][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0569, 0.1112, 0.1077, 0.1101, 0.0953, 0.1053, 0.1122, 0.0905, 0.0970,
        0.1137], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,920][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.1544, 0.0127, 0.0346, 0.0025, 0.0117, 0.0205, 0.0749, 0.2963, 0.1522,
        0.2401], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,920][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([9.7965e-01, 3.1762e-03, 1.0484e-03, 5.2232e-04, 8.3798e-04, 1.4133e-03,
        2.4042e-03, 3.7883e-03, 4.5434e-03, 2.6181e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,921][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0723, 0.1087, 0.1115, 0.0883, 0.1034, 0.0927, 0.0909, 0.1176, 0.0943,
        0.1203], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,921][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.8920, 0.0050, 0.0048, 0.0023, 0.0080, 0.0036, 0.0038, 0.0211, 0.0231,
        0.0363], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,922][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0887, 0.0943, 0.1021, 0.0944, 0.1039, 0.0966, 0.1013, 0.1077, 0.1016,
        0.1093], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,925][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.4358, 0.0378, 0.0404, 0.0370, 0.0385, 0.0465, 0.0754, 0.0995, 0.0732,
        0.1158], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,926][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0107, 0.1044, 0.0944, 0.1270, 0.0953, 0.1191, 0.1003, 0.1034, 0.1380,
        0.1074], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,926][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1347, 0.0886, 0.0697, 0.0777, 0.0776, 0.1040, 0.0973, 0.1048, 0.1311,
        0.1145], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,927][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.4398e-04, 7.6903e-04, 2.2171e-02, 1.7692e-02, 7.0066e-02, 5.1353e-02,
        3.4103e-02, 4.1706e-02, 4.3805e-01, 3.2395e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:51,927][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([1.0000e+00, 9.8886e-09, 6.1631e-08, 1.6928e-09, 3.4014e-08, 5.2847e-09,
        2.9452e-08, 1.4456e-08, 6.9192e-09, 3.2353e-09, 5.8987e-09],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,927][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0091, 0.0741, 0.0711, 0.0880, 0.0831, 0.0947, 0.0979, 0.1255, 0.1268,
        0.1212, 0.1085], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,928][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0355, 0.1039, 0.0997, 0.1022, 0.0887, 0.1008, 0.1163, 0.0813, 0.0890,
        0.1038, 0.0787], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,932][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0425, 0.0108, 0.0339, 0.0039, 0.0147, 0.0240, 0.1101, 0.1892, 0.1629,
        0.2367, 0.1714], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,932][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([9.8914e-01, 8.4419e-04, 4.3922e-04, 1.5215e-04, 3.2780e-04, 4.3409e-04,
        7.3302e-04, 2.1110e-03, 2.2753e-03, 1.6184e-03, 1.9255e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,933][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0580, 0.0999, 0.1044, 0.0830, 0.0963, 0.0871, 0.0829, 0.1061, 0.0853,
        0.1102, 0.0868], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,933][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.8815, 0.0055, 0.0047, 0.0030, 0.0076, 0.0027, 0.0049, 0.0184, 0.0291,
        0.0160, 0.0265], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,933][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0786, 0.0852, 0.0928, 0.0862, 0.0947, 0.0880, 0.0921, 0.0977, 0.0922,
        0.0995, 0.0932], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,934][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.4895, 0.0295, 0.0298, 0.0292, 0.0294, 0.0379, 0.0564, 0.0777, 0.0520,
        0.0967, 0.0719], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,934][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0167, 0.1015, 0.0872, 0.1145, 0.0938, 0.1026, 0.0869, 0.0947, 0.1109,
        0.1029, 0.0883], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,938][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0995, 0.0795, 0.0718, 0.0740, 0.0757, 0.0921, 0.0928, 0.0921, 0.1109,
        0.1091, 0.1025], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,939][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([3.2664e-04, 1.6753e-03, 9.7779e-03, 9.7925e-03, 3.6097e-02, 2.3542e-02,
        1.2627e-02, 1.6506e-02, 2.0411e-01, 1.8874e-01, 4.9681e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:51,939][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.0000e+00, 6.7036e-09, 4.3649e-08, 1.2366e-09, 2.2835e-08, 3.1518e-09,
        1.7881e-08, 1.3021e-08, 5.4967e-09, 2.4533e-09, 5.6551e-09, 4.2751e-09],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,939][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0097, 0.0669, 0.0636, 0.0783, 0.0752, 0.0844, 0.0880, 0.1082, 0.1108,
        0.1052, 0.0969, 0.1129], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,940][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0409, 0.0868, 0.0917, 0.0824, 0.0886, 0.0872, 0.1095, 0.0842, 0.0704,
        0.0959, 0.0666, 0.0958], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,940][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1101, 0.0047, 0.0193, 0.0017, 0.0076, 0.0183, 0.0502, 0.1256, 0.0842,
        0.1542, 0.1657, 0.2585], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,941][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9841e-01, 1.1764e-04, 6.4405e-05, 1.9893e-05, 5.4922e-05, 7.0528e-05,
        1.0597e-04, 2.2582e-04, 2.1093e-04, 1.7682e-04, 3.5806e-04, 1.8100e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,945][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0533, 0.0914, 0.0958, 0.0755, 0.0885, 0.0800, 0.0763, 0.0981, 0.0781,
        0.1018, 0.0801, 0.0811], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,945][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.4663e-01, 1.9220e-03, 1.6816e-03, 8.8316e-04, 3.1372e-03, 1.1302e-03,
        2.1235e-03, 8.6678e-03, 1.3299e-02, 8.1711e-03, 6.2440e-03, 6.1076e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,945][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0747, 0.0775, 0.0844, 0.0783, 0.0862, 0.0800, 0.0838, 0.0889, 0.0841,
        0.0907, 0.0855, 0.0859], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,946][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.5003, 0.0247, 0.0247, 0.0238, 0.0243, 0.0315, 0.0484, 0.0648, 0.0455,
        0.0795, 0.0655, 0.0669], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,946][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0104, 0.0910, 0.0796, 0.1068, 0.0772, 0.0942, 0.0792, 0.0898, 0.1080,
        0.0920, 0.0884, 0.0834], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,947][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1083, 0.0730, 0.0616, 0.0668, 0.0678, 0.0839, 0.0820, 0.0840, 0.1043,
        0.0951, 0.0896, 0.0835], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,947][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.4444e-04, 5.1751e-04, 4.3576e-03, 3.3787e-03, 1.3731e-02, 9.2642e-03,
        3.4363e-03, 6.8817e-03, 9.8956e-02, 8.1102e-02, 3.2349e-01, 4.5464e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:51,948][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([1.0000e+00, 1.2389e-08, 4.6292e-08, 4.5843e-09, 2.9155e-08, 6.7351e-09,
        6.7988e-08, 2.4043e-08, 2.4904e-08, 3.9532e-09, 2.6537e-08, 2.4549e-08,
        3.0169e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,951][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0084, 0.0594, 0.0566, 0.0697, 0.0654, 0.0767, 0.0787, 0.0989, 0.1000,
        0.0968, 0.0902, 0.1044, 0.0948], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,951][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0427, 0.0891, 0.0784, 0.0878, 0.0686, 0.0767, 0.0855, 0.0781, 0.0778,
        0.0962, 0.0642, 0.0790, 0.0760], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,952][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.1683, 0.0027, 0.0126, 0.0011, 0.0048, 0.0147, 0.0328, 0.0809, 0.0585,
        0.1053, 0.1553, 0.2105, 0.1525], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,952][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([9.9314e-01, 4.1083e-04, 2.0976e-04, 8.5224e-05, 1.5526e-04, 2.3957e-04,
        6.2070e-04, 8.4366e-04, 8.0790e-04, 7.0440e-04, 1.0322e-03, 7.1102e-04,
        1.0415e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,953][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0618, 0.0840, 0.0852, 0.0667, 0.0782, 0.0703, 0.0700, 0.0894, 0.0732,
        0.0909, 0.0738, 0.0726, 0.0838], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,953][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.8473, 0.0058, 0.0054, 0.0027, 0.0091, 0.0026, 0.0046, 0.0248, 0.0247,
        0.0212, 0.0162, 0.0095, 0.0260], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,954][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0680, 0.0710, 0.0773, 0.0717, 0.0789, 0.0735, 0.0770, 0.0818, 0.0773,
        0.0830, 0.0785, 0.0790, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,957][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.4958, 0.0204, 0.0211, 0.0206, 0.0206, 0.0277, 0.0438, 0.0559, 0.0385,
        0.0683, 0.0566, 0.0619, 0.0686], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,958][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.0099, 0.0786, 0.0777, 0.1011, 0.0706, 0.0930, 0.0772, 0.0787, 0.0996,
        0.0782, 0.0817, 0.0780, 0.0758], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,958][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0638, 0.0676, 0.0649, 0.0659, 0.0680, 0.0846, 0.0831, 0.0780, 0.0871,
        0.0924, 0.0817, 0.0801, 0.0828], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,959][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([9.5864e-06, 1.0184e-04, 1.0773e-03, 2.0934e-03, 6.1738e-03, 7.8533e-03,
        6.2399e-03, 4.5524e-03, 8.0375e-02, 4.7932e-02, 2.6604e-01, 5.6647e-01,
        1.1087e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:51,959][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.0000e+00, 6.9565e-09, 6.1019e-08, 9.7589e-10, 3.1952e-08, 6.2589e-09,
        3.8744e-08, 2.1476e-08, 6.0621e-09, 4.1764e-09, 6.7756e-09, 1.0730e-08,
        4.2058e-08, 2.0894e-09], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,959][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0073, 0.0578, 0.0547, 0.0656, 0.0627, 0.0691, 0.0725, 0.0899, 0.0918,
        0.0870, 0.0803, 0.0939, 0.0846, 0.0826], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,960][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0342, 0.0802, 0.0746, 0.0729, 0.0674, 0.0737, 0.0860, 0.0660, 0.0579,
        0.0929, 0.0610, 0.0731, 0.0845, 0.0756], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,964][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0718, 0.0069, 0.0136, 0.0009, 0.0046, 0.0085, 0.0347, 0.0976, 0.0616,
        0.1436, 0.1011, 0.1939, 0.1385, 0.1225], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,964][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([9.9389e-01, 2.1359e-04, 1.1239e-04, 4.4638e-05, 8.3936e-05, 1.6220e-04,
        2.5633e-04, 5.6476e-04, 6.3868e-04, 4.5596e-04, 1.0456e-03, 4.2640e-04,
        1.1781e-03, 9.3195e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,964][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0423, 0.0777, 0.0826, 0.0643, 0.0761, 0.0672, 0.0649, 0.0857, 0.0647,
        0.0884, 0.0692, 0.0707, 0.0865, 0.0597], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,965][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.8786, 0.0029, 0.0027, 0.0020, 0.0056, 0.0019, 0.0040, 0.0142, 0.0245,
        0.0130, 0.0164, 0.0067, 0.0136, 0.0140], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,965][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0622, 0.0665, 0.0721, 0.0664, 0.0733, 0.0680, 0.0712, 0.0756, 0.0715,
        0.0770, 0.0724, 0.0730, 0.0766, 0.0743], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,966][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.5303, 0.0216, 0.0200, 0.0184, 0.0188, 0.0248, 0.0345, 0.0482, 0.0291,
        0.0626, 0.0451, 0.0479, 0.0520, 0.0468], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,967][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0100, 0.0770, 0.0680, 0.0900, 0.0718, 0.0755, 0.0709, 0.0731, 0.0913,
        0.0731, 0.0731, 0.0743, 0.0760, 0.0761], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,970][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0862, 0.0619, 0.0558, 0.0586, 0.0630, 0.0731, 0.0714, 0.0758, 0.0896,
        0.0828, 0.0772, 0.0733, 0.0772, 0.0538], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,970][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([4.8245e-04, 9.7258e-04, 2.1027e-03, 7.8492e-04, 2.7613e-03, 1.2835e-03,
        4.8251e-04, 1.2162e-03, 1.2562e-02, 1.3025e-02, 3.6854e-02, 4.8140e-02,
        1.5183e-03, 8.7781e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:51,971][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([1.0000e+00, 2.0974e-08, 9.2839e-08, 8.0184e-09, 5.9779e-08, 1.5160e-08,
        1.0539e-07, 6.4332e-08, 4.5964e-08, 7.9063e-09, 3.0425e-08, 4.8610e-08,
        9.8639e-08, 1.7205e-08, 2.6355e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,971][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0073, 0.0502, 0.0486, 0.0597, 0.0568, 0.0645, 0.0662, 0.0826, 0.0834,
        0.0808, 0.0749, 0.0885, 0.0806, 0.0754, 0.0805], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,972][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0214, 0.0779, 0.0791, 0.0762, 0.0589, 0.0638, 0.0659, 0.0722, 0.0657,
        0.0957, 0.0610, 0.0643, 0.0714, 0.0736, 0.0529], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,972][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0791, 0.0028, 0.0079, 0.0010, 0.0032, 0.0152, 0.0316, 0.0632, 0.0452,
        0.0662, 0.0907, 0.1725, 0.1222, 0.1877, 0.1112], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,973][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([9.7952e-01, 1.4059e-03, 3.3388e-04, 2.4591e-04, 2.0871e-04, 5.9694e-04,
        1.3431e-03, 1.8896e-03, 1.7245e-03, 1.2528e-03, 3.2850e-03, 1.4590e-03,
        2.4184e-03, 2.8711e-03, 1.4409e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,976][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0469, 0.0732, 0.0745, 0.0588, 0.0699, 0.0618, 0.0605, 0.0763, 0.0638,
        0.0803, 0.0646, 0.0643, 0.0745, 0.0571, 0.0736], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,977][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.7645, 0.0064, 0.0065, 0.0028, 0.0181, 0.0027, 0.0049, 0.0198, 0.0243,
        0.0268, 0.0115, 0.0101, 0.0314, 0.0148, 0.0555], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,977][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0587, 0.0612, 0.0665, 0.0615, 0.0678, 0.0633, 0.0662, 0.0704, 0.0663,
        0.0713, 0.0674, 0.0679, 0.0713, 0.0692, 0.0710], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,978][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.4918, 0.0197, 0.0189, 0.0182, 0.0176, 0.0221, 0.0373, 0.0442, 0.0322,
        0.0552, 0.0456, 0.0496, 0.0557, 0.0519, 0.0401], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,978][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0121, 0.0701, 0.0610, 0.0830, 0.0557, 0.0798, 0.0641, 0.0668, 0.0812,
        0.0700, 0.0713, 0.0692, 0.0741, 0.0736, 0.0680], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,979][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0957, 0.0594, 0.0516, 0.0537, 0.0536, 0.0692, 0.0673, 0.0687, 0.0830,
        0.0762, 0.0723, 0.0676, 0.0724, 0.0439, 0.0654], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,980][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([2.6612e-06, 5.9982e-05, 4.5196e-04, 5.1231e-04, 1.4635e-03, 1.2820e-03,
        7.7592e-04, 7.6603e-04, 1.2891e-02, 4.6834e-03, 3.1369e-02, 5.3567e-02,
        1.7907e-03, 8.8591e-01, 4.4742e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:51,981][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.0000e+00, 7.6989e-09, 4.4238e-08, 2.0650e-09, 3.1452e-08, 4.6330e-09,
        3.5897e-08, 2.3345e-08, 1.4940e-08, 2.6357e-09, 1.0122e-08, 1.6258e-08,
        5.7994e-08, 4.2144e-09, 1.2840e-08, 4.1917e-09], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,983][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0066, 0.0481, 0.0449, 0.0556, 0.0526, 0.0589, 0.0622, 0.0762, 0.0783,
        0.0749, 0.0682, 0.0807, 0.0717, 0.0713, 0.0717, 0.0782],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,983][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0389, 0.0755, 0.0721, 0.0662, 0.0553, 0.0630, 0.0716, 0.0622, 0.0615,
        0.0836, 0.0531, 0.0633, 0.0687, 0.0710, 0.0489, 0.0450],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,984][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0778, 0.0028, 0.0137, 0.0010, 0.0045, 0.0077, 0.0261, 0.0666, 0.0553,
        0.0880, 0.1060, 0.1691, 0.1233, 0.1029, 0.0829, 0.0722],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,984][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.8365e-01, 5.9628e-04, 2.3532e-04, 9.5505e-05, 2.1557e-04, 3.1836e-04,
        8.4780e-04, 1.4682e-03, 1.1655e-03, 7.9018e-04, 2.4293e-03, 1.2284e-03,
        2.0269e-03, 1.4181e-03, 1.8675e-03, 1.6469e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,985][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0413, 0.0686, 0.0705, 0.0554, 0.0650, 0.0577, 0.0562, 0.0727, 0.0581,
        0.0752, 0.0594, 0.0600, 0.0714, 0.0521, 0.0689, 0.0675],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,985][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.7425, 0.0055, 0.0040, 0.0032, 0.0082, 0.0042, 0.0069, 0.0258, 0.0287,
        0.0269, 0.0190, 0.0149, 0.0238, 0.0176, 0.0253, 0.0434],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,988][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0554, 0.0573, 0.0622, 0.0574, 0.0635, 0.0588, 0.0618, 0.0657, 0.0619,
        0.0669, 0.0631, 0.0635, 0.0666, 0.0646, 0.0666, 0.0647],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,990][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.3710, 0.0219, 0.0214, 0.0190, 0.0208, 0.0253, 0.0407, 0.0519, 0.0350,
        0.0609, 0.0490, 0.0566, 0.0624, 0.0542, 0.0483, 0.0615],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,990][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0062, 0.0676, 0.0595, 0.0792, 0.0578, 0.0656, 0.0558, 0.0600, 0.0795,
        0.0635, 0.0664, 0.0660, 0.0691, 0.0719, 0.0697, 0.0623],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,991][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0534, 0.0579, 0.0575, 0.0577, 0.0580, 0.0688, 0.0678, 0.0645, 0.0703,
        0.0755, 0.0681, 0.0671, 0.0684, 0.0445, 0.0609, 0.0598],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,991][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([8.8676e-05, 7.0562e-04, 2.6203e-03, 1.0641e-03, 5.1553e-03, 1.3727e-03,
        7.8403e-04, 1.5426e-03, 1.4373e-02, 1.0514e-02, 2.1360e-02, 5.7748e-02,
        1.7327e-03, 8.4499e-01, 9.3612e-03, 2.6586e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:51,991][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.0000e+00, 6.3365e-09, 3.8183e-08, 1.3720e-09, 2.1451e-08, 3.1418e-09,
        1.1987e-08, 1.4912e-08, 6.5248e-09, 2.2148e-09, 6.4074e-09, 4.8342e-09,
        2.2449e-08, 2.8531e-09, 7.2341e-09, 3.9638e-09, 8.4353e-09],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,992][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0061, 0.0449, 0.0422, 0.0519, 0.0491, 0.0550, 0.0568, 0.0710, 0.0725,
        0.0691, 0.0633, 0.0744, 0.0671, 0.0658, 0.0666, 0.0727, 0.0714],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,996][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0283, 0.0618, 0.0661, 0.0569, 0.0620, 0.0626, 0.0767, 0.0602, 0.0479,
        0.0717, 0.0462, 0.0704, 0.0702, 0.0574, 0.0544, 0.0475, 0.0596],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,996][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0900, 0.0012, 0.0048, 0.0005, 0.0021, 0.0054, 0.0123, 0.0424, 0.0289,
        0.0563, 0.0704, 0.1028, 0.0908, 0.0956, 0.0674, 0.1078, 0.2213],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,997][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9735e-01, 5.5118e-05, 3.3590e-05, 1.0345e-05, 2.9397e-05, 4.5643e-05,
        6.3632e-05, 1.3584e-04, 1.4204e-04, 1.1582e-04, 3.3094e-04, 1.1450e-04,
        3.3017e-04, 2.5142e-04, 2.2477e-04, 5.4397e-04, 2.2440e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,997][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0358, 0.0623, 0.0661, 0.0525, 0.0618, 0.0561, 0.0536, 0.0680, 0.0547,
        0.0708, 0.0570, 0.0573, 0.0686, 0.0495, 0.0665, 0.0658, 0.0536],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,998][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8465, 0.0030, 0.0025, 0.0013, 0.0048, 0.0016, 0.0046, 0.0124, 0.0192,
        0.0116, 0.0103, 0.0083, 0.0166, 0.0092, 0.0158, 0.0160, 0.0163],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:51,998][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0517, 0.0536, 0.0583, 0.0540, 0.0595, 0.0554, 0.0580, 0.0617, 0.0582,
        0.0627, 0.0591, 0.0595, 0.0625, 0.0607, 0.0623, 0.0610, 0.0617],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,003][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4275, 0.0183, 0.0173, 0.0165, 0.0170, 0.0212, 0.0320, 0.0424, 0.0292,
        0.0510, 0.0419, 0.0445, 0.0503, 0.0480, 0.0382, 0.0522, 0.0526],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,005][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0091, 0.0608, 0.0533, 0.0769, 0.0546, 0.0666, 0.0518, 0.0595, 0.0715,
        0.0615, 0.0604, 0.0588, 0.0631, 0.0644, 0.0652, 0.0667, 0.0558],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,006][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0493, 0.0516, 0.0530, 0.0524, 0.0547, 0.0648, 0.0649, 0.0612, 0.0667,
        0.0734, 0.0658, 0.0639, 0.0660, 0.0430, 0.0587, 0.0578, 0.0529],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,006][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.1463e-05, 3.1282e-04, 1.0676e-03, 6.4552e-04, 2.4247e-03, 1.0243e-03,
        3.5318e-04, 8.9419e-04, 1.0617e-02, 8.8806e-03, 2.7137e-02, 3.6181e-02,
        1.3845e-03, 8.3135e-01, 6.9194e-03, 5.9850e-02, 1.0934e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,006][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([1.0000e+00, 4.1822e-09, 2.8509e-08, 1.3770e-09, 2.1646e-08, 3.6234e-09,
        2.5679e-08, 1.1567e-08, 1.1124e-08, 1.9462e-09, 8.5932e-09, 1.0708e-08,
        2.0205e-08, 2.4092e-09, 8.1350e-09, 4.0306e-09, 1.7839e-08, 3.4396e-09],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,007][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0061, 0.0411, 0.0388, 0.0477, 0.0451, 0.0513, 0.0535, 0.0667, 0.0673,
        0.0651, 0.0607, 0.0703, 0.0640, 0.0602, 0.0633, 0.0689, 0.0681, 0.0618],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,007][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0351, 0.0616, 0.0568, 0.0568, 0.0465, 0.0612, 0.0676, 0.0531, 0.0554,
        0.0756, 0.0473, 0.0578, 0.0641, 0.0657, 0.0439, 0.0489, 0.0539, 0.0488],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,008][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0504, 0.0021, 0.0052, 0.0004, 0.0019, 0.0047, 0.0142, 0.0397, 0.0250,
        0.0381, 0.0535, 0.1139, 0.0776, 0.0662, 0.0591, 0.0667, 0.2488, 0.1325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,008][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([9.8506e-01, 3.5121e-04, 1.7060e-04, 1.1358e-04, 1.8999e-04, 2.9896e-04,
        3.8750e-04, 7.9734e-04, 9.2019e-04, 6.6252e-04, 1.3178e-03, 5.8562e-04,
        1.2550e-03, 1.3406e-03, 1.4761e-03, 2.2016e-03, 1.4017e-03, 1.4729e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,012][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0392, 0.0621, 0.0625, 0.0491, 0.0578, 0.0509, 0.0508, 0.0651, 0.0523,
        0.0662, 0.0538, 0.0536, 0.0625, 0.0462, 0.0612, 0.0597, 0.0493, 0.0579],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,013][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.8174, 0.0040, 0.0037, 0.0016, 0.0072, 0.0019, 0.0028, 0.0153, 0.0157,
        0.0151, 0.0088, 0.0061, 0.0175, 0.0092, 0.0220, 0.0137, 0.0084, 0.0294],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,013][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0477, 0.0507, 0.0547, 0.0507, 0.0556, 0.0521, 0.0546, 0.0581, 0.0548,
        0.0586, 0.0555, 0.0561, 0.0587, 0.0569, 0.0585, 0.0575, 0.0582, 0.0610],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,014][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.3682, 0.0182, 0.0174, 0.0155, 0.0165, 0.0199, 0.0328, 0.0430, 0.0291,
        0.0506, 0.0424, 0.0470, 0.0529, 0.0461, 0.0406, 0.0522, 0.0554, 0.0522],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,014][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0076, 0.0510, 0.0489, 0.0669, 0.0521, 0.0616, 0.0539, 0.0521, 0.0708,
        0.0539, 0.0600, 0.0581, 0.0557, 0.0639, 0.0609, 0.0672, 0.0597, 0.0557],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,015][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0586, 0.0497, 0.0460, 0.0483, 0.0512, 0.0604, 0.0609, 0.0581, 0.0682,
        0.0687, 0.0610, 0.0596, 0.0610, 0.0401, 0.0564, 0.0542, 0.0511, 0.0465],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,016][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([9.8858e-05, 7.4626e-04, 2.5039e-03, 9.7025e-04, 3.4561e-03, 1.6731e-03,
        9.5487e-04, 1.4169e-03, 1.1790e-02, 1.0258e-02, 2.4515e-02, 4.8961e-02,
        1.8091e-03, 7.2346e-01, 7.9375e-03, 4.6341e-02, 1.5049e-02, 9.8059e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,019][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0000e+00, 1.2329e-08, 6.7320e-08, 2.1499e-09, 4.2566e-08, 5.4717e-09,
        4.7929e-08, 2.3435e-08, 8.7575e-09, 3.9010e-09, 8.3345e-09, 1.2126e-08,
        5.2550e-08, 3.7776e-09, 1.3405e-08, 8.6805e-09, 3.4338e-08, 1.0376e-08,
        1.2030e-08], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,019][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0055, 0.0402, 0.0371, 0.0461, 0.0432, 0.0488, 0.0509, 0.0613, 0.0634,
        0.0593, 0.0552, 0.0644, 0.0577, 0.0573, 0.0574, 0.0631, 0.0625, 0.0573,
        0.0691], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,020][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0295, 0.0589, 0.0591, 0.0574, 0.0518, 0.0583, 0.0671, 0.0556, 0.0491,
        0.0697, 0.0458, 0.0564, 0.0586, 0.0572, 0.0451, 0.0442, 0.0521, 0.0438,
        0.0405], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,020][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1582, 0.0012, 0.0030, 0.0003, 0.0011, 0.0044, 0.0098, 0.0264, 0.0173,
        0.0333, 0.0382, 0.0618, 0.0462, 0.0520, 0.0363, 0.0656, 0.1566, 0.1029,
        0.1854], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,021][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9708e-01, 5.3740e-05, 1.8657e-05, 6.2275e-06, 1.7346e-05, 2.7713e-05,
        5.0045e-05, 1.2636e-04, 1.1872e-04, 1.0647e-04, 2.3174e-04, 9.8218e-05,
        3.3283e-04, 2.0443e-04, 1.7082e-04, 4.8814e-04, 1.8309e-04, 2.3713e-04,
        4.4857e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,021][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0333, 0.0569, 0.0593, 0.0476, 0.0555, 0.0500, 0.0480, 0.0607, 0.0490,
        0.0633, 0.0505, 0.0510, 0.0608, 0.0446, 0.0592, 0.0584, 0.0477, 0.0573,
        0.0468], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,025][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5770, 0.0075, 0.0083, 0.0050, 0.0157, 0.0034, 0.0092, 0.0212, 0.0391,
        0.0234, 0.0263, 0.0131, 0.0254, 0.0202, 0.0414, 0.0285, 0.0251, 0.0286,
        0.0818], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,025][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0460, 0.0479, 0.0518, 0.0481, 0.0528, 0.0492, 0.0516, 0.0546, 0.0517,
        0.0555, 0.0524, 0.0528, 0.0553, 0.0538, 0.0552, 0.0541, 0.0547, 0.0579,
        0.0546], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,026][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4311, 0.0164, 0.0151, 0.0144, 0.0148, 0.0184, 0.0290, 0.0360, 0.0239,
        0.0429, 0.0349, 0.0375, 0.0421, 0.0394, 0.0309, 0.0413, 0.0445, 0.0424,
        0.0449], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,026][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0096, 0.0530, 0.0458, 0.0629, 0.0511, 0.0574, 0.0507, 0.0522, 0.0604,
        0.0524, 0.0507, 0.0531, 0.0564, 0.0574, 0.0581, 0.0585, 0.0522, 0.0570,
        0.0608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,027][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0157, 0.0486, 0.0651, 0.0566, 0.0617, 0.0647, 0.0685, 0.0548, 0.0457,
        0.0767, 0.0602, 0.0634, 0.0573, 0.0429, 0.0551, 0.0483, 0.0432, 0.0424,
        0.0291], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,027][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.8145e-04, 2.8667e-03, 3.4595e-03, 9.5471e-04, 3.6668e-03, 9.8751e-04,
        4.4304e-04, 1.0396e-03, 7.6846e-03, 7.8738e-03, 1.4713e-02, 2.4224e-02,
        1.1157e-03, 6.3337e-01, 7.5482e-03, 4.4698e-02, 1.0997e-02, 1.3376e-01,
        1.0031e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,029][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:52,031][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13593],
        [ 4961],
        [13071],
        [ 3631],
        [ 1017],
        [ 2137],
        [ 1454],
        [ 2539],
        [ 4685],
        [ 3910],
        [ 7300],
        [ 3277],
        [ 4480],
        [  375],
        [ 2393],
        [  765],
        [ 1361],
        [ 1553],
        [ 2905]], device='cuda:0')
[2024-07-24 10:19:52,034][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14860],
        [15213],
        [25472],
        [10508],
        [ 2151],
        [11536],
        [ 9003],
        [ 4671],
        [ 9555],
        [ 9669],
        [15618],
        [10886],
        [ 6896],
        [ 1272],
        [ 3080],
        [ 1223],
        [ 6578],
        [ 1900],
        [ 5467]], device='cuda:0')
[2024-07-24 10:19:52,035][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[37659],
        [42095],
        [42747],
        [41581],
        [41684],
        [41573],
        [41253],
        [41026],
        [41193],
        [41242],
        [41089],
        [41015],
        [40888],
        [40802],
        [40828],
        [40742],
        [40628],
        [40701],
        [40688]], device='cuda:0')
[2024-07-24 10:19:52,036][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[37283],
        [14619],
        [ 9914],
        [ 9756],
        [ 7301],
        [ 5791],
        [ 5504],
        [ 7248],
        [ 6157],
        [ 6904],
        [ 5644],
        [ 5257],
        [ 7339],
        [ 5739],
        [ 6337],
        [ 5769],
        [ 5421],
        [ 6549],
        [ 5063]], device='cuda:0')
[2024-07-24 10:19:52,038][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2986],
        [ 651],
        [2232],
        [2293],
        [3025],
        [2794],
        [2946],
        [3260],
        [2736],
        [3154],
        [3023],
        [3028],
        [3221],
        [3162],
        [3611],
        [3496],
        [3506],
        [3862],
        [3610]], device='cuda:0')
[2024-07-24 10:19:52,040][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[21432],
        [21600],
        [21601],
        [21791],
        [21693],
        [21958],
        [21836],
        [21952],
        [21816],
        [21884],
        [21886],
        [21863],
        [22028],
        [21878],
        [21947],
        [21960],
        [21918],
        [21987],
        [21912]], device='cuda:0')
[2024-07-24 10:19:52,042][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1767],
        [1877],
        [1795],
        [1867],
        [1798],
        [1813],
        [1798],
        [1815],
        [2051],
        [1863],
        [1841],
        [1823],
        [1872],
        [1987],
        [1857],
        [2042],
        [1931],
        [1960],
        [2478]], device='cuda:0')
[2024-07-24 10:19:52,043][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[12140],
        [20951],
        [10889],
        [11104],
        [12347],
        [12397],
        [12238],
        [14143],
        [13756],
        [13996],
        [16016],
        [16244],
        [16137],
        [16208],
        [16929],
        [18837],
        [17507],
        [18359],
        [17427]], device='cuda:0')
[2024-07-24 10:19:52,045][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[26307],
        [31811],
        [31934],
        [32429],
        [32376],
        [32759],
        [32569],
        [32342],
        [32201],
        [32249],
        [32545],
        [32622],
        [32870],
        [32732],
        [32539],
        [32552],
        [32580],
        [32497],
        [32502]], device='cuda:0')
[2024-07-24 10:19:52,047][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[7043],
        [8263],
        [7759],
        [9226],
        [9104],
        [8628],
        [8890],
        [9292],
        [9071],
        [9021],
        [8941],
        [9024],
        [8905],
        [8999],
        [8975],
        [8898],
        [9034],
        [9051],
        [9243]], device='cuda:0')
[2024-07-24 10:19:52,048][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21575],
        [25311],
        [26030],
        [29098],
        [29477],
        [33847],
        [32852],
        [34174],
        [38070],
        [36011],
        [37636],
        [36989],
        [37232],
        [38202],
        [38157],
        [39465],
        [39653],
        [39613],
        [40286]], device='cuda:0')
[2024-07-24 10:19:52,050][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[45245],
        [43464],
        [46707],
        [45886],
        [45998],
        [45589],
        [45364],
        [45233],
        [45041],
        [44811],
        [44848],
        [44849],
        [44844],
        [44794],
        [44768],
        [44640],
        [44555],
        [44511],
        [44476]], device='cuda:0')
[2024-07-24 10:19:52,052][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[4066],
        [4066],
        [4066],
        [4066],
        [4066],
        [4066],
        [4066],
        [4063],
        [4066],
        [4066],
        [4066],
        [4066],
        [4062],
        [4066],
        [4066],
        [4066],
        [4065],
        [4066],
        [4066]], device='cuda:0')
[2024-07-24 10:19:52,054][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41306],
        [39076],
        [40150],
        [39206],
        [38785],
        [38797],
        [37335],
        [37065],
        [36634],
        [36624],
        [35509],
        [35302],
        [35648],
        [35147],
        [34592],
        [34730],
        [33941],
        [34349],
        [34225]], device='cuda:0')
[2024-07-24 10:19:52,055][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18770],
        [11231],
        [ 7403],
        [16553],
        [13319],
        [ 4462],
        [12028],
        [12019],
        [24533],
        [ 7965],
        [10181],
        [ 8405],
        [10387],
        [14525],
        [13872],
        [12007],
        [ 6875],
        [ 9037],
        [ 9996]], device='cuda:0')
[2024-07-24 10:19:52,057][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14160],
        [14159],
        [14160],
        [14160],
        [14160],
        [14160]], device='cuda:0')
[2024-07-24 10:19:52,059][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[31985],
        [23124],
        [24224],
        [24301],
        [24822],
        [23991],
        [23870],
        [24301],
        [24555],
        [23683],
        [23665],
        [23482],
        [23210],
        [23345],
        [23517],
        [23311],
        [23255],
        [23012],
        [23358]], device='cuda:0')
[2024-07-24 10:19:52,061][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15076],
        [27355],
        [31793],
        [33031],
        [33702],
        [33581],
        [34376],
        [32121],
        [31377],
        [32734],
        [32852],
        [32904],
        [32355],
        [32934],
        [32867],
        [33031],
        [33314],
        [33396],
        [33496]], device='cuda:0')
[2024-07-24 10:19:52,062][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1733],
        [11033],
        [13941],
        [30275],
        [16467],
        [23711],
        [12393],
        [ 5343],
        [ 8133],
        [ 9921],
        [13238],
        [10543],
        [10215],
        [10605],
        [ 8655],
        [ 9414],
        [ 9518],
        [ 9767],
        [10086]], device='cuda:0')
[2024-07-24 10:19:52,063][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[21401],
        [21404],
        [21309],
        [21356],
        [21232],
        [21269],
        [21378],
        [21420],
        [21482],
        [21560],
        [21546],
        [21431],
        [21450],
        [21441],
        [21433],
        [21437],
        [21424],
        [21297],
        [21385]], device='cuda:0')
[2024-07-24 10:19:52,066][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11893],
        [25129],
        [25920],
        [28374],
        [27258],
        [27320],
        [26987],
        [26490],
        [26423],
        [25877],
        [26063],
        [26047],
        [25954],
        [25900],
        [25612],
        [25384],
        [25288],
        [24935],
        [24845]], device='cuda:0')
[2024-07-24 10:19:52,068][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40985],
        [37970],
        [37596],
        [39998],
        [38224],
        [40458],
        [40468],
        [38744],
        [33275],
        [34747],
        [33675],
        [38445],
        [30900],
        [32849],
        [25125],
        [23473],
        [30780],
        [30661],
        [17693]], device='cuda:0')
[2024-07-24 10:19:52,069][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37836],
        [26298],
        [23018],
        [22069],
        [22176],
        [21849],
        [22858],
        [22951],
        [22826],
        [22991],
        [23330],
        [23479],
        [23268],
        [22922],
        [22957],
        [22978],
        [22948],
        [22779],
        [22632]], device='cuda:0')
[2024-07-24 10:19:52,070][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25312],
        [29264],
        [31734],
        [32578],
        [33021],
        [35487],
        [35401],
        [35938],
        [35277],
        [38016],
        [38782],
        [39003],
        [39630],
        [39397],
        [39867],
        [40281],
        [40434],
        [40722],
        [40727]], device='cuda:0')
[2024-07-24 10:19:52,073][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30226],
        [30472],
        [33214],
        [32294],
        [31974],
        [31353],
        [30684],
        [30337],
        [30705],
        [30062],
        [30382],
        [30580],
        [30775],
        [30648],
        [30938],
        [30819],
        [30743],
        [30850],
        [30857]], device='cuda:0')
[2024-07-24 10:19:52,075][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[30604],
        [35272],
        [33077],
        [34135],
        [34256],
        [34082],
        [34105],
        [35001],
        [35198],
        [35925],
        [35771],
        [35842],
        [35764],
        [35726],
        [35586],
        [35555],
        [35486],
        [35485],
        [35444]], device='cuda:0')
[2024-07-24 10:19:52,076][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5734],
        [ 4301],
        [13122],
        [15072],
        [12267],
        [ 9977],
        [10143],
        [11837],
        [ 9411],
        [11153],
        [11024],
        [13218],
        [13737],
        [11696],
        [11755],
        [11675],
        [11660],
        [11832],
        [11804]], device='cuda:0')
[2024-07-24 10:19:52,077][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29671],
        [21314],
        [17547],
        [12906],
        [16107],
        [14832],
        [17465],
        [19060],
        [18983],
        [17443],
        [16512],
        [15964],
        [17470],
        [17145],
        [18665],
        [18854],
        [18322],
        [18089],
        [19771]], device='cuda:0')
[2024-07-24 10:19:52,079][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27402],
        [35412],
        [36314],
        [20806],
        [25218],
        [27531],
        [19696],
        [30504],
        [25519],
        [32728],
        [30937],
        [28473],
        [30211],
        [27821],
        [31662],
        [29462],
        [25863],
        [33300],
        [29106]], device='cuda:0')
[2024-07-24 10:19:52,082][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940],
        [15940]], device='cuda:0')
[2024-07-24 10:19:52,127][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:52,127][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,128][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,128][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,130][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,133][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,133][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,133][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,133][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,134][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,134][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,134][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,135][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,135][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9662, 0.0338], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,137][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1602, 0.8398], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,139][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0318, 0.9682], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,140][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6383, 0.3617], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,140][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1383, 0.8617], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,140][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9071, 0.0929], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,141][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,141][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0284, 0.9716], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,141][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1304, 0.8696], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,141][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0380, 0.9620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,143][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0206, 0.9794], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,146][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5279, 0.4721], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,146][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.2948, 0.0126, 0.6926], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,146][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0025, 0.8605, 0.1370], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,147][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.0175, 0.5493, 0.4332], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,147][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.6492, 0.1601, 0.1907], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,147][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0694, 0.5032, 0.4275], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,148][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.9477, 0.0306, 0.0217], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,148][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.9628, 0.0179, 0.0193], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,150][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0234, 0.8545, 0.1221], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,152][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.0318, 0.2052, 0.7630], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,153][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0473, 0.1865, 0.7662], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,153][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0387, 0.4002, 0.5611], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,153][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.3161, 0.1320, 0.5520], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,154][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([2.0348e-03, 1.1527e-04, 9.9781e-01, 4.4996e-05], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,154][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0435, 0.3895, 0.1039, 0.4631], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,154][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0117, 0.3775, 0.2987, 0.3120], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,155][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5313, 0.0992, 0.1636, 0.2059], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,157][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0487, 0.3305, 0.2862, 0.3347], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,159][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7562, 0.0551, 0.1690, 0.0197], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,159][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9819, 0.0065, 0.0067, 0.0049], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,160][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0094, 0.5118, 0.1682, 0.3105], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,160][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0116, 0.1579, 0.7856, 0.0449], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,160][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([3.8654e-04, 5.8504e-02, 9.3506e-01, 6.0535e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,161][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0065, 0.1539, 0.7522, 0.0875], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,161][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1014, 0.1223, 0.6975, 0.0788], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,161][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0266, 0.0044, 0.8084, 0.0614, 0.0991], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,165][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0127, 0.3001, 0.0616, 0.3749, 0.2508], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,165][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0094, 0.2811, 0.2229, 0.2339, 0.2527], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,166][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.4077, 0.1349, 0.1520, 0.2177, 0.0876], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,166][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0343, 0.2426, 0.2108, 0.2422, 0.2701], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,167][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.6404, 0.1114, 0.0882, 0.0880, 0.0719], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,167][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.8987, 0.0306, 0.0429, 0.0164, 0.0114], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,169][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0168, 0.4666, 0.0892, 0.3215, 0.1058], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,171][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0385, 0.0612, 0.4132, 0.0390, 0.4482], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,171][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0088, 0.0748, 0.6204, 0.0078, 0.2883], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,172][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0105, 0.1387, 0.4857, 0.0935, 0.2716], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,172][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0658, 0.1260, 0.3728, 0.3332, 0.1022], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,172][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([2.5786e-03, 5.8294e-04, 7.6813e-01, 2.5907e-03, 2.2562e-01, 4.9355e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,173][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0096, 0.2067, 0.0583, 0.2683, 0.1694, 0.2876], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,173][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0075, 0.2184, 0.1747, 0.1830, 0.1975, 0.2190], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,175][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.3055, 0.0582, 0.1213, 0.1674, 0.0616, 0.2859], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,177][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0202, 0.1974, 0.1728, 0.2055, 0.2326, 0.1715], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,178][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.6364, 0.0359, 0.1422, 0.0442, 0.1167, 0.0246], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,178][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.9746, 0.0054, 0.0078, 0.0059, 0.0036, 0.0027], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,178][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0098, 0.2935, 0.1133, 0.3358, 0.1455, 0.1020], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,179][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0017, 0.0592, 0.2778, 0.0188, 0.5328, 0.1097], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,179][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([9.4856e-05, 3.1569e-02, 7.6784e-01, 6.3811e-03, 1.7313e-01, 2.0978e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,179][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0071, 0.0833, 0.2014, 0.2128, 0.2766, 0.2188], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,180][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0067, 0.0440, 0.2078, 0.2056, 0.1088, 0.4271], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,180][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.6373e-03, 1.9625e-03, 6.6676e-01, 1.1080e-02, 3.1331e-01, 3.6363e-03,
        6.1912e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,182][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0050, 0.1700, 0.0304, 0.2261, 0.0916, 0.2850, 0.1920],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,184][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0059, 0.1778, 0.1417, 0.1490, 0.1603, 0.1804, 0.1848],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,185][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1697, 0.0482, 0.0913, 0.1832, 0.0461, 0.3054, 0.1562],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,185][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0178, 0.1628, 0.1461, 0.1740, 0.1981, 0.1472, 0.1539],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,185][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7613, 0.0323, 0.0646, 0.0258, 0.0730, 0.0247, 0.0183],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,186][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9799, 0.0032, 0.0057, 0.0023, 0.0027, 0.0019, 0.0042],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,186][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0098, 0.2591, 0.1248, 0.2397, 0.1564, 0.1704, 0.0397],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,186][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0043, 0.0245, 0.2142, 0.0200, 0.4172, 0.2259, 0.0939],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,188][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.2263e-04, 3.0862e-02, 5.0368e-01, 2.2481e-02, 3.0677e-01, 1.0213e-01,
        3.3850e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,191][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0017, 0.0376, 0.1530, 0.1131, 0.1647, 0.3716, 0.1584],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,191][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0028, 0.0333, 0.0993, 0.3140, 0.0408, 0.4713, 0.0385],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,191][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0523, 0.0019, 0.4265, 0.0090, 0.1804, 0.0049, 0.0133, 0.3117],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,192][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0124, 0.1496, 0.0328, 0.1724, 0.0879, 0.1940, 0.1374, 0.2134],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,192][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0052, 0.1495, 0.1182, 0.1253, 0.1353, 0.1525, 0.1586, 0.1555],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,193][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1911, 0.0519, 0.0951, 0.1457, 0.0501, 0.2767, 0.1273, 0.0621],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,193][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0177, 0.1385, 0.1219, 0.1464, 0.1618, 0.1240, 0.1306, 0.1591],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,195][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.4853, 0.0789, 0.0688, 0.0527, 0.0562, 0.0680, 0.0488, 0.1412],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,200][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.8922, 0.0092, 0.0184, 0.0130, 0.0145, 0.0101, 0.0237, 0.0188],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,200][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0106, 0.1293, 0.0639, 0.1796, 0.0908, 0.1475, 0.0747, 0.3035],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,200][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0153, 0.0067, 0.0756, 0.0030, 0.0737, 0.0351, 0.0256, 0.7649],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,201][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0078, 0.0091, 0.0739, 0.0014, 0.0286, 0.0091, 0.0060, 0.8640],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,201][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0008, 0.0357, 0.0509, 0.0603, 0.0912, 0.2003, 0.5091, 0.0517],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,201][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0017, 0.0571, 0.0434, 0.1375, 0.0314, 0.4128, 0.1542, 0.1619],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,202][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([1.0557e-03, 1.9490e-05, 1.0237e-01, 1.7623e-04, 9.5355e-02, 2.6965e-04,
        8.8492e-04, 7.9973e-01, 1.3491e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,202][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0819, 0.1052, 0.0443, 0.1265, 0.0823, 0.1473, 0.1268, 0.1764, 0.1093],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,205][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0044, 0.1324, 0.1048, 0.1098, 0.1190, 0.1331, 0.1387, 0.1375, 0.1204],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,206][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.3126, 0.0353, 0.0579, 0.0888, 0.0294, 0.1665, 0.0905, 0.0426, 0.1766],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,207][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0150, 0.1186, 0.1082, 0.1209, 0.1362, 0.1040, 0.1076, 0.1286, 0.1608],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,207][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.3394, 0.0322, 0.1843, 0.0158, 0.1828, 0.0282, 0.0409, 0.1362, 0.0401],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,208][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.9409, 0.0074, 0.0146, 0.0056, 0.0106, 0.0037, 0.0077, 0.0050, 0.0045],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,208][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0073, 0.1273, 0.0808, 0.1384, 0.0892, 0.1175, 0.0387, 0.3244, 0.0764],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,208][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0026, 0.0015, 0.0370, 0.0012, 0.0353, 0.0278, 0.0179, 0.8067, 0.0700],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,209][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([8.7721e-05, 2.8512e-03, 5.5620e-02, 1.5331e-03, 2.4383e-02, 7.0241e-03,
        3.0809e-03, 9.0069e-01, 4.7282e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,209][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0041, 0.0207, 0.1581, 0.0498, 0.2511, 0.1390, 0.2046, 0.1125, 0.0602],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,211][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0185, 0.0290, 0.1156, 0.0776, 0.0426, 0.2914, 0.1137, 0.0777, 0.2340],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,213][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([4.1102e-03, 2.9538e-04, 1.1127e-01, 4.5192e-03, 2.6552e-02, 4.8606e-04,
        6.4082e-03, 7.1513e-01, 6.3639e-02, 6.7583e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,214][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0148, 0.0589, 0.0178, 0.0976, 0.0697, 0.1408, 0.0951, 0.1616, 0.1699,
        0.1737], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,214][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0039, 0.1142, 0.0912, 0.0955, 0.1039, 0.1162, 0.1212, 0.1192, 0.1053,
        0.1295], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,214][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1424, 0.0537, 0.0732, 0.1015, 0.0407, 0.1905, 0.0918, 0.0538, 0.1841,
        0.0682], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,215][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0116, 0.1054, 0.0899, 0.1081, 0.1199, 0.0903, 0.0943, 0.1169, 0.1519,
        0.1116], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,215][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.3724, 0.0591, 0.0835, 0.0521, 0.0583, 0.0654, 0.0672, 0.0719, 0.0798,
        0.0902], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,216][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.7492, 0.0167, 0.0376, 0.0170, 0.0202, 0.0277, 0.0410, 0.0288, 0.0386,
        0.0233], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,220][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0098, 0.1052, 0.0639, 0.1217, 0.0939, 0.0982, 0.0566, 0.2505, 0.1246,
        0.0756], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,220][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0015, 0.0018, 0.0132, 0.0007, 0.0150, 0.0089, 0.0074, 0.3921, 0.0812,
        0.4783], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,220][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0008, 0.0051, 0.0643, 0.0008, 0.0234, 0.0030, 0.0029, 0.6907, 0.0053,
        0.2038], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,221][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0003, 0.0268, 0.0567, 0.0354, 0.1033, 0.1303, 0.2622, 0.1014, 0.2505,
        0.0331], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,221][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0019, 0.0533, 0.0573, 0.1154, 0.0335, 0.2382, 0.1035, 0.0648, 0.2788,
        0.0533], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,222][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([7.3216e-03, 3.2998e-05, 8.9660e-02, 2.1446e-04, 1.6726e-01, 7.9092e-04,
        1.3844e-03, 3.7672e-01, 2.5129e-04, 3.5610e-01, 2.6066e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,222][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0022, 0.0595, 0.0135, 0.0889, 0.0441, 0.1167, 0.0827, 0.1520, 0.1354,
        0.1988, 0.1064], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,224][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0034, 0.1026, 0.0816, 0.0856, 0.0923, 0.1037, 0.1079, 0.1074, 0.0940,
        0.1167, 0.1048], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,226][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2327, 0.0186, 0.0353, 0.0579, 0.0206, 0.1015, 0.0612, 0.0329, 0.1344,
        0.0450, 0.2598], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,226][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0092, 0.0965, 0.0828, 0.0979, 0.1100, 0.0817, 0.0861, 0.1034, 0.1385,
        0.1019, 0.0920], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,227][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2863, 0.0345, 0.0941, 0.0188, 0.1431, 0.0442, 0.0419, 0.1671, 0.0677,
        0.0667, 0.0356], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,227][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.8891, 0.0123, 0.0161, 0.0092, 0.0152, 0.0057, 0.0082, 0.0083, 0.0091,
        0.0095, 0.0173], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,228][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0059, 0.0722, 0.0741, 0.1397, 0.0557, 0.0985, 0.0359, 0.2364, 0.1217,
        0.1248, 0.0350], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,228][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0010, 0.0005, 0.0074, 0.0005, 0.0114, 0.0125, 0.0049, 0.3728, 0.0421,
        0.5075, 0.0393], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,228][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([6.3528e-05, 2.8320e-03, 9.4464e-02, 1.6522e-03, 3.5672e-02, 7.2157e-03,
        3.9053e-03, 6.0860e-01, 5.3021e-03, 2.3556e-01, 4.7424e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,232][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0065, 0.0239, 0.1180, 0.0396, 0.1792, 0.1207, 0.1698, 0.1430, 0.1026,
        0.0626, 0.0341], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,233][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0194, 0.0398, 0.1059, 0.0628, 0.0367, 0.1587, 0.0554, 0.0870, 0.1986,
        0.1395, 0.0962], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,233][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.0476e-03, 7.6323e-05, 1.2289e-01, 2.4086e-04, 4.3826e-02, 3.3138e-04,
        1.0915e-04, 3.3323e-01, 6.0318e-03, 4.7614e-01, 1.5692e-02, 3.8431e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,233][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0019, 0.0584, 0.0140, 0.0803, 0.0426, 0.1054, 0.0737, 0.1406, 0.1236,
        0.1554, 0.1065, 0.0976], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,234][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0032, 0.0934, 0.0745, 0.0778, 0.0837, 0.0943, 0.0977, 0.0970, 0.0853,
        0.1057, 0.0956, 0.0919], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,234][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2032, 0.0139, 0.0269, 0.0377, 0.0132, 0.0738, 0.0347, 0.0205, 0.0797,
        0.0309, 0.2118, 0.2538], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,235][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0080, 0.0848, 0.0755, 0.0884, 0.1023, 0.0762, 0.0784, 0.0968, 0.1261,
        0.0951, 0.0871, 0.0814], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,238][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2923, 0.0409, 0.1043, 0.0260, 0.1484, 0.0440, 0.0344, 0.1262, 0.0628,
        0.0725, 0.0220, 0.0261], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,239][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.9561, 0.0025, 0.0051, 0.0028, 0.0029, 0.0024, 0.0046, 0.0055, 0.0030,
        0.0054, 0.0079, 0.0019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,239][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0050, 0.0773, 0.0447, 0.0696, 0.0467, 0.0642, 0.0465, 0.2474, 0.1366,
        0.1672, 0.0633, 0.0313], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,240][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0031, 0.0005, 0.0100, 0.0005, 0.0117, 0.0113, 0.0031, 0.3316, 0.0505,
        0.3844, 0.0931, 0.1002], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,240][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([5.0010e-05, 1.2616e-03, 3.9185e-02, 7.6208e-04, 1.5993e-02, 3.7604e-03,
        2.5159e-03, 7.1257e-01, 3.3140e-03, 2.0684e-01, 5.3306e-03, 8.4137e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,240][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0014, 0.0250, 0.0725, 0.0336, 0.0753, 0.1243, 0.2180, 0.1294, 0.1489,
        0.0364, 0.0545, 0.0807], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,241][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0117, 0.0326, 0.0607, 0.0704, 0.0203, 0.1565, 0.0429, 0.0563, 0.2131,
        0.0664, 0.1683, 0.1010], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,243][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ office] are: tensor([8.6034e-04, 3.4528e-05, 5.4139e-02, 1.1611e-03, 1.4087e-02, 7.3405e-04,
        1.0360e-03, 3.6175e-01, 4.8218e-03, 3.3583e-01, 2.4416e-02, 3.3406e-03,
        1.9779e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,245][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0066, 0.0387, 0.0075, 0.0603, 0.0320, 0.0818, 0.0606, 0.1064, 0.1125,
        0.1215, 0.1133, 0.1036, 0.1551], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,245][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0030, 0.0839, 0.0674, 0.0708, 0.0763, 0.0858, 0.0893, 0.0885, 0.0779,
        0.0959, 0.0876, 0.0840, 0.0895], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,246][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0899, 0.0219, 0.0372, 0.0475, 0.0197, 0.1039, 0.0402, 0.0251, 0.0845,
        0.0316, 0.2149, 0.2416, 0.0419], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,246][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0095, 0.0763, 0.0673, 0.0807, 0.0900, 0.0692, 0.0717, 0.0871, 0.1132,
        0.0854, 0.0793, 0.0750, 0.0954], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,246][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.1921, 0.0592, 0.0663, 0.0530, 0.0793, 0.0306, 0.0681, 0.0556, 0.0745,
        0.0770, 0.0431, 0.0680, 0.1330], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,247][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.7248, 0.0127, 0.0160, 0.0136, 0.0107, 0.0139, 0.0240, 0.0211, 0.0266,
        0.0171, 0.0673, 0.0205, 0.0317], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,251][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0040, 0.0931, 0.0341, 0.1009, 0.0475, 0.0739, 0.0450, 0.1567, 0.1135,
        0.0470, 0.0841, 0.1152, 0.0850], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,251][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ office] are: tensor([5.2801e-03, 1.8828e-04, 2.4383e-03, 1.4976e-04, 3.5868e-03, 4.2159e-03,
        3.4853e-03, 1.5224e-01, 4.4843e-02, 1.9058e-01, 7.5169e-02, 1.1363e-01,
        4.0419e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,252][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ office] are: tensor([1.6033e-03, 1.3117e-03, 3.9626e-02, 4.1897e-04, 1.4170e-02, 4.3765e-03,
        2.7300e-03, 4.4977e-01, 5.8934e-03, 1.6653e-01, 9.7525e-03, 1.3129e-02,
        2.9069e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,252][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0005, 0.0104, 0.0288, 0.0236, 0.0360, 0.0582, 0.1602, 0.1189, 0.2385,
        0.0344, 0.1115, 0.1278, 0.0512], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,252][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0034, 0.0218, 0.0459, 0.1047, 0.0184, 0.0879, 0.0646, 0.0379, 0.1714,
        0.0294, 0.1821, 0.2001, 0.0324], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,253][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([4.4097e-04, 4.6179e-06, 5.2072e-02, 3.0220e-05, 3.1697e-02, 3.2874e-04,
        1.5799e-03, 1.9361e-01, 5.4952e-04, 5.9785e-01, 4.2045e-03, 5.3544e-03,
        1.1207e-01, 2.1629e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,253][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0165, 0.0270, 0.0114, 0.0521, 0.0349, 0.0698, 0.0668, 0.0938, 0.0709,
        0.0969, 0.0890, 0.0970, 0.1385, 0.1356], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,257][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0026, 0.0792, 0.0629, 0.0658, 0.0715, 0.0798, 0.0832, 0.0821, 0.0723,
        0.0894, 0.0812, 0.0784, 0.0836, 0.0682], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,257][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.4613, 0.0125, 0.0181, 0.0215, 0.0088, 0.0397, 0.0168, 0.0110, 0.0412,
        0.0163, 0.0950, 0.1109, 0.0184, 0.1286], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,258][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0059, 0.0742, 0.0637, 0.0750, 0.0872, 0.0635, 0.0663, 0.0809, 0.1078,
        0.0796, 0.0717, 0.0686, 0.0878, 0.0677], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,258][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.2232, 0.0280, 0.1389, 0.0132, 0.1335, 0.0299, 0.0468, 0.1075, 0.0291,
        0.0625, 0.0190, 0.0294, 0.1245, 0.0147], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,259][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.9178, 0.0041, 0.0029, 0.0046, 0.0025, 0.0041, 0.0087, 0.0090, 0.0067,
        0.0039, 0.0220, 0.0055, 0.0040, 0.0041], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,259][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0020, 0.0598, 0.0336, 0.0560, 0.0506, 0.0581, 0.0321, 0.2125, 0.0876,
        0.1157, 0.0723, 0.0712, 0.1058, 0.0427], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,262][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0245, 0.0030, 0.0218, 0.0003, 0.0106, 0.0074, 0.0021, 0.1991, 0.0132,
        0.2381, 0.0388, 0.0442, 0.1527, 0.2442], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,263][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([2.0801e-04, 4.5156e-03, 7.4859e-02, 3.8566e-04, 1.9274e-02, 2.1644e-03,
        1.1022e-03, 4.3937e-01, 1.5008e-03, 1.6081e-01, 2.6943e-03, 6.4148e-03,
        2.6495e-01, 2.1749e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,264][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0009, 0.0225, 0.1498, 0.0313, 0.1529, 0.0884, 0.1369, 0.0732, 0.0933,
        0.0222, 0.0396, 0.0929, 0.0715, 0.0247], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,264][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0096, 0.0239, 0.0620, 0.0285, 0.0130, 0.1044, 0.0605, 0.0377, 0.0881,
        0.0499, 0.0929, 0.1953, 0.0321, 0.2021], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,265][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([2.1249e-03, 1.9653e-04, 5.0294e-02, 2.5297e-03, 5.1733e-03, 8.4462e-04,
        4.0064e-03, 3.4277e-01, 1.4903e-02, 1.9728e-01, 3.0871e-02, 1.0434e-02,
        3.1239e-01, 1.1320e-02, 1.4867e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,265][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0013, 0.0407, 0.0108, 0.0604, 0.0356, 0.0747, 0.0469, 0.0761, 0.0794,
        0.1059, 0.0815, 0.0726, 0.1264, 0.1405, 0.0473], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,266][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0027, 0.0733, 0.0587, 0.0614, 0.0659, 0.0741, 0.0766, 0.0759, 0.0671,
        0.0824, 0.0751, 0.0720, 0.0771, 0.0628, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,270][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0551, 0.0237, 0.0263, 0.0457, 0.0164, 0.0910, 0.0392, 0.0200, 0.0761,
        0.0231, 0.1366, 0.2254, 0.0287, 0.1783, 0.0145], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,270][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0087, 0.0643, 0.0582, 0.0675, 0.0760, 0.0597, 0.0616, 0.0757, 0.0948,
        0.0746, 0.0676, 0.0631, 0.0813, 0.0614, 0.0855], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,270][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1610, 0.0580, 0.0514, 0.0525, 0.0384, 0.0646, 0.0348, 0.0598, 0.1152,
        0.0458, 0.0283, 0.0355, 0.1624, 0.0675, 0.0248], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,271][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.6918, 0.0120, 0.0203, 0.0089, 0.0047, 0.0186, 0.0102, 0.0178, 0.0229,
        0.0099, 0.0588, 0.0092, 0.0804, 0.0251, 0.0093], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,271][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0046, 0.1017, 0.0262, 0.0731, 0.0273, 0.0561, 0.0466, 0.1845, 0.1118,
        0.0699, 0.0634, 0.0878, 0.0616, 0.0552, 0.0302], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,273][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([2.7673e-03, 2.5247e-04, 3.9840e-03, 2.0501e-04, 2.4438e-03, 2.9704e-03,
        1.3877e-03, 1.0013e-01, 1.2738e-02, 5.5781e-02, 1.4910e-02, 7.3033e-02,
        2.4611e-01, 4.0425e-01, 7.9039e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,275][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0024, 0.0028, 0.0506, 0.0005, 0.0193, 0.0037, 0.0031, 0.3743, 0.0037,
        0.1383, 0.0055, 0.0144, 0.2729, 0.0477, 0.0608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,276][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0013, 0.0387, 0.1283, 0.0227, 0.0554, 0.1043, 0.1134, 0.1081, 0.0774,
        0.0202, 0.0513, 0.0790, 0.1009, 0.0270, 0.0721], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,276][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0095, 0.0186, 0.0250, 0.0246, 0.0058, 0.1011, 0.0852, 0.0314, 0.1231,
        0.0461, 0.1347, 0.1787, 0.0216, 0.1513, 0.0432], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,277][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([3.4926e-03, 7.2327e-05, 1.4064e-01, 4.9338e-04, 3.0228e-02, 1.1641e-04,
        5.7201e-04, 3.0486e-01, 1.7811e-03, 1.1341e-01, 9.4583e-03, 5.2303e-03,
        3.0711e-01, 4.4559e-03, 7.7297e-02, 7.7092e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,277][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0011, 0.0326, 0.0094, 0.0478, 0.0267, 0.0552, 0.0381, 0.0707, 0.0718,
        0.1039, 0.0831, 0.0555, 0.1321, 0.1318, 0.0467, 0.0936],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,278][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0024, 0.0687, 0.0548, 0.0575, 0.0621, 0.0690, 0.0720, 0.0706, 0.0626,
        0.0768, 0.0699, 0.0675, 0.0720, 0.0595, 0.0704, 0.0643],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,278][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1362, 0.0165, 0.0272, 0.0315, 0.0149, 0.0589, 0.0272, 0.0167, 0.0615,
        0.0256, 0.1308, 0.1756, 0.0278, 0.1729, 0.0126, 0.0642],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,280][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0068, 0.0613, 0.0554, 0.0636, 0.0724, 0.0549, 0.0572, 0.0687, 0.0883,
        0.0674, 0.0617, 0.0593, 0.0765, 0.0585, 0.0801, 0.0680],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,282][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1476, 0.0263, 0.0450, 0.0401, 0.0719, 0.0259, 0.0528, 0.1431, 0.0677,
        0.0404, 0.0253, 0.0554, 0.1483, 0.0338, 0.0409, 0.0353],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,283][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.8763, 0.0048, 0.0084, 0.0078, 0.0024, 0.0048, 0.0051, 0.0121, 0.0076,
        0.0046, 0.0209, 0.0035, 0.0160, 0.0057, 0.0050, 0.0151],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,283][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0035, 0.0749, 0.0241, 0.0829, 0.0380, 0.0595, 0.0286, 0.1218, 0.1043,
        0.1090, 0.0732, 0.0691, 0.0639, 0.0463, 0.0398, 0.0612],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,284][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([2.7866e-03, 9.2701e-04, 5.9266e-03, 1.3489e-04, 3.2509e-03, 1.3906e-03,
        1.1990e-03, 8.8206e-02, 1.2595e-02, 8.1061e-02, 1.9632e-02, 3.1023e-02,
        1.1970e-01, 2.2765e-01, 6.1463e-02, 3.4305e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,284][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([8.8128e-04, 6.1528e-03, 8.2695e-02, 2.2153e-04, 2.1686e-02, 9.2896e-04,
        9.0749e-04, 2.8998e-01, 1.9934e-03, 1.3670e-01, 2.6904e-03, 6.1244e-03,
        2.1508e-01, 2.0463e-02, 6.1931e-02, 1.5157e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,288][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0005, 0.0263, 0.0487, 0.0492, 0.0650, 0.0756, 0.1149, 0.0324, 0.1026,
        0.0263, 0.0950, 0.1216, 0.1211, 0.0395, 0.0722, 0.0090],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,289][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0080, 0.0120, 0.0268, 0.0347, 0.0164, 0.0934, 0.0537, 0.0322, 0.1543,
        0.0385, 0.0693, 0.1725, 0.0298, 0.1720, 0.0491, 0.0371],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,289][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([8.5362e-04, 1.8265e-04, 8.9547e-02, 7.9143e-04, 3.3676e-02, 2.2354e-04,
        7.6727e-05, 2.6879e-01, 2.2350e-03, 1.6253e-01, 6.5068e-03, 1.4152e-03,
        3.0154e-01, 1.0764e-02, 1.0999e-01, 1.0040e-02, 8.4005e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,289][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0012, 0.0263, 0.0069, 0.0444, 0.0203, 0.0615, 0.0434, 0.0689, 0.0707,
        0.0770, 0.0606, 0.0628, 0.1058, 0.1148, 0.0463, 0.1048, 0.0844],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,290][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0021, 0.0646, 0.0514, 0.0539, 0.0577, 0.0653, 0.0669, 0.0668, 0.0588,
        0.0727, 0.0658, 0.0632, 0.0677, 0.0556, 0.0659, 0.0616, 0.0599],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,290][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0822, 0.0096, 0.0182, 0.0307, 0.0098, 0.0493, 0.0229, 0.0124, 0.0530,
        0.0181, 0.1198, 0.1679, 0.0216, 0.2542, 0.0086, 0.0565, 0.0651],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,291][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0056, 0.0545, 0.0506, 0.0587, 0.0683, 0.0517, 0.0532, 0.0647, 0.0840,
        0.0634, 0.0587, 0.0566, 0.0711, 0.0558, 0.0762, 0.0644, 0.0625],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,293][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2901, 0.0318, 0.0512, 0.0259, 0.0711, 0.0271, 0.0212, 0.0881, 0.0362,
        0.0427, 0.0200, 0.0202, 0.1356, 0.0332, 0.0498, 0.0392, 0.0166],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,295][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9548, 0.0019, 0.0038, 0.0018, 0.0018, 0.0014, 0.0020, 0.0030, 0.0013,
        0.0027, 0.0047, 0.0010, 0.0043, 0.0017, 0.0039, 0.0083, 0.0018],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,295][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0029, 0.0558, 0.0406, 0.0523, 0.0424, 0.0478, 0.0108, 0.1641, 0.0902,
        0.0918, 0.0539, 0.0416, 0.0849, 0.0516, 0.0475, 0.1123, 0.0095],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,296][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.3717e-03, 1.2490e-04, 1.5087e-03, 3.4833e-05, 9.2032e-04, 7.3398e-04,
        2.7129e-04, 3.4364e-02, 2.7098e-03, 3.7396e-02, 7.6878e-03, 9.2220e-03,
        4.6670e-02, 9.9417e-02, 1.7586e-02, 6.7187e-01, 6.7111e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,296][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.5653e-04, 1.0883e-03, 2.4422e-02, 3.0823e-04, 8.0329e-03, 2.0970e-03,
        1.0340e-03, 3.2867e-01, 2.1069e-03, 1.1474e-01, 3.4827e-03, 5.3629e-03,
        1.3774e-01, 2.8565e-02, 2.8958e-02, 2.7345e-01, 3.9583e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,297][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0017, 0.0127, 0.0685, 0.0420, 0.0563, 0.1453, 0.0733, 0.0953, 0.0830,
        0.0296, 0.0498, 0.0794, 0.0551, 0.0267, 0.0716, 0.0506, 0.0590],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,297][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0020, 0.0152, 0.0233, 0.0717, 0.0092, 0.1249, 0.0123, 0.0163, 0.1291,
        0.0253, 0.0671, 0.1112, 0.0135, 0.1959, 0.0385, 0.0982, 0.0462],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,299][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([1.2276e-03, 4.2053e-05, 6.2857e-02, 3.1812e-04, 3.2704e-02, 2.1414e-04,
        7.7176e-04, 2.8777e-01, 1.0022e-02, 1.0129e-01, 3.9611e-02, 3.3287e-03,
        3.0172e-01, 3.7215e-03, 1.2744e-01, 6.5782e-03, 7.6570e-03, 1.2716e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,301][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0210, 0.0159, 0.0074, 0.0257, 0.0240, 0.0431, 0.0385, 0.0572, 0.0505,
        0.0529, 0.0622, 0.0567, 0.0897, 0.0919, 0.0415, 0.0890, 0.0870, 0.1459],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,302][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0020, 0.0607, 0.0484, 0.0506, 0.0547, 0.0611, 0.0634, 0.0625, 0.0548,
        0.0681, 0.0619, 0.0596, 0.0636, 0.0517, 0.0625, 0.0581, 0.0568, 0.0595],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,302][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0355, 0.0170, 0.0264, 0.0326, 0.0139, 0.0612, 0.0293, 0.0171, 0.0621,
        0.0223, 0.1431, 0.1779, 0.0246, 0.1648, 0.0119, 0.0699, 0.0737, 0.0168],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,303][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0052, 0.0518, 0.0466, 0.0552, 0.0639, 0.0489, 0.0504, 0.0611, 0.0789,
        0.0608, 0.0547, 0.0524, 0.0670, 0.0507, 0.0704, 0.0599, 0.0578, 0.0645],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,303][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.1182, 0.0515, 0.0421, 0.0586, 0.0579, 0.0259, 0.0615, 0.0256, 0.0707,
        0.0542, 0.0247, 0.0484, 0.1116, 0.0692, 0.0308, 0.0255, 0.0435, 0.0803],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,303][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.5005, 0.0066, 0.0072, 0.0087, 0.0066, 0.0204, 0.0273, 0.0148, 0.0242,
        0.0184, 0.0354, 0.0174, 0.0360, 0.0099, 0.0135, 0.1893, 0.0329, 0.0309],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,307][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0036, 0.0471, 0.0342, 0.0616, 0.0405, 0.0524, 0.0300, 0.1567, 0.0464,
        0.0531, 0.0411, 0.0751, 0.0593, 0.0360, 0.0407, 0.1576, 0.0277, 0.0368],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,308][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([6.4451e-03, 3.1423e-04, 2.1459e-03, 3.9296e-05, 1.3285e-03, 1.1789e-03,
        9.3849e-04, 3.6193e-02, 5.2381e-03, 3.4768e-02, 8.0986e-03, 2.2685e-02,
        3.4241e-02, 8.0554e-02, 2.7999e-02, 4.3989e-01, 1.5227e-01, 1.4568e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,308][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([3.1969e-03, 2.9374e-03, 2.6806e-02, 1.2636e-04, 7.6422e-03, 9.5674e-04,
        7.8759e-04, 1.3682e-01, 1.2461e-03, 5.7850e-02, 2.2983e-03, 4.2648e-03,
        1.1581e-01, 1.0801e-02, 3.3606e-02, 1.5322e-01, 4.0553e-02, 4.0108e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,309][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0011, 0.0116, 0.0409, 0.0276, 0.0920, 0.0987, 0.0969, 0.0605, 0.0622,
        0.0149, 0.0645, 0.0806, 0.0385, 0.0246, 0.1029, 0.0836, 0.0933, 0.0057],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,309][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0014, 0.0251, 0.0291, 0.0539, 0.0201, 0.0697, 0.0585, 0.0166, 0.0927,
        0.0279, 0.0637, 0.1442, 0.0170, 0.0808, 0.0650, 0.0475, 0.1612, 0.0256],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,310][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.2985e-03, 3.0205e-06, 5.3725e-02, 1.3375e-05, 3.5617e-02, 4.7739e-05,
        2.4624e-04, 2.7610e-01, 2.7392e-05, 1.9646e-01, 1.3865e-04, 1.5175e-03,
        1.8504e-01, 6.7633e-04, 1.8470e-01, 3.4405e-03, 4.1427e-03, 5.6617e-02,
        1.9289e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,313][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0882, 0.0165, 0.0120, 0.0268, 0.0199, 0.0394, 0.0393, 0.0532, 0.0320,
        0.0541, 0.0492, 0.0558, 0.0756, 0.0617, 0.0481, 0.0907, 0.0898, 0.1003,
        0.0472], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,314][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0018, 0.0577, 0.0456, 0.0478, 0.0515, 0.0580, 0.0600, 0.0598, 0.0525,
        0.0651, 0.0589, 0.0568, 0.0606, 0.0497, 0.0590, 0.0551, 0.0538, 0.0567,
        0.0497], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,314][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0996, 0.0142, 0.0218, 0.0276, 0.0119, 0.0441, 0.0246, 0.0138, 0.0491,
        0.0201, 0.1050, 0.1409, 0.0231, 0.1878, 0.0111, 0.0578, 0.0575, 0.0136,
        0.0764], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,315][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0062, 0.0486, 0.0465, 0.0512, 0.0593, 0.0461, 0.0476, 0.0559, 0.0688,
        0.0548, 0.0503, 0.0499, 0.0600, 0.0490, 0.0652, 0.0551, 0.0541, 0.0594,
        0.0720], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,315][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0881, 0.0171, 0.0620, 0.0137, 0.1047, 0.0201, 0.0454, 0.0995, 0.0400,
        0.0375, 0.0115, 0.0323, 0.1820, 0.0156, 0.0591, 0.0308, 0.0309, 0.1004,
        0.0091], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,316][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.9170, 0.0019, 0.0036, 0.0023, 0.0032, 0.0019, 0.0019, 0.0036, 0.0024,
        0.0029, 0.0076, 0.0018, 0.0062, 0.0027, 0.0077, 0.0177, 0.0023, 0.0093,
        0.0040], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,320][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0027, 0.0432, 0.0295, 0.0410, 0.0311, 0.0604, 0.0285, 0.1620, 0.0710,
        0.0861, 0.0464, 0.0548, 0.0975, 0.0310, 0.0330, 0.0901, 0.0255, 0.0507,
        0.0154], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,320][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.0852e-03, 2.1862e-04, 2.2104e-03, 2.5718e-05, 8.6130e-04, 8.3586e-04,
        3.2624e-04, 2.5707e-02, 1.7370e-03, 2.6083e-02, 4.5619e-03, 8.4360e-03,
        2.9653e-02, 9.7918e-02, 1.6112e-02, 3.6524e-01, 7.5621e-02, 1.5964e-01,
        1.7772e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,321][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.5555e-04, 1.6441e-03, 1.6262e-02, 1.5863e-04, 5.6988e-03, 8.4710e-04,
        5.3605e-04, 1.3220e-01, 7.3299e-04, 5.5202e-02, 1.4526e-03, 2.8897e-03,
        7.3863e-02, 1.5500e-02, 1.7808e-02, 1.0801e-01, 2.1990e-02, 5.2187e-01,
        2.2879e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,321][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0038, 0.0115, 0.0517, 0.0206, 0.0751, 0.0676, 0.1288, 0.0780, 0.0465,
        0.0188, 0.0242, 0.0751, 0.0717, 0.0242, 0.0903, 0.0610, 0.1025, 0.0178,
        0.0308], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,322][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0047, 0.0102, 0.0262, 0.0258, 0.0109, 0.0928, 0.0317, 0.0273, 0.0764,
        0.0286, 0.0679, 0.1085, 0.0257, 0.1258, 0.0305, 0.0695, 0.0959, 0.0517,
        0.0899], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,370][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:52,373][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,373][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,374][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,374][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,374][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,375][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,375][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,375][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,376][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,378][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,380][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,380][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,380][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2546, 0.7454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,381][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3713, 0.6287], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,381][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0372, 0.9628], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,381][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2550, 0.7450], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,382][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1824, 0.8176], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,382][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9913, 0.0087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,384][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7964, 0.2036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,386][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7829, 0.2171], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,387][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1304, 0.8696], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,387][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0429, 0.9571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,387][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0178, 0.9822], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,388][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7939, 0.2061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,388][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.0693, 0.3367, 0.5940], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,388][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0801, 0.2278, 0.6920], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,389][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.0188, 0.5538, 0.4275], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,390][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.3274, 0.2019, 0.4708], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,393][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0635, 0.2144, 0.7221], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,393][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.9050, 0.0332, 0.0618], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,393][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.4940, 0.1071, 0.3989], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,394][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.2781, 0.4295, 0.2924], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,394][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.0318, 0.2052, 0.7630], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,394][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0331, 0.5076, 0.4593], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,395][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0330, 0.3719, 0.5951], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,395][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.2724, 0.1265, 0.6010], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,398][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0074, 0.0998, 0.8811, 0.0118], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,402][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0561, 0.1734, 0.5009, 0.2696], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,403][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0146, 0.1893, 0.3174, 0.4787], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,403][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0421, 0.2328, 0.7051, 0.0199], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,403][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1014, 0.1894, 0.4587, 0.2506], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,404][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9846, 0.0040, 0.0090, 0.0024], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,404][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3962, 0.1556, 0.3411, 0.1071], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,404][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6045, 0.0995, 0.1916, 0.1044], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,405][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0116, 0.1579, 0.7856, 0.0449], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,405][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0025, 0.2854, 0.6558, 0.0563], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,407][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0065, 0.1707, 0.7314, 0.0914], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,409][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2166, 0.0768, 0.5956, 0.1110], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,410][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0552, 0.1016, 0.4407, 0.0257, 0.3768], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,410][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0236, 0.1093, 0.1469, 0.1504, 0.5697], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,410][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0055, 0.2100, 0.1784, 0.4727, 0.1334], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,411][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.1641, 0.1272, 0.4453, 0.0139, 0.2495], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,411][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0339, 0.0502, 0.1436, 0.0824, 0.6899], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,411][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.8951, 0.0167, 0.0445, 0.0223, 0.0214], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,412][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.2009, 0.0840, 0.3295, 0.1506, 0.2350], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,412][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1399, 0.2686, 0.2124, 0.1713, 0.2078], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,413][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0385, 0.0612, 0.4132, 0.0390, 0.4482], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,416][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0155, 0.2122, 0.2901, 0.0490, 0.4331], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,417][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0103, 0.1383, 0.4682, 0.0957, 0.2875], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,417][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.1659, 0.0944, 0.3518, 0.2496, 0.1383], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,417][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0125, 0.0371, 0.3782, 0.0045, 0.3320, 0.2357], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,418][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0227, 0.0888, 0.2327, 0.1389, 0.3820, 0.1349], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,418][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0048, 0.1109, 0.1488, 0.3831, 0.1740, 0.1783], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,418][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0072, 0.0973, 0.4622, 0.0184, 0.3714, 0.0434], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,419][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0014, 0.0162, 0.1236, 0.0640, 0.7271, 0.0677], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,419][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9150, 0.0087, 0.0420, 0.0055, 0.0176, 0.0111], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,422][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2903, 0.0769, 0.1808, 0.0929, 0.2215, 0.1377], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,423][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2417, 0.1072, 0.2420, 0.1311, 0.1758, 0.1021], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,424][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0017, 0.0592, 0.2778, 0.0188, 0.5328, 0.1097], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,424][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0018, 0.1520, 0.3895, 0.0374, 0.2175, 0.2019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,425][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0075, 0.0876, 0.1929, 0.2088, 0.2724, 0.2308], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,425][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0347, 0.0308, 0.2125, 0.1460, 0.1190, 0.4570], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,425][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0225, 0.0116, 0.1583, 0.0047, 0.2094, 0.4638, 0.1296],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,426][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0779, 0.0494, 0.1303, 0.1138, 0.1826, 0.2339, 0.2120],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,427][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0010, 0.0460, 0.0581, 0.2510, 0.0618, 0.3897, 0.1925],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,430][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0095, 0.0858, 0.4322, 0.0330, 0.3017, 0.0937, 0.0440],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,430][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0010, 0.0094, 0.0934, 0.0525, 0.7653, 0.0519, 0.0266],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,431][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9300, 0.0079, 0.0215, 0.0052, 0.0113, 0.0210, 0.0031],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,431][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2958, 0.0580, 0.1235, 0.0776, 0.1890, 0.1367, 0.1195],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,431][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2179, 0.0869, 0.1454, 0.0779, 0.1131, 0.2356, 0.1233],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,432][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0043, 0.0245, 0.2142, 0.0200, 0.4172, 0.2259, 0.0939],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,432][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0033, 0.0570, 0.1135, 0.0350, 0.1440, 0.3689, 0.2785],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,434][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0020, 0.0423, 0.1550, 0.1163, 0.1690, 0.3545, 0.1610],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,437][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0410, 0.0299, 0.1775, 0.1711, 0.0609, 0.4439, 0.0758],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,437][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([9.3995e-03, 3.2765e-04, 3.5152e-03, 6.2422e-05, 4.2186e-03, 1.0662e-02,
        6.9963e-03, 9.6482e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,437][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0222, 0.0522, 0.0820, 0.1071, 0.1991, 0.1521, 0.2979, 0.0874],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,438][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0006, 0.0288, 0.0130, 0.0823, 0.0314, 0.2512, 0.4650, 0.1277],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,438][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1730, 0.0318, 0.1457, 0.0064, 0.0973, 0.0244, 0.0132, 0.5082],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,438][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0085, 0.0505, 0.1126, 0.1078, 0.4585, 0.0912, 0.0504, 0.1205],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,439][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.9118, 0.0083, 0.0327, 0.0047, 0.0120, 0.0138, 0.0040, 0.0128],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,441][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2746, 0.0552, 0.1191, 0.0697, 0.1546, 0.1228, 0.1443, 0.0597],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,443][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1893, 0.0540, 0.0623, 0.0389, 0.0426, 0.1274, 0.1527, 0.3329],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,444][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0153, 0.0067, 0.0756, 0.0030, 0.0737, 0.0351, 0.0256, 0.7649],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,444][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0095, 0.0165, 0.0178, 0.0044, 0.0191, 0.0494, 0.0587, 0.8246],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,444][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0009, 0.0344, 0.0528, 0.0626, 0.0949, 0.1989, 0.4987, 0.0568],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,445][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0139, 0.0309, 0.0666, 0.0902, 0.0426, 0.4104, 0.1669, 0.1785],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,445][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([2.1490e-03, 1.1410e-04, 1.2795e-03, 3.0384e-05, 1.4762e-03, 3.3805e-03,
        2.5347e-03, 9.5000e-01, 3.9036e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,445][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0197, 0.0532, 0.1010, 0.0791, 0.1524, 0.1345, 0.1594, 0.1363, 0.1643],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,448][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0038, 0.0214, 0.0434, 0.0693, 0.0601, 0.0877, 0.2297, 0.1013, 0.3833],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,450][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0113, 0.0325, 0.0888, 0.0065, 0.0723, 0.0264, 0.0200, 0.6891, 0.0531],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,450][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0063, 0.0427, 0.1083, 0.1052, 0.3817, 0.1030, 0.0444, 0.1391, 0.0692],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,451][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.9514, 0.0037, 0.0116, 0.0033, 0.0060, 0.0105, 0.0021, 0.0077, 0.0037],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,451][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2680, 0.0298, 0.0780, 0.0564, 0.0924, 0.0966, 0.1213, 0.1069, 0.1506],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,451][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2111, 0.0480, 0.0796, 0.0359, 0.0464, 0.1141, 0.1028, 0.2611, 0.1010],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,452][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0026, 0.0015, 0.0370, 0.0012, 0.0353, 0.0278, 0.0179, 0.8067, 0.0700],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,452][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0010, 0.0039, 0.0112, 0.0022, 0.0101, 0.0244, 0.0264, 0.8657, 0.0551],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,454][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0045, 0.0233, 0.1569, 0.0516, 0.2527, 0.1370, 0.2028, 0.1144, 0.0568],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,456][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0861, 0.0170, 0.1468, 0.0620, 0.0498, 0.3130, 0.1127, 0.0652, 0.1476],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,457][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([1.7182e-03, 1.2218e-04, 1.3301e-03, 1.7179e-05, 9.2959e-04, 1.6650e-03,
        1.9646e-03, 6.2590e-01, 5.3327e-02, 3.1302e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,457][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0064, 0.0522, 0.1105, 0.0809, 0.1904, 0.0859, 0.1417, 0.0731, 0.2249,
        0.0340], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,458][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([1.1477e-04, 1.1276e-02, 1.3136e-02, 3.2910e-02, 1.8796e-02, 8.1864e-02,
        1.3369e-01, 5.2369e-02, 5.9037e-01, 6.5475e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,458][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0221, 0.0264, 0.0726, 0.0033, 0.0619, 0.0098, 0.0068, 0.4291, 0.0295,
        0.3385], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,458][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0052, 0.0301, 0.0451, 0.0646, 0.3944, 0.0565, 0.0300, 0.1615, 0.0585,
        0.1542], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,459][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.8518, 0.0123, 0.0330, 0.0054, 0.0145, 0.0244, 0.0044, 0.0193, 0.0146,
        0.0203], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,461][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1284, 0.0377, 0.0837, 0.0560, 0.1069, 0.0906, 0.1195, 0.1208, 0.1820,
        0.0744], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,463][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0398, 0.0482, 0.0994, 0.0335, 0.0589, 0.0916, 0.1052, 0.2497, 0.1608,
        0.1128], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,464][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0015, 0.0018, 0.0132, 0.0007, 0.0150, 0.0089, 0.0074, 0.3921, 0.0812,
        0.4783], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,464][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0014, 0.0072, 0.0122, 0.0015, 0.0111, 0.0134, 0.0228, 0.5910, 0.0576,
        0.2818], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,464][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0004, 0.0294, 0.0602, 0.0386, 0.1105, 0.1310, 0.2584, 0.1020, 0.2357,
        0.0338], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,465][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0109, 0.0443, 0.0943, 0.0783, 0.0445, 0.2516, 0.1278, 0.0817, 0.2077,
        0.0590], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,465][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.7246e-03, 1.0653e-04, 1.3166e-03, 2.5399e-05, 2.0129e-03, 2.7898e-03,
        2.2232e-03, 5.3845e-01, 2.9077e-02, 4.0533e-01, 1.5942e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,466][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0077, 0.0403, 0.0612, 0.0863, 0.1293, 0.1092, 0.1185, 0.1065, 0.2366,
        0.0320, 0.0724], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,468][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0012, 0.0121, 0.0205, 0.0411, 0.0267, 0.0564, 0.1669, 0.0940, 0.4248,
        0.1194, 0.0369], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,470][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0027, 0.0099, 0.0438, 0.0036, 0.0446, 0.0113, 0.0103, 0.4433, 0.0330,
        0.3759, 0.0216], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,470][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0016, 0.0153, 0.0604, 0.0476, 0.4010, 0.0697, 0.0372, 0.1056, 0.0343,
        0.1575, 0.0698], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,471][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.7918, 0.0115, 0.0255, 0.0073, 0.0169, 0.0303, 0.0078, 0.0260, 0.0191,
        0.0244, 0.0396], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,471][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2401, 0.0242, 0.0631, 0.0357, 0.0734, 0.0764, 0.0753, 0.0864, 0.1317,
        0.0712, 0.1223], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,471][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1076, 0.0352, 0.0739, 0.0405, 0.0444, 0.0984, 0.0747, 0.2238, 0.1439,
        0.0818, 0.0759], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,472][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0010, 0.0005, 0.0074, 0.0005, 0.0114, 0.0125, 0.0049, 0.3728, 0.0421,
        0.5075, 0.0393], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,472][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0006, 0.0047, 0.0189, 0.0022, 0.0154, 0.0206, 0.0230, 0.5327, 0.0467,
        0.2955, 0.0396], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,474][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0066, 0.0246, 0.1289, 0.0452, 0.1956, 0.1179, 0.1611, 0.1345, 0.0940,
        0.0592, 0.0325], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,476][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0771, 0.0255, 0.1053, 0.0595, 0.0444, 0.1963, 0.0676, 0.0786, 0.1431,
        0.1018, 0.1007], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,477][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.3174e-03, 4.9441e-05, 8.0989e-04, 1.6328e-05, 1.1161e-03, 2.0254e-03,
        8.9256e-04, 4.8309e-01, 4.2051e-02, 3.7951e-01, 3.9743e-02, 4.8375e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,477][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0154, 0.0196, 0.0811, 0.0587, 0.1372, 0.0754, 0.1120, 0.1332, 0.1300,
        0.0249, 0.0997, 0.1129], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,478][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0008, 0.0142, 0.0303, 0.0488, 0.0218, 0.0758, 0.1425, 0.0610, 0.3859,
        0.1057, 0.0596, 0.0537], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,478][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0047, 0.0104, 0.0576, 0.0030, 0.0405, 0.0116, 0.0064, 0.3959, 0.0221,
        0.3689, 0.0303, 0.0487], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,478][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0028, 0.0154, 0.0548, 0.0509, 0.2970, 0.0650, 0.0301, 0.1143, 0.0382,
        0.1498, 0.1148, 0.0668], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,479][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9216, 0.0038, 0.0101, 0.0019, 0.0059, 0.0074, 0.0016, 0.0071, 0.0055,
        0.0082, 0.0214, 0.0054], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,482][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2686, 0.0224, 0.0692, 0.0342, 0.0799, 0.0627, 0.0676, 0.0725, 0.0811,
        0.0565, 0.1130, 0.0723], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,483][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0895, 0.0269, 0.0531, 0.0239, 0.0337, 0.0792, 0.1184, 0.1873, 0.1381,
        0.0795, 0.0977, 0.0728], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,483][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0031, 0.0005, 0.0100, 0.0005, 0.0117, 0.0113, 0.0031, 0.3316, 0.0505,
        0.3844, 0.0931, 0.1002], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,484][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0014, 0.0020, 0.0069, 0.0009, 0.0054, 0.0126, 0.0159, 0.5149, 0.0320,
        0.2068, 0.0527, 0.1483], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,484][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0015, 0.0272, 0.0790, 0.0379, 0.0842, 0.1239, 0.2093, 0.1287, 0.1394,
        0.0359, 0.0526, 0.0804], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,485][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0826, 0.0256, 0.0866, 0.0479, 0.0328, 0.1601, 0.0681, 0.0653, 0.1297,
        0.0534, 0.1242, 0.1236], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,485][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([3.6999e-03, 1.5212e-05, 2.1725e-04, 5.8544e-06, 3.1175e-04, 9.4190e-04,
        9.3509e-04, 2.2121e-01, 1.3490e-02, 1.5788e-01, 2.3760e-02, 3.9423e-02,
        5.3811e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,486][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0133, 0.0245, 0.0206, 0.0355, 0.0515, 0.0450, 0.0975, 0.0798, 0.1574,
        0.0345, 0.1155, 0.2188, 0.1060], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,487][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([2.1902e-04, 7.0487e-03, 1.3381e-02, 2.7710e-02, 9.8779e-03, 5.9346e-02,
        9.6560e-02, 6.2317e-02, 4.7573e-01, 5.4068e-02, 7.9339e-02, 6.5851e-02,
        4.8556e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,490][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.0387, 0.0048, 0.0290, 0.0011, 0.0186, 0.0047, 0.0028, 0.1521, 0.0100,
        0.1379, 0.0207, 0.0260, 0.5537], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,490][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0104, 0.0166, 0.0295, 0.0377, 0.1596, 0.0394, 0.0212, 0.1241, 0.0421,
        0.1107, 0.0804, 0.0590, 0.2694], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,490][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.9056, 0.0028, 0.0087, 0.0026, 0.0068, 0.0056, 0.0028, 0.0058, 0.0048,
        0.0090, 0.0219, 0.0060, 0.0176], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,491][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.1490, 0.0183, 0.0562, 0.0292, 0.0529, 0.0653, 0.0869, 0.0752, 0.1044,
        0.0430, 0.1178, 0.1051, 0.0968], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,491][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0611, 0.0243, 0.0566, 0.0235, 0.0377, 0.0588, 0.0680, 0.1634, 0.1063,
        0.0501, 0.0806, 0.1053, 0.1643], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,492][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([5.2801e-03, 1.8828e-04, 2.4383e-03, 1.4976e-04, 3.5868e-03, 4.2159e-03,
        3.4853e-03, 1.5224e-01, 4.4843e-02, 1.9058e-01, 7.5169e-02, 1.1363e-01,
        4.0419e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,492][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([2.5130e-03, 1.0245e-03, 4.1700e-03, 3.0834e-04, 3.1889e-03, 7.4695e-03,
        8.0473e-03, 1.6856e-01, 2.3626e-02, 1.1870e-01, 3.9774e-02, 1.1952e-01,
        5.0310e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,495][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0006, 0.0123, 0.0330, 0.0275, 0.0428, 0.0625, 0.1622, 0.1217, 0.2152,
        0.0338, 0.1063, 0.1276, 0.0545], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,497][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.0346, 0.0166, 0.0663, 0.0551, 0.0285, 0.1083, 0.0751, 0.0540, 0.1351,
        0.0394, 0.1566, 0.1775, 0.0528], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,497][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([4.0687e-02, 3.6082e-04, 9.1250e-04, 8.9792e-06, 4.3511e-04, 7.1268e-04,
        6.2147e-04, 1.8169e-01, 7.0060e-03, 2.0928e-01, 1.2953e-02, 1.9109e-02,
        2.9151e-01, 2.3471e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,497][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0458, 0.0118, 0.0741, 0.0422, 0.1091, 0.0753, 0.0805, 0.0588, 0.0946,
        0.0157, 0.0938, 0.1347, 0.1341, 0.0295], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,498][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0006, 0.0164, 0.0278, 0.0433, 0.0352, 0.0583, 0.1256, 0.0407, 0.3309,
        0.0652, 0.0588, 0.0975, 0.0696, 0.0301], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,498][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0056, 0.0089, 0.0309, 0.0010, 0.0173, 0.0040, 0.0024, 0.1432, 0.0096,
        0.1192, 0.0168, 0.0279, 0.5294, 0.0838], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,499][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0042, 0.0273, 0.0550, 0.0495, 0.2315, 0.0490, 0.0189, 0.0936, 0.0344,
        0.0855, 0.0602, 0.0468, 0.1926, 0.0515], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,500][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.9244, 0.0029, 0.0072, 0.0015, 0.0031, 0.0060, 0.0013, 0.0044, 0.0027,
        0.0055, 0.0121, 0.0040, 0.0149, 0.0101], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,503][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2157, 0.0270, 0.0738, 0.0264, 0.0654, 0.0544, 0.0569, 0.0527, 0.0700,
        0.0437, 0.0889, 0.0659, 0.0995, 0.0597], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,504][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0552, 0.0314, 0.0536, 0.0265, 0.0505, 0.0645, 0.0668, 0.1480, 0.0996,
        0.0595, 0.0768, 0.0933, 0.1102, 0.0642], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,504][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0245, 0.0030, 0.0218, 0.0003, 0.0106, 0.0074, 0.0021, 0.1991, 0.0132,
        0.2381, 0.0388, 0.0442, 0.1527, 0.2442], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,505][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0069, 0.0058, 0.0094, 0.0004, 0.0047, 0.0043, 0.0049, 0.2022, 0.0081,
        0.0901, 0.0147, 0.0548, 0.3280, 0.2658], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,505][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0009, 0.0244, 0.1521, 0.0338, 0.1596, 0.0870, 0.1323, 0.0726, 0.0885,
        0.0220, 0.0381, 0.0913, 0.0726, 0.0248], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,505][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0332, 0.0130, 0.0767, 0.0385, 0.0273, 0.1615, 0.0641, 0.0613, 0.0769,
        0.0428, 0.0867, 0.1397, 0.0513, 0.1270], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,506][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([1.2610e-03, 3.6056e-05, 2.4352e-04, 6.6375e-06, 1.7110e-04, 3.8928e-04,
        4.3650e-04, 9.3505e-02, 7.7523e-03, 7.8430e-02, 7.5508e-03, 1.7533e-02,
        3.3080e-01, 4.3490e-01, 2.6989e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,509][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0095, 0.0178, 0.0359, 0.0422, 0.1181, 0.0426, 0.0475, 0.0705, 0.0778,
        0.0191, 0.0658, 0.1040, 0.1205, 0.0270, 0.2016], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,510][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0009, 0.0159, 0.0239, 0.0341, 0.0128, 0.0613, 0.0803, 0.0387, 0.4663,
        0.0402, 0.0701, 0.0487, 0.0415, 0.0207, 0.0445], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,510][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0295, 0.0044, 0.0289, 0.0009, 0.0158, 0.0045, 0.0028, 0.1083, 0.0072,
        0.0715, 0.0082, 0.0213, 0.4142, 0.0862, 0.1965], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,511][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0117, 0.0181, 0.0477, 0.0335, 0.1834, 0.0359, 0.0199, 0.0762, 0.0265,
        0.1124, 0.0555, 0.0424, 0.1524, 0.0346, 0.1497], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,511][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.6642, 0.0081, 0.0277, 0.0081, 0.0131, 0.0228, 0.0052, 0.0117, 0.0115,
        0.0191, 0.0617, 0.0152, 0.0540, 0.0442, 0.0334], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,512][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0749, 0.0119, 0.0706, 0.0184, 0.0509, 0.0572, 0.0739, 0.0375, 0.0853,
        0.0287, 0.0752, 0.0907, 0.0787, 0.0479, 0.1984], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,512][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0259, 0.0370, 0.0429, 0.0221, 0.0298, 0.0567, 0.1046, 0.1427, 0.0868,
        0.0564, 0.0548, 0.0762, 0.0695, 0.0580, 0.1366], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,514][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([2.7673e-03, 2.5247e-04, 3.9840e-03, 2.0501e-04, 2.4438e-03, 2.9704e-03,
        1.3877e-03, 1.0013e-01, 1.2738e-02, 5.5781e-02, 1.4910e-02, 7.3033e-02,
        2.4611e-01, 4.0425e-01, 7.9039e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,516][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([1.8093e-03, 8.3826e-04, 2.0218e-03, 1.8558e-04, 2.0341e-03, 3.0999e-03,
        4.8637e-03, 1.1086e-01, 9.7137e-03, 5.8290e-02, 1.3112e-02, 6.5661e-02,
        2.8367e-01, 3.4748e-01, 9.6353e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,517][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0014, 0.0390, 0.1327, 0.0246, 0.0613, 0.1030, 0.1075, 0.1084, 0.0744,
        0.0202, 0.0491, 0.0770, 0.1021, 0.0270, 0.0723], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,517][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0583, 0.0168, 0.0421, 0.0266, 0.0152, 0.1241, 0.0674, 0.0397, 0.0864,
        0.0438, 0.1131, 0.1236, 0.0349, 0.1013, 0.1067], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,518][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.8357e-02, 1.1460e-04, 8.6809e-04, 2.5673e-06, 3.6522e-04, 2.2659e-04,
        2.5029e-04, 1.1432e-01, 4.2454e-03, 6.5300e-02, 6.4362e-03, 1.0722e-02,
        2.0647e-01, 2.0908e-01, 2.5570e-02, 3.3768e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,518][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0081, 0.0202, 0.0696, 0.0299, 0.0759, 0.0328, 0.0490, 0.0390, 0.0654,
        0.0281, 0.1393, 0.1016, 0.1181, 0.0349, 0.1691, 0.0189],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,519][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.3662e-04, 2.3647e-02, 2.6439e-02, 5.9811e-02, 4.3793e-02, 3.7489e-02,
        1.1907e-01, 1.8778e-02, 3.4332e-01, 3.4270e-02, 3.2059e-02, 5.0891e-02,
        4.8062e-02, 6.2417e-02, 8.9530e-02, 1.0089e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,519][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0203, 0.0076, 0.0324, 0.0005, 0.0183, 0.0014, 0.0015, 0.0871, 0.0052,
        0.0784, 0.0073, 0.0131, 0.2770, 0.0464, 0.1807, 0.2229],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,522][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0056, 0.0236, 0.0424, 0.0377, 0.1506, 0.0334, 0.0155, 0.0649, 0.0297,
        0.0764, 0.0485, 0.0430, 0.2053, 0.0454, 0.0989, 0.0792],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,524][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.8571, 0.0044, 0.0129, 0.0015, 0.0064, 0.0063, 0.0027, 0.0070, 0.0055,
        0.0071, 0.0158, 0.0056, 0.0191, 0.0140, 0.0137, 0.0209],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,524][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0756, 0.0086, 0.0371, 0.0168, 0.0512, 0.0352, 0.0547, 0.0504, 0.0888,
        0.0331, 0.0839, 0.0726, 0.0871, 0.0586, 0.1993, 0.0468],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,524][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1054, 0.0251, 0.0450, 0.0127, 0.0252, 0.0467, 0.0712, 0.1009, 0.0656,
        0.0599, 0.0536, 0.0957, 0.0885, 0.0534, 0.0791, 0.0720],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,525][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.7866e-03, 9.2701e-04, 5.9266e-03, 1.3489e-04, 3.2509e-03, 1.3906e-03,
        1.1990e-03, 8.8206e-02, 1.2595e-02, 8.1061e-02, 1.9632e-02, 3.1023e-02,
        1.1970e-01, 2.2765e-01, 6.1463e-02, 3.4305e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,525][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.5544e-03, 3.3439e-03, 6.0216e-03, 1.9415e-04, 3.8739e-03, 1.6770e-03,
        2.8634e-03, 7.1205e-02, 6.8189e-03, 5.6232e-02, 7.9305e-03, 4.0331e-02,
        1.8536e-01, 2.1860e-01, 1.2133e-01, 2.7267e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,526][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0006, 0.0272, 0.0475, 0.0491, 0.0649, 0.0755, 0.1162, 0.0329, 0.0998,
        0.0271, 0.0932, 0.1209, 0.1234, 0.0397, 0.0723, 0.0097],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,528][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0349, 0.0107, 0.0371, 0.0411, 0.0235, 0.1159, 0.0563, 0.0388, 0.1312,
        0.0297, 0.0858, 0.1394, 0.0339, 0.1132, 0.0698, 0.0387],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,530][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.5460e-03, 2.4799e-05, 1.4144e-04, 1.7340e-06, 9.7656e-05, 1.4150e-04,
        7.0080e-05, 3.8335e-02, 2.0800e-03, 3.2932e-02, 2.1041e-03, 3.6210e-03,
        1.0632e-01, 1.6135e-01, 1.1340e-02, 4.9724e-01, 1.3865e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,531][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0681, 0.0103, 0.0423, 0.0391, 0.0507, 0.0612, 0.0647, 0.0404, 0.0788,
        0.0129, 0.1018, 0.1592, 0.0577, 0.0198, 0.1126, 0.0326, 0.0478],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,531][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0004, 0.0125, 0.0210, 0.0644, 0.0154, 0.0906, 0.0519, 0.0296, 0.3841,
        0.0474, 0.0386, 0.0366, 0.0311, 0.0328, 0.0514, 0.0554, 0.0367],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,532][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0120, 0.0025, 0.0175, 0.0007, 0.0093, 0.0025, 0.0012, 0.0758, 0.0051,
        0.0668, 0.0064, 0.0103, 0.2874, 0.0786, 0.0909, 0.2493, 0.0836],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,532][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0023, 0.0171, 0.0518, 0.0469, 0.1372, 0.0387, 0.0159, 0.0725, 0.0261,
        0.0717, 0.0632, 0.0445, 0.1462, 0.0467, 0.1182, 0.0737, 0.0272],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,533][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.3175e-01, 1.1584e-03, 3.6770e-03, 8.2936e-04, 1.6458e-03, 3.4055e-03,
        5.2430e-04, 1.7725e-03, 1.5691e-03, 2.5879e-03, 7.9673e-03, 2.0377e-03,
        6.7671e-03, 5.7557e-03, 3.3746e-03, 2.2563e-02, 2.6135e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,535][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1852, 0.0123, 0.0383, 0.0180, 0.0453, 0.0367, 0.0351, 0.0314, 0.0440,
        0.0329, 0.0667, 0.0376, 0.0789, 0.0412, 0.1958, 0.0439, 0.0568],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,537][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0508, 0.0114, 0.0383, 0.0134, 0.0241, 0.0434, 0.0313, 0.0884, 0.0590,
        0.0377, 0.0664, 0.0736, 0.0707, 0.0623, 0.1099, 0.1585, 0.0608],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,538][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.3717e-03, 1.2490e-04, 1.5087e-03, 3.4833e-05, 9.2032e-04, 7.3398e-04,
        2.7129e-04, 3.4364e-02, 2.7098e-03, 3.7396e-02, 7.6878e-03, 9.2220e-03,
        4.6670e-02, 9.9417e-02, 1.7586e-02, 6.7187e-01, 6.7111e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,538][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.3152e-03, 4.4225e-04, 1.0738e-03, 9.7579e-05, 6.6493e-04, 1.4542e-03,
        1.3237e-03, 5.6869e-02, 3.7971e-03, 2.6821e-02, 6.7219e-03, 2.0189e-02,
        8.2523e-02, 1.8114e-01, 3.2711e-02, 3.2986e-01, 2.5200e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,538][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0019, 0.0138, 0.0685, 0.0430, 0.0577, 0.1372, 0.0713, 0.1012, 0.0788,
        0.0298, 0.0483, 0.0795, 0.0582, 0.0273, 0.0735, 0.0517, 0.0583],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,539][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0375, 0.0106, 0.0434, 0.0419, 0.0172, 0.1299, 0.0232, 0.0271, 0.0887,
        0.0246, 0.0768, 0.1077, 0.0230, 0.1088, 0.0812, 0.0812, 0.0771],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,539][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([6.9111e-03, 5.7266e-05, 1.8754e-04, 1.1430e-06, 1.3034e-04, 9.3937e-05,
        1.8952e-04, 5.9443e-02, 2.4181e-03, 3.2660e-02, 3.2803e-03, 6.3562e-03,
        8.7403e-02, 7.6538e-02, 1.9086e-02, 2.5821e-01, 1.8472e-01, 2.6231e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,542][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0084, 0.0376, 0.0562, 0.0443, 0.0716, 0.0293, 0.0713, 0.0457, 0.0748,
        0.0131, 0.1076, 0.0979, 0.0564, 0.0303, 0.1400, 0.0297, 0.0705, 0.0154],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,544][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.7326e-04, 1.8815e-02, 2.1388e-02, 5.1978e-02, 1.9394e-02, 4.8207e-02,
        9.7556e-02, 2.8313e-02, 2.1203e-01, 3.6828e-02, 5.8949e-02, 6.5977e-02,
        2.5690e-02, 2.4034e-02, 9.5706e-02, 7.6700e-02, 9.9158e-02, 1.9099e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,544][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([2.4895e-02, 2.3171e-03, 8.3514e-03, 1.6508e-04, 5.0122e-03, 5.7465e-04,
        6.0133e-04, 4.0120e-02, 2.0632e-03, 3.8519e-02, 4.0438e-03, 5.9590e-03,
        1.4455e-01, 2.2609e-02, 6.9412e-02, 1.0123e-01, 4.0520e-02, 4.8905e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,545][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0115, 0.0241, 0.0212, 0.0175, 0.1298, 0.0179, 0.0087, 0.0580, 0.0207,
        0.0703, 0.0313, 0.0249, 0.1042, 0.0242, 0.0633, 0.0726, 0.0180, 0.2819],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,545][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.7785, 0.0046, 0.0175, 0.0026, 0.0075, 0.0077, 0.0030, 0.0051, 0.0045,
        0.0060, 0.0190, 0.0059, 0.0242, 0.0146, 0.0188, 0.0537, 0.0144, 0.0124],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,546][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0770, 0.0149, 0.0562, 0.0202, 0.0565, 0.0392, 0.0432, 0.0447, 0.0596,
        0.0286, 0.0669, 0.0608, 0.0909, 0.0383, 0.1776, 0.0368, 0.0548, 0.0338],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,546][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0113, 0.0233, 0.0458, 0.0192, 0.0305, 0.0390, 0.0425, 0.1417, 0.0416,
        0.0337, 0.0374, 0.0865, 0.0610, 0.0473, 0.0994, 0.1078, 0.0668, 0.0650],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,548][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([6.4451e-03, 3.1423e-04, 2.1459e-03, 3.9296e-05, 1.3285e-03, 1.1789e-03,
        9.3849e-04, 3.6193e-02, 5.2381e-03, 3.4768e-02, 8.0986e-03, 2.2685e-02,
        3.4241e-02, 8.0554e-02, 2.7999e-02, 4.3989e-01, 1.5227e-01, 1.4568e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,550][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([2.3616e-03, 7.2966e-04, 1.5569e-03, 6.3157e-05, 8.1940e-04, 9.4704e-04,
        1.4081e-03, 3.2666e-02, 2.7074e-03, 1.8795e-02, 4.2639e-03, 1.8651e-02,
        7.3463e-02, 8.7213e-02, 3.5012e-02, 1.9720e-01, 2.6193e-01, 2.6022e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,551][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0012, 0.0134, 0.0416, 0.0286, 0.0940, 0.0966, 0.0920, 0.0608, 0.0590,
        0.0151, 0.0628, 0.0805, 0.0403, 0.0254, 0.1054, 0.0854, 0.0917, 0.0061],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,551][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0173, 0.0160, 0.0449, 0.0347, 0.0333, 0.0810, 0.0597, 0.0240, 0.0681,
        0.0269, 0.0611, 0.1095, 0.0289, 0.0676, 0.1140, 0.0440, 0.1476, 0.0214],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,552][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.9180e-02, 2.2862e-05, 8.6229e-05, 4.7516e-07, 3.2658e-05, 3.6157e-05,
        5.3580e-05, 1.6880e-02, 5.1442e-04, 1.2458e-02, 6.1844e-04, 1.7803e-03,
        3.3220e-02, 7.3615e-02, 3.7629e-03, 2.0236e-01, 6.9945e-02, 2.0571e-01,
        3.3972e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,552][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0468, 0.0130, 0.0490, 0.0466, 0.0638, 0.0600, 0.0760, 0.0585, 0.0757,
        0.0086, 0.0692, 0.1148, 0.0658, 0.0155, 0.1128, 0.0366, 0.0581, 0.0071,
        0.0222], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,553][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0023, 0.0092, 0.0155, 0.0303, 0.0174, 0.0409, 0.0794, 0.0279, 0.2643,
        0.0491, 0.0300, 0.0436, 0.0332, 0.0277, 0.0592, 0.0613, 0.0588, 0.0436,
        0.1063], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,553][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.3177e-03, 1.4656e-03, 7.0079e-03, 1.7911e-04, 3.6270e-03, 8.1856e-04,
        5.4781e-04, 3.2937e-02, 1.9577e-03, 2.5947e-02, 2.7406e-03, 4.4891e-03,
        1.1525e-01, 2.3205e-02, 4.5564e-02, 1.1262e-01, 3.4229e-02, 5.1535e-01,
        6.3743e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,556][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0035, 0.0195, 0.0328, 0.0314, 0.0869, 0.0277, 0.0134, 0.0523, 0.0217,
        0.0531, 0.0418, 0.0381, 0.1164, 0.0444, 0.0829, 0.0519, 0.0232, 0.2258,
        0.0333], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,557][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.1566e-01, 1.3450e-03, 2.3619e-03, 8.3074e-04, 1.5390e-03, 3.3698e-03,
        6.1913e-04, 2.0564e-03, 1.1545e-03, 2.1282e-03, 6.0267e-03, 1.8443e-03,
        6.4554e-03, 6.5917e-03, 3.6187e-03, 2.2166e-02, 3.3100e-03, 6.2208e-03,
        1.2707e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,558][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2078, 0.0087, 0.0342, 0.0134, 0.0376, 0.0264, 0.0327, 0.0260, 0.0456,
        0.0223, 0.0692, 0.0388, 0.0651, 0.0324, 0.1546, 0.0299, 0.0534, 0.0324,
        0.0697], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,558][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0956, 0.0111, 0.0458, 0.0100, 0.0242, 0.0346, 0.0455, 0.0777, 0.0634,
        0.0237, 0.0464, 0.0589, 0.0704, 0.0345, 0.0885, 0.0918, 0.0693, 0.0712,
        0.0372], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,559][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.0852e-03, 2.1862e-04, 2.2104e-03, 2.5718e-05, 8.6130e-04, 8.3586e-04,
        3.2624e-04, 2.5707e-02, 1.7370e-03, 2.6083e-02, 4.5619e-03, 8.4360e-03,
        2.9653e-02, 9.7918e-02, 1.6112e-02, 3.6524e-01, 7.5621e-02, 1.5964e-01,
        1.7772e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,559][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.3561e-03, 5.5151e-04, 7.0675e-04, 4.8846e-05, 4.4096e-04, 6.3012e-04,
        7.5301e-04, 2.3297e-02, 1.1927e-03, 1.1503e-02, 2.4738e-03, 9.9459e-03,
        4.1970e-02, 8.3861e-02, 1.6444e-02, 1.1652e-01, 1.2959e-01, 3.1043e-01,
        2.4428e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,560][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0039, 0.0129, 0.0563, 0.0233, 0.0827, 0.0663, 0.1211, 0.0763, 0.0440,
        0.0184, 0.0236, 0.0742, 0.0740, 0.0245, 0.0908, 0.0609, 0.0991, 0.0184,
        0.0294], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,562][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0878, 0.0059, 0.0431, 0.0171, 0.0178, 0.0986, 0.0322, 0.0326, 0.0513,
        0.0195, 0.0570, 0.0885, 0.0325, 0.0843, 0.0706, 0.0546, 0.0985, 0.0333,
        0.0746], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,564][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:52,566][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13722],
        [ 2361],
        [35573],
        [19302],
        [ 3755],
        [ 3131],
        [ 2013],
        [ 1341],
        [ 2648],
        [ 2253],
        [ 4701],
        [ 1706],
        [ 3395],
        [  324],
        [ 1894],
        [  418],
        [  898],
        [  875],
        [ 1175]], device='cuda:0')
[2024-07-24 10:19:52,567][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13765],
        [ 5483],
        [27785],
        [ 4134],
        [  836],
        [ 2404],
        [ 1620],
        [ 2354],
        [ 5061],
        [ 2796],
        [ 7673],
        [ 3250],
        [ 3981],
        [  348],
        [ 1767],
        [  643],
        [ 1156],
        [  760],
        [ 2197]], device='cuda:0')
[2024-07-24 10:19:52,568][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30767],
        [30852],
        [34467],
        [34326],
        [33282],
        [32069],
        [31075],
        [25942],
        [17777],
        [18473],
        [19411],
        [19632],
        [16126],
        [18009],
        [14942],
        [16667],
        [16364],
        [15395],
        [17159]], device='cuda:0')
[2024-07-24 10:19:52,569][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 7797],
        [11656],
        [13043],
        [11105],
        [ 7360],
        [ 9489],
        [ 9586],
        [ 9211],
        [ 9858],
        [ 9260],
        [ 8687],
        [ 8513],
        [ 8105],
        [ 6850],
        [ 6511],
        [ 6677],
        [ 6825],
        [ 5857],
        [ 5967]], device='cuda:0')
[2024-07-24 10:19:52,572][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[35447],
        [30199],
        [42081],
        [40167],
        [40720],
        [38787],
        [38246],
        [36851],
        [35707],
        [34379],
        [34441],
        [34417],
        [35059],
        [35088],
        [35567],
        [35405],
        [35269],
        [34856],
        [34683]], device='cuda:0')
[2024-07-24 10:19:52,574][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7864],
        [11326],
        [ 7835],
        [12992],
        [14576],
        [14703],
        [18071],
        [17111],
        [17459],
        [17885],
        [19353],
        [19951],
        [20065],
        [18554],
        [21272],
        [20521],
        [22044],
        [21455],
        [21864]], device='cuda:0')
[2024-07-24 10:19:52,575][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[16291],
        [13092],
        [11338],
        [11684],
        [10381],
        [10559],
        [10459],
        [10807],
        [10718],
        [10370],
        [10286],
        [ 9967],
        [ 9474],
        [ 9294],
        [ 9114],
        [ 8968],
        [ 8809],
        [ 8688],
        [ 8698]], device='cuda:0')
[2024-07-24 10:19:52,576][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45703],
        [37783],
        [39132],
        [ 2556],
        [ 4878],
        [ 2493],
        [ 9712],
        [ 3448],
        [ 1446],
        [ 4792],
        [ 3951],
        [ 3823],
        [ 3852],
        [ 2174],
        [ 3203],
        [ 3240],
        [ 3352],
        [ 2467],
        [ 1805]], device='cuda:0')
[2024-07-24 10:19:52,578][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 4594],
        [ 4692],
        [ 8982],
        [ 6208],
        [22292],
        [ 6538],
        [ 5913],
        [19838],
        [10349],
        [41147],
        [18229],
        [ 7889],
        [41494],
        [12219],
        [44670],
        [20493],
        [ 7460],
        [41137],
        [10970]], device='cuda:0')
[2024-07-24 10:19:52,580][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[22267],
        [34866],
        [36226],
        [34708],
        [35816],
        [35535],
        [35555],
        [37105],
        [38654],
        [38304],
        [36556],
        [36386],
        [36087],
        [36986],
        [36974],
        [36033],
        [37562],
        [36687],
        [36578]], device='cuda:0')
[2024-07-24 10:19:52,582][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9237],
        [40359],
        [49230],
        [49115],
        [44186],
        [39503],
        [34192],
        [ 8501],
        [ 6707],
        [11506],
        [11882],
        [10968],
        [15461],
        [10975],
        [10600],
        [12475],
        [13868],
        [15177],
        [14777]], device='cuda:0')
[2024-07-24 10:19:52,583][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41193],
        [20561],
        [12959],
        [12040],
        [20486],
        [16943],
        [24944],
        [37471],
        [37925],
        [41282],
        [41376],
        [41673],
        [42659],
        [42035],
        [43298],
        [43554],
        [43987],
        [45286],
        [45360]], device='cuda:0')
[2024-07-24 10:19:52,584][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[18581],
        [20329],
        [50256],
        [50256],
        [50250],
        [49306],
        [49068],
        [45696],
        [49805],
        [47303],
        [49381],
        [47241],
        [41522],
        [49634],
        [49228],
        [42857],
        [47284],
        [45945],
        [47031]], device='cuda:0')
[2024-07-24 10:19:52,586][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[17602],
        [25815],
        [49935],
        [49945],
        [49405],
        [48726],
        [46775],
        [43378],
        [46369],
        [42928],
        [46734],
        [45847],
        [46188],
        [47379],
        [46194],
        [46394],
        [46295],
        [46378],
        [46492]], device='cuda:0')
[2024-07-24 10:19:52,588][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25695],
        [24559],
        [15395],
        [25182],
        [20104],
        [24183],
        [23079],
        [20121],
        [20544],
        [21995],
        [22306],
        [23101],
        [27848],
        [23411],
        [23657],
        [25348],
        [25073],
        [24657],
        [19984]], device='cuda:0')
[2024-07-24 10:19:52,590][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[44729],
        [18853],
        [12440],
        [ 9548],
        [11368],
        [13780],
        [22656],
        [39868],
        [40121],
        [37994],
        [37264],
        [36850],
        [40990],
        [33907],
        [28096],
        [31337],
        [28961],
        [33254],
        [26273]], device='cuda:0')
[2024-07-24 10:19:52,591][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[28722],
        [21792],
        [17756],
        [21054],
        [25986],
        [23115],
        [21501],
        [24142],
        [23389],
        [23494],
        [23247],
        [23561],
        [22388],
        [21852],
        [24201],
        [22669],
        [23180],
        [23491],
        [23905]], device='cuda:0')
[2024-07-24 10:19:52,593][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[24541],
        [39276],
        [40902],
        [40897],
        [41531],
        [41397],
        [40270],
        [35897],
        [40863],
        [40802],
        [38950],
        [40753],
        [41688],
        [41684],
        [42260],
        [42117],
        [43271],
        [42720],
        [40823]], device='cuda:0')
[2024-07-24 10:19:52,595][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20851],
        [41618],
        [45026],
        [44817],
        [42149],
        [39376],
        [38269],
        [43382],
        [41830],
        [36367],
        [34856],
        [34884],
        [ 6295],
        [ 5859],
        [ 6252],
        [ 8648],
        [ 7976],
        [ 3685],
        [ 3926]], device='cuda:0')
[2024-07-24 10:19:52,597][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[44602],
        [33333],
        [30101],
        [34077],
        [36582],
        [35376],
        [35760],
        [32360],
        [30028],
        [24915],
        [24478],
        [21617],
        [18944],
        [22662],
        [21451],
        [21319],
        [20952],
        [18534],
        [18732]], device='cuda:0')
[2024-07-24 10:19:52,598][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[40233],
        [40348],
        [35513],
        [39670],
        [37969],
        [37120],
        [37662],
        [36880],
        [38687],
        [36566],
        [36702],
        [39942],
        [40305],
        [40306],
        [30917],
        [40204],
        [40625],
        [38041],
        [40443]], device='cuda:0')
[2024-07-24 10:19:52,599][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[42987],
        [35471],
        [22942],
        [24112],
        [23382],
        [25671],
        [28733],
        [29688],
        [29843],
        [28081],
        [28256],
        [30178],
        [31955],
        [30291],
        [31870],
        [31761],
        [32134],
        [32433],
        [33347]], device='cuda:0')
[2024-07-24 10:19:52,601][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[15790],
        [ 4607],
        [ 5935],
        [ 7057],
        [ 7674],
        [10877],
        [18151],
        [25535],
        [21994],
        [18784],
        [18555],
        [18067],
        [16765],
        [16796],
        [15771],
        [15503],
        [15056],
        [15587],
        [13688]], device='cuda:0')
[2024-07-24 10:19:52,602][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44545],
        [34469],
        [26561],
        [25857],
        [15668],
        [13950],
        [17624],
        [20296],
        [22485],
        [24674],
        [24080],
        [22130],
        [26388],
        [23885],
        [22528],
        [ 9202],
        [ 6907],
        [ 6528],
        [ 6747]], device='cuda:0')
[2024-07-24 10:19:52,606][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22374],
        [19530],
        [21348],
        [22202],
        [16520],
        [16359],
        [ 6306],
        [15976],
        [16447],
        [16821],
        [16176],
        [12533],
        [ 3150],
        [ 3926],
        [ 3289],
        [ 5888],
        [ 7247],
        [ 7196],
        [ 7206]], device='cuda:0')
[2024-07-24 10:19:52,609][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[35034],
        [37438],
        [12757],
        [14406],
        [12801],
        [21981],
        [23868],
        [24149],
        [21671],
        [28337],
        [24704],
        [30152],
        [34425],
        [27980],
        [29486],
        [30889],
        [29685],
        [27895],
        [28773]], device='cuda:0')
[2024-07-24 10:19:52,610][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[31899],
        [ 7896],
        [ 2831],
        [ 3175],
        [ 3035],
        [ 4448],
        [ 5204],
        [ 7122],
        [ 5626],
        [ 6781],
        [ 6105],
        [ 5884],
        [ 6058],
        [ 5621],
        [ 4863],
        [ 5405],
        [ 5440],
        [ 5532],
        [ 5714]], device='cuda:0')
[2024-07-24 10:19:52,611][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4471],
        [18660],
        [27951],
        [25036],
        [28795],
        [25630],
        [21301],
        [11159],
        [11626],
        [13367],
        [15091],
        [15316],
        [19624],
        [23013],
        [26740],
        [26579],
        [27872],
        [28846],
        [30975]], device='cuda:0')
[2024-07-24 10:19:52,612][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8763],
        [ 4334],
        [27223],
        [23660],
        [22026],
        [21440],
        [24901],
        [20188],
        [21269],
        [21281],
        [20864],
        [21553],
        [26737],
        [32154],
        [30563],
        [27409],
        [29658],
        [29781],
        [34286]], device='cuda:0')
[2024-07-24 10:19:52,614][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551],
        [5551]], device='cuda:0')
[2024-07-24 10:19:52,653][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:52,654][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,654][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,654][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,654][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,655][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,656][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,656][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,657][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,657][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,657][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,658][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,658][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,658][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8539, 0.1461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,659][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,659][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1800, 0.8200], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,659][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0410, 0.9590], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,660][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5682, 0.4318], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,660][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9943, 0.0057], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,660][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0385, 0.9615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,660][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0052, 0.9948], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,661][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8290, 0.1710], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,661][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1785, 0.8215], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,661][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2471, 0.7529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,662][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0848, 0.9152], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,662][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.1241, 0.1180, 0.7579], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,662][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0007, 0.5658, 0.4335], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,663][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.0737, 0.4383, 0.4880], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,663][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.0189, 0.5250, 0.4561], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,663][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.1685, 0.1450, 0.6865], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,664][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0693, 0.9234, 0.0073], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,665][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0202, 0.5476, 0.4322], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,667][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0025, 0.7158, 0.2818], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,667][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.6939, 0.2283, 0.0778], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,668][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0975, 0.4729, 0.4296], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,668][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.2164, 0.3694, 0.4143], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,668][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.0092, 0.9473, 0.0435], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,669][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1709, 0.0904, 0.6791, 0.0595], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,669][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0004, 0.3454, 0.2714, 0.3828], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,669][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0613, 0.2881, 0.3289, 0.3217], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,673][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0225, 0.3280, 0.2823, 0.3671], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,673][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3314, 0.0456, 0.3376, 0.2854], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,674][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3478, 0.6301, 0.0103, 0.0118], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,674][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0138, 0.3262, 0.2857, 0.3743], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,674][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0046, 0.7904, 0.1860, 0.0190], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,675][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7176, 0.1552, 0.0790, 0.0482], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,675][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0890, 0.3668, 0.3065, 0.2376], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,675][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1476, 0.2218, 0.2622, 0.3684], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,679][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0154, 0.7785, 0.0603, 0.1457], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,680][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1083, 0.0757, 0.4303, 0.0360, 0.3497], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,680][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0004, 0.2576, 0.1915, 0.2805, 0.2700], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,680][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0421, 0.2013, 0.2276, 0.2241, 0.3049], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,681][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0091, 0.2565, 0.1940, 0.2375, 0.3029], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,681][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0758, 0.0503, 0.3718, 0.4618, 0.0403], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,681][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0198, 0.9611, 0.0064, 0.0088, 0.0038], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,682][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0157, 0.2409, 0.2129, 0.2762, 0.2544], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,685][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0050, 0.1022, 0.0299, 0.0295, 0.8334], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,686][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.3809, 0.4236, 0.1099, 0.0510, 0.0347], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,686][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0415, 0.3166, 0.1735, 0.2390, 0.2294], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,687][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.1407, 0.1827, 0.1900, 0.2680, 0.2187], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,687][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0070, 0.6976, 0.0475, 0.1410, 0.1068], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,687][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0676, 0.0390, 0.2227, 0.0295, 0.1796, 0.4616], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,688][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0003, 0.2215, 0.1609, 0.2428, 0.2249, 0.1496], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,688][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0220, 0.1638, 0.1893, 0.1873, 0.2574, 0.1803], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,692][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0048, 0.2157, 0.1933, 0.2164, 0.2277, 0.1421], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,692][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0911, 0.0050, 0.0391, 0.0365, 0.0050, 0.8234], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,692][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0640, 0.8955, 0.0119, 0.0123, 0.0077, 0.0085], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,693][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0092, 0.1874, 0.1784, 0.2214, 0.2127, 0.1910], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,693][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0038, 0.0705, 0.0225, 0.0094, 0.6730, 0.2208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,693][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4257, 0.2531, 0.0585, 0.0762, 0.0390, 0.1475], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,694][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0240, 0.1883, 0.1951, 0.2345, 0.2284, 0.1298], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,694][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0529, 0.1035, 0.1551, 0.2101, 0.1579, 0.3204], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,698][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0058, 0.5005, 0.0633, 0.2163, 0.1180, 0.0961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,698][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0688, 0.0463, 0.2139, 0.0399, 0.1964, 0.4323, 0.0023],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,699][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0003, 0.1848, 0.1419, 0.2260, 0.1882, 0.1460, 0.1128],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,699][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0205, 0.1354, 0.1504, 0.1523, 0.2051, 0.1454, 0.1910],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,699][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0053, 0.1867, 0.1461, 0.2020, 0.1927, 0.1334, 0.1337],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,700][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0191, 0.0028, 0.0222, 0.0332, 0.0034, 0.8376, 0.0817],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,700][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2037, 0.7073, 0.0186, 0.0208, 0.0135, 0.0184, 0.0177],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,701][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0074, 0.1581, 0.1369, 0.1840, 0.1735, 0.1706, 0.1695],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,703][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.0144e-04, 2.1571e-02, 1.2102e-02, 1.5652e-02, 4.4954e-01, 4.1679e-01,
        8.4041e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,704][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3497, 0.2212, 0.1036, 0.0801, 0.0420, 0.1532, 0.0502],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,705][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0215, 0.1841, 0.1436, 0.2026, 0.1868, 0.1193, 0.1421],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,705][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0245, 0.0806, 0.1170, 0.1807, 0.1391, 0.2590, 0.1990],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,705][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0049, 0.5215, 0.0425, 0.1644, 0.1162, 0.0800, 0.0706],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,706][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0423, 0.0603, 0.2400, 0.0424, 0.1528, 0.3970, 0.0015, 0.0637],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,706][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0003, 0.1553, 0.1196, 0.1833, 0.1595, 0.1248, 0.1121, 0.1453],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,707][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0159, 0.1106, 0.1236, 0.1274, 0.1712, 0.1235, 0.1621, 0.1656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,710][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0051, 0.1472, 0.1008, 0.2003, 0.1635, 0.1076, 0.1379, 0.1377],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,711][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0711, 0.0034, 0.0309, 0.0213, 0.0040, 0.5760, 0.1095, 0.1838],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,711][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.3477, 0.5958, 0.0087, 0.0086, 0.0062, 0.0057, 0.0100, 0.0172],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,712][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0085, 0.1334, 0.1241, 0.1531, 0.1411, 0.1358, 0.1467, 0.1572],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,712][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([3.4883e-04, 6.1789e-05, 1.5671e-04, 5.6953e-05, 3.7146e-03, 6.6097e-03,
        2.5896e-03, 9.8646e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,712][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.6041, 0.1202, 0.0243, 0.0274, 0.0188, 0.0862, 0.0276, 0.0914],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,716][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0198, 0.1567, 0.1119, 0.1803, 0.1180, 0.0887, 0.1215, 0.2032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,716][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0348, 0.0729, 0.0943, 0.1340, 0.1064, 0.2261, 0.1659, 0.1656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,717][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0088, 0.4221, 0.0294, 0.0689, 0.0586, 0.0629, 0.0534, 0.2958],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,717][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0320, 0.0348, 0.2066, 0.0221, 0.1750, 0.3626, 0.0015, 0.0291, 0.1363],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,718][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0002, 0.1417, 0.1117, 0.1687, 0.1479, 0.1123, 0.0946, 0.1273, 0.0956],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,718][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0186, 0.1016, 0.1022, 0.1066, 0.1336, 0.0978, 0.1291, 0.1273, 0.1832],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,718][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0062, 0.1293, 0.1012, 0.1624, 0.1323, 0.0930, 0.1254, 0.1320, 0.1181],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,719][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0389, 0.0007, 0.0084, 0.0068, 0.0013, 0.1913, 0.0306, 0.1023, 0.6198],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,719][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.4169, 0.4123, 0.0234, 0.0227, 0.0190, 0.0190, 0.0233, 0.0343, 0.0289],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,723][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0075, 0.1172, 0.1031, 0.1332, 0.1137, 0.1217, 0.1158, 0.1382, 0.1497],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,723][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([4.7294e-04, 4.1533e-04, 1.7067e-04, 1.3318e-04, 3.7118e-03, 5.4510e-03,
        1.7432e-03, 8.7308e-01, 1.1482e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,724][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.4327, 0.2794, 0.0645, 0.0392, 0.0302, 0.0740, 0.0347, 0.0290, 0.0162],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,724][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0236, 0.1128, 0.1107, 0.1106, 0.1411, 0.0787, 0.0887, 0.2005, 0.1332],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,725][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0237, 0.0600, 0.0814, 0.1198, 0.0940, 0.1733, 0.1404, 0.1509, 0.1565],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,725][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0091, 0.2995, 0.0336, 0.0616, 0.0531, 0.0613, 0.0434, 0.3220, 0.1164],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,725][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0488, 0.0531, 0.1896, 0.0298, 0.1169, 0.3155, 0.0015, 0.0388, 0.0915,
        0.1145], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,729][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0002, 0.1300, 0.0979, 0.1461, 0.1307, 0.0984, 0.0878, 0.1077, 0.0894,
        0.1117], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,730][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0107, 0.0794, 0.0860, 0.0900, 0.1199, 0.0863, 0.1142, 0.1182, 0.1792,
        0.1160], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,730][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0051, 0.1136, 0.0991, 0.1258, 0.1140, 0.0956, 0.1207, 0.1023, 0.1153,
        0.1084], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,731][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0014, 0.0007, 0.0113, 0.0082, 0.0014, 0.2584, 0.0475, 0.0919, 0.5708,
        0.0084], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,731][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0573, 0.8335, 0.0129, 0.0116, 0.0086, 0.0100, 0.0117, 0.0316, 0.0159,
        0.0069], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,731][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0050, 0.1009, 0.0896, 0.1149, 0.1018, 0.1006, 0.1053, 0.1238, 0.1338,
        0.1243], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,733][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([5.9760e-05, 3.3636e-05, 4.5938e-05, 1.3602e-05, 6.3128e-04, 9.4414e-04,
        5.9947e-04, 4.3873e-01, 5.5247e-02, 5.0369e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,735][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2354, 0.2136, 0.0663, 0.0379, 0.0576, 0.1768, 0.0476, 0.0823, 0.0603,
        0.0223], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,736][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0110, 0.0973, 0.0944, 0.0925, 0.1139, 0.0822, 0.0879, 0.1580, 0.1844,
        0.0784], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,736][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0295, 0.0563, 0.0709, 0.1007, 0.0805, 0.1735, 0.1303, 0.1190, 0.1327,
        0.1067], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,736][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0036, 0.2874, 0.0139, 0.0500, 0.0420, 0.0349, 0.0380, 0.2257, 0.0943,
        0.2103], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,737][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0501, 0.0293, 0.1811, 0.0222, 0.1408, 0.2448, 0.0020, 0.0319, 0.0877,
        0.0828, 0.1272], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,737][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0002, 0.1179, 0.0888, 0.1357, 0.1156, 0.0894, 0.0792, 0.1101, 0.0838,
        0.1093, 0.0702], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,738][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0096, 0.0694, 0.0766, 0.0792, 0.1069, 0.0754, 0.0997, 0.1029, 0.1589,
        0.1004, 0.1212], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,738][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0035, 0.1101, 0.0798, 0.1381, 0.1158, 0.0718, 0.0959, 0.1119, 0.0999,
        0.0841, 0.0890], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,739][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([1.4766e-02, 1.3328e-04, 1.7241e-03, 1.7483e-03, 3.2731e-04, 4.7818e-02,
        9.8633e-03, 2.5327e-02, 1.5199e-01, 2.4398e-03, 7.4387e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,742][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.1920, 0.5238, 0.0302, 0.0322, 0.0255, 0.0347, 0.0303, 0.0507, 0.0324,
        0.0183, 0.0300], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,742][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0041, 0.0893, 0.0780, 0.1073, 0.0939, 0.0930, 0.0899, 0.1120, 0.1254,
        0.1132, 0.0938], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,743][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.9952e-03, 4.1080e-04, 1.8210e-04, 1.5118e-04, 2.1074e-03, 3.0343e-03,
        9.6209e-04, 2.0834e-01, 4.1388e-02, 6.3861e-01, 1.0283e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,743][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0497, 0.2986, 0.0770, 0.0826, 0.0709, 0.1287, 0.0668, 0.1480, 0.0319,
        0.0360, 0.0098], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,744][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0226, 0.0813, 0.0794, 0.0903, 0.1014, 0.0788, 0.0638, 0.1376, 0.1122,
        0.0871, 0.1456], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,744][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0177, 0.0472, 0.0720, 0.0969, 0.0799, 0.1472, 0.1089, 0.1085, 0.1181,
        0.0837, 0.1199], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,744][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0038, 0.2283, 0.0273, 0.0782, 0.0591, 0.0358, 0.0328, 0.2593, 0.0776,
        0.1404, 0.0574], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,748][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0375, 0.0321, 0.1328, 0.0308, 0.1193, 0.2643, 0.0030, 0.0491, 0.1072,
        0.0981, 0.1237, 0.0021], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,749][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0001, 0.0991, 0.0812, 0.1266, 0.1090, 0.0849, 0.0724, 0.1021, 0.0780,
        0.1016, 0.0695, 0.0755], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,749][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0092, 0.0637, 0.0685, 0.0727, 0.0978, 0.0691, 0.0912, 0.0929, 0.1421,
        0.0914, 0.1090, 0.0924], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,749][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0031, 0.0965, 0.0792, 0.1141, 0.0906, 0.0680, 0.0778, 0.1054, 0.0977,
        0.0942, 0.0906, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,750][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([7.7733e-03, 1.2006e-04, 1.5504e-03, 1.1262e-03, 1.6887e-04, 2.7083e-02,
        4.7071e-03, 1.2561e-02, 8.9516e-02, 1.2053e-03, 4.7027e-01, 3.8392e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,754][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3046, 0.4579, 0.0219, 0.0220, 0.0178, 0.0220, 0.0229, 0.0345, 0.0288,
        0.0162, 0.0339, 0.0176], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,754][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0045, 0.0823, 0.0775, 0.0957, 0.0848, 0.0829, 0.0836, 0.0953, 0.1084,
        0.1005, 0.0857, 0.0989], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,755][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.1773e-03, 7.8972e-04, 2.2198e-04, 2.1983e-04, 2.2378e-03, 3.8380e-03,
        6.0502e-04, 1.9996e-01, 7.2443e-02, 5.2426e-01, 1.2293e-01, 7.1317e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,755][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1948, 0.2961, 0.0801, 0.0520, 0.0315, 0.1458, 0.0313, 0.0805, 0.0280,
        0.0307, 0.0100, 0.0193], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,755][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0135, 0.0732, 0.0759, 0.0816, 0.0926, 0.0545, 0.0601, 0.1562, 0.1077,
        0.0820, 0.1222, 0.0805], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,756][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0161, 0.0411, 0.0635, 0.0821, 0.0687, 0.1242, 0.0922, 0.1028, 0.1029,
        0.0809, 0.1073, 0.1181], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,756][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0047, 0.2269, 0.0260, 0.0513, 0.0498, 0.0310, 0.0309, 0.2004, 0.0732,
        0.1478, 0.0598, 0.0982], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,760][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0366, 0.0320, 0.1159, 0.0252, 0.1141, 0.2243, 0.0012, 0.0235, 0.0818,
        0.0647, 0.1064, 0.0007, 0.1735], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,760][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0002, 0.0992, 0.0704, 0.1128, 0.0987, 0.0768, 0.0671, 0.0872, 0.0707,
        0.0858, 0.0632, 0.0689, 0.0989], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,761][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0108, 0.0558, 0.0633, 0.0635, 0.0880, 0.0621, 0.0807, 0.0833, 0.1225,
        0.0822, 0.0975, 0.0818, 0.1083], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,761][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.0028, 0.0880, 0.0736, 0.0921, 0.1026, 0.0595, 0.0803, 0.0808, 0.0900,
        0.0737, 0.0843, 0.0820, 0.0905], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,762][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ office] are: tensor([1.2042e-03, 1.1639e-04, 1.6966e-03, 1.2205e-03, 2.5215e-04, 4.5391e-02,
        8.0995e-03, 1.6313e-02, 8.0136e-02, 1.9713e-03, 4.1639e-01, 4.2079e-01,
        6.4142e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,762][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.1377, 0.7197, 0.0119, 0.0131, 0.0076, 0.0102, 0.0113, 0.0245, 0.0165,
        0.0068, 0.0135, 0.0111, 0.0162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,762][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0047, 0.0743, 0.0645, 0.0843, 0.0756, 0.0733, 0.0762, 0.0872, 0.0976,
        0.0887, 0.0801, 0.0908, 0.1027], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,765][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ office] are: tensor([8.6197e-02, 7.1636e-06, 1.4547e-06, 1.4138e-06, 1.2564e-05, 5.8611e-05,
        2.5263e-05, 2.1165e-03, 1.5310e-03, 4.3833e-03, 1.0558e-02, 7.2228e-03,
        8.8788e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,766][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.0760, 0.2359, 0.0590, 0.0551, 0.0464, 0.1711, 0.0667, 0.0727, 0.0835,
        0.0259, 0.0180, 0.0480, 0.0418], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,767][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ office] are: tensor([0.0106, 0.0915, 0.0772, 0.1049, 0.0656, 0.0428, 0.0633, 0.0783, 0.1145,
        0.0617, 0.1128, 0.0693, 0.1074], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,767][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0256, 0.0410, 0.0489, 0.0722, 0.0536, 0.1245, 0.0934, 0.0835, 0.0966,
        0.0723, 0.1071, 0.1081, 0.0733], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,768][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0138, 0.1556, 0.0121, 0.0299, 0.0264, 0.0283, 0.0222, 0.1674, 0.0980,
        0.2164, 0.0628, 0.1036, 0.0635], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:52,768][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0608, 0.0211, 0.1679, 0.0176, 0.1167, 0.1946, 0.0021, 0.0340, 0.0645,
        0.0696, 0.1010, 0.0012, 0.1320, 0.0169], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,768][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.0408e-04, 9.0976e-02, 7.2869e-02, 1.1006e-01, 9.8379e-02, 7.4182e-02,
        6.1192e-02, 8.1993e-02, 6.2404e-02, 8.2413e-02, 5.5722e-02, 6.1727e-02,
        9.3854e-02, 5.4125e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,769][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0077, 0.0517, 0.0581, 0.0598, 0.0830, 0.0565, 0.0758, 0.0774, 0.1204,
        0.0781, 0.0919, 0.0764, 0.1027, 0.0606], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,769][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0042, 0.0771, 0.0629, 0.0932, 0.0927, 0.0591, 0.0769, 0.0802, 0.0781,
        0.0725, 0.0786, 0.0767, 0.0705, 0.0771], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,771][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([1.0070e-01, 1.8323e-04, 1.0303e-03, 4.0465e-04, 9.1519e-05, 7.3566e-03,
        1.0360e-03, 4.7985e-03, 1.2239e-02, 3.7962e-04, 9.2044e-02, 8.6232e-02,
        2.1610e-03, 6.9135e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,773][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.3176, 0.4189, 0.0226, 0.0234, 0.0168, 0.0192, 0.0195, 0.0296, 0.0220,
        0.0108, 0.0241, 0.0154, 0.0240, 0.0361], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,774][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0028, 0.0697, 0.0617, 0.0834, 0.0718, 0.0689, 0.0686, 0.0771, 0.0879,
        0.0816, 0.0690, 0.0810, 0.0893, 0.0873], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,774][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([7.5122e-02, 3.8628e-03, 1.4415e-04, 3.3340e-05, 4.9997e-04, 1.7294e-04,
        6.5114e-05, 2.5673e-02, 1.7556e-03, 3.1402e-02, 7.7800e-03, 3.6552e-03,
        4.9679e-01, 3.5305e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,774][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0856, 0.3029, 0.0623, 0.0357, 0.0377, 0.1650, 0.0456, 0.0997, 0.0269,
        0.0181, 0.0069, 0.0228, 0.0267, 0.0642], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,775][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0159, 0.0740, 0.0722, 0.0687, 0.0719, 0.0569, 0.0652, 0.0851, 0.0847,
        0.0701, 0.1084, 0.0801, 0.0797, 0.0670], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,775][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0236, 0.0388, 0.0503, 0.0669, 0.0524, 0.0987, 0.0775, 0.0807, 0.0829,
        0.0632, 0.0871, 0.0944, 0.0634, 0.1200], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,779][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0113, 0.2559, 0.0250, 0.0345, 0.0338, 0.0331, 0.0251, 0.1744, 0.0364,
        0.0874, 0.0407, 0.0737, 0.0523, 0.1164], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:52,780][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0378, 0.0353, 0.1175, 0.0187, 0.1100, 0.1705, 0.0010, 0.0146, 0.0557,
        0.0604, 0.0609, 0.0005, 0.1266, 0.0202, 0.1703], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,780][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0001, 0.0826, 0.0638, 0.0959, 0.0857, 0.0678, 0.0578, 0.0777, 0.0617,
        0.0738, 0.0559, 0.0612, 0.0895, 0.0534, 0.0730], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,781][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0088, 0.0487, 0.0527, 0.0552, 0.0765, 0.0533, 0.0709, 0.0714, 0.1090,
        0.0708, 0.0831, 0.0703, 0.0946, 0.0571, 0.0774], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,781][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0026, 0.0786, 0.0573, 0.0752, 0.0870, 0.0556, 0.0618, 0.0693, 0.0782,
        0.0624, 0.0683, 0.0705, 0.0779, 0.0750, 0.0804], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,783][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([2.0576e-04, 7.3468e-05, 1.0613e-03, 7.5397e-04, 9.1331e-05, 1.6058e-02,
        3.3040e-03, 4.4954e-03, 2.8492e-02, 4.8371e-04, 1.0405e-01, 1.4525e-01,
        1.6587e-03, 6.9321e-01, 8.1159e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,785][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1084, 0.6911, 0.0123, 0.0143, 0.0085, 0.0084, 0.0100, 0.0223, 0.0161,
        0.0061, 0.0125, 0.0108, 0.0138, 0.0229, 0.0425], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,785][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0030, 0.0616, 0.0544, 0.0667, 0.0591, 0.0626, 0.0648, 0.0794, 0.0814,
        0.0783, 0.0677, 0.0807, 0.0890, 0.0761, 0.0751], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,786][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([1.1460e-04, 1.6134e-05, 3.8156e-06, 3.3594e-06, 3.1060e-05, 6.0871e-05,
        1.7639e-05, 8.4107e-03, 1.9880e-03, 1.0066e-02, 4.3444e-03, 3.7288e-03,
        6.4610e-01, 2.5290e-01, 7.2208e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,786][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0685, 0.2114, 0.0485, 0.0272, 0.0231, 0.1802, 0.0302, 0.0729, 0.0483,
        0.0213, 0.0127, 0.0164, 0.0800, 0.1444, 0.0149], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,787][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0091, 0.0778, 0.0480, 0.0635, 0.0620, 0.0380, 0.0402, 0.1129, 0.0850,
        0.0752, 0.0982, 0.0523, 0.0900, 0.0838, 0.0640], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,787][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0095, 0.0346, 0.0469, 0.0612, 0.0552, 0.1010, 0.0760, 0.0758, 0.0793,
        0.0680, 0.0876, 0.0957, 0.0651, 0.1035, 0.0404], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,788][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0020, 0.1397, 0.0176, 0.0444, 0.0340, 0.0309, 0.0292, 0.1288, 0.0760,
        0.0763, 0.0557, 0.1090, 0.0717, 0.1439, 0.0409], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:52,789][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0330, 0.0162, 0.0794, 0.0124, 0.0674, 0.2073, 0.0005, 0.0105, 0.0409,
        0.0419, 0.0655, 0.0003, 0.1049, 0.0112, 0.1169, 0.1919],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,792][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0001, 0.0802, 0.0593, 0.0974, 0.0822, 0.0599, 0.0549, 0.0687, 0.0575,
        0.0723, 0.0512, 0.0563, 0.0848, 0.0516, 0.0647, 0.0588],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,792][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0075, 0.0474, 0.0511, 0.0532, 0.0705, 0.0489, 0.0654, 0.0658, 0.1026,
        0.0655, 0.0784, 0.0661, 0.0866, 0.0528, 0.0727, 0.0656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,793][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0017, 0.0727, 0.0520, 0.0839, 0.0790, 0.0494, 0.0588, 0.0664, 0.0650,
        0.0856, 0.0711, 0.0625, 0.0723, 0.0639, 0.0652, 0.0506],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,793][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([4.5539e-02, 3.4641e-05, 3.3611e-04, 7.2810e-05, 3.2368e-05, 2.3047e-03,
        3.7022e-04, 1.7341e-03, 7.2248e-03, 2.1218e-04, 4.1744e-02, 4.4902e-02,
        7.3047e-04, 2.4972e-01, 4.3695e-04, 6.0460e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,794][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.4306, 0.4093, 0.0077, 0.0074, 0.0056, 0.0048, 0.0074, 0.0119, 0.0104,
        0.0032, 0.0078, 0.0063, 0.0083, 0.0180, 0.0307, 0.0307],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,794][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0040, 0.0572, 0.0512, 0.0648, 0.0593, 0.0573, 0.0593, 0.0703, 0.0767,
        0.0689, 0.0618, 0.0737, 0.0819, 0.0734, 0.0670, 0.0732],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,796][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([5.6236e-01, 2.5650e-05, 2.1707e-06, 6.6194e-08, 2.6058e-06, 1.0289e-06,
        1.2130e-06, 2.3296e-04, 4.3570e-05, 2.1824e-04, 1.6807e-04, 1.2064e-04,
        1.5746e-02, 8.4851e-03, 3.9273e-03, 4.0867e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,798][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0677, 0.1865, 0.0320, 0.0508, 0.0482, 0.1569, 0.0443, 0.0634, 0.0500,
        0.0184, 0.0111, 0.0326, 0.0702, 0.1244, 0.0210, 0.0225],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,799][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0102, 0.0546, 0.0444, 0.0771, 0.0710, 0.0332, 0.0373, 0.1110, 0.0739,
        0.0757, 0.0789, 0.0512, 0.0865, 0.0640, 0.0671, 0.0637],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,799][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0119, 0.0318, 0.0468, 0.0565, 0.0498, 0.0882, 0.0648, 0.0722, 0.0728,
        0.0623, 0.0776, 0.0806, 0.0653, 0.1037, 0.0354, 0.0804],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,799][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0088, 0.1604, 0.0137, 0.0295, 0.0228, 0.0148, 0.0176, 0.1664, 0.0452,
        0.0998, 0.0487, 0.0651, 0.0754, 0.1259, 0.0261, 0.0798],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:52,800][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0276, 0.0216, 0.0952, 0.0198, 0.0787, 0.1991, 0.0013, 0.0216, 0.0566,
        0.0484, 0.0686, 0.0008, 0.1065, 0.0144, 0.0966, 0.1422, 0.0012],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,800][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0001, 0.0700, 0.0565, 0.0927, 0.0760, 0.0594, 0.0483, 0.0689, 0.0557,
        0.0699, 0.0483, 0.0535, 0.0774, 0.0491, 0.0635, 0.0616, 0.0491],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,804][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0076, 0.0448, 0.0473, 0.0502, 0.0661, 0.0469, 0.0626, 0.0627, 0.0960,
        0.0615, 0.0737, 0.0625, 0.0799, 0.0498, 0.0670, 0.0616, 0.0599],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,805][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0025, 0.0667, 0.0504, 0.0731, 0.0679, 0.0486, 0.0520, 0.0758, 0.0674,
        0.0738, 0.0626, 0.0625, 0.0585, 0.0654, 0.0621, 0.0580, 0.0527],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,805][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.5955e-02, 1.6864e-05, 1.2912e-04, 5.8549e-05, 1.3097e-05, 1.2346e-03,
        1.4145e-04, 6.5280e-04, 2.3966e-03, 5.6917e-05, 1.4479e-02, 1.4436e-02,
        3.0721e-04, 1.7442e-01, 1.1693e-04, 4.5513e-01, 3.2046e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,806][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7162, 0.1273, 0.0049, 0.0050, 0.0037, 0.0037, 0.0050, 0.0059, 0.0070,
        0.0027, 0.0080, 0.0047, 0.0060, 0.0155, 0.0256, 0.0264, 0.0325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,806][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0024, 0.0549, 0.0487, 0.0643, 0.0567, 0.0573, 0.0558, 0.0636, 0.0704,
        0.0667, 0.0563, 0.0654, 0.0742, 0.0693, 0.0642, 0.0681, 0.0617],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,806][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([6.3560e-02, 2.1420e-04, 1.2047e-05, 2.6700e-06, 1.6917e-05, 9.1134e-06,
        2.6568e-06, 3.5078e-04, 9.3743e-05, 4.7676e-04, 1.8495e-04, 2.0344e-04,
        1.1101e-02, 2.2007e-02, 7.3649e-03, 8.8030e-01, 1.4102e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,811][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1047, 0.1804, 0.0730, 0.0524, 0.0292, 0.1223, 0.0362, 0.1031, 0.0321,
        0.0315, 0.0132, 0.0263, 0.0328, 0.0882, 0.0142, 0.0402, 0.0202],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,813][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0088, 0.0541, 0.0461, 0.0609, 0.0564, 0.0333, 0.0431, 0.1050, 0.0783,
        0.0495, 0.0911, 0.0504, 0.0758, 0.0670, 0.0542, 0.0736, 0.0525],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,814][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0075, 0.0300, 0.0415, 0.0598, 0.0484, 0.0837, 0.0638, 0.0721, 0.0676,
        0.0555, 0.0683, 0.0772, 0.0616, 0.1030, 0.0343, 0.0732, 0.0525],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,814][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0138, 0.1480, 0.0151, 0.0290, 0.0268, 0.0191, 0.0205, 0.1306, 0.0456,
        0.0689, 0.0371, 0.0706, 0.0456, 0.0944, 0.0265, 0.0866, 0.1217],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:52,815][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0271, 0.0245, 0.0984, 0.0132, 0.0783, 0.1360, 0.0005, 0.0108, 0.0455,
        0.0590, 0.0638, 0.0003, 0.1038, 0.0149, 0.1281, 0.1286, 0.0005, 0.0667],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,815][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0001, 0.0711, 0.0537, 0.0864, 0.0724, 0.0546, 0.0478, 0.0621, 0.0509,
        0.0621, 0.0454, 0.0502, 0.0734, 0.0451, 0.0589, 0.0573, 0.0481, 0.0604],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,816][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0068, 0.0396, 0.0434, 0.0449, 0.0621, 0.0437, 0.0580, 0.0588, 0.0888,
        0.0575, 0.0686, 0.0583, 0.0760, 0.0453, 0.0629, 0.0574, 0.0538, 0.0741],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,819][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0019, 0.0539, 0.0474, 0.0569, 0.0801, 0.0422, 0.0536, 0.0599, 0.0604,
        0.0698, 0.0580, 0.0510, 0.0653, 0.0530, 0.0691, 0.0556, 0.0502, 0.0718],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,820][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([4.4300e-04, 2.5784e-05, 2.7544e-04, 9.2215e-05, 2.4764e-05, 2.2449e-03,
        4.0734e-04, 1.2611e-03, 4.4650e-03, 1.5785e-04, 1.8112e-02, 2.3504e-02,
        5.2188e-04, 9.4531e-02, 2.2355e-04, 4.6126e-01, 3.9062e-01, 1.8301e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,820][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.3642, 0.3816, 0.0061, 0.0069, 0.0040, 0.0041, 0.0062, 0.0106, 0.0107,
        0.0033, 0.0086, 0.0063, 0.0076, 0.0180, 0.0293, 0.0358, 0.0424, 0.0542],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,821][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0025, 0.0515, 0.0459, 0.0583, 0.0534, 0.0524, 0.0511, 0.0595, 0.0671,
        0.0596, 0.0539, 0.0625, 0.0689, 0.0619, 0.0606, 0.0632, 0.0564, 0.0714],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,821][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([1.1349e-02, 1.4393e-04, 1.3135e-05, 1.8255e-06, 2.7945e-05, 2.2293e-05,
        7.4223e-06, 1.4266e-03, 1.5028e-04, 1.7576e-03, 4.0225e-04, 2.3761e-04,
        1.5594e-02, 1.6222e-02, 1.3186e-02, 9.2308e-01, 1.0090e-02, 6.2923e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,822][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1446, 0.1509, 0.0435, 0.0491, 0.0327, 0.1206, 0.0599, 0.0276, 0.0452,
        0.0155, 0.0122, 0.0283, 0.0350, 0.1035, 0.0202, 0.0341, 0.0444, 0.0330],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,822][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0071, 0.0548, 0.0406, 0.0749, 0.0468, 0.0364, 0.0441, 0.0641, 0.0803,
        0.0332, 0.1149, 0.0570, 0.0873, 0.0528, 0.0435, 0.0619, 0.0541, 0.0463],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,826][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0165, 0.0326, 0.0395, 0.0518, 0.0420, 0.0839, 0.0636, 0.0701, 0.0657,
        0.0583, 0.0730, 0.0743, 0.0533, 0.0855, 0.0293, 0.0702, 0.0470, 0.0433],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,827][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0071, 0.1695, 0.0088, 0.0312, 0.0159, 0.0151, 0.0165, 0.0802, 0.0414,
        0.0750, 0.0312, 0.0585, 0.0335, 0.0756, 0.0172, 0.0815, 0.0957, 0.1460],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:52,827][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0210, 0.0243, 0.1183, 0.0159, 0.0759, 0.1459, 0.0019, 0.0200, 0.0779,
        0.0449, 0.0637, 0.0011, 0.0849, 0.0154, 0.0784, 0.1358, 0.0016, 0.0498,
        0.0233], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,828][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0001, 0.0656, 0.0518, 0.0804, 0.0727, 0.0528, 0.0455, 0.0617, 0.0489,
        0.0616, 0.0421, 0.0469, 0.0740, 0.0427, 0.0579, 0.0528, 0.0455, 0.0589,
        0.0382], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,828][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0102, 0.0445, 0.0440, 0.0469, 0.0571, 0.0425, 0.0558, 0.0540, 0.0756,
        0.0530, 0.0619, 0.0541, 0.0652, 0.0435, 0.0585, 0.0536, 0.0515, 0.0640,
        0.0642], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,829][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0032, 0.0557, 0.0469, 0.0684, 0.0631, 0.0418, 0.0575, 0.0629, 0.0602,
        0.0575, 0.0587, 0.0557, 0.0539, 0.0573, 0.0553, 0.0409, 0.0539, 0.0516,
        0.0556], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,831][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.3127e-02, 2.1453e-05, 1.6739e-04, 5.3978e-05, 1.3514e-05, 6.4796e-04,
        1.7766e-04, 6.5210e-04, 1.7550e-03, 6.1572e-05, 1.2835e-02, 1.2957e-02,
        3.0017e-04, 1.5034e-01, 1.2703e-04, 2.4785e-01, 3.1333e-01, 1.4904e-03,
        2.3409e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,833][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6556, 0.0763, 0.0055, 0.0059, 0.0041, 0.0045, 0.0060, 0.0059, 0.0082,
        0.0032, 0.0105, 0.0055, 0.0064, 0.0167, 0.0234, 0.0245, 0.0327, 0.0435,
        0.0617], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,833][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0023, 0.0497, 0.0443, 0.0578, 0.0499, 0.0496, 0.0488, 0.0565, 0.0639,
        0.0573, 0.0486, 0.0575, 0.0635, 0.0614, 0.0548, 0.0602, 0.0547, 0.0660,
        0.0531], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,833][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.3025e-01, 1.7758e-03, 2.8637e-05, 3.4021e-06, 1.8979e-05, 5.8367e-06,
        3.1355e-06, 2.7599e-04, 3.1830e-05, 2.4254e-04, 7.1438e-05, 9.7015e-05,
        1.8428e-03, 1.3302e-02, 4.0351e-03, 2.2048e-01, 7.0013e-03, 6.9439e-03,
        1.3599e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,834][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1530, 0.1999, 0.0810, 0.0479, 0.0469, 0.0946, 0.0370, 0.0436, 0.0237,
        0.0245, 0.0109, 0.0274, 0.0298, 0.0686, 0.0198, 0.0270, 0.0230, 0.0269,
        0.0145], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,834][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0110, 0.0482, 0.0535, 0.0512, 0.0596, 0.0313, 0.0432, 0.0649, 0.0713,
        0.0523, 0.0740, 0.0557, 0.0701, 0.0526, 0.0560, 0.0624, 0.0539, 0.0352,
        0.0536], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,835][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0102, 0.0299, 0.0403, 0.0540, 0.0449, 0.0748, 0.0572, 0.0654, 0.0621,
        0.0529, 0.0639, 0.0696, 0.0556, 0.0847, 0.0331, 0.0672, 0.0455, 0.0428,
        0.0458], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,839][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0127, 0.1293, 0.0113, 0.0198, 0.0172, 0.0153, 0.0164, 0.1347, 0.0319,
        0.0532, 0.0218, 0.0444, 0.0258, 0.0531, 0.0132, 0.0804, 0.0871, 0.1714,
        0.0609], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:52,891][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:52,891][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,892][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,892][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,893][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,893][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,894][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,894][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,894][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,895][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,895][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,895][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,896][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:52,896][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9974, 0.0026], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,896][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5886, 0.4114], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,897][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9658, 0.0342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,897][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9901, 0.0099], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,897][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0217, 0.9783], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,898][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6492, 0.3508], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,898][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9986, 0.0014], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,898][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0726, 0.9274], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,899][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9784, 0.0216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,899][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,899][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7989, 0.2011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,899][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0848, 0.9152], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:52,902][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.9720, 0.0107, 0.0172], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,903][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0209, 0.4874, 0.4917], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,903][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.5477, 0.1367, 0.3156], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,904][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.8490, 0.0604, 0.0906], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,904][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0044, 0.3525, 0.6431], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,904][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.2863, 0.3884, 0.3253], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,905][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.9517, 0.0263, 0.0221], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,905][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.0205, 0.7751, 0.2044], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,905][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.7705, 0.1026, 0.1269], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,907][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.7398, 0.1318, 0.1285], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,910][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.3256, 0.4984, 0.1759], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,910][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0092, 0.9473, 0.0435], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:52,910][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9648, 0.0021, 0.0057, 0.0273], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,911][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0814, 0.2090, 0.5892, 0.1204], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,911][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6466, 0.0579, 0.2764, 0.0191], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,911][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9546, 0.0094, 0.0292, 0.0068], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,912][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0039, 0.2560, 0.6687, 0.0714], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,912][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3063, 0.2766, 0.3546, 0.0626], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,916][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9842, 0.0041, 0.0097, 0.0020], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,916][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0620, 0.5228, 0.3719, 0.0433], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,917][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8643, 0.0336, 0.0959, 0.0062], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,917][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9206, 0.0361, 0.0390, 0.0042], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,917][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5513, 0.2650, 0.1387, 0.0450], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,918][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0154, 0.7785, 0.0603, 0.1457], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:52,918][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.9031, 0.0070, 0.0169, 0.0690, 0.0041], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,919][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0261, 0.1824, 0.4288, 0.1689, 0.1938], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,922][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.4104, 0.0962, 0.3441, 0.0351, 0.1143], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,923][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.8355, 0.0288, 0.0490, 0.0259, 0.0608], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,923][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0078, 0.1569, 0.4522, 0.0955, 0.2876], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,923][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.2955, 0.1590, 0.2221, 0.0662, 0.2572], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,924][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.9482, 0.0144, 0.0189, 0.0068, 0.0118], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,924][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0422, 0.3098, 0.1489, 0.0790, 0.4201], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,924][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.7094, 0.0622, 0.1709, 0.0156, 0.0419], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,925][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.8637, 0.0622, 0.0545, 0.0092, 0.0105], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,929][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.4123, 0.2781, 0.1013, 0.0490, 0.1593], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,929][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0070, 0.6976, 0.0475, 0.1410, 0.1068], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:52,929][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8839, 0.0052, 0.0179, 0.0866, 0.0039, 0.0024], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,930][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0352, 0.1072, 0.3592, 0.1691, 0.2361, 0.0932], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,930][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2573, 0.0827, 0.4486, 0.0348, 0.1125, 0.0641], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,930][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6018, 0.0537, 0.1223, 0.0394, 0.0920, 0.0909], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,931][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0061, 0.1112, 0.2708, 0.0567, 0.2944, 0.2607], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,931][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1254, 0.0817, 0.2006, 0.0320, 0.1982, 0.3621], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,935][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.8371, 0.0250, 0.0838, 0.0115, 0.0300, 0.0126], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,935][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0353, 0.1767, 0.1369, 0.0193, 0.3795, 0.2522], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,935][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.6234, 0.1041, 0.1774, 0.0186, 0.0528, 0.0237], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,936][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.7299, 0.0920, 0.1181, 0.0197, 0.0226, 0.0177], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,936][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3373, 0.2168, 0.1568, 0.0522, 0.1095, 0.1274], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,937][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0058, 0.5005, 0.0633, 0.2163, 0.1180, 0.0961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:52,937][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.3534e-01, 8.7678e-04, 1.5896e-03, 1.0251e-02, 6.2751e-04, 3.3773e-04,
        8.5097e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,937][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0070, 0.0529, 0.2844, 0.2170, 0.0994, 0.2657, 0.0735],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,941][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2063, 0.0789, 0.4072, 0.0364, 0.1030, 0.0858, 0.0824],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,941][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5672, 0.0457, 0.0842, 0.0409, 0.0838, 0.0726, 0.1055],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,942][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0019, 0.0828, 0.1943, 0.0675, 0.2617, 0.3618, 0.0300],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,942][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0295, 0.0388, 0.1182, 0.0425, 0.1907, 0.5121, 0.0682],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,942][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9319, 0.0083, 0.0134, 0.0041, 0.0066, 0.0152, 0.0204],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,943][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0031, 0.0676, 0.0898, 0.0307, 0.2814, 0.4262, 0.1013],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,943][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7458, 0.0667, 0.1130, 0.0113, 0.0314, 0.0165, 0.0153],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,944][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8533, 0.0403, 0.0495, 0.0105, 0.0116, 0.0148, 0.0199],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,947][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2154, 0.2407, 0.1044, 0.0651, 0.1119, 0.1368, 0.1256],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,948][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0049, 0.5215, 0.0425, 0.1644, 0.1162, 0.0800, 0.0706],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:52,948][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([1.7828e-01, 1.4087e-03, 1.8987e-03, 1.0297e-02, 6.3593e-04, 3.5760e-04,
        8.0590e-01, 1.2210e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,948][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0281, 0.0822, 0.1676, 0.0920, 0.0579, 0.1502, 0.2030, 0.2190],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,949][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1933, 0.0593, 0.2725, 0.0385, 0.1174, 0.0844, 0.1186, 0.1160],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,949][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.4714, 0.0399, 0.0710, 0.0289, 0.0870, 0.0709, 0.0629, 0.1680],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,950][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0093, 0.0442, 0.0990, 0.0132, 0.0742, 0.0832, 0.0189, 0.6580],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,953][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0894, 0.0297, 0.0654, 0.0128, 0.0824, 0.1593, 0.0460, 0.5150],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,954][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.9001, 0.0124, 0.0255, 0.0054, 0.0089, 0.0091, 0.0271, 0.0115],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,954][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0098, 0.0107, 0.0231, 0.0026, 0.0398, 0.0530, 0.0223, 0.8388],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,955][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.7486, 0.0707, 0.0905, 0.0075, 0.0215, 0.0153, 0.0159, 0.0299],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,955][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.8287, 0.0525, 0.0401, 0.0089, 0.0107, 0.0122, 0.0153, 0.0316],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,955][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2719, 0.1808, 0.0699, 0.0338, 0.0667, 0.0924, 0.0777, 0.2068],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,956][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0088, 0.4221, 0.0294, 0.0689, 0.0586, 0.0629, 0.0534, 0.2958],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:52,957][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([1.8691e-01, 6.9278e-04, 2.3187e-03, 7.9019e-03, 6.0338e-04, 2.6350e-04,
        7.9876e-01, 8.8062e-04, 1.6654e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,960][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0409, 0.0285, 0.2710, 0.0804, 0.0676, 0.1586, 0.0962, 0.1840, 0.0728],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,960][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3202, 0.0494, 0.2458, 0.0238, 0.0667, 0.0561, 0.0851, 0.0745, 0.0783],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,961][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.3849, 0.0335, 0.0553, 0.0305, 0.0652, 0.0537, 0.0601, 0.2258, 0.0911],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,961][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0024, 0.0096, 0.0469, 0.0083, 0.0571, 0.0630, 0.0106, 0.6440, 0.1580],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,961][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0456, 0.0094, 0.0237, 0.0066, 0.0317, 0.1097, 0.0314, 0.4301, 0.3118],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,962][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.9496, 0.0032, 0.0066, 0.0015, 0.0025, 0.0076, 0.0086, 0.0090, 0.0113],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,962][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0062, 0.0041, 0.0060, 0.0010, 0.0134, 0.0258, 0.0095, 0.7546, 0.1792],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,966][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.8141, 0.0365, 0.0776, 0.0038, 0.0182, 0.0075, 0.0076, 0.0247, 0.0100],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,966][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.8888, 0.0236, 0.0339, 0.0049, 0.0055, 0.0064, 0.0082, 0.0169, 0.0118],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,967][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.3765, 0.1139, 0.0613, 0.0249, 0.0592, 0.0610, 0.0554, 0.1596, 0.0882],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,967][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0091, 0.2995, 0.0336, 0.0616, 0.0531, 0.0613, 0.0434, 0.3220, 0.1164],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:52,967][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([1.5904e-01, 1.6437e-03, 3.0125e-03, 1.0814e-02, 7.8390e-04, 3.6574e-04,
        8.1796e-01, 2.2064e-03, 2.6123e-03, 1.5626e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,968][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0040, 0.0596, 0.2126, 0.0709, 0.0836, 0.0993, 0.1389, 0.1257, 0.1352,
        0.0700], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,972][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1026, 0.0619, 0.2295, 0.0288, 0.0808, 0.0875, 0.0966, 0.1254, 0.0931,
        0.0937], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,972][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.2865, 0.0365, 0.0854, 0.0296, 0.0768, 0.0674, 0.0806, 0.1628, 0.0902,
        0.0845], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,972][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0022, 0.0101, 0.0390, 0.0050, 0.0244, 0.0335, 0.0095, 0.4180, 0.1021,
        0.3562], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,973][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0349, 0.0123, 0.0164, 0.0028, 0.0218, 0.0441, 0.0156, 0.2379, 0.2656,
        0.3485], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,973][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.5820, 0.0344, 0.0555, 0.0165, 0.0217, 0.0275, 0.0607, 0.0466, 0.0999,
        0.0552], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,974][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([1.4483e-03, 2.1004e-03, 3.7445e-03, 3.9324e-04, 4.7135e-03, 7.5840e-03,
        4.6523e-03, 3.0525e-01, 9.0188e-02, 5.7993e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,974][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.6125, 0.0923, 0.1116, 0.0100, 0.0294, 0.0176, 0.0192, 0.0511, 0.0354,
        0.0209], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,974][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.8078, 0.0442, 0.0466, 0.0053, 0.0093, 0.0085, 0.0120, 0.0276, 0.0190,
        0.0198], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,975][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1917, 0.1306, 0.0579, 0.0236, 0.0601, 0.0606, 0.0531, 0.1568, 0.0777,
        0.1878], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,979][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0036, 0.2874, 0.0139, 0.0500, 0.0420, 0.0349, 0.0380, 0.2257, 0.0943,
        0.2103], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:52,979][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([1.1149e-01, 5.5945e-04, 2.2246e-03, 6.2135e-03, 3.0574e-04, 1.8823e-04,
        8.7470e-01, 1.1651e-03, 1.3296e-03, 8.2712e-04, 1.0008e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,979][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0236, 0.0300, 0.1841, 0.0555, 0.0479, 0.0942, 0.0947, 0.2692, 0.0997,
        0.0797, 0.0213], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,980][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1599, 0.0380, 0.1850, 0.0240, 0.0616, 0.0887, 0.0865, 0.1086, 0.0950,
        0.0604, 0.0924], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,980][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1801, 0.0369, 0.0677, 0.0443, 0.0791, 0.0870, 0.0722, 0.1793, 0.1228,
        0.0897, 0.0410], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,981][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0019, 0.0046, 0.0287, 0.0048, 0.0384, 0.0426, 0.0080, 0.3159, 0.0809,
        0.3872, 0.0869], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,981][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0212, 0.0069, 0.0222, 0.0058, 0.0260, 0.0771, 0.0172, 0.2390, 0.1696,
        0.2999, 0.1150], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,985][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.7648, 0.0099, 0.0252, 0.0069, 0.0192, 0.0173, 0.0239, 0.0328, 0.0418,
        0.0281, 0.0300], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,985][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([5.1296e-03, 1.6480e-03, 2.8584e-03, 5.3535e-04, 4.9850e-03, 9.9038e-03,
        3.6096e-03, 1.9680e-01, 5.2823e-02, 6.3970e-01, 8.2005e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,986][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.3883, 0.1161, 0.1399, 0.0155, 0.0601, 0.0242, 0.0245, 0.0670, 0.0778,
        0.0296, 0.0570], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,986][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.7741, 0.0346, 0.0525, 0.0083, 0.0095, 0.0117, 0.0126, 0.0273, 0.0206,
        0.0230, 0.0257], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,986][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1609, 0.0863, 0.0733, 0.0257, 0.0591, 0.0690, 0.0488, 0.1226, 0.0762,
        0.1601, 0.1182], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,987][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0038, 0.2283, 0.0273, 0.0782, 0.0591, 0.0358, 0.0328, 0.2593, 0.0776,
        0.1404, 0.0574], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:52,987][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.6903e-01, 4.8588e-04, 1.5127e-03, 6.3470e-03, 4.4154e-04, 2.2736e-04,
        6.9703e-01, 1.0994e-03, 1.2965e-03, 9.2566e-04, 8.3039e-04, 1.2077e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,991][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0118, 0.0208, 0.1391, 0.0522, 0.0405, 0.0889, 0.0894, 0.1943, 0.1148,
        0.0882, 0.0621, 0.0979], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,992][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2705, 0.0340, 0.1395, 0.0180, 0.0537, 0.0506, 0.0563, 0.0690, 0.0562,
        0.0492, 0.0649, 0.1381], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,992][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2195, 0.0207, 0.0493, 0.0280, 0.0526, 0.0429, 0.0477, 0.2294, 0.0857,
        0.0716, 0.0444, 0.1082], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,992][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0022, 0.0055, 0.0254, 0.0038, 0.0175, 0.0251, 0.0045, 0.2390, 0.0613,
        0.2894, 0.0677, 0.2587], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,993][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0495, 0.0045, 0.0124, 0.0028, 0.0147, 0.0415, 0.0099, 0.1379, 0.1479,
        0.2078, 0.1341, 0.2370], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,993][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8678, 0.0065, 0.0197, 0.0032, 0.0077, 0.0065, 0.0125, 0.0100, 0.0198,
        0.0128, 0.0175, 0.0159], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,994][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([4.5751e-03, 1.2638e-03, 1.8405e-03, 3.0584e-04, 2.9324e-03, 7.1569e-03,
        1.6792e-03, 1.7511e-01, 7.3985e-02, 4.4168e-01, 8.8636e-02, 2.0083e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,997][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6520, 0.0457, 0.0807, 0.0062, 0.0228, 0.0093, 0.0082, 0.0325, 0.0201,
        0.0137, 0.0323, 0.0765], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,998][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8497, 0.0187, 0.0289, 0.0047, 0.0051, 0.0061, 0.0082, 0.0173, 0.0113,
        0.0113, 0.0150, 0.0238], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,998][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2135, 0.0692, 0.0522, 0.0160, 0.0369, 0.0389, 0.0299, 0.1017, 0.0475,
        0.1238, 0.0891, 0.1813], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,999][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0047, 0.2269, 0.0260, 0.0513, 0.0498, 0.0310, 0.0309, 0.2004, 0.0732,
        0.1478, 0.0598, 0.0982], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:52,999][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([1.9767e-01, 4.8259e-04, 1.2957e-03, 5.2918e-03, 3.3542e-04, 1.6865e-04,
        6.4984e-01, 1.1360e-03, 1.4349e-03, 6.7383e-04, 7.5658e-04, 1.4022e-01,
        6.8759e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,003][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0045, 0.0436, 0.1016, 0.0577, 0.0478, 0.0700, 0.0883, 0.1412, 0.1309,
        0.0529, 0.0591, 0.1172, 0.0854], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,003][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.2559, 0.0170, 0.1268, 0.0103, 0.0601, 0.0525, 0.0417, 0.0546, 0.0464,
        0.0372, 0.0756, 0.1091, 0.1127], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,004][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.2647, 0.0185, 0.0269, 0.0176, 0.0361, 0.0317, 0.0490, 0.1662, 0.0985,
        0.0677, 0.0467, 0.1081, 0.0684], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,004][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0040, 0.0014, 0.0048, 0.0008, 0.0033, 0.0091, 0.0020, 0.0947, 0.0199,
        0.1007, 0.0360, 0.1316, 0.5917], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,005][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0568, 0.0022, 0.0055, 0.0014, 0.0047, 0.0199, 0.0048, 0.0636, 0.0772,
        0.0924, 0.0623, 0.1663, 0.4430], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,005][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.6383, 0.0144, 0.0228, 0.0076, 0.0177, 0.0139, 0.0303, 0.0219, 0.0482,
        0.0268, 0.0520, 0.0448, 0.0614], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,006][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([5.2103e-03, 2.5660e-04, 3.4519e-04, 8.3995e-05, 6.8895e-04, 2.5177e-03,
        9.3203e-04, 5.2667e-02, 2.0452e-02, 1.4998e-01, 5.0529e-02, 8.9751e-02,
        6.2658e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,006][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.7088, 0.0235, 0.0354, 0.0031, 0.0098, 0.0069, 0.0082, 0.0166, 0.0120,
        0.0083, 0.0310, 0.0756, 0.0608], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,011][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([0.8708, 0.0153, 0.0183, 0.0030, 0.0048, 0.0040, 0.0065, 0.0096, 0.0082,
        0.0092, 0.0107, 0.0160, 0.0235], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,013][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.2438, 0.0414, 0.0219, 0.0111, 0.0210, 0.0301, 0.0258, 0.0616, 0.0377,
        0.0978, 0.0749, 0.1283, 0.2047], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,013][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.0138, 0.1556, 0.0121, 0.0299, 0.0264, 0.0283, 0.0222, 0.1674, 0.0980,
        0.2164, 0.0628, 0.1036, 0.0635], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,014][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([2.7685e-01, 5.5755e-04, 1.8991e-03, 7.0905e-03, 4.8753e-04, 2.4832e-04,
        5.7674e-01, 1.0041e-03, 1.1896e-03, 8.2181e-04, 7.3615e-04, 1.2566e-01,
        5.5778e-04, 6.1596e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,014][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0070, 0.0275, 0.1856, 0.0440, 0.0583, 0.1078, 0.0646, 0.1269, 0.0737,
        0.0683, 0.0378, 0.0806, 0.0786, 0.0394], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,014][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2858, 0.0237, 0.1070, 0.0187, 0.0470, 0.0505, 0.0395, 0.0362, 0.0290,
        0.0334, 0.0594, 0.0858, 0.0796, 0.1044], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,015][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.5886, 0.0122, 0.0347, 0.0115, 0.0279, 0.0235, 0.0229, 0.0763, 0.0294,
        0.0281, 0.0165, 0.0512, 0.0375, 0.0395], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,015][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.4898e-02, 9.0860e-03, 9.8328e-03, 6.9209e-04, 3.4556e-03, 3.5083e-03,
        5.4345e-04, 4.3840e-02, 4.7927e-03, 2.8408e-02, 8.1797e-03, 3.2866e-02,
        2.0850e-01, 6.3140e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,017][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.9394e-01, 5.2832e-03, 3.5972e-03, 4.2025e-04, 1.8325e-03, 5.1517e-03,
        1.3837e-03, 2.2304e-02, 1.0437e-02, 2.3699e-02, 1.4219e-02, 3.2911e-02,
        7.1779e-02, 6.1304e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,019][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6563, 0.0161, 0.0303, 0.0105, 0.0192, 0.0162, 0.0252, 0.0154, 0.0363,
        0.0239, 0.0329, 0.0333, 0.0358, 0.0485], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,020][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.4527e-01, 3.8655e-03, 6.4921e-04, 4.8230e-05, 5.7545e-04, 3.7526e-04,
        1.9200e-04, 2.0294e-02, 2.3160e-03, 3.1638e-02, 5.8724e-03, 1.2882e-02,
        9.1188e-02, 6.8483e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,020][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.8066, 0.0264, 0.0434, 0.0021, 0.0079, 0.0037, 0.0025, 0.0081, 0.0034,
        0.0027, 0.0090, 0.0229, 0.0267, 0.0346], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,020][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.9112, 0.0108, 0.0165, 0.0021, 0.0020, 0.0028, 0.0037, 0.0063, 0.0035,
        0.0044, 0.0060, 0.0096, 0.0118, 0.0094], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,021][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.3242, 0.0523, 0.0323, 0.0073, 0.0206, 0.0139, 0.0133, 0.0489, 0.0163,
        0.0517, 0.0342, 0.0737, 0.0799, 0.2313], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,021][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0113, 0.2559, 0.0250, 0.0345, 0.0338, 0.0331, 0.0251, 0.1744, 0.0364,
        0.0874, 0.0407, 0.0737, 0.0523, 0.1164], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,022][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([1.1001e-01, 8.1506e-04, 1.5244e-03, 6.1991e-03, 4.3534e-04, 2.0510e-04,
        7.4639e-01, 6.5831e-04, 1.2953e-03, 9.0231e-04, 9.4619e-04, 1.1749e-01,
        7.1116e-04, 9.9861e-03, 2.4292e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,022][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0030, 0.0310, 0.1399, 0.0488, 0.0351, 0.0811, 0.0700, 0.1096, 0.0928,
        0.0364, 0.0495, 0.0911, 0.0930, 0.0296, 0.0892], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,026][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0681, 0.0201, 0.0953, 0.0143, 0.0495, 0.0483, 0.0452, 0.0442, 0.0318,
        0.0304, 0.0363, 0.0764, 0.0808, 0.0959, 0.2634], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,026][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.2029, 0.0181, 0.0346, 0.0188, 0.0489, 0.0335, 0.0350, 0.1391, 0.0780,
        0.0478, 0.0303, 0.0954, 0.0708, 0.0701, 0.0768], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,027][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([3.8337e-04, 8.2116e-04, 4.4610e-03, 4.0522e-04, 1.5848e-03, 2.7282e-03,
        6.0169e-04, 2.2487e-02, 4.8936e-03, 1.7414e-02, 5.6251e-03, 2.9253e-02,
        1.1496e-01, 7.4696e-01, 4.7425e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,027][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([7.7251e-03, 7.7761e-04, 1.5704e-03, 2.8212e-04, 1.1356e-03, 2.7425e-03,
        8.9097e-04, 1.4216e-02, 1.4622e-02, 1.5209e-02, 1.1762e-02, 3.6345e-02,
        8.4224e-02, 7.6685e-01, 4.1650e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,028][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.4735, 0.0180, 0.0290, 0.0085, 0.0156, 0.0150, 0.0363, 0.0300, 0.0485,
        0.0285, 0.0418, 0.0553, 0.0679, 0.0445, 0.0876], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,028][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([2.0453e-04, 1.0171e-04, 6.9632e-05, 2.1453e-05, 1.1196e-04, 2.6897e-04,
        7.4967e-05, 6.3246e-03, 2.5469e-03, 1.4891e-02, 3.3849e-03, 1.3410e-02,
        7.6826e-02, 8.6631e-01, 1.5457e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,032][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.2052, 0.0366, 0.0912, 0.0093, 0.0243, 0.0151, 0.0139, 0.0270, 0.0260,
        0.0130, 0.0475, 0.1584, 0.1204, 0.1558, 0.0563], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,032][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.6800, 0.0310, 0.0448, 0.0053, 0.0071, 0.0057, 0.0105, 0.0184, 0.0143,
        0.0126, 0.0228, 0.0334, 0.0520, 0.0335, 0.0287], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,033][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0885, 0.0420, 0.0211, 0.0082, 0.0262, 0.0160, 0.0161, 0.0429, 0.0246,
        0.0729, 0.0478, 0.1067, 0.1335, 0.2764, 0.0771], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,033][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0020, 0.1397, 0.0176, 0.0444, 0.0340, 0.0309, 0.0292, 0.1288, 0.0760,
        0.0763, 0.0557, 0.1090, 0.0717, 0.1439, 0.0409], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,034][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.5402e-01, 6.8306e-04, 2.7170e-03, 6.6323e-03, 5.7247e-04, 2.2102e-04,
        6.8244e-01, 1.5416e-03, 1.8223e-03, 9.2077e-04, 1.0427e-03, 1.3348e-01,
        1.1273e-03, 8.8349e-03, 2.5950e-03, 1.3419e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,034][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0063, 0.0346, 0.1054, 0.0722, 0.0405, 0.0369, 0.0597, 0.0778, 0.0878,
        0.0476, 0.0517, 0.1275, 0.1088, 0.0625, 0.0519, 0.0289],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,038][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1684, 0.0203, 0.1372, 0.0156, 0.0394, 0.0265, 0.0305, 0.0329, 0.0271,
        0.0283, 0.0390, 0.0677, 0.0515, 0.0893, 0.1422, 0.0839],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,039][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.3488, 0.0179, 0.0438, 0.0165, 0.0310, 0.0282, 0.0214, 0.1001, 0.0343,
        0.0585, 0.0242, 0.0467, 0.0611, 0.0450, 0.0319, 0.0906],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,039][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([6.2254e-03, 8.1642e-04, 1.4974e-03, 6.5236e-05, 7.1728e-04, 5.7296e-04,
        1.3298e-04, 9.7327e-03, 2.0339e-03, 1.3405e-02, 2.4662e-03, 1.2554e-02,
        4.2653e-02, 2.1527e-01, 2.3837e-02, 6.6802e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,040][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([6.2819e-02, 1.8480e-03, 1.9724e-03, 1.2249e-04, 1.1136e-03, 1.6410e-03,
        6.0073e-04, 9.6060e-03, 6.0334e-03, 7.5010e-03, 3.6509e-03, 1.5098e-02,
        4.3650e-02, 2.8862e-01, 1.8425e-02, 5.3729e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,040][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.7117, 0.0066, 0.0131, 0.0025, 0.0064, 0.0055, 0.0119, 0.0123, 0.0297,
        0.0109, 0.0223, 0.0306, 0.0342, 0.0297, 0.0379, 0.0347],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,041][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([2.1905e-02, 3.1067e-04, 1.3093e-04, 4.2711e-06, 1.0667e-04, 6.3654e-05,
        4.3297e-05, 3.6471e-03, 8.5056e-04, 8.2355e-03, 1.4116e-03, 3.5732e-03,
        2.3953e-02, 3.2022e-01, 6.6039e-03, 6.0894e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,044][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4935, 0.0271, 0.0397, 0.0041, 0.0130, 0.0083, 0.0084, 0.0225, 0.0147,
        0.0082, 0.0177, 0.0536, 0.0729, 0.0907, 0.0352, 0.0902],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,045][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.7847, 0.0160, 0.0208, 0.0027, 0.0042, 0.0028, 0.0046, 0.0174, 0.0079,
        0.0102, 0.0100, 0.0164, 0.0287, 0.0168, 0.0132, 0.0437],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,045][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2132, 0.0284, 0.0172, 0.0041, 0.0120, 0.0105, 0.0088, 0.0287, 0.0161,
        0.0419, 0.0353, 0.0590, 0.0723, 0.1871, 0.0347, 0.2306],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,046][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0088, 0.1604, 0.0137, 0.0295, 0.0228, 0.0148, 0.0176, 0.1664, 0.0452,
        0.0998, 0.0487, 0.0651, 0.0754, 0.1259, 0.0261, 0.0798],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,046][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.8227e-01, 3.1002e-04, 8.9211e-04, 4.2149e-03, 2.4447e-04, 1.2279e-04,
        3.8362e-01, 7.4521e-04, 7.9048e-04, 5.9974e-04, 6.8520e-04, 6.6543e-02,
        4.2868e-04, 4.6125e-03, 1.0446e-03, 5.9765e-04, 3.5228e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,047][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0031, 0.0102, 0.1240, 0.0725, 0.0336, 0.0780, 0.0285, 0.1052, 0.0722,
        0.0629, 0.0389, 0.0755, 0.0504, 0.0431, 0.0651, 0.0905, 0.0462],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,051][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2911, 0.0137, 0.0752, 0.0083, 0.0247, 0.0224, 0.0248, 0.0321, 0.0239,
        0.0181, 0.0315, 0.0528, 0.0450, 0.0757, 0.0780, 0.0702, 0.1127],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,051][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4252, 0.0091, 0.0216, 0.0085, 0.0180, 0.0164, 0.0239, 0.1025, 0.0296,
        0.0359, 0.0218, 0.0569, 0.0399, 0.0403, 0.0307, 0.0676, 0.0520],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,052][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.5912e-03, 4.6196e-04, 7.8648e-04, 8.6461e-05, 4.0947e-04, 5.6374e-04,
        6.1208e-05, 5.0866e-03, 8.3396e-04, 4.3686e-03, 1.0877e-03, 5.1461e-03,
        2.7072e-02, 1.5258e-01, 7.9260e-03, 7.1960e-01, 7.2335e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,052][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.0793e-02, 3.7056e-04, 5.9334e-04, 8.2496e-05, 4.3263e-04, 9.6303e-04,
        1.9422e-04, 3.2109e-03, 2.8040e-03, 4.8268e-03, 3.3475e-03, 7.2241e-03,
        1.9144e-02, 2.1139e-01, 1.1964e-02, 6.0253e-01, 1.0013e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,053][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6893, 0.0072, 0.0137, 0.0044, 0.0057, 0.0129, 0.0137, 0.0106, 0.0282,
        0.0136, 0.0201, 0.0204, 0.0220, 0.0352, 0.0254, 0.0332, 0.0445],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,053][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.9724e-03, 8.3140e-05, 4.5975e-05, 5.1686e-06, 4.5350e-05, 5.7379e-05,
        1.3639e-05, 1.6951e-03, 4.3964e-04, 3.5210e-03, 5.8122e-04, 1.6516e-03,
        1.2032e-02, 2.1540e-01, 3.9259e-03, 6.5423e-01, 1.0430e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,057][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7916, 0.0113, 0.0209, 0.0013, 0.0040, 0.0022, 0.0020, 0.0082, 0.0030,
        0.0030, 0.0084, 0.0176, 0.0204, 0.0308, 0.0101, 0.0256, 0.0396],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,058][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8835, 0.0077, 0.0115, 0.0015, 0.0017, 0.0017, 0.0029, 0.0053, 0.0035,
        0.0036, 0.0056, 0.0078, 0.0147, 0.0077, 0.0053, 0.0239, 0.0122],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,058][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1919, 0.0304, 0.0145, 0.0054, 0.0106, 0.0109, 0.0093, 0.0298, 0.0120,
        0.0350, 0.0242, 0.0519, 0.0561, 0.1970, 0.0273, 0.1929, 0.1008],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,058][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0138, 0.1480, 0.0151, 0.0290, 0.0268, 0.0191, 0.0205, 0.1306, 0.0456,
        0.0689, 0.0371, 0.0706, 0.0456, 0.0944, 0.0265, 0.0866, 0.1217],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,059][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([1.4710e-01, 3.3855e-04, 8.1655e-04, 3.5298e-03, 3.1786e-04, 1.1813e-04,
        4.1455e-01, 6.0327e-04, 7.3103e-04, 4.7889e-04, 5.4568e-04, 8.1315e-02,
        6.2259e-04, 4.6752e-03, 1.4019e-03, 5.2420e-04, 3.4167e-01, 6.5546e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,059][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0038, 0.0313, 0.1459, 0.0814, 0.0564, 0.0493, 0.0499, 0.0705, 0.0561,
        0.0335, 0.0330, 0.0704, 0.0552, 0.0333, 0.0819, 0.0638, 0.0634, 0.0209],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,063][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1840, 0.0136, 0.0572, 0.0061, 0.0292, 0.0351, 0.0314, 0.0252, 0.0241,
        0.0136, 0.0329, 0.0769, 0.0688, 0.0473, 0.0997, 0.0964, 0.1192, 0.0392],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,064][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.3588, 0.0118, 0.0238, 0.0118, 0.0264, 0.0208, 0.0210, 0.0965, 0.0502,
        0.0382, 0.0221, 0.0473, 0.0304, 0.0259, 0.0277, 0.0892, 0.0436, 0.0543],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,064][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([1.6965e-03, 6.2729e-04, 9.7536e-04, 6.2323e-05, 3.6479e-04, 3.9544e-04,
        8.7159e-05, 6.9423e-03, 1.0362e-03, 6.1417e-03, 1.0597e-03, 5.9548e-03,
        3.2796e-02, 1.0331e-01, 8.9038e-03, 6.0365e-01, 9.3804e-02, 1.3219e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,065][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([6.2835e-02, 4.9489e-04, 5.4767e-04, 4.7337e-05, 3.1099e-04, 7.1368e-04,
        3.0324e-04, 3.6289e-03, 3.5628e-03, 5.1259e-03, 3.0415e-03, 8.3133e-03,
        2.3357e-02, 1.2450e-01, 1.0145e-02, 4.8448e-01, 1.3699e-01, 1.3161e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,065][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.3458, 0.0182, 0.0306, 0.0082, 0.0153, 0.0187, 0.0260, 0.0191, 0.0527,
        0.0191, 0.0383, 0.0402, 0.0441, 0.0442, 0.0592, 0.0550, 0.0774, 0.0880],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,066][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([5.6447e-03, 1.4476e-04, 5.7069e-05, 3.8120e-06, 6.0082e-05, 8.2427e-05,
        3.0071e-05, 2.9966e-03, 5.6179e-04, 6.0840e-03, 1.0604e-03, 2.3753e-03,
        1.3745e-02, 1.4002e-01, 5.1621e-03, 5.1151e-01, 1.2285e-01, 1.8761e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,069][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.6246, 0.0187, 0.0321, 0.0024, 0.0049, 0.0050, 0.0038, 0.0106, 0.0042,
        0.0035, 0.0133, 0.0307, 0.0335, 0.0339, 0.0101, 0.0516, 0.0787, 0.0384],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,070][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.8536, 0.0120, 0.0156, 0.0015, 0.0026, 0.0023, 0.0029, 0.0081, 0.0031,
        0.0040, 0.0069, 0.0082, 0.0146, 0.0067, 0.0063, 0.0278, 0.0113, 0.0125],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,070][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.1994, 0.0338, 0.0134, 0.0035, 0.0104, 0.0078, 0.0076, 0.0350, 0.0105,
        0.0380, 0.0235, 0.0420, 0.0523, 0.1108, 0.0230, 0.1719, 0.0724, 0.1447],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,071][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0071, 0.1695, 0.0088, 0.0312, 0.0159, 0.0151, 0.0165, 0.0802, 0.0414,
        0.0750, 0.0312, 0.0585, 0.0335, 0.0756, 0.0172, 0.0815, 0.0957, 0.1460],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,071][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.3498e-01, 2.0680e-04, 7.8384e-04, 2.7583e-03, 1.8427e-04, 9.1034e-05,
        3.3686e-01, 3.8411e-04, 5.5890e-04, 3.0206e-04, 3.4791e-04, 5.8032e-02,
        2.6464e-04, 2.8379e-03, 8.8835e-04, 3.7076e-04, 3.5140e-01, 4.1276e-04,
        8.3301e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,072][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0094, 0.0156, 0.1264, 0.0429, 0.0441, 0.0590, 0.0464, 0.0975, 0.0525,
        0.0382, 0.0259, 0.0691, 0.0923, 0.0334, 0.0564, 0.0580, 0.0682, 0.0225,
        0.0423], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,076][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3456, 0.0105, 0.0462, 0.0055, 0.0145, 0.0181, 0.0215, 0.0153, 0.0185,
        0.0102, 0.0220, 0.0482, 0.0313, 0.0545, 0.0606, 0.0577, 0.1039, 0.0239,
        0.0920], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,076][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4208, 0.0083, 0.0217, 0.0086, 0.0182, 0.0184, 0.0214, 0.0801, 0.0379,
        0.0220, 0.0151, 0.0486, 0.0359, 0.0240, 0.0269, 0.0684, 0.0427, 0.0377,
        0.0433], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,077][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.3843e-03, 5.8431e-04, 1.0262e-03, 6.1903e-05, 3.1668e-04, 1.8672e-04,
        6.7471e-05, 4.2343e-03, 5.3135e-04, 3.3859e-03, 9.2060e-04, 4.3256e-03,
        1.8780e-02, 1.5708e-01, 6.4968e-03, 4.0053e-01, 8.4162e-02, 9.8297e-02,
        2.1462e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,077][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.0597e-01, 5.6477e-04, 5.2251e-04, 4.8567e-05, 2.2709e-04, 5.0211e-04,
        1.6124e-04, 2.6680e-03, 1.7929e-03, 3.5826e-03, 2.1900e-03, 4.9694e-03,
        9.0127e-03, 1.5802e-01, 5.3396e-03, 3.5596e-01, 7.6128e-02, 1.3236e-01,
        1.3999e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,078][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7267, 0.0047, 0.0108, 0.0025, 0.0045, 0.0057, 0.0089, 0.0066, 0.0192,
        0.0071, 0.0126, 0.0145, 0.0138, 0.0187, 0.0216, 0.0249, 0.0349, 0.0350,
        0.0273], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,078][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.8449e-02, 1.7311e-04, 3.7029e-05, 2.5125e-06, 2.7797e-05, 2.6076e-05,
        1.2461e-05, 1.5321e-03, 1.8085e-04, 2.0600e-03, 3.0873e-04, 1.0732e-03,
        5.2485e-03, 1.6272e-01, 2.0362e-03, 2.4730e-01, 7.5709e-02, 1.6158e-01,
        3.2153e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,082][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7532, 0.0130, 0.0296, 0.0012, 0.0049, 0.0018, 0.0015, 0.0055, 0.0021,
        0.0014, 0.0078, 0.0172, 0.0180, 0.0238, 0.0079, 0.0213, 0.0306, 0.0259,
        0.0333], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,082][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.1929e-01, 4.6928e-03, 1.1074e-02, 6.8422e-04, 9.6318e-04, 1.1151e-03,
        1.5169e-03, 3.7172e-03, 1.8377e-03, 1.5740e-03, 2.8733e-03, 4.1542e-03,
        7.0225e-03, 3.4535e-03, 2.9402e-03, 1.3183e-02, 6.4188e-03, 7.4695e-03,
        6.0228e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,083][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2339, 0.0227, 0.0117, 0.0033, 0.0087, 0.0063, 0.0061, 0.0207, 0.0085,
        0.0242, 0.0177, 0.0384, 0.0373, 0.1164, 0.0242, 0.1523, 0.0620, 0.1264,
        0.0791], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,083][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0127, 0.1293, 0.0113, 0.0198, 0.0172, 0.0153, 0.0164, 0.1347, 0.0319,
        0.0532, 0.0218, 0.0444, 0.0258, 0.0531, 0.0132, 0.0804, 0.0871, 0.1714,
        0.0609], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,085][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:53,087][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13200],
        [  884],
        [19381],
        [  917],
        [  117],
        [  747],
        [  553],
        [  254],
        [  825],
        [  541],
        [ 1164],
        [  430],
        [  765],
        [   26],
        [  313],
        [   62],
        [   69],
        [   12],
        [   55]], device='cuda:0')
[2024-07-24 10:19:53,090][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15162],
        [ 5870],
        [31293],
        [ 5668],
        [ 1020],
        [ 3459],
        [ 3617],
        [ 2384],
        [ 5237],
        [ 3661],
        [ 7237],
        [ 3676],
        [ 4764],
        [  455],
        [ 1830],
        [ 1074],
        [ 1760],
        [  560],
        [ 1638]], device='cuda:0')
[2024-07-24 10:19:53,091][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10158],
        [10805],
        [14052],
        [13159],
        [22446],
        [16117],
        [16535],
        [15254],
        [14262],
        [14230],
        [13162],
        [12345],
        [11674],
        [12641],
        [17496],
        [13330],
        [13287],
        [14678],
        [12562]], device='cuda:0')
[2024-07-24 10:19:53,092][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[14764],
        [17252],
        [33411],
        [24624],
        [23661],
        [23510],
        [22153],
        [20421],
        [19769],
        [19097],
        [18679],
        [18218],
        [18045],
        [18148],
        [18200],
        [18305],
        [18364],
        [18523],
        [18792]], device='cuda:0')
[2024-07-24 10:19:53,094][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[3976],
        [1765],
        [2621],
        [2807],
        [3084],
        [3142],
        [3129],
        [3404],
        [3585],
        [3560],
        [3551],
        [3487],
        [3504],
        [3516],
        [3526],
        [3470],
        [3479],
        [3514],
        [3548]], device='cuda:0')
[2024-07-24 10:19:53,097][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[35998],
        [ 2746],
        [ 4291],
        [ 1493],
        [ 1064],
        [ 1254],
        [  939],
        [  790],
        [  952],
        [  997],
        [  821],
        [  797],
        [  796],
        [  711],
        [  720],
        [  764],
        [  785],
        [  825],
        [  746]], device='cuda:0')
[2024-07-24 10:19:53,098][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[40020],
        [20834],
        [32822],
        [32168],
        [30099],
        [30656],
        [30786],
        [31178],
        [33535],
        [33231],
        [31569],
        [34775],
        [35060],
        [36655],
        [36434],
        [35692],
        [36684],
        [36677],
        [37598]], device='cuda:0')
[2024-07-24 10:19:53,099][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15350],
        [16187],
        [46881],
        [46036],
        [46953],
        [46828],
        [46344],
        [45816],
        [44584],
        [46597],
        [45376],
        [44923],
        [46234],
        [44672],
        [46159],
        [44532],
        [37973],
        [44071],
        [37678]], device='cuda:0')
[2024-07-24 10:19:53,102][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 5835],
        [ 5602],
        [12591],
        [ 9586],
        [12283],
        [10804],
        [ 9816],
        [ 8345],
        [ 7607],
        [ 6805],
        [ 6847],
        [ 6857],
        [ 6526],
        [ 6406],
        [ 6636],
        [ 6530],
        [ 6389],
        [ 6133],
        [ 6069]], device='cuda:0')
[2024-07-24 10:19:53,104][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40562],
        [35254],
        [37273],
        [36546],
        [25081],
        [27649],
        [30064],
        [33321],
        [33146],
        [31576],
        [29095],
        [28977],
        [29813],
        [25136],
        [25514],
        [12866],
        [ 4172],
        [ 4036],
        [24169]], device='cuda:0')
[2024-07-24 10:19:53,105][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30900],
        [11128],
        [  264],
        [  150],
        [  250],
        [  767],
        [  224],
        [ 4559],
        [  645],
        [ 1241],
        [ 1285],
        [  756],
        [ 1095],
        [ 1183],
        [ 1283],
        [ 1515],
        [  917],
        [  926],
        [  482]], device='cuda:0')
[2024-07-24 10:19:53,106][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23313],
        [ 5374],
        [ 1606],
        [ 2430],
        [ 2787],
        [ 3482],
        [ 3666],
        [ 3678],
        [ 3372],
        [ 3525],
        [ 3876],
        [ 3533],
        [ 3111],
        [ 3271],
        [ 3084],
        [ 3472],
        [ 3686],
        [ 3969],
        [ 3658]], device='cuda:0')
[2024-07-24 10:19:53,108][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29116],
        [13511],
        [ 4866],
        [ 4240],
        [ 4282],
        [ 3896],
        [ 4753],
        [ 4676],
        [ 5488],
        [ 5317],
        [ 5849],
        [ 6302],
        [ 6251],
        [ 6606],
        [ 6707],
        [ 6892],
        [ 7093],
        [ 7205],
        [ 7460]], device='cuda:0')
[2024-07-24 10:19:53,111][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14490],
        [21974],
        [29072],
        [33138],
        [38486],
        [43413],
        [41006],
        [36992],
        [40076],
        [36607],
        [40117],
        [40034],
        [39380],
        [38511],
        [41235],
        [39912],
        [37693],
        [31096],
        [30746]], device='cuda:0')
[2024-07-24 10:19:53,112][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[9486],
        [2244],
        [2831],
        [3581],
        [1867],
        [2456],
        [2644],
        [1830],
        [4951],
        [1024],
        [4421],
        [1901],
        [1919],
        [4705],
        [1709],
        [1835],
        [2292],
        [1479],
        [2575]], device='cuda:0')
[2024-07-24 10:19:53,113][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21378],
        [21281],
        [20829],
        [21741],
        [21245],
        [20895],
        [29453],
        [29358],
        [29354],
        [29347],
        [29505],
        [28522],
        [28297],
        [28002],
        [28516],
        [28247],
        [26970],
        [27077],
        [26688]], device='cuda:0')
[2024-07-24 10:19:53,114][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14090],
        [ 8798],
        [ 5208],
        [ 5728],
        [11107],
        [11341],
        [ 6234],
        [ 8622],
        [ 8281],
        [ 7909],
        [10579],
        [10033],
        [10470],
        [ 8490],
        [12041],
        [13480],
        [12978],
        [13085],
        [10732]], device='cuda:0')
[2024-07-24 10:19:53,117][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22216],
        [22172],
        [ 6717],
        [ 7946],
        [ 4310],
        [ 5806],
        [ 8267],
        [15922],
        [ 8880],
        [10508],
        [ 8858],
        [ 6932],
        [ 8499],
        [ 8547],
        [ 8745],
        [ 7907],
        [14172],
        [14290],
        [12333]], device='cuda:0')
[2024-07-24 10:19:53,119][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[39429],
        [40033],
        [33542],
        [39988],
        [33177],
        [21263],
        [22274],
        [21023],
        [17728],
        [18787],
        [18489],
        [17495],
        [17891],
        [22677],
        [21595],
        [24131],
        [23424],
        [24953],
        [25264]], device='cuda:0')
[2024-07-24 10:19:53,120][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[39088],
        [ 4056],
        [10971],
        [10998],
        [ 7493],
        [ 5106],
        [ 4166],
        [ 2388],
        [ 2156],
        [ 3735],
        [ 4306],
        [ 4164],
        [14995],
        [ 3498],
        [ 2700],
        [10050],
        [10633],
        [12038],
        [11295]], device='cuda:0')
[2024-07-24 10:19:53,121][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[45530],
        [29280],
        [ 7636],
        [ 5703],
        [ 6325],
        [ 3407],
        [ 3118],
        [ 6804],
        [ 3621],
        [ 3630],
        [ 3896],
        [ 4521],
        [ 4144],
        [ 4902],
        [ 4648],
        [ 3672],
        [ 3890],
        [ 3792],
        [ 3481]], device='cuda:0')
[2024-07-24 10:19:53,124][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26386],
        [26263],
        [19995],
        [24562],
        [19501],
        [ 3643],
        [20221],
        [16022],
        [22953],
        [18630],
        [12556],
        [14836],
        [15051],
        [14147],
        [21949],
        [13747],
        [14998],
        [24974],
        [13959]], device='cuda:0')
[2024-07-24 10:19:53,126][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7064],
        [13307],
        [11378],
        [10410],
        [17018],
        [16675],
        [18044],
        [ 7236],
        [ 8694],
        [17578],
        [20233],
        [17225],
        [14426],
        [16596],
        [19168],
        [36969],
        [39752],
        [36270],
        [34386]], device='cuda:0')
[2024-07-24 10:19:53,127][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30644],
        [31399],
        [25368],
        [24759],
        [25870],
        [26644],
        [25694],
        [29543],
        [29691],
        [32406],
        [30600],
        [31799],
        [28042],
        [29788],
        [19245],
        [19284],
        [29640],
        [24717],
        [31544]], device='cuda:0')
[2024-07-24 10:19:53,128][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10871],
        [ 9586],
        [ 6394],
        [ 7819],
        [ 6637],
        [ 7038],
        [ 7576],
        [ 7715],
        [ 7868],
        [ 7003],
        [ 6372],
        [ 8006],
        [ 7977],
        [ 8331],
        [ 5359],
        [ 7181],
        [ 7626],
        [ 7931],
        [ 8320]], device='cuda:0')
[2024-07-24 10:19:53,130][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14719],
        [ 5973],
        [10205],
        [12951],
        [11607],
        [15524],
        [12347],
        [16064],
        [14581],
        [14507],
        [13532],
        [13426],
        [11978],
        [13112],
        [13743],
        [11243],
        [11914],
        [13589],
        [13881]], device='cuda:0')
[2024-07-24 10:19:53,133][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20093],
        [ 3867],
        [ 4844],
        [ 3701],
        [ 4282],
        [ 4909],
        [ 4228],
        [ 3982],
        [ 2479],
        [ 3072],
        [ 2353],
        [ 2226],
        [ 2379],
        [ 2588],
        [ 2117],
        [ 2541],
        [ 2122],
        [ 1874],
        [ 1846]], device='cuda:0')
[2024-07-24 10:19:53,134][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[15436],
        [39660],
        [45536],
        [41721],
        [44353],
        [47566],
        [46265],
        [46848],
        [47060],
        [45152],
        [45849],
        [46227],
        [44536],
        [45801],
        [45829],
        [41704],
        [36418],
        [35828],
        [38123]], device='cuda:0')
[2024-07-24 10:19:53,136][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40273],
        [49461],
        [49924],
        [49990],
        [49919],
        [49798],
        [49893],
        [49949],
        [49862],
        [50170],
        [49169],
        [49993],
        [49926],
        [49652],
        [49830],
        [49975],
        [50015],
        [50069],
        [49993]], device='cuda:0')
[2024-07-24 10:19:53,139][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535],
        [24535]], device='cuda:0')
[2024-07-24 10:19:53,195][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:53,195][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,196][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,196][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,196][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,197][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,197][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,197][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,198][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,198][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,198][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,198][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,199][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,199][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0159, 0.9841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,199][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0076, 0.9924], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,200][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9995e-01, 5.0052e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,203][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9940, 0.0060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,203][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2464, 0.7536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,203][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,204][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0723, 0.9277], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,204][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3440, 0.6560], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,204][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9922, 0.0078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,205][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0150, 0.9850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,205][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1511, 0.8489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,205][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1480, 0.8520], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,208][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.0033, 0.6758, 0.3209], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,212][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.0029, 0.5624, 0.4347], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,213][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.9975, 0.0014, 0.0011], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,213][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.9023, 0.0522, 0.0454], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,213][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.1374, 0.4211, 0.4415], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,214][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.8313, 0.0801, 0.0886], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,214][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0039, 0.5244, 0.4717], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,214][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0770, 0.7967, 0.1263], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,215][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.8008, 0.1584, 0.0408], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,215][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0018, 0.6635, 0.3348], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,215][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0108, 0.7728, 0.2164], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,216][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.1485, 0.6110, 0.2404], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,220][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0007, 0.5605, 0.2261, 0.2127], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,220][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0027, 0.3587, 0.2963, 0.3423], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,220][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9960e-01, 1.8314e-04, 1.7795e-04, 4.0924e-05], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,221][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9912, 0.0016, 0.0060, 0.0012], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,221][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1177, 0.2878, 0.2923, 0.3021], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,221][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9815, 0.0090, 0.0074, 0.0021], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,222][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0050, 0.2662, 0.4831, 0.2457], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,222][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0425, 0.7696, 0.1413, 0.0466], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,226][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8905, 0.0730, 0.0157, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,226][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([7.0964e-04, 1.2075e-01, 1.5309e-01, 7.2545e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,227][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1005, 0.4457, 0.3779, 0.0759], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,227][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0531, 0.3821, 0.1789, 0.3859], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,227][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0018, 0.4393, 0.2062, 0.1710, 0.1818], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,228][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0014, 0.2509, 0.2232, 0.2499, 0.2746], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,228][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([9.9825e-01, 4.7267e-04, 6.5641e-04, 2.1610e-04, 4.0768e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,228][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.9426, 0.0050, 0.0109, 0.0064, 0.0351], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,232][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0863, 0.2149, 0.2264, 0.2321, 0.2403], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,233][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.9278, 0.0190, 0.0212, 0.0072, 0.0248], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,233][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0012, 0.1458, 0.2614, 0.2204, 0.3712], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,233][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0278, 0.6877, 0.1054, 0.1005, 0.0786], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,234][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.6919, 0.1107, 0.0329, 0.0479, 0.1165], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,234][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([1.1507e-04, 5.5044e-02, 7.2795e-02, 4.3173e-01, 4.4032e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,234][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0401, 0.3045, 0.1953, 0.1022, 0.3579], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,235][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0573, 0.2925, 0.1158, 0.2731, 0.2613], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,236][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([1.6689e-04, 4.5924e-01, 1.7171e-01, 1.6501e-01, 1.4991e-01, 5.3963e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,239][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0012, 0.2129, 0.1837, 0.2078, 0.2320, 0.1623], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,239][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([9.9474e-01, 1.1447e-03, 1.3646e-03, 5.1606e-04, 1.0382e-03, 1.1962e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,239][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.9438, 0.0029, 0.0048, 0.0014, 0.0082, 0.0389], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,240][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0698, 0.1741, 0.1877, 0.1856, 0.1852, 0.1976], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,240][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.8203, 0.0516, 0.0267, 0.0097, 0.0136, 0.0781], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,240][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0006, 0.0950, 0.2019, 0.2110, 0.3398, 0.1517], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,241][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0226, 0.5477, 0.1645, 0.0697, 0.1155, 0.0800], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,241][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5311, 0.1800, 0.0607, 0.0551, 0.0737, 0.0992], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,243][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([5.8927e-05, 2.1385e-02, 3.3172e-02, 2.3781e-01, 3.0640e-01, 4.0117e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,245][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0375, 0.0974, 0.0602, 0.0140, 0.1023, 0.6886], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,245][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0327, 0.1974, 0.0834, 0.1881, 0.1753, 0.3230], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,246][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.4145e-04, 4.4780e-01, 1.3899e-01, 1.5447e-01, 1.2427e-01, 4.8325e-02,
        8.5903e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,246][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0011, 0.1835, 0.1620, 0.1786, 0.2033, 0.1390, 0.1326],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,246][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.9412e-01, 1.2045e-03, 1.1563e-03, 4.0303e-04, 8.6257e-04, 9.1609e-04,
        1.3418e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,247][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.5302, 0.0040, 0.0132, 0.0074, 0.0436, 0.3834, 0.0182],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,247][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0578, 0.1463, 0.1544, 0.1563, 0.1565, 0.1681, 0.1607],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,251][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5560, 0.0943, 0.0731, 0.0251, 0.0366, 0.1385, 0.0764],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,251][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0005, 0.1389, 0.1478, 0.1969, 0.2375, 0.1050, 0.1734],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,252][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0101, 0.4976, 0.1354, 0.0990, 0.1105, 0.1056, 0.0419],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,252][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5891, 0.1404, 0.0380, 0.0531, 0.0489, 0.0784, 0.0520],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,252][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.0813e-05, 2.3600e-02, 2.7446e-02, 2.4711e-01, 2.6352e-01, 3.1117e-01,
        1.2709e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,253][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0011, 0.0361, 0.0245, 0.0204, 0.0711, 0.8239, 0.0230],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,253][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0285, 0.1658, 0.0730, 0.1570, 0.1442, 0.2603, 0.1712],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,254][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([1.7207e-04, 4.3005e-01, 1.3702e-01, 1.3789e-01, 1.2564e-01, 4.4438e-02,
        7.8766e-02, 4.6024e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,257][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0010, 0.1768, 0.1419, 0.1520, 0.1751, 0.1290, 0.1280, 0.0963],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,258][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([9.8246e-01, 3.3937e-03, 1.6749e-03, 7.3320e-04, 2.0879e-03, 1.6242e-03,
        2.8402e-03, 5.1866e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,258][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.7488, 0.0023, 0.0038, 0.0014, 0.0106, 0.0392, 0.0071, 0.1867],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,258][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0430, 0.1175, 0.1287, 0.1276, 0.1370, 0.1404, 0.1379, 0.1678],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,259][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.5460, 0.0319, 0.0549, 0.0125, 0.0210, 0.0757, 0.0416, 0.2164],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,259][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([2.8075e-04, 1.4911e-01, 1.4177e-01, 6.5558e-02, 1.9359e-01, 7.2992e-02,
        3.0179e-01, 7.4902e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,259][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0142, 0.4355, 0.1234, 0.0748, 0.0805, 0.1213, 0.0394, 0.1109],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,261][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.2642, 0.1734, 0.0414, 0.0571, 0.0604, 0.1535, 0.0743, 0.1757],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,264][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([3.7781e-05, 1.8388e-02, 4.1154e-02, 1.1267e-01, 3.4060e-01, 2.4501e-01,
        1.5513e-01, 8.7016e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,264][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0161, 0.0346, 0.0300, 0.0110, 0.0511, 0.4646, 0.0279, 0.3648],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,264][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0281, 0.1310, 0.0536, 0.1296, 0.1168, 0.2159, 0.1429, 0.1821],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,265][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0004, 0.3572, 0.1402, 0.1384, 0.0818, 0.0393, 0.0619, 0.0403, 0.1406],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,265][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0008, 0.1501, 0.1302, 0.1388, 0.1600, 0.1140, 0.1128, 0.0870, 0.1065],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,266][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([9.9664e-01, 4.5511e-04, 7.1292e-04, 1.0611e-04, 2.8514e-04, 2.5744e-04,
        3.6471e-04, 6.6624e-04, 5.1490e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,266][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.7160, 0.0009, 0.0020, 0.0011, 0.0046, 0.0291, 0.0047, 0.1913, 0.0503],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,270][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0481, 0.1025, 0.1121, 0.1123, 0.1161, 0.1202, 0.1181, 0.1412, 0.1293],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,270][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.4399, 0.0379, 0.0445, 0.0119, 0.0329, 0.0806, 0.0415, 0.2218, 0.0890],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,271][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0005, 0.0742, 0.1937, 0.0635, 0.2598, 0.0609, 0.1461, 0.0595, 0.1418],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,271][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0570, 0.3155, 0.0824, 0.0596, 0.0520, 0.0979, 0.0369, 0.1585, 0.1402],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,272][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.5408, 0.1061, 0.0256, 0.0247, 0.0369, 0.0573, 0.0509, 0.1131, 0.0447],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,272][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([4.4444e-05, 7.2680e-03, 2.3770e-02, 8.1133e-02, 1.4196e-01, 1.7460e-01,
        1.1846e-01, 1.0116e-01, 3.5161e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,272][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0139, 0.0096, 0.0088, 0.0033, 0.0231, 0.2777, 0.0159, 0.3363, 0.3114],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,276][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0214, 0.1145, 0.0478, 0.1104, 0.0964, 0.1764, 0.1164, 0.1513, 0.1653],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,277][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([1.1246e-04, 3.6679e-01, 9.3107e-02, 1.0546e-01, 9.3270e-02, 3.2317e-02,
        5.5566e-02, 3.2694e-02, 1.6739e-01, 5.3300e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,277][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0006, 0.1339, 0.1168, 0.1277, 0.1426, 0.1049, 0.1000, 0.0779, 0.0938,
        0.1018], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,277][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([9.8693e-01, 1.9727e-03, 1.2757e-03, 5.6510e-04, 8.3294e-04, 8.8476e-04,
        1.6957e-03, 2.8346e-03, 1.6106e-03, 1.4012e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,278][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.4964, 0.0012, 0.0012, 0.0007, 0.0026, 0.0182, 0.0027, 0.1588, 0.0576,
        0.2607], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,278][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0311, 0.0913, 0.1027, 0.1004, 0.1067, 0.1071, 0.1041, 0.1242, 0.1158,
        0.1165], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,279][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.3210, 0.0176, 0.0554, 0.0165, 0.0287, 0.0595, 0.0453, 0.2541, 0.0658,
        0.1362], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,280][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([1.4433e-04, 6.7051e-02, 9.4556e-02, 7.7040e-02, 1.5098e-01, 5.5462e-02,
        1.6517e-01, 5.6310e-02, 1.8122e-01, 1.5206e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,283][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0159, 0.3603, 0.0500, 0.0390, 0.0579, 0.0789, 0.0312, 0.0973, 0.1677,
        0.1019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,283][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1607, 0.1730, 0.0478, 0.0480, 0.0520, 0.1018, 0.0715, 0.1955, 0.0716,
        0.0782], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,284][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([1.0611e-05, 1.1475e-02, 1.9740e-02, 1.0222e-01, 1.9473e-01, 1.3242e-01,
        9.4604e-02, 5.8298e-02, 2.6543e-01, 1.2106e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,284][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0037, 0.0066, 0.0042, 0.0009, 0.0052, 0.0532, 0.0043, 0.1278, 0.1302,
        0.6640], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,284][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0313, 0.0981, 0.0397, 0.0956, 0.0826, 0.1521, 0.1008, 0.1357, 0.1506,
        0.1136], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,285][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([6.9190e-05, 3.0537e-01, 1.1247e-01, 1.0706e-01, 9.0918e-02, 2.9724e-02,
        5.0804e-02, 3.3523e-02, 1.6821e-01, 5.4059e-02, 4.7793e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,285][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0006, 0.1217, 0.1077, 0.1174, 0.1306, 0.0938, 0.0921, 0.0715, 0.0910,
        0.0920, 0.0816], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,287][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([9.7268e-01, 1.8791e-03, 2.9511e-03, 8.5078e-04, 1.4553e-03, 1.7803e-03,
        2.2608e-03, 3.6082e-03, 4.0011e-03, 2.6555e-03, 5.8767e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,289][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.5499, 0.0007, 0.0014, 0.0008, 0.0030, 0.0280, 0.0032, 0.1083, 0.0328,
        0.1654, 0.1065], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,289][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0336, 0.0820, 0.0867, 0.0933, 0.0924, 0.0967, 0.0962, 0.1122, 0.1068,
        0.1038, 0.0963], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,290][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2901, 0.0208, 0.0501, 0.0121, 0.0175, 0.0662, 0.0381, 0.1464, 0.0500,
        0.0859, 0.2228], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,290][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0004, 0.0569, 0.1013, 0.0557, 0.1640, 0.0871, 0.1422, 0.0628, 0.1276,
        0.1304, 0.0714], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,291][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0239, 0.2347, 0.1043, 0.0535, 0.0592, 0.0777, 0.0245, 0.0971, 0.0960,
        0.1268, 0.1022], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,291][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2261, 0.1491, 0.0365, 0.0495, 0.0502, 0.0753, 0.0651, 0.1652, 0.0472,
        0.0565, 0.0794], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,291][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([2.6670e-05, 1.1189e-02, 2.1289e-02, 8.7934e-02, 1.8711e-01, 1.5066e-01,
        6.2975e-02, 6.6207e-02, 2.7339e-01, 1.1130e-01, 2.7924e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,295][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0075, 0.0041, 0.0039, 0.0015, 0.0065, 0.0891, 0.0047, 0.1046, 0.0840,
        0.5431, 0.1509], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,296][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0238, 0.0906, 0.0372, 0.0857, 0.0749, 0.1366, 0.0907, 0.1217, 0.1367,
        0.1040, 0.0980], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,296][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.1330e-04, 2.9304e-01, 1.1353e-01, 1.0315e-01, 8.3614e-02, 2.9695e-02,
        5.1336e-02, 3.0849e-02, 1.5572e-01, 4.5352e-02, 4.6886e-02, 4.6725e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,296][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0006, 0.1139, 0.0985, 0.1049, 0.1211, 0.0840, 0.0835, 0.0671, 0.0794,
        0.0891, 0.0763, 0.0816], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,297][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([9.8983e-01, 4.7042e-04, 8.0799e-04, 1.8589e-04, 4.3401e-04, 3.1024e-04,
        5.3514e-04, 9.6368e-04, 9.1794e-04, 5.9309e-04, 1.8667e-03, 3.0885e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,297][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([6.6888e-01, 3.1506e-04, 5.0609e-04, 2.1698e-04, 9.1514e-04, 7.5712e-03,
        7.2050e-04, 2.9863e-02, 1.4510e-02, 8.9794e-02, 6.6561e-02, 1.2014e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,298][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0349, 0.0765, 0.0827, 0.0816, 0.0820, 0.0854, 0.0854, 0.1037, 0.0920,
        0.0954, 0.0903, 0.0900], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,301][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.3626, 0.0161, 0.0361, 0.0072, 0.0181, 0.0516, 0.0238, 0.1104, 0.0401,
        0.0782, 0.1510, 0.1048], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,302][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0004, 0.0711, 0.1339, 0.0484, 0.1711, 0.0512, 0.1151, 0.0417, 0.0979,
        0.1341, 0.0760, 0.0591], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,302][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0358, 0.1826, 0.0698, 0.0447, 0.0457, 0.0459, 0.0189, 0.0472, 0.1024,
        0.1088, 0.1072, 0.1908], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,303][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4622, 0.0699, 0.0298, 0.0248, 0.0324, 0.0518, 0.0402, 0.0828, 0.0348,
        0.0334, 0.0677, 0.0702], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,303][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.0259e-05, 7.6949e-03, 1.6801e-02, 6.4641e-02, 1.4748e-01, 1.2139e-01,
        7.1629e-02, 8.6790e-02, 2.2999e-01, 1.2317e-01, 4.6352e-02, 8.4030e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,303][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0104, 0.0020, 0.0014, 0.0008, 0.0022, 0.0503, 0.0017, 0.0804, 0.0453,
        0.2408, 0.1772, 0.3875], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,304][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0167, 0.0827, 0.0346, 0.0779, 0.0691, 0.1234, 0.0824, 0.1119, 0.1242,
        0.0947, 0.0881, 0.0943], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,306][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ office] are: tensor([1.8893e-04, 2.4676e-01, 9.6170e-02, 1.0337e-01, 8.4714e-02, 3.4190e-02,
        5.6647e-02, 3.3222e-02, 1.3907e-01, 5.4179e-02, 4.2102e-02, 5.1523e-02,
        5.7871e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,308][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ office] are: tensor([0.0007, 0.1029, 0.0891, 0.0972, 0.1130, 0.0781, 0.0760, 0.0612, 0.0745,
        0.0827, 0.0691, 0.0728, 0.0827], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,308][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ office] are: tensor([9.6831e-01, 1.6653e-03, 1.0120e-03, 5.2855e-04, 9.0412e-04, 6.1499e-04,
        1.7020e-03, 1.9754e-03, 2.4269e-03, 2.5785e-03, 6.7820e-03, 8.6653e-03,
        2.8313e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,309][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ office] are: tensor([5.3438e-01, 4.9377e-05, 7.9492e-05, 5.3384e-05, 1.5990e-04, 1.9580e-03,
        2.4132e-04, 1.1620e-02, 4.1321e-03, 1.6316e-02, 1.7192e-02, 5.7208e-02,
        3.5661e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,309][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0308, 0.0635, 0.0723, 0.0741, 0.0780, 0.0784, 0.0778, 0.0929, 0.0909,
        0.0868, 0.0863, 0.0872, 0.0809], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,309][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.6762, 0.0115, 0.0169, 0.0035, 0.0050, 0.0212, 0.0166, 0.0523, 0.0138,
        0.0271, 0.0790, 0.0438, 0.0331], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,310][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ office] are: tensor([2.2224e-04, 4.6216e-02, 6.3803e-02, 4.0802e-02, 5.3035e-02, 4.9937e-02,
        9.6671e-02, 4.6568e-02, 2.4350e-01, 8.4106e-02, 1.5669e-01, 7.9470e-02,
        3.8980e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,311][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0265, 0.1202, 0.0307, 0.0209, 0.0265, 0.0308, 0.0134, 0.0453, 0.0653,
        0.0639, 0.1094, 0.1876, 0.2595], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,314][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.3288, 0.0397, 0.0168, 0.0095, 0.0169, 0.0440, 0.0429, 0.0916, 0.0562,
        0.0710, 0.1059, 0.0921, 0.0846], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,314][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ office] are: tensor([3.7617e-05, 8.1076e-03, 1.1652e-02, 8.6963e-02, 1.2769e-01, 9.7554e-02,
        5.0070e-02, 6.7606e-02, 2.4530e-01, 1.6305e-01, 6.1788e-02, 4.6266e-02,
        3.3920e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,315][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ office] are: tensor([8.1614e-03, 2.7685e-04, 2.6413e-04, 9.7242e-05, 3.1010e-04, 7.1575e-03,
        3.2296e-04, 1.2151e-02, 1.0364e-02, 5.9289e-02, 5.7973e-02, 1.3248e-01,
        7.1116e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,315][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.0226, 0.0809, 0.0333, 0.0753, 0.0641, 0.1158, 0.0759, 0.1029, 0.1168,
        0.0846, 0.0783, 0.0830, 0.0663], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,316][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.6119e-04, 2.3444e-01, 1.1269e-01, 9.3897e-02, 8.6660e-02, 3.4393e-02,
        5.4191e-02, 2.8983e-02, 1.3024e-01, 4.3761e-02, 4.1772e-02, 4.9379e-02,
        5.0328e-02, 3.9111e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,316][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0005, 0.0966, 0.0859, 0.0909, 0.1078, 0.0754, 0.0714, 0.0557, 0.0676,
        0.0772, 0.0641, 0.0676, 0.0760, 0.0633], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,317][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([9.9607e-01, 1.4912e-04, 3.9826e-04, 4.7457e-05, 1.5656e-04, 1.3508e-04,
        1.3997e-04, 2.8264e-04, 2.0815e-04, 1.7804e-04, 5.0336e-04, 8.7935e-04,
        4.4525e-04, 4.0503e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,319][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([9.5037e-01, 7.8549e-06, 2.2776e-06, 4.4335e-07, 1.2266e-06, 6.0442e-06,
        5.2899e-07, 4.3030e-05, 5.3423e-06, 5.5529e-05, 3.9060e-05, 8.4815e-05,
        6.2325e-04, 4.8766e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,320][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0273, 0.0640, 0.0710, 0.0717, 0.0719, 0.0751, 0.0719, 0.0860, 0.0772,
        0.0770, 0.0754, 0.0797, 0.0772, 0.0747], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,321][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.6645, 0.0087, 0.0210, 0.0027, 0.0093, 0.0154, 0.0116, 0.0654, 0.0172,
        0.0265, 0.0552, 0.0485, 0.0333, 0.0207], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,321][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0004, 0.0290, 0.1617, 0.0366, 0.1875, 0.0557, 0.1075, 0.0333, 0.0659,
        0.0835, 0.0496, 0.0589, 0.0734, 0.0570], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,322][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0853, 0.0963, 0.0142, 0.0047, 0.0102, 0.0062, 0.0045, 0.0111, 0.0198,
        0.0211, 0.0297, 0.0508, 0.0690, 0.5771], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,322][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.4292, 0.0340, 0.0234, 0.0149, 0.0364, 0.0455, 0.0318, 0.0585, 0.0287,
        0.0258, 0.0559, 0.0497, 0.0487, 0.1174], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,323][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([2.9435e-05, 6.7957e-03, 1.8382e-02, 6.9354e-02, 1.7594e-01, 1.3412e-01,
        6.9567e-02, 6.8549e-02, 1.7194e-01, 8.3636e-02, 4.4829e-02, 7.0519e-02,
        6.2301e-02, 2.4039e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,324][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([6.2101e-02, 7.6499e-04, 6.9916e-05, 1.1072e-05, 4.5453e-05, 3.5564e-04,
        2.5757e-05, 9.5717e-04, 4.0469e-04, 3.2351e-03, 1.6648e-03, 3.7222e-03,
        1.5584e-02, 9.1106e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,327][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0162, 0.0761, 0.0318, 0.0717, 0.0619, 0.1083, 0.0710, 0.0969, 0.1080,
        0.0795, 0.0739, 0.0787, 0.0623, 0.0640], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,327][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([1.4151e-04, 2.6342e-01, 1.2520e-01, 8.6352e-02, 8.7014e-02, 2.8253e-02,
        4.3148e-02, 2.6035e-02, 1.1799e-01, 3.9902e-02, 3.6804e-02, 3.7652e-02,
        4.5427e-02, 3.1440e-02, 3.1213e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,328][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0004, 0.0834, 0.0795, 0.0880, 0.0980, 0.0706, 0.0688, 0.0532, 0.0666,
        0.0703, 0.0614, 0.0656, 0.0732, 0.0629, 0.0581], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,328][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([9.2612e-01, 1.1511e-03, 2.9920e-03, 7.9571e-04, 1.6476e-03, 1.5152e-03,
        2.7371e-03, 2.5641e-03, 4.4699e-03, 5.1341e-03, 1.2907e-02, 1.2866e-02,
        7.2832e-03, 6.1972e-03, 1.1614e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,328][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([1.3837e-03, 3.9572e-06, 4.1402e-06, 2.3704e-06, 6.7493e-06, 5.6516e-05,
        5.8788e-06, 1.6657e-04, 1.2019e-04, 4.4325e-04, 3.8736e-04, 1.5673e-03,
        8.4748e-03, 9.8646e-01, 9.1830e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,329][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0262, 0.0561, 0.0631, 0.0660, 0.0668, 0.0699, 0.0663, 0.0777, 0.0732,
        0.0779, 0.0723, 0.0763, 0.0714, 0.0684, 0.0685], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,333][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.2246, 0.0123, 0.0425, 0.0075, 0.0286, 0.0640, 0.0365, 0.0731, 0.0437,
        0.0575, 0.1692, 0.0950, 0.0761, 0.0415, 0.0279], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,333][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0002, 0.0335, 0.0731, 0.0415, 0.0923, 0.0404, 0.1037, 0.0396, 0.0898,
        0.0761, 0.1023, 0.0629, 0.0765, 0.0329, 0.1353], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,334][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0036, 0.0346, 0.0118, 0.0114, 0.0056, 0.0101, 0.0047, 0.0131, 0.0174,
        0.0183, 0.0261, 0.0674, 0.0776, 0.6773, 0.0209], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,334][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0486, 0.0307, 0.0162, 0.0185, 0.0573, 0.0419, 0.0668, 0.1001, 0.0393,
        0.0535, 0.0740, 0.1182, 0.0884, 0.1169, 0.1296], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,335][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([2.4351e-05, 1.0116e-02, 1.8228e-02, 1.0546e-01, 8.8989e-02, 1.4445e-01,
        6.0490e-02, 4.7738e-02, 1.4719e-01, 4.0712e-02, 4.3441e-02, 7.0358e-02,
        5.2154e-02, 1.8052e-02, 1.5260e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,335][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([5.1686e-05, 1.7756e-05, 8.3318e-06, 2.8037e-06, 1.1644e-05, 1.1831e-04,
        1.3353e-05, 3.7097e-04, 2.5961e-04, 1.1931e-03, 7.6394e-04, 2.9663e-03,
        2.2586e-02, 9.6967e-01, 1.9662e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,337][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0219, 0.0747, 0.0279, 0.0643, 0.0565, 0.1011, 0.0683, 0.0947, 0.1056,
        0.0766, 0.0723, 0.0742, 0.0597, 0.0601, 0.0423], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,339][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.6735e-04, 2.3013e-01, 1.0458e-01, 7.7797e-02, 8.4029e-02, 2.8344e-02,
        4.4106e-02, 2.5014e-02, 1.1237e-01, 4.0774e-02, 3.5359e-02, 4.1231e-02,
        4.8346e-02, 3.7021e-02, 3.7037e-02, 5.3700e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,340][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0004, 0.0800, 0.0716, 0.0777, 0.0901, 0.0658, 0.0660, 0.0516, 0.0634,
        0.0659, 0.0588, 0.0629, 0.0690, 0.0585, 0.0534, 0.0647],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,340][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([9.7517e-01, 5.7143e-04, 1.0249e-03, 2.0002e-04, 4.1446e-04, 6.2765e-04,
        7.1490e-04, 1.3779e-03, 9.0947e-04, 8.7907e-04, 2.4699e-03, 3.8331e-03,
        2.0765e-03, 1.5449e-03, 1.8988e-03, 6.2919e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,341][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([4.8474e-01, 9.6199e-06, 2.6425e-06, 3.1956e-07, 1.7402e-06, 6.3327e-06,
        1.0412e-06, 5.5284e-05, 1.2969e-05, 6.8818e-05, 7.6101e-05, 1.6364e-04,
        9.0825e-04, 2.1279e-01, 2.1817e-04, 3.0094e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,341][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0232, 0.0523, 0.0601, 0.0603, 0.0607, 0.0631, 0.0613, 0.0755, 0.0676,
        0.0696, 0.0663, 0.0676, 0.0683, 0.0641, 0.0608, 0.0790],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,341][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.5449, 0.0077, 0.0197, 0.0060, 0.0077, 0.0251, 0.0164, 0.0423, 0.0183,
        0.0328, 0.0905, 0.0542, 0.0530, 0.0317, 0.0087, 0.0410],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,345][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0002, 0.0257, 0.0565, 0.0303, 0.0923, 0.0271, 0.0981, 0.0325, 0.0805,
        0.0761, 0.0703, 0.0660, 0.0619, 0.0607, 0.1913, 0.0305],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,346][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0311, 0.0262, 0.0060, 0.0027, 0.0034, 0.0045, 0.0018, 0.0047, 0.0096,
        0.0084, 0.0175, 0.0274, 0.0356, 0.2965, 0.0160, 0.5087],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,346][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2702, 0.0478, 0.0139, 0.0158, 0.0235, 0.0338, 0.0248, 0.0584, 0.0243,
        0.0235, 0.0357, 0.0637, 0.0573, 0.1217, 0.0428, 0.1429],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,347][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([3.3333e-05, 2.3984e-03, 8.8908e-03, 3.2215e-02, 7.3266e-02, 7.9359e-02,
        4.0881e-02, 4.6349e-02, 1.5353e-01, 6.1150e-02, 7.0198e-02, 5.8316e-02,
        6.0776e-02, 1.6337e-02, 2.8955e-01, 6.7516e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,347][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([5.3955e-03, 4.8850e-05, 9.3567e-06, 1.1127e-06, 5.0255e-06, 4.2939e-05,
        2.6187e-06, 1.5211e-04, 5.9437e-05, 3.2241e-04, 2.1214e-04, 4.6734e-04,
        3.6560e-03, 1.4232e-01, 3.4037e-04, 8.4696e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,348][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0165, 0.0666, 0.0265, 0.0633, 0.0536, 0.0965, 0.0637, 0.0868, 0.0967,
        0.0723, 0.0675, 0.0711, 0.0548, 0.0566, 0.0406, 0.0671],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,349][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.9561e-04, 2.1591e-01, 9.0231e-02, 7.8902e-02, 7.2983e-02, 2.8696e-02,
        4.7415e-02, 2.6354e-02, 1.0894e-01, 3.6468e-02, 3.9932e-02, 4.2893e-02,
        4.6138e-02, 3.4975e-02, 3.2995e-02, 5.1699e-02, 4.5270e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,352][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0005, 0.0812, 0.0729, 0.0748, 0.0903, 0.0603, 0.0607, 0.0478, 0.0577,
        0.0641, 0.0551, 0.0581, 0.0640, 0.0531, 0.0528, 0.0603, 0.0462],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,352][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.9393e-01, 1.0562e-04, 2.0582e-04, 3.7923e-05, 8.5678e-05, 9.2719e-05,
        1.3211e-04, 2.3398e-04, 1.8979e-04, 9.6765e-05, 5.9952e-04, 7.5673e-04,
        3.4809e-04, 3.0492e-04, 4.5287e-04, 7.6190e-04, 1.6625e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,353][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.6426e-01, 1.6371e-06, 1.1319e-06, 3.1354e-07, 8.6667e-07, 9.3890e-06,
        4.4406e-07, 3.7362e-05, 1.0817e-05, 5.7790e-05, 6.3920e-05, 1.0611e-04,
        6.0051e-04, 1.3885e-01, 1.0824e-04, 5.7168e-01, 2.4202e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,353][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0257, 0.0509, 0.0574, 0.0561, 0.0558, 0.0593, 0.0580, 0.0731, 0.0637,
        0.0628, 0.0625, 0.0648, 0.0614, 0.0591, 0.0555, 0.0714, 0.0625],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,354][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2561, 0.0157, 0.0292, 0.0059, 0.0141, 0.0396, 0.0297, 0.1037, 0.0318,
        0.0651, 0.1120, 0.0833, 0.0560, 0.0532, 0.0153, 0.0239, 0.0656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,354][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0005, 0.0246, 0.0727, 0.0468, 0.0858, 0.0426, 0.0853, 0.0338, 0.0902,
        0.0741, 0.0677, 0.0727, 0.0398, 0.0362, 0.1193, 0.0303, 0.0776],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,358][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0458, 0.0374, 0.0108, 0.0044, 0.0045, 0.0040, 0.0021, 0.0058, 0.0098,
        0.0118, 0.0117, 0.0213, 0.0309, 0.2652, 0.0181, 0.3748, 0.1416],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,358][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6001, 0.0236, 0.0109, 0.0080, 0.0101, 0.0178, 0.0145, 0.0325, 0.0144,
        0.0124, 0.0266, 0.0257, 0.0228, 0.0511, 0.0166, 0.0506, 0.0622],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,359][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.6992e-05, 4.1709e-03, 1.0767e-02, 7.5299e-02, 9.6450e-02, 8.4478e-02,
        4.1446e-02, 5.6887e-02, 1.5020e-01, 4.9691e-02, 4.2043e-02, 6.4407e-02,
        3.4807e-02, 1.7024e-02, 2.5283e-01, 6.0225e-03, 1.3403e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,359][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.6896e-04, 2.1417e-05, 3.0231e-06, 1.2111e-06, 2.6324e-06, 3.7073e-05,
        1.6384e-06, 8.6614e-05, 4.1380e-05, 1.8488e-04, 1.6276e-04, 3.6949e-04,
        1.8534e-03, 1.6090e-01, 2.5820e-04, 7.7797e-01, 5.7437e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,360][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0145, 0.0643, 0.0266, 0.0599, 0.0521, 0.0899, 0.0588, 0.0830, 0.0908,
        0.0675, 0.0622, 0.0652, 0.0516, 0.0523, 0.0398, 0.0615, 0.0602],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,360][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([1.6487e-04, 2.0798e-01, 8.8529e-02, 7.2374e-02, 8.0434e-02, 2.8246e-02,
        4.3204e-02, 2.5841e-02, 1.0959e-01, 3.9964e-02, 3.5321e-02, 3.9309e-02,
        4.2307e-02, 3.1660e-02, 3.1548e-02, 4.9587e-02, 4.0164e-02, 3.3781e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,364][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0004, 0.0736, 0.0675, 0.0729, 0.0864, 0.0574, 0.0566, 0.0467, 0.0571,
        0.0615, 0.0505, 0.0543, 0.0628, 0.0502, 0.0512, 0.0563, 0.0423, 0.0523],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,365][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([9.7186e-01, 5.8188e-04, 4.8972e-04, 1.9964e-04, 3.6195e-04, 5.0317e-04,
        7.1902e-04, 8.7250e-04, 1.0257e-03, 7.7908e-04, 3.7994e-03, 3.5177e-03,
        1.0331e-03, 9.5892e-04, 1.4421e-03, 2.8185e-03, 6.4496e-03, 2.5896e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,365][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([2.1603e-01, 6.2631e-06, 2.3232e-06, 5.4453e-07, 2.1867e-06, 1.0792e-05,
        1.1444e-06, 9.6557e-05, 1.8980e-05, 9.4138e-05, 9.4941e-05, 2.2200e-04,
        1.5577e-03, 1.7440e-01, 2.2676e-04, 5.0005e-01, 5.7093e-02, 5.0103e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,365][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0206, 0.0450, 0.0539, 0.0532, 0.0548, 0.0564, 0.0537, 0.0686, 0.0604,
        0.0602, 0.0593, 0.0597, 0.0582, 0.0549, 0.0533, 0.0697, 0.0575, 0.0604],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,366][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.2248, 0.0122, 0.0322, 0.0046, 0.0158, 0.0245, 0.0161, 0.0432, 0.0244,
        0.0501, 0.1034, 0.0558, 0.0548, 0.0357, 0.0146, 0.0433, 0.0412, 0.2033],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,366][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0003, 0.0432, 0.0799, 0.0399, 0.1087, 0.0450, 0.0848, 0.0235, 0.0617,
        0.0702, 0.0732, 0.0338, 0.0306, 0.0384, 0.1106, 0.0707, 0.0678, 0.0178],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,370][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0195, 0.0354, 0.0057, 0.0021, 0.0035, 0.0025, 0.0020, 0.0062, 0.0078,
        0.0060, 0.0127, 0.0240, 0.0294, 0.2232, 0.0173, 0.3354, 0.1618, 0.1056],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,371][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.2876, 0.0292, 0.0104, 0.0105, 0.0150, 0.0264, 0.0302, 0.0378, 0.0294,
        0.0227, 0.0266, 0.0544, 0.0362, 0.0865, 0.0263, 0.0953, 0.1099, 0.0656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,371][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([2.7777e-05, 3.9904e-03, 9.7155e-03, 8.9562e-02, 1.5371e-01, 1.1577e-01,
        4.5091e-02, 5.6066e-02, 1.5046e-01, 7.5645e-02, 3.1604e-02, 3.7667e-02,
        2.7659e-02, 1.0005e-02, 1.6446e-01, 1.3100e-02, 1.1217e-02, 4.2515e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,372][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([1.2616e-03, 2.4335e-05, 3.9555e-06, 8.0271e-07, 4.0475e-06, 3.8609e-05,
        2.1690e-06, 1.2497e-04, 4.3577e-05, 3.8041e-04, 1.8874e-04, 5.1616e-04,
        2.8444e-03, 1.0130e-01, 3.2102e-04, 7.7290e-01, 5.1092e-02, 6.8952e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,372][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0157, 0.0608, 0.0240, 0.0584, 0.0481, 0.0851, 0.0564, 0.0789, 0.0879,
        0.0641, 0.0594, 0.0622, 0.0494, 0.0510, 0.0360, 0.0589, 0.0579, 0.0459],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,373][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0003, 0.2058, 0.1014, 0.0791, 0.0636, 0.0292, 0.0409, 0.0250, 0.0774,
        0.0301, 0.0343, 0.0375, 0.0394, 0.0325, 0.0268, 0.0420, 0.0363, 0.0303,
        0.0681], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,376][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0750, 0.0651, 0.0681, 0.0793, 0.0559, 0.0570, 0.0436, 0.0539,
        0.0579, 0.0509, 0.0536, 0.0586, 0.0482, 0.0473, 0.0545, 0.0425, 0.0495,
        0.0388], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,377][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.9605e-01, 7.0762e-05, 1.2174e-04, 1.8236e-05, 5.5943e-05, 3.0057e-05,
        6.6626e-05, 1.3804e-04, 9.1650e-05, 3.4201e-05, 3.4104e-04, 4.3738e-04,
        1.5517e-04, 1.3119e-04, 2.2799e-04, 3.7554e-04, 9.4854e-04, 3.4784e-04,
        3.6107e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,377][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.5454e-01, 2.7727e-06, 7.0780e-07, 1.4724e-07, 3.7687e-07, 2.3944e-06,
        2.2512e-07, 1.2420e-05, 3.2490e-06, 2.7112e-05, 1.9739e-05, 4.4491e-05,
        2.1185e-04, 5.2263e-02, 3.2889e-05, 1.3913e-01, 9.7692e-03, 1.4794e-02,
        2.9149e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,378][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0227, 0.0441, 0.0503, 0.0487, 0.0505, 0.0523, 0.0510, 0.0651, 0.0563,
        0.0560, 0.0544, 0.0569, 0.0553, 0.0519, 0.0509, 0.0641, 0.0553, 0.0570,
        0.0573], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,378][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1392, 0.0094, 0.0171, 0.0038, 0.0174, 0.0271, 0.0172, 0.0541, 0.0274,
        0.0600, 0.0852, 0.0585, 0.0516, 0.0298, 0.0139, 0.0183, 0.0374, 0.3013,
        0.0312], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,379][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0010, 0.0195, 0.0872, 0.0197, 0.0967, 0.0285, 0.0653, 0.0252, 0.0614,
        0.0490, 0.0472, 0.0423, 0.0429, 0.0294, 0.1798, 0.0386, 0.0776, 0.0236,
        0.0651], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,383][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0741, 0.0243, 0.0059, 0.0017, 0.0021, 0.0026, 0.0015, 0.0057, 0.0051,
        0.0071, 0.0107, 0.0165, 0.0179, 0.1784, 0.0114, 0.2873, 0.0994, 0.0714,
        0.1770], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,383][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4759, 0.0154, 0.0069, 0.0047, 0.0106, 0.0131, 0.0198, 0.0349, 0.0170,
        0.0129, 0.0234, 0.0317, 0.0202, 0.0620, 0.0224, 0.0509, 0.0814, 0.0408,
        0.0558], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,384][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.0484e-04, 3.5047e-03, 9.9066e-03, 5.0595e-02, 7.2134e-02, 8.7433e-02,
        4.2950e-02, 5.4724e-02, 1.8769e-01, 4.3092e-02, 3.6145e-02, 6.4876e-02,
        3.9444e-02, 1.5095e-02, 2.1577e-01, 9.0318e-03, 1.6369e-02, 8.2050e-03,
        4.2933e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,384][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.3167e-02, 4.0684e-05, 4.1925e-06, 8.3771e-07, 3.2214e-06, 2.8891e-05,
        1.6483e-06, 9.2692e-05, 3.0983e-05, 1.8371e-04, 1.9698e-04, 4.0720e-04,
        1.7250e-03, 1.3815e-01, 2.4563e-04, 5.0599e-01, 4.6461e-02, 8.6201e-02,
        2.0707e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,385][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0161, 0.0574, 0.0244, 0.0541, 0.0466, 0.0807, 0.0524, 0.0729, 0.0803,
        0.0595, 0.0552, 0.0591, 0.0470, 0.0477, 0.0356, 0.0553, 0.0546, 0.0433,
        0.0577], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,436][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:53,437][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,437][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,437][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,438][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,438][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,438][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,439][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,439][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,439][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,440][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,440][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,440][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,440][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9995e-01, 4.6658e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,441][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1506, 0.8494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,441][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9995e-01, 5.0052e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,444][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9940, 0.0060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,445][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9682, 0.0318], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,445][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9901e-01, 9.8763e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,445][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0723, 0.9277], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,446][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3440, 0.6560], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,446][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9922, 0.0078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,446][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0150, 0.9850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,447][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1511, 0.8489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,447][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1936, 0.8064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,449][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.9972, 0.0010, 0.0018], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,450][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.0036, 0.6728, 0.3236], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,452][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.9975, 0.0014, 0.0011], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,453][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.9023, 0.0522, 0.0454], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,454][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.6640, 0.1253, 0.2107], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,455][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.9612, 0.0231, 0.0158], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,455][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0039, 0.5244, 0.4717], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,455][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.0770, 0.7967, 0.1263], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,456][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.8008, 0.1584, 0.0408], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,456][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0018, 0.6635, 0.3348], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,456][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0108, 0.7728, 0.2164], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,457][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.0110, 0.7317, 0.2573], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,457][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9923e-01, 1.8016e-04, 4.6077e-04, 1.3365e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,458][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0187, 0.3680, 0.3469, 0.2664], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,459][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9960e-01, 1.8314e-04, 1.7795e-04, 4.0924e-05], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,460][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9912, 0.0016, 0.0060, 0.0012], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,462][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9361, 0.0227, 0.0300, 0.0112], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,463][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9466e-01, 2.9046e-03, 1.6343e-03, 7.9754e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,464][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0050, 0.2662, 0.4831, 0.2457], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,465][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0425, 0.7696, 0.1413, 0.0466], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,465][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8905, 0.0730, 0.0157, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,465][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([7.0964e-04, 1.2075e-01, 1.5309e-01, 7.2545e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,466][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1005, 0.4457, 0.3779, 0.0759], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,466][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0032, 0.2394, 0.2547, 0.5027], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,466][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([9.9703e-01, 5.1837e-04, 1.3675e-03, 6.4915e-04, 4.3202e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,467][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0025, 0.1524, 0.2602, 0.2064, 0.3786], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,467][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([9.9825e-01, 4.7267e-04, 6.5641e-04, 2.1610e-04, 4.0768e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,468][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.9426, 0.0050, 0.0109, 0.0064, 0.0351], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,469][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.6027, 0.0526, 0.1082, 0.0442, 0.1925], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,471][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.9824, 0.0064, 0.0045, 0.0024, 0.0043], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,473][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0012, 0.1458, 0.2614, 0.2204, 0.3712], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,474][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0278, 0.6877, 0.1054, 0.1005, 0.0786], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,475][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.6919, 0.1107, 0.0329, 0.0479, 0.1165], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,475][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([1.1507e-04, 5.5044e-02, 7.2795e-02, 4.3173e-01, 4.4032e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,475][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0401, 0.3045, 0.1953, 0.1022, 0.3579], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,476][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0033, 0.1911, 0.1968, 0.3837, 0.2251], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,476][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([9.9158e-01, 1.0843e-03, 2.1874e-03, 1.1867e-03, 8.8634e-04, 3.0797e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,477][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0044, 0.1084, 0.2370, 0.1406, 0.4415, 0.0681], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,477][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([9.9474e-01, 1.1447e-03, 1.3646e-03, 5.1606e-04, 1.0382e-03, 1.1962e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,477][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.9438, 0.0029, 0.0048, 0.0014, 0.0082, 0.0389], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,478][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6060, 0.0538, 0.1152, 0.0432, 0.1260, 0.0558], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,480][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9680, 0.0083, 0.0035, 0.0019, 0.0018, 0.0166], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,481][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0006, 0.0950, 0.2019, 0.2110, 0.3398, 0.1517], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,483][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0226, 0.5477, 0.1645, 0.0697, 0.1155, 0.0800], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,484][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5311, 0.1800, 0.0607, 0.0551, 0.0737, 0.0992], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,485][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([5.8927e-05, 2.1385e-02, 3.3172e-02, 2.3781e-01, 3.0640e-01, 4.0117e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,485][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0375, 0.0974, 0.0602, 0.0140, 0.1023, 0.6886], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,486][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0010, 0.0854, 0.0937, 0.1475, 0.1100, 0.5624], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,486][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.9501e-01, 6.7852e-04, 8.5397e-04, 5.0329e-04, 3.5080e-04, 1.0327e-03,
        1.5693e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,486][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0031, 0.1214, 0.2091, 0.1380, 0.4025, 0.0623, 0.0636],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,487][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.9412e-01, 1.2045e-03, 1.1563e-03, 4.0303e-04, 8.6257e-04, 9.1609e-04,
        1.3418e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,487][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5302, 0.0040, 0.0132, 0.0074, 0.0436, 0.3834, 0.0182],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,488][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.7520, 0.0259, 0.0500, 0.0217, 0.0827, 0.0280, 0.0397],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,489][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9630, 0.0074, 0.0043, 0.0023, 0.0024, 0.0135, 0.0071],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,490][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0005, 0.1389, 0.1478, 0.1969, 0.2375, 0.1050, 0.1734],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,492][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0101, 0.4976, 0.1354, 0.0990, 0.1105, 0.1056, 0.0419],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,493][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5891, 0.1404, 0.0380, 0.0531, 0.0489, 0.0784, 0.0520],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,494][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.0813e-05, 2.3600e-02, 2.7446e-02, 2.4711e-01, 2.6352e-01, 3.1117e-01,
        1.2709e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,495][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0011, 0.0361, 0.0245, 0.0204, 0.0711, 0.8239, 0.0230],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,496][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0011, 0.1225, 0.1179, 0.2393, 0.1074, 0.3075, 0.1042],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,496][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.9729, 0.0027, 0.0036, 0.0020, 0.0017, 0.0045, 0.0077, 0.0050],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,496][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0039, 0.2154, 0.1420, 0.0833, 0.2806, 0.1058, 0.1496, 0.0194],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,497][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([9.8246e-01, 3.3937e-03, 1.6749e-03, 7.3320e-04, 2.0879e-03, 1.6242e-03,
        2.8402e-03, 5.1866e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,497][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.7488, 0.0023, 0.0038, 0.0014, 0.0106, 0.0392, 0.0071, 0.1867],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,497][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.1711, 0.0600, 0.1306, 0.0442, 0.2623, 0.0633, 0.1183, 0.1501],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,498][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.9308, 0.0082, 0.0081, 0.0028, 0.0035, 0.0171, 0.0082, 0.0213],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,498][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([2.8075e-04, 1.4911e-01, 1.4177e-01, 6.5558e-02, 1.9359e-01, 7.2992e-02,
        3.0179e-01, 7.4902e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,500][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0142, 0.4355, 0.1234, 0.0748, 0.0805, 0.1213, 0.0394, 0.1109],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,502][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.2642, 0.1734, 0.0414, 0.0571, 0.0604, 0.1535, 0.0743, 0.1757],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,503][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([3.7781e-05, 1.8388e-02, 4.1154e-02, 1.1267e-01, 3.4060e-01, 2.4501e-01,
        1.5513e-01, 8.7016e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,504][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0161, 0.0346, 0.0300, 0.0110, 0.0511, 0.4646, 0.0279, 0.3648],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,505][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([2.0751e-04, 9.2032e-02, 4.4476e-02, 1.2554e-01, 5.9477e-02, 3.8617e-01,
        1.4355e-01, 1.4856e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,506][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([9.9461e-01, 2.9128e-04, 1.0830e-03, 2.8790e-04, 1.7812e-04, 5.7053e-04,
        1.1004e-03, 1.1987e-03, 6.7809e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,506][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0017, 0.0924, 0.2063, 0.0813, 0.3517, 0.0637, 0.1219, 0.0231, 0.0579],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,506][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([9.9664e-01, 4.5511e-04, 7.1292e-04, 1.0611e-04, 2.8514e-04, 2.5744e-04,
        3.6471e-04, 6.6624e-04, 5.1490e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,507][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.7160, 0.0009, 0.0020, 0.0011, 0.0046, 0.0291, 0.0047, 0.1913, 0.0503],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,507][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.4568, 0.0343, 0.0775, 0.0240, 0.1214, 0.0327, 0.0654, 0.0698, 0.1181],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,508][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.9480, 0.0051, 0.0043, 0.0018, 0.0029, 0.0122, 0.0050, 0.0119, 0.0088],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,508][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0005, 0.0742, 0.1937, 0.0635, 0.2598, 0.0609, 0.1461, 0.0595, 0.1418],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,509][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0570, 0.3155, 0.0824, 0.0596, 0.0520, 0.0979, 0.0369, 0.1585, 0.1402],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,510][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.5408, 0.1061, 0.0256, 0.0247, 0.0369, 0.0573, 0.0509, 0.1131, 0.0447],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,512][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([4.4444e-05, 7.2680e-03, 2.3770e-02, 8.1133e-02, 1.4196e-01, 1.7460e-01,
        1.1846e-01, 1.0116e-01, 3.5161e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,513][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0139, 0.0096, 0.0088, 0.0033, 0.0231, 0.2777, 0.0159, 0.3363, 0.3114],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,514][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0007, 0.0349, 0.0600, 0.0821, 0.0582, 0.3148, 0.1434, 0.1035, 0.2023],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,516][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.9534, 0.0047, 0.0028, 0.0030, 0.0020, 0.0052, 0.0089, 0.0065, 0.0056,
        0.0079], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,516][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0011, 0.1043, 0.1870, 0.1080, 0.2875, 0.1026, 0.0861, 0.0283, 0.0588,
        0.0364], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,517][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([9.8693e-01, 1.9727e-03, 1.2757e-03, 5.6510e-04, 8.3294e-04, 8.8476e-04,
        1.6957e-03, 2.8346e-03, 1.6106e-03, 1.4012e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,517][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.4964, 0.0012, 0.0012, 0.0007, 0.0026, 0.0182, 0.0027, 0.1588, 0.0576,
        0.2607], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,517][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1027, 0.0694, 0.1373, 0.0457, 0.2194, 0.0452, 0.0708, 0.0662, 0.1472,
        0.0960], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,518][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.8486, 0.0086, 0.0124, 0.0057, 0.0068, 0.0252, 0.0128, 0.0345, 0.0187,
        0.0267], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,518][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([1.4433e-04, 6.7051e-02, 9.4556e-02, 7.7040e-02, 1.5098e-01, 5.5462e-02,
        1.6517e-01, 5.6310e-02, 1.8122e-01, 1.5206e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,519][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0159, 0.3603, 0.0500, 0.0390, 0.0579, 0.0789, 0.0312, 0.0973, 0.1677,
        0.1019], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,520][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1607, 0.1730, 0.0478, 0.0480, 0.0520, 0.1018, 0.0715, 0.1955, 0.0716,
        0.0782], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,521][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.0611e-05, 1.1475e-02, 1.9740e-02, 1.0222e-01, 1.9473e-01, 1.3242e-01,
        9.4604e-02, 5.8298e-02, 2.6543e-01, 1.2106e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,523][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0037, 0.0066, 0.0042, 0.0009, 0.0052, 0.0532, 0.0043, 0.1278, 0.1302,
        0.6640], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,524][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.4467e-04, 1.0512e-01, 8.1033e-02, 8.9748e-02, 7.0604e-02, 2.3189e-01,
        9.8634e-02, 9.5162e-02, 1.3633e-01, 9.1337e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,525][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.9504, 0.0019, 0.0048, 0.0024, 0.0016, 0.0035, 0.0051, 0.0064, 0.0044,
        0.0077, 0.0118], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,526][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0008, 0.0870, 0.1808, 0.1061, 0.2459, 0.0566, 0.0784, 0.0228, 0.1047,
        0.0258, 0.0912], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,526][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([9.7268e-01, 1.8791e-03, 2.9511e-03, 8.5078e-04, 1.4553e-03, 1.7803e-03,
        2.2608e-03, 3.6082e-03, 4.0011e-03, 2.6555e-03, 5.8767e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,527][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.5499, 0.0007, 0.0014, 0.0008, 0.0030, 0.0280, 0.0032, 0.1083, 0.0328,
        0.1654, 0.1065], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,527][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1550, 0.0367, 0.0427, 0.0525, 0.1062, 0.0403, 0.1034, 0.0744, 0.2061,
        0.0803, 0.1023], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,528][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.8324, 0.0070, 0.0098, 0.0041, 0.0038, 0.0233, 0.0098, 0.0193, 0.0136,
        0.0174, 0.0595], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,528][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0004, 0.0569, 0.1013, 0.0557, 0.1640, 0.0871, 0.1422, 0.0628, 0.1276,
        0.1304, 0.0714], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,528][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0239, 0.2347, 0.1043, 0.0535, 0.0592, 0.0777, 0.0245, 0.0971, 0.0960,
        0.1268, 0.1022], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,529][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2261, 0.1491, 0.0365, 0.0495, 0.0502, 0.0753, 0.0651, 0.1652, 0.0472,
        0.0565, 0.0794], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,531][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([2.6670e-05, 1.1189e-02, 2.1289e-02, 8.7934e-02, 1.8711e-01, 1.5066e-01,
        6.2975e-02, 6.6207e-02, 2.7339e-01, 1.1130e-01, 2.7924e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,532][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0075, 0.0041, 0.0039, 0.0015, 0.0065, 0.0891, 0.0047, 0.1046, 0.0840,
        0.5431, 0.1509], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,534][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0005, 0.0204, 0.0416, 0.0685, 0.0376, 0.2246, 0.1033, 0.1331, 0.2270,
        0.0605, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,535][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.8322e-01, 4.7670e-04, 1.6913e-03, 5.1453e-04, 3.4213e-04, 8.1708e-04,
        1.3440e-03, 1.2941e-03, 1.0305e-03, 9.3430e-04, 3.5297e-03, 4.8017e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,536][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0021, 0.1029, 0.1917, 0.0678, 0.2424, 0.0419, 0.0620, 0.0232, 0.0460,
        0.0486, 0.1005, 0.0708], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,536][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([9.8983e-01, 4.7042e-04, 8.0799e-04, 1.8589e-04, 4.3401e-04, 3.1024e-04,
        5.3514e-04, 9.6368e-04, 9.1794e-04, 5.9309e-04, 1.8667e-03, 3.0885e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,537][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([6.6888e-01, 3.1506e-04, 5.0609e-04, 2.1698e-04, 9.1514e-04, 7.5712e-03,
        7.2050e-04, 2.9863e-02, 1.4510e-02, 8.9794e-02, 6.6561e-02, 1.2014e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,537][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3483, 0.0274, 0.0468, 0.0184, 0.0698, 0.0217, 0.0586, 0.0681, 0.0763,
        0.0618, 0.1280, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,538][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9000, 0.0036, 0.0043, 0.0015, 0.0022, 0.0114, 0.0044, 0.0092, 0.0064,
        0.0090, 0.0256, 0.0225], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,538][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0004, 0.0711, 0.1339, 0.0484, 0.1711, 0.0512, 0.1151, 0.0417, 0.0979,
        0.1341, 0.0760, 0.0591], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,538][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0358, 0.1826, 0.0698, 0.0447, 0.0457, 0.0459, 0.0189, 0.0472, 0.1024,
        0.1088, 0.1072, 0.1908], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,539][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.4622, 0.0699, 0.0298, 0.0248, 0.0324, 0.0518, 0.0402, 0.0828, 0.0348,
        0.0334, 0.0677, 0.0702], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,540][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.0259e-05, 7.6949e-03, 1.6801e-02, 6.4641e-02, 1.4748e-01, 1.2139e-01,
        7.1629e-02, 8.6790e-02, 2.2999e-01, 1.2317e-01, 4.6352e-02, 8.4030e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,542][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0104, 0.0020, 0.0014, 0.0008, 0.0022, 0.0503, 0.0017, 0.0804, 0.0453,
        0.2408, 0.1772, 0.3875], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,544][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0007, 0.0374, 0.0593, 0.0683, 0.0336, 0.2201, 0.0954, 0.0895, 0.1395,
        0.0782, 0.0972, 0.0807], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,545][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([9.6904e-01, 6.5272e-04, 1.9525e-03, 1.1399e-03, 6.7502e-04, 1.5134e-03,
        2.3784e-03, 2.0454e-03, 1.9060e-03, 2.9034e-03, 3.3360e-03, 9.4260e-03,
        3.0307e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,546][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([0.0009, 0.0944, 0.1250, 0.0672, 0.2920, 0.0478, 0.0445, 0.0215, 0.0587,
        0.0488, 0.0881, 0.0562, 0.0548], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,546][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([9.6831e-01, 1.6653e-03, 1.0120e-03, 5.2855e-04, 9.0412e-04, 6.1499e-04,
        1.7020e-03, 1.9754e-03, 2.4269e-03, 2.5785e-03, 6.7820e-03, 8.6653e-03,
        2.8313e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,547][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([5.3438e-01, 4.9377e-05, 7.9492e-05, 5.3384e-05, 1.5990e-04, 1.9580e-03,
        2.4132e-04, 1.1620e-02, 4.1321e-03, 1.6316e-02, 1.7192e-02, 5.7208e-02,
        3.5661e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,547][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.1106, 0.0127, 0.0487, 0.0187, 0.1026, 0.0188, 0.0403, 0.0456, 0.1644,
        0.0710, 0.1902, 0.1267, 0.0498], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,548][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.9127, 0.0032, 0.0025, 0.0011, 0.0011, 0.0078, 0.0038, 0.0064, 0.0039,
        0.0051, 0.0207, 0.0155, 0.0162], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,548][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([2.2224e-04, 4.6216e-02, 6.3803e-02, 4.0802e-02, 5.3035e-02, 4.9937e-02,
        9.6671e-02, 4.6568e-02, 2.4350e-01, 8.4106e-02, 1.5669e-01, 7.9470e-02,
        3.8980e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,549][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0265, 0.1202, 0.0307, 0.0209, 0.0265, 0.0308, 0.0134, 0.0453, 0.0653,
        0.0639, 0.1094, 0.1876, 0.2595], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,550][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.3288, 0.0397, 0.0168, 0.0095, 0.0169, 0.0440, 0.0429, 0.0916, 0.0562,
        0.0710, 0.1059, 0.0921, 0.0846], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,551][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([3.7617e-05, 8.1076e-03, 1.1652e-02, 8.6963e-02, 1.2769e-01, 9.7554e-02,
        5.0070e-02, 6.7606e-02, 2.4530e-01, 1.6305e-01, 6.1788e-02, 4.6266e-02,
        3.3920e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,552][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([8.1614e-03, 2.7685e-04, 2.6413e-04, 9.7242e-05, 3.1010e-04, 7.1575e-03,
        3.2296e-04, 1.2151e-02, 1.0364e-02, 5.9289e-02, 5.7973e-02, 1.3248e-01,
        7.1116e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,554][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.0004, 0.0307, 0.0473, 0.0659, 0.0297, 0.1907, 0.0817, 0.1002, 0.1410,
        0.0802, 0.0879, 0.0762, 0.0682], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,555][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.9305e-01, 9.5823e-05, 8.6527e-04, 1.3743e-04, 1.5358e-04, 3.5083e-04,
        4.1244e-04, 2.6789e-04, 2.3685e-04, 1.9743e-04, 7.1321e-04, 1.8346e-03,
        3.7549e-04, 1.3070e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,556][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0030, 0.0732, 0.1744, 0.0524, 0.3386, 0.0667, 0.0491, 0.0135, 0.0264,
        0.0382, 0.0604, 0.0417, 0.0416, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,557][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([9.9607e-01, 1.4912e-04, 3.9826e-04, 4.7457e-05, 1.5656e-04, 1.3508e-04,
        1.3997e-04, 2.8264e-04, 2.0815e-04, 1.7804e-04, 5.0336e-04, 8.7935e-04,
        4.4525e-04, 4.0503e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,557][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.5037e-01, 7.8549e-06, 2.2776e-06, 4.4335e-07, 1.2266e-06, 6.0442e-06,
        5.2899e-07, 4.3030e-05, 5.3423e-06, 5.5529e-05, 3.9060e-05, 8.4815e-05,
        6.2325e-04, 4.8766e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,557][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2425, 0.0201, 0.0609, 0.0269, 0.0748, 0.0240, 0.0363, 0.0384, 0.0496,
        0.0331, 0.0862, 0.0835, 0.0522, 0.1715], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,558][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.3826e-01, 2.4749e-03, 2.7887e-03, 7.8530e-04, 1.3634e-03, 4.3149e-03,
        2.1659e-03, 5.3480e-03, 2.8300e-03, 3.4207e-03, 9.5185e-03, 9.9550e-03,
        1.0476e-02, 6.2947e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,558][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0004, 0.0290, 0.1617, 0.0366, 0.1875, 0.0557, 0.1075, 0.0333, 0.0659,
        0.0835, 0.0496, 0.0589, 0.0734, 0.0570], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,559][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0853, 0.0963, 0.0142, 0.0047, 0.0102, 0.0062, 0.0045, 0.0111, 0.0198,
        0.0211, 0.0297, 0.0508, 0.0690, 0.5771], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,560][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.4292, 0.0340, 0.0234, 0.0149, 0.0364, 0.0455, 0.0318, 0.0585, 0.0287,
        0.0258, 0.0559, 0.0497, 0.0487, 0.1174], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,561][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([2.9435e-05, 6.7957e-03, 1.8382e-02, 6.9354e-02, 1.7594e-01, 1.3412e-01,
        6.9567e-02, 6.8549e-02, 1.7194e-01, 8.3636e-02, 4.4829e-02, 7.0519e-02,
        6.2301e-02, 2.4039e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,562][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([6.2101e-02, 7.6499e-04, 6.9916e-05, 1.1072e-05, 4.5453e-05, 3.5564e-04,
        2.5757e-05, 9.5717e-04, 4.0469e-04, 3.2351e-03, 1.6648e-03, 3.7222e-03,
        1.5584e-02, 9.1106e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,564][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0010, 0.0219, 0.0425, 0.0647, 0.0312, 0.1625, 0.0734, 0.1189, 0.0973,
        0.0859, 0.0741, 0.0796, 0.0646, 0.0823], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,565][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([9.3620e-01, 8.5759e-04, 6.9418e-03, 1.9606e-03, 1.3122e-03, 3.1363e-03,
        3.3976e-03, 3.0964e-03, 3.0707e-03, 2.5615e-03, 7.2600e-03, 1.2623e-02,
        4.6636e-03, 1.0414e-02, 2.5083e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,566][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0003, 0.0564, 0.1519, 0.0859, 0.2029, 0.0551, 0.0557, 0.0156, 0.0491,
        0.0240, 0.0807, 0.0571, 0.0502, 0.0340, 0.0812], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,567][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([9.2612e-01, 1.1511e-03, 2.9920e-03, 7.9571e-04, 1.6476e-03, 1.5152e-03,
        2.7371e-03, 2.5641e-03, 4.4699e-03, 5.1341e-03, 1.2907e-02, 1.2866e-02,
        7.2832e-03, 6.1972e-03, 1.1614e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,567][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([1.3837e-03, 3.9572e-06, 4.1402e-06, 2.3704e-06, 6.7493e-06, 5.6516e-05,
        5.8788e-06, 1.6657e-04, 1.2019e-04, 4.4325e-04, 3.8736e-04, 1.5673e-03,
        8.4748e-03, 9.8646e-01, 9.1830e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,568][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0915, 0.0144, 0.0406, 0.0270, 0.0763, 0.0228, 0.0316, 0.0228, 0.0634,
        0.0700, 0.0861, 0.1043, 0.0392, 0.1182, 0.1917], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,568][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.6775, 0.0077, 0.0100, 0.0037, 0.0074, 0.0329, 0.0133, 0.0169, 0.0145,
        0.0160, 0.0629, 0.0465, 0.0549, 0.0240, 0.0118], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,568][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0002, 0.0335, 0.0731, 0.0415, 0.0923, 0.0404, 0.1037, 0.0396, 0.0898,
        0.0761, 0.1023, 0.0629, 0.0765, 0.0329, 0.1353], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,569][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0036, 0.0346, 0.0118, 0.0114, 0.0056, 0.0101, 0.0047, 0.0131, 0.0174,
        0.0183, 0.0261, 0.0674, 0.0776, 0.6773, 0.0209], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,571][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0486, 0.0307, 0.0162, 0.0185, 0.0573, 0.0419, 0.0668, 0.1001, 0.0393,
        0.0535, 0.0740, 0.1182, 0.0884, 0.1169, 0.1296], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,572][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([2.4351e-05, 1.0116e-02, 1.8228e-02, 1.0546e-01, 8.8989e-02, 1.4445e-01,
        6.0490e-02, 4.7738e-02, 1.4719e-01, 4.0712e-02, 4.3441e-02, 7.0358e-02,
        5.2154e-02, 1.8052e-02, 1.5260e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,573][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([5.1686e-05, 1.7756e-05, 8.3318e-06, 2.8037e-06, 1.1644e-05, 1.1831e-04,
        1.3353e-05, 3.7097e-04, 2.5961e-04, 1.1931e-03, 7.6394e-04, 2.9663e-03,
        2.2586e-02, 9.6967e-01, 1.9662e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,574][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0008, 0.0341, 0.0582, 0.0620, 0.0301, 0.1105, 0.0710, 0.0934, 0.1477,
        0.1107, 0.0677, 0.0636, 0.0568, 0.0622, 0.0313], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,575][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([9.5794e-01, 2.7744e-04, 2.0816e-03, 3.9073e-04, 4.6922e-04, 1.2871e-03,
        1.5465e-03, 1.3847e-03, 9.1402e-04, 1.5763e-03, 2.4186e-03, 6.4644e-03,
        2.0040e-03, 7.1409e-03, 1.5438e-03, 1.2561e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,576][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0016, 0.0308, 0.0965, 0.0509, 0.1644, 0.0459, 0.0612, 0.0223, 0.0600,
        0.0235, 0.0841, 0.0737, 0.0569, 0.0417, 0.0650, 0.1215],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,577][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([9.7517e-01, 5.7143e-04, 1.0249e-03, 2.0002e-04, 4.1446e-04, 6.2765e-04,
        7.1490e-04, 1.3779e-03, 9.0947e-04, 8.7907e-04, 2.4699e-03, 3.8331e-03,
        2.0765e-03, 1.5449e-03, 1.8988e-03, 6.2919e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,577][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([4.8474e-01, 9.6199e-06, 2.6425e-06, 3.1956e-07, 1.7402e-06, 6.3327e-06,
        1.0412e-06, 5.5284e-05, 1.2969e-05, 6.8818e-05, 7.6101e-05, 1.6364e-04,
        9.0825e-04, 2.1279e-01, 2.1817e-04, 3.0094e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,578][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0927, 0.0125, 0.0399, 0.0192, 0.0523, 0.0186, 0.0311, 0.0465, 0.0631,
        0.0521, 0.0912, 0.0728, 0.0754, 0.1311, 0.1220, 0.0795],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,578][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.9211, 0.0023, 0.0023, 0.0011, 0.0009, 0.0050, 0.0023, 0.0032, 0.0026,
        0.0034, 0.0127, 0.0101, 0.0121, 0.0084, 0.0016, 0.0110],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,579][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0002, 0.0257, 0.0565, 0.0303, 0.0923, 0.0271, 0.0981, 0.0325, 0.0805,
        0.0761, 0.0703, 0.0660, 0.0619, 0.0607, 0.1913, 0.0305],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,579][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0311, 0.0262, 0.0060, 0.0027, 0.0034, 0.0045, 0.0018, 0.0047, 0.0096,
        0.0084, 0.0175, 0.0274, 0.0356, 0.2965, 0.0160, 0.5087],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,581][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2702, 0.0478, 0.0139, 0.0158, 0.0235, 0.0338, 0.0248, 0.0584, 0.0243,
        0.0235, 0.0357, 0.0637, 0.0573, 0.1217, 0.0428, 0.1429],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,582][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([3.3333e-05, 2.3984e-03, 8.8908e-03, 3.2215e-02, 7.3266e-02, 7.9359e-02,
        4.0881e-02, 4.6349e-02, 1.5353e-01, 6.1150e-02, 7.0198e-02, 5.8316e-02,
        6.0776e-02, 1.6337e-02, 2.8955e-01, 6.7516e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,583][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([5.3955e-03, 4.8850e-05, 9.3567e-06, 1.1127e-06, 5.0255e-06, 4.2939e-05,
        2.6187e-06, 1.5211e-04, 5.9437e-05, 3.2241e-04, 2.1214e-04, 4.6734e-04,
        3.6560e-03, 1.4232e-01, 3.4037e-04, 8.4696e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,584][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0006, 0.0188, 0.0266, 0.0595, 0.0260, 0.1494, 0.0781, 0.0566, 0.0864,
        0.0320, 0.0514, 0.0803, 0.0520, 0.0636, 0.0468, 0.1718],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,585][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.9105e-01, 7.8706e-05, 3.7809e-04, 1.0521e-04, 5.9934e-05, 2.4598e-04,
        3.6301e-04, 2.9788e-04, 1.9050e-04, 1.3444e-04, 8.4947e-04, 1.2356e-03,
        2.9272e-04, 7.9693e-04, 1.3704e-04, 1.7269e-03, 2.0553e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,587][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0027, 0.0552, 0.1371, 0.0540, 0.2471, 0.0291, 0.0393, 0.0135, 0.0237,
        0.0233, 0.0537, 0.0361, 0.0327, 0.0203, 0.0846, 0.0857, 0.0617],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,587][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.9393e-01, 1.0562e-04, 2.0582e-04, 3.7923e-05, 8.5678e-05, 9.2719e-05,
        1.3211e-04, 2.3398e-04, 1.8979e-04, 9.6765e-05, 5.9952e-04, 7.5673e-04,
        3.4809e-04, 3.0492e-04, 4.5287e-04, 7.6190e-04, 1.6625e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,588][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.6426e-01, 1.6371e-06, 1.1319e-06, 3.1354e-07, 8.6667e-07, 9.3890e-06,
        4.4406e-07, 3.7362e-05, 1.0817e-05, 5.7790e-05, 6.3920e-05, 1.0611e-04,
        6.0051e-04, 1.3885e-01, 1.0824e-04, 5.7168e-01, 2.4202e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,588][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4145, 0.0065, 0.0248, 0.0078, 0.0252, 0.0097, 0.0177, 0.0396, 0.0433,
        0.0174, 0.0715, 0.0689, 0.0298, 0.0643, 0.0750, 0.0313, 0.0527],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,588][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.1443e-01, 2.5627e-03, 2.2789e-03, 7.4325e-04, 1.1620e-03, 5.0813e-03,
        3.0128e-03, 5.2927e-03, 2.9005e-03, 4.5716e-03, 1.3193e-02, 1.0604e-02,
        9.2622e-03, 7.0138e-03, 1.7493e-03, 4.4777e-03, 1.1668e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,589][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0005, 0.0246, 0.0727, 0.0468, 0.0858, 0.0426, 0.0853, 0.0338, 0.0902,
        0.0741, 0.0677, 0.0727, 0.0398, 0.0362, 0.1193, 0.0303, 0.0776],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,589][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0458, 0.0374, 0.0108, 0.0044, 0.0045, 0.0040, 0.0021, 0.0058, 0.0098,
        0.0118, 0.0117, 0.0213, 0.0309, 0.2652, 0.0181, 0.3748, 0.1416],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,591][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6001, 0.0236, 0.0109, 0.0080, 0.0101, 0.0178, 0.0145, 0.0325, 0.0144,
        0.0124, 0.0266, 0.0257, 0.0228, 0.0511, 0.0166, 0.0506, 0.0622],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,593][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.6992e-05, 4.1709e-03, 1.0767e-02, 7.5299e-02, 9.6450e-02, 8.4478e-02,
        4.1446e-02, 5.6887e-02, 1.5020e-01, 4.9691e-02, 4.2043e-02, 6.4407e-02,
        3.4807e-02, 1.7024e-02, 2.5283e-01, 6.0225e-03, 1.3403e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,594][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.6896e-04, 2.1417e-05, 3.0231e-06, 1.2111e-06, 2.6324e-06, 3.7073e-05,
        1.6384e-06, 8.6614e-05, 4.1380e-05, 1.8488e-04, 1.6276e-04, 3.6949e-04,
        1.8534e-03, 1.6090e-01, 2.5820e-04, 7.7797e-01, 5.7437e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,595][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0009, 0.0303, 0.0452, 0.0664, 0.0330, 0.1572, 0.0468, 0.0628, 0.0788,
        0.0481, 0.0611, 0.0480, 0.0421, 0.0634, 0.0379, 0.1176, 0.0604],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,596][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.7107e-01, 2.6213e-04, 1.2866e-03, 3.3646e-04, 2.9099e-04, 9.1054e-04,
        9.2109e-04, 8.4581e-04, 7.1261e-04, 6.3952e-04, 1.9907e-03, 3.6774e-03,
        7.2487e-04, 2.4217e-03, 4.8811e-04, 6.1626e-03, 5.2387e-03, 2.0170e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,597][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0006, 0.0498, 0.1100, 0.0488, 0.2950, 0.0280, 0.0297, 0.0152, 0.0325,
        0.0272, 0.0367, 0.0276, 0.0389, 0.0154, 0.0919, 0.0692, 0.0411, 0.0424],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,597][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([9.7186e-01, 5.8188e-04, 4.8972e-04, 1.9964e-04, 3.6195e-04, 5.0317e-04,
        7.1902e-04, 8.7250e-04, 1.0257e-03, 7.7908e-04, 3.7994e-03, 3.5177e-03,
        1.0331e-03, 9.5892e-04, 1.4421e-03, 2.8185e-03, 6.4496e-03, 2.5896e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,598][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([2.1603e-01, 6.2631e-06, 2.3232e-06, 5.4453e-07, 2.1867e-06, 1.0792e-05,
        1.1444e-06, 9.6557e-05, 1.8980e-05, 9.4138e-05, 9.4941e-05, 2.2200e-04,
        1.5577e-03, 1.7440e-01, 2.2676e-04, 5.0005e-01, 5.7093e-02, 5.0103e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,598][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1067, 0.0106, 0.0549, 0.0167, 0.0567, 0.0174, 0.0245, 0.0547, 0.0641,
        0.0381, 0.0969, 0.0599, 0.0362, 0.0761, 0.0875, 0.0569, 0.0488, 0.0930],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,599][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.8266, 0.0042, 0.0044, 0.0012, 0.0022, 0.0064, 0.0035, 0.0051, 0.0041,
        0.0053, 0.0204, 0.0136, 0.0148, 0.0089, 0.0033, 0.0123, 0.0144, 0.0493],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,599][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0003, 0.0432, 0.0799, 0.0399, 0.1087, 0.0450, 0.0848, 0.0235, 0.0617,
        0.0702, 0.0732, 0.0338, 0.0306, 0.0384, 0.1106, 0.0707, 0.0678, 0.0178],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,600][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0195, 0.0354, 0.0057, 0.0021, 0.0035, 0.0025, 0.0020, 0.0062, 0.0078,
        0.0060, 0.0127, 0.0240, 0.0294, 0.2232, 0.0173, 0.3354, 0.1618, 0.1056],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,602][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.2876, 0.0292, 0.0104, 0.0105, 0.0150, 0.0264, 0.0302, 0.0378, 0.0294,
        0.0227, 0.0266, 0.0544, 0.0362, 0.0865, 0.0263, 0.0953, 0.1099, 0.0656],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,603][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([2.7777e-05, 3.9904e-03, 9.7155e-03, 8.9562e-02, 1.5371e-01, 1.1577e-01,
        4.5091e-02, 5.6066e-02, 1.5046e-01, 7.5645e-02, 3.1604e-02, 3.7667e-02,
        2.7659e-02, 1.0005e-02, 1.6446e-01, 1.3100e-02, 1.1217e-02, 4.2515e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,604][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([1.2616e-03, 2.4335e-05, 3.9555e-06, 8.0271e-07, 4.0475e-06, 3.8609e-05,
        2.1690e-06, 1.2497e-04, 4.3577e-05, 3.8041e-04, 1.8874e-04, 5.1616e-04,
        2.8444e-03, 1.0130e-01, 3.2102e-04, 7.7290e-01, 5.1092e-02, 6.8952e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,605][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([9.2814e-05, 2.7311e-02, 3.6388e-02, 3.2281e-02, 2.9830e-02, 1.6085e-01,
        4.9169e-02, 8.0866e-02, 6.8132e-02, 4.2217e-02, 4.8020e-02, 5.0070e-02,
        5.8939e-02, 2.8432e-02, 3.8114e-02, 1.2825e-01, 4.5589e-02, 7.5452e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,606][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8431e-01, 1.0192e-04, 8.0891e-04, 1.7866e-04, 8.3062e-05, 4.0267e-04,
        5.8404e-04, 4.1903e-04, 3.3340e-04, 1.4974e-04, 1.0312e-03, 2.1052e-03,
        3.2071e-04, 1.3040e-03, 1.4685e-04, 2.0869e-03, 3.1499e-03, 8.7127e-04,
        1.6145e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,607][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0027, 0.0553, 0.1147, 0.0386, 0.1602, 0.0280, 0.0564, 0.0117, 0.0370,
        0.0250, 0.0716, 0.0492, 0.0337, 0.0167, 0.0677, 0.0771, 0.0773, 0.0415,
        0.0356], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,607][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9605e-01, 7.0762e-05, 1.2174e-04, 1.8236e-05, 5.5943e-05, 3.0057e-05,
        6.6626e-05, 1.3804e-04, 9.1650e-05, 3.4201e-05, 3.4104e-04, 4.3738e-04,
        1.5517e-04, 1.3119e-04, 2.2799e-04, 3.7554e-04, 9.4854e-04, 3.4784e-04,
        3.6107e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,608][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.5454e-01, 2.7727e-06, 7.0780e-07, 1.4724e-07, 3.7687e-07, 2.3944e-06,
        2.2512e-07, 1.2420e-05, 3.2490e-06, 2.7112e-05, 1.9739e-05, 4.4491e-05,
        2.1185e-04, 5.2263e-02, 3.2889e-05, 1.3913e-01, 9.7692e-03, 1.4794e-02,
        2.9149e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,608][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3561, 0.0059, 0.0245, 0.0057, 0.0314, 0.0076, 0.0146, 0.0329, 0.0383,
        0.0159, 0.0551, 0.0528, 0.0255, 0.0494, 0.0956, 0.0304, 0.0450, 0.0641,
        0.0493], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,608][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.7225e-01, 2.0622e-03, 1.6880e-03, 5.7747e-04, 1.2666e-03, 4.0448e-03,
        2.1814e-03, 4.2256e-03, 2.7696e-03, 3.9601e-03, 1.2441e-02, 9.6763e-03,
        9.2173e-03, 4.8392e-03, 1.8366e-03, 4.2485e-03, 8.7050e-03, 4.8629e-02,
        5.3771e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,609][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0010, 0.0195, 0.0872, 0.0197, 0.0967, 0.0285, 0.0653, 0.0252, 0.0614,
        0.0490, 0.0472, 0.0423, 0.0429, 0.0294, 0.1798, 0.0386, 0.0776, 0.0236,
        0.0651], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,610][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0741, 0.0243, 0.0059, 0.0017, 0.0021, 0.0026, 0.0015, 0.0057, 0.0051,
        0.0071, 0.0107, 0.0165, 0.0179, 0.1784, 0.0114, 0.2873, 0.0994, 0.0714,
        0.1770], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,612][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4759, 0.0154, 0.0069, 0.0047, 0.0106, 0.0131, 0.0198, 0.0349, 0.0170,
        0.0129, 0.0234, 0.0317, 0.0202, 0.0620, 0.0224, 0.0509, 0.0814, 0.0408,
        0.0558], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,613][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.0484e-04, 3.5047e-03, 9.9066e-03, 5.0595e-02, 7.2134e-02, 8.7433e-02,
        4.2950e-02, 5.4724e-02, 1.8769e-01, 4.3092e-02, 3.6145e-02, 6.4876e-02,
        3.9444e-02, 1.5095e-02, 2.1577e-01, 9.0318e-03, 1.6369e-02, 8.2050e-03,
        4.2933e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,614][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.3167e-02, 4.0684e-05, 4.1925e-06, 8.3771e-07, 3.2214e-06, 2.8891e-05,
        1.6483e-06, 9.2692e-05, 3.0983e-05, 1.8371e-04, 1.9698e-04, 4.0720e-04,
        1.7250e-03, 1.3815e-01, 2.4563e-04, 5.0599e-01, 4.6461e-02, 8.6201e-02,
        2.0707e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,616][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0007, 0.0253, 0.0353, 0.0319, 0.0193, 0.1374, 0.0452, 0.0523, 0.0647,
        0.0369, 0.0457, 0.0421, 0.0351, 0.0389, 0.0312, 0.1469, 0.0634, 0.0670,
        0.0808], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,617][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:53,619][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14957],
        [ 3372],
        [25757],
        [ 1078],
        [  132],
        [  835],
        [  608],
        [  692],
        [ 1280],
        [  567],
        [ 1264],
        [  491],
        [  954],
        [  164],
        [  176],
        [  594],
        [  291],
        [   58],
        [  234]], device='cuda:0')
[2024-07-24 10:19:53,620][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11841],
        [ 1779],
        [ 6841],
        [  112],
        [   11],
        [  240],
        [  235],
        [   92],
        [  590],
        [  209],
        [  729],
        [  239],
        [  322],
        [   32],
        [   99],
        [  145],
        [  106],
        [   18],
        [  105]], device='cuda:0')
[2024-07-24 10:19:53,621][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25977],
        [33977],
        [43222],
        [41077],
        [37996],
        [37183],
        [36786],
        [37469],
        [38322],
        [36198],
        [37042],
        [37633],
        [37597],
        [38362],
        [38376],
        [38348],
        [38563],
        [38801],
        [39687]], device='cuda:0')
[2024-07-24 10:19:53,623][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13363],
        [ 6235],
        [ 5714],
        [ 7983],
        [ 9571],
        [ 8660],
        [ 8415],
        [ 7734],
        [ 7859],
        [ 7710],
        [ 7285],
        [ 6968],
        [ 6735],
        [ 6600],
        [ 6583],
        [ 6128],
        [ 6113],
        [ 5963],
        [ 6046]], device='cuda:0')
[2024-07-24 10:19:53,624][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13812],
        [13812],
        [14073],
        [13827],
        [13904],
        [14076],
        [14184],
        [15088],
        [14127],
        [14818],
        [15885],
        [14499],
        [15655],
        [14079],
        [17471],
        [15556],
        [14214],
        [15467],
        [14049]], device='cuda:0')
[2024-07-24 10:19:53,626][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[24473],
        [24670],
        [28316],
        [24778],
        [26242],
        [25817],
        [34980],
        [30132],
        [30346],
        [37683],
        [33170],
        [31870],
        [34330],
        [25652],
        [38035],
        [33725],
        [33476],
        [35545],
        [29892]], device='cuda:0')
[2024-07-24 10:19:53,628][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6195],
        [ 9483],
        [ 6872],
        [ 7091],
        [ 5926],
        [ 7957],
        [ 9611],
        [12038],
        [12961],
        [14101],
        [14529],
        [14646],
        [14861],
        [14559],
        [14051],
        [14336],
        [14503],
        [14332],
        [14461]], device='cuda:0')
[2024-07-24 10:19:53,629][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48014],
        [47949],
        [ 9593],
        [46984],
        [37251],
        [13517],
        [ 2221],
        [ 1655],
        [ 1887],
        [ 1272],
        [ 1834],
        [ 1792],
        [ 4294],
        [ 3618],
        [ 1682],
        [ 2565],
        [ 1407],
        [ 3468],
        [ 4943]], device='cuda:0')
[2024-07-24 10:19:53,630][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28693],
        [42529],
        [49940],
        [49811],
        [44024],
        [38314],
        [34878],
        [35628],
        [37764],
        [24605],
        [26128],
        [30438],
        [21426],
        [33474],
        [23105],
        [20374],
        [21148],
        [22540],
        [23006]], device='cuda:0')
[2024-07-24 10:19:53,631][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12995],
        [41155],
        [40342],
        [40065],
        [41066],
        [40489],
        [39753],
        [40448],
        [40733],
        [41904],
        [41534],
        [40491],
        [38890],
        [41909],
        [42096],
        [46981],
        [45191],
        [43834],
        [43143]], device='cuda:0')
[2024-07-24 10:19:53,633][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6364],
        [ 6323],
        [23317],
        [ 9321],
        [16004],
        [26442],
        [19668],
        [32474],
        [28560],
        [35340],
        [28835],
        [22375],
        [21601],
        [16915],
        [17748],
        [26274],
        [19759],
        [21916],
        [18391]], device='cuda:0')
[2024-07-24 10:19:53,634][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16323],
        [12523],
        [49847],
        [36426],
        [44333],
        [25844],
        [25231],
        [37032],
        [30461],
        [31820],
        [32404],
        [32566],
        [30631],
        [33251],
        [31231],
        [36017],
        [35116],
        [33452],
        [32629]], device='cuda:0')
[2024-07-24 10:19:53,636][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33168],
        [35547],
        [37564],
        [39927],
        [34978],
        [43672],
        [43840],
        [42663],
        [42573],
        [35605],
        [37806],
        [37577],
        [42487],
        [45254],
        [45172],
        [46680],
        [46536],
        [46335],
        [46153]], device='cuda:0')
[2024-07-24 10:19:53,638][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14670],
        [14001],
        [18168],
        [17804],
        [20180],
        [19000],
        [19935],
        [19073],
        [19416],
        [19504],
        [20408],
        [20884],
        [21117],
        [21537],
        [21909],
        [22099],
        [22333],
        [22352],
        [22685]], device='cuda:0')
[2024-07-24 10:19:53,639][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[34453],
        [22848],
        [26302],
        [22709],
        [23961],
        [24593],
        [22682],
        [27396],
        [20756],
        [25784],
        [24833],
        [23547],
        [28283],
        [22876],
        [19539],
        [21538],
        [17942],
        [19916],
        [18294]], device='cuda:0')
[2024-07-24 10:19:53,641][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26577],
        [26587],
        [26618],
        [26600],
        [26752],
        [27164],
        [27084],
        [29061],
        [27144],
        [32999],
        [31980],
        [28292],
        [30281],
        [27286],
        [31868],
        [30881],
        [27542],
        [29508],
        [28274]], device='cuda:0')
[2024-07-24 10:19:53,642][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15791],
        [19361],
        [39267],
        [42554],
        [45159],
        [45379],
        [45467],
        [45159],
        [45855],
        [45267],
        [44997],
        [44954],
        [44256],
        [44984],
        [44206],
        [40353],
        [43784],
        [43244],
        [41174]], device='cuda:0')
[2024-07-24 10:19:53,643][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33937],
        [33935],
        [33926],
        [33931],
        [33908],
        [33848],
        [33618],
        [32803],
        [33688],
        [32479],
        [30678],
        [33146],
        [30783],
        [33628],
        [26262],
        [32151],
        [33369],
        [30810],
        [33485]], device='cuda:0')
[2024-07-24 10:19:53,644][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3262],
        [ 3147],
        [ 1950],
        [ 3131],
        [ 2942],
        [ 3014],
        [ 3611],
        [ 4006],
        [ 4640],
        [ 4890],
        [ 6352],
        [ 5324],
        [11371],
        [ 3467],
        [10567],
        [ 7970],
        [ 7377],
        [ 7504],
        [ 4103]], device='cuda:0')
[2024-07-24 10:19:53,646][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17152],
        [18886],
        [ 8631],
        [16411],
        [ 4427],
        [ 5828],
        [ 8422],
        [ 5756],
        [ 9306],
        [ 8958],
        [14416],
        [14257],
        [14454],
        [12792],
        [11056],
        [11827],
        [12285],
        [11640],
        [11585]], device='cuda:0')
[2024-07-24 10:19:53,648][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[10190],
        [10130],
        [ 9360],
        [10125],
        [10533],
        [ 9101],
        [ 9180],
        [ 8136],
        [ 9050],
        [ 3784],
        [ 4767],
        [ 6267],
        [ 7997],
        [ 8755],
        [ 4227],
        [ 7650],
        [ 7520],
        [ 4234],
        [ 5604]], device='cuda:0')
[2024-07-24 10:19:53,650][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15978],
        [27131],
        [22615],
        [29876],
        [39393],
        [35676],
        [35467],
        [32367],
        [32857],
        [25184],
        [23758],
        [25092],
        [18169],
        [24947],
        [23542],
        [26292],
        [25995],
        [27598],
        [29944]], device='cuda:0')
[2024-07-24 10:19:53,651][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11813],
        [ 1039],
        [ 1185],
        [ 1074],
        [ 1003],
        [ 1170],
        [ 1068],
        [  927],
        [  903],
        [ 1741],
        [ 2406],
        [ 2032],
        [ 4820],
        [ 2316],
        [ 2680],
        [ 4321],
        [ 3873],
        [ 3298],
        [ 2429]], device='cuda:0')
[2024-07-24 10:19:53,653][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27205],
        [27022],
        [35608],
        [29333],
        [36708],
        [36090],
        [36511],
        [37401],
        [35161],
        [37375],
        [36827],
        [34178],
        [33333],
        [33745],
        [37306],
        [35464],
        [33298],
        [36756],
        [37003]], device='cuda:0')
[2024-07-24 10:19:53,654][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18504],
        [35996],
        [39089],
        [34299],
        [22951],
        [29875],
        [31914],
        [33628],
        [41614],
        [38321],
        [38872],
        [41620],
        [39904],
        [39376],
        [38100],
        [36110],
        [36512],
        [36302],
        [38847]], device='cuda:0')
[2024-07-24 10:19:53,655][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7114],
        [ 8138],
        [ 9082],
        [10361],
        [14976],
        [17137],
        [18494],
        [18401],
        [12931],
        [20706],
        [20537],
        [13725],
        [23715],
        [14055],
        [14215],
        [24653],
        [22967],
        [22941],
        [16316]], device='cuda:0')
[2024-07-24 10:19:53,656][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[3737],
        [9319],
        [5801],
        [3989],
        [4192],
        [3488],
        [3244],
        [3268],
        [2611],
        [3103],
        [2512],
        [2512],
        [2648],
        [2668],
        [2844],
        [3718],
        [3156],
        [3242],
        [3133]], device='cuda:0')
[2024-07-24 10:19:53,658][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44915],
        [42687],
        [42675],
        [38826],
        [39693],
        [41279],
        [38104],
        [40740],
        [38966],
        [37699],
        [35033],
        [36618],
        [31525],
        [38801],
        [39984],
        [32843],
        [33570],
        [36692],
        [38050]], device='cuda:0')
[2024-07-24 10:19:53,660][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15071],
        [33551],
        [28275],
        [33587],
        [30834],
        [26400],
        [29062],
        [23706],
        [31808],
        [26216],
        [27172],
        [28200],
        [20368],
        [28007],
        [28910],
        [27445],
        [32393],
        [28176],
        [33500]], device='cuda:0')
[2024-07-24 10:19:53,661][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205],
        [16205]], device='cuda:0')
[2024-07-24 10:19:53,719][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:53,720][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,720][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,721][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,721][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,721][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,722][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,722][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,722][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,722][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,723][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,724][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,725][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,727][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5958, 0.4042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,729][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,730][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9972, 0.0028], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,730][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9883, 0.0117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,731][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9930, 0.0070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,731][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1014, 0.8986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,731][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1196, 0.8804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,741][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0574, 0.9426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,741][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3191, 0.6809], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,741][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0331, 0.9669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,742][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0276, 0.9724], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,742][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9984e-01, 1.5918e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,742][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.5207, 0.1279, 0.3514], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,743][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([9.8951e-05, 8.6537e-01, 1.3453e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,743][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([0.0914, 0.1713, 0.7373], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,745][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.8146, 0.1468, 0.0386], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,746][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.8762, 0.1147, 0.0092], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,748][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0016, 0.0024, 0.9960], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,749][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.0088, 0.7091, 0.2821], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,750][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.0226, 0.4691, 0.5083], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,751][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([0.1949, 0.4286, 0.3764], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,751][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.0025, 0.8035, 0.1939], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,751][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([0.0045, 0.4494, 0.5461], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,751][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.6883, 0.0366, 0.2751], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,752][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2505, 0.2532, 0.2885, 0.2078], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,752][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([6.3198e-05, 2.6291e-01, 2.6186e-01, 4.7516e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,752][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7874, 0.0063, 0.2032, 0.0030], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,752][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7669, 0.1102, 0.0770, 0.0459], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,753][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9582, 0.0291, 0.0037, 0.0090], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,753][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.0771e-01, 4.7290e-04, 1.6093e-01, 7.3089e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,755][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0265, 0.2910, 0.2335, 0.4491], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,756][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0210, 0.3192, 0.3089, 0.3509], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,758][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1309, 0.3043, 0.2685, 0.2963], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,759][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0054, 0.1961, 0.0195, 0.7789], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,761][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0114, 0.3845, 0.5896, 0.0146], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,761][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.5561e-01, 1.1326e-03, 4.2350e-02, 9.1094e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,761][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0458, 0.0949, 0.2330, 0.1029, 0.5234], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,761][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([5.2166e-06, 1.0063e-01, 6.9735e-02, 2.5139e-01, 5.7824e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,762][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0892, 0.0610, 0.3053, 0.1300, 0.4144], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,762][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.2424, 0.2088, 0.2326, 0.1114, 0.2050], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,762][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.9069, 0.0557, 0.0045, 0.0264, 0.0065], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,762][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([2.9520e-03, 4.3378e-05, 5.9847e-03, 1.0505e-01, 8.8597e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,763][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0029, 0.1844, 0.0910, 0.2474, 0.4744], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,763][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0112, 0.2491, 0.2543, 0.2254, 0.2600], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,764][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.1013, 0.2314, 0.2044, 0.2207, 0.2421], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,765][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([2.5204e-04, 2.8001e-02, 5.5984e-03, 6.5092e-01, 3.1523e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,767][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0038, 0.3820, 0.5146, 0.0140, 0.0856], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,768][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.4688, 0.0259, 0.2387, 0.0235, 0.2430], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,769][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1236, 0.0812, 0.1235, 0.0712, 0.3387, 0.2618], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,770][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([6.0519e-05, 7.7443e-02, 1.9525e-01, 1.2824e-01, 5.6610e-01, 3.2909e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,771][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2608, 0.0032, 0.0698, 0.0030, 0.6077, 0.0555], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,771][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.5986, 0.1242, 0.0781, 0.0542, 0.0767, 0.0682], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,772][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7329, 0.1377, 0.0113, 0.0779, 0.0122, 0.0280], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,772][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.2451e-02, 3.0494e-05, 8.2901e-04, 1.4858e-02, 5.3296e-02, 9.1854e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,772][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0025, 0.1165, 0.0999, 0.1808, 0.3699, 0.2306], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,772][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0077, 0.1846, 0.2044, 0.1931, 0.1904, 0.2198], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,773][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0847, 0.1824, 0.1648, 0.1791, 0.1915, 0.1974], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,773][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([2.5808e-04, 1.7736e-02, 1.0324e-03, 4.8741e-02, 4.9256e-02, 8.8298e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,773][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0076, 0.3282, 0.5669, 0.0108, 0.0593, 0.0272], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,774][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1863, 0.0203, 0.4462, 0.0384, 0.2303, 0.0785], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,774][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2235, 0.0712, 0.0955, 0.0488, 0.3298, 0.1619, 0.0694],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,775][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.8499e-05, 9.5543e-02, 1.4153e-01, 1.8830e-01, 5.0137e-01, 2.8155e-02,
        4.5079e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,777][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1212, 0.0043, 0.1068, 0.0022, 0.7285, 0.0263, 0.0107],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,778][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3808, 0.1702, 0.0753, 0.0825, 0.0704, 0.1463, 0.0745],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,780][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5070, 0.2743, 0.0073, 0.1027, 0.0209, 0.0580, 0.0297],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,781][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.0115e-03, 5.7662e-06, 4.8329e-04, 4.5673e-03, 7.6315e-02, 8.7738e-01,
        4.0238e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,781][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0028, 0.1104, 0.0778, 0.1626, 0.2702, 0.1768, 0.1994],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,781][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0092, 0.1523, 0.1668, 0.1596, 0.1524, 0.1614, 0.1983],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,782][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0714, 0.1526, 0.1391, 0.1496, 0.1612, 0.1652, 0.1610],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,782][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.7366e-06, 5.7128e-03, 6.1139e-04, 3.9946e-02, 4.6142e-02, 8.9575e-01,
        1.1835e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,782][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0054, 0.2657, 0.3995, 0.0121, 0.0679, 0.0267, 0.2227],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,783][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2068, 0.0214, 0.3178, 0.0262, 0.2979, 0.0665, 0.0635],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:53,783][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.1127, 0.0568, 0.0944, 0.0345, 0.2740, 0.1395, 0.0673, 0.2208],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,783][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([9.0501e-06, 1.2296e-01, 6.1981e-02, 6.6243e-02, 6.6832e-01, 1.8484e-02,
        5.7593e-02, 4.4100e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,784][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1609, 0.0041, 0.0323, 0.0079, 0.6056, 0.0699, 0.0844, 0.0349],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,784][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1744, 0.2451, 0.0908, 0.0427, 0.1558, 0.1113, 0.0879, 0.0921],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,786][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.3172, 0.4790, 0.0239, 0.0611, 0.0653, 0.0239, 0.0224, 0.0071],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,787][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([1.4414e-03, 1.5667e-05, 2.1012e-04, 3.9119e-03, 1.3902e-02, 2.4120e-01,
        2.4503e-02, 7.1482e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,789][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0003, 0.0836, 0.0557, 0.1257, 0.2710, 0.1341, 0.1872, 0.1423],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,790][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0063, 0.1197, 0.1407, 0.1292, 0.1279, 0.1141, 0.1597, 0.2024],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,791][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0623, 0.1311, 0.1186, 0.1271, 0.1408, 0.1427, 0.1413, 0.1361],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,792][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([3.2972e-05, 8.6350e-03, 3.1914e-04, 1.6548e-02, 1.5626e-02, 5.7034e-01,
        6.8379e-03, 3.8166e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,792][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0008, 0.2058, 0.3757, 0.0083, 0.0716, 0.0245, 0.2637, 0.0498],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,792][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0381, 0.0199, 0.3788, 0.0113, 0.4071, 0.0358, 0.0656, 0.0435],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:53,793][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0973, 0.0457, 0.0558, 0.0289, 0.2739, 0.1469, 0.0623, 0.1666, 0.1226],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,793][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([3.1360e-05, 5.4798e-02, 1.3029e-01, 1.2220e-01, 5.1799e-01, 2.0942e-02,
        4.4410e-02, 1.1230e-02, 9.8112e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,793][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0290, 0.0014, 0.0264, 0.0013, 0.8836, 0.0290, 0.0138, 0.0050, 0.0105],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,794][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.3881, 0.1330, 0.0789, 0.0442, 0.0688, 0.1006, 0.0615, 0.0609, 0.0639],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,794][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.6257, 0.1209, 0.0097, 0.0843, 0.0120, 0.0197, 0.0145, 0.0170, 0.0964],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,795][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([4.0946e-03, 3.5373e-06, 1.5549e-04, 1.6967e-03, 1.0800e-02, 2.5315e-01,
        1.4068e-02, 6.5840e-01, 5.7626e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,796][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0028, 0.0674, 0.0549, 0.0789, 0.2329, 0.0888, 0.1242, 0.1195, 0.2305],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,798][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0045, 0.1045, 0.1219, 0.1101, 0.1101, 0.1024, 0.1328, 0.1705, 0.1432],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,800][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0521, 0.1152, 0.1045, 0.1126, 0.1209, 0.1271, 0.1256, 0.1197, 0.1223],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,800][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([4.4082e-05, 6.0297e-04, 3.8792e-05, 6.9353e-03, 1.9629e-03, 1.5678e-01,
        2.8963e-03, 1.1222e-01, 7.1852e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,802][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0017, 0.2138, 0.4793, 0.0084, 0.0446, 0.0204, 0.1967, 0.0320, 0.0032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,802][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0650, 0.0112, 0.3942, 0.0203, 0.3078, 0.0394, 0.0518, 0.0644, 0.0459],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:53,802][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0431, 0.0468, 0.0600, 0.0413, 0.2207, 0.1466, 0.0527, 0.1354, 0.1213,
        0.1321], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,803][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.2566e-05, 1.0087e-01, 7.7279e-02, 1.1565e-01, 4.8619e-01, 2.2915e-02,
        4.9351e-02, 6.1362e-03, 1.2478e-01, 1.6817e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,803][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0693, 0.0073, 0.0528, 0.0161, 0.6986, 0.0627, 0.0180, 0.0037, 0.0227,
        0.0487], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,803][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0810, 0.2114, 0.1319, 0.0943, 0.1297, 0.1097, 0.0692, 0.0469, 0.0628,
        0.0631], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,804][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.4669, 0.2871, 0.0124, 0.0532, 0.0222, 0.0283, 0.0131, 0.0161, 0.0798,
        0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,804][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([9.1001e-04, 1.0509e-06, 1.0984e-05, 4.4665e-04, 1.2290e-03, 4.0403e-02,
        2.7574e-03, 2.1576e-01, 4.1819e-02, 6.9667e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,804][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0010, 0.0690, 0.0373, 0.0948, 0.2128, 0.0949, 0.1024, 0.0895, 0.1792,
        0.1192], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,805][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0025, 0.0937, 0.1109, 0.0918, 0.1040, 0.0920, 0.1240, 0.1602, 0.1299,
        0.0910], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,807][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0478, 0.1049, 0.0946, 0.1007, 0.1090, 0.1104, 0.1076, 0.1064, 0.1077,
        0.1110], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,808][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([5.4441e-06, 1.5031e-03, 4.3031e-05, 4.2899e-03, 1.8613e-03, 1.2550e-01,
        1.4141e-03, 9.5383e-02, 6.5783e-01, 1.1216e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,810][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0023, 0.2085, 0.4312, 0.0090, 0.0649, 0.0244, 0.1954, 0.0383, 0.0048,
        0.0212], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,811][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0075, 0.0114, 0.4015, 0.0135, 0.3986, 0.0360, 0.0454, 0.0271, 0.0184,
        0.0405], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:53,812][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0230, 0.0366, 0.0375, 0.0316, 0.2514, 0.1263, 0.0621, 0.1477, 0.1123,
        0.1285, 0.0429], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,812][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.0898e-05, 5.9057e-02, 8.1730e-02, 6.7257e-02, 5.1715e-01, 2.5066e-02,
        4.4241e-02, 9.8861e-03, 1.2135e-01, 1.7096e-02, 5.7160e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,812][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0158, 0.0011, 0.0414, 0.0016, 0.8124, 0.0356, 0.0111, 0.0067, 0.0105,
        0.0582, 0.0057], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,813][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2137, 0.1070, 0.1416, 0.0427, 0.0675, 0.0605, 0.0750, 0.0726, 0.0893,
        0.0493, 0.0807], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,813][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.4787, 0.1696, 0.0185, 0.0871, 0.0287, 0.0266, 0.0245, 0.0243, 0.0780,
        0.0125, 0.0515], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,813][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([2.3148e-04, 8.2391e-07, 2.0102e-05, 3.5855e-04, 1.8585e-03, 3.2159e-02,
        3.4790e-03, 1.7388e-01, 2.8580e-02, 7.1989e-01, 3.9540e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,814][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0012, 0.0531, 0.0396, 0.0739, 0.1571, 0.0916, 0.1071, 0.0970, 0.1811,
        0.0916, 0.1067], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,814][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0022, 0.0814, 0.0980, 0.0859, 0.0970, 0.0846, 0.1073, 0.1353, 0.1178,
        0.0852, 0.1054], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,814][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0441, 0.0920, 0.0850, 0.0902, 0.0970, 0.1004, 0.0985, 0.0974, 0.0979,
        0.0996, 0.0979], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,815][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([3.0636e-05, 4.4860e-04, 2.6541e-05, 3.1536e-03, 1.5223e-03, 8.6955e-02,
        2.2923e-03, 1.1325e-01, 4.2399e-01, 1.3068e-01, 2.3765e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,817][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0039, 0.1985, 0.4487, 0.0053, 0.0520, 0.0223, 0.2138, 0.0353, 0.0036,
        0.0153, 0.0013], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,818][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0399, 0.0078, 0.4213, 0.0154, 0.2178, 0.0277, 0.0443, 0.0681, 0.0315,
        0.0788, 0.0475], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:53,820][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1226, 0.0359, 0.0450, 0.0241, 0.1667, 0.0972, 0.0406, 0.1475, 0.1068,
        0.1462, 0.0340, 0.0333], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,821][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.2526e-05, 4.2696e-02, 9.0960e-02, 5.7709e-02, 5.5013e-01, 1.2604e-02,
        4.1824e-02, 7.8512e-03, 6.2449e-02, 1.5361e-02, 6.2212e-02, 5.6180e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,822][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2910, 0.0018, 0.0572, 0.0032, 0.4531, 0.0364, 0.0052, 0.0130, 0.0207,
        0.0966, 0.0090, 0.0130], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,822][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3268, 0.0746, 0.0881, 0.0313, 0.0355, 0.0637, 0.0539, 0.0567, 0.0471,
        0.0359, 0.1025, 0.0838], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,823][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6970, 0.0734, 0.0074, 0.0385, 0.0087, 0.0170, 0.0119, 0.0076, 0.0622,
        0.0091, 0.0301, 0.0371], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,823][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([5.1629e-04, 3.4495e-07, 9.8418e-06, 1.3148e-04, 1.4854e-03, 2.9229e-02,
        1.3021e-03, 1.4410e-01, 1.2108e-02, 7.5056e-01, 2.6128e-02, 3.4433e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,823][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0012, 0.0475, 0.0356, 0.0618, 0.1564, 0.0694, 0.1025, 0.0771, 0.1621,
        0.0813, 0.0903, 0.1148], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,824][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0040, 0.0720, 0.0840, 0.0754, 0.0819, 0.0740, 0.1006, 0.1223, 0.1046,
        0.0708, 0.0933, 0.1170], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,824][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0404, 0.0840, 0.0765, 0.0818, 0.0883, 0.0921, 0.0907, 0.0881, 0.0880,
        0.0901, 0.0896, 0.0904], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,824][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.0848e-05, 6.0047e-05, 1.2781e-06, 2.4132e-04, 5.5366e-05, 3.5333e-03,
        7.9520e-05, 4.9846e-03, 4.4577e-02, 7.2151e-03, 2.0267e-02, 9.1895e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,825][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0077, 0.1976, 0.3810, 0.0059, 0.0484, 0.0180, 0.2343, 0.0490, 0.0047,
        0.0176, 0.0021, 0.0337], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,826][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0295, 0.0194, 0.3303, 0.0185, 0.2618, 0.0239, 0.0351, 0.0324, 0.0288,
        0.0507, 0.0519, 0.1178], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:53,828][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.0448, 0.0337, 0.0504, 0.0306, 0.1764, 0.0855, 0.0390, 0.1108, 0.1010,
        0.1000, 0.0383, 0.0311, 0.1585], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,829][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ office] are: tensor([1.0266e-05, 4.0583e-02, 5.3002e-02, 7.4042e-02, 5.2605e-01, 1.6125e-02,
        1.9890e-02, 4.8617e-03, 8.8650e-02, 1.0775e-02, 1.0241e-01, 4.1139e-02,
        2.2466e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,830][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0861, 0.0092, 0.0552, 0.0122, 0.2394, 0.0443, 0.0192, 0.0086, 0.0244,
        0.0474, 0.0221, 0.0313, 0.4006], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,832][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ office] are: tensor([0.2630, 0.0956, 0.0423, 0.0198, 0.0566, 0.0366, 0.0312, 0.0502, 0.0481,
        0.0661, 0.0838, 0.0566, 0.1503], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,832][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.4421, 0.1445, 0.0083, 0.0562, 0.0252, 0.0330, 0.0193, 0.0102, 0.1215,
        0.0137, 0.0533, 0.0579, 0.0148], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,833][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ office] are: tensor([1.0928e-03, 2.8417e-07, 2.8826e-06, 1.3942e-04, 3.5157e-04, 1.8045e-02,
        1.3152e-03, 6.6672e-02, 1.7395e-02, 2.2749e-01, 4.3564e-02, 4.3007e-02,
        5.8093e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,833][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ office] are: tensor([0.0012, 0.0397, 0.0302, 0.0515, 0.1391, 0.0736, 0.0830, 0.0641, 0.1520,
        0.0941, 0.0878, 0.0920, 0.0917], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,833][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.0036, 0.0620, 0.0784, 0.0664, 0.0748, 0.0718, 0.0913, 0.1155, 0.0993,
        0.0713, 0.0830, 0.0958, 0.0867], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,834][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ office] are: tensor([0.0402, 0.0773, 0.0712, 0.0742, 0.0820, 0.0830, 0.0797, 0.0805, 0.0806,
        0.0843, 0.0820, 0.0822, 0.0829], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,834][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ office] are: tensor([2.3617e-05, 1.1700e-05, 3.8897e-07, 7.1298e-05, 2.6342e-05, 1.3811e-03,
        2.6039e-05, 1.8127e-03, 1.0249e-02, 2.4805e-03, 4.7714e-03, 2.9906e-01,
        6.8009e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,834][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ office] are: tensor([0.0021, 0.2268, 0.4462, 0.0058, 0.0462, 0.0204, 0.1646, 0.0368, 0.0034,
        0.0171, 0.0015, 0.0232, 0.0057], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,835][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ office] are: tensor([0.1644, 0.0131, 0.2328, 0.0091, 0.1037, 0.0250, 0.0512, 0.1033, 0.0218,
        0.0712, 0.0525, 0.1133, 0.0386], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:53,836][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0441, 0.0252, 0.0340, 0.0236, 0.1923, 0.1054, 0.0580, 0.1014, 0.0823,
        0.1108, 0.0380, 0.0410, 0.1045, 0.0393], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,837][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.6889e-05, 4.4987e-02, 8.7432e-02, 4.7725e-02, 5.0453e-01, 1.8654e-02,
        2.8294e-02, 4.6311e-03, 4.7274e-02, 1.1133e-02, 4.3996e-02, 2.3752e-02,
        2.6530e-02, 1.1103e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,838][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([7.0345e-02, 8.5661e-04, 1.6309e-02, 4.5990e-04, 6.9696e-01, 2.6918e-02,
        1.1552e-02, 3.8179e-03, 8.1225e-03, 1.2597e-02, 7.4134e-03, 2.2313e-02,
        1.2190e-01, 4.3529e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,839][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.4408, 0.0356, 0.0727, 0.0126, 0.0421, 0.0380, 0.0335, 0.0261, 0.0175,
        0.0187, 0.0513, 0.0440, 0.0689, 0.0983], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,841][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.7827, 0.0381, 0.0067, 0.0137, 0.0052, 0.0072, 0.0048, 0.0034, 0.0168,
        0.0021, 0.0104, 0.0158, 0.0042, 0.0888], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,842][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([2.8875e-03, 3.9121e-06, 1.5335e-05, 2.1883e-04, 2.2277e-03, 2.1034e-02,
        7.6772e-04, 1.1043e-01, 6.0269e-03, 5.4924e-01, 1.0460e-02, 1.3605e-02,
        1.8123e-01, 1.0185e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,842][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0017, 0.0354, 0.0314, 0.0565, 0.1146, 0.0700, 0.0754, 0.0572, 0.1188,
        0.0611, 0.0728, 0.0864, 0.0938, 0.1246], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,843][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0035, 0.0590, 0.0735, 0.0622, 0.0696, 0.0643, 0.0827, 0.1009, 0.0892,
        0.0593, 0.0710, 0.0901, 0.0661, 0.1087], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,843][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0354, 0.0706, 0.0650, 0.0691, 0.0748, 0.0776, 0.0757, 0.0743, 0.0751,
        0.0763, 0.0759, 0.0767, 0.0756, 0.0780], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,844][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([8.8895e-05, 3.9749e-06, 4.1621e-09, 7.3485e-07, 6.5814e-08, 4.3839e-06,
        5.6950e-08, 1.6343e-06, 9.1307e-06, 1.8282e-06, 6.9474e-06, 1.5695e-04,
        1.5633e-04, 9.9957e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,844][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0147, 0.1357, 0.3969, 0.0052, 0.0446, 0.0259, 0.2373, 0.0492, 0.0059,
        0.0150, 0.0023, 0.0362, 0.0127, 0.0183], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,844][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.4258, 0.0060, 0.1930, 0.0067, 0.1446, 0.0152, 0.0125, 0.0209, 0.0140,
        0.0181, 0.0131, 0.0357, 0.0187, 0.0757], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:53,845][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0073, 0.0204, 0.0527, 0.0255, 0.1426, 0.1102, 0.0452, 0.0724, 0.0717,
        0.0796, 0.0298, 0.0355, 0.1361, 0.0337, 0.1372], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,845][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([9.0993e-07, 3.3073e-02, 3.5212e-02, 7.9328e-02, 3.2187e-01, 9.0811e-03,
        3.2768e-02, 2.7810e-03, 4.0842e-02, 1.6182e-03, 5.7718e-02, 2.5788e-02,
        1.8621e-02, 4.9708e-02, 2.9159e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,846][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0181, 0.0200, 0.0685, 0.0424, 0.0659, 0.1942, 0.0552, 0.0269, 0.1251,
        0.0264, 0.0647, 0.0330, 0.2031, 0.0150, 0.0415], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,848][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0435, 0.0502, 0.1457, 0.0289, 0.0682, 0.0370, 0.0364, 0.0430, 0.0364,
        0.0266, 0.1025, 0.0670, 0.1174, 0.1011, 0.0961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,850][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.2671, 0.0651, 0.0100, 0.0435, 0.0120, 0.0302, 0.0191, 0.0217, 0.1006,
        0.0171, 0.0542, 0.0639, 0.0194, 0.2262, 0.0498], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,850][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([4.8101e-05, 2.0922e-07, 3.8778e-06, 1.0704e-04, 9.9568e-04, 1.4840e-02,
        1.1490e-03, 6.3094e-02, 9.3384e-03, 3.2563e-01, 1.4226e-02, 1.8469e-02,
        3.9541e-01, 1.4721e-01, 9.4843e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,852][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0007, 0.0326, 0.0198, 0.0451, 0.1056, 0.0440, 0.0588, 0.0462, 0.1066,
        0.0530, 0.0651, 0.0699, 0.0667, 0.0888, 0.1969], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,853][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0048, 0.0640, 0.0714, 0.0564, 0.0664, 0.0582, 0.0739, 0.0924, 0.0862,
        0.0472, 0.0626, 0.0801, 0.0583, 0.0948, 0.0833], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,853][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0327, 0.0660, 0.0601, 0.0633, 0.0702, 0.0708, 0.0690, 0.0691, 0.0690,
        0.0719, 0.0703, 0.0708, 0.0695, 0.0722, 0.0751], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,853][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([3.2698e-10, 1.6189e-08, 6.2696e-10, 1.7395e-07, 2.2528e-08, 1.3630e-06,
        2.1102e-08, 8.3692e-07, 7.5488e-06, 1.5463e-06, 3.5730e-06, 2.4123e-04,
        2.8623e-04, 9.9946e-01, 2.2474e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,854][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0020, 0.1948, 0.4387, 0.0105, 0.0590, 0.0176, 0.2073, 0.0238, 0.0021,
        0.0113, 0.0009, 0.0196, 0.0038, 0.0072, 0.0014], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,854][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0041, 0.0187, 0.1425, 0.0255, 0.1759, 0.0285, 0.0803, 0.0357, 0.0254,
        0.0292, 0.0137, 0.1256, 0.0397, 0.1451, 0.1102], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:53,855][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0286, 0.0176, 0.0268, 0.0189, 0.1322, 0.0655, 0.0324, 0.0700, 0.0557,
        0.0807, 0.0230, 0.0292, 0.0947, 0.0324, 0.1897, 0.1028],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,855][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.9637e-05, 2.8219e-02, 4.7408e-02, 4.0626e-02, 2.8605e-01, 5.8946e-03,
        1.4829e-02, 3.6823e-03, 3.5214e-02, 7.1144e-03, 6.4392e-02, 2.3531e-02,
        3.9390e-02, 8.8534e-02, 2.8370e-01, 3.1394e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,855][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([7.4427e-02, 5.8161e-04, 1.6951e-02, 1.3387e-03, 1.8900e-01, 2.8447e-02,
        5.2974e-03, 3.1093e-03, 5.7504e-03, 2.4726e-02, 3.8865e-03, 9.4201e-03,
        1.0279e-01, 2.2971e-04, 5.0414e-01, 2.9915e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,856][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1549, 0.0166, 0.0608, 0.0104, 0.0602, 0.0187, 0.0328, 0.0207, 0.0390,
        0.0326, 0.0626, 0.0514, 0.0826, 0.0959, 0.1541, 0.1067],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,858][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.5541, 0.0355, 0.0060, 0.0346, 0.0090, 0.0155, 0.0062, 0.0047, 0.0366,
        0.0047, 0.0159, 0.0206, 0.0051, 0.1709, 0.0336, 0.0469],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,859][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.1948e-03, 3.9151e-06, 1.5666e-05, 1.3851e-04, 4.1502e-04, 8.1335e-03,
        4.2668e-04, 2.2866e-02, 2.8101e-03, 3.9037e-02, 4.2477e-03, 3.1856e-03,
        4.7548e-02, 8.8398e-03, 1.8469e-03, 8.5629e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,860][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0014, 0.0264, 0.0203, 0.0379, 0.1040, 0.0476, 0.0529, 0.0443, 0.0926,
        0.0519, 0.0516, 0.0650, 0.0629, 0.0954, 0.1756, 0.0702],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,862][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0025, 0.0467, 0.0630, 0.0505, 0.0601, 0.0559, 0.0677, 0.0844, 0.0721,
        0.0549, 0.0626, 0.0703, 0.0653, 0.0911, 0.0729, 0.0800],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,863][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0314, 0.0613, 0.0567, 0.0605, 0.0648, 0.0660, 0.0653, 0.0630, 0.0655,
        0.0647, 0.0663, 0.0669, 0.0657, 0.0677, 0.0683, 0.0661],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,863][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.3205e-05, 7.9752e-07, 2.1587e-09, 2.9121e-07, 5.5923e-08, 1.9396e-06,
        3.1904e-08, 1.2048e-06, 6.4471e-06, 1.3498e-06, 5.2530e-06, 1.2738e-04,
        1.8365e-04, 5.7608e-01, 5.5441e-06, 4.2358e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,864][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0058, 0.1623, 0.3793, 0.0072, 0.0519, 0.0197, 0.2153, 0.0379, 0.0037,
        0.0155, 0.0018, 0.0246, 0.0090, 0.0128, 0.0031, 0.0501],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,864][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.3325, 0.0107, 0.2187, 0.0090, 0.0913, 0.0135, 0.0095, 0.0214, 0.0136,
        0.0158, 0.0193, 0.0378, 0.0139, 0.0989, 0.0315, 0.0625],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:53,864][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0712, 0.0218, 0.0280, 0.0153, 0.1233, 0.0598, 0.0258, 0.0823, 0.0612,
        0.0882, 0.0228, 0.0207, 0.0605, 0.0222, 0.1841, 0.0967, 0.0159],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,865][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.3054e-05, 2.0445e-02, 4.3033e-02, 4.8746e-02, 2.4202e-01, 9.4933e-03,
        2.3976e-02, 2.9711e-03, 3.4764e-02, 4.5699e-03, 5.0511e-02, 2.5953e-02,
        1.3999e-02, 5.4403e-02, 3.3629e-01, 4.8360e-02, 4.0430e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,865][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0773, 0.0010, 0.0355, 0.0012, 0.1490, 0.0144, 0.0033, 0.0074, 0.0116,
        0.0491, 0.0052, 0.0066, 0.1841, 0.0004, 0.4369, 0.0138, 0.0032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,866][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4956, 0.0200, 0.0372, 0.0105, 0.0136, 0.0268, 0.0202, 0.0164, 0.0160,
        0.0077, 0.0397, 0.0326, 0.0310, 0.0522, 0.0202, 0.0819, 0.0784],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,867][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8119, 0.0186, 0.0017, 0.0103, 0.0020, 0.0062, 0.0030, 0.0025, 0.0174,
        0.0018, 0.0112, 0.0089, 0.0016, 0.0463, 0.0062, 0.0292, 0.0211],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,868][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.0181e-04, 2.3298e-06, 1.2014e-05, 6.1981e-05, 6.1007e-04, 4.4255e-03,
        2.4539e-04, 1.8344e-02, 1.3869e-03, 4.2112e-02, 2.1091e-03, 2.2535e-03,
        1.6767e-02, 7.9282e-03, 1.7703e-03, 8.9621e-01, 5.4567e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,870][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0022, 0.0274, 0.0236, 0.0414, 0.0790, 0.0526, 0.0625, 0.0464, 0.0927,
        0.0448, 0.0565, 0.0751, 0.0551, 0.0787, 0.1393, 0.0627, 0.0601],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,871][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0039, 0.0473, 0.0602, 0.0487, 0.0556, 0.0491, 0.0650, 0.0803, 0.0654,
        0.0500, 0.0592, 0.0719, 0.0567, 0.0839, 0.0640, 0.0622, 0.0767],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,873][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0287, 0.0571, 0.0528, 0.0568, 0.0610, 0.0627, 0.0612, 0.0609, 0.0612,
        0.0616, 0.0622, 0.0621, 0.0606, 0.0635, 0.0644, 0.0621, 0.0609],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,873][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.7205e-06, 3.8146e-07, 1.2796e-09, 2.2519e-07, 2.7775e-08, 1.6487e-06,
        1.9082e-08, 1.7788e-06, 9.5101e-06, 1.0456e-06, 4.9537e-06, 9.3511e-05,
        1.0752e-04, 4.8724e-01, 2.4094e-06, 4.5513e-01, 5.7403e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,874][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0095, 0.1303, 0.3393, 0.0049, 0.0236, 0.0142, 0.1879, 0.0207, 0.0018,
        0.0078, 0.0007, 0.0117, 0.0029, 0.0046, 0.0008, 0.0251, 0.2140],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,874][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1167, 0.0142, 0.1907, 0.0171, 0.1857, 0.0274, 0.0303, 0.0237, 0.0163,
        0.0235, 0.0286, 0.0374, 0.0158, 0.0433, 0.0619, 0.0758, 0.0916],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:53,875][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0452, 0.0150, 0.0331, 0.0141, 0.1262, 0.0494, 0.0227, 0.0546, 0.0463,
        0.0627, 0.0151, 0.0169, 0.0766, 0.0212, 0.1821, 0.0861, 0.0112, 0.1215],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,875][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([4.4641e-05, 1.7285e-02, 5.1810e-02, 4.8920e-02, 4.2378e-01, 8.0316e-03,
        9.1293e-03, 1.4729e-03, 2.3527e-02, 3.3316e-03, 3.4495e-02, 1.1665e-02,
        5.9648e-03, 3.1877e-02, 2.7297e-01, 3.2202e-02, 1.1597e-02, 1.1900e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,875][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0323, 0.0013, 0.0183, 0.0025, 0.0983, 0.0157, 0.0042, 0.0037, 0.0067,
        0.0250, 0.0074, 0.0101, 0.2160, 0.0009, 0.1703, 0.0357, 0.0057, 0.3460],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,876][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.2948, 0.0251, 0.0516, 0.0084, 0.0516, 0.0265, 0.0187, 0.0269, 0.0180,
        0.0256, 0.0408, 0.0248, 0.0564, 0.0588, 0.0427, 0.1531, 0.0447, 0.0314],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,876][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.6654, 0.0342, 0.0027, 0.0129, 0.0052, 0.0113, 0.0036, 0.0042, 0.0236,
        0.0044, 0.0180, 0.0108, 0.0038, 0.0492, 0.0119, 0.0961, 0.0272, 0.0153],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,877][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([4.4005e-05, 8.3026e-07, 7.5147e-06, 6.7058e-05, 4.0231e-04, 4.0542e-03,
        2.9159e-04, 1.4528e-02, 1.9663e-03, 6.0242e-02, 2.2931e-03, 2.8094e-03,
        2.8183e-02, 8.9910e-03, 1.3148e-03, 8.6695e-01, 5.2762e-03, 2.5803e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,879][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0016, 0.0311, 0.0180, 0.0397, 0.0846, 0.0434, 0.0524, 0.0380, 0.0853,
        0.0501, 0.0545, 0.0583, 0.0505, 0.0771, 0.1367, 0.0570, 0.0505, 0.0712],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,880][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0040, 0.0463, 0.0560, 0.0439, 0.0557, 0.0446, 0.0594, 0.0729, 0.0635,
        0.0483, 0.0554, 0.0596, 0.0585, 0.0749, 0.0633, 0.0623, 0.0673, 0.0642],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,882][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0282, 0.0554, 0.0506, 0.0533, 0.0581, 0.0592, 0.0564, 0.0570, 0.0574,
        0.0589, 0.0580, 0.0576, 0.0574, 0.0592, 0.0611, 0.0589, 0.0563, 0.0568],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,883][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([4.3105e-06, 1.2201e-06, 4.7378e-09, 6.4600e-07, 8.6326e-08, 3.5312e-06,
        6.8319e-08, 1.9668e-06, 1.2160e-05, 1.9336e-06, 8.1746e-06, 1.9602e-04,
        3.4959e-04, 5.2203e-01, 4.9916e-06, 3.6502e-01, 9.6874e-02, 1.5495e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,883][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0099, 0.1300, 0.3768, 0.0060, 0.0402, 0.0189, 0.1641, 0.0182, 0.0016,
        0.0083, 0.0007, 0.0103, 0.0032, 0.0046, 0.0010, 0.0256, 0.1796, 0.0010],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,884][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0824, 0.0169, 0.2641, 0.0177, 0.1537, 0.0249, 0.0254, 0.0232, 0.0110,
        0.0260, 0.0081, 0.0438, 0.0125, 0.0810, 0.0267, 0.0591, 0.1100, 0.0135],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:53,884][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0099, 0.0186, 0.0218, 0.0165, 0.1144, 0.0846, 0.0327, 0.0765, 0.0527,
        0.0580, 0.0232, 0.0271, 0.0793, 0.0264, 0.1309, 0.1105, 0.0215, 0.0840,
        0.0116], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,885][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.5689e-05, 1.0634e-02, 2.3003e-02, 1.7776e-02, 2.4577e-01, 4.7267e-03,
        1.1275e-02, 1.8614e-03, 1.9874e-02, 3.3446e-03, 1.8081e-02, 1.1174e-02,
        1.2153e-02, 3.8221e-02, 4.1784e-01, 4.8652e-02, 1.7659e-02, 3.3316e-02,
        6.4619e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,885][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0366, 0.0043, 0.0229, 0.0056, 0.1739, 0.1029, 0.0290, 0.0090, 0.0285,
        0.0099, 0.0147, 0.0400, 0.0669, 0.0010, 0.2814, 0.0528, 0.0342, 0.0428,
        0.0437], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,885][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6664, 0.0190, 0.0203, 0.0041, 0.0133, 0.0084, 0.0091, 0.0122, 0.0071,
        0.0075, 0.0213, 0.0127, 0.0264, 0.0307, 0.0203, 0.0408, 0.0362, 0.0180,
        0.0263], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,886][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8027, 0.0172, 0.0025, 0.0075, 0.0030, 0.0025, 0.0020, 0.0016, 0.0125,
        0.0013, 0.0077, 0.0080, 0.0017, 0.0428, 0.0116, 0.0269, 0.0186, 0.0040,
        0.0258], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,887][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.1062e-03, 1.3719e-04, 2.8100e-04, 5.6543e-04, 3.3014e-03, 1.8258e-02,
        2.1120e-03, 4.0257e-02, 2.0619e-03, 1.0731e-01, 4.7015e-03, 5.5230e-03,
        1.8604e-02, 7.4241e-03, 4.0659e-03, 7.6446e-01, 7.8652e-03, 4.6142e-03,
        5.3548e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,888][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0034, 0.0195, 0.0182, 0.0262, 0.0846, 0.0332, 0.0488, 0.0429, 0.0810,
        0.0384, 0.0429, 0.0591, 0.0512, 0.0672, 0.1730, 0.0529, 0.0489, 0.0582,
        0.0503], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,890][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0041, 0.0419, 0.0542, 0.0440, 0.0509, 0.0426, 0.0551, 0.0696, 0.0591,
        0.0468, 0.0546, 0.0588, 0.0518, 0.0697, 0.0565, 0.0547, 0.0617, 0.0545,
        0.0693], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,892][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0251, 0.0518, 0.0477, 0.0509, 0.0548, 0.0561, 0.0550, 0.0539, 0.0546,
        0.0549, 0.0551, 0.0554, 0.0541, 0.0561, 0.0575, 0.0552, 0.0541, 0.0534,
        0.0546], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,893][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.1261e-04, 3.4169e-06, 3.7702e-09, 4.5059e-07, 5.3976e-08, 2.6866e-06,
        7.2069e-08, 2.4627e-06, 9.8783e-06, 1.6111e-06, 4.7467e-06, 1.2571e-04,
        8.8231e-05, 4.3871e-01, 3.2740e-06, 2.5628e-01, 7.4301e-02, 1.9277e-02,
        2.1108e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,893][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0035, 0.1330, 0.3931, 0.0045, 0.0270, 0.0159, 0.1967, 0.0210, 0.0014,
        0.0063, 0.0005, 0.0090, 0.0023, 0.0034, 0.0006, 0.0168, 0.1452, 0.0011,
        0.0188], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,894][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1597, 0.0067, 0.1375, 0.0069, 0.1211, 0.0109, 0.0153, 0.0186, 0.0118,
        0.0182, 0.0152, 0.0510, 0.0186, 0.0616, 0.0668, 0.0734, 0.1069, 0.0151,
        0.0846], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:53,951][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:53,952][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,953][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,953][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,954][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,954][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,954][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,955][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,955][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,955][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,956][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,956][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,958][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:53,959][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7895, 0.2105], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,961][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,962][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6925, 0.3075], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,963][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9883, 0.0117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,964][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9930, 0.0070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,964][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3455, 0.6545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,964][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3910, 0.6090], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,964][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([9.9922e-01, 7.7910e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,965][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9732, 0.0268], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,965][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5753, 0.4247], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,965][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3464, 0.6536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,965][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9984e-01, 1.5918e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:53,966][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.0743, 0.6419, 0.2838], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,966][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([9.8951e-05, 8.6537e-01, 1.3453e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,967][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([0.2812, 0.5657, 0.1531], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,969][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.8146, 0.1468, 0.0386], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,970][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.8762, 0.1147, 0.0092], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,972][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.0191, 0.3814, 0.5995], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,973][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.0514, 0.7764, 0.1721], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,974][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([9.9839e-01, 4.6078e-04, 1.1516e-03], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,974][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.6674, 0.2017, 0.1309], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,974][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.0455, 0.6884, 0.2661], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,974][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([0.0425, 0.3997, 0.5577], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,975][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.6883, 0.0366, 0.2751], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:53,975][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0850, 0.5596, 0.1954, 0.1601], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,975][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.3198e-05, 2.6291e-01, 2.6186e-01, 4.7516e-01], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,975][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2127, 0.3226, 0.1156, 0.3492], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,976][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7669, 0.1102, 0.0770, 0.0459], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,976][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9582, 0.0291, 0.0037, 0.0090], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,977][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4432, 0.1712, 0.3132, 0.0723], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,978][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0882, 0.3283, 0.2407, 0.3428], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,980][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.9678e-01, 1.0543e-03, 1.5419e-03, 6.2314e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,981][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4338, 0.1971, 0.1545, 0.2146], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,982][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5799, 0.1512, 0.0374, 0.2315], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,984][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0879, 0.1752, 0.7313, 0.0057], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,985][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.5561e-01, 1.1326e-03, 4.2350e-02, 9.1094e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:53,987][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0357, 0.3200, 0.1145, 0.0965, 0.4333], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,988][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([5.2166e-06, 1.0063e-01, 6.9735e-02, 2.5139e-01, 5.7824e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,989][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0402, 0.2078, 0.1789, 0.3928, 0.1804], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,989][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.2424, 0.2088, 0.2326, 0.1114, 0.2050], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,990][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.9069, 0.0557, 0.0045, 0.0264, 0.0065], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,990][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0175, 0.0427, 0.0739, 0.0774, 0.7885], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,990][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0048, 0.0841, 0.0363, 0.0529, 0.8219], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,991][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([9.8283e-01, 1.7600e-03, 5.4401e-03, 4.1738e-04, 9.5553e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,991][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1729, 0.1056, 0.1143, 0.0772, 0.5300], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,991][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0105, 0.0342, 0.0133, 0.3960, 0.5460], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,991][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0078, 0.1983, 0.5441, 0.0079, 0.2419], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,992][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.4688, 0.0259, 0.2387, 0.0235, 0.2430], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:53,992][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0132, 0.3316, 0.2093, 0.1007, 0.1857, 0.1594], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,992][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([6.0519e-05, 7.7443e-02, 1.9525e-01, 1.2824e-01, 5.6610e-01, 3.2909e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,993][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0318, 0.1751, 0.1520, 0.3440, 0.0905, 0.2065], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,993][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5986, 0.1242, 0.0781, 0.0542, 0.0767, 0.0682], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,995][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.7329, 0.1377, 0.0113, 0.0779, 0.0122, 0.0280], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,997][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1357, 0.0456, 0.0399, 0.0264, 0.1357, 0.6168], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,998][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0052, 0.0504, 0.0718, 0.0646, 0.7121, 0.0959], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:53,999][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([9.8388e-01, 2.7031e-03, 5.8750e-03, 8.4573e-04, 2.8109e-03, 3.8898e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,001][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0526, 0.1190, 0.1914, 0.1279, 0.3199, 0.1892], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,001][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0354, 0.0204, 0.0023, 0.0202, 0.0663, 0.8554], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,001][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0399, 0.1154, 0.7318, 0.0061, 0.0983, 0.0085], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,001][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1863, 0.0203, 0.4462, 0.0384, 0.2303, 0.0785], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,002][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0246, 0.3967, 0.0953, 0.0878, 0.1777, 0.1130, 0.1050],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,002][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.8499e-05, 9.5543e-02, 1.4153e-01, 1.8830e-01, 5.0137e-01, 2.8155e-02,
        4.5079e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,002][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0268, 0.2313, 0.1412, 0.2375, 0.1162, 0.1231, 0.1238],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,003][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3808, 0.1702, 0.0753, 0.0825, 0.0704, 0.1463, 0.0745],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,003][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5070, 0.2743, 0.0073, 0.1027, 0.0209, 0.0580, 0.0297],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,003][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0013, 0.0085, 0.0254, 0.0091, 0.1631, 0.7916, 0.0010],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,005][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0050, 0.1034, 0.0601, 0.1138, 0.5334, 0.1010, 0.0832],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,007][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.9753, 0.0041, 0.0072, 0.0016, 0.0040, 0.0033, 0.0045],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,008][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0745, 0.0881, 0.1805, 0.1036, 0.3021, 0.1617, 0.0895],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,009][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.1067e-04, 8.4825e-03, 1.5933e-03, 2.3656e-02, 7.7928e-02, 8.8498e-01,
        3.0539e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,010][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0154, 0.2127, 0.5993, 0.0092, 0.1318, 0.0100, 0.0216],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,011][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2068, 0.0214, 0.3178, 0.0262, 0.2979, 0.0665, 0.0635],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,011][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0067, 0.2079, 0.0858, 0.0892, 0.2395, 0.1137, 0.1096, 0.1478],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,011][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([9.0501e-06, 1.2296e-01, 6.1981e-02, 6.6243e-02, 6.6832e-01, 1.8484e-02,
        5.7593e-02, 4.4100e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,012][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0135, 0.3046, 0.0548, 0.2404, 0.0686, 0.1188, 0.1590, 0.0403],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,012][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1744, 0.2451, 0.0908, 0.0427, 0.1558, 0.1113, 0.0879, 0.0921],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,012][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.3172, 0.4790, 0.0239, 0.0611, 0.0653, 0.0239, 0.0224, 0.0071],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,013][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0018, 0.0278, 0.0313, 0.0226, 0.1607, 0.6899, 0.0030, 0.0628],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,013][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0007, 0.0427, 0.0281, 0.0325, 0.6641, 0.0388, 0.0706, 0.1225],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,013][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.8947, 0.0099, 0.0371, 0.0049, 0.0223, 0.0073, 0.0132, 0.0107],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,014][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0359, 0.0799, 0.1005, 0.0371, 0.3913, 0.1453, 0.1394, 0.0705],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,016][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0029, 0.0173, 0.0011, 0.0114, 0.0306, 0.6702, 0.0023, 0.2642],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,017][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0070, 0.1122, 0.4753, 0.0071, 0.2863, 0.0206, 0.0822, 0.0093],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,019][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0381, 0.0199, 0.3788, 0.0113, 0.4071, 0.0358, 0.0656, 0.0435],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,020][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0344, 0.2041, 0.0600, 0.0563, 0.0848, 0.0655, 0.0801, 0.1242, 0.2907],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,021][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([3.1360e-05, 5.4798e-02, 1.3029e-01, 1.2220e-01, 5.1799e-01, 2.0942e-02,
        4.4410e-02, 1.1230e-02, 9.8112e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,021][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0305, 0.1240, 0.0805, 0.1427, 0.0727, 0.1005, 0.1244, 0.0533, 0.2715],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,022][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.3881, 0.1330, 0.0789, 0.0442, 0.0688, 0.1006, 0.0615, 0.0609, 0.0639],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,022][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.6257, 0.1209, 0.0097, 0.0843, 0.0120, 0.0197, 0.0145, 0.0170, 0.0964],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,022][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0196, 0.0062, 0.0158, 0.0118, 0.0697, 0.6641, 0.0017, 0.0753, 0.1357],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,023][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0017, 0.0280, 0.0258, 0.0256, 0.5594, 0.0208, 0.0397, 0.0635, 0.2354],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,023][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.9603, 0.0023, 0.0108, 0.0013, 0.0080, 0.0027, 0.0045, 0.0035, 0.0066],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,023][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.1117, 0.0497, 0.1095, 0.0406, 0.1524, 0.1754, 0.1293, 0.0491, 0.1823],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,023][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.3035e-02, 2.6915e-03, 3.3470e-04, 1.0294e-02, 9.0321e-03, 3.4368e-01,
        1.8813e-03, 1.3362e-01, 4.8543e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,024][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0333, 0.1147, 0.6672, 0.0052, 0.1245, 0.0107, 0.0334, 0.0069, 0.0041],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,026][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0650, 0.0112, 0.3942, 0.0203, 0.3078, 0.0394, 0.0518, 0.0644, 0.0459],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,028][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0041, 0.1806, 0.0419, 0.0546, 0.1046, 0.0942, 0.0930, 0.0939, 0.2304,
        0.1027], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,029][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.2566e-05, 1.0087e-01, 7.7279e-02, 1.1565e-01, 4.8619e-01, 2.2915e-02,
        4.9351e-02, 6.1362e-03, 1.2478e-01, 1.6817e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,030][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0132, 0.1120, 0.0538, 0.2372, 0.0612, 0.0927, 0.0987, 0.0330, 0.1636,
        0.1345], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,031][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0810, 0.2114, 0.1319, 0.0943, 0.1297, 0.1097, 0.0692, 0.0469, 0.0628,
        0.0631], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,032][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.4669, 0.2871, 0.0124, 0.0532, 0.0222, 0.0283, 0.0131, 0.0161, 0.0798,
        0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,032][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0017, 0.0104, 0.0084, 0.0078, 0.0388, 0.3507, 0.0010, 0.0355, 0.1051,
        0.4406], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,032][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([3.7847e-04, 3.8336e-02, 1.4596e-02, 4.3854e-02, 5.5615e-01, 2.6274e-02,
        2.1591e-02, 4.7881e-02, 1.7013e-01, 8.0810e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,033][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.9407, 0.0065, 0.0246, 0.0014, 0.0115, 0.0038, 0.0039, 0.0024, 0.0035,
        0.0017], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,033][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0389, 0.1037, 0.1634, 0.0525, 0.2809, 0.0719, 0.0467, 0.0393, 0.1101,
        0.0925], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,033][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([7.1270e-04, 4.2216e-03, 1.9419e-04, 3.8876e-03, 4.7147e-03, 1.7751e-01,
        5.5006e-04, 7.8945e-02, 3.2929e-01, 3.9998e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,034][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0044, 0.1617, 0.5088, 0.0113, 0.2391, 0.0165, 0.0365, 0.0048, 0.0043,
        0.0125], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,034][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0075, 0.0114, 0.4015, 0.0135, 0.3986, 0.0360, 0.0454, 0.0271, 0.0184,
        0.0405], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,034][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0055, 0.1701, 0.0948, 0.0482, 0.1246, 0.0480, 0.0600, 0.0619, 0.1607,
        0.0520, 0.1741], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,036][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.0898e-05, 5.9057e-02, 8.1730e-02, 6.7257e-02, 5.1715e-01, 2.5066e-02,
        4.4241e-02, 9.8861e-03, 1.2135e-01, 1.7096e-02, 5.7160e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,037][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0143, 0.0395, 0.0623, 0.1257, 0.0738, 0.0644, 0.0764, 0.0552, 0.2130,
        0.0705, 0.2047], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,039][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.2137, 0.1070, 0.1416, 0.0427, 0.0675, 0.0605, 0.0750, 0.0726, 0.0893,
        0.0493, 0.0807], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,040][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.4787, 0.1696, 0.0185, 0.0871, 0.0287, 0.0266, 0.0245, 0.0243, 0.0780,
        0.0125, 0.0515], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,041][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0102, 0.0044, 0.0094, 0.0082, 0.0425, 0.2622, 0.0014, 0.0398, 0.0622,
        0.3998, 0.1599], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,042][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0009, 0.0320, 0.0257, 0.0310, 0.3783, 0.0367, 0.0433, 0.0759, 0.2205,
        0.0578, 0.0979], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,042][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.8077, 0.0077, 0.0367, 0.0046, 0.0270, 0.0127, 0.0111, 0.0074, 0.0172,
        0.0053, 0.0625], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,042][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0947, 0.0296, 0.1154, 0.0391, 0.2084, 0.0958, 0.0828, 0.0634, 0.1243,
        0.0698, 0.0766], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,043][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([6.8136e-03, 1.1171e-03, 1.4444e-04, 3.2038e-03, 4.5906e-03, 1.2385e-01,
        1.0465e-03, 9.2808e-02, 2.0258e-01, 4.2740e-01, 1.3645e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,043][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([1.0797e-02, 1.0026e-01, 7.0659e-01, 2.8236e-03, 1.3043e-01, 9.7678e-03,
        2.2962e-02, 4.9482e-03, 1.9222e-03, 9.0907e-03, 4.1109e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,043][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0399, 0.0078, 0.4213, 0.0154, 0.2178, 0.0277, 0.0443, 0.0681, 0.0315,
        0.0788, 0.0475], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,044][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0162, 0.1399, 0.0737, 0.0342, 0.1016, 0.0344, 0.0478, 0.0407, 0.1076,
        0.0477, 0.1908, 0.1655], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,044][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.2526e-05, 4.2696e-02, 9.0960e-02, 5.7709e-02, 5.5013e-01, 1.2604e-02,
        4.1824e-02, 7.8512e-03, 6.2449e-02, 1.5361e-02, 6.2212e-02, 5.6180e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,045][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0423, 0.0873, 0.0996, 0.1047, 0.0468, 0.0398, 0.0774, 0.0339, 0.1415,
        0.0389, 0.1654, 0.1225], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,046][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3268, 0.0746, 0.0881, 0.0313, 0.0355, 0.0637, 0.0539, 0.0567, 0.0471,
        0.0359, 0.1025, 0.0838], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,048][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.6970, 0.0734, 0.0074, 0.0385, 0.0087, 0.0170, 0.0119, 0.0076, 0.0622,
        0.0091, 0.0301, 0.0371], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,049][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([7.7909e-02, 2.8790e-03, 3.2544e-03, 2.1128e-03, 1.2536e-02, 1.3162e-01,
        2.0175e-04, 1.0266e-02, 1.7095e-02, 9.3463e-02, 6.1207e-02, 5.8745e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,050][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0011, 0.0249, 0.0213, 0.0213, 0.3969, 0.0197, 0.0441, 0.0446, 0.1927,
        0.0415, 0.0760, 0.1157], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,051][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([9.3483e-01, 3.1240e-03, 8.0827e-03, 1.0970e-03, 6.5180e-03, 2.1241e-03,
        3.5729e-03, 1.9669e-03, 2.9682e-03, 6.8827e-04, 1.2825e-02, 2.2204e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,052][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1008, 0.0409, 0.0754, 0.0315, 0.1194, 0.1247, 0.1022, 0.0567, 0.0886,
        0.0676, 0.1080, 0.0841], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,052][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.6029e-02, 7.1140e-04, 3.3956e-05, 9.1267e-04, 6.2907e-04, 1.6560e-02,
        1.5386e-04, 1.4673e-02, 7.1754e-02, 8.4214e-02, 3.9727e-02, 7.5460e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,052][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.9915e-02, 1.3167e-01, 6.6325e-01, 3.8290e-03, 1.2435e-01, 6.6331e-03,
        2.8441e-02, 4.2196e-03, 1.8149e-03, 7.0273e-03, 5.1311e-04, 8.3370e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,053][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0295, 0.0194, 0.3303, 0.0185, 0.2618, 0.0239, 0.0351, 0.0324, 0.0288,
        0.0507, 0.0519, 0.1178], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,053][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.0116, 0.0728, 0.0281, 0.0215, 0.0552, 0.0494, 0.0324, 0.0523, 0.1469,
        0.0509, 0.2181, 0.1645, 0.0965], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,053][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([1.0266e-05, 4.0583e-02, 5.3002e-02, 7.4042e-02, 5.2605e-01, 1.6125e-02,
        1.9890e-02, 4.8617e-03, 8.8650e-02, 1.0775e-02, 1.0241e-01, 4.1139e-02,
        2.2466e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,054][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0260, 0.0699, 0.0461, 0.0751, 0.0348, 0.0624, 0.0770, 0.0376, 0.1625,
        0.1143, 0.1551, 0.0887, 0.0505], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,054][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([0.2630, 0.0956, 0.0423, 0.0198, 0.0566, 0.0366, 0.0312, 0.0502, 0.0481,
        0.0661, 0.0838, 0.0566, 0.1503], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,055][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.4421, 0.1445, 0.0083, 0.0562, 0.0252, 0.0330, 0.0193, 0.0102, 0.1215,
        0.0137, 0.0533, 0.0579, 0.0148], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,056][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([6.6595e-03, 2.9427e-04, 1.8850e-04, 3.0022e-04, 6.2783e-04, 1.2689e-02,
        2.9357e-05, 1.0449e-03, 2.7635e-03, 1.1887e-02, 1.2399e-02, 1.0682e-01,
        8.4430e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,058][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([0.0021, 0.0196, 0.0223, 0.0150, 0.3760, 0.0304, 0.0250, 0.0503, 0.1517,
        0.0945, 0.0907, 0.0670, 0.0553], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,059][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.9327, 0.0027, 0.0139, 0.0012, 0.0070, 0.0029, 0.0032, 0.0027, 0.0035,
        0.0018, 0.0120, 0.0116, 0.0048], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,061][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.1341, 0.0324, 0.0820, 0.0145, 0.1982, 0.0603, 0.0225, 0.0377, 0.0555,
        0.1060, 0.0648, 0.0447, 0.1473], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,061][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([2.0555e-03, 1.4018e-05, 8.0329e-07, 2.9113e-05, 2.8475e-05, 8.4721e-04,
        5.0945e-06, 7.4773e-04, 2.6716e-03, 4.0972e-03, 1.4097e-03, 4.6831e-02,
        9.4126e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,062][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([0.0248, 0.1729, 0.5234, 0.0070, 0.1599, 0.0133, 0.0281, 0.0062, 0.0041,
        0.0205, 0.0011, 0.0134, 0.0254], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,062][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([0.1644, 0.0131, 0.2328, 0.0091, 0.1037, 0.0250, 0.0512, 0.1033, 0.0218,
        0.0712, 0.0525, 0.1133, 0.0386], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,063][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0167, 0.0777, 0.0624, 0.0340, 0.0740, 0.0427, 0.0503, 0.0308, 0.0729,
        0.0253, 0.1388, 0.1055, 0.1480, 0.1208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,063][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.6889e-05, 4.4987e-02, 8.7432e-02, 4.7725e-02, 5.0453e-01, 1.8654e-02,
        2.8294e-02, 4.6311e-03, 4.7274e-02, 1.1133e-02, 4.3996e-02, 2.3752e-02,
        2.6530e-02, 1.1103e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,063][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1054, 0.0456, 0.0547, 0.0618, 0.0333, 0.0546, 0.0723, 0.0307, 0.0886,
        0.0354, 0.1231, 0.0960, 0.0720, 0.1267], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,064][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.4408, 0.0356, 0.0727, 0.0126, 0.0421, 0.0380, 0.0335, 0.0261, 0.0175,
        0.0187, 0.0513, 0.0440, 0.0689, 0.0983], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,064][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.7827, 0.0381, 0.0067, 0.0137, 0.0052, 0.0072, 0.0048, 0.0034, 0.0168,
        0.0021, 0.0104, 0.0158, 0.0042, 0.0888], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,065][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.0377e-01, 4.0711e-04, 2.8885e-05, 3.1211e-05, 8.1769e-05, 3.2682e-04,
        1.2958e-06, 3.2807e-05, 5.6782e-05, 2.5973e-04, 2.4802e-04, 1.9629e-03,
        7.4487e-03, 8.8534e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,065][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0015, 0.0192, 0.0351, 0.0227, 0.2891, 0.0231, 0.0243, 0.0269, 0.0760,
        0.0235, 0.0477, 0.0656, 0.0725, 0.2727], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,066][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([9.6103e-01, 7.0891e-04, 5.4386e-03, 3.9948e-04, 2.8808e-03, 1.1348e-03,
        1.3427e-03, 8.0416e-04, 2.2913e-03, 3.0951e-04, 3.9252e-03, 9.2092e-03,
        1.0999e-03, 9.4256e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,068][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2601, 0.0132, 0.0593, 0.0181, 0.1220, 0.0760, 0.0451, 0.0336, 0.0624,
        0.0402, 0.0731, 0.0484, 0.0736, 0.0748], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,069][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.6073e-02, 2.1013e-05, 6.4539e-08, 1.1298e-06, 3.3595e-07, 8.5401e-06,
        5.9251e-08, 2.3842e-06, 8.7551e-06, 1.1232e-05, 9.0725e-06, 1.1804e-04,
        5.6981e-04, 9.6318e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,070][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([4.6184e-02, 8.1950e-02, 6.4378e-01, 4.7220e-03, 1.1776e-01, 1.3950e-02,
        3.0100e-02, 3.2061e-03, 2.1611e-03, 4.8552e-03, 6.2981e-04, 8.9831e-03,
        1.9494e-02, 2.2217e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,071][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.4258, 0.0060, 0.1930, 0.0067, 0.1446, 0.0152, 0.0125, 0.0209, 0.0140,
        0.0181, 0.0131, 0.0357, 0.0187, 0.0757], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,072][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0038, 0.0582, 0.0371, 0.0351, 0.0782, 0.0368, 0.0411, 0.0379, 0.0770,
        0.0263, 0.1002, 0.0950, 0.1364, 0.0990, 0.1380], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,073][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.0993e-07, 3.3073e-02, 3.5212e-02, 7.9328e-02, 3.2187e-01, 9.0811e-03,
        3.2768e-02, 2.7810e-03, 4.0842e-02, 1.6182e-03, 5.7718e-02, 2.5788e-02,
        1.8621e-02, 4.9708e-02, 2.9159e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,073][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0167, 0.0654, 0.1312, 0.1444, 0.0642, 0.0612, 0.0521, 0.0194, 0.0979,
        0.0169, 0.0652, 0.0611, 0.0327, 0.1180, 0.0535], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,073][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0435, 0.0502, 0.1457, 0.0289, 0.0682, 0.0370, 0.0364, 0.0430, 0.0364,
        0.0266, 0.1025, 0.0670, 0.1174, 0.1011, 0.0961], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,074][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.2671, 0.0651, 0.0100, 0.0435, 0.0120, 0.0302, 0.0191, 0.0217, 0.1006,
        0.0171, 0.0542, 0.0639, 0.0194, 0.2262, 0.0498], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,074][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([1.0017e-05, 3.4704e-06, 2.5575e-06, 4.3690e-06, 2.6453e-05, 2.1591e-04,
        4.6875e-07, 2.0952e-05, 3.1493e-05, 2.0815e-04, 9.3057e-05, 1.1956e-03,
        1.4755e-02, 9.8224e-01, 1.1937e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,074][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([1.3878e-04, 1.1819e-02, 8.2253e-03, 1.3264e-02, 2.3757e-01, 6.8216e-03,
        1.1951e-02, 2.1673e-02, 5.6136e-02, 1.7783e-02, 3.8439e-02, 3.5691e-02,
        3.1975e-02, 9.4805e-02, 4.1371e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,075][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.7451, 0.0048, 0.0266, 0.0014, 0.0225, 0.0034, 0.0040, 0.0038, 0.0122,
        0.0016, 0.0131, 0.0324, 0.0060, 0.0266, 0.0966], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,076][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0596, 0.0199, 0.0518, 0.0142, 0.1963, 0.0524, 0.0345, 0.0311, 0.0445,
        0.0759, 0.0609, 0.0448, 0.0580, 0.0469, 0.2093], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,077][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([4.5959e-08, 7.1066e-08, 4.4608e-09, 3.0457e-07, 9.6143e-08, 3.4911e-06,
        1.3608e-08, 1.2076e-06, 6.1724e-06, 9.0324e-06, 3.0825e-06, 1.0719e-04,
        1.4978e-03, 9.9836e-01, 7.4306e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,079][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0044, 0.1115, 0.4919, 0.0078, 0.2485, 0.0073, 0.0399, 0.0041, 0.0021,
        0.0054, 0.0006, 0.0096, 0.0356, 0.0184, 0.0129], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,080][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0041, 0.0187, 0.1425, 0.0255, 0.1759, 0.0285, 0.0803, 0.0357, 0.0254,
        0.0292, 0.0137, 0.1256, 0.0397, 0.1451, 0.1102], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,082][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0059, 0.0594, 0.0511, 0.0265, 0.0553, 0.0284, 0.0255, 0.0191, 0.0601,
        0.0381, 0.0656, 0.0621, 0.0681, 0.1198, 0.1049, 0.2101],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,082][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.9637e-05, 2.8219e-02, 4.7408e-02, 4.0626e-02, 2.8605e-01, 5.8946e-03,
        1.4829e-02, 3.6823e-03, 3.5214e-02, 7.1144e-03, 6.4392e-02, 2.3531e-02,
        3.9390e-02, 8.8534e-02, 2.8370e-01, 3.1394e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,083][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0157, 0.0227, 0.0582, 0.0584, 0.0364, 0.0475, 0.0530, 0.0322, 0.1207,
        0.0347, 0.1069, 0.0708, 0.0629, 0.0887, 0.0732, 0.1178],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,083][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1549, 0.0166, 0.0608, 0.0104, 0.0602, 0.0187, 0.0328, 0.0207, 0.0390,
        0.0326, 0.0626, 0.0514, 0.0826, 0.0959, 0.1541, 0.1067],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,083][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.5541, 0.0355, 0.0060, 0.0346, 0.0090, 0.0155, 0.0062, 0.0047, 0.0366,
        0.0047, 0.0159, 0.0206, 0.0051, 0.1709, 0.0336, 0.0469],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,084][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9986e-03, 5.5449e-06, 7.0103e-07, 7.0250e-07, 1.1723e-06, 1.5500e-05,
        3.4571e-08, 9.1243e-07, 2.9842e-06, 7.3919e-06, 8.9357e-06, 7.4465e-05,
        4.5126e-04, 5.6625e-02, 3.3483e-05, 9.3877e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,084][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0007, 0.0081, 0.0108, 0.0083, 0.2648, 0.0096, 0.0093, 0.0196, 0.0417,
        0.0216, 0.0234, 0.0290, 0.0247, 0.1306, 0.3679, 0.0301],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,085][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.8659, 0.0015, 0.0137, 0.0016, 0.0050, 0.0034, 0.0020, 0.0014, 0.0060,
        0.0009, 0.0183, 0.0130, 0.0032, 0.0168, 0.0333, 0.0140],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,085][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0317, 0.0231, 0.0902, 0.0317, 0.1099, 0.0400, 0.0420, 0.0167, 0.0932,
        0.0214, 0.0919, 0.0730, 0.0929, 0.0835, 0.1106, 0.0483],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,086][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.6666e-03, 6.4526e-07, 3.2075e-09, 5.5463e-08, 3.3169e-08, 6.4665e-07,
        3.7144e-09, 2.8414e-07, 1.1594e-06, 1.3406e-06, 1.2246e-06, 2.1602e-05,
        1.6824e-04, 2.6193e-01, 3.1643e-06, 7.3521e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,087][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0448, 0.0575, 0.4253, 0.0076, 0.2193, 0.0098, 0.0378, 0.0045, 0.0030,
        0.0089, 0.0016, 0.0165, 0.0639, 0.0285, 0.0188, 0.0523],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,089][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3325, 0.0107, 0.2187, 0.0090, 0.0913, 0.0135, 0.0095, 0.0214, 0.0136,
        0.0158, 0.0193, 0.0378, 0.0139, 0.0989, 0.0315, 0.0625],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,091][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0463, 0.0655, 0.0274, 0.0229, 0.0380, 0.0234, 0.0309, 0.0226, 0.0662,
        0.0134, 0.1054, 0.0854, 0.0686, 0.0745, 0.0552, 0.1218, 0.1327],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,092][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.3054e-05, 2.0445e-02, 4.3033e-02, 4.8746e-02, 2.4202e-01, 9.4933e-03,
        2.3976e-02, 2.9711e-03, 3.4764e-02, 4.5699e-03, 5.0511e-02, 2.5953e-02,
        1.3999e-02, 5.4403e-02, 3.3629e-01, 4.8360e-02, 4.0430e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,092][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0439, 0.0546, 0.0692, 0.0962, 0.0301, 0.0380, 0.0637, 0.0243, 0.0716,
        0.0257, 0.0906, 0.0690, 0.0410, 0.0844, 0.0336, 0.0639, 0.1002],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,093][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4956, 0.0200, 0.0372, 0.0105, 0.0136, 0.0268, 0.0202, 0.0164, 0.0160,
        0.0077, 0.0397, 0.0326, 0.0310, 0.0522, 0.0202, 0.0819, 0.0784],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,093][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8119, 0.0186, 0.0017, 0.0103, 0.0020, 0.0062, 0.0030, 0.0025, 0.0174,
        0.0018, 0.0112, 0.0089, 0.0016, 0.0463, 0.0062, 0.0292, 0.0211],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,094][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([6.4816e-04, 1.9357e-06, 3.6542e-07, 4.1544e-07, 1.3676e-06, 9.4467e-06,
        2.0391e-08, 9.7838e-07, 1.7991e-06, 5.0221e-06, 5.4274e-06, 4.1025e-05,
        2.4197e-04, 2.3364e-02, 3.3737e-05, 9.7084e-01, 4.8065e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,094][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0039, 0.0116, 0.0147, 0.0152, 0.1347, 0.0191, 0.0205, 0.0239, 0.0805,
        0.0171, 0.0444, 0.0692, 0.0207, 0.1147, 0.2989, 0.0279, 0.0830],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,094][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([9.1005e-01, 1.5463e-03, 7.0005e-03, 6.8771e-04, 2.8142e-03, 1.3174e-03,
        2.3456e-03, 1.3896e-03, 2.3532e-03, 3.3129e-04, 7.7019e-03, 1.4811e-02,
        1.5510e-03, 1.3658e-02, 1.3409e-02, 1.6538e-03, 1.7384e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,095][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0588, 0.0125, 0.0489, 0.0289, 0.0902, 0.0533, 0.0346, 0.0436, 0.0768,
        0.0362, 0.0933, 0.0528, 0.0511, 0.0873, 0.1299, 0.0466, 0.0551],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,095][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0764e-04, 4.7274e-07, 2.7287e-09, 6.7586e-08, 2.3198e-08, 7.4634e-07,
        3.4188e-09, 5.6095e-07, 1.9867e-06, 1.4062e-06, 1.3413e-06, 1.6708e-05,
        1.2020e-04, 1.9786e-01, 1.7141e-06, 7.7380e-01, 2.7786e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,097][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0530, 0.0685, 0.4281, 0.0051, 0.0832, 0.0071, 0.0292, 0.0023, 0.0018,
        0.0036, 0.0005, 0.0067, 0.0135, 0.0168, 0.0043, 0.0366, 0.2395],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,098][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1167, 0.0142, 0.1907, 0.0171, 0.1857, 0.0274, 0.0303, 0.0237, 0.0163,
        0.0235, 0.0286, 0.0374, 0.0158, 0.0433, 0.0619, 0.0758, 0.0916],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,100][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0208, 0.0470, 0.0158, 0.0184, 0.0668, 0.0455, 0.0261, 0.0229, 0.0791,
        0.0288, 0.1220, 0.0575, 0.0579, 0.0672, 0.0512, 0.1277, 0.0762, 0.0689],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,101][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([4.4641e-05, 1.7285e-02, 5.1810e-02, 4.8920e-02, 4.2378e-01, 8.0316e-03,
        9.1293e-03, 1.4729e-03, 2.3527e-02, 3.3316e-03, 3.4495e-02, 1.1665e-02,
        5.9648e-03, 3.1877e-02, 2.7297e-01, 3.2202e-02, 1.1597e-02, 1.1900e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,102][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0197, 0.0641, 0.0431, 0.1233, 0.0395, 0.0309, 0.0517, 0.0160, 0.0900,
        0.0397, 0.0612, 0.0416, 0.0344, 0.0710, 0.0351, 0.1006, 0.0776, 0.0604],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,103][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.2948, 0.0251, 0.0516, 0.0084, 0.0516, 0.0265, 0.0187, 0.0269, 0.0180,
        0.0256, 0.0408, 0.0248, 0.0564, 0.0588, 0.0427, 0.1531, 0.0447, 0.0314],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,103][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.6654, 0.0342, 0.0027, 0.0129, 0.0052, 0.0113, 0.0036, 0.0042, 0.0236,
        0.0044, 0.0180, 0.0108, 0.0038, 0.0492, 0.0119, 0.0961, 0.0272, 0.0153],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,104][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.9440e-04, 4.9165e-06, 8.5759e-07, 6.9293e-07, 2.0520e-06, 1.2716e-05,
        3.8567e-08, 9.6129e-07, 3.6916e-06, 7.9127e-06, 8.8933e-06, 7.1416e-05,
        3.7288e-04, 2.9560e-02, 3.1113e-05, 9.5410e-01, 8.3842e-03, 7.1468e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,104][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0018, 0.0210, 0.0119, 0.0196, 0.2297, 0.0171, 0.0168, 0.0204, 0.0658,
        0.0299, 0.0497, 0.0360, 0.0214, 0.1138, 0.1875, 0.0226, 0.0488, 0.0861],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,104][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([9.4155e-01, 1.3446e-03, 7.0172e-03, 2.9087e-04, 4.7512e-03, 7.2476e-04,
        1.0888e-03, 9.5242e-04, 1.5441e-03, 8.7391e-04, 6.4947e-03, 4.4060e-03,
        1.4209e-03, 4.4750e-03, 1.3670e-02, 1.9889e-03, 4.7220e-03, 2.6877e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,105][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1303, 0.0297, 0.0644, 0.0196, 0.1456, 0.0583, 0.0230, 0.0281, 0.0476,
        0.0509, 0.0530, 0.0249, 0.0591, 0.0391, 0.1329, 0.0345, 0.0227, 0.0363],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,105][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([2.7752e-04, 1.3270e-06, 7.3239e-09, 1.5603e-07, 5.3535e-08, 1.3320e-06,
        8.3430e-09, 4.3308e-07, 1.9471e-06, 1.8652e-06, 1.7439e-06, 2.9791e-05,
        3.4940e-04, 2.3352e-01, 2.8542e-06, 6.9817e-01, 5.0860e-02, 1.6790e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,106][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0225, 0.0675, 0.3859, 0.0068, 0.1890, 0.0093, 0.0236, 0.0022, 0.0017,
        0.0048, 0.0006, 0.0054, 0.0125, 0.0130, 0.0086, 0.0535, 0.1852, 0.0081],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,108][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0824, 0.0169, 0.2641, 0.0177, 0.1537, 0.0249, 0.0254, 0.0232, 0.0110,
        0.0260, 0.0081, 0.0438, 0.0125, 0.0810, 0.0267, 0.0591, 0.1100, 0.0135],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,109][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0369, 0.0326, 0.0257, 0.0137, 0.0446, 0.0149, 0.0211, 0.0147, 0.0581,
        0.0106, 0.0824, 0.0677, 0.0660, 0.0700, 0.0761, 0.0859, 0.0987, 0.0832,
        0.0969], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,110][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.5689e-05, 1.0634e-02, 2.3003e-02, 1.7776e-02, 2.4577e-01, 4.7267e-03,
        1.1275e-02, 1.8614e-03, 1.9874e-02, 3.3446e-03, 1.8081e-02, 1.1174e-02,
        1.2153e-02, 3.8221e-02, 4.1784e-01, 4.8652e-02, 1.7659e-02, 3.3316e-02,
        6.4619e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,112][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0995, 0.0325, 0.0699, 0.0651, 0.0207, 0.0300, 0.0394, 0.0139, 0.0861,
        0.0127, 0.0730, 0.0415, 0.0263, 0.0522, 0.0216, 0.0650, 0.0756, 0.0363,
        0.1386], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,113][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6664, 0.0190, 0.0203, 0.0041, 0.0133, 0.0084, 0.0091, 0.0122, 0.0071,
        0.0075, 0.0213, 0.0127, 0.0264, 0.0307, 0.0203, 0.0408, 0.0362, 0.0180,
        0.0263], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,113][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8027, 0.0172, 0.0025, 0.0075, 0.0030, 0.0025, 0.0020, 0.0016, 0.0125,
        0.0013, 0.0077, 0.0080, 0.0017, 0.0428, 0.0116, 0.0269, 0.0186, 0.0040,
        0.0258], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,114][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.4825e-03, 9.2534e-06, 4.5735e-07, 5.6219e-07, 1.5038e-06, 8.7456e-06,
        5.2281e-08, 1.6258e-06, 1.6615e-06, 8.8766e-06, 7.1328e-06, 6.6236e-05,
        2.4387e-04, 4.0957e-02, 3.3808e-05, 8.8479e-01, 8.6915e-03, 7.6119e-03,
        5.0084e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,114][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0023, 0.0040, 0.0055, 0.0037, 0.1694, 0.0041, 0.0093, 0.0150, 0.0528,
        0.0093, 0.0175, 0.0304, 0.0147, 0.0686, 0.4624, 0.0141, 0.0406, 0.0332,
        0.0433], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,114][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.3787e-01, 7.5735e-04, 4.5750e-03, 2.8550e-04, 2.6011e-03, 5.1715e-04,
        9.6242e-04, 7.1118e-04, 1.6759e-03, 4.0435e-04, 5.9850e-03, 4.7378e-03,
        1.3729e-03, 4.1377e-03, 1.1794e-02, 1.8184e-03, 4.9116e-03, 1.1570e-03,
        1.3722e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,115][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2100, 0.0169, 0.0670, 0.0229, 0.0907, 0.0413, 0.0311, 0.0230, 0.0514,
        0.0219, 0.0517, 0.0348, 0.0369, 0.0491, 0.0972, 0.0321, 0.0358, 0.0210,
        0.0651], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,115][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.2400e-02, 2.9530e-06, 5.8992e-09, 8.4882e-08, 3.2524e-08, 9.3998e-07,
        9.1927e-09, 6.0688e-07, 1.6763e-06, 1.6666e-06, 1.0981e-06, 2.2678e-05,
        8.6508e-05, 2.3210e-01, 1.9367e-06, 4.7005e-01, 3.9513e-02, 1.9818e-02,
        2.2600e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,116][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0840, 0.0343, 0.3319, 0.0022, 0.0695, 0.0064, 0.0320, 0.0027, 0.0016,
        0.0028, 0.0004, 0.0061, 0.0149, 0.0130, 0.0041, 0.0356, 0.2831, 0.0099,
        0.0655], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,118][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1597, 0.0067, 0.1375, 0.0069, 0.1211, 0.0109, 0.0153, 0.0186, 0.0118,
        0.0182, 0.0152, 0.0510, 0.0186, 0.0616, 0.0668, 0.0734, 0.1069, 0.0151,
        0.0846], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,119][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:54,121][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12211],
        [ 3522],
        [ 1386],
        [  151],
        [    8],
        [  219],
        [  155],
        [   46],
        [   73],
        [   22],
        [  118],
        [   67],
        [  143],
        [   28],
        [   20],
        [  107],
        [   51],
        [   15],
        [   21]], device='cuda:0')
[2024-07-24 10:19:54,122][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12924],
        [ 3393],
        [ 8384],
        [  407],
        [   42],
        [  901],
        [  457],
        [  234],
        [  443],
        [  259],
        [  499],
        [  222],
        [  215],
        [   79],
        [   23],
        [  374],
        [  184],
        [   65],
        [  132]], device='cuda:0')
[2024-07-24 10:19:54,124][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[31014],
        [19448],
        [   81],
        [  491],
        [ 1910],
        [ 3108],
        [ 3836],
        [ 4773],
        [ 6184],
        [ 5675],
        [ 6161],
        [ 5877],
        [ 4188],
        [ 4963],
        [ 4277],
        [ 5432],
        [ 5903],
        [ 6328],
        [ 6275]], device='cuda:0')
[2024-07-24 10:19:54,125][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12092],
        [36354],
        [42428],
        [45342],
        [35916],
        [41565],
        [40032],
        [35766],
        [39542],
        [37146],
        [38117],
        [39538],
        [38257],
        [40245],
        [38425],
        [39546],
        [38657],
        [37086],
        [36886]], device='cuda:0')
[2024-07-24 10:19:54,126][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18154],
        [18146],
        [    3],
        [    2],
        [   81],
        [  265],
        [  200],
        [  514],
        [  338],
        [  389],
        [  351],
        [  397],
        [ 1694],
        [  459],
        [ 7410],
        [  302],
        [  321],
        [ 4482],
        [ 1133]], device='cuda:0')
[2024-07-24 10:19:54,127][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[34935],
        [34268],
        [26657],
        [31198],
        [29737],
        [29014],
        [25626],
        [24879],
        [24530],
        [25320],
        [21695],
        [19613],
        [23457],
        [25103],
        [23164],
        [20869],
        [19090],
        [21626],
        [23026]], device='cuda:0')
[2024-07-24 10:19:54,128][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[39103],
        [39795],
        [46438],
        [42284],
        [44361],
        [45561],
        [44351],
        [44365],
        [45250],
        [45737],
        [44652],
        [45678],
        [44711],
        [46112],
        [43616],
        [45042],
        [46244],
        [46869],
        [46531]], device='cuda:0')
[2024-07-24 10:19:54,130][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24616],
        [28483],
        [21878],
        [24398],
        [29719],
        [29515],
        [29452],
        [24946],
        [24802],
        [32046],
        [32023],
        [32241],
        [21144],
        [29505],
        [24937],
        [26901],
        [27322],
        [27373],
        [27859]], device='cuda:0')
[2024-07-24 10:19:54,132][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12130],
        [34849],
        [44411],
        [38649],
        [35287],
        [38461],
        [35821],
        [35407],
        [36497],
        [29076],
        [32627],
        [34785],
        [34638],
        [37626],
        [35452],
        [36371],
        [36861],
        [35646],
        [36162]], device='cuda:0')
[2024-07-24 10:19:54,133][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40170],
        [42884],
        [13030],
        [21949],
        [21270],
        [26283],
        [29024],
        [29897],
        [31330],
        [31904],
        [29731],
        [30490],
        [29876],
        [30415],
        [30704],
        [30287],
        [30558],
        [30992],
        [30225]], device='cuda:0')
[2024-07-24 10:19:54,135][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15724],
        [11462],
        [ 7630],
        [ 9164],
        [10381],
        [11216],
        [11437],
        [11728],
        [11533],
        [11872],
        [11515],
        [11482],
        [11788],
        [11184],
        [11379],
        [11458],
        [11321],
        [11649],
        [11305]], device='cuda:0')
[2024-07-24 10:19:54,136][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24451],
        [33577],
        [32267],
        [36562],
        [36566],
        [38045],
        [38065],
        [32825],
        [31181],
        [30812],
        [29521],
        [36217],
        [36433],
        [39857],
        [39858],
        [37347],
        [36791],
        [37191],
        [36902]], device='cuda:0')
[2024-07-24 10:19:54,137][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32745],
        [ 1769],
        [15610],
        [18584],
        [14841],
        [18224],
        [11417],
        [11412],
        [16238],
        [13742],
        [15059],
        [11678],
        [14126],
        [13337],
        [14288],
        [13511],
        [14138],
        [15529],
        [15831]], device='cuda:0')
[2024-07-24 10:19:54,138][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24410],
        [24415],
        [32332],
        [25594],
        [31055],
        [31752],
        [31003],
        [31407],
        [32604],
        [31258],
        [33459],
        [33051],
        [36274],
        [32956],
        [31991],
        [33998],
        [32921],
        [32789],
        [34048]], device='cuda:0')
[2024-07-24 10:19:54,140][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8951],
        [26049],
        [25207],
        [22672],
        [19467],
        [ 5787],
        [29887],
        [ 9687],
        [24143],
        [ 4244],
        [17781],
        [13673],
        [ 8195],
        [13075],
        [10865],
        [10427],
        [17104],
        [ 1779],
        [ 2783]], device='cuda:0')
[2024-07-24 10:19:54,141][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12257],
        [11447],
        [21175],
        [18057],
        [22907],
        [19117],
        [17930],
        [17788],
        [19415],
        [20587],
        [23065],
        [20525],
        [21173],
        [22672],
        [23140],
        [19319],
        [20440],
        [19476],
        [19859]], device='cuda:0')
[2024-07-24 10:19:54,143][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[48683],
        [29984],
        [31759],
        [40119],
        [40766],
        [43138],
        [42727],
        [41420],
        [43011],
        [42365],
        [43299],
        [43111],
        [43487],
        [43329],
        [39902],
        [41381],
        [40451],
        [40017],
        [38189]], device='cuda:0')
[2024-07-24 10:19:54,144][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[36135],
        [35500],
        [31461],
        [29013],
        [25622],
        [24315],
        [26781],
        [30263],
        [27844],
        [28482],
        [26340],
        [26853],
        [28657],
        [28740],
        [26900],
        [26847],
        [28186],
        [28059],
        [27299]], device='cuda:0')
[2024-07-24 10:19:54,146][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17444],
        [17721],
        [27674],
        [29234],
        [27882],
        [27950],
        [30788],
        [29656],
        [31138],
        [30041],
        [33887],
        [35522],
        [33743],
        [34810],
        [35249],
        [32696],
        [35577],
        [33452],
        [33507]], device='cuda:0')
[2024-07-24 10:19:54,148][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25493],
        [25405],
        [20730],
        [25118],
        [24348],
        [25776],
        [29843],
        [25971],
        [30495],
        [30028],
        [30932],
        [30230],
        [31050],
        [29021],
        [32947],
        [33015],
        [29553],
        [29742],
        [29925]], device='cuda:0')
[2024-07-24 10:19:54,149][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[26642],
        [15600],
        [24176],
        [26274],
        [33747],
        [22658],
        [22162],
        [23192],
        [21134],
        [24237],
        [23722],
        [23528],
        [28198],
        [24155],
        [24368],
        [19382],
        [19077],
        [19351],
        [19468]], device='cuda:0')
[2024-07-24 10:19:54,149][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[16052],
        [35523],
        [35228],
        [33049],
        [18193],
        [19511],
        [24083],
        [23437],
        [29102],
        [28450],
        [34460],
        [34790],
        [35634],
        [36134],
        [29585],
        [28999],
        [33628],
        [34211],
        [29631]], device='cuda:0')
[2024-07-24 10:19:54,151][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17106],
        [17124],
        [17130],
        [17186],
        [17569],
        [17445],
        [17441],
        [18866],
        [17550],
        [18217],
        [19816],
        [17414],
        [17547],
        [17281],
        [22287],
        [19731],
        [17735],
        [17774],
        [17698]], device='cuda:0')
[2024-07-24 10:19:54,152][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12677],
        [13941],
        [15452],
        [16329],
        [13451],
        [11617],
        [11701],
        [11702],
        [12537],
        [12006],
        [12713],
        [12369],
        [11317],
        [12670],
        [11462],
        [11867],
        [12494],
        [11221],
        [12740]], device='cuda:0')
[2024-07-24 10:19:54,154][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17560],
        [31713],
        [44054],
        [32068],
        [37518],
        [32021],
        [32233],
        [34213],
        [36809],
        [34618],
        [33569],
        [38346],
        [37743],
        [42542],
        [42754],
        [39229],
        [38777],
        [39509],
        [39990]], device='cuda:0')
[2024-07-24 10:19:54,156][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34157],
        [32667],
        [43240],
        [44233],
        [44168],
        [44507],
        [44149],
        [44327],
        [44618],
        [44185],
        [44657],
        [44563],
        [43902],
        [44548],
        [43853],
        [43890],
        [44524],
        [44474],
        [44226]], device='cuda:0')
[2024-07-24 10:19:54,157][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20767],
        [20768],
        [30688],
        [22670],
        [29696],
        [26922],
        [25003],
        [24015],
        [24358],
        [24423],
        [24353],
        [24499],
        [20064],
        [24109],
        [20383],
        [21592],
        [20213],
        [21312],
        [17339]], device='cuda:0')
[2024-07-24 10:19:54,159][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11716],
        [17969],
        [ 6691],
        [ 9383],
        [ 8831],
        [13204],
        [11825],
        [12018],
        [ 9216],
        [ 9922],
        [ 7844],
        [ 7503],
        [ 7497],
        [ 5941],
        [ 8135],
        [ 9180],
        [ 9360],
        [ 9660],
        [10686]], device='cuda:0')
[2024-07-24 10:19:54,160][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34329],
        [ 7319],
        [ 5051],
        [ 9143],
        [13394],
        [27043],
        [ 8996],
        [17267],
        [ 5838],
        [23123],
        [ 7862],
        [ 7366],
        [21587],
        [11703],
        [12214],
        [19947],
        [14730],
        [28271],
        [27395]], device='cuda:0')
[2024-07-24 10:19:54,161][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597],
        [23597]], device='cuda:0')
[2024-07-24 10:19:54,207][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:54,207][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,208][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,208][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,208][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,208][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,209][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,209][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,209][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,210][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,210][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,210][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,211][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,211][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9890, 0.0110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,211][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.9950e-01, 4.9778e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,212][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0285, 0.9715], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,212][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,212][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0444, 0.9556], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,213][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9467, 0.0533], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,215][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8331, 0.1669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,216][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7857, 0.2143], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,217][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1536, 0.8464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,217][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9756, 0.0244], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,217][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.0000e+00, 2.4905e-08], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,218][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9833, 0.0167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,218][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Kenneth] are: tensor([0.8224, 0.1282, 0.0494], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,218][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Kenneth] are: tensor([0.9820, 0.0082, 0.0098], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,219][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Kenneth] are: tensor([8.6256e-04, 9.9879e-01, 3.4724e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,219][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Kenneth] are: tensor([0.7414, 0.2509, 0.0077], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,219][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Kenneth] are: tensor([0.0010, 0.2175, 0.7815], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,219][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Kenneth] are: tensor([0.0817, 0.8932, 0.0251], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,220][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Kenneth] are: tensor([0.3880, 0.5830, 0.0289], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,222][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Kenneth] are: tensor([0.1931, 0.7281, 0.0788], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,223][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Kenneth] are: tensor([3.5837e-05, 8.1813e-01, 1.8183e-01], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,224][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Kenneth] are: tensor([0.2969, 0.6750, 0.0281], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,225][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Kenneth] are: tensor([1.0000e+00, 1.1959e-06, 5.6491e-07], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,226][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Kenneth] are: tensor([0.9296, 0.0503, 0.0201], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,227][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8176, 0.0933, 0.0110, 0.0781], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,227][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.4588e-01, 4.0482e-03, 4.9425e-02, 6.5139e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,228][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0062, 0.9433, 0.0198, 0.0308], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,228][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.8670e-01, 9.7927e-03, 9.2362e-04, 2.5869e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,228][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0009, 0.0735, 0.4555, 0.4701], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,229][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8170, 0.1459, 0.0177, 0.0194], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,229][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5468, 0.3644, 0.0789, 0.0099], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,229][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4490, 0.4648, 0.0549, 0.0314], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,229][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.4261, 0.1004, 0.4620], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,230][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9190, 0.0223, 0.0206, 0.0380], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,230][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.0000e+00, 4.3975e-08, 5.3122e-09, 3.9855e-08], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,231][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9678e-01, 2.7209e-03, 4.1368e-04, 8.7218e-05], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,233][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.4972, 0.0628, 0.0691, 0.2232, 0.1476], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,234][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.9102, 0.0228, 0.0444, 0.0033, 0.0194], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,235][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([6.5833e-04, 8.6724e-01, 4.0725e-03, 3.8707e-02, 8.9322e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,236][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.4931, 0.0618, 0.0026, 0.1438, 0.2987], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,237][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([1.8104e-04, 6.0692e-02, 4.3532e-01, 1.1199e-01, 3.9181e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,238][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1192, 0.7427, 0.0155, 0.0270, 0.0956], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,238][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0679, 0.8263, 0.0529, 0.0317, 0.0212], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,238][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.2977, 0.5119, 0.0343, 0.0560, 0.1001], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,239][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([1.4539e-04, 5.3037e-02, 6.7968e-02, 2.5363e-01, 6.2522e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,239][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.1312, 0.3163, 0.0333, 0.4761, 0.0430], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,239][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([9.9979e-01, 1.5240e-05, 4.0521e-06, 3.1248e-05, 1.6053e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,239][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.9464, 0.0261, 0.0180, 0.0068, 0.0027], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,240][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.6491, 0.1249, 0.0271, 0.0990, 0.0938, 0.0061], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,240][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.8257, 0.0213, 0.1104, 0.0061, 0.0316, 0.0049], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,241][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0068, 0.3938, 0.0186, 0.1035, 0.4658, 0.0114], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,242][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([8.9192e-01, 3.4789e-02, 6.3591e-04, 1.1121e-02, 7.8189e-03, 5.3719e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,243][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([1.0709e-04, 1.2619e-02, 3.8052e-01, 1.4572e-01, 3.5562e-01, 1.0541e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,245][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1491, 0.5430, 0.1527, 0.0961, 0.0337, 0.0254], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,246][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.5574, 0.3044, 0.0476, 0.0240, 0.0458, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,247][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.5532, 0.3417, 0.0248, 0.0300, 0.0433, 0.0070], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,248][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([3.8917e-04, 1.6368e-01, 8.2854e-03, 2.2319e-01, 1.4445e-01, 4.6001e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,248][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.8922, 0.0306, 0.0295, 0.0376, 0.0072, 0.0029], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,248][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.9999e-01, 1.7759e-06, 5.3462e-07, 3.9124e-06, 3.1688e-06, 8.9287e-07],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,249][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([9.8408e-01, 1.1911e-02, 2.0882e-03, 1.2086e-03, 6.2534e-05, 6.5138e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,249][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3458, 0.1993, 0.0229, 0.2174, 0.1542, 0.0279, 0.0325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,249][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6811, 0.0446, 0.1696, 0.0089, 0.0872, 0.0061, 0.0024],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,250][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.9553e-04, 6.4207e-01, 5.3766e-03, 1.0689e-01, 2.3008e-01, 1.1877e-02,
        3.4096e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,250][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0830, 0.0587, 0.0026, 0.0687, 0.0685, 0.7169, 0.0016],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,250][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([6.9137e-05, 5.0701e-02, 4.1717e-01, 1.8576e-01, 1.8720e-01, 1.3540e-01,
        2.3690e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,251][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0949, 0.4678, 0.1289, 0.0785, 0.1753, 0.0472, 0.0074],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,252][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0985, 0.7539, 0.0621, 0.0289, 0.0377, 0.0124, 0.0065],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,254][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3751, 0.3865, 0.0789, 0.0404, 0.0702, 0.0140, 0.0349],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,256][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0018, 0.1554, 0.0141, 0.1737, 0.0647, 0.5045, 0.0858],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,257][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.7715, 0.0650, 0.0382, 0.0908, 0.0220, 0.0100, 0.0025],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,258][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9987e-01, 3.3435e-05, 3.4968e-06, 6.1933e-05, 2.4194e-05, 6.2438e-06,
        1.9981e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,258][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.8837e-01, 1.2476e-01, 2.1783e-02, 3.7020e-02, 3.3206e-03, 2.4609e-02,
        1.3870e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,258][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.6766, 0.1071, 0.0328, 0.0982, 0.0580, 0.0100, 0.0066, 0.0107],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,259][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.4492, 0.1031, 0.2260, 0.0215, 0.1296, 0.0390, 0.0264, 0.0053],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,259][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([4.8369e-04, 7.3208e-01, 2.4028e-03, 1.0569e-01, 1.3169e-01, 1.2189e-02,
        1.4580e-02, 8.7322e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,259][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([9.2582e-02, 1.7419e-01, 8.0330e-04, 6.0986e-02, 5.4330e-02, 6.1466e-01,
        1.8417e-03, 6.0321e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,260][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([6.4705e-05, 3.2492e-02, 3.5469e-01, 7.2965e-02, 4.3681e-01, 8.2177e-02,
        1.6910e-02, 3.8948e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,260][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0120, 0.5224, 0.0463, 0.0260, 0.3654, 0.0144, 0.0103, 0.0032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,260][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0280, 0.5536, 0.1029, 0.0417, 0.1951, 0.0425, 0.0355, 0.0008],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,261][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1799, 0.4282, 0.0991, 0.0420, 0.1755, 0.0166, 0.0522, 0.0064],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,261][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([6.7429e-05, 2.6576e-01, 3.4125e-03, 1.5378e-01, 1.2170e-01, 2.2852e-01,
        1.2134e-01, 1.0542e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,263][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1121, 0.1374, 0.0775, 0.2808, 0.2463, 0.0937, 0.0459, 0.0063],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,264][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([9.9881e-01, 2.4821e-04, 6.7660e-05, 4.9338e-04, 3.3152e-04, 2.2923e-05,
        6.0882e-06, 1.8243e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,265][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([7.6376e-01, 1.5149e-01, 2.8405e-02, 2.4991e-02, 5.5373e-03, 2.5482e-02,
        1.8313e-04, 1.5632e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,266][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.7389, 0.0655, 0.0122, 0.0630, 0.0699, 0.0134, 0.0084, 0.0206, 0.0080],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,268][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.8130, 0.0174, 0.1254, 0.0064, 0.0261, 0.0064, 0.0022, 0.0011, 0.0021],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,268][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0032, 0.8089, 0.0064, 0.0470, 0.0771, 0.0133, 0.0162, 0.0009, 0.0271],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,269][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([7.6547e-01, 2.1936e-02, 1.0840e-03, 6.0602e-03, 8.7848e-03, 1.5740e-01,
        4.1778e-04, 1.2275e-03, 3.7612e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,269][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([2.8798e-04, 2.1967e-02, 1.9656e-01, 1.7962e-01, 2.9736e-01, 1.4189e-01,
        2.7835e-02, 4.7569e-03, 1.2973e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,269][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.3368, 0.3180, 0.0381, 0.0848, 0.1334, 0.0522, 0.0186, 0.0044, 0.0137],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,269][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([4.7361e-01, 3.5214e-01, 9.9571e-02, 1.4500e-02, 3.6064e-02, 7.8530e-03,
        9.3684e-03, 3.0897e-04, 6.5863e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,270][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.6828, 0.2067, 0.0162, 0.0181, 0.0157, 0.0088, 0.0358, 0.0039, 0.0120],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,270][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0006, 0.1914, 0.0071, 0.0896, 0.0524, 0.5228, 0.0748, 0.0326, 0.0286],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,270][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([8.2521e-01, 2.8953e-02, 3.2851e-02, 8.0763e-02, 1.1827e-02, 1.0754e-02,
        5.8302e-03, 3.9173e-04, 3.4193e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,271][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.9996e-01, 8.9007e-06, 4.5418e-06, 1.3228e-05, 7.3435e-06, 1.0317e-06,
        4.0968e-07, 6.6562e-07, 4.2704e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,271][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([9.9459e-01, 3.7816e-03, 6.8538e-04, 2.7236e-04, 6.6617e-05, 5.8022e-04,
        3.2348e-06, 7.0794e-06, 1.4391e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,273][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.8078, 0.0898, 0.0138, 0.0212, 0.0457, 0.0087, 0.0032, 0.0049, 0.0031,
        0.0018], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,275][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.4174, 0.2830, 0.1956, 0.0194, 0.0636, 0.0131, 0.0041, 0.0010, 0.0024,
        0.0006], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,276][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([2.1985e-04, 8.0305e-01, 4.9713e-03, 7.6609e-02, 6.3209e-02, 1.9724e-02,
        6.8843e-03, 5.3124e-04, 2.4320e-02, 4.7806e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,277][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1759, 0.2132, 0.0008, 0.0500, 0.0446, 0.4366, 0.0008, 0.0008, 0.0732,
        0.0040], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,278][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([1.2489e-04, 8.4236e-02, 2.7395e-01, 1.7334e-01, 2.5082e-01, 1.0112e-01,
        1.9178e-02, 2.3827e-03, 7.1251e-02, 2.3595e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,279][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0043, 0.6950, 0.0758, 0.0523, 0.1191, 0.0306, 0.0079, 0.0016, 0.0095,
        0.0040], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,279][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([3.0979e-02, 7.7112e-01, 4.8106e-02, 4.1606e-02, 6.1549e-02, 3.0207e-02,
        1.1083e-02, 1.2677e-04, 4.5292e-03, 6.9414e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,279][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0610, 0.7559, 0.0225, 0.0535, 0.0384, 0.0153, 0.0342, 0.0019, 0.0121,
        0.0053], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,279][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([3.7438e-05, 1.6113e-01, 8.5396e-03, 8.1249e-02, 9.7722e-02, 2.5484e-01,
        4.8894e-02, 8.0817e-02, 5.0897e-02, 2.1587e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,280][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1327, 0.4025, 0.0503, 0.2429, 0.0941, 0.0527, 0.0100, 0.0019, 0.0124,
        0.0005], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,280][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([9.9938e-01, 2.0093e-04, 3.5417e-05, 1.4053e-04, 2.0835e-04, 1.6069e-05,
        2.5305e-06, 1.9135e-06, 1.3439e-05, 2.3550e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,280][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([8.9158e-01, 9.0612e-02, 6.5352e-03, 3.9350e-03, 1.8252e-03, 5.3102e-03,
        2.9414e-05, 6.6773e-05, 8.7869e-05, 1.7919e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,281][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.8153, 0.0386, 0.0176, 0.0306, 0.0688, 0.0068, 0.0063, 0.0088, 0.0034,
        0.0014, 0.0024], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,281][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([8.8702e-01, 1.4045e-02, 6.7320e-02, 4.0202e-03, 1.2094e-02, 5.6761e-03,
        1.3619e-03, 7.3484e-04, 2.0760e-03, 4.0724e-04, 5.2428e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,282][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([2.9998e-03, 7.3190e-01, 8.6915e-03, 5.4852e-02, 1.3418e-01, 1.2475e-02,
        4.2526e-03, 8.8212e-04, 2.7233e-02, 6.2874e-04, 2.1907e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,283][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([5.7729e-01, 5.4996e-02, 6.8715e-04, 2.4729e-02, 1.4245e-02, 1.6558e-01,
        3.9877e-04, 1.5268e-03, 5.4932e-02, 1.1808e-03, 1.0444e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,284][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([1.9621e-04, 1.6985e-02, 2.0785e-01, 1.3610e-01, 1.9547e-01, 1.3949e-01,
        2.0093e-02, 2.0320e-03, 5.8797e-02, 1.7399e-02, 2.0558e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,285][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0128, 0.5122, 0.0538, 0.1017, 0.1688, 0.0753, 0.0162, 0.0044, 0.0433,
        0.0043, 0.0074], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,286][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([4.3026e-01, 4.3523e-01, 4.9529e-02, 1.7158e-02, 3.0342e-02, 1.8361e-02,
        6.3487e-03, 1.5619e-04, 6.9134e-03, 4.3925e-04, 5.2599e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,288][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.4381, 0.2519, 0.0147, 0.0896, 0.1020, 0.0170, 0.0235, 0.0024, 0.0145,
        0.0109, 0.0354], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,289][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0074, 0.2304, 0.0097, 0.0869, 0.0529, 0.2604, 0.0535, 0.0626, 0.0347,
        0.0634, 0.1379], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,289][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([7.0916e-01, 1.2731e-01, 6.0081e-02, 5.2727e-02, 2.3075e-02, 1.3818e-02,
        6.6124e-03, 7.5311e-04, 4.6509e-03, 3.2609e-04, 1.4928e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,289][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([9.9985e-01, 7.3566e-06, 6.8663e-06, 2.0231e-05, 1.6962e-05, 5.1862e-06,
        6.8289e-07, 1.1998e-06, 5.5676e-06, 6.6002e-07, 8.1463e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,290][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([9.7758e-01, 1.3021e-02, 4.1978e-03, 3.2161e-03, 5.2544e-04, 1.2365e-03,
        6.8999e-06, 4.7557e-06, 3.1006e-05, 4.3027e-06, 1.7316e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,290][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.7481, 0.0552, 0.0151, 0.0553, 0.0376, 0.0144, 0.0080, 0.0081, 0.0067,
        0.0016, 0.0038, 0.0462], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,290][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([8.5483e-01, 2.0474e-02, 8.2023e-02, 4.2136e-03, 1.7435e-02, 2.0945e-03,
        1.7614e-03, 3.6958e-04, 1.3730e-03, 1.2632e-04, 6.1081e-03, 9.1877e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,291][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([5.4862e-03, 6.8220e-01, 8.6209e-03, 4.8582e-02, 1.3769e-01, 8.3709e-03,
        5.7518e-03, 3.3798e-04, 2.0781e-02, 2.8856e-04, 3.4477e-02, 4.7413e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,291][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([3.0104e-01, 2.0304e-02, 1.5561e-04, 5.3001e-03, 3.6326e-03, 3.5977e-02,
        5.9558e-05, 1.2586e-04, 1.5153e-02, 2.9583e-04, 2.7474e-02, 5.9048e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,291][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0004, 0.0263, 0.2775, 0.1245, 0.1437, 0.1277, 0.0222, 0.0023, 0.0484,
        0.0067, 0.1953, 0.0250], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,292][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1331, 0.5884, 0.0624, 0.0366, 0.1265, 0.0160, 0.0099, 0.0016, 0.0069,
        0.0014, 0.0040, 0.0133], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,293][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([6.5774e-01, 2.4652e-01, 4.4569e-02, 5.0249e-03, 2.5872e-02, 3.5190e-03,
        3.2179e-03, 7.2966e-05, 2.0794e-03, 2.2658e-04, 4.2068e-03, 6.9518e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,295][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.5200, 0.2081, 0.0369, 0.0277, 0.0388, 0.0062, 0.0377, 0.0022, 0.0084,
        0.0030, 0.0175, 0.0936], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,296][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0448, 0.1182, 0.0117, 0.0660, 0.0352, 0.1779, 0.0295, 0.0368, 0.0180,
        0.0331, 0.0726, 0.3563], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,297][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.0697e-01, 4.4255e-02, 2.4132e-02, 7.6825e-03, 1.0940e-02, 1.3737e-03,
        1.3493e-03, 1.0032e-04, 7.4618e-04, 1.0855e-04, 5.9905e-04, 1.7419e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,298][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9993e-01, 1.2234e-05, 4.4313e-06, 1.2498e-05, 1.2500e-05, 1.1747e-06,
        2.7027e-07, 2.4899e-07, 2.5367e-06, 1.0617e-07, 2.4566e-05, 3.0843e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,299][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.9216e-01, 4.9698e-03, 9.1332e-04, 6.8618e-04, 7.0154e-05, 5.0348e-04,
        2.9705e-06, 2.9951e-06, 1.0010e-05, 1.1429e-06, 6.6469e-05, 6.1128e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,299][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ office] are: tensor([0.8297, 0.0819, 0.0142, 0.0154, 0.0256, 0.0033, 0.0028, 0.0043, 0.0026,
        0.0011, 0.0017, 0.0150, 0.0025], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,300][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ office] are: tensor([7.7270e-01, 1.3729e-02, 3.2249e-02, 1.1692e-03, 1.4906e-02, 6.1360e-03,
        1.1984e-03, 1.9208e-03, 3.4271e-03, 5.6741e-04, 9.5177e-03, 1.2734e-02,
        1.2975e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,300][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ office] are: tensor([0.0126, 0.4008, 0.0100, 0.1163, 0.1448, 0.0313, 0.0110, 0.0016, 0.1004,
        0.0018, 0.0538, 0.1101, 0.0056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,300][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ office] are: tensor([6.0527e-01, 6.3277e-03, 1.8871e-05, 2.0776e-03, 1.5307e-03, 4.1278e-02,
        6.4773e-05, 7.6408e-05, 8.1186e-03, 3.5829e-04, 1.0758e-02, 3.0986e-01,
        1.4262e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,301][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ office] are: tensor([0.0005, 0.0181, 0.1846, 0.0531, 0.1074, 0.0934, 0.0195, 0.0025, 0.0484,
        0.0135, 0.2511, 0.0169, 0.1910], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,301][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ office] are: tensor([0.0744, 0.4672, 0.0656, 0.0298, 0.2774, 0.0322, 0.0076, 0.0032, 0.0076,
        0.0050, 0.0091, 0.0104, 0.0105], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,301][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ office] are: tensor([2.5299e-01, 4.0773e-01, 8.4209e-02, 3.3847e-02, 9.2258e-02, 2.5418e-02,
        1.1682e-02, 3.3853e-04, 2.8020e-02, 1.1051e-03, 2.5980e-02, 3.3419e-02,
        3.0067e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,302][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ office] are: tensor([0.3921, 0.3362, 0.0218, 0.0130, 0.0557, 0.0074, 0.0170, 0.0047, 0.0110,
        0.0122, 0.0323, 0.0858, 0.0109], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,303][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ office] are: tensor([2.6847e-04, 3.1328e-02, 2.6522e-03, 1.3836e-02, 2.7599e-02, 3.8473e-02,
        2.9875e-02, 8.0084e-02, 1.8262e-02, 1.4655e-01, 5.3199e-02, 3.5062e-01,
        2.0725e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,304][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ office] are: tensor([5.4191e-01, 1.2042e-01, 2.6838e-02, 1.4531e-01, 5.9634e-02, 4.5801e-02,
        9.0240e-03, 1.5972e-03, 1.4726e-02, 4.3295e-04, 6.3864e-03, 2.4564e-02,
        3.3613e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,305][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ office] are: tensor([9.9983e-01, 1.6292e-05, 4.9676e-06, 4.5635e-05, 2.5771e-05, 3.9677e-06,
        6.2813e-07, 1.5717e-06, 6.8313e-06, 8.3082e-07, 5.4418e-05, 4.3531e-06,
        4.5137e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,306][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ office] are: tensor([9.9561e-01, 3.0601e-03, 5.2594e-04, 1.9930e-04, 3.4132e-05, 1.6940e-04,
        2.3139e-06, 1.2426e-06, 7.1826e-06, 1.5168e-06, 5.4793e-05, 2.4970e-04,
        8.4880e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,307][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.1411e-01, 9.6820e-03, 1.6032e-03, 5.6064e-03, 5.1407e-03, 1.0940e-03,
        7.2075e-04, 9.2778e-04, 4.9601e-04, 9.9596e-05, 3.4193e-04, 6.1389e-03,
        1.3004e-04, 5.3904e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,308][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([9.2693e-01, 1.6828e-03, 3.4343e-02, 5.8598e-04, 5.9867e-03, 6.6940e-04,
        1.5396e-04, 2.0787e-04, 2.6454e-04, 4.1718e-05, 2.9956e-03, 2.3192e-03,
        1.5187e-02, 8.6323e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,309][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([2.3328e-02, 3.4787e-01, 6.2209e-03, 4.4441e-02, 1.2642e-01, 2.6777e-02,
        5.0666e-03, 4.2811e-04, 1.7183e-02, 3.1245e-04, 3.7991e-02, 3.1329e-02,
        4.5707e-03, 3.2806e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,310][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([4.0285e-01, 2.0256e-03, 4.2140e-06, 1.0878e-04, 2.6755e-05, 6.4593e-04,
        4.8708e-07, 3.8256e-07, 9.3235e-05, 8.1754e-07, 1.5618e-04, 3.5750e-03,
        1.7347e-04, 5.9034e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,312][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0011, 0.0171, 0.2726, 0.0883, 0.1526, 0.0819, 0.0115, 0.0026, 0.0334,
        0.0051, 0.1338, 0.0155, 0.0639, 0.1206], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,314][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.4394, 0.2006, 0.0372, 0.0466, 0.1061, 0.0287, 0.0064, 0.0023, 0.0078,
        0.0017, 0.0046, 0.0128, 0.0054, 0.1002], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,315][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([8.4179e-01, 9.9281e-02, 1.0460e-02, 2.4055e-03, 1.1846e-02, 2.9935e-03,
        1.1084e-03, 3.3916e-05, 1.2412e-03, 7.5882e-05, 3.1910e-03, 5.0221e-03,
        4.7041e-04, 2.0078e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,315][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.5848, 0.1381, 0.0121, 0.0148, 0.0325, 0.0036, 0.0095, 0.0015, 0.0046,
        0.0032, 0.0082, 0.0308, 0.0040, 0.1522], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,315][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0060, 0.0399, 0.0054, 0.0154, 0.0109, 0.0566, 0.0164, 0.0501, 0.0049,
        0.0111, 0.0294, 0.1152, 0.0511, 0.5877], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,316][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([9.3399e-01, 7.2705e-03, 7.7790e-03, 4.2293e-03, 4.1639e-03, 1.1835e-03,
        5.2126e-04, 4.1781e-05, 4.7339e-04, 3.9722e-05, 4.5170e-04, 1.2544e-03,
        6.5766e-04, 3.7942e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,316][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.9995e-01, 5.0668e-07, 1.1698e-07, 4.6775e-07, 3.0345e-07, 4.0801e-08,
        6.2778e-09, 1.1837e-08, 5.9439e-08, 5.2571e-09, 6.3201e-07, 8.1209e-08,
        4.7788e-08, 4.4504e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,316][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([9.9309e-01, 2.4028e-03, 1.9701e-04, 1.5339e-04, 1.3729e-05, 1.3165e-04,
        3.1662e-07, 6.2092e-07, 3.2875e-06, 1.6953e-07, 1.0673e-05, 4.2541e-05,
        2.3089e-05, 3.9329e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,317][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1925, 0.0055, 0.0146, 0.0651, 0.0841, 0.0149, 0.0224, 0.0089, 0.0158,
        0.0011, 0.0051, 0.1433, 0.0013, 0.3695, 0.0558], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,317][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([4.6448e-01, 7.0748e-02, 7.4883e-02, 1.5316e-02, 6.1627e-02, 1.5577e-02,
        1.8661e-03, 6.3515e-04, 2.9731e-03, 3.8371e-04, 1.9012e-02, 2.4791e-02,
        1.1231e-01, 1.2815e-01, 7.2509e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,318][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([5.0561e-04, 3.2118e-01, 2.8416e-03, 8.1712e-02, 4.0882e-02, 1.0618e-02,
        1.7611e-03, 1.0500e-04, 1.2795e-02, 8.6535e-05, 2.0582e-02, 2.1096e-02,
        6.0589e-03, 4.6803e-01, 1.1743e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,318][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([1.1301e-04, 1.1271e-04, 6.9914e-07, 1.2965e-04, 5.9288e-05, 9.6719e-04,
        2.2066e-06, 6.8070e-06, 3.5801e-04, 3.2502e-06, 2.0791e-04, 1.4628e-02,
        4.8514e-04, 9.8115e-01, 1.7716e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,318][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0007, 0.0531, 0.2511, 0.0853, 0.1291, 0.1253, 0.0093, 0.0024, 0.0272,
        0.0100, 0.0596, 0.0168, 0.1107, 0.1065, 0.0130], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,320][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0153, 0.3894, 0.0109, 0.0765, 0.2410, 0.0361, 0.0067, 0.0051, 0.0220,
        0.0026, 0.0075, 0.0174, 0.0090, 0.1468, 0.0137], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,321][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([4.7095e-02, 6.7084e-01, 4.0792e-02, 3.7928e-02, 2.9175e-02, 4.1205e-02,
        4.2179e-03, 5.1231e-05, 2.9307e-03, 1.4575e-04, 6.8685e-03, 2.2265e-02,
        3.8489e-04, 9.4625e-02, 1.4730e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,323][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1562, 0.2526, 0.0158, 0.0593, 0.0531, 0.0216, 0.0259, 0.0027, 0.0132,
        0.0045, 0.0175, 0.1202, 0.0097, 0.2385, 0.0091], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,323][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([1.9970e-04, 1.1343e-02, 1.9425e-03, 8.0251e-03, 7.6822e-03, 2.6603e-02,
        5.0040e-03, 4.5652e-03, 4.8143e-03, 8.9874e-03, 2.6740e-02, 9.6992e-02,
        7.3254e-02, 6.9142e-01, 3.2425e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,324][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([6.8087e-03, 1.4528e-01, 1.5934e-02, 4.3909e-01, 3.4412e-02, 3.9610e-02,
        1.0813e-02, 1.9431e-04, 3.3295e-03, 6.5655e-05, 3.1183e-03, 1.5156e-02,
        1.2663e-03, 2.8444e-01, 4.7429e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,325][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([8.8767e-01, 5.3487e-04, 2.4770e-04, 9.7014e-04, 3.1633e-03, 3.4387e-04,
        1.1718e-04, 1.8882e-05, 1.2463e-04, 1.7178e-05, 2.4834e-03, 3.3020e-04,
        1.6774e-04, 9.2748e-02, 1.1066e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,326][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([5.8488e-01, 8.5733e-02, 3.1841e-02, 1.7090e-02, 3.4066e-03, 7.9897e-03,
        1.3979e-04, 2.3690e-04, 5.4124e-04, 9.8005e-05, 1.3720e-03, 1.3125e-02,
        5.5465e-03, 2.4782e-01, 1.7862e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,326][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([7.9457e-01, 5.3416e-02, 2.5503e-03, 6.8857e-03, 1.1793e-02, 9.7197e-04,
        2.6133e-04, 5.8917e-04, 5.8393e-04, 1.4692e-04, 4.1104e-04, 5.8681e-03,
        1.2763e-04, 4.8412e-02, 4.4724e-03, 6.8944e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,326][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([8.7470e-01, 1.3828e-02, 2.4548e-02, 2.0380e-03, 8.8437e-03, 1.4682e-03,
        1.0951e-03, 1.1984e-04, 7.9502e-04, 5.8588e-05, 2.9908e-03, 5.5671e-03,
        1.8690e-02, 3.4989e-02, 1.9403e-03, 8.3284e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,327][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([1.4440e-02, 1.7020e-01, 6.9577e-03, 5.0711e-02, 1.0058e-01, 7.4879e-03,
        3.8035e-03, 4.0738e-04, 2.4210e-02, 3.6306e-04, 1.9107e-02, 4.2641e-02,
        7.6450e-03, 4.8567e-01, 4.6562e-02, 1.9212e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,327][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.6958e-01, 5.9849e-04, 3.5897e-07, 4.9934e-05, 6.9092e-06, 3.1639e-04,
        1.6743e-07, 1.0614e-07, 2.5542e-05, 3.7579e-07, 3.2283e-05, 1.0230e-03,
        8.2275e-05, 5.8780e-01, 1.1524e-04, 2.4036e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,327][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.8786e-04, 7.3148e-03, 3.4538e-01, 3.4760e-02, 1.3426e-01, 4.5875e-02,
        1.1463e-02, 6.9273e-04, 1.8458e-02, 5.0408e-03, 7.9023e-02, 1.4427e-02,
        9.4097e-02, 4.4017e-02, 2.3034e-02, 1.4197e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,328][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0440, 0.1719, 0.0718, 0.0758, 0.2268, 0.0455, 0.0207, 0.0039, 0.0275,
        0.0030, 0.0120, 0.0357, 0.0098, 0.1599, 0.0258, 0.0660],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,328][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([6.3670e-01, 1.5792e-01, 1.7399e-02, 1.0684e-02, 4.0974e-02, 9.0957e-03,
        4.2892e-03, 5.4276e-05, 3.6267e-03, 2.0760e-04, 5.9368e-03, 1.2061e-02,
        9.4841e-04, 6.8255e-02, 4.6823e-03, 2.7169e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,329][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1045, 0.0243, 0.0109, 0.0220, 0.0614, 0.0058, 0.0136, 0.0007, 0.0110,
        0.0018, 0.0181, 0.0681, 0.0093, 0.4090, 0.0460, 0.1933],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,330][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.9746e-03, 1.2370e-02, 3.1861e-04, 6.2621e-03, 1.6910e-03, 3.1165e-02,
        3.8827e-03, 7.1767e-03, 1.7907e-03, 3.8272e-03, 1.1924e-02, 4.6727e-02,
        1.8388e-02, 2.1360e-01, 4.1684e-03, 6.3473e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,331][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([4.4395e-01, 2.4850e-02, 1.0253e-02, 6.0498e-02, 3.2297e-02, 7.0155e-03,
        2.8716e-03, 2.7307e-04, 3.8770e-03, 2.3694e-04, 3.4100e-03, 9.2909e-03,
        3.8851e-03, 3.8206e-01, 2.7808e-03, 1.2456e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,332][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([9.9986e-01, 1.5573e-06, 2.3541e-07, 1.4050e-06, 6.5982e-07, 8.2905e-08,
        9.4057e-09, 1.3001e-08, 6.8704e-08, 8.7988e-09, 8.8250e-07, 2.3875e-07,
        9.7710e-08, 1.0883e-04, 4.3909e-06, 2.3541e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,333][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.9858e-01, 5.1385e-04, 3.1632e-05, 3.3775e-05, 1.3650e-06, 2.1017e-05,
        6.9690e-08, 8.1098e-08, 4.6808e-07, 2.7079e-08, 1.4907e-06, 1.3429e-05,
        5.3065e-06, 6.0706e-04, 9.1936e-08, 1.9037e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,334][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([7.0963e-01, 2.3688e-02, 3.4932e-03, 1.3643e-02, 7.8161e-03, 2.2017e-03,
        1.3077e-03, 1.3017e-03, 1.1794e-03, 4.1098e-04, 8.9029e-04, 7.8336e-03,
        2.9514e-04, 5.2809e-02, 3.3176e-03, 7.7284e-02, 9.2903e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,335][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.5578e-01, 1.9186e-03, 1.5165e-02, 5.9027e-04, 6.4998e-03, 4.2420e-04,
        2.4725e-04, 8.9375e-05, 1.7104e-04, 1.5654e-05, 1.2243e-03, 8.7185e-04,
        7.8615e-03, 3.8470e-03, 7.5754e-04, 2.2086e-03, 2.3262e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,336][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.3028e-02, 3.3021e-01, 5.1565e-03, 7.9048e-02, 1.1931e-01, 1.3959e-02,
        3.4629e-03, 4.2571e-04, 1.5922e-02, 1.8621e-04, 1.9982e-02, 3.0375e-02,
        1.8218e-03, 1.8217e-01, 3.0606e-02, 2.7533e-02, 1.1680e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,336][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.6670e-02, 3.1701e-04, 9.9391e-07, 2.9458e-05, 1.1257e-05, 2.1867e-04,
        1.6243e-07, 5.2939e-07, 5.1031e-05, 8.0342e-07, 9.2706e-05, 1.6002e-03,
        9.9316e-05, 2.4302e-01, 2.0445e-04, 6.5424e-01, 2.3439e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,337][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0008, 0.0297, 0.2618, 0.1165, 0.1070, 0.0853, 0.0147, 0.0015, 0.0280,
        0.0040, 0.0952, 0.0137, 0.0479, 0.0647, 0.0118, 0.0558, 0.0617],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,337][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3082, 0.2939, 0.0711, 0.0631, 0.1062, 0.0366, 0.0070, 0.0017, 0.0056,
        0.0008, 0.0036, 0.0099, 0.0026, 0.0438, 0.0041, 0.0115, 0.0304],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,337][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([8.0738e-01, 1.1068e-01, 1.7532e-02, 4.7107e-03, 1.7526e-02, 2.7979e-03,
        1.6652e-03, 2.2884e-05, 7.1822e-04, 5.0312e-05, 1.7028e-03, 3.1753e-03,
        3.2010e-04, 7.7581e-03, 9.2120e-04, 5.9290e-03, 1.7114e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,338][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.6781, 0.0829, 0.0104, 0.0070, 0.0092, 0.0027, 0.0093, 0.0007, 0.0027,
        0.0012, 0.0086, 0.0234, 0.0022, 0.0470, 0.0027, 0.0400, 0.0719],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,338][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0068, 0.0137, 0.0013, 0.0071, 0.0035, 0.0237, 0.0061, 0.0107, 0.0024,
        0.0048, 0.0108, 0.0848, 0.0132, 0.2044, 0.0076, 0.4331, 0.1660],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,338][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.6936e-01, 6.9687e-03, 3.8670e-03, 3.7195e-03, 2.2043e-03, 5.1684e-04,
        2.6483e-04, 1.6625e-05, 1.9018e-04, 1.0407e-05, 1.5771e-04, 5.0772e-04,
        1.3630e-04, 8.1518e-03, 1.0054e-04, 1.5158e-03, 2.3120e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,339][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9991e-01, 2.9798e-06, 3.5190e-07, 1.3739e-06, 6.5706e-07, 1.6238e-07,
        3.0246e-08, 2.3570e-08, 1.1172e-07, 6.2938e-09, 1.2821e-06, 2.4800e-07,
        8.7069e-08, 7.3362e-05, 2.1180e-06, 8.2175e-06, 3.3928e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,340][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9016e-01, 2.8875e-03, 1.8888e-04, 2.4131e-04, 1.8175e-05, 8.0513e-05,
        6.4700e-07, 1.0637e-06, 2.7927e-06, 3.1719e-07, 1.6355e-05, 1.0256e-04,
        4.7221e-05, 3.4232e-03, 8.7083e-07, 2.0173e-03, 8.1342e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,341][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([7.4845e-01, 2.9611e-02, 5.8602e-03, 1.4645e-02, 9.9617e-03, 2.5118e-03,
        9.9752e-04, 4.5896e-04, 1.0790e-03, 4.8516e-04, 9.5874e-04, 5.4478e-03,
        6.2334e-04, 5.2245e-02, 3.0067e-03, 5.1153e-02, 5.9290e-02, 1.3221e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,342][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([9.3288e-01, 5.0274e-03, 3.1059e-02, 8.0404e-04, 5.6938e-03, 9.6182e-04,
        1.3973e-04, 3.6249e-04, 2.2555e-04, 4.4392e-05, 6.0727e-04, 9.6712e-04,
        7.7307e-03, 6.8214e-03, 3.7684e-04, 3.6414e-03, 1.6387e-03, 1.0225e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,344][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0548, 0.1798, 0.0105, 0.0623, 0.1525, 0.0215, 0.0027, 0.0005, 0.0126,
        0.0005, 0.0240, 0.0134, 0.0041, 0.1540, 0.0360, 0.1363, 0.1218, 0.0128],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,345][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([1.3076e-01, 1.5155e-03, 1.0120e-06, 6.1701e-05, 9.5551e-05, 3.8172e-04,
        5.2424e-07, 4.3626e-07, 6.0177e-05, 5.2411e-06, 6.5552e-05, 6.6360e-04,
        5.2461e-04, 2.9263e-01, 2.2728e-04, 4.4399e-01, 5.6712e-02, 7.2300e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,346][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0014, 0.0160, 0.2831, 0.0465, 0.1096, 0.0319, 0.0080, 0.0014, 0.0226,
        0.0057, 0.0640, 0.0071, 0.0613, 0.0326, 0.0109, 0.1043, 0.0361, 0.1573],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,346][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.5017, 0.1765, 0.0228, 0.0167, 0.1949, 0.0085, 0.0029, 0.0012, 0.0024,
        0.0016, 0.0025, 0.0031, 0.0040, 0.0161, 0.0103, 0.0109, 0.0108, 0.0130],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,347][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([7.7396e-01, 1.1224e-01, 1.3637e-02, 6.3772e-03, 3.5946e-02, 2.0524e-03,
        1.0306e-03, 3.1027e-05, 1.0310e-03, 1.3332e-04, 1.8556e-03, 2.4483e-03,
        3.3841e-04, 1.5032e-02, 1.2009e-03, 1.3310e-02, 1.7660e-02, 1.7200e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,347][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.7273, 0.0998, 0.0038, 0.0064, 0.0120, 0.0009, 0.0013, 0.0008, 0.0010,
        0.0016, 0.0029, 0.0063, 0.0015, 0.0289, 0.0025, 0.0661, 0.0250, 0.0122],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,347][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([1.1996e-04, 1.8123e-02, 1.6788e-03, 3.3434e-03, 3.0721e-03, 6.5932e-03,
        3.0205e-03, 6.6057e-03, 1.8677e-03, 8.0140e-03, 9.8448e-03, 2.9978e-02,
        1.4213e-02, 1.6591e-01, 8.8714e-03, 4.8387e-01, 1.2459e-01, 1.1029e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,348][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([9.4227e-01, 1.4102e-02, 5.2747e-03, 8.7627e-03, 1.6661e-02, 7.2083e-04,
        1.2693e-04, 6.7201e-05, 2.2836e-04, 4.0615e-05, 3.3294e-04, 2.4674e-04,
        1.6167e-04, 6.9814e-03, 2.1984e-04, 1.2003e-03, 8.3913e-04, 1.7679e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,348][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([9.9951e-01, 2.2672e-05, 3.2961e-06, 2.3147e-05, 2.4095e-05, 9.8650e-07,
        1.9105e-07, 6.3521e-08, 1.1991e-06, 4.8261e-07, 5.3018e-06, 8.2924e-07,
        9.7218e-07, 2.4716e-04, 1.7629e-05, 8.5143e-05, 1.1933e-05, 4.2058e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,349][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([9.7858e-01, 8.0722e-03, 9.2819e-04, 7.1010e-04, 8.4767e-05, 2.8731e-04,
        1.5811e-06, 1.6615e-06, 4.7792e-06, 1.5127e-06, 1.7225e-05, 1.0031e-04,
        1.0516e-04, 5.8146e-03, 1.9218e-06, 3.1839e-03, 1.9675e-03, 1.3761e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,349][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.4548e-01, 1.1687e-02, 3.5143e-03, 6.2486e-03, 6.9080e-03, 1.3962e-03,
        8.7756e-04, 1.2471e-03, 7.8595e-04, 1.7993e-04, 4.5240e-04, 7.4028e-03,
        1.2641e-04, 3.6195e-02, 1.8191e-03, 3.6130e-02, 7.5169e-02, 2.3752e-03,
        6.2004e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,350][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.7441e-01, 1.4791e-03, 1.1932e-02, 2.6112e-04, 2.2463e-03, 1.5759e-04,
        1.0764e-04, 6.1800e-05, 1.1365e-04, 9.3903e-06, 5.2421e-04, 5.3469e-04,
        3.6348e-03, 2.1006e-03, 1.6676e-04, 7.8841e-04, 7.8538e-04, 2.7381e-04,
        4.0834e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,351][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.7746e-02, 3.0533e-01, 4.7945e-03, 2.7142e-02, 7.0681e-02, 5.9473e-03,
        3.9687e-03, 4.1407e-04, 1.5907e-02, 2.3643e-04, 2.2998e-02, 2.6393e-02,
        3.2264e-03, 1.5904e-01, 1.9758e-02, 2.4767e-02, 1.4566e-01, 1.6361e-02,
        9.9632e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,352][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.2519e-01, 5.0618e-04, 7.9403e-07, 1.4280e-05, 1.3875e-05, 1.9083e-04,
        1.9232e-07, 4.7821e-07, 3.2333e-05, 6.8039e-07, 5.9788e-05, 1.0892e-03,
        7.9231e-05, 1.5078e-01, 1.4837e-04, 2.6403e-01, 2.2118e-02, 1.1128e-02,
        3.2461e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,354][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0009, 0.0100, 0.1802, 0.0554, 0.1003, 0.0650, 0.0104, 0.0014, 0.0289,
        0.0035, 0.0901, 0.0117, 0.0422, 0.0538, 0.0090, 0.0946, 0.0557, 0.1580,
        0.0288], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,355][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2967, 0.2462, 0.0297, 0.0399, 0.1296, 0.0219, 0.0103, 0.0030, 0.0144,
        0.0010, 0.0061, 0.0161, 0.0049, 0.0706, 0.0108, 0.0184, 0.0364, 0.0103,
        0.0338], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,356][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([8.5536e-01, 6.9211e-02, 1.6439e-02, 2.0563e-03, 1.4298e-02, 2.7056e-03,
        1.4129e-03, 2.4564e-05, 1.5650e-03, 7.0438e-05, 2.3384e-03, 2.3029e-03,
        4.5032e-04, 6.2622e-03, 8.2407e-04, 5.9190e-03, 1.3732e-02, 8.7403e-04,
        4.1583e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,356][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.2870e-01, 6.6219e-02, 1.1320e-02, 5.0322e-03, 1.2567e-02, 1.7095e-03,
        6.0598e-03, 7.0296e-04, 2.3519e-03, 8.6216e-04, 5.6651e-03, 1.4830e-02,
        2.6998e-03, 3.8793e-02, 2.9644e-03, 3.6387e-02, 3.7892e-02, 1.4767e-02,
        1.0482e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,357][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0061, 0.0159, 0.0013, 0.0044, 0.0036, 0.0124, 0.0050, 0.0088, 0.0020,
        0.0032, 0.0083, 0.0738, 0.0152, 0.1684, 0.0096, 0.3261, 0.1374, 0.0728,
        0.1257], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,357][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.5005e-01, 7.9913e-03, 4.8670e-03, 2.3471e-03, 5.0551e-03, 4.1293e-04,
        4.3193e-04, 4.4237e-05, 4.9395e-04, 1.8330e-05, 2.6426e-04, 7.3861e-04,
        2.5692e-04, 1.4303e-02, 2.7873e-04, 2.6134e-03, 3.1126e-03, 2.0255e-03,
        4.6949e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,357][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9998e-01, 4.7200e-07, 7.7850e-08, 9.0334e-08, 1.7777e-07, 8.7472e-09,
        3.6602e-09, 3.3656e-09, 2.5837e-08, 2.8957e-09, 4.6572e-07, 3.8961e-08,
        1.7879e-08, 1.5004e-05, 1.3373e-06, 1.4453e-06, 4.7533e-07, 3.7319e-07,
        4.3896e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,358][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9383e-01, 2.0310e-03, 8.8255e-05, 5.4675e-05, 1.4501e-05, 2.7497e-05,
        2.6516e-07, 7.1192e-07, 1.4160e-06, 2.2087e-07, 1.1477e-05, 5.1802e-05,
        3.2948e-05, 1.6788e-03, 1.2043e-06, 1.2578e-03, 4.1770e-04, 6.1448e-05,
        4.3818e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,407][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:19:54,407][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,408][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,408][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,408][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,409][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,409][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,409][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,409][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,410][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,410][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,410][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,411][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:19:54,412][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9890, 0.0110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,413][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9950e-01, 4.9778e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,415][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0285, 0.9715], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,416][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,417][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0444, 0.9556], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,417][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9467, 0.0533], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,418][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8331, 0.1669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,418][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0126, 0.9874], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,418][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2409, 0.7591], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,418][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9756, 0.0244], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,419][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.0000e+00, 2.4905e-08], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,419][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9833, 0.0167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:19:54,419][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Kenneth] are: tensor([0.8224, 0.1282, 0.0494], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,420][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Kenneth] are: tensor([0.9820, 0.0082, 0.0098], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,420][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Kenneth] are: tensor([8.6256e-04, 9.9879e-01, 3.4724e-04], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,422][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Kenneth] are: tensor([0.7414, 0.2509, 0.0077], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,424][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Kenneth] are: tensor([0.0010, 0.2175, 0.7815], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,425][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Kenneth] are: tensor([0.0817, 0.8932, 0.0251], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,426][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Kenneth] are: tensor([0.3880, 0.5830, 0.0289], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,427][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Kenneth] are: tensor([0.0062, 0.7893, 0.2045], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,428][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Kenneth] are: tensor([0.0485, 0.6003, 0.3511], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,428][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Kenneth] are: tensor([0.2969, 0.6750, 0.0281], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,428][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Kenneth] are: tensor([1.0000e+00, 1.1959e-06, 5.6491e-07], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,428][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Kenneth] are: tensor([0.9296, 0.0503, 0.0201], device='cuda:0') for source tokens [Then, Kenneth]
[2024-07-24 10:19:54,429][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8176, 0.0933, 0.0110, 0.0781], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,429][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.4588e-01, 4.0482e-03, 4.9425e-02, 6.5139e-04], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,429][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0062, 0.9433, 0.0198, 0.0308], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,429][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.8670e-01, 9.7927e-03, 9.2362e-04, 2.5869e-03], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,430][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0009, 0.0735, 0.4555, 0.4701], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,430][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8170, 0.1459, 0.0177, 0.0194], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,431][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5468, 0.3644, 0.0789, 0.0099], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,432][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0031, 0.4412, 0.1584, 0.3973], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,434][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0498, 0.4350, 0.2638, 0.2515], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,435][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9190, 0.0223, 0.0206, 0.0380], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,436][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.0000e+00, 4.3975e-08, 5.3122e-09, 3.9855e-08], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,437][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.9678e-01, 2.7209e-03, 4.1368e-04, 8.7218e-05], device='cuda:0') for source tokens [Then, Kenneth and]
[2024-07-24 10:19:54,438][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.4972, 0.0628, 0.0691, 0.2232, 0.1476], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,438][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.9102, 0.0228, 0.0444, 0.0033, 0.0194], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,438][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([6.5833e-04, 8.6724e-01, 4.0725e-03, 3.8707e-02, 8.9322e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,438][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.4931, 0.0618, 0.0026, 0.1438, 0.2987], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,439][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([1.8104e-04, 6.0692e-02, 4.3532e-01, 1.1199e-01, 3.9181e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,439][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.1192, 0.7427, 0.0155, 0.0270, 0.0956], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,439][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0679, 0.8263, 0.0529, 0.0317, 0.0212], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,440][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0029, 0.3488, 0.0874, 0.4139, 0.1470], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,440][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0402, 0.3252, 0.2076, 0.1988, 0.2281], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,440][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1312, 0.3163, 0.0333, 0.4761, 0.0430], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,441][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([9.9979e-01, 1.5240e-05, 4.0521e-06, 3.1248e-05, 1.6053e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,442][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.9464, 0.0261, 0.0180, 0.0068, 0.0027], device='cuda:0') for source tokens [Then, Kenneth and Kelly]
[2024-07-24 10:19:54,444][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6491, 0.1249, 0.0271, 0.0990, 0.0938, 0.0061], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,446][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.8257, 0.0213, 0.1104, 0.0061, 0.0316, 0.0049], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,447][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0068, 0.3938, 0.0186, 0.1035, 0.4658, 0.0114], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,448][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([8.9192e-01, 3.4789e-02, 6.3591e-04, 1.1121e-02, 7.8189e-03, 5.3719e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,448][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([1.0709e-04, 1.2619e-02, 3.8052e-01, 1.4572e-01, 3.5562e-01, 1.0541e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,448][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1491, 0.5430, 0.1527, 0.0961, 0.0337, 0.0254], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,449][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.5574, 0.3044, 0.0476, 0.0240, 0.0458, 0.0208], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,449][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0014, 0.3237, 0.1005, 0.3766, 0.1134, 0.0844], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,449][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0415, 0.2592, 0.1589, 0.1586, 0.1739, 0.2079], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,450][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.8922, 0.0306, 0.0295, 0.0376, 0.0072, 0.0029], device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,450][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([9.9999e-01, 1.7759e-06, 5.3462e-07, 3.9124e-06, 3.1688e-06, 8.9287e-07],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,450][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([9.8408e-01, 1.1911e-02, 2.0882e-03, 1.2086e-03, 6.2534e-05, 6.5138e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had]
[2024-07-24 10:19:54,451][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3458, 0.1993, 0.0229, 0.2174, 0.1542, 0.0279, 0.0325],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,451][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6811, 0.0446, 0.1696, 0.0089, 0.0872, 0.0061, 0.0024],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,452][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.9553e-04, 6.4207e-01, 5.3766e-03, 1.0689e-01, 2.3008e-01, 1.1877e-02,
        3.4096e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,454][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0830, 0.0587, 0.0026, 0.0687, 0.0685, 0.7169, 0.0016],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,455][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([6.9137e-05, 5.0701e-02, 4.1717e-01, 1.8576e-01, 1.8720e-01, 1.3540e-01,
        2.3690e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,456][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0949, 0.4678, 0.1289, 0.0785, 0.1753, 0.0472, 0.0074],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,458][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0985, 0.7539, 0.0621, 0.0289, 0.0377, 0.0124, 0.0065],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,458][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0021, 0.3165, 0.0777, 0.2771, 0.1033, 0.0607, 0.1626],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,458][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0445, 0.2086, 0.1331, 0.1317, 0.1403, 0.1694, 0.1723],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,459][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7715, 0.0650, 0.0382, 0.0908, 0.0220, 0.0100, 0.0025],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,459][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9987e-01, 3.3435e-05, 3.4968e-06, 6.1933e-05, 2.4194e-05, 6.2438e-06,
        1.9981e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,459][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.8837e-01, 1.2476e-01, 2.1783e-02, 3.7020e-02, 3.3206e-03, 2.4609e-02,
        1.3870e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a]
[2024-07-24 10:19:54,460][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.6766, 0.1071, 0.0328, 0.0982, 0.0580, 0.0100, 0.0066, 0.0107],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,460][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.4492, 0.1031, 0.2260, 0.0215, 0.1296, 0.0390, 0.0264, 0.0053],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,460][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([4.8369e-04, 7.3208e-01, 2.4028e-03, 1.0569e-01, 1.3169e-01, 1.2189e-02,
        1.4580e-02, 8.7322e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,461][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([9.2582e-02, 1.7419e-01, 8.0330e-04, 6.0986e-02, 5.4330e-02, 6.1466e-01,
        1.8417e-03, 6.0321e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,461][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([6.4705e-05, 3.2492e-02, 3.5469e-01, 7.2965e-02, 4.3681e-01, 8.2177e-02,
        1.6910e-02, 3.8948e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,463][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0120, 0.5224, 0.0463, 0.0260, 0.3654, 0.0144, 0.0103, 0.0032],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,465][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0280, 0.5536, 0.1029, 0.0417, 0.1951, 0.0425, 0.0355, 0.0008],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,466][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0012, 0.2356, 0.0580, 0.3221, 0.0790, 0.0663, 0.1735, 0.0642],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,467][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0370, 0.1738, 0.1061, 0.1078, 0.1178, 0.1356, 0.1404, 0.1814],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,468][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.1121, 0.1374, 0.0775, 0.2808, 0.2463, 0.0937, 0.0459, 0.0063],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,469][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([9.9881e-01, 2.4821e-04, 6.7660e-05, 4.9338e-04, 3.3152e-04, 2.2923e-05,
        6.0882e-06, 1.8243e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,469][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([7.6376e-01, 1.5149e-01, 2.8405e-02, 2.4991e-02, 5.5373e-03, 2.5482e-02,
        1.8313e-04, 1.5632e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot]
[2024-07-24 10:19:54,469][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.7389, 0.0655, 0.0122, 0.0630, 0.0699, 0.0134, 0.0084, 0.0206, 0.0080],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,470][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.8130, 0.0174, 0.1254, 0.0064, 0.0261, 0.0064, 0.0022, 0.0011, 0.0021],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,470][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0032, 0.8089, 0.0064, 0.0470, 0.0771, 0.0133, 0.0162, 0.0009, 0.0271],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,470][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([7.6547e-01, 2.1936e-02, 1.0840e-03, 6.0602e-03, 8.7848e-03, 1.5740e-01,
        4.1778e-04, 1.2275e-03, 3.7612e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,471][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([2.8798e-04, 2.1967e-02, 1.9656e-01, 1.7962e-01, 2.9736e-01, 1.4189e-01,
        2.7835e-02, 4.7569e-03, 1.2973e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,471][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.3368, 0.3180, 0.0381, 0.0848, 0.1334, 0.0522, 0.0186, 0.0044, 0.0137],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,472][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([4.7361e-01, 3.5214e-01, 9.9571e-02, 1.4500e-02, 3.6064e-02, 7.8530e-03,
        9.3684e-03, 3.0897e-04, 6.5863e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,473][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0011, 0.1937, 0.0377, 0.2907, 0.0516, 0.0560, 0.1470, 0.0648, 0.1573],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,475][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0271, 0.1541, 0.0938, 0.0917, 0.1006, 0.1238, 0.1295, 0.1666, 0.1129],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,476][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([8.2521e-01, 2.8953e-02, 3.2851e-02, 8.0763e-02, 1.1827e-02, 1.0754e-02,
        5.8302e-03, 3.9173e-04, 3.4193e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,477][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([9.9996e-01, 8.9007e-06, 4.5418e-06, 1.3228e-05, 7.3435e-06, 1.0317e-06,
        4.0968e-07, 6.6562e-07, 4.2704e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,478][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([9.9459e-01, 3.7816e-03, 6.8538e-04, 2.7236e-04, 6.6617e-05, 5.8022e-04,
        3.2348e-06, 7.0794e-06, 1.4391e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of]
[2024-07-24 10:19:54,479][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.8078, 0.0898, 0.0138, 0.0212, 0.0457, 0.0087, 0.0032, 0.0049, 0.0031,
        0.0018], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,479][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.4174, 0.2830, 0.1956, 0.0194, 0.0636, 0.0131, 0.0041, 0.0010, 0.0024,
        0.0006], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,479][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([2.1985e-04, 8.0305e-01, 4.9713e-03, 7.6609e-02, 6.3209e-02, 1.9724e-02,
        6.8843e-03, 5.3124e-04, 2.4320e-02, 4.7806e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,480][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.1759, 0.2132, 0.0008, 0.0500, 0.0446, 0.4366, 0.0008, 0.0008, 0.0732,
        0.0040], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,480][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([1.2489e-04, 8.4236e-02, 2.7395e-01, 1.7334e-01, 2.5082e-01, 1.0112e-01,
        1.9178e-02, 2.3827e-03, 7.1251e-02, 2.3595e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,480][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0043, 0.6950, 0.0758, 0.0523, 0.1191, 0.0306, 0.0079, 0.0016, 0.0095,
        0.0040], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,481][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([3.0979e-02, 7.7112e-01, 4.8106e-02, 4.1606e-02, 6.1549e-02, 3.0207e-02,
        1.1083e-02, 1.2677e-04, 4.5292e-03, 6.9414e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,481][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0006, 0.2112, 0.0358, 0.2750, 0.0544, 0.0518, 0.1338, 0.0504, 0.1247,
        0.0623], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,481][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0274, 0.1335, 0.0847, 0.0824, 0.0907, 0.1059, 0.1060, 0.1396, 0.0985,
        0.1314], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,482][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1327, 0.4025, 0.0503, 0.2429, 0.0941, 0.0527, 0.0100, 0.0019, 0.0124,
        0.0005], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,483][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([9.9938e-01, 2.0093e-04, 3.5417e-05, 1.4053e-04, 2.0835e-04, 1.6069e-05,
        2.5305e-06, 1.9135e-06, 1.3439e-05, 2.3550e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,484][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([8.9158e-01, 9.0612e-02, 6.5352e-03, 3.9350e-03, 1.8252e-03, 5.3102e-03,
        2.9414e-05, 6.6773e-05, 8.7869e-05, 1.7919e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun]
[2024-07-24 10:19:54,486][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.8153, 0.0386, 0.0176, 0.0306, 0.0688, 0.0068, 0.0063, 0.0088, 0.0034,
        0.0014, 0.0024], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,487][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([8.8702e-01, 1.4045e-02, 6.7320e-02, 4.0202e-03, 1.2094e-02, 5.6761e-03,
        1.3619e-03, 7.3484e-04, 2.0760e-03, 4.0724e-04, 5.2428e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,487][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.9998e-03, 7.3190e-01, 8.6915e-03, 5.4852e-02, 1.3418e-01, 1.2475e-02,
        4.2526e-03, 8.8212e-04, 2.7233e-02, 6.2874e-04, 2.1907e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,488][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([5.7729e-01, 5.4996e-02, 6.8715e-04, 2.4729e-02, 1.4245e-02, 1.6558e-01,
        3.9877e-04, 1.5268e-03, 5.4932e-02, 1.1808e-03, 1.0444e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,489][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([1.9621e-04, 1.6985e-02, 2.0785e-01, 1.3610e-01, 1.9547e-01, 1.3949e-01,
        2.0093e-02, 2.0320e-03, 5.8797e-02, 1.7399e-02, 2.0558e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,489][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0128, 0.5122, 0.0538, 0.1017, 0.1688, 0.0753, 0.0162, 0.0044, 0.0433,
        0.0043, 0.0074], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,489][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([4.3026e-01, 4.3523e-01, 4.9529e-02, 1.7158e-02, 3.0342e-02, 1.8361e-02,
        6.3487e-03, 1.5619e-04, 6.9134e-03, 4.3925e-04, 5.2599e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,490][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0012, 0.1320, 0.0242, 0.2778, 0.0518, 0.0489, 0.1027, 0.0500, 0.1247,
        0.0711, 0.1155], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,490][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0288, 0.1215, 0.0762, 0.0742, 0.0798, 0.0944, 0.0968, 0.1259, 0.0887,
        0.1155, 0.0982], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,490][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.0916e-01, 1.2731e-01, 6.0081e-02, 5.2727e-02, 2.3075e-02, 1.3818e-02,
        6.6124e-03, 7.5311e-04, 4.6509e-03, 3.2609e-04, 1.4928e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,491][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([9.9985e-01, 7.3566e-06, 6.8663e-06, 2.0231e-05, 1.6962e-05, 5.1862e-06,
        6.8289e-07, 1.1998e-06, 5.5676e-06, 6.6002e-07, 8.1463e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,491][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([9.7758e-01, 1.3021e-02, 4.1978e-03, 3.2161e-03, 5.2544e-04, 1.2365e-03,
        6.8999e-06, 4.7557e-06, 3.1006e-05, 4.3027e-06, 1.7316e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at]
[2024-07-24 10:19:54,491][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7481, 0.0552, 0.0151, 0.0553, 0.0376, 0.0144, 0.0080, 0.0081, 0.0067,
        0.0016, 0.0038, 0.0462], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,492][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([8.5483e-01, 2.0474e-02, 8.2023e-02, 4.2136e-03, 1.7435e-02, 2.0945e-03,
        1.7614e-03, 3.6958e-04, 1.3730e-03, 1.2632e-04, 6.1081e-03, 9.1877e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,494][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([5.4862e-03, 6.8220e-01, 8.6209e-03, 4.8582e-02, 1.3769e-01, 8.3709e-03,
        5.7518e-03, 3.3798e-04, 2.0781e-02, 2.8856e-04, 3.4477e-02, 4.7413e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,495][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([3.0104e-01, 2.0304e-02, 1.5561e-04, 5.3001e-03, 3.6326e-03, 3.5977e-02,
        5.9558e-05, 1.2586e-04, 1.5153e-02, 2.9583e-04, 2.7474e-02, 5.9048e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,496][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0004, 0.0263, 0.2775, 0.1245, 0.1437, 0.1277, 0.0222, 0.0023, 0.0484,
        0.0067, 0.1953, 0.0250], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,498][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1331, 0.5884, 0.0624, 0.0366, 0.1265, 0.0160, 0.0099, 0.0016, 0.0069,
        0.0014, 0.0040, 0.0133], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,498][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([6.5774e-01, 2.4652e-01, 4.4569e-02, 5.0249e-03, 2.5872e-02, 3.5190e-03,
        3.2179e-03, 7.2966e-05, 2.0794e-03, 2.2658e-04, 4.2068e-03, 6.9518e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,499][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0013, 0.1431, 0.0356, 0.2157, 0.0513, 0.0353, 0.1040, 0.0468, 0.1092,
        0.0570, 0.0896, 0.1112], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,499][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0340, 0.1066, 0.0710, 0.0688, 0.0734, 0.0843, 0.0851, 0.1086, 0.0777,
        0.0991, 0.0857, 0.1057], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,500][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.0697e-01, 4.4255e-02, 2.4132e-02, 7.6825e-03, 1.0940e-02, 1.3737e-03,
        1.3493e-03, 1.0032e-04, 7.4618e-04, 1.0855e-04, 5.9905e-04, 1.7419e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,500][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.9993e-01, 1.2234e-05, 4.4313e-06, 1.2498e-05, 1.2500e-05, 1.1747e-06,
        2.7027e-07, 2.4899e-07, 2.5367e-06, 1.0617e-07, 2.4566e-05, 3.0843e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,500][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([9.9216e-01, 4.9698e-03, 9.1332e-04, 6.8618e-04, 7.0154e-05, 5.0348e-04,
        2.9705e-06, 2.9951e-06, 1.0010e-05, 1.1429e-06, 6.6469e-05, 6.1128e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the]
[2024-07-24 10:19:54,501][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ office] are: tensor([0.8297, 0.0819, 0.0142, 0.0154, 0.0256, 0.0033, 0.0028, 0.0043, 0.0026,
        0.0011, 0.0017, 0.0150, 0.0025], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,501][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ office] are: tensor([7.7270e-01, 1.3729e-02, 3.2249e-02, 1.1692e-03, 1.4906e-02, 6.1360e-03,
        1.1984e-03, 1.9208e-03, 3.4271e-03, 5.6741e-04, 9.5177e-03, 1.2734e-02,
        1.2975e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,501][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ office] are: tensor([0.0126, 0.4008, 0.0100, 0.1163, 0.1448, 0.0313, 0.0110, 0.0016, 0.1004,
        0.0018, 0.0538, 0.1101, 0.0056], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,502][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ office] are: tensor([6.0527e-01, 6.3277e-03, 1.8871e-05, 2.0776e-03, 1.5307e-03, 4.1278e-02,
        6.4773e-05, 7.6408e-05, 8.1186e-03, 3.5829e-04, 1.0758e-02, 3.0986e-01,
        1.4262e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,504][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ office] are: tensor([0.0005, 0.0181, 0.1846, 0.0531, 0.1074, 0.0934, 0.0195, 0.0025, 0.0484,
        0.0135, 0.2511, 0.0169, 0.1910], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,506][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ office] are: tensor([0.0744, 0.4672, 0.0656, 0.0298, 0.2774, 0.0322, 0.0076, 0.0032, 0.0076,
        0.0050, 0.0091, 0.0104, 0.0105], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,507][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ office] are: tensor([2.5299e-01, 4.0773e-01, 8.4209e-02, 3.3847e-02, 9.2258e-02, 2.5418e-02,
        1.1682e-02, 3.3853e-04, 2.8020e-02, 1.1051e-03, 2.5980e-02, 3.3419e-02,
        3.0067e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,508][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ office] are: tensor([0.0006, 0.1223, 0.0245, 0.1855, 0.0413, 0.0468, 0.0991, 0.0482, 0.1027,
        0.0680, 0.1042, 0.1157, 0.0411], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,509][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ office] are: tensor([0.0206, 0.0967, 0.0619, 0.0588, 0.0666, 0.0753, 0.0788, 0.1053, 0.0716,
        0.0976, 0.0795, 0.0995, 0.0879], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,510][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ office] are: tensor([5.4191e-01, 1.2042e-01, 2.6838e-02, 1.4531e-01, 5.9634e-02, 4.5801e-02,
        9.0240e-03, 1.5972e-03, 1.4726e-02, 4.3295e-04, 6.3864e-03, 2.4564e-02,
        3.3613e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,510][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ office] are: tensor([9.9983e-01, 1.6292e-05, 4.9676e-06, 4.5635e-05, 2.5771e-05, 3.9677e-06,
        6.2813e-07, 1.5717e-06, 6.8313e-06, 8.3082e-07, 5.4418e-05, 4.3531e-06,
        4.5137e-06], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,510][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ office] are: tensor([9.9561e-01, 3.0601e-03, 5.2594e-04, 1.9930e-04, 3.4132e-05, 1.6940e-04,
        2.3139e-06, 1.2426e-06, 7.1826e-06, 1.5168e-06, 5.4793e-05, 2.4970e-04,
        8.4880e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office]
[2024-07-24 10:19:54,511][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.1411e-01, 9.6820e-03, 1.6032e-03, 5.6064e-03, 5.1407e-03, 1.0940e-03,
        7.2075e-04, 9.2778e-04, 4.9601e-04, 9.9596e-05, 3.4193e-04, 6.1389e-03,
        1.3004e-04, 5.3904e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,511][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([9.2693e-01, 1.6828e-03, 3.4343e-02, 5.8598e-04, 5.9867e-03, 6.6940e-04,
        1.5396e-04, 2.0787e-04, 2.6454e-04, 4.1718e-05, 2.9956e-03, 2.3192e-03,
        1.5187e-02, 8.6323e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,511][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([2.3328e-02, 3.4787e-01, 6.2209e-03, 4.4441e-02, 1.2642e-01, 2.6777e-02,
        5.0666e-03, 4.2811e-04, 1.7183e-02, 3.1245e-04, 3.7991e-02, 3.1329e-02,
        4.5707e-03, 3.2806e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,512][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([4.0285e-01, 2.0256e-03, 4.2140e-06, 1.0878e-04, 2.6755e-05, 6.4593e-04,
        4.8708e-07, 3.8256e-07, 9.3235e-05, 8.1754e-07, 1.5618e-04, 3.5750e-03,
        1.7347e-04, 5.9034e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,512][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0011, 0.0171, 0.2726, 0.0883, 0.1526, 0.0819, 0.0115, 0.0026, 0.0334,
        0.0051, 0.1338, 0.0155, 0.0639, 0.1206], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,514][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.4394, 0.2006, 0.0372, 0.0466, 0.1061, 0.0287, 0.0064, 0.0023, 0.0078,
        0.0017, 0.0046, 0.0128, 0.0054, 0.1002], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,515][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([8.4179e-01, 9.9281e-02, 1.0460e-02, 2.4055e-03, 1.1846e-02, 2.9935e-03,
        1.1084e-03, 3.3916e-05, 1.2412e-03, 7.5882e-05, 3.1910e-03, 5.0221e-03,
        4.7041e-04, 2.0078e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,517][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0011, 0.1178, 0.0247, 0.1764, 0.0458, 0.0405, 0.0793, 0.0359, 0.0852,
        0.0509, 0.0724, 0.0855, 0.0365, 0.1482], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,518][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0231, 0.0904, 0.0595, 0.0562, 0.0607, 0.0710, 0.0736, 0.0981, 0.0651,
        0.0856, 0.0729, 0.0899, 0.0782, 0.0756], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,519][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([9.3399e-01, 7.2705e-03, 7.7790e-03, 4.2293e-03, 4.1639e-03, 1.1835e-03,
        5.2126e-04, 4.1781e-05, 4.7339e-04, 3.9722e-05, 4.5170e-04, 1.2544e-03,
        6.5766e-04, 3.7942e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,520][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([9.9995e-01, 5.0668e-07, 1.1698e-07, 4.6775e-07, 3.0345e-07, 4.0801e-08,
        6.2778e-09, 1.1837e-08, 5.9439e-08, 5.2571e-09, 6.3201e-07, 8.1209e-08,
        4.7788e-08, 4.4504e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,520][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([9.9309e-01, 2.4028e-03, 1.9701e-04, 1.5339e-04, 1.3729e-05, 1.3165e-04,
        3.1662e-07, 6.2092e-07, 3.2875e-06, 1.6953e-07, 1.0673e-05, 4.2541e-05,
        2.3089e-05, 3.9329e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office.]
[2024-07-24 10:19:54,520][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.1925, 0.0055, 0.0146, 0.0651, 0.0841, 0.0149, 0.0224, 0.0089, 0.0158,
        0.0011, 0.0051, 0.1433, 0.0013, 0.3695, 0.0558], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,521][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([4.6448e-01, 7.0748e-02, 7.4883e-02, 1.5316e-02, 6.1627e-02, 1.5577e-02,
        1.8661e-03, 6.3515e-04, 2.9731e-03, 3.8371e-04, 1.9012e-02, 2.4791e-02,
        1.1231e-01, 1.2815e-01, 7.2509e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,521][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([5.0561e-04, 3.2118e-01, 2.8416e-03, 8.1712e-02, 4.0882e-02, 1.0618e-02,
        1.7611e-03, 1.0500e-04, 1.2795e-02, 8.6535e-05, 2.0582e-02, 2.1096e-02,
        6.0589e-03, 4.6803e-01, 1.1743e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,521][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([1.1301e-04, 1.1271e-04, 6.9914e-07, 1.2965e-04, 5.9288e-05, 9.6719e-04,
        2.2066e-06, 6.8070e-06, 3.5801e-04, 3.2502e-06, 2.0791e-04, 1.4628e-02,
        4.8514e-04, 9.8115e-01, 1.7716e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,522][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0007, 0.0531, 0.2511, 0.0853, 0.1291, 0.1253, 0.0093, 0.0024, 0.0272,
        0.0100, 0.0596, 0.0168, 0.1107, 0.1065, 0.0130], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,522][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0153, 0.3894, 0.0109, 0.0765, 0.2410, 0.0361, 0.0067, 0.0051, 0.0220,
        0.0026, 0.0075, 0.0174, 0.0090, 0.1468, 0.0137], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,523][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([4.7095e-02, 6.7084e-01, 4.0792e-02, 3.7928e-02, 2.9175e-02, 4.1205e-02,
        4.2179e-03, 5.1231e-05, 2.9307e-03, 1.4575e-04, 6.8685e-03, 2.2265e-02,
        3.8489e-04, 9.4625e-02, 1.4730e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,525][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0012, 0.1015, 0.0180, 0.1860, 0.0290, 0.0441, 0.0812, 0.0347, 0.0936,
        0.0448, 0.0723, 0.0924, 0.0334, 0.1258, 0.0423], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,526][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0198, 0.0836, 0.0536, 0.0518, 0.0568, 0.0667, 0.0671, 0.0857, 0.0617,
        0.0804, 0.0701, 0.0874, 0.0764, 0.0752, 0.0636], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,527][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([6.8087e-03, 1.4528e-01, 1.5934e-02, 4.3909e-01, 3.4412e-02, 3.9610e-02,
        1.0813e-02, 1.9431e-04, 3.3295e-03, 6.5655e-05, 3.1183e-03, 1.5156e-02,
        1.2663e-03, 2.8444e-01, 4.7429e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,528][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([8.8767e-01, 5.3487e-04, 2.4770e-04, 9.7014e-04, 3.1633e-03, 3.4387e-04,
        1.1718e-04, 1.8882e-05, 1.2463e-04, 1.7178e-05, 2.4834e-03, 3.3020e-04,
        1.6774e-04, 9.2748e-02, 1.1066e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,529][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([5.8488e-01, 8.5733e-02, 3.1841e-02, 1.7090e-02, 3.4066e-03, 7.9897e-03,
        1.3979e-04, 2.3690e-04, 5.4124e-04, 9.8005e-05, 1.3720e-03, 1.3125e-02,
        5.5465e-03, 2.4782e-01, 1.7862e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly]
[2024-07-24 10:19:54,530][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([7.9457e-01, 5.3416e-02, 2.5503e-03, 6.8857e-03, 1.1793e-02, 9.7197e-04,
        2.6133e-04, 5.8917e-04, 5.8393e-04, 1.4692e-04, 4.1104e-04, 5.8681e-03,
        1.2763e-04, 4.8412e-02, 4.4724e-03, 6.8944e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,530][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([8.7470e-01, 1.3828e-02, 2.4548e-02, 2.0380e-03, 8.8437e-03, 1.4682e-03,
        1.0951e-03, 1.1984e-04, 7.9502e-04, 5.8588e-05, 2.9908e-03, 5.5671e-03,
        1.8690e-02, 3.4989e-02, 1.9403e-03, 8.3284e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,531][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.4440e-02, 1.7020e-01, 6.9577e-03, 5.0711e-02, 1.0058e-01, 7.4879e-03,
        3.8035e-03, 4.0738e-04, 2.4210e-02, 3.6306e-04, 1.9107e-02, 4.2641e-02,
        7.6450e-03, 4.8567e-01, 4.6562e-02, 1.9212e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,531][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.6958e-01, 5.9849e-04, 3.5897e-07, 4.9934e-05, 6.9092e-06, 3.1639e-04,
        1.6743e-07, 1.0614e-07, 2.5542e-05, 3.7579e-07, 3.2283e-05, 1.0230e-03,
        8.2275e-05, 5.8780e-01, 1.1524e-04, 2.4036e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,531][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.8786e-04, 7.3148e-03, 3.4538e-01, 3.4760e-02, 1.3426e-01, 4.5875e-02,
        1.1463e-02, 6.9273e-04, 1.8458e-02, 5.0408e-03, 7.9023e-02, 1.4427e-02,
        9.4097e-02, 4.4017e-02, 2.3034e-02, 1.4197e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,532][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0440, 0.1719, 0.0718, 0.0758, 0.2268, 0.0455, 0.0207, 0.0039, 0.0275,
        0.0030, 0.0120, 0.0357, 0.0098, 0.1599, 0.0258, 0.0660],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,532][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([6.3670e-01, 1.5792e-01, 1.7399e-02, 1.0684e-02, 4.0974e-02, 9.0957e-03,
        4.2892e-03, 5.4276e-05, 3.6267e-03, 2.0760e-04, 5.9368e-03, 1.2061e-02,
        9.4841e-04, 6.8255e-02, 4.6823e-03, 2.7169e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,532][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0004, 0.0721, 0.0170, 0.1691, 0.0362, 0.0340, 0.0767, 0.0312, 0.0906,
        0.0414, 0.0764, 0.0983, 0.0309, 0.1155, 0.0562, 0.0540],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,533][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0217, 0.0776, 0.0487, 0.0487, 0.0505, 0.0618, 0.0619, 0.0812, 0.0561,
        0.0728, 0.0632, 0.0780, 0.0672, 0.0658, 0.0537, 0.0912],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,534][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([4.4395e-01, 2.4850e-02, 1.0253e-02, 6.0498e-02, 3.2297e-02, 7.0155e-03,
        2.8716e-03, 2.7307e-04, 3.8770e-03, 2.3694e-04, 3.4100e-03, 9.2909e-03,
        3.8851e-03, 3.8206e-01, 2.7808e-03, 1.2456e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,535][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([9.9986e-01, 1.5573e-06, 2.3541e-07, 1.4050e-06, 6.5982e-07, 8.2905e-08,
        9.4057e-09, 1.3001e-08, 6.8704e-08, 8.7988e-09, 8.8250e-07, 2.3875e-07,
        9.7710e-08, 1.0883e-04, 4.3909e-06, 2.3541e-05], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,536][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([9.9858e-01, 5.1385e-04, 3.1632e-05, 3.3775e-05, 1.3650e-06, 2.1017e-05,
        6.9690e-08, 8.1098e-08, 4.6808e-07, 2.7079e-08, 1.4907e-06, 1.3429e-05,
        5.3065e-06, 6.0706e-04, 9.1936e-08, 1.9037e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave]
[2024-07-24 10:19:54,537][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([7.0963e-01, 2.3688e-02, 3.4932e-03, 1.3643e-02, 7.8161e-03, 2.2017e-03,
        1.3077e-03, 1.3017e-03, 1.1794e-03, 4.1098e-04, 8.9029e-04, 7.8336e-03,
        2.9514e-04, 5.2809e-02, 3.3176e-03, 7.7284e-02, 9.2903e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,538][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.5578e-01, 1.9186e-03, 1.5165e-02, 5.9027e-04, 6.4998e-03, 4.2420e-04,
        2.4725e-04, 8.9375e-05, 1.7104e-04, 1.5654e-05, 1.2243e-03, 8.7185e-04,
        7.8615e-03, 3.8470e-03, 7.5754e-04, 2.2086e-03, 2.3262e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,539][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.3028e-02, 3.3021e-01, 5.1565e-03, 7.9048e-02, 1.1931e-01, 1.3959e-02,
        3.4629e-03, 4.2571e-04, 1.5922e-02, 1.8621e-04, 1.9982e-02, 3.0375e-02,
        1.8218e-03, 1.8217e-01, 3.0606e-02, 2.7533e-02, 1.1680e-01],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,540][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.6670e-02, 3.1701e-04, 9.9391e-07, 2.9458e-05, 1.1257e-05, 2.1867e-04,
        1.6243e-07, 5.2939e-07, 5.1031e-05, 8.0342e-07, 9.2706e-05, 1.6002e-03,
        9.9316e-05, 2.4302e-01, 2.0445e-04, 6.5424e-01, 2.3439e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,541][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0008, 0.0297, 0.2618, 0.1165, 0.1070, 0.0853, 0.0147, 0.0015, 0.0280,
        0.0040, 0.0952, 0.0137, 0.0479, 0.0647, 0.0118, 0.0558, 0.0617],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,541][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3082, 0.2939, 0.0711, 0.0631, 0.1062, 0.0366, 0.0070, 0.0017, 0.0056,
        0.0008, 0.0036, 0.0099, 0.0026, 0.0438, 0.0041, 0.0115, 0.0304],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,541][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([8.0738e-01, 1.1068e-01, 1.7532e-02, 4.7107e-03, 1.7526e-02, 2.7979e-03,
        1.6652e-03, 2.2884e-05, 7.1822e-04, 5.0312e-05, 1.7028e-03, 3.1753e-03,
        3.2010e-04, 7.7581e-03, 9.2120e-04, 5.9290e-03, 1.7114e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,542][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0010, 0.1155, 0.0190, 0.1603, 0.0306, 0.0303, 0.0761, 0.0307, 0.0784,
        0.0372, 0.0720, 0.0824, 0.0295, 0.0962, 0.0385, 0.0450, 0.0574],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,542][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0166, 0.0721, 0.0454, 0.0441, 0.0474, 0.0566, 0.0586, 0.0774, 0.0520,
        0.0694, 0.0579, 0.0739, 0.0623, 0.0604, 0.0514, 0.0841, 0.0702],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,542][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.6936e-01, 6.9687e-03, 3.8670e-03, 3.7195e-03, 2.2043e-03, 5.1684e-04,
        2.6483e-04, 1.6625e-05, 1.9018e-04, 1.0407e-05, 1.5771e-04, 5.0772e-04,
        1.3630e-04, 8.1518e-03, 1.0054e-04, 1.5158e-03, 2.3120e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,543][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9991e-01, 2.9798e-06, 3.5190e-07, 1.3739e-06, 6.5706e-07, 1.6238e-07,
        3.0246e-08, 2.3570e-08, 1.1172e-07, 6.2938e-09, 1.2821e-06, 2.4800e-07,
        8.7069e-08, 7.3362e-05, 2.1180e-06, 8.2175e-06, 3.3928e-06],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,544][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.9016e-01, 2.8875e-03, 1.8888e-04, 2.4131e-04, 1.8175e-05, 8.0513e-05,
        6.4700e-07, 1.0637e-06, 2.7927e-06, 3.1719e-07, 1.6355e-05, 1.0256e-04,
        4.7221e-05, 3.4232e-03, 8.7083e-07, 2.0173e-03, 8.1342e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a]
[2024-07-24 10:19:54,545][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([7.4845e-01, 2.9611e-02, 5.8602e-03, 1.4645e-02, 9.9617e-03, 2.5118e-03,
        9.9752e-04, 4.5896e-04, 1.0790e-03, 4.8516e-04, 9.5874e-04, 5.4478e-03,
        6.2334e-04, 5.2245e-02, 3.0067e-03, 5.1153e-02, 5.9290e-02, 1.3221e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,546][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([9.3288e-01, 5.0274e-03, 3.1059e-02, 8.0404e-04, 5.6938e-03, 9.6182e-04,
        1.3973e-04, 3.6249e-04, 2.2555e-04, 4.4392e-05, 6.0727e-04, 9.6712e-04,
        7.7307e-03, 6.8214e-03, 3.7684e-04, 3.6414e-03, 1.6387e-03, 1.0225e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,548][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0548, 0.1798, 0.0105, 0.0623, 0.1525, 0.0215, 0.0027, 0.0005, 0.0126,
        0.0005, 0.0240, 0.0134, 0.0041, 0.1540, 0.0360, 0.1363, 0.1218, 0.0128],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,549][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([1.3076e-01, 1.5155e-03, 1.0120e-06, 6.1701e-05, 9.5551e-05, 3.8172e-04,
        5.2424e-07, 4.3626e-07, 6.0177e-05, 5.2411e-06, 6.5552e-05, 6.6360e-04,
        5.2461e-04, 2.9263e-01, 2.2728e-04, 4.4399e-01, 5.6712e-02, 7.2300e-02],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,550][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0014, 0.0160, 0.2831, 0.0465, 0.1096, 0.0319, 0.0080, 0.0014, 0.0226,
        0.0057, 0.0640, 0.0071, 0.0613, 0.0326, 0.0109, 0.1043, 0.0361, 0.1573],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,551][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.5017, 0.1765, 0.0228, 0.0167, 0.1949, 0.0085, 0.0029, 0.0012, 0.0024,
        0.0016, 0.0025, 0.0031, 0.0040, 0.0161, 0.0103, 0.0109, 0.0108, 0.0130],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,551][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([7.7396e-01, 1.1224e-01, 1.3637e-02, 6.3772e-03, 3.5946e-02, 2.0524e-03,
        1.0306e-03, 3.1027e-05, 1.0310e-03, 1.3332e-04, 1.8556e-03, 2.4483e-03,
        3.3841e-04, 1.5032e-02, 1.2009e-03, 1.3310e-02, 1.7660e-02, 1.7200e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,551][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0006, 0.1095, 0.0189, 0.1634, 0.0324, 0.0313, 0.0694, 0.0404, 0.0707,
        0.0458, 0.0646, 0.0715, 0.0269, 0.0988, 0.0416, 0.0551, 0.0503, 0.0088],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,552][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0116, 0.0693, 0.0423, 0.0401, 0.0442, 0.0523, 0.0554, 0.0739, 0.0492,
        0.0683, 0.0555, 0.0698, 0.0603, 0.0580, 0.0500, 0.0820, 0.0674, 0.0502],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,552][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([9.4227e-01, 1.4102e-02, 5.2747e-03, 8.7627e-03, 1.6661e-02, 7.2083e-04,
        1.2693e-04, 6.7201e-05, 2.2836e-04, 4.0615e-05, 3.3294e-04, 2.4674e-04,
        1.6167e-04, 6.9814e-03, 2.1984e-04, 1.2003e-03, 8.3913e-04, 1.7679e-03],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,552][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([9.9951e-01, 2.2672e-05, 3.2961e-06, 2.3147e-05, 2.4095e-05, 9.8650e-07,
        1.9105e-07, 6.3521e-08, 1.1991e-06, 4.8261e-07, 5.3018e-06, 8.2924e-07,
        9.7218e-07, 2.4716e-04, 1.7629e-05, 8.5143e-05, 1.1933e-05, 4.2058e-05],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,553][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([9.7858e-01, 8.0722e-03, 9.2819e-04, 7.1010e-04, 8.4767e-05, 2.8731e-04,
        1.5811e-06, 1.6615e-06, 4.7792e-06, 1.5127e-06, 1.7225e-05, 1.0031e-04,
        1.0516e-04, 5.8146e-03, 1.9218e-06, 3.1839e-03, 1.9675e-03, 1.3761e-04],
       device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer]
[2024-07-24 10:19:54,554][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.4548e-01, 1.1687e-02, 3.5143e-03, 6.2486e-03, 6.9080e-03, 1.3962e-03,
        8.7756e-04, 1.2471e-03, 7.8595e-04, 1.7993e-04, 4.5240e-04, 7.4028e-03,
        1.2641e-04, 3.6195e-02, 1.8191e-03, 3.6130e-02, 7.5169e-02, 2.3752e-03,
        6.2004e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,555][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.7441e-01, 1.4791e-03, 1.1932e-02, 2.6112e-04, 2.2463e-03, 1.5759e-04,
        1.0764e-04, 6.1800e-05, 1.1365e-04, 9.3903e-06, 5.2421e-04, 5.3469e-04,
        3.6348e-03, 2.1006e-03, 1.6676e-04, 7.8841e-04, 7.8538e-04, 2.7381e-04,
        4.0834e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,556][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.7746e-02, 3.0533e-01, 4.7945e-03, 2.7142e-02, 7.0681e-02, 5.9473e-03,
        3.9687e-03, 4.1407e-04, 1.5907e-02, 2.3643e-04, 2.2998e-02, 2.6393e-02,
        3.2264e-03, 1.5904e-01, 1.9758e-02, 2.4767e-02, 1.4566e-01, 1.6361e-02,
        9.9632e-02], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,557][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.2519e-01, 5.0618e-04, 7.9403e-07, 1.4280e-05, 1.3875e-05, 1.9083e-04,
        1.9232e-07, 4.7821e-07, 3.2333e-05, 6.8039e-07, 5.9788e-05, 1.0892e-03,
        7.9231e-05, 1.5078e-01, 1.4837e-04, 2.6403e-01, 2.2118e-02, 1.1128e-02,
        3.2461e-01], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,559][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0009, 0.0100, 0.1802, 0.0554, 0.1003, 0.0650, 0.0104, 0.0014, 0.0289,
        0.0035, 0.0901, 0.0117, 0.0422, 0.0538, 0.0090, 0.0946, 0.0557, 0.1580,
        0.0288], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,560][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2967, 0.2462, 0.0297, 0.0399, 0.1296, 0.0219, 0.0103, 0.0030, 0.0144,
        0.0010, 0.0061, 0.0161, 0.0049, 0.0706, 0.0108, 0.0184, 0.0364, 0.0103,
        0.0338], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,561][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.5536e-01, 6.9211e-02, 1.6439e-02, 2.0563e-03, 1.4298e-02, 2.7056e-03,
        1.4129e-03, 2.4564e-05, 1.5650e-03, 7.0438e-05, 2.3384e-03, 2.3029e-03,
        4.5032e-04, 6.2622e-03, 8.2407e-04, 5.9190e-03, 1.3732e-02, 8.7403e-04,
        4.1583e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,561][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0010, 0.0968, 0.0182, 0.1598, 0.0280, 0.0304, 0.0653, 0.0298, 0.0771,
        0.0378, 0.0688, 0.0731, 0.0307, 0.0970, 0.0361, 0.0478, 0.0488, 0.0095,
        0.0439], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,561][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0131, 0.0653, 0.0406, 0.0386, 0.0423, 0.0498, 0.0535, 0.0716, 0.0471,
        0.0636, 0.0520, 0.0670, 0.0570, 0.0535, 0.0462, 0.0755, 0.0629, 0.0458,
        0.0546], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,562][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.5005e-01, 7.9913e-03, 4.8670e-03, 2.3471e-03, 5.0551e-03, 4.1293e-04,
        4.3193e-04, 4.4237e-05, 4.9395e-04, 1.8330e-05, 2.6426e-04, 7.3861e-04,
        2.5692e-04, 1.4303e-02, 2.7873e-04, 2.6134e-03, 3.1126e-03, 2.0255e-03,
        4.6949e-03], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,562][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.9998e-01, 4.7200e-07, 7.7850e-08, 9.0334e-08, 1.7777e-07, 8.7472e-09,
        3.6602e-09, 3.3656e-09, 2.5837e-08, 2.8957e-09, 4.6572e-07, 3.8961e-08,
        1.7879e-08, 1.5004e-05, 1.3373e-06, 1.4453e-06, 4.7533e-07, 3.7319e-07,
        4.3896e-07], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,562][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9383e-01, 2.0310e-03, 8.8255e-05, 5.4675e-05, 1.4501e-05, 2.7497e-05,
        2.6516e-07, 7.1192e-07, 1.4160e-06, 2.2087e-07, 1.1477e-05, 5.1802e-05,
        3.2948e-05, 1.6788e-03, 1.2043e-06, 1.2578e-03, 4.1770e-04, 6.1448e-05,
        4.3818e-04], device='cuda:0') for source tokens [Then, Kenneth and Kelly had a lot of fun at the office. Kelly gave a computer to]
[2024-07-24 10:19:54,563][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:19:54,565][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1408],
        [ 163],
        [ 208],
        [  52],
        [  14],
        [  15],
        [  39],
        [ 109],
        [  54],
        [   6],
        [   7],
        [   5],
        [  13],
        [   1],
        [   1],
        [   5],
        [   1],
        [   3],
        [   1]], device='cuda:0')
[2024-07-24 10:19:54,567][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1967],
        [ 378],
        [ 415],
        [ 134],
        [  46],
        [  62],
        [ 140],
        [ 243],
        [ 134],
        [  41],
        [  49],
        [  69],
        [  63],
        [  19],
        [  29],
        [  29],
        [  30],
        [  24],
        [  14]], device='cuda:0')
[2024-07-24 10:19:54,568][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20522],
        [19947],
        [11470],
        [15696],
        [11218],
        [12380],
        [12747],
        [12226],
        [12777],
        [13438],
        [12961],
        [13590],
        [13982],
        [18067],
        [14216],
        [14045],
        [15135],
        [15638],
        [16933]], device='cuda:0')
[2024-07-24 10:19:54,570][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  671],
        [  672],
        [  864],
        [ 2453],
        [ 1944],
        [ 7806],
        [15147],
        [15032],
        [10196],
        [14721],
        [ 3013],
        [ 4406],
        [ 1775],
        [ 1666],
        [ 4543],
        [ 1408],
        [  948],
        [ 1448],
        [  891]], device='cuda:0')
[2024-07-24 10:19:54,571][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6765],
        [44918],
        [44974],
        [45280],
        [44514],
        [39750],
        [42561],
        [43211],
        [44657],
        [44159],
        [44580],
        [44758],
        [43788],
        [44254],
        [43119],
        [42402],
        [43397],
        [42122],
        [45497]], device='cuda:0')
[2024-07-24 10:19:54,573][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13039],
        [13961],
        [32032],
        [14699],
        [41582],
        [25687],
        [32291],
        [32770],
        [29817],
        [33426],
        [30696],
        [39221],
        [38448],
        [40867],
        [41326],
        [43053],
        [44536],
        [44810],
        [44875]], device='cuda:0')
[2024-07-24 10:19:54,574][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15471],
        [10213],
        [ 5263],
        [10513],
        [ 9614],
        [11489],
        [11034],
        [11574],
        [15630],
        [12907],
        [14320],
        [13079],
        [12087],
        [13389],
        [13279],
        [14399],
        [15651],
        [17190],
        [21180]], device='cuda:0')
[2024-07-24 10:19:54,575][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31525],
        [26714],
        [16004],
        [18999],
        [15375],
        [12745],
        [12723],
        [14218],
        [13278],
        [13896],
        [12820],
        [13988],
        [13552],
        [10645],
        [10346],
        [ 7667],
        [10766],
        [13074],
        [ 9238]], device='cuda:0')
[2024-07-24 10:19:54,576][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[32926],
        [40197],
        [40781],
        [45231],
        [40767],
        [43714],
        [41495],
        [43861],
        [45841],
        [40622],
        [42421],
        [44634],
        [43433],
        [42044],
        [39780],
        [42728],
        [43286],
        [42958],
        [43385]], device='cuda:0')
[2024-07-24 10:19:54,578][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49152],
        [47745],
        [41107],
        [44436],
        [44161],
        [46183],
        [45410],
        [44661],
        [47946],
        [41990],
        [47829],
        [47003],
        [45919],
        [48293],
        [46493],
        [47300],
        [48532],
        [49003],
        [49124]], device='cuda:0')
[2024-07-24 10:19:54,579][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15366],
        [23839],
        [15647],
        [17425],
        [22220],
        [19378],
        [19051],
        [17862],
        [18589],
        [19627],
        [18083],
        [19191],
        [17748],
        [17119],
        [17003],
        [17967],
        [17171],
        [17273],
        [16592]], device='cuda:0')
[2024-07-24 10:19:54,581][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38568],
        [42186],
        [46673],
        [42053],
        [36183],
        [43167],
        [41264],
        [35008],
        [39753],
        [41448],
        [44982],
        [44863],
        [38112],
        [36484],
        [25437],
        [18827],
        [39213],
        [39283],
        [38340]], device='cuda:0')
[2024-07-24 10:19:54,583][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32805],
        [32805],
        [32805],
        [32805],
        [32847],
        [32805],
        [32842],
        [33097],
        [32808],
        [32925],
        [32827],
        [32814],
        [32838],
        [32814],
        [48701],
        [32843],
        [32830],
        [32943],
        [32807]], device='cuda:0')
[2024-07-24 10:19:54,584][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13276],
        [11517],
        [11668],
        [13030],
        [11461],
        [11893],
        [ 6286],
        [ 7377],
        [12841],
        [ 7678],
        [11559],
        [12658],
        [12971],
        [12997],
        [15532],
        [13203],
        [12743],
        [12135],
        [13008]], device='cuda:0')
[2024-07-24 10:19:54,585][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15359],
        [ 5529],
        [ 7327],
        [ 5268],
        [ 6769],
        [ 6120],
        [ 5590],
        [ 7091],
        [ 8126],
        [ 5286],
        [ 6087],
        [ 7013],
        [ 5658],
        [ 5338],
        [ 5790],
        [ 7101],
        [ 5263],
        [ 4252],
        [ 4166]], device='cuda:0')
[2024-07-24 10:19:54,586][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22661],
        [22618],
        [21656],
        [21415],
        [22448],
        [21968],
        [20989],
        [21542],
        [21893],
        [22028],
        [22593],
        [20697],
        [21677],
        [23455],
        [23611],
        [23291],
        [22727],
        [23171],
        [23028]], device='cuda:0')
[2024-07-24 10:19:54,587][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14071],
        [14064],
        [13839],
        [13306],
        [13822],
        [13542],
        [13773],
        [14676],
        [13490],
        [16128],
        [13609],
        [13742],
        [19160],
        [14228],
        [18978],
        [14791],
        [14149],
        [13811],
        [13977]], device='cuda:0')
[2024-07-24 10:19:54,589][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28981],
        [19573],
        [19551],
        [20144],
        [21580],
        [29830],
        [25089],
        [23524],
        [22291],
        [22559],
        [23206],
        [23580],
        [27841],
        [26873],
        [27849],
        [31154],
        [27231],
        [32374],
        [27129]], device='cuda:0')
[2024-07-24 10:19:54,591][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22817],
        [23169],
        [16653],
        [23474],
        [16650],
        [17841],
        [12232],
        [12646],
        [12795],
        [13093],
        [15022],
        [15511],
        [15083],
        [ 9455],
        [ 9395],
        [10564],
        [13797],
        [12772],
        [12990]], device='cuda:0')
[2024-07-24 10:19:54,592][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25316],
        [16102],
        [ 8579],
        [ 5722],
        [ 6556],
        [ 5405],
        [ 5635],
        [ 5854],
        [ 4779],
        [ 5655],
        [ 5356],
        [ 5489],
        [ 4791],
        [ 4866],
        [ 4904],
        [ 4104],
        [ 5222],
        [ 5092],
        [ 5698]], device='cuda:0')
[2024-07-24 10:19:54,594][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[4314],
        [4444],
        [4521],
        [4432],
        [3703],
        [3806],
        [2890],
        [2382],
        [3106],
        [3500],
        [3238],
        [3330],
        [2593],
        [3949],
        [3563],
        [4248],
        [3694],
        [2718],
        [4267]], device='cuda:0')
[2024-07-24 10:19:54,595][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18952],
        [24274],
        [25281],
        [25320],
        [25874],
        [27078],
        [26126],
        [29326],
        [26948],
        [26486],
        [26264],
        [26442],
        [28150],
        [22624],
        [25847],
        [21579],
        [22570],
        [23381],
        [21377]], device='cuda:0')
[2024-07-24 10:19:54,596][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34436],
        [16430],
        [20067],
        [22089],
        [22928],
        [24348],
        [28372],
        [29175],
        [30533],
        [29308],
        [29387],
        [32064],
        [32444],
        [31748],
        [31963],
        [32521],
        [32639],
        [32192],
        [32926]], device='cuda:0')
[2024-07-24 10:19:54,597][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21765],
        [22032],
        [22124],
        [22104],
        [22050],
        [22045],
        [22022],
        [21994],
        [22004],
        [21989],
        [21985],
        [21983],
        [22007],
        [22016],
        [22018],
        [22026],
        [22035],
        [22041],
        [22043]], device='cuda:0')
[2024-07-24 10:19:54,598][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16823],
        [18637],
        [23192],
        [21100],
        [25408],
        [22226],
        [24518],
        [23510],
        [23318],
        [26322],
        [25893],
        [21434],
        [25565],
        [20855],
        [26925],
        [32206],
        [18579],
        [19064],
        [19789]], device='cuda:0')
[2024-07-24 10:19:54,600][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11754],
        [11754],
        [11754],
        [11754],
        [11765],
        [11755],
        [11761],
        [11830],
        [11756],
        [11791],
        [11760],
        [11757],
        [11762],
        [11756],
        [14200],
        [11758],
        [11757],
        [11774],
        [11755]], device='cuda:0')
[2024-07-24 10:19:54,602][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13874],
        [14703],
        [15605],
        [13977],
        [15055],
        [14467],
        [19603],
        [18876],
        [14054],
        [19158],
        [14673],
        [14137],
        [13990],
        [13682],
        [14556],
        [13818],
        [13476],
        [13663],
        [13616]], device='cuda:0')
[2024-07-24 10:19:54,603][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28130],
        [32600],
        [33534],
        [32780],
        [33076],
        [31704],
        [33580],
        [33170],
        [34227],
        [32110],
        [33003],
        [32753],
        [31072],
        [34600],
        [31469],
        [32598],
        [33325],
        [33369],
        [33236]], device='cuda:0')
[2024-07-24 10:19:54,605][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31872],
        [40345],
        [37959],
        [40614],
        [38383],
        [40054],
        [40409],
        [40055],
        [38074],
        [40719],
        [39762],
        [39057],
        [40336],
        [40581],
        [40338],
        [39685],
        [40347],
        [40427],
        [42053]], device='cuda:0')
[2024-07-24 10:19:54,606][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712],
        [12712]], device='cuda:0')
