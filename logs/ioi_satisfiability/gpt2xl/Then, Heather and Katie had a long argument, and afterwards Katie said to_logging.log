[2024-07-24 10:23:57,978][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Heather and Katie had a long argument, and afterwards Katie said to
[2024-07-24 10:23:57,979][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Heather
[2024-07-24 10:23:57,979][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:23:57,979][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:23:57,979][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:23:57,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,980][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:23:57,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit16']
[2024-07-24 10:23:57,981][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:23:57,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,981][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:23:57,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:57,982][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:23:57,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,982][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:23:57,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,983][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:23:57,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,983][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:23:57,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:57,984][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:23:57,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:57,984][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:23:57,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,984][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:23:57,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit12', 'circuit14', 'circuit26']
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,985][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit27']
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:23:57,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:57,987][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:23:57,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,988][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:23:57,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit24']
[2024-07-24 10:23:57,988][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:23:57,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,988][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:23:57,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:23:57,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6']
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5']
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:57,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,992][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:23:57,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:23:57,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit27']
[2024-07-24 10:23:57,995][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:23:57,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,996][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:23:57,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:57,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:57,996][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:23:57,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit20']
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit13']
[2024-07-24 10:23:57,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:23:57,999][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:23:57,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:57,999][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:57,999][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:23:57,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:57,999][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,000][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:23:58,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:23:58,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:23:58,001][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:23:58,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit9', 'circuit11', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,001][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:23:58,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,003][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:23:58,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,003][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,003][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:23:58,005][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:23:58,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,005][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:23:58,005][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17']
[2024-07-24 10:23:58,005][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:23:58,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,006][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit7']
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,008][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:23:58,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,008][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,008][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,008][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:23:58,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,009][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,011][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:23:58,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,011][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,011][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:23:58,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,012][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,013][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,014][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:23:58,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,014][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,014][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:23:58,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,015][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,016][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,017][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:23:58,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,017][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,017][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:23:58,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,018][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:23:58,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,019][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,019][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:23:58,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:23:58,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,021][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,021][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,021][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:23:58,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22']
[2024-07-24 10:23:58,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:23:58,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,024][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,024][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,024][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:23:58,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit25']
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,026][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:23:58,026][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,026][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,026][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,026][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:58,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit22']
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,028][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,029][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:23:58,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,029][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,031][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,031][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:23:58,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,032][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,034][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,034][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:23:58,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,035][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,037][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:23:58,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,038][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,040][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,040][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:23:58,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,041][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:23:58,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,042][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,042][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:23:58,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit20']
[2024-07-24 10:23:58,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit17', 'circuit18']
[2024-07-24 10:23:58,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:58,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,044][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,044][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:23:58,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit24']
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:23:58,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:23:58,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,046][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,046][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:23:58,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:23:58,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:23:58,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,048][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,048][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:23:58,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit12', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit21']
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit23']
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:23:58,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,050][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:23:58,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,052][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:23:58,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit13', 'circuit26']
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,054][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:23:58,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,056][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:23:58,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,059][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:23:58,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,060][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:23:58,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,061][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:23:58,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:23:58,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:23:58,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:23:58,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,066][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:23:58,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:23:58,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,069][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:23:58,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:23:58,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit24']
[2024-07-24 10:23:58,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:58,071][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:23:58,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:23:58,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17']
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:23:58,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,073][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:23:58,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit8', 'circuit9', 'circuit10']
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit4', 'circuit5', 'circuit12', 'circuit16', 'circuit17', 'circuit22']
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,076][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:23:58,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:23:58,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:23:58,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,079][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,080][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit27']
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,081][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:23:58,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,083][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:23:58,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:23:58,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,086][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:23:58,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:23:58,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,088][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:23:58,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:23:58,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19']
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,091][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:23:58,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,093][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:23:58,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:23:58,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:23:58,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:23:58,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:23:58,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,096][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,097][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:23:58,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,099][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:23:58,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,101][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:23:58,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:58,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:23:58,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit26']
[2024-07-24 10:23:58,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit20', 'circuit21']
[2024-07-24 10:23:58,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16', 'circuit23']
[2024-07-24 10:23:58,103][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit3', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,105][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:23:58,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10']
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit26']
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:23:58,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,108][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:23:58,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,109][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:23:58,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:58,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:23:58,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,112][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:23:58,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:23:58,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:23:58,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit13']
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,114][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit12', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:23:58,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,116][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:23:58,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,117][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:23:58,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit20', 'circuit27']
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:23:58,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:23:58,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit24']
[2024-07-24 10:23:58,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20']
[2024-07-24 10:23:58,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16']
[2024-07-24 10:23:58,122][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:23:58,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:23:58,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:23:58,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:23:58,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit19']
[2024-07-24 10:23:58,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,124][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:23:58,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit14', 'circuit21', 'circuit23']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,125][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,127][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:23:58,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,129][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:23:58,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:23:58,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit12', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,131][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:23:58,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,133][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,133][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:23:58,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,134][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:23:58,134][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:23:58,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit16', 'circuit25']
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19']
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:23:58,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,138][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,138][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:23:58,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,139][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:23:58,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit28']
[2024-07-24 10:23:58,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit25', 'circuit27']
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit18', 'circuit20']
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit26']
[2024-07-24 10:23:58,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:23:58,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit3', 'circuit6', 'circuit10']
[2024-07-24 10:23:58,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:23:58,142][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,142][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:23:58,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit8', 'circuit11']
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,143][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit11']
[2024-07-24 10:23:58,144][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:23:58,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit23']
[2024-07-24 10:23:58,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,145][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:23:58,145][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:23:58,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,146][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit15', 'circuit18', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,148][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,148][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:23:58,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit19']
[2024-07-24 10:23:58,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:23:58,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:23:58,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit26']
[2024-07-24 10:23:58,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,150][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15']
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,152][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,152][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:23:58,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20']
[2024-07-24 10:23:58,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit6', 'circuit7']
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:23:58,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,154][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,154][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,157][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,157][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,158][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,160][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,160][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:23:58,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,161][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:23:58,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,168][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:23:58,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,170][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:23:58,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,172][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,172][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,174][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:23:58,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,175][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:23:58,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,177][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,177][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:23:58,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:23:58,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,179][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,180][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,180][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:23:58,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:23:58,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit27']
[2024-07-24 10:23:58,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8', 'circuit13', 'circuit16', 'circuit22']
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:23:58,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17']
[2024-07-24 10:23:58,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,184][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,184][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21']
[2024-07-24 10:23:58,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,187][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,187][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,189][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,189][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:23:58,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,190][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit3', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:23:58,192][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:23:58,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit4', 'circuit6']
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,193][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:23:58,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit25']
[2024-07-24 10:23:58,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,199][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,201][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:23:58,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,202][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,204][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,204][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:23:58,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,207][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,207][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,207][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:23:58,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,208][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,209][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:23:58,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,211][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,212][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:23:58,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,214][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,215][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:23:58,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,216][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,216][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,216][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,216][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,216][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:23:58,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,218][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,218][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:23:58,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,219][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,219][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,219][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,219][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,219][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,219][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,221][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,221][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit3', 'circuit6', 'circuit13', 'circuit14']
[2024-07-24 10:23:58,221][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,221][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:23:58,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,222][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,224][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,224][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,224][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,224][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,224][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,224][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit6', 'circuit10']
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,227][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,227][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,227][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:23:58,227][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:23:58,227][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit7', 'circuit12']
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,228][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,229][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,229][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,229][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,229][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,229][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,229][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,230][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,231][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:23:58,231][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,231][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:23:58,231][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:23:58,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:23:58,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,232][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-24 10:23:58,233][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,233][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:23:58,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:23:58,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit25']
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,234][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit6']
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,235][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,236][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,236][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,236][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,236][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:23:58,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,237][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,239][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,239][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,239][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,239][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,239][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,239][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,240][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,241][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,241][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,241][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,241][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:23:58,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:23:58,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,242][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,244][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,244][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,244][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,244][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,244][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,245][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,246][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,246][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,246][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,246][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:23:58,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,247][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,249][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,249][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,249][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,249][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,249][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,250][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,252][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,252][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,252][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,254][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,254][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,254][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,254][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,254][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,255][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,257][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,257][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:23:58,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,260][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,262][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,262][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,264][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,264][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,264][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,264][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,266][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,266][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,266][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,266][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:23:58,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,267][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:23:58,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:23:58,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:23:58,269][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit4', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:23:58,269][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit10', 'circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:23:58,269][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,271][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:23:58,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:23:58,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:23:58,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,274][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,276][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,278][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,279][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,279][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:23:58,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,280][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,281][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:23:58,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:23:58,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,282][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,284][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,284][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,284][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,284][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:23:58,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,285][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,286][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,286][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,286][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:23:58,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:23:58,287][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit19', 'circuit20']
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,289][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,289][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,291][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:23:58,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,292][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit21']
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit25']
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:23:58,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,294][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,294][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,295][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,296][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,297][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,297][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,297][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:23:58,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,297][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,298][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,299][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,300][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,300][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,300][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,300][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,300][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,301][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,302][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,302][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,302][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,302][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,303][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,304][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,305][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,305][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,305][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,305][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,306][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,307][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,308][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,308][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:23:58,308][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,308][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,308][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,309][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,310][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:23:58,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,310][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,310][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,310][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,311][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:23:58,312][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,312][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,312][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,312][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,312][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,312][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:23:58,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:23:58,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:23:58,314][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:23:58,314][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:23:58,314][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:23:58,314][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:23:58,314][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,316][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,316][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,316][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,316][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,316][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,317][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,317][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,317][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,317][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:23:58,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,319][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,319][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,319][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:23:58,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,320][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,320][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,320][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,320][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,321][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:58,321][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:23:59,939][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:23:59,941][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,942][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,943][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,944][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,946][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,949][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,949][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,950][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,951][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,954][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,956][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,957][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:23:59,958][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,961][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,962][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,963][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,963][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,964][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,966][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,968][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,973][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,977][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,980][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,984][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:23:59,985][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.4789, 0.3610, 0.1601], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,985][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([6.1376e-04, 4.3381e-04, 9.9895e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,986][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.5312, 0.3824, 0.0864], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,987][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([2.6458e-02, 1.6669e-04, 9.7337e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,989][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.0397, 0.0032, 0.9571], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,991][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([1.2856e-02, 2.3965e-06, 9.8714e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,995][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.3575, 0.3537, 0.2889], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:23:59,998][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.5526, 0.3651, 0.0823], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,002][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.4951, 0.2864, 0.2186], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,006][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.5970, 0.3289, 0.0742], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,007][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.4449, 0.2478, 0.3073], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,008][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.4760, 0.3297, 0.1944], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,009][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6378, 0.0723, 0.2336, 0.0563], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,009][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3015e-03, 3.9229e-02, 9.4513e-04, 9.5752e-01], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,011][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2380, 0.1782, 0.0357, 0.5482], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,014][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1109, 0.3789, 0.0467, 0.4635], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,018][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3279, 0.1486, 0.2545, 0.2691], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,022][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1229, 0.1968, 0.0082, 0.6721], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,026][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5538, 0.0265, 0.3996, 0.0201], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,029][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1968, 0.1497, 0.4283, 0.2253], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,030][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0672, 0.4704, 0.0214, 0.4411], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,031][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4259, 0.2378, 0.1153, 0.2209], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,032][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4140, 0.3083, 0.0743, 0.2034], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,032][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4323, 0.1888, 0.1322, 0.2467], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,035][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.2438, 0.2026, 0.2682, 0.1554, 0.1300], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,036][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([4.6162e-04, 9.0491e-05, 6.0022e-03, 3.1943e-04, 9.9313e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,041][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.3783, 0.2279, 0.0824, 0.1223, 0.1890], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,043][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([2.2086e-02, 2.9335e-04, 7.0648e-02, 4.7682e-04, 9.0650e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,047][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0283, 0.0028, 0.0994, 0.0021, 0.8675], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,049][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([2.9553e-02, 3.0483e-06, 2.3940e-03, 1.0719e-06, 9.6805e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,052][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.1877, 0.2603, 0.1934, 0.1393, 0.2192], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,053][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.2461, 0.1269, 0.2428, 0.3096, 0.0745], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,054][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.3491, 0.1862, 0.1110, 0.1380, 0.2156], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,054][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.3856, 0.2239, 0.1754, 0.1881, 0.0270], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,055][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.2754, 0.2008, 0.1266, 0.1270, 0.2702], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,057][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.2177, 0.1751, 0.1678, 0.2151, 0.2245], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,061][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3942, 0.0347, 0.1727, 0.0345, 0.0603, 0.3037], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,063][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2219e-04, 1.6755e-03, 2.3832e-04, 2.8619e-03, 1.3353e-04, 9.9477e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,066][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4793, 0.1222, 0.0452, 0.1446, 0.0655, 0.1432], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,069][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9380e-03, 5.4272e-03, 7.0857e-04, 1.1484e-02, 1.9674e-03, 9.7547e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,073][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2125, 0.0604, 0.0762, 0.1094, 0.0902, 0.4513], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,075][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9822e-02, 1.8583e-03, 2.9351e-04, 1.2919e-03, 6.7230e-05, 9.5667e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,076][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2225, 0.0166, 0.3867, 0.0156, 0.3363, 0.0223], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,076][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1146, 0.0892, 0.0783, 0.2071, 0.2533, 0.2575], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,077][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0932, 0.2617, 0.0380, 0.3438, 0.0507, 0.2127], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,078][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3020, 0.1821, 0.1203, 0.1876, 0.0813, 0.1268], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,081][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2564, 0.1977, 0.0524, 0.1448, 0.0343, 0.3144], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,085][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4266, 0.1425, 0.0935, 0.1777, 0.0700, 0.0898], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,089][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4442, 0.0512, 0.1905, 0.0387, 0.1774, 0.0638, 0.0343],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,091][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5545e-04, 4.2991e-03, 1.7512e-03, 4.2971e-03, 3.8186e-04, 4.6821e-04,
        9.8795e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,095][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2987, 0.1853, 0.0595, 0.2185, 0.0681, 0.1237, 0.0462],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,097][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0294, 0.0180, 0.0076, 0.0331, 0.0148, 0.1792, 0.7180],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,098][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1409, 0.0310, 0.0638, 0.0436, 0.0672, 0.4404, 0.2131],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,099][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0561, 0.1300, 0.0030, 0.0973, 0.0007, 0.0449, 0.6681],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,100][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3096, 0.0103, 0.3196, 0.0088, 0.2962, 0.0455, 0.0101],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,102][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0940, 0.0565, 0.0627, 0.1263, 0.1568, 0.2119, 0.2917],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,105][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0240, 0.1305, 0.0081, 0.1938, 0.0125, 0.1416, 0.4895],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,109][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2550, 0.1633, 0.0965, 0.1657, 0.0862, 0.1028, 0.1307],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,113][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2263, 0.1930, 0.0634, 0.1636, 0.0437, 0.0838, 0.2262],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,116][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3267, 0.1310, 0.1090, 0.1407, 0.0999, 0.0844, 0.1083],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,120][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2325, 0.0556, 0.1465, 0.0516, 0.2772, 0.0958, 0.0730, 0.0677],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,121][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8477e-04, 9.8981e-04, 4.0383e-04, 1.4120e-03, 1.2780e-04, 3.2542e-03,
        9.3904e-04, 9.9259e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,122][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2958, 0.1525, 0.0838, 0.1542, 0.0907, 0.1076, 0.0770, 0.0383],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,122][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5168e-03, 4.5987e-04, 3.9472e-04, 8.0326e-04, 4.8606e-04, 9.1033e-03,
        7.2521e-03, 9.7498e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,123][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1027, 0.0234, 0.0303, 0.0307, 0.0232, 0.1533, 0.0812, 0.5552],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,124][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4048e-03, 1.8792e-04, 3.9559e-05, 1.0307e-04, 7.0287e-06, 1.9186e-04,
        8.2381e-05, 9.9398e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,127][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2675, 0.0288, 0.2762, 0.0200, 0.2651, 0.0443, 0.0207, 0.0774],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,128][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1098, 0.0477, 0.0172, 0.1001, 0.0331, 0.2012, 0.3715, 0.1193],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,128][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1070, 0.1071, 0.0568, 0.1361, 0.1539, 0.1318, 0.2677, 0.0396],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,132][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2421, 0.1583, 0.0799, 0.1532, 0.0729, 0.0935, 0.1343, 0.0659],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,136][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2265, 0.1605, 0.0392, 0.1124, 0.0346, 0.0779, 0.0881, 0.2607],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,140][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3810, 0.1025, 0.0801, 0.1276, 0.0702, 0.0632, 0.0646, 0.1108],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,143][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3294, 0.0788, 0.1584, 0.0621, 0.1298, 0.0672, 0.0529, 0.0671, 0.0542],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,145][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8585e-03, 3.0796e-04, 1.2984e-04, 2.0932e-04, 1.0669e-03, 3.4911e-04,
        1.9537e-04, 3.4369e-05, 9.9585e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,146][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2650, 0.0901, 0.1580, 0.0660, 0.0992, 0.0868, 0.1016, 0.0840, 0.0491],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,146][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3887e-03, 4.0926e-05, 1.3834e-04, 9.1364e-05, 1.8943e-04, 2.4719e-04,
        6.3023e-04, 4.3100e-03, 9.9096e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,147][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1297, 0.0059, 0.0124, 0.0050, 0.0302, 0.0157, 0.0133, 0.1739, 0.6139],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,148][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2029e-02, 1.5135e-05, 1.9156e-06, 4.1252e-06, 1.4933e-05, 2.0255e-06,
        1.5990e-06, 6.3681e-07, 9.8793e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,151][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.2065, 0.0537, 0.1775, 0.0469, 0.1507, 0.0354, 0.0380, 0.0852, 0.2061],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,156][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0889, 0.0510, 0.0173, 0.0949, 0.0548, 0.1308, 0.2087, 0.2513, 0.1022],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,159][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2461, 0.0951, 0.0553, 0.1113, 0.0696, 0.2321, 0.1188, 0.0641, 0.0074],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,163][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2183, 0.1271, 0.1048, 0.1191, 0.1048, 0.1035, 0.1065, 0.0768, 0.0390],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,167][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2164, 0.1348, 0.0399, 0.1139, 0.0473, 0.0777, 0.0751, 0.0394, 0.2555],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,168][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3051, 0.1353, 0.1166, 0.0979, 0.0787, 0.0387, 0.0374, 0.0826, 0.1076],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,169][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4265, 0.0146, 0.1190, 0.0170, 0.1255, 0.0755, 0.0327, 0.0606, 0.1161,
        0.0124], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,170][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8445e-03, 4.4357e-01, 1.4345e-04, 1.1171e-02, 4.8992e-05, 3.9672e-04,
        1.7962e-04, 5.1706e-05, 7.8250e-06, 5.4259e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,172][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1979, 0.3115, 0.0218, 0.0762, 0.0226, 0.0363, 0.0075, 0.0101, 0.0100,
        0.3063], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,174][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0332, 0.0077, 0.0014, 0.0078, 0.0023, 0.0607, 0.0499, 0.0552, 0.0866,
        0.6952], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,178][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2768, 0.0268, 0.0388, 0.0231, 0.0282, 0.1337, 0.0326, 0.1143, 0.0479,
        0.2777], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,182][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0973, 0.3437, 0.0145, 0.1240, 0.0051, 0.0690, 0.1020, 0.0301, 0.0101,
        0.2041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,186][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2589, 0.0076, 0.3059, 0.0074, 0.1982, 0.0242, 0.0095, 0.0625, 0.1207,
        0.0051], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,190][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0370, 0.0140, 0.0259, 0.0379, 0.0659, 0.0693, 0.1105, 0.1449, 0.1384,
        0.3562], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,191][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0192, 0.1650, 0.0052, 0.1853, 0.0062, 0.0643, 0.1662, 0.0292, 0.0076,
        0.3519], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,191][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2119, 0.1212, 0.0684, 0.1259, 0.0670, 0.0849, 0.0926, 0.0692, 0.0559,
        0.1031], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,192][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1723, 0.1586, 0.0676, 0.1457, 0.0599, 0.0943, 0.0913, 0.0585, 0.0418,
        0.1099], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,194][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2374, 0.0918, 0.1030, 0.1041, 0.0765, 0.0662, 0.0631, 0.0770, 0.0717,
        0.1091], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,197][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3243, 0.0264, 0.1335, 0.0227, 0.1347, 0.0637, 0.0385, 0.0847, 0.1177,
        0.0259, 0.0276], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,199][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0614e-03, 1.2475e-02, 2.2415e-04, 5.1181e-01, 4.6643e-05, 6.9037e-04,
        2.3418e-04, 1.8325e-04, 8.4962e-06, 7.4671e-03, 4.6580e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,203][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0821, 0.0613, 0.0186, 0.3073, 0.0338, 0.0428, 0.0172, 0.0146, 0.0229,
        0.0545, 0.3450], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,206][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0821e-02, 6.0644e-03, 3.1235e-04, 3.9880e-03, 4.6456e-04, 7.8464e-03,
        1.3924e-02, 1.5637e-02, 7.4089e-03, 4.9300e-01, 4.4053e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,210][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0351, 0.0129, 0.0101, 0.0244, 0.0253, 0.1602, 0.0650, 0.1186, 0.1759,
        0.1203, 0.2523], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,212][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0326, 0.0873, 0.0041, 0.3883, 0.0013, 0.0544, 0.1212, 0.0254, 0.0037,
        0.0307, 0.2509], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,213][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2151, 0.0087, 0.2711, 0.0083, 0.2221, 0.0273, 0.0100, 0.0760, 0.1456,
        0.0066, 0.0092], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,214][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0323, 0.0117, 0.0291, 0.0195, 0.0456, 0.0413, 0.0621, 0.0777, 0.0956,
        0.2392, 0.3459], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,215][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.1001, 0.0051, 0.1175, 0.0051, 0.0609, 0.1999, 0.0256, 0.0109,
        0.2626, 0.2009], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,217][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1728, 0.1078, 0.0611, 0.1087, 0.0668, 0.0753, 0.0865, 0.0581, 0.0568,
        0.0953, 0.1108], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,219][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1444, 0.1308, 0.0569, 0.1390, 0.0388, 0.0977, 0.0987, 0.0525, 0.0353,
        0.0948, 0.1111], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,223][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2134, 0.0870, 0.0788, 0.1002, 0.0633, 0.0521, 0.0462, 0.0598, 0.0763,
        0.1100, 0.1129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,227][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2107, 0.0383, 0.1770, 0.0425, 0.1107, 0.1118, 0.0436, 0.0306, 0.1345,
        0.0333, 0.0507, 0.0162], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,230][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7395e-03, 4.1720e-04, 6.8513e-04, 1.5585e-04, 2.3698e-03, 1.7361e-04,
        9.0117e-05, 1.4331e-04, 6.0550e-04, 9.2277e-05, 7.0709e-05, 9.9346e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,233][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2449, 0.0801, 0.1321, 0.0760, 0.0304, 0.1546, 0.0634, 0.0560, 0.0323,
        0.0508, 0.0611, 0.0184], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,235][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2694e-02, 5.1808e-05, 1.4871e-04, 7.2023e-05, 1.7288e-04, 1.1421e-03,
        2.1226e-04, 3.4369e-03, 1.4252e-03, 2.2500e-03, 4.8170e-03, 9.7358e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,236][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0421, 0.0034, 0.0049, 0.0070, 0.0030, 0.0114, 0.0109, 0.0295, 0.0154,
        0.0128, 0.0439, 0.8159], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,236][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2371e-02, 4.3702e-06, 1.0809e-03, 1.6918e-06, 3.5137e-05, 4.4267e-06,
        4.7508e-07, 4.6443e-06, 5.0004e-06, 9.8347e-08, 2.7218e-07, 9.0649e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,237][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1433, 0.0600, 0.1595, 0.0446, 0.1084, 0.0374, 0.0636, 0.0558, 0.1288,
        0.0530, 0.0491, 0.0964], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,238][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0519, 0.0186, 0.0115, 0.0288, 0.0299, 0.0330, 0.0701, 0.0482, 0.0272,
        0.1892, 0.3853, 0.1063], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,240][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0981, 0.1108, 0.0249, 0.1403, 0.0143, 0.0397, 0.1226, 0.0368, 0.1005,
        0.1307, 0.1684, 0.0129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,243][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1769, 0.1000, 0.0703, 0.0919, 0.0559, 0.0761, 0.0670, 0.0574, 0.0868,
        0.0848, 0.0922, 0.0406], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,247][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1904, 0.0925, 0.0482, 0.0886, 0.0480, 0.0829, 0.0550, 0.0515, 0.0385,
        0.0660, 0.0685, 0.1698], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,251][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1763, 0.1397, 0.0788, 0.0926, 0.0544, 0.0318, 0.0407, 0.0410, 0.0375,
        0.1597, 0.0994, 0.0480], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,255][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1531, 0.0974, 0.1714, 0.0793, 0.0829, 0.0171, 0.0351, 0.0227, 0.0479,
        0.0790, 0.0899, 0.0302, 0.0939], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,258][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([2.4364e-04, 2.2487e-05, 2.2937e-03, 1.0158e-04, 5.3429e-01, 1.2920e-05,
        3.0378e-05, 1.9600e-05, 4.4008e-05, 3.1872e-06, 4.5896e-05, 4.7077e-04,
        4.6242e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,259][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.1616, 0.0856, 0.0460, 0.0587, 0.1036, 0.0605, 0.0794, 0.0305, 0.1371,
        0.0450, 0.0472, 0.0503, 0.0946], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,259][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([3.0380e-03, 4.5639e-06, 9.4404e-04, 3.1493e-06, 8.5699e-03, 1.4473e-05,
        1.9802e-05, 5.6340e-05, 1.6795e-03, 1.4287e-04, 1.7797e-04, 1.5888e-03,
        9.8376e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,260][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([5.0581e-03, 2.9875e-04, 7.7639e-03, 1.8167e-04, 7.1092e-02, 4.0347e-04,
        3.1076e-04, 2.8052e-03, 8.3332e-04, 1.1944e-03, 1.3278e-03, 1.1176e-03,
        9.0761e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,262][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([6.3308e-03, 4.9977e-07, 8.7999e-04, 1.9060e-07, 5.9621e-01, 2.3006e-07,
        1.9530e-08, 3.3108e-07, 8.4497e-07, 1.0833e-08, 3.2441e-08, 7.5814e-07,
        3.9658e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,264][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0932, 0.1200, 0.1294, 0.0729, 0.1555, 0.0182, 0.0410, 0.0196, 0.0324,
        0.0829, 0.0633, 0.0155, 0.1561], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,269][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0768, 0.0143, 0.0245, 0.0289, 0.0072, 0.0325, 0.0524, 0.0428, 0.0312,
        0.1530, 0.2873, 0.1672, 0.0819], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,273][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.1718, 0.0818, 0.0635, 0.0702, 0.1291, 0.0252, 0.0509, 0.0460, 0.0833,
        0.0567, 0.0632, 0.0212, 0.1372], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,276][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.1948, 0.1158, 0.1083, 0.1026, 0.0162, 0.0562, 0.0700, 0.0451, 0.0415,
        0.0927, 0.0987, 0.0421, 0.0161], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,280][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0918, 0.0695, 0.0763, 0.0631, 0.2459, 0.0358, 0.0470, 0.0226, 0.0220,
        0.0488, 0.0470, 0.0187, 0.2116], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,281][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0768, 0.0608, 0.0691, 0.0648, 0.0867, 0.0570, 0.0564, 0.0544, 0.1099,
        0.0570, 0.0757, 0.1199, 0.1113], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,282][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3309, 0.0287, 0.1469, 0.0166, 0.0408, 0.0603, 0.0176, 0.0438, 0.0422,
        0.0282, 0.0176, 0.0959, 0.0569, 0.0736], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,283][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4474e-03, 3.5578e-03, 1.4575e-04, 1.2031e-03, 4.6624e-05, 8.5060e-03,
        1.4072e-03, 4.5866e-05, 1.5949e-03, 1.5536e-03, 7.2353e-04, 1.1259e-04,
        2.7953e-05, 9.7963e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,285][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2319, 0.0518, 0.0248, 0.0447, 0.0145, 0.1067, 0.0352, 0.0258, 0.0507,
        0.0428, 0.0417, 0.0419, 0.0141, 0.2733], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,287][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([2.0062e-03, 7.4202e-05, 1.5350e-05, 5.5237e-05, 7.2963e-06, 3.1095e-04,
        4.3201e-04, 4.9108e-04, 1.2659e-03, 2.5635e-03, 3.5835e-03, 1.3298e-03,
        6.4721e-04, 9.8722e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,291][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0848, 0.0130, 0.0032, 0.0185, 0.0061, 0.0264, 0.0214, 0.0249, 0.0422,
        0.0556, 0.1183, 0.0239, 0.0473, 0.5145], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,293][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2080e-02, 2.4351e-03, 4.0701e-05, 8.9087e-04, 3.9519e-05, 8.7005e-03,
        2.0769e-04, 2.9487e-05, 6.7271e-04, 2.4892e-04, 2.8131e-04, 6.2036e-06,
        1.3130e-05, 9.7435e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,296][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1634, 0.0080, 0.2529, 0.0081, 0.1309, 0.0107, 0.0065, 0.0292, 0.0771,
        0.0060, 0.0080, 0.1120, 0.1713, 0.0158], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,301][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0326, 0.0062, 0.0047, 0.0104, 0.0109, 0.0140, 0.0296, 0.0128, 0.0203,
        0.1077, 0.1683, 0.1734, 0.2387, 0.1703], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,303][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0522, 0.1081, 0.0172, 0.1061, 0.0137, 0.1033, 0.1398, 0.0318, 0.0282,
        0.1789, 0.1400, 0.0253, 0.0175, 0.0379], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,304][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1479, 0.0795, 0.0496, 0.0817, 0.0499, 0.0654, 0.0622, 0.0462, 0.0543,
        0.0740, 0.0846, 0.0549, 0.0554, 0.0946], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,305][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1065, 0.0768, 0.0239, 0.0809, 0.0245, 0.0834, 0.0625, 0.0262, 0.0501,
        0.0649, 0.0699, 0.0298, 0.0203, 0.2802], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,305][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2450, 0.0583, 0.0653, 0.0779, 0.0489, 0.0372, 0.0312, 0.0562, 0.0668,
        0.0618, 0.0791, 0.0820, 0.0510, 0.0392], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,307][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2593, 0.0251, 0.0945, 0.0210, 0.0585, 0.0677, 0.0226, 0.0365, 0.0722,
        0.0251, 0.0257, 0.0836, 0.0839, 0.1077, 0.0166], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,309][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1201e-03, 1.1776e-02, 5.3181e-04, 3.4307e-02, 5.1488e-05, 3.0525e-04,
        1.4488e-03, 1.7842e-04, 5.7916e-05, 8.2822e-03, 3.0198e-02, 2.4498e-04,
        3.2875e-05, 1.4511e-04, 9.0832e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,314][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1592, 0.0700, 0.0254, 0.0961, 0.0288, 0.0584, 0.0251, 0.0376, 0.0306,
        0.0598, 0.0946, 0.0389, 0.0293, 0.0743, 0.1720], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,316][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9454e-03, 2.6589e-04, 2.6305e-05, 1.8221e-04, 3.5730e-05, 7.2931e-04,
        1.2062e-03, 2.4257e-04, 1.1483e-03, 7.2018e-03, 1.1942e-02, 1.6578e-02,
        3.4992e-03, 2.9345e-01, 6.6054e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,319][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0361, 0.0023, 0.0015, 0.0038, 0.0010, 0.0341, 0.0104, 0.0264, 0.0576,
        0.0124, 0.0318, 0.0737, 0.0103, 0.4188, 0.2796], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,321][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.3436e-02, 6.1361e-02, 1.6965e-03, 7.8563e-02, 2.6950e-04, 3.1291e-02,
        2.2710e-01, 3.4449e-02, 4.7743e-03, 2.1250e-02, 4.1385e-02, 7.4712e-04,
        1.1129e-04, 3.2716e-02, 4.2085e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,325][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1188, 0.0057, 0.1150, 0.0049, 0.0697, 0.0166, 0.0047, 0.0308, 0.0530,
        0.0042, 0.0062, 0.1081, 0.1150, 0.0319, 0.3153], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,326][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0220, 0.0041, 0.0047, 0.0068, 0.0071, 0.0089, 0.0119, 0.0183, 0.0267,
        0.0489, 0.0793, 0.0929, 0.1393, 0.2570, 0.2720], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,327][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0080, 0.0594, 0.0032, 0.1035, 0.0049, 0.0466, 0.1310, 0.0197, 0.0089,
        0.1507, 0.1813, 0.0048, 0.0075, 0.0338, 0.2367], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,328][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1182, 0.0733, 0.0462, 0.0806, 0.0430, 0.0538, 0.0686, 0.0471, 0.0423,
        0.0692, 0.0846, 0.0454, 0.0482, 0.0821, 0.0975], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,330][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1023, 0.0841, 0.0375, 0.1007, 0.0297, 0.0746, 0.0858, 0.0504, 0.0334,
        0.0763, 0.0930, 0.0276, 0.0264, 0.0644, 0.1138], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,333][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1770, 0.0700, 0.0599, 0.0718, 0.0483, 0.0498, 0.0453, 0.0531, 0.0533,
        0.0719, 0.0683, 0.0735, 0.0490, 0.0365, 0.0722], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,345][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:00,346][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,346][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,347][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,348][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,349][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,349][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,350][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,351][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,351][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,352][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,353][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,353][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,354][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,355][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,355][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,358][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,363][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,369][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,369][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,370][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,371][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,375][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,380][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,385][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,389][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.4789, 0.3610, 0.1601], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,389][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([6.1376e-04, 4.3381e-04, 9.9895e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,390][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.5312, 0.3824, 0.0864], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,391][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([2.6458e-02, 1.6669e-04, 9.7337e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,391][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.0397, 0.0032, 0.9571], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,393][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([1.2856e-02, 2.3965e-06, 9.8714e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,397][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.3575, 0.3537, 0.2889], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,403][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.5526, 0.3651, 0.0823], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,408][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.4951, 0.2864, 0.2186], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,410][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.5970, 0.3289, 0.0742], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,410][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.4449, 0.2478, 0.3073], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,411][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.4760, 0.3297, 0.1944], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,412][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6378, 0.0723, 0.2336, 0.0563], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,413][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3015e-03, 3.9229e-02, 9.4513e-04, 9.5752e-01], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,419][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2380, 0.1782, 0.0357, 0.5482], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,424][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1109, 0.3789, 0.0467, 0.4635], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,430][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3279, 0.1486, 0.2545, 0.2691], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,430][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1229, 0.1968, 0.0082, 0.6721], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,431][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5538, 0.0265, 0.3996, 0.0201], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,432][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1968, 0.1497, 0.4283, 0.2253], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,433][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0672, 0.4704, 0.0214, 0.4411], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,435][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4259, 0.2378, 0.1153, 0.2209], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,440][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4140, 0.3083, 0.0743, 0.2034], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,447][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4323, 0.1888, 0.1322, 0.2467], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,451][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2438, 0.2026, 0.2682, 0.1554, 0.1300], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,451][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([4.6162e-04, 9.0491e-05, 6.0022e-03, 3.1943e-04, 9.9313e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,452][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.3783, 0.2279, 0.0824, 0.1223, 0.1890], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,453][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([2.2086e-02, 2.9335e-04, 7.0648e-02, 4.7682e-04, 9.0650e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,454][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0283, 0.0028, 0.0994, 0.0021, 0.8675], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,455][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([2.9553e-02, 3.0483e-06, 2.3940e-03, 1.0719e-06, 9.6805e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,461][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.1877, 0.2603, 0.1934, 0.1393, 0.2192], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,467][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2461, 0.1269, 0.2428, 0.3096, 0.0745], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,471][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.3491, 0.1862, 0.1110, 0.1380, 0.2156], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,472][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.3856, 0.2239, 0.1754, 0.1881, 0.0270], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,473][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.2754, 0.2008, 0.1266, 0.1270, 0.2702], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,474][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.2177, 0.1751, 0.1678, 0.2151, 0.2245], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:00,474][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3942, 0.0347, 0.1727, 0.0345, 0.0603, 0.3037], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,476][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2219e-04, 1.6755e-03, 2.3832e-04, 2.8619e-03, 1.3353e-04, 9.9477e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,481][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4793, 0.1222, 0.0452, 0.1446, 0.0655, 0.1432], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,484][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9380e-03, 5.4272e-03, 7.0857e-04, 1.1484e-02, 1.9674e-03, 9.7547e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,490][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2125, 0.0604, 0.0762, 0.1094, 0.0902, 0.4513], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,494][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9822e-02, 1.8583e-03, 2.9351e-04, 1.2919e-03, 6.7230e-05, 9.5667e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,495][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2225, 0.0166, 0.3867, 0.0156, 0.3363, 0.0223], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,495][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1146, 0.0892, 0.0783, 0.2071, 0.2533, 0.2575], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,496][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0932, 0.2617, 0.0380, 0.3438, 0.0507, 0.2127], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,498][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3020, 0.1821, 0.1203, 0.1876, 0.0813, 0.1268], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,503][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2564, 0.1977, 0.0524, 0.1448, 0.0343, 0.3144], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,508][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4266, 0.1425, 0.0935, 0.1777, 0.0700, 0.0898], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:00,513][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4442, 0.0512, 0.1905, 0.0387, 0.1774, 0.0638, 0.0343],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,515][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5545e-04, 4.2991e-03, 1.7512e-03, 4.2971e-03, 3.8186e-04, 4.6821e-04,
        9.8795e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,516][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2987, 0.1853, 0.0595, 0.2185, 0.0681, 0.1237, 0.0462],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,516][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0294, 0.0180, 0.0076, 0.0331, 0.0148, 0.1792, 0.7180],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,517][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1409, 0.0310, 0.0638, 0.0436, 0.0672, 0.4404, 0.2131],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,522][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0561, 0.1300, 0.0030, 0.0973, 0.0007, 0.0449, 0.6681],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,527][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3096, 0.0103, 0.3196, 0.0088, 0.2962, 0.0455, 0.0101],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,533][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0940, 0.0565, 0.0627, 0.1263, 0.1568, 0.2119, 0.2917],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,535][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0240, 0.1305, 0.0081, 0.1938, 0.0125, 0.1416, 0.4895],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,536][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2550, 0.1633, 0.0965, 0.1657, 0.0862, 0.1028, 0.1307],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,536][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2263, 0.1930, 0.0634, 0.1636, 0.0437, 0.0838, 0.2262],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,537][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3267, 0.1310, 0.1090, 0.1407, 0.0999, 0.0844, 0.1083],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:00,539][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2325, 0.0556, 0.1465, 0.0516, 0.2772, 0.0958, 0.0730, 0.0677],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,543][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8477e-04, 9.8981e-04, 4.0383e-04, 1.4120e-03, 1.2780e-04, 3.2542e-03,
        9.3904e-04, 9.9259e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,548][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2958, 0.1525, 0.0838, 0.1542, 0.0907, 0.1076, 0.0770, 0.0383],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,551][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5168e-03, 4.5987e-04, 3.9472e-04, 8.0326e-04, 4.8606e-04, 9.1033e-03,
        7.2521e-03, 9.7498e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,555][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1027, 0.0234, 0.0303, 0.0307, 0.0232, 0.1533, 0.0812, 0.5552],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,556][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4048e-03, 1.8792e-04, 3.9559e-05, 1.0307e-04, 7.0287e-06, 1.9186e-04,
        8.2381e-05, 9.9398e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,557][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2675, 0.0288, 0.2762, 0.0200, 0.2651, 0.0443, 0.0207, 0.0774],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,558][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1098, 0.0477, 0.0172, 0.1001, 0.0331, 0.2012, 0.3715, 0.1193],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,560][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1070, 0.1071, 0.0568, 0.1361, 0.1539, 0.1318, 0.2677, 0.0396],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,565][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2421, 0.1583, 0.0799, 0.1532, 0.0729, 0.0935, 0.1343, 0.0659],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,570][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2265, 0.1605, 0.0392, 0.1124, 0.0346, 0.0779, 0.0881, 0.2607],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,576][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3810, 0.1025, 0.0801, 0.1276, 0.0702, 0.0632, 0.0646, 0.1108],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:00,577][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3294, 0.0788, 0.1584, 0.0621, 0.1298, 0.0672, 0.0529, 0.0671, 0.0542],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,578][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8585e-03, 3.0796e-04, 1.2984e-04, 2.0932e-04, 1.0669e-03, 3.4911e-04,
        1.9537e-04, 3.4369e-05, 9.9585e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,578][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2650, 0.0901, 0.1580, 0.0660, 0.0992, 0.0868, 0.1016, 0.0840, 0.0491],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,580][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3887e-03, 4.0926e-05, 1.3834e-04, 9.1364e-05, 1.8943e-04, 2.4719e-04,
        6.3023e-04, 4.3100e-03, 9.9096e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,584][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1297, 0.0059, 0.0124, 0.0050, 0.0302, 0.0157, 0.0133, 0.1739, 0.6139],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,588][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2029e-02, 1.5135e-05, 1.9156e-06, 4.1252e-06, 1.4933e-05, 2.0255e-06,
        1.5990e-06, 6.3681e-07, 9.8793e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,594][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.2065, 0.0537, 0.1775, 0.0469, 0.1507, 0.0354, 0.0380, 0.0852, 0.2061],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,596][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0889, 0.0510, 0.0173, 0.0949, 0.0548, 0.1308, 0.2087, 0.2513, 0.1022],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,597][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2461, 0.0951, 0.0553, 0.1113, 0.0696, 0.2321, 0.1188, 0.0641, 0.0074],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,598][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2183, 0.1271, 0.1048, 0.1191, 0.1048, 0.1035, 0.1065, 0.0768, 0.0390],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,599][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2164, 0.1348, 0.0399, 0.1139, 0.0473, 0.0777, 0.0751, 0.0394, 0.2555],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,602][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3051, 0.1353, 0.1166, 0.0979, 0.0787, 0.0387, 0.0374, 0.0826, 0.1076],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:00,608][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4265, 0.0146, 0.1190, 0.0170, 0.1255, 0.0755, 0.0327, 0.0606, 0.1161,
        0.0124], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,611][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8445e-03, 4.4357e-01, 1.4345e-04, 1.1171e-02, 4.8992e-05, 3.9672e-04,
        1.7962e-04, 5.1706e-05, 7.8250e-06, 5.4259e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,616][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1979, 0.3115, 0.0218, 0.0762, 0.0226, 0.0363, 0.0075, 0.0101, 0.0100,
        0.3063], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,617][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0332, 0.0077, 0.0014, 0.0078, 0.0023, 0.0607, 0.0499, 0.0552, 0.0866,
        0.6952], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,618][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2768, 0.0268, 0.0388, 0.0231, 0.0282, 0.1337, 0.0326, 0.1143, 0.0479,
        0.2777], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,619][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0973, 0.3437, 0.0145, 0.1240, 0.0051, 0.0690, 0.1020, 0.0301, 0.0101,
        0.2041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,624][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2589, 0.0076, 0.3059, 0.0074, 0.1982, 0.0242, 0.0095, 0.0625, 0.1207,
        0.0051], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,628][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0370, 0.0140, 0.0259, 0.0379, 0.0659, 0.0693, 0.1105, 0.1449, 0.1384,
        0.3562], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,634][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0192, 0.1650, 0.0052, 0.1853, 0.0062, 0.0643, 0.1662, 0.0292, 0.0076,
        0.3519], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,636][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2119, 0.1212, 0.0684, 0.1259, 0.0670, 0.0849, 0.0926, 0.0692, 0.0559,
        0.1031], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,637][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1723, 0.1586, 0.0676, 0.1457, 0.0599, 0.0943, 0.0913, 0.0585, 0.0418,
        0.1099], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,638][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2374, 0.0918, 0.1030, 0.1041, 0.0765, 0.0662, 0.0631, 0.0770, 0.0717,
        0.1091], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:00,639][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3243, 0.0264, 0.1335, 0.0227, 0.1347, 0.0637, 0.0385, 0.0847, 0.1177,
        0.0259, 0.0276], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,640][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0614e-03, 1.2475e-02, 2.2415e-04, 5.1181e-01, 4.6643e-05, 6.9037e-04,
        2.3418e-04, 1.8325e-04, 8.4962e-06, 7.4671e-03, 4.6580e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,645][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0821, 0.0613, 0.0186, 0.3073, 0.0338, 0.0428, 0.0172, 0.0146, 0.0229,
        0.0545, 0.3450], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,648][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0821e-02, 6.0644e-03, 3.1235e-04, 3.9880e-03, 4.6456e-04, 7.8464e-03,
        1.3924e-02, 1.5637e-02, 7.4089e-03, 4.9300e-01, 4.4053e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,654][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0351, 0.0129, 0.0101, 0.0244, 0.0253, 0.1602, 0.0650, 0.1186, 0.1759,
        0.1203, 0.2523], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,656][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0326, 0.0873, 0.0041, 0.3883, 0.0013, 0.0544, 0.1212, 0.0254, 0.0037,
        0.0307, 0.2509], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,657][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2151, 0.0087, 0.2711, 0.0083, 0.2221, 0.0273, 0.0100, 0.0760, 0.1456,
        0.0066, 0.0092], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,658][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0323, 0.0117, 0.0291, 0.0195, 0.0456, 0.0413, 0.0621, 0.0777, 0.0956,
        0.2392, 0.3459], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,662][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.1001, 0.0051, 0.1175, 0.0051, 0.0609, 0.1999, 0.0256, 0.0109,
        0.2626, 0.2009], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,667][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1728, 0.1078, 0.0611, 0.1087, 0.0668, 0.0753, 0.0865, 0.0581, 0.0568,
        0.0953, 0.1108], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,673][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1444, 0.1308, 0.0569, 0.1390, 0.0388, 0.0977, 0.0987, 0.0525, 0.0353,
        0.0948, 0.1111], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,676][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2134, 0.0870, 0.0788, 0.1002, 0.0633, 0.0521, 0.0462, 0.0598, 0.0763,
        0.1100, 0.1129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:00,676][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2107, 0.0383, 0.1770, 0.0425, 0.1107, 0.1118, 0.0436, 0.0306, 0.1345,
        0.0333, 0.0507, 0.0162], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,677][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7395e-03, 4.1720e-04, 6.8513e-04, 1.5585e-04, 2.3698e-03, 1.7361e-04,
        9.0117e-05, 1.4331e-04, 6.0550e-04, 9.2277e-05, 7.0709e-05, 9.9346e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,681][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2449, 0.0801, 0.1321, 0.0760, 0.0304, 0.1546, 0.0634, 0.0560, 0.0323,
        0.0508, 0.0611, 0.0184], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,685][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2694e-02, 5.1808e-05, 1.4871e-04, 7.2023e-05, 1.7288e-04, 1.1421e-03,
        2.1226e-04, 3.4369e-03, 1.4252e-03, 2.2500e-03, 4.8170e-03, 9.7358e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,691][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0421, 0.0034, 0.0049, 0.0070, 0.0030, 0.0114, 0.0109, 0.0295, 0.0154,
        0.0128, 0.0439, 0.8159], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,695][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2371e-02, 4.3702e-06, 1.0809e-03, 1.6918e-06, 3.5137e-05, 4.4267e-06,
        4.7508e-07, 4.6443e-06, 5.0004e-06, 9.8347e-08, 2.7218e-07, 9.0649e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,695][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1433, 0.0600, 0.1595, 0.0446, 0.1084, 0.0374, 0.0636, 0.0558, 0.1288,
        0.0530, 0.0491, 0.0964], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,696][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0519, 0.0186, 0.0115, 0.0288, 0.0299, 0.0330, 0.0701, 0.0482, 0.0272,
        0.1892, 0.3853, 0.1063], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,700][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0981, 0.1108, 0.0249, 0.1403, 0.0143, 0.0397, 0.1226, 0.0368, 0.1005,
        0.1307, 0.1684, 0.0129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,706][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1769, 0.1000, 0.0703, 0.0919, 0.0559, 0.0761, 0.0670, 0.0574, 0.0868,
        0.0848, 0.0922, 0.0406], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,712][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1904, 0.0925, 0.0482, 0.0886, 0.0480, 0.0829, 0.0550, 0.0515, 0.0385,
        0.0660, 0.0685, 0.1698], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,714][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1763, 0.1397, 0.0788, 0.0926, 0.0544, 0.0318, 0.0407, 0.0410, 0.0375,
        0.1597, 0.0994, 0.0480], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:00,715][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.1531, 0.0974, 0.1714, 0.0793, 0.0829, 0.0171, 0.0351, 0.0227, 0.0479,
        0.0790, 0.0899, 0.0302, 0.0939], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,716][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([2.4364e-04, 2.2487e-05, 2.2937e-03, 1.0158e-04, 5.3429e-01, 1.2920e-05,
        3.0378e-05, 1.9600e-05, 4.4008e-05, 3.1872e-06, 4.5896e-05, 4.7077e-04,
        4.6242e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,717][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1616, 0.0856, 0.0460, 0.0587, 0.1036, 0.0605, 0.0794, 0.0305, 0.1371,
        0.0450, 0.0472, 0.0503, 0.0946], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,718][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([3.0380e-03, 4.5639e-06, 9.4404e-04, 3.1493e-06, 8.5699e-03, 1.4473e-05,
        1.9802e-05, 5.6340e-05, 1.6795e-03, 1.4287e-04, 1.7797e-04, 1.5888e-03,
        9.8376e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,722][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([5.0581e-03, 2.9875e-04, 7.7639e-03, 1.8167e-04, 7.1092e-02, 4.0347e-04,
        3.1076e-04, 2.8052e-03, 8.3332e-04, 1.1944e-03, 1.3278e-03, 1.1176e-03,
        9.0761e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,726][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([6.3308e-03, 4.9977e-07, 8.7999e-04, 1.9060e-07, 5.9621e-01, 2.3006e-07,
        1.9530e-08, 3.3108e-07, 8.4497e-07, 1.0833e-08, 3.2441e-08, 7.5814e-07,
        3.9658e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,732][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0932, 0.1200, 0.1294, 0.0729, 0.1555, 0.0182, 0.0410, 0.0196, 0.0324,
        0.0829, 0.0633, 0.0155, 0.1561], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,734][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0768, 0.0143, 0.0245, 0.0289, 0.0072, 0.0325, 0.0524, 0.0428, 0.0312,
        0.1530, 0.2873, 0.1672, 0.0819], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,735][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1718, 0.0818, 0.0635, 0.0702, 0.1291, 0.0252, 0.0509, 0.0460, 0.0833,
        0.0567, 0.0632, 0.0212, 0.1372], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,736][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.1948, 0.1158, 0.1083, 0.1026, 0.0162, 0.0562, 0.0700, 0.0451, 0.0415,
        0.0927, 0.0987, 0.0421, 0.0161], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,739][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0918, 0.0695, 0.0763, 0.0631, 0.2459, 0.0358, 0.0470, 0.0226, 0.0220,
        0.0488, 0.0470, 0.0187, 0.2116], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,745][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0768, 0.0608, 0.0691, 0.0648, 0.0867, 0.0570, 0.0564, 0.0544, 0.1099,
        0.0570, 0.0757, 0.1199, 0.1113], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:00,751][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3309, 0.0287, 0.1469, 0.0166, 0.0408, 0.0603, 0.0176, 0.0438, 0.0422,
        0.0282, 0.0176, 0.0959, 0.0569, 0.0736], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,753][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4474e-03, 3.5578e-03, 1.4575e-04, 1.2031e-03, 4.6624e-05, 8.5060e-03,
        1.4072e-03, 4.5866e-05, 1.5949e-03, 1.5536e-03, 7.2353e-04, 1.1259e-04,
        2.7953e-05, 9.7963e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,754][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2319, 0.0518, 0.0248, 0.0447, 0.0145, 0.1067, 0.0352, 0.0258, 0.0507,
        0.0428, 0.0417, 0.0419, 0.0141, 0.2733], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,755][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.0062e-03, 7.4202e-05, 1.5350e-05, 5.5237e-05, 7.2963e-06, 3.1095e-04,
        4.3201e-04, 4.9108e-04, 1.2659e-03, 2.5635e-03, 3.5835e-03, 1.3298e-03,
        6.4721e-04, 9.8722e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,756][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0848, 0.0130, 0.0032, 0.0185, 0.0061, 0.0264, 0.0214, 0.0249, 0.0422,
        0.0556, 0.1183, 0.0239, 0.0473, 0.5145], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,757][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2080e-02, 2.4351e-03, 4.0701e-05, 8.9087e-04, 3.9519e-05, 8.7005e-03,
        2.0769e-04, 2.9487e-05, 6.7271e-04, 2.4892e-04, 2.8131e-04, 6.2036e-06,
        1.3130e-05, 9.7435e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,763][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1634, 0.0080, 0.2529, 0.0081, 0.1309, 0.0107, 0.0065, 0.0292, 0.0771,
        0.0060, 0.0080, 0.1120, 0.1713, 0.0158], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,769][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0326, 0.0062, 0.0047, 0.0104, 0.0109, 0.0140, 0.0296, 0.0128, 0.0203,
        0.1077, 0.1683, 0.1734, 0.2387, 0.1703], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,773][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0522, 0.1081, 0.0172, 0.1061, 0.0137, 0.1033, 0.1398, 0.0318, 0.0282,
        0.1789, 0.1400, 0.0253, 0.0175, 0.0379], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,774][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1479, 0.0795, 0.0496, 0.0817, 0.0499, 0.0654, 0.0622, 0.0462, 0.0543,
        0.0740, 0.0846, 0.0549, 0.0554, 0.0946], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,775][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1065, 0.0768, 0.0239, 0.0809, 0.0245, 0.0834, 0.0625, 0.0262, 0.0501,
        0.0649, 0.0699, 0.0298, 0.0203, 0.2802], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,778][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2450, 0.0583, 0.0653, 0.0779, 0.0489, 0.0372, 0.0312, 0.0562, 0.0668,
        0.0618, 0.0791, 0.0820, 0.0510, 0.0392], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:00,784][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2593, 0.0251, 0.0945, 0.0210, 0.0585, 0.0677, 0.0226, 0.0365, 0.0722,
        0.0251, 0.0257, 0.0836, 0.0839, 0.1077, 0.0166], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,788][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1201e-03, 1.1776e-02, 5.3181e-04, 3.4307e-02, 5.1488e-05, 3.0525e-04,
        1.4488e-03, 1.7842e-04, 5.7916e-05, 8.2822e-03, 3.0198e-02, 2.4498e-04,
        3.2875e-05, 1.4511e-04, 9.0832e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,792][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1592, 0.0700, 0.0254, 0.0961, 0.0288, 0.0584, 0.0251, 0.0376, 0.0306,
        0.0598, 0.0946, 0.0389, 0.0293, 0.0743, 0.1720], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,793][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9454e-03, 2.6589e-04, 2.6305e-05, 1.8221e-04, 3.5730e-05, 7.2931e-04,
        1.2062e-03, 2.4257e-04, 1.1483e-03, 7.2018e-03, 1.1942e-02, 1.6578e-02,
        3.4992e-03, 2.9345e-01, 6.6054e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,794][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0361, 0.0023, 0.0015, 0.0038, 0.0010, 0.0341, 0.0104, 0.0264, 0.0576,
        0.0124, 0.0318, 0.0737, 0.0103, 0.4188, 0.2796], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,795][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.3436e-02, 6.1361e-02, 1.6965e-03, 7.8563e-02, 2.6950e-04, 3.1291e-02,
        2.2710e-01, 3.4449e-02, 4.7743e-03, 2.1250e-02, 4.1385e-02, 7.4712e-04,
        1.1129e-04, 3.2716e-02, 4.2085e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,798][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1188, 0.0057, 0.1150, 0.0049, 0.0697, 0.0166, 0.0047, 0.0308, 0.0530,
        0.0042, 0.0062, 0.1081, 0.1150, 0.0319, 0.3153], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,804][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0220, 0.0041, 0.0047, 0.0068, 0.0071, 0.0089, 0.0119, 0.0183, 0.0267,
        0.0489, 0.0793, 0.0929, 0.1393, 0.2570, 0.2720], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,810][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0594, 0.0032, 0.1035, 0.0049, 0.0466, 0.1310, 0.0197, 0.0089,
        0.1507, 0.1813, 0.0048, 0.0075, 0.0338, 0.2367], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,812][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1182, 0.0733, 0.0462, 0.0806, 0.0430, 0.0538, 0.0686, 0.0471, 0.0423,
        0.0692, 0.0846, 0.0454, 0.0482, 0.0821, 0.0975], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,813][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1023, 0.0841, 0.0375, 0.1007, 0.0297, 0.0746, 0.0858, 0.0504, 0.0334,
        0.0763, 0.0930, 0.0276, 0.0264, 0.0644, 0.1138], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,814][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1770, 0.0700, 0.0599, 0.0718, 0.0483, 0.0498, 0.0453, 0.0531, 0.0533,
        0.0719, 0.0683, 0.0735, 0.0490, 0.0365, 0.0722], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:00,817][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:00,819][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[28131],
        [18695],
        [    1],
        [20195],
        [  536],
        [15410],
        [29532],
        [28469],
        [32106],
        [12330],
        [21428],
        [31659],
        [  753],
        [ 9199],
        [13407]], device='cuda:0')
[2024-07-24 10:24:00,822][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[42314],
        [27870],
        [    1],
        [32961],
        [  148],
        [41530],
        [28829],
        [37234],
        [42157],
        [35019],
        [30383],
        [44517],
        [  149],
        [30497],
        [32564]], device='cuda:0')
[2024-07-24 10:24:00,824][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[7255],
        [6457],
        [1895],
        [3118],
        [1561],
        [2007],
        [4698],
        [4141],
        [1626],
        [2715],
        [1613],
        [ 859],
        [1609],
        [3181],
        [2947]], device='cuda:0')
[2024-07-24 10:24:00,827][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[36081],
        [ 4973],
        [12255],
        [22172],
        [ 7517],
        [40087],
        [45786],
        [32409],
        [38355],
        [ 6004],
        [23762],
        [48545],
        [ 7983],
        [26872],
        [38229]], device='cuda:0')
[2024-07-24 10:24:00,829][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5363],
        [ 7449],
        [ 7003],
        [19807],
        [ 7110],
        [12080],
        [14092],
        [11743],
        [ 7887],
        [14251],
        [25351],
        [13121],
        [ 8446],
        [17256],
        [19855]], device='cuda:0')
[2024-07-24 10:24:00,832][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30005],
        [26989],
        [ 9034],
        [19365],
        [23840],
        [ 3278],
        [ 4180],
        [ 1446],
        [ 7190],
        [17245],
        [22025],
        [25063],
        [26196],
        [  193],
        [ 2918]], device='cuda:0')
[2024-07-24 10:24:00,834][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[42270],
        [42019],
        [  324],
        [ 9435],
        [ 6168],
        [25183],
        [21671],
        [14414],
        [38821],
        [21744],
        [21597],
        [41328],
        [ 6554],
        [16191],
        [14669]], device='cuda:0')
[2024-07-24 10:24:00,836][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40071],
        [46807],
        [35329],
        [46760],
        [28825],
        [48413],
        [45605],
        [44605],
        [42535],
        [46917],
        [46459],
        [48905],
        [26817],
        [44561],
        [46096]], device='cuda:0')
[2024-07-24 10:24:00,838][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[20457],
        [20671],
        [ 8549],
        [  748],
        [ 1762],
        [   22],
        [   24],
        [   53],
        [  183],
        [   23],
        [   20],
        [ 3725],
        [  880],
        [   43],
        [ 2406]], device='cuda:0')
[2024-07-24 10:24:00,839][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23988],
        [21909],
        [12949],
        [16350],
        [24103],
        [33954],
        [28813],
        [31400],
        [34781],
        [15861],
        [29888],
        [31576],
        [28538],
        [19356],
        [23271]], device='cuda:0')
[2024-07-24 10:24:00,841][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38420],
        [39877],
        [29098],
        [38828],
        [26853],
        [42483],
        [44105],
        [40504],
        [43092],
        [39577],
        [40178],
        [37041],
        [17738],
        [40407],
        [39509]], device='cuda:0')
[2024-07-24 10:24:00,843][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29628],
        [33923],
        [34056],
        [34695],
        [33780],
        [35451],
        [34460],
        [33753],
        [32032],
        [34004],
        [34633],
        [33683],
        [34273],
        [34544],
        [34938]], device='cuda:0')
[2024-07-24 10:24:00,846][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 2640],
        [ 1031],
        [ 5184],
        [ 1124],
        [ 8290],
        [  644],
        [ 2397],
        [ 2407],
        [ 1580],
        [ 1533],
        [ 1551],
        [ 3822],
        [27109],
        [  801],
        [ 1490]], device='cuda:0')
[2024-07-24 10:24:00,848][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[28199],
        [26791],
        [24174],
        [29858],
        [24712],
        [27522],
        [25567],
        [29556],
        [28759],
        [29006],
        [32112],
        [30690],
        [27148],
        [29079],
        [29847]], device='cuda:0')
[2024-07-24 10:24:00,851][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[47787],
        [15434],
        [   21],
        [39929],
        [ 1199],
        [45193],
        [46315],
        [42866],
        [47080],
        [21600],
        [40369],
        [48065],
        [ 1141],
        [28713],
        [34048]], device='cuda:0')
[2024-07-24 10:24:00,853][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35712],
        [35523],
        [25707],
        [27815],
        [18965],
        [20722],
        [22604],
        [19302],
        [21018],
        [24595],
        [22507],
        [19457],
        [19171],
        [23739],
        [21752]], device='cuda:0')
[2024-07-24 10:24:00,856][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7069],
        [23347],
        [ 9159],
        [ 6557],
        [11863],
        [ 4550],
        [ 2269],
        [11513],
        [10023],
        [19111],
        [ 5011],
        [ 3434],
        [10673],
        [11456],
        [ 2249]], device='cuda:0')
[2024-07-24 10:24:00,858][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13331],
        [ 7159],
        [ 6185],
        [18489],
        [10407],
        [11256],
        [12335],
        [13106],
        [15422],
        [ 4345],
        [23460],
        [12813],
        [17930],
        [18737],
        [10248]], device='cuda:0')
[2024-07-24 10:24:00,860][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15931],
        [21344],
        [12752],
        [20415],
        [14744],
        [17543],
        [18790],
        [19290],
        [16789],
        [19647],
        [24188],
        [16450],
        [21408],
        [23686],
        [24828]], device='cuda:0')
[2024-07-24 10:24:00,862][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12948],
        [13669],
        [16775],
        [33197],
        [47772],
        [28291],
        [26563],
        [36472],
        [34724],
        [32967],
        [31680],
        [44159],
        [47592],
        [37559],
        [35300]], device='cuda:0')
[2024-07-24 10:24:00,863][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27546],
        [21792],
        [21507],
        [21613],
        [22591],
        [15564],
        [22493],
        [19529],
        [20886],
        [20770],
        [22709],
        [ 7302],
        [23271],
        [15703],
        [21486]], device='cuda:0')
[2024-07-24 10:24:00,866][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24082],
        [24422],
        [ 7965],
        [ 4486],
        [16414],
        [ 3206],
        [ 4367],
        [ 4876],
        [ 5691],
        [ 2424],
        [ 2603],
        [ 7555],
        [18413],
        [ 3863],
        [26667]], device='cuda:0')
[2024-07-24 10:24:00,869][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21539],
        [20204],
        [11697],
        [ 7933],
        [ 7001],
        [ 5238],
        [ 6988],
        [ 7708],
        [ 4804],
        [ 3349],
        [ 3799],
        [ 5661],
        [ 6754],
        [ 7243],
        [ 6531]], device='cuda:0')
[2024-07-24 10:24:00,871][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42327],
        [16892],
        [34613],
        [17551],
        [33661],
        [26738],
        [17896],
        [30143],
        [34404],
        [10965],
        [12974],
        [21873],
        [31691],
        [20477],
        [16123]], device='cuda:0')
[2024-07-24 10:24:00,874][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22516],
        [17887],
        [18293],
        [20796],
        [22949],
        [24977],
        [22575],
        [20331],
        [22515],
        [20043],
        [20664],
        [21387],
        [21396],
        [22994],
        [21552]], device='cuda:0')
[2024-07-24 10:24:00,876][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[45536],
        [48372],
        [48264],
        [48351],
        [48982],
        [46652],
        [46400],
        [45600],
        [47139],
        [47219],
        [45708],
        [48913],
        [49075],
        [45849],
        [46479]], device='cuda:0')
[2024-07-24 10:24:00,879][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[15482],
        [23382],
        [45226],
        [41484],
        [43305],
        [42882],
        [44633],
        [41962],
        [43110],
        [45023],
        [43971],
        [44928],
        [35487],
        [39286],
        [40373]], device='cuda:0')
[2024-07-24 10:24:00,881][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[12005],
        [10164],
        [11889],
        [14698],
        [ 8938],
        [20790],
        [20777],
        [16020],
        [12874],
        [18577],
        [19261],
        [12513],
        [10222],
        [17351],
        [16439]], device='cuda:0')
[2024-07-24 10:24:00,883][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 1973],
        [30171],
        [50172],
        [ 7899],
        [48011],
        [ 4163],
        [ 2776],
        [ 5852],
        [ 2271],
        [23862],
        [ 7296],
        [ 1988],
        [48115],
        [17406],
        [12454]], device='cuda:0')
[2024-07-24 10:24:00,885][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666],
        [22666]], device='cuda:0')
[2024-07-24 10:24:00,908][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:00,909][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,909][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,910][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,911][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,911][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,912][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,913][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,913][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,914][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,915][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,915][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,917][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:00,922][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8576, 0.1424], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,924][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7582, 0.2418], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,925][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6345, 0.3655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,926][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4408, 0.5592], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,927][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8975, 0.1025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,930][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7570, 0.2430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,936][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6731, 0.3269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,940][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5961, 0.4039], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,944][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7910, 0.2090], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,944][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6109, 0.3891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,945][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2360, 0.7640], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,946][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8407, 0.1593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:00,947][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.0102, 0.1134, 0.8763], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,950][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.7706, 0.2001, 0.0293], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,955][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.4708, 0.2903, 0.2389], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,960][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.4715, 0.3623, 0.1662], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,964][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.6048, 0.2545, 0.1407], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,964][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.2984, 0.2108, 0.4907], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,965][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.4744, 0.4285, 0.0971], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,966][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.0866, 0.2246, 0.6888], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,969][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.7538, 0.1993, 0.0469], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,975][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.3564, 0.2888, 0.3548], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,979][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.1283, 0.3949, 0.4768], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,983][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.0075, 0.0253, 0.9672], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:00,984][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0272, 0.1022, 0.8258, 0.0448], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,984][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7191, 0.1638, 0.0261, 0.0910], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,985][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3426, 0.2108, 0.1998, 0.2468], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,987][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3924, 0.2663, 0.1060, 0.2353], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,991][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4002, 0.1101, 0.1995, 0.2903], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:00,997][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0552, 0.7129, 0.0477, 0.1843], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,002][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3350, 0.1761, 0.0614, 0.4275], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,003][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1364, 0.2134, 0.5272, 0.1229], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,004][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7134, 0.1817, 0.0423, 0.0626], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,005][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3315, 0.2183, 0.2683, 0.1819], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,006][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0978, 0.2802, 0.3762, 0.2458], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,009][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2339, 0.0805, 0.0094, 0.6763], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,015][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0020, 0.0156, 0.6772, 0.0153, 0.2898], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,021][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.7714, 0.1350, 0.0171, 0.0735, 0.0030], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,023][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.2861, 0.1878, 0.1526, 0.2132, 0.1603], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,024][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.3525, 0.2139, 0.1109, 0.2256, 0.0972], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,025][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.2568, 0.2133, 0.1041, 0.2686, 0.1572], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,026][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0731, 0.0423, 0.6623, 0.0717, 0.1506], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,027][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.1544, 0.1852, 0.0319, 0.4814, 0.1471], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,032][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0267, 0.0691, 0.6314, 0.0960, 0.1768], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,038][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.7395, 0.1596, 0.0341, 0.0490, 0.0177], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,042][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.2057, 0.1723, 0.2373, 0.2388, 0.1460], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,044][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0779, 0.2200, 0.2696, 0.1908, 0.2418], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,045][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([2.8133e-04, 1.2976e-03, 1.9052e-03, 5.0515e-04, 9.9601e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,046][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1591, 0.0743, 0.0532, 0.1167, 0.3590, 0.2377], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,046][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.7068, 0.1540, 0.0230, 0.0827, 0.0043, 0.0292], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,050][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2302, 0.1569, 0.1395, 0.1690, 0.1491, 0.1554], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,056][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2891, 0.1841, 0.0848, 0.1574, 0.0993, 0.1853], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,062][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2560, 0.1034, 0.0957, 0.1750, 0.1529, 0.2169], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,064][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0151, 0.1449, 0.0015, 0.7351, 0.0023, 0.1011], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,065][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2088, 0.0891, 0.0307, 0.3451, 0.0895, 0.2369], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,066][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0296, 0.0480, 0.1483, 0.0628, 0.3934, 0.3180], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,066][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.6199, 0.1890, 0.0429, 0.0614, 0.0249, 0.0620], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,070][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2206, 0.1522, 0.1901, 0.1340, 0.1047, 0.1985], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,074][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0573, 0.1782, 0.2294, 0.1516, 0.2155, 0.1680], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,080][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0050, 0.0239, 0.0027, 0.0149, 0.0027, 0.9507], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,084][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0042, 0.0143, 0.0495, 0.0184, 0.1450, 0.7085, 0.0601],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,085][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6965, 0.1403, 0.0201, 0.0770, 0.0037, 0.0286, 0.0339],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,086][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2073, 0.1321, 0.1167, 0.1504, 0.1262, 0.1285, 0.1387],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,087][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2863, 0.1520, 0.0642, 0.1318, 0.0804, 0.1527, 0.1327],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,090][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1878, 0.0732, 0.0823, 0.1415, 0.1418, 0.1583, 0.2152],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,096][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0263, 0.4004, 0.0247, 0.1803, 0.0294, 0.2632, 0.0757],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,102][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0993, 0.0525, 0.0130, 0.1409, 0.0291, 0.0942, 0.5709],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,106][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0395, 0.0199, 0.1351, 0.0228, 0.3681, 0.3571, 0.0575],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,107][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6264, 0.1503, 0.0295, 0.0512, 0.0170, 0.0448, 0.0808],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,108][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2016, 0.1373, 0.1648, 0.1161, 0.0902, 0.1778, 0.1121],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,109][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0526, 0.1518, 0.2014, 0.1321, 0.1862, 0.1446, 0.1313],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,110][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.6069e-03, 4.3955e-03, 9.3161e-05, 3.6916e-03, 2.1515e-04, 3.0237e-04,
        9.8370e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,113][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0016, 0.0021, 0.1141, 0.0037, 0.0206, 0.3323, 0.5137, 0.0119],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,119][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.6919, 0.1429, 0.0196, 0.0739, 0.0035, 0.0269, 0.0346, 0.0068],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,123][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1881, 0.1189, 0.1062, 0.1267, 0.1117, 0.1124, 0.1142, 0.1219],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,127][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2945, 0.1319, 0.0555, 0.1233, 0.0759, 0.1343, 0.1151, 0.0695],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,128][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1632, 0.1096, 0.0737, 0.1341, 0.1320, 0.1371, 0.1505, 0.0998],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,129][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0422, 0.1357, 0.0033, 0.5658, 0.0019, 0.0599, 0.1529, 0.0383],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,130][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0943, 0.0460, 0.0066, 0.1433, 0.0099, 0.1004, 0.5426, 0.0568],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,132][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0342, 0.0227, 0.1111, 0.0243, 0.1236, 0.5419, 0.1267, 0.0154],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,137][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.5785, 0.1591, 0.0324, 0.0563, 0.0201, 0.0487, 0.0886, 0.0162],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,143][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1602, 0.1202, 0.1615, 0.1237, 0.0961, 0.1671, 0.1000, 0.0713],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,148][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0453, 0.1341, 0.1746, 0.1148, 0.1627, 0.1251, 0.1137, 0.1299],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,148][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([1.1676e-02, 2.6522e-02, 2.7614e-04, 1.3526e-02, 3.5000e-05, 1.2130e-03,
        5.4260e-04, 9.4621e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,149][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0005, 0.0042, 0.0368, 0.0118, 0.1341, 0.3222, 0.2975, 0.1742, 0.0186],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,150][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.7190, 0.1294, 0.0177, 0.0655, 0.0031, 0.0237, 0.0322, 0.0065, 0.0029],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,152][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1660, 0.1049, 0.0923, 0.1109, 0.0971, 0.0989, 0.1014, 0.1070, 0.1214],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,158][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2359, 0.1261, 0.0593, 0.1210, 0.0691, 0.1327, 0.1070, 0.0683, 0.0805],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,163][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1578, 0.0817, 0.0805, 0.1144, 0.1332, 0.1373, 0.1290, 0.0788, 0.0873],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,168][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0060, 0.0815, 0.0297, 0.4619, 0.0211, 0.1082, 0.2558, 0.0209, 0.0148],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,169][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1006, 0.0564, 0.0081, 0.1688, 0.0150, 0.0880, 0.4831, 0.0401, 0.0398],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,170][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0081, 0.0083, 0.0721, 0.0134, 0.1169, 0.5172, 0.0204, 0.1688, 0.0748],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,171][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.5834, 0.1501, 0.0321, 0.0509, 0.0183, 0.0440, 0.0785, 0.0149, 0.0279],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,173][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1340, 0.1081, 0.1548, 0.1347, 0.0953, 0.1669, 0.0962, 0.0661, 0.0438],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,179][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0397, 0.1147, 0.1525, 0.0968, 0.1409, 0.1054, 0.0966, 0.1106, 0.1429],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,183][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.4522e-02, 1.2160e-02, 1.4735e-04, 9.8953e-03, 2.3321e-04, 1.5776e-04,
        1.6790e-03, 1.2054e-04, 9.6108e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,187][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0194, 0.0061, 0.0629, 0.0180, 0.1085, 0.0454, 0.1926, 0.0534, 0.4758,
        0.0179], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,189][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6706, 0.1349, 0.0204, 0.0700, 0.0038, 0.0271, 0.0324, 0.0072, 0.0035,
        0.0302], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,190][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1389, 0.0876, 0.0832, 0.0979, 0.0901, 0.0901, 0.0911, 0.0959, 0.1086,
        0.1166], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,191][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2602, 0.1072, 0.0410, 0.1038, 0.0521, 0.1130, 0.0939, 0.0546, 0.0657,
        0.1085], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,192][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1016, 0.0566, 0.0618, 0.1040, 0.0998, 0.1050, 0.1000, 0.0628, 0.0897,
        0.2185], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,195][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0028, 0.2591, 0.0032, 0.0530, 0.0153, 0.4510, 0.0465, 0.0366, 0.0377,
        0.0949], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,199][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0645, 0.0451, 0.0167, 0.0921, 0.0360, 0.0848, 0.3399, 0.0633, 0.0313,
        0.2261], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,205][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0113, 0.0180, 0.0889, 0.0211, 0.2612, 0.1386, 0.0383, 0.0835, 0.3130,
        0.0262], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,209][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5339, 0.1421, 0.0287, 0.0474, 0.0159, 0.0445, 0.0785, 0.0137, 0.0281,
        0.0670], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,210][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1650, 0.1119, 0.1468, 0.0942, 0.0824, 0.1448, 0.0919, 0.0707, 0.0385,
        0.0540], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,211][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0357, 0.1025, 0.1376, 0.0887, 0.1288, 0.0979, 0.0867, 0.1034, 0.1318,
        0.0870], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,212][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1025, 0.1122, 0.0586, 0.1094, 0.2555, 0.0445, 0.0336, 0.0344, 0.1109,
        0.1385], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,213][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0025, 0.0123, 0.0983, 0.0054, 0.1096, 0.0440, 0.2654, 0.1344, 0.2874,
        0.0352, 0.0054], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,216][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6975, 0.1190, 0.0175, 0.0579, 0.0032, 0.0241, 0.0295, 0.0065, 0.0031,
        0.0273, 0.0145], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,222][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1223, 0.0775, 0.0755, 0.0907, 0.0814, 0.0815, 0.0818, 0.0848, 0.0986,
        0.1041, 0.1019], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,226][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2460, 0.0963, 0.0353, 0.0944, 0.0480, 0.0975, 0.0829, 0.0479, 0.0576,
        0.1039, 0.0902], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,230][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0845, 0.0489, 0.0607, 0.0880, 0.0935, 0.0861, 0.0761, 0.0459, 0.0632,
        0.1778, 0.1754], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,231][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0034, 0.3251, 0.0054, 0.0199, 0.0161, 0.4390, 0.0299, 0.0717, 0.0416,
        0.0338, 0.0142], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,232][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0602, 0.0371, 0.0125, 0.0755, 0.0257, 0.0765, 0.3522, 0.0495, 0.0257,
        0.1867, 0.0984], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,232][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0193, 0.0281, 0.0585, 0.0176, 0.2365, 0.2203, 0.0365, 0.0648, 0.2580,
        0.0410, 0.0195], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,236][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5129, 0.1394, 0.0275, 0.0478, 0.0161, 0.0419, 0.0763, 0.0137, 0.0272,
        0.0651, 0.0320], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,240][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1566, 0.1074, 0.1355, 0.0879, 0.0761, 0.1365, 0.0868, 0.0656, 0.0359,
        0.0511, 0.0606], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,246][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0335, 0.0928, 0.1267, 0.0821, 0.1182, 0.0902, 0.0795, 0.0957, 0.1223,
        0.0798, 0.0790], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,250][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0593, 0.0648, 0.0095, 0.2982, 0.0183, 0.0402, 0.0025, 0.0032, 0.0212,
        0.1260, 0.3568], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,251][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0016, 0.0101, 0.0363, 0.0213, 0.0101, 0.2784, 0.0504, 0.3928, 0.0702,
        0.0571, 0.0224, 0.0493], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,252][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.6635, 0.1355, 0.0184, 0.0670, 0.0031, 0.0237, 0.0310, 0.0063, 0.0028,
        0.0308, 0.0158, 0.0021], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,253][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1228, 0.0773, 0.0683, 0.0813, 0.0723, 0.0724, 0.0750, 0.0786, 0.0893,
        0.0972, 0.0902, 0.0753], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,256][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.2839, 0.0817, 0.0285, 0.1078, 0.0308, 0.1055, 0.0909, 0.0508, 0.0483,
        0.0774, 0.0823, 0.0121], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,262][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0936, 0.0657, 0.0459, 0.0785, 0.0633, 0.0725, 0.0780, 0.0497, 0.0539,
        0.1977, 0.1357, 0.0656], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,266][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0165, 0.0701, 0.0048, 0.1565, 0.0060, 0.1137, 0.0534, 0.0800, 0.0212,
        0.1872, 0.1920, 0.0985], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,270][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0503, 0.0365, 0.0048, 0.1135, 0.0106, 0.0613, 0.2499, 0.0360, 0.0101,
        0.2691, 0.1374, 0.0204], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,271][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0045, 0.0092, 0.0340, 0.0080, 0.0733, 0.2566, 0.0150, 0.0258, 0.5063,
        0.0105, 0.0076, 0.0493], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,272][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.4553, 0.1474, 0.0331, 0.0489, 0.0189, 0.0438, 0.0767, 0.0155, 0.0294,
        0.0686, 0.0337, 0.0287], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,273][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1212, 0.0950, 0.1249, 0.1023, 0.0760, 0.1324, 0.0789, 0.0554, 0.0344,
        0.0532, 0.0665, 0.0597], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,276][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0310, 0.0878, 0.1134, 0.0750, 0.1041, 0.0806, 0.0740, 0.0833, 0.1068,
        0.0728, 0.0714, 0.0997], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,280][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([2.0675e-03, 1.2076e-03, 1.8324e-04, 1.2857e-03, 3.0949e-05, 6.5621e-05,
        1.8516e-05, 6.9932e-04, 6.3450e-04, 8.5642e-04, 7.0688e-04, 9.9224e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,286][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0008, 0.0068, 0.2831, 0.0072, 0.1264, 0.1500, 0.1029, 0.0177, 0.0529,
        0.0276, 0.0074, 0.0801, 0.1373], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,290][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.7205, 0.1061, 0.0134, 0.0556, 0.0023, 0.0204, 0.0278, 0.0054, 0.0024,
        0.0286, 0.0144, 0.0018, 0.0013], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,291][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.1081, 0.0726, 0.0592, 0.0810, 0.0624, 0.0696, 0.0706, 0.0719, 0.0834,
        0.0939, 0.0897, 0.0711, 0.0665], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,292][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.2353, 0.0826, 0.0385, 0.0912, 0.0373, 0.0945, 0.0816, 0.0469, 0.0490,
        0.0896, 0.0862, 0.0326, 0.0347], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,295][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0861, 0.0849, 0.0344, 0.0972, 0.0489, 0.0953, 0.0818, 0.0292, 0.0458,
        0.1877, 0.1251, 0.0480, 0.0358], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,301][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0175, 0.0925, 0.2042, 0.0466, 0.0874, 0.1486, 0.0530, 0.1146, 0.0675,
        0.0526, 0.0490, 0.0120, 0.0546], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,307][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0320, 0.0378, 0.0059, 0.1028, 0.0272, 0.0642, 0.2556, 0.0287, 0.0066,
        0.2593, 0.1422, 0.0168, 0.0209], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,309][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0036, 0.0115, 0.1078, 0.0157, 0.0290, 0.2454, 0.0854, 0.0172, 0.3929,
        0.0144, 0.0145, 0.0338, 0.0289], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,310][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.5445, 0.1338, 0.0272, 0.0404, 0.0143, 0.0362, 0.0688, 0.0114, 0.0218,
        0.0477, 0.0232, 0.0216, 0.0090], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,311][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0872, 0.0815, 0.1115, 0.1217, 0.0722, 0.1336, 0.0727, 0.0469, 0.0340,
        0.0542, 0.0724, 0.0529, 0.0591], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,312][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0302, 0.0812, 0.1004, 0.0707, 0.0903, 0.0732, 0.0668, 0.0754, 0.0951,
        0.0673, 0.0673, 0.0894, 0.0926], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,313][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([3.4266e-06, 2.6332e-04, 7.7462e-04, 2.4911e-05, 6.9584e-01, 2.9271e-05,
        8.8654e-06, 8.2185e-07, 7.6876e-06, 2.3485e-03, 1.1091e-04, 1.0341e-05,
        3.0058e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,319][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0084, 0.0152, 0.0542, 0.0339, 0.0868, 0.2693, 0.1027, 0.0792, 0.0184,
        0.0603, 0.0415, 0.0807, 0.1019, 0.0475], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,325][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.6663, 0.1343, 0.0177, 0.0635, 0.0030, 0.0236, 0.0293, 0.0061, 0.0029,
        0.0283, 0.0150, 0.0021, 0.0016, 0.0064], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,329][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0978, 0.0633, 0.0588, 0.0676, 0.0636, 0.0631, 0.0635, 0.0658, 0.0771,
        0.0830, 0.0762, 0.0664, 0.0686, 0.0853], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,330][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.2128, 0.0763, 0.0304, 0.0794, 0.0397, 0.0852, 0.0702, 0.0402, 0.0478,
        0.0869, 0.0765, 0.0357, 0.0356, 0.0833], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,331][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0663, 0.0509, 0.0393, 0.0796, 0.0575, 0.0602, 0.0748, 0.0329, 0.0339,
        0.1771, 0.1237, 0.0538, 0.0480, 0.1021], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,331][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0012, 0.0307, 0.0025, 0.1412, 0.0030, 0.1142, 0.0301, 0.0113, 0.0148,
        0.1856, 0.3076, 0.0121, 0.0101, 0.1356], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,335][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0557, 0.0357, 0.0081, 0.0904, 0.0176, 0.0580, 0.2110, 0.0267, 0.0288,
        0.1962, 0.1214, 0.0282, 0.0120, 0.1102], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,341][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0045, 0.0060, 0.0358, 0.0069, 0.1655, 0.1208, 0.0050, 0.0344, 0.1035,
        0.0052, 0.0076, 0.1290, 0.1673, 0.2084], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,347][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.4437, 0.1341, 0.0299, 0.0457, 0.0177, 0.0430, 0.0759, 0.0146, 0.0289,
        0.0670, 0.0330, 0.0271, 0.0117, 0.0278], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,349][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0947, 0.0745, 0.0989, 0.0727, 0.0593, 0.1078, 0.0650, 0.0478, 0.0266,
        0.0396, 0.0486, 0.0476, 0.0542, 0.1627], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,350][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0241, 0.0700, 0.0943, 0.0609, 0.0882, 0.0674, 0.0597, 0.0710, 0.0910,
        0.0598, 0.0587, 0.0873, 0.0909, 0.0768], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,351][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.4568e-03, 9.1389e-03, 5.6275e-05, 6.5744e-03, 1.2146e-04, 2.0547e-04,
        2.1535e-03, 7.7835e-05, 9.3204e-03, 2.8550e-02, 4.6118e-03, 4.6941e-04,
        1.3131e-05, 9.3625e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,351][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.4063e-03, 4.0460e-03, 2.4618e-02, 2.7221e-03, 2.1583e-02, 2.8048e-01,
        5.1764e-02, 3.5125e-02, 8.4076e-02, 1.5452e-02, 3.4863e-03, 3.9972e-02,
        2.7034e-02, 4.0696e-01, 2.7009e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,355][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.6578, 0.1301, 0.0182, 0.0630, 0.0032, 0.0244, 0.0294, 0.0064, 0.0031,
        0.0285, 0.0154, 0.0023, 0.0018, 0.0069, 0.0095], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,361][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0901, 0.0572, 0.0547, 0.0629, 0.0596, 0.0590, 0.0609, 0.0642, 0.0720,
        0.0772, 0.0711, 0.0640, 0.0645, 0.0767, 0.0659], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,367][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2253, 0.0771, 0.0251, 0.0750, 0.0338, 0.0861, 0.0688, 0.0379, 0.0456,
        0.0775, 0.0675, 0.0273, 0.0289, 0.0753, 0.0487], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,369][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0638, 0.0311, 0.0374, 0.0491, 0.0524, 0.0630, 0.0638, 0.0381, 0.0407,
        0.1242, 0.0874, 0.0566, 0.0449, 0.0986, 0.1490], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,370][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0067, 0.1610, 0.0077, 0.0783, 0.0163, 0.2476, 0.0284, 0.0335, 0.0252,
        0.0741, 0.0815, 0.0377, 0.0226, 0.1341, 0.0452], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,371][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0603, 0.0240, 0.0077, 0.0711, 0.0096, 0.0568, 0.3045, 0.0351, 0.0159,
        0.1364, 0.0911, 0.0216, 0.0065, 0.0839, 0.0754], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,374][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0072, 0.0147, 0.0383, 0.0116, 0.0844, 0.1105, 0.0145, 0.0251, 0.2927,
        0.0201, 0.0119, 0.0855, 0.0796, 0.1943, 0.0096], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,380][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4494, 0.1302, 0.0279, 0.0442, 0.0161, 0.0401, 0.0713, 0.0135, 0.0270,
        0.0630, 0.0308, 0.0249, 0.0102, 0.0258, 0.0256], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,386][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0989, 0.0753, 0.0973, 0.0660, 0.0561, 0.1040, 0.0649, 0.0494, 0.0259,
        0.0385, 0.0461, 0.0471, 0.0531, 0.1476, 0.0298], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,388][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0229, 0.0664, 0.0898, 0.0570, 0.0834, 0.0632, 0.0567, 0.0667, 0.0862,
        0.0565, 0.0548, 0.0814, 0.0858, 0.0727, 0.0563], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,389][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.5883e-02, 2.3620e-02, 3.2696e-04, 4.4279e-02, 1.4294e-04, 9.7547e-04,
        4.1745e-03, 2.6783e-04, 2.7689e-03, 5.3205e-02, 2.0101e-02, 1.5707e-03,
        1.6892e-05, 4.2484e-03, 8.1842e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,408][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:01,409][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,409][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,410][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,411][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,411][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,413][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,413][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,414][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,415][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,415][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,416][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,417][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,417][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5006, 0.4994], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,418][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9630, 0.0370], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,419][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5372, 0.4628], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,423][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3691, 0.6309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,426][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2632, 0.7368], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,430][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6137, 0.3863], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,430][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6800, 0.3200], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,431][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8792, 0.1208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,432][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4423, 0.5577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,433][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9526, 0.0474], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,435][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2380, 0.7620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,437][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4491, 0.5509], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,441][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.3338, 0.3331, 0.3331], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,445][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.7377, 0.2555, 0.0067], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,448][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.3077, 0.4244, 0.2679], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,452][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.3278, 0.4855, 0.1867], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,452][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.1089, 0.5785, 0.3126], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,453][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.2514, 0.3674, 0.3811], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,454][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.4916, 0.2837, 0.2247], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,454][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.4032, 0.2837, 0.3131], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,456][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.3997, 0.5162, 0.0840], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,459][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.3437, 0.6425, 0.0137], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,463][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.1293, 0.3939, 0.4768], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,466][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.0953, 0.3203, 0.5844], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:01,470][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2504, 0.2498, 0.2498, 0.2500], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,473][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6440, 0.1022, 0.2446, 0.0091], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,474][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2333, 0.2841, 0.2670, 0.2157], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,475][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2104, 0.2742, 0.1578, 0.3576], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,476][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0838, 0.2787, 0.3939, 0.2436], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,477][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0398, 0.1895, 0.0040, 0.7667], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,480][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2891, 0.1360, 0.1629, 0.4121], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,482][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2197, 0.1549, 0.3514, 0.2741], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,487][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1797, 0.2711, 0.0294, 0.5198], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,491][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5479, 0.0564, 0.0882, 0.3076], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,495][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0983, 0.2797, 0.3761, 0.2458], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,495][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1897, 0.3541, 0.2331, 0.2232], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:01,496][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2003, 0.1998, 0.1998, 0.1999, 0.2002], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,497][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.4247, 0.2534, 0.0230, 0.2221, 0.0769], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,499][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1566, 0.2897, 0.1760, 0.1915, 0.1862], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,504][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.1669, 0.2637, 0.1116, 0.3084, 0.1493], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,509][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0621, 0.3357, 0.2000, 0.2585, 0.1437], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,514][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1450, 0.1838, 0.5636, 0.0952, 0.0125], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,515][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.2347, 0.1426, 0.1024, 0.3720, 0.1483], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,516][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.3820, 0.1085, 0.3363, 0.1194, 0.0538], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,517][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1806, 0.2565, 0.0421, 0.4722, 0.0485], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,519][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.1855, 0.5476, 0.0255, 0.2054, 0.0359], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,524][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0785, 0.2198, 0.2697, 0.1909, 0.2411], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,529][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0438, 0.2346, 0.4997, 0.1424, 0.0796], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:01,534][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1669, 0.1665, 0.1665, 0.1666, 0.1668, 0.1665], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,535][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.3539, 0.1286, 0.0375, 0.1281, 0.2704, 0.0815], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,536][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1107, 0.2353, 0.1682, 0.1224, 0.1985, 0.1648], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,536][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1293, 0.1927, 0.0987, 0.2314, 0.1490, 0.1989], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,538][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0497, 0.2304, 0.2217, 0.1283, 0.2173, 0.1525], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,544][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0538, 0.3284, 0.0198, 0.4110, 0.0036, 0.1833], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,548][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0926, 0.0679, 0.1107, 0.2584, 0.1926, 0.2777], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,554][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0944, 0.1012, 0.0913, 0.1192, 0.2830, 0.3110], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,555][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1267, 0.2438, 0.0260, 0.3307, 0.0435, 0.2293], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,555][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3643, 0.1269, 0.0867, 0.2079, 0.0965, 0.1177], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,556][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0577, 0.1779, 0.2295, 0.1517, 0.2149, 0.1682], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,558][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0463, 0.2242, 0.2657, 0.1382, 0.0403, 0.2853], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:01,564][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1431, 0.1427, 0.1427, 0.1428, 0.1430, 0.1427, 0.1429],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,568][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5574, 0.0551, 0.0521, 0.0354, 0.1204, 0.1555, 0.0241],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,574][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1221, 0.1871, 0.1407, 0.1180, 0.1700, 0.1204, 0.1417],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,574][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1102, 0.1459, 0.0801, 0.1784, 0.1118, 0.1496, 0.2240],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,575][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0579, 0.1867, 0.1820, 0.1372, 0.1794, 0.1400, 0.1168],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,576][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0738, 0.1699, 0.0065, 0.5274, 0.0057, 0.1732, 0.0435],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,579][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1269, 0.0641, 0.0880, 0.1904, 0.1367, 0.1884, 0.2055],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,584][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1058, 0.0719, 0.1099, 0.0849, 0.2411, 0.2765, 0.1099],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,589][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1147, 0.1490, 0.0169, 0.2595, 0.0282, 0.1235, 0.3081],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,594][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3032, 0.0821, 0.0977, 0.2134, 0.0930, 0.0913, 0.1192],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,594][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0529, 0.1517, 0.2015, 0.1322, 0.1856, 0.1448, 0.1313],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,595][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0378, 0.2080, 0.1802, 0.1414, 0.0289, 0.2154, 0.1883],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:01,596][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1252, 0.1249, 0.1249, 0.1250, 0.1251, 0.1249, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,598][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.2002, 0.0514, 0.0906, 0.0393, 0.1298, 0.0837, 0.2805, 0.1244],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,604][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1017, 0.1681, 0.1433, 0.0912, 0.1579, 0.1078, 0.1014, 0.1285],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,610][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0975, 0.1312, 0.0674, 0.1589, 0.1029, 0.1376, 0.1743, 0.1303],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,614][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0407, 0.2119, 0.1646, 0.1124, 0.1472, 0.1174, 0.0791, 0.1267],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,615][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1542, 0.2322, 0.0060, 0.4200, 0.0017, 0.0635, 0.0565, 0.0659],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,615][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0987, 0.0613, 0.0593, 0.1734, 0.0912, 0.1720, 0.2025, 0.1416],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,616][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0563, 0.0711, 0.1294, 0.0828, 0.1180, 0.3844, 0.0881, 0.0698],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,620][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0655, 0.1509, 0.0190, 0.2599, 0.0309, 0.1119, 0.2997, 0.0622],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,624][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2146, 0.1106, 0.0469, 0.2005, 0.0483, 0.1030, 0.2455, 0.0306],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,630][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0455, 0.1339, 0.1746, 0.1149, 0.1622, 0.1252, 0.1137, 0.1300],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,634][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0235, 0.1519, 0.2071, 0.1035, 0.0348, 0.1839, 0.1241, 0.1713],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:01,635][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1113, 0.1110, 0.1110, 0.1111, 0.1112, 0.1110, 0.1111, 0.1110, 0.1113],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,636][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.2055, 0.0374, 0.0233, 0.0308, 0.0574, 0.0908, 0.1084, 0.2791, 0.1673],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,637][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0876, 0.1562, 0.1184, 0.0848, 0.1333, 0.0985, 0.0918, 0.1057, 0.1237],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,640][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0877, 0.1226, 0.0631, 0.1521, 0.0887, 0.1229, 0.1656, 0.1242, 0.0730],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,645][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0347, 0.1471, 0.1586, 0.0755, 0.1508, 0.1077, 0.0520, 0.0802, 0.1935],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,651][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0666, 0.0823, 0.0131, 0.6048, 0.0572, 0.0719, 0.0455, 0.0238, 0.0349],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,655][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0700, 0.0463, 0.0381, 0.1303, 0.0539, 0.1467, 0.1846, 0.1158, 0.2145],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,656][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0224, 0.0453, 0.1671, 0.1137, 0.1005, 0.3280, 0.1023, 0.0752, 0.0455],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,656][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0948, 0.1106, 0.0171, 0.2070, 0.0286, 0.1423, 0.2790, 0.0942, 0.0263],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,657][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1926, 0.0938, 0.0725, 0.1815, 0.0569, 0.1445, 0.1955, 0.0390, 0.0239],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,661][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0400, 0.1145, 0.1526, 0.0968, 0.1405, 0.1055, 0.0966, 0.1107, 0.1429],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,665][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0229, 0.1539, 0.2167, 0.1041, 0.0304, 0.1685, 0.1159, 0.1175, 0.0699],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:01,671][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1001, 0.0999, 0.0999, 0.1000, 0.1001, 0.0999, 0.1000, 0.0999, 0.1002,
        0.1000], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,675][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0502, 0.0016, 0.0058, 0.0086, 0.0364, 0.1017, 0.0131, 0.3974, 0.3847,
        0.0006], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,676][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0789, 0.1135, 0.1074, 0.0715, 0.1375, 0.0940, 0.0867, 0.1130, 0.1392,
        0.0582], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,677][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0816, 0.1004, 0.0561, 0.1353, 0.0800, 0.1080, 0.1457, 0.1190, 0.0715,
        0.1024], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,678][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0346, 0.1144, 0.1348, 0.0862, 0.1434, 0.1071, 0.0592, 0.0901, 0.1739,
        0.0563], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,682][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0287, 0.2375, 0.0045, 0.2855, 0.0011, 0.1888, 0.0412, 0.0473, 0.0427,
        0.1227], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,687][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0721, 0.0392, 0.0397, 0.0988, 0.0555, 0.0952, 0.1119, 0.0806, 0.1950,
        0.2121], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,692][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1139, 0.0406, 0.0659, 0.0686, 0.1476, 0.1789, 0.0808, 0.1466, 0.1264,
        0.0307], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,696][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0709, 0.0956, 0.0125, 0.1341, 0.0196, 0.0983, 0.2124, 0.0448, 0.0185,
        0.2933], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,697][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1843, 0.0516, 0.1051, 0.2478, 0.1127, 0.0589, 0.0800, 0.0287, 0.0369,
        0.0939], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,697][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0359, 0.1024, 0.1377, 0.0887, 0.1285, 0.0980, 0.0868, 0.1035, 0.1317,
        0.0869], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,698][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0406, 0.1824, 0.1415, 0.1275, 0.0210, 0.1432, 0.1210, 0.0854, 0.0451,
        0.0922], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:01,702][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0910, 0.0908, 0.0908, 0.0909, 0.0910, 0.0908, 0.0909, 0.0908, 0.0910,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,708][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0768, 0.0125, 0.0146, 0.0008, 0.1169, 0.0927, 0.0238, 0.3922, 0.2650,
        0.0037, 0.0008], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,714][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0740, 0.1023, 0.1006, 0.0764, 0.1260, 0.0865, 0.0799, 0.0967, 0.1360,
        0.0533, 0.0682], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,718][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0722, 0.0849, 0.0496, 0.1210, 0.0727, 0.0903, 0.1196, 0.1032, 0.0639,
        0.0883, 0.1345], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,719][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0374, 0.0961, 0.1386, 0.0930, 0.1273, 0.0839, 0.0567, 0.0796, 0.1742,
        0.0533, 0.0599], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,720][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0165, 0.1564, 0.0029, 0.3242, 0.0012, 0.0784, 0.0390, 0.0286, 0.0234,
        0.1099, 0.2195], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,720][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0586, 0.0284, 0.0342, 0.0782, 0.0487, 0.0782, 0.0944, 0.0630, 0.1717,
        0.1847, 0.1599], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,724][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0896, 0.0470, 0.0712, 0.0720, 0.1331, 0.2108, 0.0698, 0.1264, 0.1016,
        0.0333, 0.0454], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,729][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0498, 0.0765, 0.0082, 0.1449, 0.0132, 0.0675, 0.1539, 0.0306, 0.0129,
        0.2678, 0.1746], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,734][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2330, 0.0248, 0.0824, 0.1311, 0.0721, 0.0615, 0.1179, 0.0344, 0.0457,
        0.0598, 0.1373], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,739][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0337, 0.0928, 0.1268, 0.0822, 0.1178, 0.0903, 0.0796, 0.0958, 0.1223,
        0.0797, 0.0791], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,739][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0282, 0.1470, 0.1232, 0.1200, 0.0200, 0.1368, 0.1159, 0.0874, 0.0455,
        0.0899, 0.0862], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:01,740][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0834, 0.0833, 0.0832, 0.0833, 0.0834, 0.0832, 0.0833, 0.0832, 0.0835,
        0.0834, 0.0834, 0.0834], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,741][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0890, 0.0226, 0.0068, 0.0354, 0.0159, 0.0376, 0.0190, 0.2991, 0.4109,
        0.0082, 0.0515, 0.0038], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,746][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0806, 0.1255, 0.0964, 0.0664, 0.1088, 0.0743, 0.0744, 0.0906, 0.1057,
        0.0508, 0.0547, 0.0718], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,751][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0697, 0.0911, 0.0395, 0.1159, 0.0600, 0.0922, 0.1266, 0.0948, 0.0578,
        0.0985, 0.1282, 0.0256], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,757][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0324, 0.1504, 0.0963, 0.0922, 0.0961, 0.0677, 0.0605, 0.0785, 0.1397,
        0.0703, 0.0503, 0.0656], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,759][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([2.1899e-02, 5.2607e-02, 1.0126e-03, 3.8205e-02, 1.4524e-05, 5.5427e-01,
        1.3679e-02, 2.6360e-01, 4.1065e-02, 5.8182e-03, 7.8120e-03, 9.1387e-06],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,760][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0495, 0.0300, 0.0265, 0.0778, 0.0382, 0.0825, 0.1001, 0.0694, 0.1510,
        0.1841, 0.1596, 0.0314], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,761][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.3529, 0.0395, 0.0924, 0.0538, 0.1962, 0.0621, 0.0713, 0.0702, 0.0172,
        0.0182, 0.0225, 0.0036], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,761][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0451, 0.0710, 0.0158, 0.1118, 0.0236, 0.0729, 0.1770, 0.0774, 0.0229,
        0.2078, 0.1327, 0.0420], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,765][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0573, 0.1497, 0.0367, 0.1117, 0.0855, 0.1319, 0.1384, 0.0175, 0.0267,
        0.1353, 0.0936, 0.0157], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,769][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0312, 0.0877, 0.1135, 0.0751, 0.1039, 0.0807, 0.0739, 0.0834, 0.1069,
        0.0727, 0.0714, 0.0996], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,775][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0226, 0.1291, 0.1499, 0.0992, 0.0269, 0.1183, 0.0893, 0.0837, 0.0420,
        0.0690, 0.0656, 0.1044], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:01,779][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0770, 0.0768, 0.0768, 0.0769, 0.0770, 0.0768, 0.0769, 0.0768, 0.0770,
        0.0769, 0.0769, 0.0770, 0.0770], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,780][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0670, 0.0352, 0.0035, 0.0330, 0.0104, 0.0500, 0.0230, 0.1698, 0.5140,
        0.0111, 0.0359, 0.0176, 0.0295], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,781][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0576, 0.1192, 0.0721, 0.0757, 0.0780, 0.0792, 0.0735, 0.0838, 0.0983,
        0.0541, 0.0633, 0.0716, 0.0738], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,783][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0633, 0.0926, 0.0399, 0.1151, 0.0548, 0.0898, 0.1168, 0.0780, 0.0538,
        0.0919, 0.1232, 0.0245, 0.0563], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,789][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0264, 0.1459, 0.0833, 0.1068, 0.0589, 0.0846, 0.0544, 0.0730, 0.1258,
        0.0662, 0.0606, 0.0721, 0.0421], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,793][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([1.2071e-02, 6.3436e-02, 2.0639e-01, 2.7011e-02, 1.8135e-03, 3.9874e-02,
        7.1728e-03, 9.1491e-02, 5.1191e-01, 1.8423e-02, 1.6979e-02, 2.1569e-04,
        3.2109e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,799][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0423, 0.0262, 0.0198, 0.0771, 0.0311, 0.0823, 0.1111, 0.0674, 0.1290,
        0.1912, 0.1716, 0.0296, 0.0212], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,800][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.1149, 0.0660, 0.0995, 0.0447, 0.0392, 0.1177, 0.1136, 0.0293, 0.0652,
        0.0778, 0.0510, 0.1293, 0.0520], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,801][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0523, 0.0675, 0.0113, 0.1293, 0.0134, 0.0829, 0.1262, 0.0638, 0.0148,
        0.2269, 0.1586, 0.0408, 0.0121], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,801][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0426, 0.2444, 0.0126, 0.0358, 0.0212, 0.0535, 0.3433, 0.0107, 0.0178,
        0.1475, 0.0256, 0.0061, 0.0388], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,805][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0305, 0.0812, 0.1005, 0.0707, 0.0901, 0.0733, 0.0668, 0.0755, 0.0951,
        0.0672, 0.0673, 0.0894, 0.0923], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,811][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0102, 0.1148, 0.2180, 0.0792, 0.0380, 0.1140, 0.0915, 0.0830, 0.0424,
        0.0523, 0.0537, 0.0674, 0.0358], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:01,817][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0715, 0.0714, 0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0713, 0.0715,
        0.0715, 0.0714, 0.0715, 0.0715, 0.0713], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,819][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1111, 0.0405, 0.0040, 0.0262, 0.0198, 0.0433, 0.0305, 0.4543, 0.1387,
        0.0246, 0.0310, 0.0314, 0.0401, 0.0045], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,820][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0555, 0.0974, 0.0816, 0.0503, 0.1014, 0.0679, 0.0630, 0.0701, 0.0966,
        0.0437, 0.0430, 0.0637, 0.0965, 0.0693], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,821][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0604, 0.0758, 0.0400, 0.0976, 0.0608, 0.0819, 0.1020, 0.0803, 0.0513,
        0.0801, 0.1100, 0.0267, 0.0629, 0.0702], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,824][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0201, 0.1074, 0.1120, 0.0550, 0.0857, 0.0699, 0.0432, 0.0453, 0.1203,
        0.0543, 0.0317, 0.0764, 0.0667, 0.1119], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,830][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0166, 0.1778, 0.0372, 0.1484, 0.0035, 0.2239, 0.0571, 0.0739, 0.0555,
        0.0799, 0.0719, 0.0107, 0.0020, 0.0416], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,836][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0164, 0.0159, 0.0233, 0.0570, 0.0400, 0.0722, 0.0827, 0.0605, 0.1740,
        0.1682, 0.1361, 0.0298, 0.0312, 0.0926], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,838][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0770, 0.0721, 0.0367, 0.0910, 0.0983, 0.0872, 0.1051, 0.1572, 0.0440,
        0.0599, 0.0660, 0.0521, 0.0261, 0.0272], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,839][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0627, 0.0733, 0.0095, 0.1095, 0.0154, 0.0822, 0.1853, 0.0344, 0.0162,
        0.2177, 0.1271, 0.0323, 0.0133, 0.0212], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,840][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1478, 0.0350, 0.0601, 0.1010, 0.0469, 0.0722, 0.1369, 0.0464, 0.0317,
        0.0827, 0.0990, 0.0386, 0.0417, 0.0600], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,841][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0242, 0.0700, 0.0944, 0.0609, 0.0880, 0.0675, 0.0597, 0.0712, 0.0910,
        0.0598, 0.0588, 0.0872, 0.0906, 0.0768], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,846][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0201, 0.1132, 0.1228, 0.0862, 0.0231, 0.1279, 0.0887, 0.0792, 0.0428,
        0.0635, 0.0583, 0.0659, 0.0181, 0.0901], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:01,852][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0668, 0.0666, 0.0666, 0.0666, 0.0667, 0.0666, 0.0667, 0.0666, 0.0668,
        0.0667, 0.0667, 0.0667, 0.0668, 0.0666, 0.0666], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,858][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0893, 0.0078, 0.0080, 0.0138, 0.0474, 0.1029, 0.0399, 0.2695, 0.1849,
        0.0045, 0.0184, 0.0386, 0.1058, 0.0540, 0.0152], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,859][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0501, 0.0769, 0.0750, 0.0435, 0.0971, 0.0613, 0.0598, 0.0807, 0.0944,
        0.0379, 0.0378, 0.0718, 0.0945, 0.0584, 0.0608], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,859][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0546, 0.0649, 0.0362, 0.0830, 0.0527, 0.0747, 0.0956, 0.0724, 0.0506,
        0.0710, 0.0928, 0.0235, 0.0553, 0.0623, 0.1105], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,860][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0357, 0.0699, 0.1088, 0.0520, 0.0978, 0.0621, 0.0582, 0.0704, 0.0954,
        0.0492, 0.0359, 0.0840, 0.0825, 0.0566, 0.0415], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,864][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0232, 0.1615, 0.0076, 0.1287, 0.0010, 0.1854, 0.0708, 0.0842, 0.0158,
        0.0434, 0.0441, 0.0093, 0.0003, 0.0129, 0.2118], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,870][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0303, 0.0188, 0.0222, 0.0499, 0.0319, 0.0631, 0.0688, 0.0468, 0.1245,
        0.1294, 0.1061, 0.0237, 0.0252, 0.0714, 0.1879], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,876][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1049, 0.0641, 0.0630, 0.0769, 0.1050, 0.1383, 0.1054, 0.0843, 0.0512,
        0.0353, 0.0354, 0.0389, 0.0258, 0.0525, 0.0189], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,878][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0419, 0.0622, 0.0084, 0.0952, 0.0137, 0.0622, 0.1369, 0.0319, 0.0124,
        0.1931, 0.1119, 0.0322, 0.0119, 0.0162, 0.1699], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,879][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2041, 0.0202, 0.0370, 0.0708, 0.0359, 0.0881, 0.1625, 0.0386, 0.0341,
        0.0435, 0.0630, 0.0492, 0.0255, 0.1021, 0.0255], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,879][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0230, 0.0664, 0.0899, 0.0571, 0.0832, 0.0633, 0.0567, 0.0668, 0.0862,
        0.0565, 0.0548, 0.0813, 0.0856, 0.0728, 0.0564], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,880][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0228, 0.1070, 0.1040, 0.0837, 0.0202, 0.1183, 0.0843, 0.0755, 0.0377,
        0.0641, 0.0591, 0.0609, 0.0153, 0.0763, 0.0710], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:01,884][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:01,887][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12966],
        [10928],
        [  150],
        [10762],
        [ 1277],
        [ 7237],
        [14917],
        [17134],
        [ 9781],
        [ 6942],
        [14663],
        [10214],
        [ 3472],
        [ 7860],
        [12590]], device='cuda:0')
[2024-07-24 10:24:01,890][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[24524],
        [28275],
        [    5],
        [30156],
        [  919],
        [24838],
        [33901],
        [37549],
        [35612],
        [28200],
        [28263],
        [23963],
        [ 1493],
        [23414],
        [20457]], device='cuda:0')
[2024-07-24 10:24:01,892][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1337],
        [ 677],
        [4331],
        [3910],
        [7439],
        [ 960],
        [1088],
        [3622],
        [2009],
        [ 855],
        [1325],
        [1043],
        [2578],
        [ 709],
        [ 737]], device='cuda:0')
[2024-07-24 10:24:01,895][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[40801],
        [39459],
        [39539],
        [38650],
        [39109],
        [38520],
        [38438],
        [38427],
        [38696],
        [38089],
        [38310],
        [37939],
        [38497],
        [37986],
        [37848]], device='cuda:0')
[2024-07-24 10:24:01,897][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17737],
        [21509],
        [21847],
        [23511],
        [24341],
        [24396],
        [25627],
        [25625],
        [25933],
        [26690],
        [26991],
        [26529],
        [26877],
        [26718],
        [27025]], device='cuda:0')
[2024-07-24 10:24:01,900][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[38826],
        [24117],
        [21636],
        [26549],
        [25549],
        [26299],
        [28128],
        [29497],
        [27937],
        [28595],
        [28735],
        [29418],
        [28090],
        [26370],
        [26631]], device='cuda:0')
[2024-07-24 10:24:01,902][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 2090],
        [ 2518],
        [10722],
        [ 8508],
        [13174],
        [10258],
        [ 6244],
        [ 7534],
        [ 9346],
        [13093],
        [13318],
        [13593],
        [13178],
        [17321],
        [20454]], device='cuda:0')
[2024-07-24 10:24:01,904][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[10094],
        [12511],
        [33234],
        [17312],
        [43998],
        [14647],
        [26339],
        [16262],
        [21226],
        [32972],
        [33995],
        [26521],
        [41626],
        [25397],
        [35930]], device='cuda:0')
[2024-07-24 10:24:01,905][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12138],
        [13471],
        [11508],
        [16440],
        [16862],
        [17059],
        [12672],
        [13449],
        [13432],
        [14277],
        [15233],
        [17308],
        [16861],
        [15131],
        [15276]], device='cuda:0')
[2024-07-24 10:24:01,908][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[27486],
        [27713],
        [  585],
        [ 2408],
        [  356],
        [ 1887],
        [ 2354],
        [12642],
        [13066],
        [ 1492],
        [ 3016],
        [10102],
        [ 7844],
        [ 4237],
        [ 7967]], device='cuda:0')
[2024-07-24 10:24:01,911][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11405],
        [13396],
        [13753],
        [13758],
        [13429],
        [13788],
        [13466],
        [13698],
        [13493],
        [13579],
        [13519],
        [13752],
        [13373],
        [13603],
        [13548]], device='cuda:0')
[2024-07-24 10:24:01,913][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[2715],
        [2073],
        [1762],
        [1602],
        [1483],
        [1427],
        [1323],
        [1254],
        [1234],
        [1258],
        [1235],
        [1226],
        [1212],
        [1167],
        [1173]], device='cuda:0')
[2024-07-24 10:24:01,916][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[7820],
        [9526],
        [7842],
        [8219],
        [7619],
        [8708],
        [8373],
        [8485],
        [8875],
        [8862],
        [8875],
        [8527],
        [8155],
        [8175],
        [8262]], device='cuda:0')
[2024-07-24 10:24:01,918][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10158],
        [ 9106],
        [21393],
        [17006],
        [30375],
        [32994],
        [45847],
        [28600],
        [22172],
        [15396],
        [13353],
        [39203],
        [30958],
        [35155],
        [21797]], device='cuda:0')
[2024-07-24 10:24:01,921][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15882],
        [25378],
        [28765],
        [35056],
        [18990],
        [45017],
        [42355],
        [43426],
        [24858],
        [31430],
        [34976],
        [47054],
        [31051],
        [33854],
        [32973]], device='cuda:0')
[2024-07-24 10:24:01,923][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[37746],
        [37742],
        [37754],
        [37750],
        [37737],
        [37744],
        [37744],
        [37741],
        [37747],
        [37745],
        [37748],
        [37748],
        [37752],
        [37751],
        [37750]], device='cuda:0')
[2024-07-24 10:24:01,926][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7301],
        [ 7133],
        [ 6147],
        [ 5363],
        [ 6806],
        [ 4702],
        [ 5697],
        [22377],
        [ 7221],
        [ 1251],
        [ 1611],
        [ 1620],
        [ 1183],
        [ 4257],
        [ 2959]], device='cuda:0')
[2024-07-24 10:24:01,927][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[1705],
        [2170],
        [2314],
        [2348],
        [2518],
        [2475],
        [2389],
        [2345],
        [2349],
        [2349],
        [2366],
        [2336],
        [2376],
        [2296],
        [2354]], device='cuda:0')
[2024-07-24 10:24:01,928][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[23405],
        [15453],
        [10640],
        [14249],
        [11585],
        [ 9235],
        [10144],
        [ 9249],
        [ 9085],
        [10329],
        [11583],
        [11675],
        [10740],
        [ 9315],
        [10731]], device='cuda:0')
[2024-07-24 10:24:01,930][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[28153],
        [20504],
        [19281],
        [19018],
        [19267],
        [24871],
        [28062],
        [28377],
        [30946],
        [29206],
        [26822],
        [24547],
        [23224],
        [23049],
        [26600]], device='cuda:0')
[2024-07-24 10:24:01,932][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22818],
        [22680],
        [29852],
        [25026],
        [32940],
        [25821],
        [25818],
        [24891],
        [27587],
        [25232],
        [26693],
        [16752],
        [43923],
        [24803],
        [20552]], device='cuda:0')
[2024-07-24 10:24:01,935][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[19548],
        [18978],
        [18634],
        [20299],
        [20957],
        [22440],
        [22232],
        [22380],
        [23420],
        [23208],
        [23556],
        [23448],
        [23449],
        [23712],
        [23446]], device='cuda:0')
[2024-07-24 10:24:01,938][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 2579],
        [ 2990],
        [ 5303],
        [ 5969],
        [ 8407],
        [11540],
        [11719],
        [10886],
        [11592],
        [ 8968],
        [ 6722],
        [ 6649],
        [ 3563],
        [ 3111],
        [ 4347]], device='cuda:0')
[2024-07-24 10:24:01,940][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12414],
        [12534],
        [11958],
        [10429],
        [10711],
        [11569],
        [11676],
        [11001],
        [10816],
        [10798],
        [10192],
        [ 9888],
        [ 9816],
        [10327],
        [ 9389]], device='cuda:0')
[2024-07-24 10:24:01,943][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8207],
        [ 8724],
        [14271],
        [ 9456],
        [11722],
        [ 3237],
        [ 1400],
        [ 1874],
        [ 1458],
        [ 5187],
        [ 2471],
        [ 9079],
        [ 9911],
        [ 1315],
        [ 3762]], device='cuda:0')
[2024-07-24 10:24:01,945][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[4987],
        [4136],
        [4399],
        [4376],
        [4350],
        [4186],
        [4270],
        [4315],
        [4445],
        [4405],
        [4384],
        [4461],
        [4462],
        [4481],
        [4431]], device='cuda:0')
[2024-07-24 10:24:01,948][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17133],
        [18596],
        [14460],
        [15709],
        [14151],
        [14237],
        [14513],
        [14029],
        [13930],
        [14348],
        [14201],
        [14078],
        [13862],
        [14011],
        [14012]], device='cuda:0')
[2024-07-24 10:24:01,950][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[45409],
        [46514],
        [45899],
        [46559],
        [44475],
        [46559],
        [46745],
        [44658],
        [46658],
        [46754],
        [47436],
        [47609],
        [46121],
        [48380],
        [48299]], device='cuda:0')
[2024-07-24 10:24:01,951][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[19771],
        [23650],
        [45156],
        [21200],
        [41528],
        [ 5703],
        [ 7845],
        [ 9039],
        [27503],
        [19088],
        [17429],
        [ 2776],
        [39950],
        [23317],
        [28022]], device='cuda:0')
[2024-07-24 10:24:01,953][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409],
        [45409]], device='cuda:0')
[2024-07-24 10:24:01,983][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:01,984][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,985][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,985][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,986][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,987][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,987][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,988][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,989][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,989][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,990][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,991][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,991][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:01,992][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4946, 0.5054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,993][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2721, 0.7279], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,994][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,994][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6518, 0.3482], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,995][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5467, 0.4533], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,996][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5736, 0.4264], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,996][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5024, 0.4976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:01,997][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2481, 0.7519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,002][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4718, 0.5282], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,006][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3938, 0.6062], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,012][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2187, 0.7813], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,014][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2083, 0.7917], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,015][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.2603, 0.7039, 0.0358], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,016][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.1992, 0.4077, 0.3931], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,016][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([3.7917e-06, 9.9322e-02, 9.0067e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,020][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.6376, 0.2481, 0.1144], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,026][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.1214, 0.6165, 0.2621], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,030][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.4227, 0.3247, 0.2526], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,034][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.0821, 0.0686, 0.8493], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,035][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.0181, 0.0872, 0.8948], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,036][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.2012, 0.3940, 0.4048], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,036][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.2303, 0.4854, 0.2843], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,040][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.0746, 0.3653, 0.5601], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,046][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.2855, 0.6247, 0.0898], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,051][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0524, 0.4806, 0.4502, 0.0167], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,054][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0466, 0.1868, 0.2543, 0.5123], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,055][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([6.1913e-07, 3.4559e-03, 5.8171e-01, 4.1483e-01], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,056][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5507, 0.2248, 0.1089, 0.1156], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,056][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1425, 0.3975, 0.2694, 0.1905], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,057][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3341, 0.2440, 0.1912, 0.2307], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,061][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0400, 0.0299, 0.6778, 0.2522], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,066][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0029, 0.0047, 0.0739, 0.9186], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,071][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0867, 0.1840, 0.4196, 0.3098], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,075][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0611, 0.1152, 0.0766, 0.7471], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,076][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0661, 0.2512, 0.4589, 0.2238], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,076][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1776, 0.3240, 0.1164, 0.3820], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,077][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1473, 0.2715, 0.3432, 0.2298, 0.0081], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,081][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0853, 0.1885, 0.1901, 0.3984, 0.1377], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,085][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([8.4566e-08, 3.5596e-04, 3.8965e-02, 2.2702e-01, 7.3365e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,089][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.4905, 0.1950, 0.0940, 0.0996, 0.1210], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,095][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.1159, 0.2872, 0.2623, 0.2374, 0.0973], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,096][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.2443, 0.1994, 0.1647, 0.2236, 0.1681], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,097][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0340, 0.0301, 0.2361, 0.1880, 0.5118], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,097][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0018, 0.0057, 0.0485, 0.6788, 0.2651], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,098][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0479, 0.1182, 0.2374, 0.5215, 0.0749], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,102][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0345, 0.0571, 0.0329, 0.8218, 0.0538], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,107][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0324, 0.1749, 0.2995, 0.1495, 0.3436], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,112][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.2008, 0.3340, 0.0467, 0.3510, 0.0675], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,116][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0544, 0.2513, 0.4016, 0.0722, 0.2168, 0.0037], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,117][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0175, 0.0746, 0.1272, 0.2033, 0.1366, 0.4407], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,117][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([9.4432e-09, 6.1008e-05, 9.0322e-03, 6.8796e-02, 7.5871e-01, 1.6340e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,118][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.5139, 0.1829, 0.0762, 0.0877, 0.1059, 0.0333], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,122][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1594, 0.2116, 0.0746, 0.3004, 0.1426, 0.1114], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,127][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2688, 0.1909, 0.1388, 0.1736, 0.1399, 0.0881], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,134][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0110, 0.0115, 0.1971, 0.0979, 0.4710, 0.2115], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,136][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0006, 0.0019, 0.0221, 0.2965, 0.1296, 0.5492], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,137][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0720, 0.1934, 0.1852, 0.2236, 0.1367, 0.1891], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,137][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0139, 0.0368, 0.0283, 0.2246, 0.0481, 0.6483], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,138][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0352, 0.1461, 0.2492, 0.1142, 0.2847, 0.1705], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,140][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1428, 0.2185, 0.0423, 0.2936, 0.0674, 0.2353], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,146][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0505, 0.3044, 0.0490, 0.4358, 0.1262, 0.0231, 0.0111],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,152][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0136, 0.0594, 0.0892, 0.1620, 0.1062, 0.3319, 0.2377],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,155][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([6.4516e-09, 1.3580e-05, 9.7596e-04, 2.0558e-02, 2.0033e-01, 5.8923e-01,
        1.8889e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,156][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.5012, 0.1781, 0.0741, 0.0817, 0.1022, 0.0314, 0.0312],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,157][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1377, 0.1872, 0.0670, 0.2211, 0.1604, 0.1277, 0.0989],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,158][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2406, 0.1721, 0.1249, 0.1563, 0.1239, 0.0860, 0.0962],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,159][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0068, 0.0063, 0.1487, 0.0576, 0.4021, 0.1494, 0.2290],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,162][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.9188e-04, 7.2960e-04, 9.2041e-03, 1.2944e-01, 5.2386e-02, 2.0783e-01,
        6.0003e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,168][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0263, 0.0556, 0.2146, 0.2014, 0.1244, 0.3260, 0.0517],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,173][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0116, 0.0245, 0.0179, 0.1311, 0.0286, 0.4354, 0.3509],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,176][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0327, 0.1200, 0.2159, 0.1067, 0.2375, 0.1529, 0.1343],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,177][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0902, 0.1464, 0.0335, 0.2047, 0.0581, 0.2068, 0.2603],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,178][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0676, 0.3321, 0.1316, 0.1284, 0.0572, 0.0246, 0.2209, 0.0376],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,179][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0170, 0.0585, 0.0768, 0.1339, 0.0742, 0.2120, 0.2067, 0.2209],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,180][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([7.4342e-10, 4.5595e-07, 8.3254e-05, 3.7459e-04, 8.5367e-03, 3.0745e-02,
        1.2948e-01, 8.3078e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,185][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.3956, 0.1662, 0.0853, 0.0817, 0.1103, 0.0379, 0.0401, 0.0829],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,191][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1086, 0.1651, 0.1213, 0.1849, 0.0545, 0.1326, 0.1694, 0.0636],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,195][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1689, 0.1377, 0.1177, 0.1386, 0.1179, 0.0955, 0.1026, 0.1211],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,197][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0093, 0.0080, 0.1135, 0.0466, 0.2947, 0.1212, 0.1818, 0.2248],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,198][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([2.4947e-04, 5.7555e-04, 5.6153e-03, 8.8902e-02, 3.2397e-02, 1.2892e-01,
        3.4586e-01, 3.9748e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,199][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0231, 0.0620, 0.1119, 0.1703, 0.0864, 0.3659, 0.1177, 0.0628],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,200][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0206, 0.0205, 0.0126, 0.1164, 0.0186, 0.3700, 0.3520, 0.0893],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,205][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0214, 0.0992, 0.1686, 0.0829, 0.1939, 0.1251, 0.1043, 0.2046],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,211][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1409, 0.1615, 0.0257, 0.2006, 0.0450, 0.1191, 0.1712, 0.1361],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,215][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0411, 0.2158, 0.1199, 0.1160, 0.0665, 0.1270, 0.1123, 0.1883, 0.0131],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,217][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0173, 0.0493, 0.0536, 0.1117, 0.0403, 0.1608, 0.2150, 0.2637, 0.0883],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,218][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.1621e-11, 8.4491e-08, 1.6420e-05, 8.0270e-05, 1.8910e-03, 2.4536e-03,
        1.4217e-02, 6.4598e-01, 3.3536e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,219][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.4280, 0.1649, 0.0752, 0.0764, 0.1004, 0.0318, 0.0316, 0.0634, 0.0284],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,220][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0547, 0.1266, 0.0826, 0.1585, 0.1448, 0.1349, 0.1631, 0.0833, 0.0515],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,223][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1466, 0.1226, 0.1020, 0.1365, 0.1043, 0.0883, 0.0951, 0.1129, 0.0917],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,228][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0131, 0.0110, 0.1005, 0.0468, 0.1933, 0.1168, 0.1660, 0.1666, 0.1859],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,231][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([1.7148e-04, 4.4131e-04, 4.2665e-03, 6.7282e-02, 2.2864e-02, 8.9514e-02,
        2.4694e-01, 2.6885e-01, 2.9967e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,236][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0233, 0.0558, 0.1439, 0.1485, 0.0597, 0.3361, 0.1164, 0.0701, 0.0463],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,238][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0094, 0.0112, 0.0067, 0.0922, 0.0100, 0.3655, 0.4103, 0.0724, 0.0222],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,239][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0182, 0.0834, 0.1388, 0.0675, 0.1554, 0.1061, 0.0857, 0.1676, 0.1772],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,240][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1514, 0.1638, 0.0227, 0.1934, 0.0384, 0.1138, 0.1506, 0.1243, 0.0417],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,243][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0777, 0.0444, 0.1343, 0.1391, 0.0640, 0.1663, 0.1197, 0.1908, 0.0365,
        0.0272], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,248][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0082, 0.0348, 0.0483, 0.0954, 0.0519, 0.1822, 0.1531, 0.1436, 0.1140,
        0.1686], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,251][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([6.9274e-11, 2.9180e-09, 2.8026e-06, 2.7728e-05, 4.1789e-04, 5.6729e-04,
        2.5660e-03, 1.5571e-01, 2.1124e-01, 6.2946e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,256][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5240, 0.1574, 0.0572, 0.0676, 0.0821, 0.0224, 0.0211, 0.0403, 0.0142,
        0.0137], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,258][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0802, 0.0795, 0.1189, 0.1140, 0.1025, 0.0579, 0.1673, 0.0738, 0.0744,
        0.1315], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,259][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1724, 0.1221, 0.0898, 0.1201, 0.0917, 0.0626, 0.0709, 0.0950, 0.0752,
        0.1001], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,260][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0048, 0.0047, 0.0855, 0.0338, 0.2038, 0.0928, 0.1251, 0.1538, 0.1464,
        0.1491], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,260][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([8.1647e-05, 1.4971e-04, 1.6839e-03, 2.4802e-02, 9.3237e-03, 3.7702e-02,
        9.5374e-02, 1.0650e-01, 1.2651e-01, 5.9788e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,264][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0298, 0.0443, 0.1144, 0.1290, 0.0621, 0.2425, 0.0968, 0.0847, 0.1008,
        0.0956], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,269][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0105, 0.0156, 0.0099, 0.0834, 0.0154, 0.2670, 0.2585, 0.0884, 0.0413,
        0.2100], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,274][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0197, 0.0760, 0.1303, 0.0680, 0.1438, 0.0996, 0.0830, 0.1524, 0.1603,
        0.0669], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,279][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0672, 0.0972, 0.0268, 0.1377, 0.0408, 0.1298, 0.1722, 0.1489, 0.0543,
        0.1252], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,279][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0188, 0.1857, 0.1592, 0.0103, 0.1363, 0.0320, 0.0878, 0.1899, 0.0408,
        0.1271, 0.0122], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,280][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0047, 0.0243, 0.0394, 0.0749, 0.0496, 0.1619, 0.1117, 0.0899, 0.1030,
        0.1378, 0.2028], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,281][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.8869e-11, 6.9786e-10, 2.3160e-07, 1.1488e-07, 4.5255e-05, 1.5003e-05,
        1.1654e-04, 3.9171e-03, 8.4883e-03, 1.4718e-01, 8.4024e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,286][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4754, 0.1556, 0.0614, 0.0698, 0.0855, 0.0251, 0.0243, 0.0460, 0.0176,
        0.0158, 0.0235], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,291][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0408, 0.1550, 0.0974, 0.0727, 0.1158, 0.0435, 0.1319, 0.0351, 0.0257,
        0.2239, 0.0582], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,296][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1707, 0.1184, 0.0859, 0.1074, 0.0870, 0.0570, 0.0638, 0.0867, 0.0693,
        0.0859, 0.0678], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,299][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0040, 0.0041, 0.0679, 0.0267, 0.1553, 0.0733, 0.0984, 0.1177, 0.1050,
        0.1230, 0.2245], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,299][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([4.9304e-05, 7.6078e-05, 7.5253e-04, 1.0428e-02, 4.2001e-03, 1.6431e-02,
        4.0931e-02, 4.2243e-02, 5.2217e-02, 2.6041e-01, 5.7226e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,300][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0230, 0.0504, 0.1190, 0.0762, 0.0687, 0.2122, 0.0961, 0.0840, 0.0755,
        0.1397, 0.0553], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,301][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0053, 0.0131, 0.0087, 0.0535, 0.0138, 0.1591, 0.1446, 0.0698, 0.0368,
        0.1420, 0.3533], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,305][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0181, 0.0696, 0.1288, 0.0624, 0.1417, 0.0963, 0.0791, 0.1379, 0.1561,
        0.0611, 0.0489], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,309][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0679, 0.0884, 0.0317, 0.1196, 0.0465, 0.1013, 0.1235, 0.1495, 0.0669,
        0.0878, 0.1167], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,315][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0314, 0.3190, 0.0347, 0.1310, 0.0132, 0.0251, 0.0205, 0.0285, 0.0337,
        0.2213, 0.1342, 0.0074], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,319][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0096, 0.0301, 0.0387, 0.0720, 0.0333, 0.1131, 0.1325, 0.1548, 0.0732,
        0.1201, 0.1650, 0.0573], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,320][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([7.5433e-12, 1.9384e-10, 1.0923e-08, 1.8263e-07, 1.6217e-06, 2.3559e-06,
        2.6099e-05, 2.0373e-04, 1.2458e-03, 2.3333e-02, 8.5380e-01, 1.2138e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,321][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.4064, 0.1441, 0.0645, 0.0674, 0.0879, 0.0262, 0.0267, 0.0549, 0.0241,
        0.0180, 0.0260, 0.0539], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,322][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0412, 0.1184, 0.0404, 0.1160, 0.0137, 0.0875, 0.0429, 0.2512, 0.0217,
        0.1473, 0.0745, 0.0452], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,325][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1069, 0.0870, 0.0751, 0.0988, 0.0807, 0.0628, 0.0687, 0.0888, 0.0755,
        0.0928, 0.0726, 0.0902], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,331][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0086, 0.0077, 0.0414, 0.0318, 0.0678, 0.0649, 0.0881, 0.0785, 0.0823,
        0.1651, 0.2542, 0.1097], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,335][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([5.1619e-05, 1.2717e-04, 8.2699e-04, 1.0720e-02, 4.3030e-03, 1.5904e-02,
        3.7543e-02, 4.3041e-02, 4.7271e-02, 2.3809e-01, 4.5072e-01, 1.5140e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,341][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0172, 0.0418, 0.0593, 0.1153, 0.0278, 0.2701, 0.0537, 0.0669, 0.0772,
        0.1215, 0.0975, 0.0518], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,342][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0044, 0.0054, 0.0033, 0.0380, 0.0053, 0.1512, 0.1477, 0.0373, 0.0156,
        0.1121, 0.4381, 0.0416], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,343][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0116, 0.0650, 0.1054, 0.0526, 0.1297, 0.0821, 0.0658, 0.1243, 0.1450,
        0.0559, 0.0405, 0.1221], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,344][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1289, 0.1348, 0.0199, 0.1406, 0.0335, 0.0740, 0.1042, 0.0997, 0.0421,
        0.0759, 0.1348, 0.0116], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,347][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0673, 0.0922, 0.1197, 0.1175, 0.0029, 0.1090, 0.0634, 0.0981, 0.0204,
        0.1161, 0.1704, 0.0198, 0.0032], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,353][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0161, 0.0322, 0.0326, 0.0647, 0.0226, 0.0851, 0.1421, 0.2314, 0.0551,
        0.1050, 0.1363, 0.0593, 0.0175], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,357][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([2.0148e-12, 5.2456e-11, 6.1175e-09, 2.7432e-08, 1.8156e-07, 1.6209e-06,
        2.8468e-06, 4.5138e-05, 2.1760e-04, 3.3868e-03, 1.1011e-01, 2.1779e-01,
        6.6844e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,361][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.5048, 0.1455, 0.0513, 0.0560, 0.0709, 0.0171, 0.0170, 0.0384, 0.0140,
        0.0106, 0.0167, 0.0382, 0.0196], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,362][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0384, 0.1019, 0.0813, 0.0849, 0.0309, 0.0842, 0.0910, 0.0426, 0.0551,
        0.1573, 0.0706, 0.1355, 0.0264], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,363][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1100, 0.0885, 0.0705, 0.1022, 0.0739, 0.0568, 0.0629, 0.0840, 0.0681,
        0.0915, 0.0655, 0.0865, 0.0396], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,364][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0060, 0.0055, 0.0282, 0.0261, 0.0537, 0.0604, 0.0851, 0.0802, 0.0444,
        0.1405, 0.2091, 0.0890, 0.1718], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,365][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([3.5300e-05, 1.5217e-04, 8.4923e-04, 1.1344e-02, 3.9162e-03, 1.5560e-02,
        3.6472e-02, 3.4465e-02, 3.9502e-02, 1.9677e-01, 4.2110e-01, 1.5022e-01,
        8.9622e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,370][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0093, 0.0223, 0.0457, 0.1086, 0.0140, 0.3129, 0.0482, 0.0499, 0.0664,
        0.1048, 0.0795, 0.1316, 0.0068], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,376][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0009, 0.0014, 0.0007, 0.0204, 0.0012, 0.1423, 0.1283, 0.0229, 0.0060,
        0.0873, 0.5586, 0.0272, 0.0028], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,382][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0096, 0.0558, 0.0956, 0.0476, 0.1104, 0.0763, 0.0546, 0.1132, 0.1368,
        0.0475, 0.0357, 0.1116, 0.1052], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,383][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0630, 0.0897, 0.0121, 0.0956, 0.0211, 0.1063, 0.1146, 0.0671, 0.0298,
        0.0930, 0.1174, 0.0121, 0.1780], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,384][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0117, 0.1067, 0.0140, 0.1166, 0.0426, 0.0852, 0.0357, 0.0368, 0.1332,
        0.1237, 0.1658, 0.0755, 0.0414, 0.0109], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,384][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0046, 0.0196, 0.0303, 0.0540, 0.0312, 0.1100, 0.0810, 0.0711, 0.0643,
        0.0930, 0.1299, 0.0381, 0.0322, 0.2408], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,386][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([7.1625e-13, 1.1295e-11, 8.2234e-10, 7.6683e-09, 5.2069e-08, 3.2272e-07,
        5.7417e-07, 8.3613e-06, 5.8130e-05, 1.9761e-03, 6.7185e-02, 1.3638e-01,
        4.1428e-01, 3.8011e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,392][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.4004, 0.1421, 0.0597, 0.0669, 0.0847, 0.0260, 0.0248, 0.0453, 0.0181,
        0.0167, 0.0244, 0.0485, 0.0281, 0.0144], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,398][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1420, 0.1049, 0.0446, 0.0882, 0.0393, 0.0682, 0.0739, 0.0705, 0.0179,
        0.1329, 0.0788, 0.0892, 0.0327, 0.0171], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,402][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1274, 0.0946, 0.0709, 0.0884, 0.0747, 0.0479, 0.0549, 0.0759, 0.0622,
        0.0763, 0.0602, 0.0828, 0.0452, 0.0387], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,403][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0027, 0.0027, 0.0355, 0.0150, 0.0809, 0.0334, 0.0482, 0.0627, 0.0555,
        0.0610, 0.1137, 0.1092, 0.3093, 0.0703], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,404][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([2.4289e-05, 7.0196e-05, 4.8524e-04, 6.2620e-03, 2.2690e-03, 8.5692e-03,
        2.2196e-02, 2.2003e-02, 2.5413e-02, 1.3470e-01, 2.6434e-01, 9.9223e-02,
        5.5641e-02, 3.5881e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,405][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0242, 0.0659, 0.0960, 0.0873, 0.0684, 0.1010, 0.0387, 0.0564, 0.0540,
        0.1303, 0.0710, 0.1031, 0.0481, 0.0556], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,408][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0046, 0.0076, 0.0051, 0.0403, 0.0083, 0.1104, 0.1238, 0.0415, 0.0182,
        0.1053, 0.3264, 0.0611, 0.0173, 0.1300], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,414][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0128, 0.0528, 0.0940, 0.0417, 0.0970, 0.0649, 0.0575, 0.1087, 0.1117,
        0.0452, 0.0331, 0.1056, 0.0946, 0.0805], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,420][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0685, 0.0762, 0.0096, 0.1005, 0.0200, 0.0816, 0.1047, 0.0642, 0.0213,
        0.0819, 0.1200, 0.0097, 0.1907, 0.0511], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,422][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0148, 0.1132, 0.0345, 0.1206, 0.0741, 0.0334, 0.0334, 0.0480, 0.0257,
        0.0925, 0.1821, 0.0977, 0.1004, 0.0256, 0.0039], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,423][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0038, 0.0166, 0.0270, 0.0474, 0.0312, 0.0947, 0.0710, 0.0597, 0.0598,
        0.0830, 0.1200, 0.0337, 0.0348, 0.2087, 0.1085], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,424][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.4975e-13, 6.2279e-13, 4.7332e-11, 3.1128e-10, 3.6644e-09, 1.4504e-08,
        3.6894e-08, 1.1311e-06, 6.3521e-06, 5.8296e-05, 2.0717e-03, 3.7306e-03,
        2.4755e-02, 2.5607e-01, 7.1331e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,425][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3011, 0.1240, 0.0621, 0.0665, 0.0841, 0.0306, 0.0315, 0.0562, 0.0262,
        0.0215, 0.0300, 0.0561, 0.0369, 0.0211, 0.0520], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,428][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0390, 0.0745, 0.0577, 0.0935, 0.0694, 0.0788, 0.0671, 0.0546, 0.0768,
        0.1187, 0.0771, 0.0511, 0.0568, 0.0441, 0.0406], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,434][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1355, 0.0916, 0.0661, 0.0779, 0.0679, 0.0448, 0.0509, 0.0694, 0.0565,
        0.0656, 0.0563, 0.0755, 0.0449, 0.0402, 0.0569], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,440][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0031, 0.0039, 0.0297, 0.0105, 0.0661, 0.0330, 0.0364, 0.0364, 0.0444,
        0.0473, 0.0857, 0.1286, 0.3073, 0.0853, 0.0826], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,442][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.3370e-05, 2.3455e-05, 1.6243e-04, 2.4948e-03, 8.5033e-04, 3.4492e-03,
        8.8945e-03, 8.5080e-03, 9.3966e-03, 5.1427e-02, 1.1061e-01, 3.9811e-02,
        2.1902e-02, 1.7620e-01, 5.6625e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,443][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0123, 0.0283, 0.0985, 0.0747, 0.0342, 0.1629, 0.0494, 0.0364, 0.0476,
        0.0858, 0.0686, 0.0768, 0.0249, 0.1872, 0.0123], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,444][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0050, 0.0089, 0.0062, 0.0342, 0.0098, 0.0839, 0.0802, 0.0398, 0.0225,
        0.0823, 0.2014, 0.0530, 0.0191, 0.1199, 0.2338], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,445][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0127, 0.0502, 0.0839, 0.0454, 0.0922, 0.0644, 0.0555, 0.0963, 0.1048,
        0.0473, 0.0371, 0.0931, 0.0905, 0.0826, 0.0438], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,448][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0344, 0.0440, 0.0118, 0.0655, 0.0215, 0.0683, 0.0791, 0.0747, 0.0276,
        0.0559, 0.0707, 0.0094, 0.2197, 0.0572, 0.1602], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,475][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:02,477][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,480][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,480][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,481][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,481][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,481][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,481][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,482][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,482][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,482][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,483][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,483][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,483][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2296, 0.7704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,484][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6159, 0.3841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,484][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,484][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4674, 0.5326], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,485][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7879, 0.2121], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,485][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5175, 0.4825], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,485][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3684, 0.6316], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,487][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7416, 0.2584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,491][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4911, 0.5089], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,495][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4679, 0.5321], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,499][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4134, 0.5866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,499][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4847, 0.5153], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,499][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.0598, 0.5173, 0.4229], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,500][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.3108, 0.5280, 0.1613], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,500][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([3.7917e-06, 9.9322e-02, 9.0067e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,500][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.1582, 0.2330, 0.6088], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,501][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.4994, 0.4203, 0.0804], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,501][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.3527, 0.4721, 0.1752], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,501][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.1352, 0.2924, 0.5724], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,502][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.4096, 0.3391, 0.2513], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,503][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.3715, 0.4315, 0.1970], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,506][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.2099, 0.3287, 0.4614], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,512][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.1886, 0.3415, 0.4699], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,516][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.3188, 0.3446, 0.3366], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,520][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0325, 0.2550, 0.6489, 0.0636], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,520][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3633, 0.3164, 0.1339, 0.1863], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,520][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([6.1913e-07, 3.4559e-03, 5.8171e-01, 4.1483e-01], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,521][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0987, 0.1469, 0.5008, 0.2536], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,521][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4923, 0.3066, 0.0901, 0.1111], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,522][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1466, 0.2196, 0.5405, 0.0934], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,522][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1501, 0.2608, 0.4418, 0.1473], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,522][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5360, 0.1682, 0.2538, 0.0420], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,525][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2193, 0.2899, 0.3683, 0.1225], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,525][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1019, 0.1939, 0.5524, 0.1517], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,526][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1530, 0.2224, 0.2635, 0.3611], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,526][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2371, 0.2558, 0.2494, 0.2577], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,526][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0302, 0.3975, 0.4702, 0.0666, 0.0356], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,527][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.1044, 0.1344, 0.0866, 0.1600, 0.5146], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,527][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([8.4566e-08, 3.5596e-04, 3.8965e-02, 2.2702e-01, 7.3365e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,532][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0488, 0.0821, 0.3668, 0.2186, 0.2836], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,536][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.4547, 0.2081, 0.1487, 0.1529, 0.0356], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,542][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0996, 0.1564, 0.3982, 0.3144, 0.0314], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,542][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0600, 0.1609, 0.3643, 0.0888, 0.3260], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,543][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2488, 0.3707, 0.1653, 0.0594, 0.1558], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,543][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1763, 0.2569, 0.2518, 0.2497, 0.0654], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,543][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0666, 0.1357, 0.4225, 0.1584, 0.2168], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,544][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.1118, 0.1736, 0.2313, 0.3154, 0.1679], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,544][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.1885, 0.2059, 0.1997, 0.2061, 0.1998], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,544][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0285, 0.2189, 0.5505, 0.0541, 0.1378, 0.0101], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,545][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2373, 0.1660, 0.1097, 0.1721, 0.2763, 0.0387], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,545][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([9.4432e-09, 6.1008e-05, 9.0322e-03, 6.8796e-02, 7.5871e-01, 1.6340e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,548][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0739, 0.0888, 0.2263, 0.1654, 0.2892, 0.1563], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,553][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.4753, 0.1899, 0.0324, 0.2178, 0.0413, 0.0434], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,558][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1072, 0.1469, 0.2612, 0.2055, 0.2440, 0.0352], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,563][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0889, 0.1694, 0.2548, 0.0824, 0.2593, 0.1453], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,563][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2625, 0.2331, 0.1636, 0.0461, 0.2140, 0.0806], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,563][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1947, 0.3337, 0.1828, 0.1002, 0.0867, 0.1020], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,564][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0835, 0.1476, 0.2588, 0.1300, 0.2772, 0.1029], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,564][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1043, 0.1461, 0.1693, 0.2373, 0.1376, 0.2055], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,564][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1532, 0.1637, 0.1582, 0.1635, 0.1611, 0.2004], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,565][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0264, 0.2634, 0.4722, 0.0486, 0.1313, 0.0089, 0.0493],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,565][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2348, 0.1871, 0.0792, 0.1415, 0.2256, 0.0522, 0.0795],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,566][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.4516e-09, 1.3580e-05, 9.7596e-04, 2.0558e-02, 2.0033e-01, 5.8923e-01,
        1.8889e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,569][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0473, 0.0670, 0.1726, 0.1591, 0.2086, 0.1687, 0.1769],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,575][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4602, 0.1487, 0.0377, 0.1822, 0.0800, 0.0563, 0.0350],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,579][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0729, 0.1001, 0.0950, 0.1547, 0.2951, 0.2667, 0.0153],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,583][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0903, 0.1515, 0.2265, 0.0903, 0.1945, 0.1515, 0.0953],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,583][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2994, 0.1780, 0.1651, 0.0410, 0.1918, 0.0658, 0.0589],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,584][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0968, 0.1276, 0.2208, 0.1386, 0.1020, 0.2764, 0.0378],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,584][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0659, 0.1268, 0.2565, 0.1048, 0.2198, 0.1526, 0.0735],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,584][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0765, 0.1114, 0.1293, 0.1826, 0.1016, 0.1573, 0.2412],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,585][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1336, 0.1431, 0.1325, 0.1393, 0.1361, 0.1662, 0.1492],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,585][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0219, 0.2141, 0.5063, 0.0511, 0.0748, 0.0131, 0.0827, 0.0361],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,585][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.3598, 0.1790, 0.0385, 0.1874, 0.1218, 0.0083, 0.0907, 0.0145],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,586][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([7.4342e-10, 4.5595e-07, 8.3254e-05, 3.7459e-04, 8.5367e-03, 3.0745e-02,
        1.2948e-01, 8.3078e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,589][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0284, 0.0356, 0.1257, 0.1107, 0.1647, 0.1649, 0.2085, 0.1615],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,595][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.3741, 0.1659, 0.1037, 0.1648, 0.0245, 0.0579, 0.1034, 0.0056],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,600][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0430, 0.0519, 0.1248, 0.1351, 0.3141, 0.1283, 0.1905, 0.0124],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,603][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0599, 0.1229, 0.2041, 0.0722, 0.1726, 0.1617, 0.0812, 0.1255],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,604][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.2727, 0.2098, 0.1285, 0.0411, 0.1231, 0.0597, 0.0402, 0.1249],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,604][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1039, 0.1749, 0.1750, 0.1045, 0.0853, 0.2462, 0.0693, 0.0408],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,604][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0645, 0.1051, 0.1627, 0.1169, 0.1816, 0.1625, 0.1234, 0.0834],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,605][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0873, 0.1011, 0.1172, 0.1488, 0.0823, 0.1143, 0.1841, 0.1649],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,605][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1120, 0.1246, 0.1154, 0.1174, 0.1159, 0.1398, 0.1360, 0.1389],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,606][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0261, 0.1711, 0.4645, 0.0532, 0.0643, 0.0140, 0.0893, 0.0475, 0.0699],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,606][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.3382, 0.1972, 0.0935, 0.1082, 0.1318, 0.0158, 0.0759, 0.0132, 0.0263],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,607][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.1621e-11, 8.4491e-08, 1.6420e-05, 8.0270e-05, 1.8910e-03, 2.4536e-03,
        1.4217e-02, 6.4598e-01, 3.3536e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,611][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0194, 0.0289, 0.1327, 0.0817, 0.1398, 0.1443, 0.1617, 0.1816, 0.1099],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,616][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.4141, 0.1321, 0.0599, 0.1283, 0.1108, 0.0701, 0.0651, 0.0115, 0.0081],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,622][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0405, 0.0632, 0.2854, 0.1166, 0.1778, 0.0948, 0.1487, 0.0616, 0.0114],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,624][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0501, 0.0959, 0.1759, 0.0544, 0.1616, 0.1114, 0.0754, 0.1150, 0.1604],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,624][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1689, 0.1436, 0.1273, 0.0340, 0.1223, 0.0684, 0.0455, 0.1165, 0.1734],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,625][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1054, 0.1649, 0.1930, 0.0916, 0.0550, 0.2300, 0.0746, 0.0441, 0.0414],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,625][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0407, 0.0821, 0.1757, 0.0851, 0.1990, 0.1428, 0.1119, 0.1075, 0.0551],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,626][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0326, 0.0593, 0.0718, 0.1060, 0.0540, 0.0832, 0.1468, 0.1319, 0.3143],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,626][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1003, 0.1084, 0.1014, 0.1017, 0.1032, 0.1203, 0.1166, 0.1189, 0.1291],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,626][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0497, 0.2256, 0.3776, 0.0473, 0.0985, 0.0133, 0.0477, 0.0342, 0.0514,
        0.0547], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,630][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1964, 0.1320, 0.0735, 0.1096, 0.2202, 0.0270, 0.0953, 0.0291, 0.0566,
        0.0603], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,634][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.9274e-11, 2.9180e-09, 2.8026e-06, 2.7728e-05, 4.1789e-04, 5.6729e-04,
        2.5660e-03, 1.5571e-01, 2.1124e-01, 6.2946e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,638][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0230, 0.0310, 0.0990, 0.0774, 0.1152, 0.1385, 0.1305, 0.1777, 0.1286,
        0.0791], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,644][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3292, 0.1030, 0.1063, 0.1203, 0.0601, 0.0331, 0.1267, 0.0123, 0.0314,
        0.0777], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,645][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0390, 0.0460, 0.1180, 0.1722, 0.1370, 0.1697, 0.0656, 0.0653, 0.0879,
        0.0993], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,645][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0556, 0.0851, 0.1560, 0.0618, 0.1313, 0.0998, 0.0698, 0.0949, 0.1309,
        0.1149], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,645][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2245, 0.0783, 0.1049, 0.0316, 0.1281, 0.0638, 0.0447, 0.1036, 0.2010,
        0.0195], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,646][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1124, 0.1105, 0.1358, 0.0901, 0.0533, 0.1714, 0.0697, 0.0619, 0.1332,
        0.0614], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,646][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0461, 0.0731, 0.1536, 0.0733, 0.1827, 0.1131, 0.0885, 0.0976, 0.0997,
        0.0722], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,647][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0246, 0.0425, 0.0475, 0.0724, 0.0353, 0.0578, 0.0961, 0.0909, 0.2000,
        0.3329], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,647][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0956, 0.1016, 0.0952, 0.0993, 0.0953, 0.1175, 0.1018, 0.0906, 0.1002,
        0.1029], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,650][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0289, 0.2255, 0.3508, 0.0486, 0.0949, 0.0113, 0.0614, 0.0317, 0.0492,
        0.0665, 0.0313], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,655][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1925, 0.1410, 0.0602, 0.0857, 0.2391, 0.0180, 0.0747, 0.0161, 0.0702,
        0.0590, 0.0435], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,659][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.8869e-11, 6.9786e-10, 2.3160e-07, 1.1488e-07, 4.5255e-05, 1.5003e-05,
        1.1654e-04, 3.9171e-03, 8.4883e-03, 1.4718e-01, 8.4024e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,663][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0199, 0.0311, 0.1192, 0.0556, 0.1261, 0.1078, 0.1289, 0.1524, 0.1220,
        0.0856, 0.0514], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,665][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2700, 0.1893, 0.0562, 0.0661, 0.0638, 0.0201, 0.1026, 0.0048, 0.0066,
        0.1688, 0.0518], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,665][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0347, 0.0542, 0.1036, 0.0212, 0.1269, 0.2042, 0.0654, 0.0840, 0.1217,
        0.1659, 0.0183], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,666][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0501, 0.0908, 0.1589, 0.0545, 0.1238, 0.0942, 0.0657, 0.0866, 0.1095,
        0.1152, 0.0509], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,666][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2010, 0.0867, 0.1096, 0.0295, 0.1254, 0.0646, 0.0463, 0.0912, 0.2133,
        0.0180, 0.0144], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,667][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0885, 0.1170, 0.1536, 0.0511, 0.0627, 0.1695, 0.0706, 0.0678, 0.1053,
        0.0865, 0.0274], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,667][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0306, 0.0601, 0.1768, 0.0421, 0.1831, 0.1236, 0.0687, 0.1083, 0.0996,
        0.0778, 0.0293], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,667][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0182, 0.0344, 0.0365, 0.0580, 0.0295, 0.0496, 0.0747, 0.0762, 0.1422,
        0.2164, 0.2644], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,668][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0870, 0.0930, 0.0862, 0.0901, 0.0870, 0.1091, 0.0909, 0.0799, 0.0886,
        0.0946, 0.0935], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:02,671][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0126, 0.1619, 0.4296, 0.0478, 0.0895, 0.0167, 0.0655, 0.0398, 0.0643,
        0.0369, 0.0249, 0.0104], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,677][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.1466, 0.1150, 0.0443, 0.2544, 0.0980, 0.0169, 0.0806, 0.0157, 0.0146,
        0.0529, 0.1461, 0.0149], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,680][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([7.5433e-12, 1.9384e-10, 1.0923e-08, 1.8263e-07, 1.6217e-06, 2.3559e-06,
        2.6099e-05, 2.0373e-04, 1.2458e-03, 2.3333e-02, 8.5380e-01, 1.2138e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,685][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0121, 0.0193, 0.0939, 0.0536, 0.1055, 0.0975, 0.1391, 0.1185, 0.1200,
        0.0848, 0.0681, 0.0876], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,686][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.2734, 0.1993, 0.0211, 0.1350, 0.0035, 0.0431, 0.0211, 0.0909, 0.0050,
        0.1027, 0.0868, 0.0182], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,686][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0274, 0.0365, 0.0827, 0.0859, 0.1232, 0.1988, 0.0542, 0.0372, 0.0757,
        0.1430, 0.1122, 0.0232], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,687][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0358, 0.0716, 0.1393, 0.0404, 0.1291, 0.1003, 0.0462, 0.0861, 0.1250,
        0.0875, 0.0368, 0.1018], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,687][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1446, 0.1541, 0.0884, 0.0336, 0.0969, 0.0715, 0.0379, 0.1076, 0.1623,
        0.0313, 0.0164, 0.0552], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,687][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0878, 0.1314, 0.1039, 0.0794, 0.0294, 0.2069, 0.0394, 0.0548, 0.1157,
        0.0741, 0.0412, 0.0360], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,688][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0346, 0.0651, 0.1230, 0.0634, 0.1241, 0.1153, 0.0843, 0.0811, 0.0710,
        0.0908, 0.0578, 0.0896], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,688][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0126, 0.0223, 0.0258, 0.0397, 0.0190, 0.0323, 0.0559, 0.0513, 0.1205,
        0.2166, 0.2616, 0.1424], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,692][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0746, 0.0816, 0.0777, 0.0791, 0.0759, 0.0919, 0.0889, 0.0891, 0.0948,
        0.0830, 0.0843, 0.0794], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:02,698][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0304, 0.2791, 0.3072, 0.0415, 0.0257, 0.0121, 0.1011, 0.0358, 0.0575,
        0.0530, 0.0270, 0.0109, 0.0187], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,700][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0998, 0.1053, 0.0364, 0.1125, 0.2293, 0.0083, 0.0891, 0.0100, 0.0207,
        0.0972, 0.0507, 0.0315, 0.1093], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,704][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([2.0148e-12, 5.2456e-11, 6.1175e-09, 2.7432e-08, 1.8156e-07, 1.6209e-06,
        2.8468e-06, 4.5138e-05, 2.1760e-04, 3.3868e-03, 1.1011e-01, 2.1779e-01,
        6.6844e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,706][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0072, 0.0137, 0.0740, 0.0455, 0.0592, 0.0809, 0.1263, 0.1247, 0.1089,
        0.0790, 0.0595, 0.1409, 0.0801], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,707][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.3061, 0.1277, 0.0840, 0.0918, 0.0190, 0.0382, 0.0585, 0.0066, 0.0158,
        0.1106, 0.0671, 0.0628, 0.0118], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,707][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0321, 0.0469, 0.1130, 0.1043, 0.0077, 0.0633, 0.0830, 0.0693, 0.1184,
        0.1306, 0.1247, 0.1004, 0.0061], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,707][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0213, 0.0594, 0.1371, 0.0337, 0.1192, 0.0923, 0.0360, 0.0753, 0.1139,
        0.0736, 0.0317, 0.0999, 0.1067], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,708][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.1122, 0.2377, 0.0787, 0.0351, 0.0708, 0.0695, 0.0404, 0.0842, 0.1353,
        0.0248, 0.0155, 0.0436, 0.0522], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,708][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0492, 0.0686, 0.0673, 0.0756, 0.0190, 0.2914, 0.0381, 0.0514, 0.1110,
        0.0669, 0.0398, 0.1119, 0.0098], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,709][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0220, 0.0451, 0.1422, 0.0545, 0.0733, 0.0961, 0.0771, 0.0947, 0.0830,
        0.0831, 0.0519, 0.1271, 0.0500], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,710][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0057, 0.0127, 0.0169, 0.0271, 0.0128, 0.0218, 0.0424, 0.0389, 0.1011,
        0.2030, 0.2484, 0.1311, 0.1381], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,716][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0691, 0.0758, 0.0720, 0.0733, 0.0704, 0.0848, 0.0834, 0.0836, 0.0887,
        0.0770, 0.0783, 0.0734, 0.0701], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:02,721][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0190, 0.2336, 0.3194, 0.0603, 0.0584, 0.0149, 0.0468, 0.0300, 0.0591,
        0.0603, 0.0344, 0.0140, 0.0331, 0.0167], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,727][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1955, 0.1505, 0.0421, 0.1238, 0.1170, 0.0066, 0.0407, 0.0260, 0.0307,
        0.0551, 0.0548, 0.0690, 0.0574, 0.0309], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,727][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([7.1625e-13, 1.1295e-11, 8.2234e-10, 7.6683e-09, 5.2069e-08, 3.2272e-07,
        5.7417e-07, 8.3613e-06, 5.8130e-05, 1.9761e-03, 6.7185e-02, 1.3638e-01,
        4.1428e-01, 3.8011e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,728][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0216, 0.0266, 0.0723, 0.0587, 0.0811, 0.0601, 0.0831, 0.1049, 0.0933,
        0.0731, 0.0722, 0.1070, 0.1035, 0.0423], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,728][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.4147, 0.1250, 0.0234, 0.1039, 0.0178, 0.0358, 0.0357, 0.0167, 0.0033,
        0.0748, 0.0851, 0.0484, 0.0112, 0.0042], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,728][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0290, 0.0469, 0.0880, 0.0958, 0.1004, 0.0416, 0.0488, 0.0805, 0.0204,
        0.1553, 0.1335, 0.0603, 0.0955, 0.0041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,729][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0301, 0.0535, 0.1243, 0.0318, 0.1054, 0.0654, 0.0423, 0.0665, 0.0853,
        0.0678, 0.0319, 0.0980, 0.0972, 0.1004], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,729][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1174, 0.0627, 0.1065, 0.0206, 0.1096, 0.0491, 0.0326, 0.0854, 0.1542,
        0.0202, 0.0125, 0.0807, 0.0899, 0.0586], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,731][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0765, 0.1508, 0.1527, 0.0534, 0.0682, 0.0795, 0.0314, 0.0476, 0.0682,
        0.0851, 0.0331, 0.0709, 0.0444, 0.0381], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,737][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0378, 0.0656, 0.1239, 0.0598, 0.1164, 0.0771, 0.0554, 0.0666, 0.0637,
        0.0689, 0.0484, 0.1017, 0.0813, 0.0333], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,741][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0140, 0.0216, 0.0241, 0.0365, 0.0186, 0.0295, 0.0481, 0.0454, 0.0945,
        0.1512, 0.1849, 0.1087, 0.1093, 0.1137], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,747][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0679, 0.0719, 0.0682, 0.0680, 0.0682, 0.0809, 0.0721, 0.0662, 0.0734,
        0.0746, 0.0740, 0.0724, 0.0667, 0.0755], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:02,748][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0200, 0.2449, 0.3113, 0.0503, 0.0819, 0.0130, 0.0488, 0.0259, 0.0412,
        0.0558, 0.0265, 0.0098, 0.0426, 0.0165, 0.0115], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,748][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1696, 0.1260, 0.0373, 0.1078, 0.1091, 0.0072, 0.0956, 0.0184, 0.0261,
        0.0639, 0.0529, 0.0352, 0.0406, 0.0120, 0.0983], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,749][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.4975e-13, 6.2279e-13, 4.7332e-11, 3.1128e-10, 3.6644e-09, 1.4504e-08,
        3.6894e-08, 1.1311e-06, 6.3521e-06, 5.8296e-05, 2.0717e-03, 3.7306e-03,
        2.4755e-02, 2.5607e-01, 7.1331e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,749][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0230, 0.0303, 0.0695, 0.0571, 0.0752, 0.0638, 0.0940, 0.0991, 0.0815,
        0.0673, 0.0637, 0.0844, 0.0854, 0.0795, 0.0262], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,750][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1823, 0.0866, 0.0667, 0.0947, 0.0747, 0.0559, 0.0456, 0.0134, 0.0912,
        0.0648, 0.0717, 0.0261, 0.0567, 0.0389, 0.0307], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,750][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0441, 0.0485, 0.0589, 0.0863, 0.0622, 0.1297, 0.0438, 0.0552, 0.0741,
        0.0785, 0.1159, 0.0714, 0.0622, 0.0518, 0.0174], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,753][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0405, 0.0597, 0.0926, 0.0442, 0.0769, 0.0674, 0.0467, 0.0538, 0.0850,
        0.0879, 0.0416, 0.0829, 0.0662, 0.1308, 0.0239], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,758][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1564, 0.0659, 0.0718, 0.0265, 0.0766, 0.0563, 0.0366, 0.0716, 0.1143,
        0.0213, 0.0145, 0.0987, 0.0588, 0.1104, 0.0203], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,764][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0527, 0.0832, 0.1402, 0.0594, 0.0347, 0.1293, 0.0395, 0.0328, 0.0735,
        0.0700, 0.0434, 0.0559, 0.0234, 0.1458, 0.0161], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,768][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0480, 0.0660, 0.1039, 0.0486, 0.1041, 0.0649, 0.0625, 0.0760, 0.0661,
        0.0593, 0.0410, 0.0957, 0.0797, 0.0684, 0.0158], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,768][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0131, 0.0219, 0.0231, 0.0357, 0.0184, 0.0300, 0.0450, 0.0456, 0.0846,
        0.1262, 0.1537, 0.0945, 0.0866, 0.1003, 0.1213], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,769][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0619, 0.0653, 0.0654, 0.0646, 0.0650, 0.0741, 0.0677, 0.0645, 0.0683,
        0.0689, 0.0682, 0.0682, 0.0643, 0.0698, 0.0638], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:02,770][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:02,771][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12555],
        [ 8525],
        [ 1737],
        [10195],
        [ 6522],
        [ 8901],
        [ 9775],
        [10538],
        [ 7495],
        [ 7012],
        [ 8686],
        [ 9802],
        [ 4153],
        [ 8862],
        [ 8418]], device='cuda:0')
[2024-07-24 10:24:02,773][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16486],
        [22726],
        [ 2163],
        [28726],
        [ 4221],
        [27522],
        [33610],
        [31633],
        [19086],
        [18322],
        [24737],
        [15671],
        [ 3427],
        [23219],
        [23571]], device='cuda:0')
[2024-07-24 10:24:02,775][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36206],
        [30997],
        [27203],
        [26348],
        [31504],
        [28028],
        [31544],
        [37863],
        [40155],
        [41160],
        [33670],
        [25832],
        [35366],
        [29083],
        [32976]], device='cuda:0')
[2024-07-24 10:24:02,778][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 826],
        [3555],
        [4319],
        [7257],
        [6801],
        [7868],
        [8292],
        [8142],
        [8264],
        [8694],
        [8881],
        [8533],
        [8366],
        [9038],
        [8884]], device='cuda:0')
[2024-07-24 10:24:02,780][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[36368],
        [42972],
        [22575],
        [23261],
        [24485],
        [22056],
        [16566],
        [18671],
        [26443],
        [44585],
        [31746],
        [28516],
        [11568],
        [23991],
        [26345]], device='cuda:0')
[2024-07-24 10:24:02,783][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2231],
        [2068],
        [1990],
        [1907],
        [1859],
        [1848],
        [1807],
        [1656],
        [1666],
        [1766],
        [1687],
        [1580],
        [1683],
        [1569],
        [1441]], device='cuda:0')
[2024-07-24 10:24:02,786][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6641],
        [ 8396],
        [ 8952],
        [ 8358],
        [ 9824],
        [11454],
        [11204],
        [ 8941],
        [10230],
        [ 8152],
        [ 9523],
        [ 9496],
        [ 6819],
        [ 7855],
        [ 8008]], device='cuda:0')
[2024-07-24 10:24:02,788][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[42012],
        [42090],
        [42567],
        [43051],
        [43482],
        [43590],
        [43713],
        [44315],
        [44719],
        [44627],
        [44625],
        [44978],
        [44904],
        [44847],
        [44765]], device='cuda:0')
[2024-07-24 10:24:02,791][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[38141],
        [36173],
        [27816],
        [27621],
        [23579],
        [20800],
        [20049],
        [18062],
        [17798],
        [17973],
        [18063],
        [18453],
        [16280],
        [14355],
        [14656]], device='cuda:0')
[2024-07-24 10:24:02,793][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[29066],
        [24934],
        [  771],
        [18791],
        [12187],
        [24423],
        [26226],
        [27727],
        [34425],
        [34350],
        [23998],
        [26923],
        [23076],
        [31903],
        [20950]], device='cuda:0')
[2024-07-24 10:24:02,794][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30410],
        [34132],
        [32370],
        [32994],
        [34045],
        [29872],
        [27066],
        [28593],
        [29787],
        [32762],
        [33140],
        [32687],
        [31718],
        [34207],
        [34857]], device='cuda:0')
[2024-07-24 10:24:02,795][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24807],
        [30088],
        [33533],
        [31726],
        [31870],
        [27229],
        [25133],
        [25803],
        [25442],
        [27465],
        [27358],
        [26665],
        [26057],
        [28294],
        [29136]], device='cuda:0')
[2024-07-24 10:24:02,796][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11669],
        [ 7181],
        [ 5464],
        [ 5845],
        [ 5646],
        [ 6152],
        [ 6110],
        [ 5747],
        [ 5102],
        [ 5094],
        [ 5100],
        [ 4832],
        [ 4894],
        [ 4606],
        [ 4783]], device='cuda:0')
[2024-07-24 10:24:02,797][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[11693],
        [26467],
        [26158],
        [23529],
        [23415],
        [26285],
        [28270],
        [26002],
        [26081],
        [26653],
        [25901],
        [25289],
        [26511],
        [26510],
        [26596]], device='cuda:0')
[2024-07-24 10:24:02,800][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12043],
        [15393],
        [26762],
        [12084],
        [27823],
        [33329],
        [28040],
        [33544],
        [39491],
        [39199],
        [38805],
        [40433],
        [32890],
        [39100],
        [40111]], device='cuda:0')
[2024-07-24 10:24:02,802][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21090],
        [10534],
        [10131],
        [10090],
        [ 9955],
        [ 9862],
        [ 9852],
        [ 9940],
        [ 9949],
        [ 9428],
        [ 9363],
        [ 9736],
        [ 9111],
        [ 9098],
        [ 9141]], device='cuda:0')
[2024-07-24 10:24:02,805][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25102],
        [30130],
        [29406],
        [26844],
        [21849],
        [17818],
        [16583],
        [21401],
        [20519],
        [19322],
        [19490],
        [27770],
        [19621],
        [22652],
        [21204]], device='cuda:0')
[2024-07-24 10:24:02,807][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14466],
        [11657],
        [21320],
        [15286],
        [16873],
        [17011],
        [15101],
        [21182],
        [23523],
        [10270],
        [ 9215],
        [10240],
        [22042],
        [20593],
        [24966]], device='cuda:0')
[2024-07-24 10:24:02,810][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[7691],
        [8074],
        [6534],
        [7001],
        [6605],
        [6407],
        [5120],
        [5093],
        [5447],
        [5985],
        [6067],
        [6229],
        [6388],
        [6640],
        [6494]], device='cuda:0')
[2024-07-24 10:24:02,812][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29100],
        [26662],
        [24584],
        [25297],
        [27173],
        [25839],
        [27111],
        [27662],
        [28670],
        [29252],
        [26593],
        [27326],
        [28250],
        [27876],
        [30964]], device='cuda:0')
[2024-07-24 10:24:02,815][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[9535],
        [7841],
        [8607],
        [9438],
        [7705],
        [8270],
        [8458],
        [8653],
        [9391],
        [8072],
        [8787],
        [7291],
        [7658],
        [7417],
        [7968]], device='cuda:0')
[2024-07-24 10:24:02,817][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[6865],
        [4636],
        [3468],
        [3554],
        [3606],
        [3519],
        [3560],
        [3305],
        [3097],
        [3126],
        [3175],
        [3081],
        [3106],
        [3040],
        [2993]], device='cuda:0')
[2024-07-24 10:24:02,818][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22037],
        [23469],
        [ 9684],
        [ 8358],
        [ 8041],
        [ 5400],
        [ 4027],
        [ 4481],
        [ 6258],
        [ 7843],
        [ 7995],
        [ 9091],
        [ 9582],
        [ 5686],
        [ 6664]], device='cuda:0')
[2024-07-24 10:24:02,819][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36522],
        [34420],
        [34646],
        [34235],
        [33759],
        [34455],
        [35165],
        [35725],
        [35846],
        [36131],
        [36171],
        [35932],
        [36230],
        [35513],
        [35773]], device='cuda:0')
[2024-07-24 10:24:02,820][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27580],
        [28319],
        [25877],
        [25114],
        [26392],
        [27566],
        [27069],
        [27552],
        [27812],
        [28171],
        [28158],
        [28243],
        [28338],
        [28724],
        [28949]], device='cuda:0')
[2024-07-24 10:24:02,821][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2891],
        [ 4718],
        [ 7030],
        [ 9883],
        [10065],
        [11554],
        [13750],
        [13386],
        [14424],
        [15409],
        [18019],
        [17401],
        [16121],
        [16147],
        [16841]], device='cuda:0')
[2024-07-24 10:24:02,824][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9584],
        [ 8873],
        [ 9221],
        [ 9234],
        [ 9558],
        [10095],
        [ 9930],
        [ 9742],
        [ 9705],
        [ 9843],
        [ 9924],
        [ 9871],
        [ 9884],
        [10168],
        [10146]], device='cuda:0')
[2024-07-24 10:24:02,826][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18287],
        [23376],
        [23558],
        [24622],
        [25753],
        [26176],
        [26618],
        [24435],
        [23882],
        [27271],
        [26887],
        [25308],
        [24928],
        [25122],
        [23671]], device='cuda:0')
[2024-07-24 10:24:02,829][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[46041],
        [28630],
        [25129],
        [33107],
        [36556],
        [22511],
        [24453],
        [21240],
        [16549],
        [12532],
        [13499],
        [16670],
        [17713],
        [16186],
        [11912]], device='cuda:0')
[2024-07-24 10:24:02,832][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259],
        [45259]], device='cuda:0')
[2024-07-24 10:24:02,867][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:02,870][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,872][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,873][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,873][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,873][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,874][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,874][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,874][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,874][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,875][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,875][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,875][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:02,876][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5853, 0.4147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,876][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3760, 0.6240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,876][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3099, 0.6901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,877][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4483, 0.5517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,877][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2997, 0.7003], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,877][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3674, 0.6326], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,878][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0476, 0.9524], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,878][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0090, 0.9910], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,878][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0023, 0.9977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,879][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1446, 0.8554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,879][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0843, 0.9157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,879][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2180, 0.7820], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:02,880][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.4711, 0.3021, 0.2268], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,880][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.1589, 0.4257, 0.4153], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,880][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.1623, 0.3029, 0.5348], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,881][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.0148, 0.9443, 0.0409], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,881][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.1702, 0.4091, 0.4207], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,881][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.1967, 0.5690, 0.2344], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,882][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.0109, 0.8775, 0.1117], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,882][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([3.4372e-04, 9.9906e-01, 5.9720e-04], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,882][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.0024, 0.9880, 0.0097], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,883][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.0487, 0.8521, 0.0992], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,883][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.0809, 0.6611, 0.2580], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,886][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.0387, 0.9009, 0.0605], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:02,890][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3419, 0.2398, 0.1875, 0.2309], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,894][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1025, 0.2981, 0.3200, 0.2793], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,894][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0839, 0.1362, 0.2007, 0.5792], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,894][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2380, 0.4993, 0.0087, 0.2540], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,895][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1182, 0.2826, 0.2886, 0.3106], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,895][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1763, 0.5267, 0.0886, 0.2083], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,895][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0067, 0.7330, 0.1035, 0.1568], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,896][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0006, 0.5499, 0.0019, 0.4476], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,896][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([7.3546e-04, 2.0755e-01, 1.4315e-03, 7.9028e-01], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,896][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0234, 0.6407, 0.0229, 0.3131], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,896][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0466, 0.4099, 0.1176, 0.4259], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,897][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0224, 0.6009, 0.0159, 0.3609], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:02,900][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.3470, 0.2002, 0.1423, 0.1896, 0.1210], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,904][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0663, 0.2272, 0.2378, 0.1998, 0.2688], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,910][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0510, 0.0961, 0.1536, 0.4826, 0.2167], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,914][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0194, 0.6605, 0.0116, 0.2770, 0.0314], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,914][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0861, 0.2197, 0.2303, 0.2460, 0.2180], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,915][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1196, 0.2858, 0.1787, 0.1890, 0.2268], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,915][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0107, 0.6895, 0.0530, 0.1710, 0.0758], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,915][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([1.5321e-04, 4.8911e-01, 5.6604e-04, 5.0892e-01, 1.2468e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,915][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0460, 0.1050, 0.0078, 0.6911, 0.1501], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,916][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0116, 0.4151, 0.0249, 0.5132, 0.0352], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,916][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0289, 0.3507, 0.1328, 0.3796, 0.1081], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,916][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0119, 0.4546, 0.0275, 0.4804, 0.0257], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:02,917][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2667, 0.1738, 0.1314, 0.1672, 0.1187, 0.1422], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,917][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0556, 0.1824, 0.1967, 0.1682, 0.2306, 0.1665], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,920][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0347, 0.0568, 0.0973, 0.3238, 0.1291, 0.3583], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,924][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0374, 0.6585, 0.0032, 0.1943, 0.0063, 0.1003], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,930][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0742, 0.1820, 0.1838, 0.1999, 0.1691, 0.1909], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,934][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2655, 0.3245, 0.0428, 0.1532, 0.0573, 0.1566], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,935][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0248, 0.5301, 0.0558, 0.1351, 0.0706, 0.1836], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,935][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([5.0350e-03, 9.6314e-02, 3.0930e-04, 6.8319e-02, 8.5752e-04, 8.2917e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,935][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([6.2507e-02, 9.3045e-03, 6.8989e-04, 4.6133e-02, 1.8988e-02, 8.6238e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,935][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0890, 0.2670, 0.0021, 0.0702, 0.0027, 0.5691], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,936][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0237, 0.2609, 0.0993, 0.3049, 0.0815, 0.2297], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,936][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0852, 0.2574, 0.0039, 0.1289, 0.0030, 0.5216], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:02,936][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2348, 0.1531, 0.1145, 0.1458, 0.1032, 0.1214, 0.1272],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,937][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0518, 0.1502, 0.1672, 0.1437, 0.1946, 0.1426, 0.1500],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,937][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0176, 0.0388, 0.0646, 0.3051, 0.0986, 0.3664, 0.1088],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,939][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0394, 0.6485, 0.0029, 0.1942, 0.0053, 0.0591, 0.0506],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,944][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0618, 0.1522, 0.1524, 0.1658, 0.1441, 0.1574, 0.1662],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,949][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2675, 0.2888, 0.0347, 0.1310, 0.0584, 0.1141, 0.1055],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,954][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0068, 0.3913, 0.0521, 0.1165, 0.0669, 0.1749, 0.1915],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,955][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.2569e-03, 2.2129e-02, 2.9588e-05, 1.3093e-02, 1.0750e-04, 3.1607e-01,
        6.4731e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,955][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.1671e-03, 2.4229e-03, 5.4544e-05, 2.5762e-02, 5.6965e-03, 6.3823e-01,
        3.2567e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,955][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0456, 0.0887, 0.0023, 0.0686, 0.0028, 0.5511, 0.2411],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,956][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0193, 0.1703, 0.0552, 0.1982, 0.0579, 0.3214, 0.1778],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,956][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0447, 0.1155, 0.0014, 0.0723, 0.0012, 0.3992, 0.3656],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:02,956][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2396, 0.1396, 0.0991, 0.1313, 0.0852, 0.1058, 0.1108, 0.0884],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,957][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0467, 0.1337, 0.1372, 0.1244, 0.1620, 0.1268, 0.1336, 0.1355],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,957][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0084, 0.0272, 0.0426, 0.2709, 0.0731, 0.3802, 0.1464, 0.0511],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,957][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0183, 0.4743, 0.0057, 0.1852, 0.0117, 0.1495, 0.1294, 0.0259],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,958][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0495, 0.1299, 0.1322, 0.1436, 0.1263, 0.1306, 0.1410, 0.1469],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,958][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3504, 0.1563, 0.0278, 0.0750, 0.0366, 0.0801, 0.0774, 0.1964],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,959][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0164, 0.3875, 0.0366, 0.0841, 0.0423, 0.1556, 0.1786, 0.0988],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,963][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([5.3781e-04, 1.8971e-03, 1.0887e-06, 1.3960e-03, 4.9631e-06, 3.6150e-02,
        1.1532e-01, 8.4469e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,965][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([9.8749e-02, 2.0091e-04, 1.5630e-05, 1.2666e-03, 1.4297e-03, 1.1480e-01,
        1.6762e-02, 7.6677e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,969][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([3.5260e-02, 3.1095e-02, 3.7761e-04, 2.3460e-02, 5.5496e-04, 1.8731e-01,
        1.4257e-01, 5.7937e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,974][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0198, 0.1769, 0.0515, 0.2190, 0.0345, 0.2593, 0.1171, 0.1219],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,977][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.8678e-02, 2.1898e-02, 2.1098e-04, 1.6209e-02, 2.2036e-04, 6.5497e-02,
        9.9636e-02, 7.6765e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:02,978][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.2362, 0.1306, 0.0901, 0.1227, 0.0741, 0.0978, 0.1016, 0.0780, 0.0688],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,978][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0373, 0.1180, 0.1280, 0.1117, 0.1550, 0.1133, 0.1189, 0.1193, 0.0985],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,978][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0099, 0.0252, 0.0468, 0.2851, 0.0778, 0.3567, 0.1014, 0.0299, 0.0672],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,979][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0238, 0.4456, 0.0050, 0.2097, 0.0104, 0.1234, 0.1134, 0.0250, 0.0437],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,979][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0409, 0.1111, 0.1148, 0.1246, 0.1127, 0.1140, 0.1239, 0.1338, 0.1242],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,979][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1575, 0.1192, 0.0198, 0.0770, 0.0307, 0.0539, 0.0631, 0.1503, 0.3285],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,980][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0254, 0.3011, 0.0243, 0.0880, 0.0381, 0.1439, 0.1637, 0.0905, 0.1249],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,980][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([3.4909e-04, 5.2292e-04, 2.4459e-07, 3.0810e-04, 1.0399e-06, 8.8719e-03,
        2.7794e-02, 6.2883e-01, 3.3332e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,980][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([1.5107e-05, 1.5475e-06, 5.9985e-08, 7.1319e-05, 1.5514e-05, 4.5966e-03,
        2.9208e-03, 5.9264e-01, 3.9974e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,981][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([3.1569e-02, 1.7253e-02, 3.0660e-04, 1.4919e-02, 6.7218e-04, 1.2824e-01,
        7.9731e-02, 4.0493e-01, 3.2238e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,986][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0143, 0.1820, 0.0576, 0.1907, 0.0435, 0.2345, 0.1173, 0.0694, 0.0906],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,989][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([9.0470e-03, 6.6384e-03, 4.0953e-05, 4.9280e-03, 5.3301e-05, 2.5411e-02,
        4.7936e-02, 6.5369e-01, 2.5226e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:02,994][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1716, 0.1153, 0.0878, 0.1103, 0.0793, 0.0912, 0.0965, 0.0813, 0.0734,
        0.0934], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,998][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0305, 0.1052, 0.1217, 0.0990, 0.1434, 0.1007, 0.1074, 0.1081, 0.0874,
        0.0967], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,998][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0219, 0.0325, 0.0629, 0.2224, 0.0850, 0.2293, 0.0542, 0.0175, 0.0270,
        0.2473], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,998][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0523, 0.5532, 0.0027, 0.1844, 0.0061, 0.0482, 0.0409, 0.0163, 0.0260,
        0.0699], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,999][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0405, 0.1003, 0.1001, 0.1092, 0.0944, 0.1030, 0.1083, 0.1092, 0.1004,
        0.1346], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,999][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1609, 0.1155, 0.0191, 0.0537, 0.0259, 0.0656, 0.0526, 0.1201, 0.2604,
        0.1261], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:02,999][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0043, 0.1370, 0.0187, 0.0494, 0.0325, 0.0842, 0.0721, 0.0598, 0.0911,
        0.4509], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,000][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([4.0209e-04, 2.9602e-04, 4.9811e-07, 1.1396e-04, 1.4169e-06, 5.2012e-03,
        1.1563e-02, 1.9420e-01, 4.4626e-01, 3.4196e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,000][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.0529e-07, 7.3343e-07, 2.1740e-08, 4.3961e-05, 2.0395e-06, 8.1705e-04,
        1.9175e-03, 8.9662e-02, 8.7862e-01, 2.8940e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,004][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0259, 0.0114, 0.0008, 0.0123, 0.0008, 0.0606, 0.0496, 0.2965, 0.2111,
        0.3308], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,009][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0147, 0.1455, 0.0438, 0.1830, 0.0343, 0.1750, 0.0941, 0.0591, 0.0431,
        0.2074], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,012][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.3441e-02, 7.7258e-03, 1.2879e-04, 6.0947e-03, 1.4620e-04, 2.2815e-02,
        3.8330e-02, 3.2990e-01, 3.2566e-01, 2.5575e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,018][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1493, 0.1033, 0.0809, 0.0995, 0.0748, 0.0831, 0.0879, 0.0758, 0.0692,
        0.0843, 0.0918], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,018][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0269, 0.0935, 0.1104, 0.0898, 0.1306, 0.0928, 0.0975, 0.0989, 0.0816,
        0.0899, 0.0880], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,018][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0192, 0.0283, 0.0488, 0.1791, 0.0656, 0.1821, 0.0351, 0.0100, 0.0150,
        0.1883, 0.2286], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,019][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0344, 0.4508, 0.0035, 0.1553, 0.0070, 0.0675, 0.0590, 0.0196, 0.0283,
        0.1361, 0.0386], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,019][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0380, 0.0891, 0.0885, 0.0967, 0.0834, 0.0929, 0.0968, 0.0960, 0.0890,
        0.1187, 0.1109], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,019][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3233, 0.0974, 0.0125, 0.0307, 0.0139, 0.0392, 0.0310, 0.0682, 0.1372,
        0.0933, 0.1531], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,020][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0049, 0.0767, 0.0096, 0.0163, 0.0133, 0.0325, 0.0280, 0.0231, 0.0373,
        0.1768, 0.5816], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,020][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([7.1937e-04, 5.8010e-05, 4.4060e-08, 7.7261e-06, 8.1974e-08, 5.7857e-04,
        7.2501e-04, 1.3545e-02, 2.3115e-02, 4.0047e-02, 9.2120e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,020][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.9341e-07, 4.4237e-07, 1.6249e-08, 8.4210e-06, 2.5812e-06, 8.2349e-04,
        7.3124e-04, 9.8736e-02, 2.3211e-01, 1.3760e-02, 6.5383e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,021][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.1706e-02, 6.7757e-03, 7.7135e-05, 1.4326e-03, 4.2340e-05, 1.3884e-02,
        7.4649e-03, 3.0567e-02, 1.9203e-02, 8.9690e-02, 7.7916e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,026][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0174, 0.1354, 0.0418, 0.1347, 0.0333, 0.1375, 0.0786, 0.0594, 0.0459,
        0.1725, 0.1434], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,028][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.0815e-02, 4.7590e-03, 4.2028e-05, 1.2798e-03, 2.8791e-05, 8.5795e-03,
        1.1501e-02, 7.6266e-02, 7.5907e-02, 9.4925e-02, 6.9590e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,034][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1584, 0.0980, 0.0723, 0.0939, 0.0640, 0.0762, 0.0798, 0.0669, 0.0589,
        0.0793, 0.0876, 0.0649], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,038][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0267, 0.0912, 0.0964, 0.0800, 0.1068, 0.0807, 0.0873, 0.0923, 0.0740,
        0.0775, 0.0778, 0.1093], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,039][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0077, 0.0152, 0.0296, 0.1237, 0.0460, 0.1409, 0.0496, 0.0199, 0.0319,
        0.1784, 0.2759, 0.0812], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,039][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0632, 0.3290, 0.0025, 0.1727, 0.0048, 0.0507, 0.0436, 0.0118, 0.0204,
        0.1269, 0.0481, 0.1264], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,040][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0326, 0.0781, 0.0814, 0.0861, 0.0797, 0.0806, 0.0859, 0.0903, 0.0847,
        0.1076, 0.0989, 0.0941], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,040][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1567, 0.0663, 0.0265, 0.0340, 0.0296, 0.0474, 0.0473, 0.0879, 0.1260,
        0.0798, 0.1768, 0.1217], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,040][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0075, 0.0353, 0.0030, 0.0078, 0.0045, 0.0172, 0.0118, 0.0101, 0.0185,
        0.0718, 0.2039, 0.6086], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,041][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([2.6754e-05, 1.8114e-05, 2.2866e-08, 1.2390e-05, 5.7956e-08, 2.0732e-04,
        6.8001e-04, 7.3380e-03, 1.1310e-02, 2.4534e-02, 9.1146e-01, 4.4410e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,041][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([3.0275e-06, 5.1200e-07, 5.3168e-08, 4.6292e-05, 8.0445e-06, 1.0049e-03,
        8.7869e-04, 1.0001e-01, 1.6303e-01, 8.6499e-03, 5.8350e-01, 1.4287e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,042][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.6562e-02, 3.8400e-03, 2.8432e-04, 2.0631e-03, 2.8292e-04, 2.0467e-02,
        8.8525e-03, 6.1061e-02, 4.6269e-02, 7.1158e-02, 6.5509e-01, 1.1407e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,048][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0080, 0.0966, 0.0354, 0.1434, 0.0212, 0.1652, 0.0721, 0.0503, 0.0513,
        0.1557, 0.1648, 0.0360], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,051][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([8.1692e-03, 1.7440e-03, 3.3530e-05, 1.2221e-03, 3.0728e-05, 4.4787e-03,
        8.1465e-03, 6.7128e-02, 4.9728e-02, 5.9158e-02, 4.6398e-01, 3.3618e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,056][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1656, 0.0941, 0.0678, 0.0883, 0.0576, 0.0697, 0.0727, 0.0585, 0.0519,
        0.0728, 0.0819, 0.0568, 0.0624], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,059][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0219, 0.0829, 0.0881, 0.0717, 0.0987, 0.0714, 0.0780, 0.0811, 0.0632,
        0.0703, 0.0706, 0.1040, 0.0981], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,059][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0082, 0.0145, 0.0309, 0.1214, 0.0474, 0.1360, 0.0447, 0.0166, 0.0256,
        0.1589, 0.2304, 0.0814, 0.0839], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,059][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0286, 0.3230, 0.0021, 0.1411, 0.0052, 0.0547, 0.0424, 0.0109, 0.0292,
        0.1156, 0.0391, 0.1442, 0.0641], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,060][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0277, 0.0715, 0.0739, 0.0807, 0.0717, 0.0762, 0.0817, 0.0843, 0.0797,
        0.1010, 0.0944, 0.0864, 0.0707], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,060][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0870, 0.0464, 0.0324, 0.0286, 0.0302, 0.0544, 0.0401, 0.0350, 0.0889,
        0.0699, 0.1220, 0.2014, 0.1636], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,060][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0026, 0.0243, 0.0016, 0.0050, 0.0023, 0.0094, 0.0060, 0.0051, 0.0106,
        0.0506, 0.1514, 0.5219, 0.2092], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,061][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([5.7112e-06, 1.5298e-05, 9.5696e-09, 3.5162e-06, 7.3618e-09, 1.3756e-04,
        3.7843e-04, 1.0006e-02, 2.3683e-02, 2.3017e-02, 6.6132e-01, 2.8070e-01,
        7.2509e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,061][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([2.7538e-07, 3.6842e-07, 1.7548e-08, 1.5253e-05, 1.4816e-06, 2.6768e-04,
        5.7734e-04, 5.9691e-02, 1.7558e-01, 6.9941e-03, 4.2356e-01, 3.2911e-01,
        4.1958e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,061][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([5.3063e-03, 2.7405e-03, 1.0112e-04, 1.5853e-03, 8.7630e-05, 9.6749e-03,
        8.2367e-03, 3.6561e-02, 2.0828e-02, 5.7929e-02, 7.1839e-01, 7.2286e-02,
        6.6278e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,065][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0089, 0.1036, 0.0413, 0.1116, 0.0361, 0.1899, 0.0784, 0.0453, 0.0571,
        0.1306, 0.1167, 0.0454, 0.0352], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,067][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([3.0706e-03, 1.3372e-03, 5.0996e-05, 7.6135e-04, 3.1885e-05, 4.0611e-03,
        8.5005e-03, 1.8226e-02, 6.1672e-02, 4.3590e-02, 4.1431e-01, 4.2524e-01,
        1.9145e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,073][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1323, 0.0849, 0.0644, 0.0816, 0.0575, 0.0682, 0.0708, 0.0597, 0.0538,
        0.0690, 0.0755, 0.0579, 0.0600, 0.0643], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,078][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0227, 0.0750, 0.0836, 0.0691, 0.0965, 0.0696, 0.0758, 0.0745, 0.0603,
        0.0687, 0.0682, 0.0920, 0.0926, 0.0512], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,079][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0062, 0.0112, 0.0249, 0.1037, 0.0350, 0.1264, 0.0316, 0.0086, 0.0185,
        0.1809, 0.2515, 0.0713, 0.0823, 0.0479], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,080][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0220, 0.2792, 0.0024, 0.1006, 0.0044, 0.0493, 0.0392, 0.0138, 0.0256,
        0.1010, 0.0379, 0.1848, 0.0556, 0.0843], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,080][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0280, 0.0700, 0.0701, 0.0771, 0.0650, 0.0719, 0.0754, 0.0751, 0.0685,
        0.0943, 0.0881, 0.0787, 0.0625, 0.0754], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,080][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1874, 0.0385, 0.0090, 0.0204, 0.0114, 0.0237, 0.0202, 0.0341, 0.1170,
        0.0366, 0.0968, 0.2156, 0.0716, 0.1178], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,081][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0057, 0.0292, 0.0022, 0.0052, 0.0024, 0.0082, 0.0076, 0.0064, 0.0096,
        0.0489, 0.1393, 0.4286, 0.1824, 0.1245], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,081][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([5.7119e-04, 8.5403e-06, 1.0737e-08, 2.0556e-06, 2.0262e-08, 3.4795e-05,
        1.4915e-04, 6.4716e-04, 1.7360e-03, 4.9841e-03, 9.3217e-02, 4.2144e-02,
        8.9014e-04, 8.5562e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,081][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([3.2570e-05, 2.9210e-08, 2.2541e-09, 4.5458e-07, 8.3279e-07, 1.2424e-04,
        2.2768e-05, 1.6025e-02, 3.4406e-03, 1.5078e-04, 8.0414e-03, 6.8520e-03,
        1.0112e-04, 9.6521e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,082][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([3.5991e-02, 1.5065e-03, 9.8567e-06, 4.1993e-04, 7.2412e-06, 3.0506e-03,
        1.2974e-03, 8.9600e-03, 3.4497e-03, 1.6868e-02, 1.2455e-01, 1.2730e-01,
        4.2776e-03, 6.7232e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,087][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0104, 0.1011, 0.0306, 0.1049, 0.0308, 0.1198, 0.0687, 0.0453, 0.0514,
        0.1280, 0.1188, 0.0422, 0.0311, 0.1168], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,091][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.0578e-02, 1.0619e-03, 8.0820e-06, 3.3098e-04, 3.2868e-06, 2.1747e-03,
        1.7328e-03, 1.6165e-02, 1.4033e-02, 1.6790e-02, 1.3988e-01, 3.3269e-01,
        1.5738e-03, 4.5298e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,096][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1207, 0.0798, 0.0603, 0.0757, 0.0548, 0.0628, 0.0664, 0.0563, 0.0511,
        0.0641, 0.0699, 0.0541, 0.0576, 0.0587, 0.0676], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,099][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0244, 0.0690, 0.0761, 0.0649, 0.0879, 0.0649, 0.0692, 0.0693, 0.0581,
        0.0630, 0.0643, 0.0850, 0.0856, 0.0512, 0.0669], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,100][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0078, 0.0135, 0.0250, 0.0931, 0.0342, 0.1140, 0.0323, 0.0104, 0.0216,
        0.1609, 0.2172, 0.0648, 0.0751, 0.0531, 0.0770], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,100][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1011, 0.3391, 0.0012, 0.1415, 0.0022, 0.0225, 0.0213, 0.0072, 0.0129,
        0.0441, 0.0178, 0.0759, 0.0219, 0.0444, 0.1470], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,100][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0271, 0.0645, 0.0645, 0.0699, 0.0609, 0.0662, 0.0693, 0.0693, 0.0641,
        0.0851, 0.0795, 0.0728, 0.0593, 0.0695, 0.0781], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,101][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2968, 0.0418, 0.0063, 0.0144, 0.0071, 0.0159, 0.0126, 0.0286, 0.0515,
        0.0341, 0.0598, 0.1124, 0.0546, 0.0995, 0.1647], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,101][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0090, 0.0262, 0.0022, 0.0051, 0.0026, 0.0088, 0.0066, 0.0060, 0.0102,
        0.0351, 0.1117, 0.3451, 0.1546, 0.1206, 0.1561], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,101][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.9116e-04, 9.6607e-07, 3.4892e-10, 7.3692e-08, 3.5195e-10, 1.9301e-06,
        3.3343e-06, 3.0389e-05, 5.2402e-05, 1.7205e-04, 2.3689e-03, 1.8534e-03,
        2.3341e-05, 1.3286e-01, 8.6234e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,102][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.0465e-06, 9.8465e-10, 6.5981e-11, 3.6155e-08, 2.9772e-08, 1.0706e-05,
        1.5879e-06, 9.5859e-04, 2.4169e-04, 1.4079e-05, 1.1339e-03, 8.8852e-04,
        6.4059e-06, 6.3571e-01, 3.6103e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,102][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.4238e-02, 3.5181e-04, 6.8971e-06, 1.0725e-04, 3.3027e-06, 9.9139e-04,
        3.9884e-04, 1.5602e-03, 1.5313e-03, 3.7939e-03, 3.1721e-02, 1.3668e-02,
        2.3603e-03, 4.9972e-01, 4.1955e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,105][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0081, 0.0857, 0.0351, 0.0903, 0.0259, 0.1552, 0.0520, 0.0412, 0.0416,
        0.1152, 0.1005, 0.0321, 0.0272, 0.1070, 0.0828], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,108][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.2367e-02, 3.3743e-04, 3.5091e-06, 1.1210e-04, 1.4545e-06, 4.5459e-04,
        6.5121e-04, 4.0618e-03, 4.3672e-03, 5.1628e-03, 3.6710e-02, 5.1276e-02,
        8.2708e-04, 2.8814e-01, 5.8552e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,137][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:03,142][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,146][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,146][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,146][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,147][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,147][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,147][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,148][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,148][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,148][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,148][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,149][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,150][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4196, 0.5804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,150][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3341, 0.6659], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,150][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0292, 0.9708], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,151][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0086, 0.9914], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,151][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8134, 0.1866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,152][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4643, 0.5357], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,152][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0846, 0.9154], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,153][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0090, 0.9910], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,153][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0404, 0.9596], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,156][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1446, 0.8554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,159][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9138, 0.0862], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,163][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2180, 0.7820], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,169][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.0122, 0.0182, 0.9697], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,171][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.0730, 0.9163, 0.0106], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,171][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.0027, 0.9891, 0.0081], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,172][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([8.8532e-04, 9.9780e-01, 1.3103e-03], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,172][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.8484, 0.1217, 0.0299], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,172][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.2877, 0.4974, 0.2149], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,173][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.0161, 0.9428, 0.0411], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,173][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([3.4372e-04, 9.9906e-01, 5.9720e-04], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,173][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.0101, 0.9870, 0.0029], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,176][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.0487, 0.8521, 0.0992], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,181][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.6525, 0.2524, 0.0951], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,187][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.0387, 0.9009, 0.0605], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,191][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0175, 0.0382, 0.8906, 0.0536], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,191][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0605, 0.6015, 0.0044, 0.3335], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,192][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0012, 0.6863, 0.0045, 0.3080], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,192][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.9702e-04, 4.8795e-01, 5.6170e-04, 5.1099e-01], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,192][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7210, 0.1476, 0.0284, 0.1029], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,193][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2848, 0.4305, 0.0639, 0.2207], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,193][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0111, 0.4321, 0.0319, 0.5250], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,193][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0006, 0.5499, 0.0019, 0.4476], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,194][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0040, 0.5989, 0.0009, 0.3961], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,194][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0234, 0.6407, 0.0229, 0.3131], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,197][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5433, 0.2190, 0.0385, 0.1992], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,202][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0224, 0.6009, 0.0159, 0.3609], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,208][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0136, 0.0193, 0.0954, 0.0212, 0.8506], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,212][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0262, 0.5090, 0.0047, 0.4471, 0.0129], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,212][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([5.6283e-04, 3.1943e-01, 2.2486e-03, 6.6970e-01, 8.0610e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,212][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([2.3866e-04, 3.1879e-01, 4.6336e-04, 6.7873e-01, 1.7747e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,213][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.6945, 0.0974, 0.0665, 0.1363, 0.0053], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,213][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1553, 0.2675, 0.1573, 0.2182, 0.2017], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,213][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0043, 0.3929, 0.0131, 0.5696, 0.0202], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,214][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([1.5321e-04, 4.8911e-01, 5.6604e-04, 5.0892e-01, 1.2468e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,214][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0017, 0.2662, 0.0008, 0.7271, 0.0042], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,217][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0116, 0.4151, 0.0249, 0.5132, 0.0352], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,222][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.3937, 0.2101, 0.0606, 0.2732, 0.0625], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,228][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0119, 0.4546, 0.0275, 0.4804, 0.0257], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,232][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0665, 0.0706, 0.3207, 0.0522, 0.0722, 0.4178], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,232][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2706, 0.2288, 0.0011, 0.1586, 0.0015, 0.3395], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,232][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0100, 0.1966, 0.0008, 0.0780, 0.0021, 0.7126], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,233][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([1.8374e-03, 2.7323e-02, 1.4693e-05, 2.4480e-02, 8.3197e-05, 9.4626e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,233][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.8282, 0.0673, 0.0088, 0.0387, 0.0066, 0.0503], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,233][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3384, 0.2327, 0.0256, 0.1521, 0.0258, 0.2254], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,234][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0224, 0.1356, 0.0073, 0.1578, 0.0134, 0.6636], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,234][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([5.0350e-03, 9.6314e-02, 3.0930e-04, 6.8319e-02, 8.5752e-04, 8.2917e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,234][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([2.4380e-02, 1.1725e-01, 1.7662e-04, 1.0416e-01, 4.1488e-04, 7.5361e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,235][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0890, 0.2670, 0.0021, 0.0702, 0.0027, 0.5691], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,238][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.6478, 0.0553, 0.0104, 0.0600, 0.0117, 0.2149], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,244][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0852, 0.2574, 0.0039, 0.1289, 0.0030, 0.5216], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,249][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0811, 0.1026, 0.2142, 0.0933, 0.1338, 0.1317, 0.2432],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,252][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1665, 0.1594, 0.0006, 0.1087, 0.0007, 0.2474, 0.3167],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,253][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.5515e-03, 4.2491e-02, 8.9328e-05, 2.2895e-02, 2.6144e-04, 4.9793e-01,
        4.3378e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,253][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.6501e-04, 8.3758e-03, 1.4556e-06, 5.5456e-03, 7.3430e-06, 5.9196e-01,
        3.9355e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,254][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8000, 0.0617, 0.0099, 0.0354, 0.0109, 0.0478, 0.0343],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,254][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3551, 0.1852, 0.0187, 0.1227, 0.0236, 0.1625, 0.1322],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,254][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0146, 0.0611, 0.0021, 0.0826, 0.0038, 0.4263, 0.4094],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,255][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.2569e-03, 2.2129e-02, 2.9588e-05, 1.3093e-02, 1.0750e-04, 3.1607e-01,
        6.4731e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,255][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.4617e-02, 5.5286e-02, 4.4452e-05, 4.8400e-02, 2.4234e-04, 4.9136e-01,
        3.9005e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,258][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0456, 0.0887, 0.0023, 0.0686, 0.0028, 0.5511, 0.2411],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,264][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5185, 0.0460, 0.0077, 0.0570, 0.0064, 0.1532, 0.2112],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,269][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0447, 0.1155, 0.0014, 0.0723, 0.0012, 0.3992, 0.3656],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,273][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0566, 0.0707, 0.0526, 0.0620, 0.0308, 0.1295, 0.0882, 0.5096],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,273][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([1.5570e-01, 8.3043e-02, 1.7009e-04, 5.3700e-02, 2.4889e-04, 1.3509e-01,
        1.9044e-01, 3.8161e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,273][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([1.5196e-03, 7.3266e-03, 5.7234e-06, 5.2711e-03, 1.4262e-05, 1.2805e-01,
        3.6245e-01, 4.9536e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,274][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([1.7673e-04, 8.1960e-04, 1.0693e-07, 7.9161e-04, 5.3993e-07, 6.2463e-02,
        1.3973e-01, 7.9601e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,274][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.8305, 0.0460, 0.0094, 0.0297, 0.0056, 0.0329, 0.0243, 0.0216],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,274][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.3754, 0.0943, 0.0146, 0.0721, 0.0158, 0.1178, 0.0986, 0.2114],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,275][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([7.5850e-03, 1.1214e-02, 2.1918e-04, 1.6239e-02, 3.7614e-04, 8.4721e-02,
        1.5820e-01, 7.2145e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,275][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([5.3781e-04, 1.8971e-03, 1.0887e-06, 1.3960e-03, 4.9631e-06, 3.6150e-02,
        1.1532e-01, 8.4469e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,275][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([1.1754e-02, 1.4790e-02, 7.8089e-06, 1.8016e-02, 3.2435e-05, 1.8804e-01,
        1.9732e-01, 5.7003e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,276][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([3.5260e-02, 3.1095e-02, 3.7761e-04, 2.3460e-02, 5.5496e-04, 1.8731e-01,
        1.4257e-01, 5.7937e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,281][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.5105, 0.0194, 0.0024, 0.0249, 0.0023, 0.0634, 0.0896, 0.2873],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,285][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([2.8678e-02, 2.1898e-02, 2.1098e-04, 1.6209e-02, 2.2036e-04, 6.5497e-02,
        9.9636e-02, 7.6765e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,290][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0333, 0.0464, 0.0515, 0.0422, 0.0776, 0.0600, 0.0534, 0.0394, 0.5962],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,293][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.2049e-01, 3.6053e-02, 1.0621e-04, 3.6670e-02, 2.0592e-04, 7.7979e-02,
        1.0975e-01, 2.7444e-01, 3.4431e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,294][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([1.3151e-03, 1.9730e-03, 2.1585e-06, 2.2028e-03, 6.9603e-06, 6.8026e-02,
        1.8451e-01, 4.2201e-01, 3.1996e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,294][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([2.1561e-04, 2.6850e-04, 1.8079e-08, 2.9892e-04, 1.2986e-07, 1.8948e-02,
        3.2220e-02, 4.8320e-01, 4.6485e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,294][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.6748, 0.0840, 0.0235, 0.0464, 0.0137, 0.0456, 0.0538, 0.0441, 0.0141],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,295][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.2193, 0.0761, 0.0107, 0.0757, 0.0133, 0.0786, 0.0798, 0.1601, 0.2864],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,295][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([3.4043e-03, 5.2093e-03, 1.1914e-04, 8.2819e-03, 2.1784e-04, 3.1150e-02,
        8.8958e-02, 6.4056e-01, 2.2210e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,295][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([3.4909e-04, 5.2292e-04, 2.4459e-07, 3.0810e-04, 1.0399e-06, 8.8719e-03,
        2.7794e-02, 6.2883e-01, 3.3332e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,296][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.0867e-02, 4.0606e-03, 2.6763e-06, 5.1595e-03, 1.1237e-05, 6.1200e-02,
        6.3753e-02, 5.8108e-01, 2.7386e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,297][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.1569e-02, 1.7253e-02, 3.0660e-04, 1.4919e-02, 6.7218e-04, 1.2824e-01,
        7.9731e-02, 4.0493e-01, 3.2238e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,303][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.4369, 0.0165, 0.0029, 0.0206, 0.0025, 0.0577, 0.0799, 0.2266, 0.1565],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,305][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([9.0470e-03, 6.6384e-03, 4.0953e-05, 4.9280e-03, 5.3301e-05, 2.5411e-02,
        4.7936e-02, 6.5369e-01, 2.5226e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,311][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0394, 0.0705, 0.2684, 0.0722, 0.1122, 0.1092, 0.0716, 0.0601, 0.0874,
        0.1090], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,313][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([8.1726e-02, 1.4244e-02, 7.1248e-05, 1.1090e-02, 8.5106e-05, 3.3520e-02,
        4.4822e-02, 1.0164e-01, 1.2694e-01, 5.8586e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,314][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.1495e-03, 1.4159e-03, 4.8840e-06, 1.1232e-03, 1.0997e-05, 2.7157e-02,
        5.6686e-02, 1.1743e-01, 2.5325e-01, 5.4177e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,314][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([4.5860e-04, 1.7398e-04, 7.6058e-08, 8.7846e-05, 2.6644e-07, 7.4132e-03,
        1.3895e-02, 1.8480e-01, 2.1581e-01, 5.7737e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,314][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7756, 0.0431, 0.0065, 0.0296, 0.0076, 0.0454, 0.0171, 0.0199, 0.0200,
        0.0352], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,315][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2266, 0.0766, 0.0093, 0.0561, 0.0089, 0.0912, 0.0635, 0.1223, 0.2070,
        0.1385], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,315][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([5.4187e-03, 4.4829e-03, 2.6977e-04, 6.2988e-03, 3.0969e-04, 2.5482e-02,
        5.5263e-02, 3.4612e-01, 2.5947e-01, 2.9688e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,316][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([4.0209e-04, 2.9602e-04, 4.9811e-07, 1.1396e-04, 1.4169e-06, 5.2012e-03,
        1.1563e-02, 1.9420e-01, 4.4626e-01, 3.4196e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,316][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([7.3696e-03, 3.1186e-03, 2.6241e-06, 2.2383e-03, 7.3482e-06, 4.1608e-02,
        2.9222e-02, 1.3873e-01, 2.1290e-01, 5.6481e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,316][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0259, 0.0114, 0.0008, 0.0123, 0.0008, 0.0606, 0.0496, 0.2965, 0.2111,
        0.3308], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,320][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5097, 0.0228, 0.0031, 0.0170, 0.0025, 0.0583, 0.0523, 0.1166, 0.0847,
        0.1331], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,323][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.3441e-02, 7.7258e-03, 1.2879e-04, 6.0947e-03, 1.4620e-04, 2.2815e-02,
        3.8330e-02, 3.2990e-01, 3.2566e-01, 2.5575e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,328][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0526, 0.0677, 0.3097, 0.0593, 0.1092, 0.1201, 0.0631, 0.0377, 0.0436,
        0.0763, 0.0607], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,332][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.5390e-02, 4.4950e-03, 1.0236e-05, 1.0634e-03, 9.6701e-06, 5.8970e-03,
        6.2486e-03, 1.6954e-02, 1.8962e-02, 1.4549e-01, 7.3548e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,334][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([8.3142e-04, 2.1675e-04, 2.3103e-07, 2.4042e-05, 3.9429e-07, 1.7857e-03,
        2.5735e-03, 3.4496e-03, 7.0671e-03, 6.0543e-02, 9.2351e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,334][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.8648e-04, 1.4479e-05, 1.5727e-09, 2.2458e-06, 7.8625e-09, 3.2013e-04,
        3.0289e-04, 3.8965e-03, 3.5091e-03, 3.6894e-02, 9.5487e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,335][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7873, 0.0347, 0.0047, 0.0250, 0.0056, 0.0432, 0.0142, 0.0146, 0.0185,
        0.0278, 0.0244], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,335][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4003, 0.0513, 0.0047, 0.0279, 0.0036, 0.0494, 0.0330, 0.0605, 0.0900,
        0.0871, 0.1923], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,335][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.6305e-03, 1.4349e-03, 5.1094e-05, 6.3833e-04, 4.6086e-05, 6.1078e-03,
        9.3903e-03, 4.3691e-02, 2.5466e-02, 7.7540e-02, 8.2600e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,336][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([7.1937e-04, 5.8010e-05, 4.4060e-08, 7.7261e-06, 8.1974e-08, 5.7857e-04,
        7.2501e-04, 1.3545e-02, 2.3115e-02, 4.0047e-02, 9.2120e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,336][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.7293e-03, 3.0932e-04, 1.2027e-07, 6.6320e-05, 2.7732e-07, 2.3994e-03,
        1.0415e-03, 6.0670e-03, 6.0247e-03, 5.2836e-02, 9.2553e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,338][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.1706e-02, 6.7757e-03, 7.7135e-05, 1.4326e-03, 4.2340e-05, 1.3884e-02,
        7.4649e-03, 3.0567e-02, 1.9203e-02, 8.9690e-02, 7.7916e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,343][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6742, 0.0140, 0.0016, 0.0075, 0.0009, 0.0243, 0.0219, 0.0415, 0.0380,
        0.0550, 0.1213], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,346][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([3.0815e-02, 4.7590e-03, 4.2028e-05, 1.2798e-03, 2.8791e-05, 8.5795e-03,
        1.1501e-02, 7.6266e-02, 7.5907e-02, 9.4925e-02, 6.9590e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,352][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0310, 0.0494, 0.0543, 0.0294, 0.0274, 0.0771, 0.0610, 0.2606, 0.0634,
        0.0619, 0.0436, 0.2410], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,354][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([4.5328e-02, 3.2550e-03, 2.1999e-05, 2.2757e-03, 2.4902e-05, 6.6116e-03,
        6.8540e-03, 1.8473e-02, 1.6662e-02, 1.0555e-01, 7.3759e-01, 5.7357e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,354][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([2.8148e-04, 1.0009e-04, 2.9041e-07, 5.3342e-05, 4.4572e-07, 7.2613e-04,
        1.7174e-03, 4.9101e-03, 7.1948e-03, 2.8040e-02, 8.7938e-01, 7.7599e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,355][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([7.0827e-05, 8.3705e-06, 2.6414e-09, 7.1885e-06, 1.3270e-08, 3.4226e-04,
        2.4834e-04, 7.3404e-03, 4.8247e-03, 2.1636e-02, 9.3389e-01, 3.1629e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,355][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.6625, 0.0271, 0.0123, 0.0365, 0.0069, 0.0332, 0.0305, 0.0447, 0.0352,
        0.0421, 0.0499, 0.0191], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,355][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1831, 0.0427, 0.0132, 0.0332, 0.0116, 0.0603, 0.0505, 0.0853, 0.1041,
        0.0810, 0.2261, 0.1091], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,356][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([1.8092e-03, 1.0021e-03, 3.1699e-05, 8.8398e-04, 3.6129e-05, 4.7946e-03,
        6.4267e-03, 3.4599e-02, 2.3334e-02, 4.5927e-02, 7.1827e-01, 1.6288e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,356][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([2.6754e-05, 1.8114e-05, 2.2866e-08, 1.2390e-05, 5.7956e-08, 2.0732e-04,
        6.8001e-04, 7.3380e-03, 1.1310e-02, 2.4534e-02, 9.1146e-01, 4.4410e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,357][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([1.7320e-03, 1.3186e-04, 2.4522e-07, 1.4548e-04, 6.0031e-07, 1.1440e-03,
        7.4378e-04, 3.9616e-03, 6.8084e-03, 3.8337e-02, 8.8333e-01, 6.3669e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,358][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.6562e-02, 3.8400e-03, 2.8432e-04, 2.0631e-03, 2.8292e-04, 2.0467e-02,
        8.8525e-03, 6.1061e-02, 4.6269e-02, 7.1158e-02, 6.5509e-01, 1.1407e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,362][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.4527, 0.0097, 0.0016, 0.0097, 0.0012, 0.0267, 0.0236, 0.0481, 0.0248,
        0.0489, 0.1410, 0.2120], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,366][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([8.1692e-03, 1.7440e-03, 3.3530e-05, 1.2221e-03, 3.0728e-05, 4.4787e-03,
        8.1465e-03, 6.7128e-02, 4.9728e-02, 5.9158e-02, 4.6398e-01, 3.3618e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,371][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0051, 0.0136, 0.0569, 0.0151, 0.5200, 0.0148, 0.0135, 0.0118, 0.0135,
        0.0311, 0.0175, 0.0033, 0.2839], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,374][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([6.6055e-03, 2.3434e-03, 1.3226e-05, 1.3099e-03, 2.0094e-05, 5.0531e-03,
        6.6478e-03, 1.9251e-02, 1.9783e-02, 9.5422e-02, 7.0029e-01, 1.3028e-01,
        1.2983e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,375][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([6.3392e-05, 4.9620e-05, 1.7596e-07, 2.7694e-05, 2.6666e-07, 1.0183e-03,
        1.5284e-03, 3.4459e-03, 9.2954e-03, 2.9584e-02, 7.3486e-01, 2.1280e-01,
        7.3225e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,375][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([7.7944e-06, 4.3375e-06, 3.1441e-09, 1.9458e-06, 3.5249e-09, 1.0384e-04,
        1.3620e-04, 2.9446e-03, 6.8997e-03, 2.1413e-02, 8.9331e-01, 7.3910e-02,
        1.2722e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,376][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.4248, 0.0375, 0.0438, 0.0751, 0.0030, 0.0377, 0.0466, 0.0485, 0.0439,
        0.0828, 0.1201, 0.0285, 0.0077], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,376][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0827, 0.0273, 0.0165, 0.0275, 0.0142, 0.0697, 0.0470, 0.0386, 0.0880,
        0.0859, 0.1906, 0.2119, 0.0999], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,376][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([9.3673e-04, 7.9982e-04, 3.1499e-05, 5.2912e-04, 2.0765e-05, 2.2191e-03,
        3.2482e-03, 2.2684e-02, 2.0775e-02, 5.1869e-02, 7.1639e-01, 1.5058e-01,
        2.9915e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,377][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([5.7112e-06, 1.5298e-05, 9.5696e-09, 3.5162e-06, 7.3618e-09, 1.3756e-04,
        3.7843e-04, 1.0006e-02, 2.3683e-02, 2.3017e-02, 6.6132e-01, 2.8070e-01,
        7.2509e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,378][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([2.2702e-04, 6.2460e-05, 8.9255e-08, 5.1123e-05, 2.2009e-07, 6.8266e-04,
        7.0747e-04, 7.1165e-03, 1.0764e-02, 2.9604e-02, 7.9752e-01, 1.4945e-01,
        3.8166e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,382][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([5.3063e-03, 2.7405e-03, 1.0112e-04, 1.5853e-03, 8.7630e-05, 9.6749e-03,
        8.2367e-03, 3.6561e-02, 2.0828e-02, 5.7929e-02, 7.1839e-01, 7.2286e-02,
        6.6278e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,387][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.2482, 0.0167, 0.0039, 0.0121, 0.0026, 0.0376, 0.0275, 0.0451, 0.0567,
        0.0659, 0.1903, 0.2130, 0.0805], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,390][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([3.0706e-03, 1.3372e-03, 5.0996e-05, 7.6135e-04, 3.1885e-05, 4.0611e-03,
        8.5005e-03, 1.8226e-02, 6.1672e-02, 4.3590e-02, 4.1431e-01, 4.2524e-01,
        1.9145e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,394][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0303, 0.0436, 0.0692, 0.0483, 0.0374, 0.0852, 0.0494, 0.0507, 0.0701,
        0.0666, 0.0475, 0.0213, 0.0269, 0.3535], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,395][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([9.1190e-02, 2.3894e-03, 5.0838e-06, 6.8607e-04, 3.3690e-06, 1.4444e-03,
        1.3442e-03, 4.8426e-03, 4.0965e-03, 4.5205e-02, 2.4355e-01, 5.8797e-02,
        2.5688e-03, 5.4387e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,395][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.9167e-03, 5.5649e-05, 1.1025e-07, 7.7822e-06, 1.0216e-07, 1.9035e-04,
        2.8653e-04, 4.6439e-04, 9.1828e-04, 6.1965e-03, 1.0027e-01, 5.2458e-02,
        2.0504e-03, 8.3518e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,396][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.2521e-04, 1.6054e-06, 4.6220e-10, 4.6645e-07, 6.9206e-10, 2.7706e-05,
        2.3811e-05, 2.0033e-04, 2.5480e-04, 2.1183e-03, 5.8812e-02, 1.5716e-02,
        1.3360e-04, 9.2249e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,396][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.7495, 0.0336, 0.0072, 0.0206, 0.0058, 0.0176, 0.0113, 0.0139, 0.0113,
        0.0219, 0.0210, 0.0137, 0.0082, 0.0643], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,396][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1964, 0.0221, 0.0041, 0.0195, 0.0039, 0.0295, 0.0217, 0.0317, 0.0932,
        0.0393, 0.1357, 0.1877, 0.0327, 0.1825], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,397][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([7.4879e-03, 3.9917e-04, 1.1734e-05, 2.4484e-04, 8.1537e-06, 9.2404e-04,
        1.4766e-03, 6.1039e-03, 4.8587e-03, 1.6134e-02, 1.9800e-01, 9.0497e-02,
        1.2161e-02, 6.6169e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,397][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([5.7119e-04, 8.5403e-06, 1.0737e-08, 2.0556e-06, 2.0262e-08, 3.4795e-05,
        1.4915e-04, 6.4716e-04, 1.7360e-03, 4.9841e-03, 9.3217e-02, 4.2144e-02,
        8.9014e-04, 8.5562e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,399][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([9.5595e-03, 1.3417e-04, 1.0150e-07, 4.3468e-05, 1.5050e-07, 5.4020e-04,
        2.5928e-04, 1.5871e-03, 1.5824e-03, 1.2144e-02, 2.2417e-01, 3.4255e-02,
        1.3685e-03, 7.1435e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,402][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([3.5991e-02, 1.5065e-03, 9.8567e-06, 4.1993e-04, 7.2412e-06, 3.0506e-03,
        1.2974e-03, 8.9600e-03, 3.4497e-03, 1.6868e-02, 1.2455e-01, 1.2730e-01,
        4.2776e-03, 6.7232e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,407][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.4275, 0.0073, 0.0008, 0.0043, 0.0007, 0.0170, 0.0125, 0.0180, 0.0153,
        0.0337, 0.0725, 0.0774, 0.0216, 0.2913], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,410][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.0578e-02, 1.0619e-03, 8.0820e-06, 3.3098e-04, 3.2868e-06, 2.1747e-03,
        1.7328e-03, 1.6165e-02, 1.4033e-02, 1.6790e-02, 1.3988e-01, 3.3269e-01,
        1.5738e-03, 4.5298e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,414][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0379, 0.0485, 0.1833, 0.0419, 0.0691, 0.0788, 0.0552, 0.0474, 0.0515,
        0.0584, 0.0387, 0.0302, 0.0469, 0.1659, 0.0461], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,415][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.3186e-02, 6.2948e-04, 1.4945e-06, 2.0629e-04, 8.9339e-07, 6.1919e-04,
        5.3368e-04, 1.1441e-03, 1.0740e-03, 9.7654e-03, 6.0488e-02, 1.0140e-02,
        7.1335e-04, 3.0417e-01, 5.2733e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,415][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.3117e-03, 6.7679e-06, 6.1996e-09, 7.5194e-07, 7.2165e-09, 2.4595e-05,
        2.4805e-05, 3.3998e-05, 5.7808e-05, 4.3495e-04, 7.6626e-03, 5.1088e-03,
        1.9917e-04, 2.4581e-01, 7.3833e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,416][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1446e-04, 1.2399e-07, 6.6037e-12, 1.1969e-08, 1.1911e-11, 1.8477e-06,
        8.0265e-07, 4.0434e-06, 1.0858e-05, 6.4183e-05, 1.1546e-03, 2.4299e-04,
        2.5728e-06, 1.9002e-01, 8.0839e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,416][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7735, 0.0231, 0.0048, 0.0162, 0.0058, 0.0177, 0.0122, 0.0105, 0.0139,
        0.0197, 0.0168, 0.0112, 0.0076, 0.0495, 0.0175], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,417][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3679, 0.0190, 0.0023, 0.0110, 0.0019, 0.0179, 0.0110, 0.0223, 0.0324,
        0.0274, 0.0629, 0.0820, 0.0184, 0.1386, 0.1850], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,417][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.4150e-03, 1.1353e-04, 2.4429e-06, 5.2824e-05, 1.4483e-06, 2.5132e-04,
        2.2301e-04, 7.0998e-04, 6.1442e-04, 2.3976e-03, 3.3219e-02, 2.0221e-02,
        2.0243e-03, 2.2764e-01, 7.0312e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,418][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.9116e-04, 9.6607e-07, 3.4892e-10, 7.3692e-08, 3.5195e-10, 1.9301e-06,
        3.3343e-06, 3.0389e-05, 5.2402e-05, 1.7205e-04, 2.3689e-03, 1.8534e-03,
        2.3341e-05, 1.3286e-01, 8.6234e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,422][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.7665e-03, 9.6044e-06, 2.7943e-09, 2.4515e-06, 4.0150e-09, 3.4848e-05,
        1.1177e-05, 4.5814e-05, 4.8296e-05, 5.6830e-04, 1.0333e-02, 3.2717e-03,
        5.3678e-05, 1.9174e-01, 7.8912e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,424][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.4238e-02, 3.5181e-04, 6.8971e-06, 1.0725e-04, 3.3027e-06, 9.9139e-04,
        3.9884e-04, 1.5602e-03, 1.5313e-03, 3.7939e-03, 3.1721e-02, 1.3668e-02,
        2.3603e-03, 4.9972e-01, 4.1955e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,428][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.1753e-01, 3.7676e-03, 3.1213e-04, 1.3215e-03, 1.7134e-04, 5.4684e-03,
        3.7683e-03, 5.5105e-03, 5.3200e-03, 9.5415e-03, 1.6936e-02, 2.3368e-02,
        5.6855e-03, 1.2192e-01, 2.7938e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,431][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.2367e-02, 3.3743e-04, 3.5091e-06, 1.1210e-04, 1.4545e-06, 4.5459e-04,
        6.5121e-04, 4.0618e-03, 4.3672e-03, 5.1628e-03, 3.6710e-02, 5.1276e-02,
        8.2708e-04, 2.8814e-01, 5.8552e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,432][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:03,434][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14045],
        [11060],
        [ 1350],
        [12163],
        [ 7199],
        [10064],
        [10199],
        [11665],
        [ 6441],
        [ 5567],
        [ 7914],
        [10863],
        [ 4140],
        [ 9299],
        [10158]], device='cuda:0')
[2024-07-24 10:24:03,436][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15155],
        [12658],
        [ 3840],
        [13906],
        [12008],
        [22209],
        [22177],
        [21389],
        [18170],
        [14638],
        [20056],
        [20321],
        [ 6750],
        [21319],
        [21664]], device='cuda:0')
[2024-07-24 10:24:03,437][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[2683],
        [3097],
        [3646],
        [4070],
        [4142],
        [4437],
        [4637],
        [4875],
        [5060],
        [5340],
        [5395],
        [5387],
        [5340],
        [5556],
        [5562]], device='cuda:0')
[2024-07-24 10:24:03,438][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20362],
        [18488],
        [18875],
        [18672],
        [17356],
        [16966],
        [16974],
        [17065],
        [16894],
        [16615],
        [16217],
        [15533],
        [15072],
        [15121],
        [15061]], device='cuda:0')
[2024-07-24 10:24:03,439][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[28281],
        [27858],
        [24058],
        [22803],
        [22608],
        [20259],
        [19444],
        [18802],
        [18802],
        [18709],
        [18538],
        [18018],
        [18220],
        [18083],
        [18323]], device='cuda:0')
[2024-07-24 10:24:03,440][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[19888],
        [17960],
        [17879],
        [21054],
        [20769],
        [20943],
        [20115],
        [20261],
        [20310],
        [20101],
        [20461],
        [20946],
        [20232],
        [21234],
        [22136]], device='cuda:0')
[2024-07-24 10:24:03,443][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[3137],
        [5209],
        [5866],
        [5527],
        [6135],
        [5973],
        [5852],
        [6110],
        [6542],
        [6303],
        [6012],
        [6284],
        [6478],
        [6297],
        [6175]], device='cuda:0')
[2024-07-24 10:24:03,445][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31716],
        [36922],
        [43490],
        [40574],
        [46247],
        [40621],
        [40589],
        [38308],
        [37540],
        [38067],
        [37795],
        [38655],
        [41131],
        [39774],
        [39773]], device='cuda:0')
[2024-07-24 10:24:03,448][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28034],
        [22027],
        [22305],
        [21547],
        [21671],
        [21708],
        [21095],
        [21070],
        [21165],
        [20840],
        [21526],
        [22098],
        [21886],
        [22240],
        [21753]], device='cuda:0')
[2024-07-24 10:24:03,451][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 1942],
        [ 8083],
        [ 8150],
        [ 9136],
        [ 9299],
        [18371],
        [18038],
        [23662],
        [26441],
        [24130],
        [17801],
        [18242],
        [21885],
        [23594],
        [16867]], device='cuda:0')
[2024-07-24 10:24:03,453][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[30421],
        [33087],
        [32910],
        [13468],
        [12702],
        [ 8643],
        [ 9196],
        [21282],
        [23008],
        [22711],
        [18466],
        [22468],
        [28717],
        [12998],
        [16547]], device='cuda:0')
[2024-07-24 10:24:03,456][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25908],
        [18090],
        [18939],
        [17326],
        [17133],
        [22102],
        [21252],
        [11868],
        [ 9278],
        [12324],
        [20915],
        [21527],
        [22229],
        [33274],
        [28215]], device='cuda:0')
[2024-07-24 10:24:03,458][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11215],
        [ 7708],
        [ 7999],
        [ 9639],
        [ 9418],
        [10224],
        [10841],
        [11740],
        [11392],
        [10201],
        [10619],
        [11198],
        [11032],
        [11324],
        [11153]], device='cuda:0')
[2024-07-24 10:24:03,461][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29792],
        [31351],
        [32177],
        [35081],
        [36773],
        [36119],
        [29094],
        [35915],
        [37397],
        [35602],
        [30221],
        [26679],
        [25483],
        [19023],
        [28097]], device='cuda:0')
[2024-07-24 10:24:03,462][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[20082],
        [21491],
        [ 5510],
        [10906],
        [ 6631],
        [ 2216],
        [ 2757],
        [ 9750],
        [ 3671],
        [ 3251],
        [ 4162],
        [ 3359],
        [11388],
        [ 2082],
        [ 2507]], device='cuda:0')
[2024-07-24 10:24:03,462][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20425],
        [21562],
        [30263],
        [28393],
        [29732],
        [28510],
        [20421],
        [31819],
        [37166],
        [25768],
        [24974],
        [32196],
        [32073],
        [29312],
        [28302]], device='cuda:0')
[2024-07-24 10:24:03,463][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 1394],
        [ 4146],
        [ 5656],
        [ 5408],
        [ 5480],
        [ 4194],
        [ 4581],
        [ 4889],
        [ 5104],
        [11088],
        [12722],
        [13259],
        [14556],
        [18358],
        [13516]], device='cuda:0')
[2024-07-24 10:24:03,465][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 920],
        [ 729],
        [ 749],
        [ 755],
        [ 853],
        [1421],
        [1411],
        [1937],
        [2057],
        [ 681],
        [1216],
        [1366],
        [1653],
        [2090],
        [1137]], device='cuda:0')
[2024-07-24 10:24:03,467][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13572],
        [23372],
        [23386],
        [29534],
        [29453],
        [20702],
        [34114],
        [12063],
        [ 9572],
        [22601],
        [26576],
        [26423],
        [26006],
        [40178],
        [30565]], device='cuda:0')
[2024-07-24 10:24:03,470][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17847],
        [23226],
        [21390],
        [20765],
        [19065],
        [18737],
        [17951],
        [17779],
        [18135],
        [19317],
        [19124],
        [18532],
        [18263],
        [18723],
        [18203]], device='cuda:0')
[2024-07-24 10:24:03,472][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 6772],
        [ 6882],
        [18944],
        [14571],
        [21308],
        [19319],
        [18354],
        [27515],
        [26557],
        [24190],
        [26279],
        [26665],
        [22078],
        [23801],
        [23918]], device='cuda:0')
[2024-07-24 10:24:03,475][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[16100],
        [13101],
        [13354],
        [15947],
        [16072],
        [13727],
        [15104],
        [11062],
        [ 9627],
        [ 9568],
        [16265],
        [14852],
        [14922],
        [15162],
        [10464]], device='cuda:0')
[2024-07-24 10:24:03,478][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9192],
        [ 6043],
        [ 6049],
        [ 6721],
        [ 6810],
        [ 8846],
        [10423],
        [15939],
        [15040],
        [10752],
        [ 7256],
        [ 7371],
        [ 8762],
        [ 4094],
        [ 7560]], device='cuda:0')
[2024-07-24 10:24:03,480][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14556],
        [ 7594],
        [ 7429],
        [10140],
        [13675],
        [18231],
        [10232],
        [ 3777],
        [ 1665],
        [ 4839],
        [17736],
        [16215],
        [14059],
        [ 7734],
        [ 9520]], device='cuda:0')
[2024-07-24 10:24:03,483][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[6532],
        [1123],
        [1007],
        [ 987],
        [1024],
        [2799],
        [1828],
        [ 287],
        [ 189],
        [ 261],
        [1039],
        [1196],
        [1166],
        [5449],
        [1413]], device='cuda:0')
[2024-07-24 10:24:03,485][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[41807],
        [43565],
        [42904],
        [37346],
        [34125],
        [41161],
        [38301],
        [36569],
        [36949],
        [39553],
        [36370],
        [32503],
        [29022],
        [36559],
        [34805]], device='cuda:0')
[2024-07-24 10:24:03,486][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 2073],
        [ 4134],
        [ 4595],
        [ 5089],
        [ 5349],
        [ 6054],
        [ 6729],
        [12830],
        [14997],
        [12713],
        [ 8478],
        [11292],
        [12057],
        [ 9599],
        [ 8543]], device='cuda:0')
[2024-07-24 10:24:03,486][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43700],
        [43840],
        [44021],
        [43055],
        [42213],
        [41481],
        [42325],
        [44238],
        [44511],
        [43407],
        [38568],
        [38360],
        [39340],
        [39102],
        [40914]], device='cuda:0')
[2024-07-24 10:24:03,488][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15371],
        [26430],
        [ 5876],
        [ 7834],
        [ 7498],
        [16306],
        [11676],
        [ 2559],
        [ 8553],
        [ 6153],
        [17064],
        [15777],
        [ 5631],
        [ 8805],
        [13960]], device='cuda:0')
[2024-07-24 10:24:03,489][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351],
        [28351]], device='cuda:0')
[2024-07-24 10:24:03,510][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:03,514][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,516][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,518][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,519][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,519][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,519][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,520][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,520][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,521][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,522][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,524][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,527][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,528][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2098, 0.7902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,528][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2375, 0.7625], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,529][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4571, 0.5429], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,529][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3883, 0.6117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,530][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4240, 0.5760], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,530][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4403, 0.5597], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,530][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4348, 0.5652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,531][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5171, 0.4829], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,531][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9030, 0.0970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,535][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8722, 0.1278], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,538][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5243, 0.4757], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,542][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3843, 0.6157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,544][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.1062, 0.3617, 0.5321], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,544][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.0637, 0.2002, 0.7361], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,545][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.4492, 0.4317, 0.1192], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,545][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.2732, 0.3166, 0.4102], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,545][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.2492, 0.3130, 0.4378], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,546][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.3681, 0.4050, 0.2269], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,546][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.3801, 0.3981, 0.2219], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,546][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.3234, 0.4232, 0.2534], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,546][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.9557, 0.0389, 0.0054], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,547][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.4643, 0.2281, 0.3076], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,548][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.5675, 0.3470, 0.0855], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,551][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.8985, 0.0980, 0.0036], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,555][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0641, 0.2720, 0.5005, 0.1634], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,559][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0946, 0.0551, 0.2518, 0.5985], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,562][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2235, 0.2545, 0.2501, 0.2720], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,566][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1194, 0.1890, 0.4596, 0.2320], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,566][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1754, 0.2388, 0.3562, 0.2295], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,567][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2280, 0.2615, 0.1791, 0.3314], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,567][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1831, 0.2326, 0.3065, 0.2778], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,567][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1779, 0.2493, 0.0929, 0.4799], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,568][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7894, 0.0855, 0.0199, 0.1052], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,568][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5612, 0.1632, 0.1973, 0.0782], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,568][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2890, 0.2564, 0.1829, 0.2718], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,570][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0177, 0.0660, 0.7553, 0.1610], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,572][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0495, 0.2100, 0.3315, 0.1542, 0.2548], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,575][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0301, 0.0535, 0.1525, 0.4835, 0.2804], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,579][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.2745, 0.2563, 0.0705, 0.2897, 0.1090], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,583][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.1509, 0.1599, 0.1922, 0.2028, 0.2943], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,586][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.1447, 0.1846, 0.2696, 0.1761, 0.2249], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,588][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1687, 0.1833, 0.1038, 0.2794, 0.2648], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,588][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.1843, 0.1962, 0.1287, 0.2546, 0.2361], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,589][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1989, 0.2189, 0.0988, 0.3921, 0.0912], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,589][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.8888, 0.0413, 0.0056, 0.0536, 0.0107], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,589][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.3033, 0.1769, 0.2770, 0.1096, 0.1333], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,590][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.3719, 0.2289, 0.0570, 0.2453, 0.0970], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,590][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.3290, 0.2382, 0.0326, 0.3583, 0.0420], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,590][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0437, 0.1738, 0.2645, 0.1298, 0.2095, 0.1787], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,591][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0598, 0.0149, 0.0598, 0.1323, 0.1159, 0.6174], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,592][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3533, 0.2448, 0.0148, 0.2807, 0.0443, 0.0621], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,596][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0389, 0.0499, 0.0862, 0.0670, 0.0947, 0.6634], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,599][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1173, 0.1488, 0.2036, 0.1478, 0.1726, 0.2099], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,603][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1522, 0.1483, 0.0287, 0.2368, 0.1095, 0.3244], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,606][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1500, 0.1215, 0.0594, 0.1604, 0.1201, 0.3887], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,610][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1698, 0.1504, 0.0538, 0.2452, 0.0449, 0.3358], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,612][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.8625, 0.0439, 0.0080, 0.0558, 0.0137, 0.0161], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,613][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1718, 0.0992, 0.1255, 0.0616, 0.0820, 0.4599], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,613][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.4450, 0.2348, 0.0282, 0.2296, 0.0389, 0.0234], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,613][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([8.7546e-02, 3.4351e-02, 2.1594e-04, 3.4525e-02, 8.8360e-04, 8.4248e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,614][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0386, 0.1453, 0.2256, 0.0993, 0.1668, 0.1632, 0.1613],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,614][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0200, 0.0080, 0.0347, 0.0648, 0.0668, 0.4120, 0.3938],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,614][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3048, 0.2069, 0.0112, 0.2532, 0.0344, 0.0748, 0.1147],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,615][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0355, 0.0343, 0.0380, 0.0477, 0.0517, 0.3507, 0.4421],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,615][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1019, 0.1266, 0.1711, 0.1209, 0.1453, 0.1739, 0.1602],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,616][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2188, 0.1434, 0.0060, 0.2572, 0.0360, 0.0599, 0.2788],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,619][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1216, 0.0934, 0.0333, 0.1263, 0.0771, 0.2621, 0.2863],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,622][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1522, 0.1199, 0.0437, 0.1992, 0.0402, 0.2415, 0.2034],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,626][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8537, 0.0410, 0.0066, 0.0523, 0.0122, 0.0149, 0.0191],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,630][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1776, 0.0674, 0.1289, 0.0384, 0.0817, 0.3389, 0.1670],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,633][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4499, 0.2197, 0.0285, 0.2247, 0.0386, 0.0164, 0.0221],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,635][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.7366e-02, 2.6660e-02, 3.6994e-05, 2.7196e-02, 1.4929e-04, 8.8207e-01,
        3.6525e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,636][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0381, 0.1232, 0.1792, 0.0919, 0.1288, 0.1307, 0.1469, 0.1611],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,636][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0259, 0.0147, 0.0346, 0.0943, 0.0573, 0.3168, 0.3058, 0.1506],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,636][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2596, 0.1858, 0.0099, 0.2234, 0.0295, 0.0626, 0.1011, 0.1281],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,637][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0216, 0.0186, 0.0140, 0.0267, 0.0191, 0.1892, 0.2674, 0.4435],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,637][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0877, 0.1051, 0.1445, 0.1029, 0.1237, 0.1419, 0.1318, 0.1624],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,637][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1676, 0.0940, 0.0031, 0.1456, 0.0105, 0.0177, 0.0408, 0.5207],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,638][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1011, 0.0723, 0.0193, 0.0991, 0.0465, 0.1706, 0.2123, 0.2788],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,638][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1307, 0.1130, 0.0489, 0.1791, 0.0447, 0.2216, 0.1429, 0.1191],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,641][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.9199, 0.0243, 0.0029, 0.0281, 0.0053, 0.0075, 0.0094, 0.0026],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,646][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1772, 0.0545, 0.0784, 0.0337, 0.0523, 0.2652, 0.1891, 0.1496],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,652][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.4498, 0.2182, 0.0224, 0.2196, 0.0274, 0.0153, 0.0199, 0.0273],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,654][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([9.0721e-03, 6.1556e-03, 1.8293e-06, 8.6322e-03, 7.9479e-06, 5.0988e-02,
        2.3680e-02, 9.0146e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:03,656][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0314, 0.1050, 0.1500, 0.0764, 0.1109, 0.1143, 0.1217, 0.1525, 0.1379],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,656][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0165, 0.0162, 0.0342, 0.0976, 0.0535, 0.2911, 0.2698, 0.1185, 0.1026],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,657][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2316, 0.1664, 0.0106, 0.1970, 0.0294, 0.0611, 0.0947, 0.1647, 0.0445],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,657][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0146, 0.0111, 0.0093, 0.0167, 0.0130, 0.1159, 0.1742, 0.3050, 0.3401],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,657][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0745, 0.0930, 0.1253, 0.0861, 0.1066, 0.1257, 0.1163, 0.1435, 0.1291],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,658][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([4.7260e-02, 2.3836e-02, 4.7228e-04, 4.1178e-02, 1.5275e-03, 3.3795e-03,
        1.5077e-02, 2.8210e-01, 5.8517e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,658][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0692, 0.0471, 0.0104, 0.0662, 0.0279, 0.1207, 0.1523, 0.2538, 0.2525],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,659][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1052, 0.1007, 0.0508, 0.1633, 0.0501, 0.2090, 0.1433, 0.1189, 0.0588],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,659][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.9297, 0.0209, 0.0023, 0.0247, 0.0046, 0.0067, 0.0081, 0.0022, 0.0010],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,662][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1039, 0.0435, 0.0947, 0.0326, 0.0636, 0.2030, 0.2029, 0.1746, 0.0812],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,668][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.4539, 0.2129, 0.0193, 0.2173, 0.0350, 0.0094, 0.0200, 0.0208, 0.0114],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,671][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.7816e-02, 7.1549e-03, 5.9824e-07, 8.1263e-03, 1.9862e-06, 2.2202e-02,
        6.0163e-03, 9.2925e-01, 9.4301e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:03,676][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0251, 0.0874, 0.1430, 0.0584, 0.1076, 0.0956, 0.1099, 0.1368, 0.1363,
        0.0998], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,677][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0131, 0.0049, 0.0164, 0.0405, 0.0303, 0.2069, 0.2402, 0.1185, 0.0953,
        0.2339], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,677][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2503, 0.1619, 0.0090, 0.1977, 0.0222, 0.0574, 0.0729, 0.1018, 0.0339,
        0.0928], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,678][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0168, 0.0139, 0.0124, 0.0185, 0.0142, 0.0757, 0.1124, 0.1994, 0.2569,
        0.2799], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,678][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0642, 0.0826, 0.1126, 0.0769, 0.0935, 0.1148, 0.1052, 0.1297, 0.1162,
        0.1043], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,678][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2085, 0.0913, 0.0018, 0.1382, 0.0056, 0.0047, 0.0159, 0.1919, 0.2121,
        0.1301], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,679][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0676, 0.0472, 0.0139, 0.0611, 0.0289, 0.0910, 0.1007, 0.1636, 0.1958,
        0.2301], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,679][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1108, 0.0981, 0.0335, 0.1598, 0.0310, 0.1484, 0.1170, 0.0781, 0.0327,
        0.1906], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,679][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.2826e-01, 2.1376e-02, 2.3835e-03, 2.6114e-02, 4.4495e-03, 5.8663e-03,
        7.2065e-03, 1.9008e-03, 9.0766e-04, 1.5313e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,683][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1756, 0.0336, 0.0531, 0.0204, 0.0448, 0.1952, 0.1146, 0.1630, 0.1308,
        0.0689], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,687][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4250, 0.2050, 0.0216, 0.2057, 0.0305, 0.0171, 0.0204, 0.0261, 0.0158,
        0.0329], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,691][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.4658e-02, 8.0983e-03, 1.7954e-06, 6.5156e-03, 5.6412e-06, 3.1573e-03,
        3.8783e-04, 8.2068e-02, 1.2631e-02, 8.6248e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:03,696][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0256, 0.0830, 0.1285, 0.0541, 0.0955, 0.0896, 0.0986, 0.1234, 0.1210,
        0.0938, 0.0869], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,697][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0108, 0.0050, 0.0185, 0.0323, 0.0327, 0.1810, 0.1832, 0.1104, 0.0958,
        0.1867, 0.1435], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,698][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2759, 0.1617, 0.0046, 0.1980, 0.0148, 0.0376, 0.0549, 0.0728, 0.0198,
        0.0783, 0.0816], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,698][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0193, 0.0124, 0.0073, 0.0164, 0.0076, 0.0524, 0.0635, 0.1094, 0.1091,
        0.2287, 0.3738], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,698][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0598, 0.0742, 0.1037, 0.0705, 0.0864, 0.1035, 0.0958, 0.1166, 0.1055,
        0.0938, 0.0902], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,699][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5274, 0.1658, 0.0006, 0.2236, 0.0017, 0.0006, 0.0012, 0.0239, 0.0097,
        0.0221, 0.0236], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,699][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0767, 0.0455, 0.0076, 0.0596, 0.0164, 0.0647, 0.0649, 0.1029, 0.1112,
        0.1904, 0.2601], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,700][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1121, 0.0832, 0.0244, 0.1372, 0.0224, 0.1010, 0.0814, 0.0613, 0.0242,
        0.1379, 0.2149], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,700][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8936, 0.0300, 0.0034, 0.0350, 0.0060, 0.0077, 0.0102, 0.0025, 0.0011,
        0.0021, 0.0083], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,703][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1015, 0.0437, 0.0534, 0.0225, 0.0507, 0.2218, 0.1259, 0.1343, 0.0904,
        0.0985, 0.0574], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,708][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4649, 0.2025, 0.0145, 0.2068, 0.0247, 0.0104, 0.0135, 0.0162, 0.0109,
        0.0260, 0.0097], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,711][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([7.3002e-02, 6.3128e-02, 4.9254e-07, 2.9064e-02, 8.5954e-07, 8.1925e-04,
        2.8112e-05, 9.9787e-03, 1.7565e-04, 7.9249e-01, 3.1316e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:03,716][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0271, 0.0797, 0.1067, 0.0617, 0.0783, 0.0830, 0.0895, 0.1032, 0.0955,
        0.0925, 0.0878, 0.0950], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,718][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0177, 0.0083, 0.0189, 0.0544, 0.0309, 0.1597, 0.1579, 0.0756, 0.0673,
        0.1800, 0.1351, 0.0941], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,718][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2020, 0.1302, 0.0121, 0.1559, 0.0319, 0.0475, 0.0494, 0.0890, 0.0303,
        0.0711, 0.0831, 0.0975], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,719][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0049, 0.0048, 0.0049, 0.0065, 0.0060, 0.0395, 0.0656, 0.1094, 0.1497,
        0.1383, 0.3822, 0.0884], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,719][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0535, 0.0674, 0.0970, 0.0628, 0.0795, 0.0969, 0.0866, 0.1087, 0.0986,
        0.0862, 0.0828, 0.0800], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,719][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.1006, 0.0511, 0.0021, 0.0693, 0.0046, 0.0063, 0.0149, 0.1217, 0.1574,
        0.1183, 0.1858, 0.1679], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,720][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0267, 0.0218, 0.0074, 0.0290, 0.0167, 0.0577, 0.0751, 0.0949, 0.1331,
        0.1404, 0.3158, 0.0816], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,720][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1278, 0.0826, 0.0258, 0.1380, 0.0226, 0.1043, 0.0749, 0.0581, 0.0245,
        0.1091, 0.1593, 0.0729], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,720][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.8783, 0.0307, 0.0036, 0.0346, 0.0059, 0.0086, 0.0114, 0.0031, 0.0014,
        0.0023, 0.0086, 0.0115], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,724][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0673, 0.0369, 0.0445, 0.0218, 0.0315, 0.1724, 0.1968, 0.0831, 0.0892,
        0.1042, 0.0574, 0.0949], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,728][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.3404, 0.1898, 0.0293, 0.1903, 0.0475, 0.0238, 0.0267, 0.0310, 0.0212,
        0.0382, 0.0208, 0.0411], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,732][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([3.3986e-05, 1.2809e-05, 4.6338e-08, 1.9682e-05, 1.5313e-07, 5.8736e-04,
        1.6136e-04, 3.9701e-03, 1.9317e-03, 9.4553e-02, 8.9059e-01, 8.1370e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:03,737][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0164, 0.0677, 0.1044, 0.0504, 0.0801, 0.0748, 0.0850, 0.1010, 0.0906,
        0.0804, 0.0777, 0.0927, 0.0790], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,738][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0038, 0.0073, 0.0150, 0.0592, 0.0247, 0.1923, 0.1773, 0.0607, 0.0447,
        0.1871, 0.1262, 0.0787, 0.0229], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,739][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0876, 0.0732, 0.0147, 0.0871, 0.0261, 0.0634, 0.0681, 0.1177, 0.0469,
        0.0928, 0.1247, 0.1234, 0.0741], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,739][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0047, 0.0044, 0.0039, 0.0055, 0.0051, 0.0371, 0.0525, 0.0949, 0.1396,
        0.1342, 0.3605, 0.1137, 0.0438], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,740][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0493, 0.0610, 0.0903, 0.0580, 0.0743, 0.0884, 0.0804, 0.1015, 0.0912,
        0.0788, 0.0767, 0.0743, 0.0757], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,740][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0026, 0.0022, 0.0007, 0.0033, 0.0014, 0.0050, 0.0233, 0.0903, 0.4059,
        0.1136, 0.2205, 0.1142, 0.0170], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,740][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0143, 0.0126, 0.0054, 0.0164, 0.0099, 0.0535, 0.0647, 0.0937, 0.1478,
        0.1275, 0.3168, 0.0852, 0.0524], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,741][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0539, 0.0639, 0.0271, 0.1096, 0.0241, 0.1230, 0.0724, 0.0531, 0.0239,
        0.1203, 0.1905, 0.0870, 0.0514], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,741][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.8733, 0.0281, 0.0035, 0.0356, 0.0066, 0.0090, 0.0117, 0.0032, 0.0014,
        0.0022, 0.0082, 0.0106, 0.0066], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,745][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0715, 0.0380, 0.0667, 0.0239, 0.0306, 0.1443, 0.1471, 0.0967, 0.0948,
        0.0941, 0.0606, 0.0978, 0.0341], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,750][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.2494, 0.1544, 0.0357, 0.1617, 0.0606, 0.0360, 0.0360, 0.0393, 0.0357,
        0.0507, 0.0274, 0.0442, 0.0688], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,753][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([1.4310e-06, 1.5570e-06, 1.8820e-08, 2.0047e-06, 2.3988e-08, 1.5131e-04,
        5.6231e-05, 3.3469e-03, 5.0163e-03, 8.0223e-02, 8.9135e-01, 1.9402e-02,
        4.4890e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:03,759][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0141, 0.0611, 0.0995, 0.0419, 0.0766, 0.0692, 0.0763, 0.1004, 0.0881,
        0.0739, 0.0703, 0.0873, 0.0761, 0.0651], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,759][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0108, 0.0038, 0.0138, 0.0249, 0.0228, 0.1320, 0.1329, 0.0768, 0.0589,
        0.1472, 0.1172, 0.0903, 0.0247, 0.1439], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,760][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1902, 0.1098, 0.0068, 0.1411, 0.0205, 0.0324, 0.0312, 0.0562, 0.0174,
        0.0579, 0.0649, 0.0795, 0.0669, 0.1253], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,760][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0069, 0.0057, 0.0045, 0.0080, 0.0053, 0.0251, 0.0332, 0.0583, 0.0816,
        0.0999, 0.2452, 0.0877, 0.0486, 0.2901], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,760][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0466, 0.0570, 0.0822, 0.0539, 0.0673, 0.0834, 0.0739, 0.0938, 0.0833,
        0.0735, 0.0702, 0.0674, 0.0679, 0.0796], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,761][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0567, 0.0258, 0.0005, 0.0393, 0.0012, 0.0014, 0.0053, 0.0728, 0.1534,
        0.0735, 0.1491, 0.1361, 0.0230, 0.2619], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,761][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0300, 0.0195, 0.0050, 0.0261, 0.0114, 0.0350, 0.0394, 0.0639, 0.0620,
        0.0959, 0.1696, 0.0840, 0.0625, 0.2957], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,762][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0427, 0.0524, 0.0215, 0.0792, 0.0187, 0.1034, 0.0734, 0.0508, 0.0208,
        0.1236, 0.1724, 0.0690, 0.0367, 0.1353], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,765][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.8867, 0.0266, 0.0035, 0.0316, 0.0055, 0.0070, 0.0090, 0.0023, 0.0011,
        0.0020, 0.0064, 0.0085, 0.0056, 0.0041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,771][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0748, 0.0334, 0.0553, 0.0172, 0.0348, 0.1553, 0.1066, 0.0706, 0.0989,
        0.0837, 0.0508, 0.1260, 0.0381, 0.0543], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,776][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.3781, 0.1846, 0.0233, 0.1828, 0.0298, 0.0148, 0.0164, 0.0194, 0.0125,
        0.0325, 0.0134, 0.0310, 0.0394, 0.0219], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,779][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([5.7729e-05, 2.2012e-05, 8.7771e-09, 2.4217e-05, 2.2258e-08, 1.8430e-05,
        1.8888e-06, 1.5557e-04, 2.5246e-05, 6.3518e-03, 1.0485e-02, 9.6254e-03,
        5.3187e-04, 9.7270e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:03,780][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0175, 0.0578, 0.0941, 0.0394, 0.0691, 0.0653, 0.0713, 0.0883, 0.0892,
        0.0669, 0.0642, 0.0841, 0.0691, 0.0693, 0.0545], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,780][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0149, 0.0034, 0.0127, 0.0207, 0.0204, 0.1009, 0.1079, 0.0670, 0.0583,
        0.1150, 0.0963, 0.0740, 0.0240, 0.1271, 0.1575], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,781][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2449, 0.1247, 0.0027, 0.1575, 0.0091, 0.0226, 0.0272, 0.0373, 0.0105,
        0.0426, 0.0402, 0.0645, 0.0340, 0.0996, 0.0828], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,781][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0139, 0.0073, 0.0022, 0.0102, 0.0028, 0.0136, 0.0170, 0.0287, 0.0285,
        0.0639, 0.0983, 0.0657, 0.0294, 0.2086, 0.4098], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,781][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0450, 0.0548, 0.0765, 0.0514, 0.0636, 0.0757, 0.0701, 0.0844, 0.0771,
        0.0685, 0.0659, 0.0626, 0.0629, 0.0698, 0.0718], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,782][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2464, 0.0796, 0.0002, 0.1269, 0.0009, 0.0004, 0.0011, 0.0304, 0.0204,
        0.0291, 0.0502, 0.0758, 0.0150, 0.1307, 0.1929], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,782][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0472, 0.0246, 0.0030, 0.0327, 0.0069, 0.0189, 0.0184, 0.0296, 0.0265,
        0.0541, 0.0704, 0.0608, 0.0452, 0.2381, 0.3239], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,786][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1130, 0.0615, 0.0147, 0.1018, 0.0135, 0.0605, 0.0500, 0.0377, 0.0150,
        0.0781, 0.1219, 0.0488, 0.0284, 0.0846, 0.1706], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,791][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.8582, 0.0295, 0.0037, 0.0353, 0.0067, 0.0081, 0.0104, 0.0032, 0.0016,
        0.0025, 0.0082, 0.0114, 0.0071, 0.0044, 0.0096], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,796][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0922, 0.0202, 0.0405, 0.0130, 0.0366, 0.1013, 0.1093, 0.0977, 0.0981,
        0.0618, 0.0420, 0.0784, 0.0412, 0.0647, 0.1030], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,800][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4375, 0.1850, 0.0140, 0.1851, 0.0216, 0.0081, 0.0125, 0.0149, 0.0094,
        0.0217, 0.0075, 0.0244, 0.0309, 0.0140, 0.0134], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,800][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.2626e-04, 2.1803e-04, 6.4533e-10, 1.6325e-04, 2.8133e-09, 2.6042e-06,
        6.3950e-08, 9.8620e-06, 2.6099e-07, 7.4538e-04, 5.7918e-05, 2.8042e-03,
        1.4592e-04, 6.9023e-01, 3.0540e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:03,821][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:03,823][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,824][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,824][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,825][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,826][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,826][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,827][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,828][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,828][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,829][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,830][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,830][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:03,831][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4111, 0.5889], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,832][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4159, 0.5841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,832][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4650, 0.5350], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,833][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3883, 0.6117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,838][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6344, 0.3656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,842][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4124, 0.5876], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,844][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4348, 0.5652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,845][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2857, 0.7143], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,846][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4766, 0.5234], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,846][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4751, 0.5249], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,848][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5243, 0.4757], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,854][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3843, 0.6157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:03,858][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.4247, 0.3877, 0.1877], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,864][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.2608, 0.3036, 0.4356], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,865][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.4506, 0.3940, 0.1554], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,866][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.2732, 0.3166, 0.4102], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,866][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.7474, 0.2362, 0.0165], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,867][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.3487, 0.3544, 0.2969], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,870][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.3801, 0.3981, 0.2219], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,876][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.1536, 0.2303, 0.6162], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,881][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.5845, 0.3355, 0.0799], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,884][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.4859, 0.3666, 0.1475], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,885][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.5675, 0.3470, 0.0855], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,886][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.8985, 0.0980, 0.0036], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:03,886][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1592, 0.2278, 0.3221, 0.2909], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,888][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1381, 0.1975, 0.4316, 0.2329], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,893][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2294, 0.2544, 0.2445, 0.2717], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,898][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1194, 0.1890, 0.4596, 0.2320], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,904][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4305, 0.2465, 0.0631, 0.2599], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,905][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1511, 0.2154, 0.3814, 0.2522], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,906][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1831, 0.2326, 0.3065, 0.2778], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,906][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0591, 0.1638, 0.5381, 0.2390], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,908][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2375, 0.2533, 0.2502, 0.2590], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,912][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2268, 0.2446, 0.2519, 0.2766], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,918][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2890, 0.2564, 0.1829, 0.2718], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,924][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0177, 0.0660, 0.7553, 0.1610], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:03,925][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.1902, 0.1941, 0.1150, 0.2567, 0.2439], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,926][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.1171, 0.1395, 0.2116, 0.1770, 0.3548], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,926][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.2680, 0.2297, 0.0959, 0.2618, 0.1446], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,928][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.1509, 0.1599, 0.1922, 0.2028, 0.2943], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,933][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.5453, 0.1970, 0.0185, 0.2155, 0.0238], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,938][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1574, 0.1722, 0.1587, 0.2223, 0.2894], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,944][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.1843, 0.1962, 0.1287, 0.2546, 0.2361], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,945][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0541, 0.0952, 0.2893, 0.1432, 0.4182], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,946][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.3556, 0.2220, 0.0877, 0.2349, 0.0997], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,946][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.2606, 0.2046, 0.1176, 0.2440, 0.1732], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,948][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.3719, 0.2289, 0.0570, 0.2453, 0.0970], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,954][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.3290, 0.2382, 0.0326, 0.3583, 0.0420], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:03,958][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1588, 0.0879, 0.0111, 0.1096, 0.0329, 0.5998], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,964][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1459, 0.1180, 0.0854, 0.1462, 0.1268, 0.3777], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,965][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3456, 0.2222, 0.0293, 0.2642, 0.0703, 0.0684], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,966][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0389, 0.0499, 0.0862, 0.0670, 0.0947, 0.6634], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,966][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6008, 0.1777, 0.0078, 0.1973, 0.0100, 0.0065], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,970][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1551, 0.1235, 0.0640, 0.1512, 0.0974, 0.4088], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,974][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1500, 0.1215, 0.0594, 0.1604, 0.1201, 0.3887], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,980][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0116, 0.0165, 0.0330, 0.0236, 0.0524, 0.8630], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,984][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4542, 0.2301, 0.0226, 0.2186, 0.0405, 0.0340], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,985][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2698, 0.1733, 0.0559, 0.1914, 0.0967, 0.2129], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,986][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.4450, 0.2348, 0.0282, 0.2296, 0.0389, 0.0234], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,986][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([8.7546e-02, 3.4351e-02, 2.1594e-04, 3.4525e-02, 8.8360e-04, 8.4248e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:03,988][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0502, 0.0315, 0.0037, 0.0447, 0.0110, 0.4701, 0.3887],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:03,994][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0972, 0.0717, 0.0315, 0.0933, 0.0568, 0.2758, 0.3738],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,000][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3295, 0.2018, 0.0226, 0.2493, 0.0554, 0.0645, 0.0769],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,004][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0355, 0.0343, 0.0380, 0.0477, 0.0517, 0.3507, 0.4421],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,005][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6181, 0.1725, 0.0057, 0.1879, 0.0066, 0.0046, 0.0046],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,006][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1225, 0.0880, 0.0246, 0.1150, 0.0558, 0.2294, 0.3647],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,007][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1216, 0.0934, 0.0333, 0.1263, 0.0771, 0.2621, 0.2863],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,010][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0114, 0.0155, 0.0210, 0.0219, 0.0396, 0.4888, 0.4018],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,015][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4493, 0.2127, 0.0233, 0.2044, 0.0407, 0.0356, 0.0339],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,020][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2467, 0.1472, 0.0336, 0.1713, 0.0653, 0.1714, 0.1645],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,024][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4499, 0.2197, 0.0285, 0.2247, 0.0386, 0.0164, 0.0221],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,025][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.7366e-02, 2.6660e-02, 3.6994e-05, 2.7196e-02, 1.4929e-04, 8.8207e-01,
        3.6525e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,026][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0448, 0.0254, 0.0022, 0.0408, 0.0063, 0.2823, 0.2886, 0.3097],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,027][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0531, 0.0376, 0.0129, 0.0524, 0.0258, 0.1347, 0.2333, 0.4502],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,030][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2853, 0.1813, 0.0193, 0.2220, 0.0461, 0.0570, 0.0720, 0.1170],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,035][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0216, 0.0186, 0.0140, 0.0267, 0.0191, 0.1892, 0.2674, 0.4435],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,041][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.6241, 0.1702, 0.0050, 0.1820, 0.0060, 0.0038, 0.0041, 0.0049],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,045][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0806, 0.0533, 0.0103, 0.0746, 0.0234, 0.1247, 0.2036, 0.4295],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,046][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1011, 0.0723, 0.0193, 0.0991, 0.0465, 0.1706, 0.2123, 0.2788],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,046][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0080, 0.0103, 0.0142, 0.0153, 0.0237, 0.3307, 0.2448, 0.3530],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,047][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.4301, 0.2043, 0.0248, 0.1953, 0.0374, 0.0339, 0.0308, 0.0434],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,049][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1738, 0.0963, 0.0155, 0.1173, 0.0393, 0.1225, 0.1465, 0.2889],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,055][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.4498, 0.2182, 0.0224, 0.2196, 0.0274, 0.0153, 0.0199, 0.0273],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,059][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([9.0721e-03, 6.1556e-03, 1.8293e-06, 8.6322e-03, 7.9479e-06, 5.0988e-02,
        2.3680e-02, 9.0146e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,065][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0268, 0.0127, 0.0008, 0.0207, 0.0022, 0.1698, 0.2207, 0.2083, 0.3378],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,066][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0363, 0.0217, 0.0057, 0.0312, 0.0108, 0.0805, 0.1347, 0.3068, 0.3723],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,067][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2834, 0.1692, 0.0172, 0.2137, 0.0426, 0.0503, 0.0627, 0.1212, 0.0398],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,068][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0146, 0.0111, 0.0093, 0.0167, 0.0130, 0.1159, 0.1742, 0.3050, 0.3401],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,070][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.6458, 0.1586, 0.0036, 0.1758, 0.0055, 0.0028, 0.0030, 0.0036, 0.0014],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,075][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0415, 0.0259, 0.0043, 0.0386, 0.0099, 0.0761, 0.1564, 0.3310, 0.3164],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,080][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0692, 0.0471, 0.0104, 0.0662, 0.0279, 0.1207, 0.1523, 0.2538, 0.2525],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,086][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0041, 0.0053, 0.0068, 0.0078, 0.0124, 0.1897, 0.1468, 0.1949, 0.4323],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,087][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.4631, 0.1927, 0.0179, 0.1951, 0.0343, 0.0222, 0.0227, 0.0365, 0.0154],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,087][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1518, 0.0723, 0.0118, 0.0951, 0.0256, 0.0696, 0.1005, 0.2537, 0.2194],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,088][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.4539, 0.2129, 0.0193, 0.2173, 0.0350, 0.0094, 0.0200, 0.0208, 0.0114],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,090][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([1.7816e-02, 7.1549e-03, 5.9824e-07, 8.1263e-03, 1.9862e-06, 2.2202e-02,
        6.0163e-03, 9.2925e-01, 9.4301e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,094][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0373, 0.0175, 0.0016, 0.0229, 0.0036, 0.0973, 0.1035, 0.1321, 0.1881,
        0.3962], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,100][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0357, 0.0214, 0.0069, 0.0269, 0.0120, 0.0474, 0.0720, 0.1639, 0.2420,
        0.3717], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,106][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2550, 0.1584, 0.0208, 0.1907, 0.0413, 0.0542, 0.0573, 0.1021, 0.0409,
        0.0795], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,107][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0168, 0.0139, 0.0124, 0.0185, 0.0142, 0.0757, 0.1124, 0.1994, 0.2569,
        0.2799], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,108][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5944, 0.1706, 0.0066, 0.1878, 0.0076, 0.0049, 0.0042, 0.0046, 0.0027,
        0.0166], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,109][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0538, 0.0329, 0.0074, 0.0432, 0.0125, 0.0527, 0.0944, 0.1950, 0.2245,
        0.2837], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,113][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0676, 0.0472, 0.0139, 0.0611, 0.0289, 0.0910, 0.1007, 0.1636, 0.1958,
        0.2301], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,118][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0044, 0.0059, 0.0080, 0.0083, 0.0135, 0.1482, 0.1198, 0.1383, 0.2953,
        0.2583], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,125][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3882, 0.1908, 0.0239, 0.1846, 0.0385, 0.0334, 0.0283, 0.0443, 0.0273,
        0.0405], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,127][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1341, 0.0744, 0.0151, 0.0843, 0.0292, 0.0616, 0.0693, 0.1787, 0.2080,
        0.1452], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,128][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4250, 0.2050, 0.0216, 0.2057, 0.0305, 0.0171, 0.0204, 0.0261, 0.0158,
        0.0329], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,128][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.4658e-02, 8.0983e-03, 1.7954e-06, 6.5156e-03, 5.6412e-06, 3.1573e-03,
        3.8783e-04, 8.2068e-02, 1.2631e-02, 8.6248e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,129][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.6544e-02, 9.9697e-03, 3.5747e-04, 1.3393e-02, 8.6062e-04, 5.0019e-02,
        3.8233e-02, 3.8983e-02, 4.0170e-02, 2.4928e-01, 5.3219e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,133][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0360, 0.0171, 0.0030, 0.0211, 0.0047, 0.0195, 0.0268, 0.0620, 0.0642,
        0.2613, 0.4842], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,139][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3268, 0.1659, 0.0093, 0.2083, 0.0228, 0.0320, 0.0366, 0.0649, 0.0207,
        0.0592, 0.0535], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,145][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0193, 0.0124, 0.0073, 0.0164, 0.0076, 0.0524, 0.0635, 0.1094, 0.1091,
        0.2287, 0.3738], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,147][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6224, 0.1594, 0.0046, 0.1799, 0.0052, 0.0032, 0.0031, 0.0033, 0.0016,
        0.0118, 0.0056], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,148][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0518, 0.0262, 0.0024, 0.0322, 0.0046, 0.0263, 0.0510, 0.0833, 0.0712,
        0.2316, 0.4193], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,149][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0767, 0.0455, 0.0076, 0.0596, 0.0164, 0.0647, 0.0649, 0.1029, 0.1112,
        0.1904, 0.2601], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,149][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0040, 0.0044, 0.0043, 0.0064, 0.0073, 0.0880, 0.0644, 0.0838, 0.1456,
        0.1601, 0.4316], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,153][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4732, 0.1924, 0.0140, 0.1830, 0.0261, 0.0198, 0.0175, 0.0258, 0.0140,
        0.0250, 0.0094], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,159][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2165, 0.0970, 0.0102, 0.1093, 0.0238, 0.0442, 0.0484, 0.1128, 0.1108,
        0.1222, 0.1048], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,165][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4649, 0.2025, 0.0145, 0.2068, 0.0247, 0.0104, 0.0135, 0.0162, 0.0109,
        0.0260, 0.0097], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,167][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.3002e-02, 6.3128e-02, 4.9254e-07, 2.9064e-02, 8.5954e-07, 8.1925e-04,
        2.8112e-05, 9.9787e-03, 1.7565e-04, 7.9249e-01, 3.1316e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,168][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0110, 0.0066, 0.0009, 0.0092, 0.0021, 0.0403, 0.0530, 0.0636, 0.1114,
        0.1502, 0.4760, 0.0755], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,169][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0113, 0.0079, 0.0031, 0.0104, 0.0046, 0.0232, 0.0320, 0.0749, 0.0908,
        0.1619, 0.4653, 0.1147], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,170][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1578, 0.1106, 0.0257, 0.1302, 0.0463, 0.0552, 0.0547, 0.1052, 0.0461,
        0.0812, 0.0910, 0.0960], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,173][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0049, 0.0048, 0.0049, 0.0065, 0.0060, 0.0395, 0.0656, 0.1094, 0.1497,
        0.1383, 0.3822, 0.0884], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,179][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.5305, 0.1752, 0.0094, 0.1851, 0.0125, 0.0081, 0.0064, 0.0079, 0.0039,
        0.0241, 0.0129, 0.0240], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,185][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0129, 0.0098, 0.0035, 0.0127, 0.0065, 0.0318, 0.0512, 0.0886, 0.1322,
        0.1388, 0.4181, 0.0939], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,187][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0267, 0.0218, 0.0074, 0.0290, 0.0167, 0.0577, 0.0751, 0.0949, 0.1331,
        0.1404, 0.3158, 0.0816], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,188][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0013, 0.0021, 0.0041, 0.0031, 0.0061, 0.0761, 0.0730, 0.0723, 0.1449,
        0.1259, 0.4379, 0.0531], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,189][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.2752, 0.1571, 0.0401, 0.1532, 0.0484, 0.0479, 0.0420, 0.0576, 0.0370,
        0.0486, 0.0290, 0.0640], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,190][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0724, 0.0442, 0.0123, 0.0526, 0.0210, 0.0559, 0.0693, 0.1211, 0.1615,
        0.1155, 0.1578, 0.1164], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,194][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.3404, 0.1898, 0.0293, 0.1903, 0.0475, 0.0238, 0.0267, 0.0310, 0.0212,
        0.0382, 0.0208, 0.0411], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,197][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([3.3986e-05, 1.2809e-05, 4.6338e-08, 1.9682e-05, 1.5313e-07, 5.8736e-04,
        1.6136e-04, 3.9701e-03, 1.9317e-03, 9.4553e-02, 8.9059e-01, 8.1370e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,203][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0038, 0.0026, 0.0007, 0.0035, 0.0014, 0.0313, 0.0487, 0.0552, 0.1171,
        0.1400, 0.5095, 0.0611, 0.0250], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,207][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0047, 0.0039, 0.0029, 0.0050, 0.0045, 0.0173, 0.0318, 0.0646, 0.1215,
        0.1343, 0.4644, 0.0971, 0.0481], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,208][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1024, 0.0818, 0.0248, 0.0955, 0.0391, 0.0591, 0.0627, 0.1056, 0.0547,
        0.0845, 0.1032, 0.1040, 0.0826], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,209][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0047, 0.0044, 0.0039, 0.0055, 0.0051, 0.0371, 0.0525, 0.0949, 0.1396,
        0.1342, 0.3605, 0.1137, 0.0438], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,210][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.4318, 0.1675, 0.0167, 0.1857, 0.0194, 0.0114, 0.0103, 0.0103, 0.0095,
        0.0372, 0.0227, 0.0257, 0.0519], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,213][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0074, 0.0062, 0.0028, 0.0080, 0.0049, 0.0277, 0.0516, 0.0800, 0.1346,
        0.1286, 0.4042, 0.1008, 0.0431], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,219][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0143, 0.0126, 0.0054, 0.0164, 0.0099, 0.0535, 0.0647, 0.0937, 0.1478,
        0.1275, 0.3168, 0.0852, 0.0524], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,225][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0011, 0.0018, 0.0043, 0.0026, 0.0061, 0.0637, 0.0713, 0.0657, 0.1428,
        0.1181, 0.4406, 0.0517, 0.0301], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,229][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1816, 0.1197, 0.0458, 0.1233, 0.0511, 0.0606, 0.0527, 0.0668, 0.0589,
        0.0625, 0.0477, 0.0710, 0.0583], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,230][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0482, 0.0319, 0.0118, 0.0373, 0.0186, 0.0440, 0.0606, 0.1217, 0.1703,
        0.1007, 0.1508, 0.1093, 0.0949], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,231][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.2494, 0.1544, 0.0357, 0.1617, 0.0606, 0.0360, 0.0360, 0.0393, 0.0357,
        0.0507, 0.0274, 0.0442, 0.0688], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,232][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([1.4310e-06, 1.5570e-06, 1.8820e-08, 2.0047e-06, 2.3988e-08, 1.5131e-04,
        5.6231e-05, 3.3469e-03, 5.0163e-03, 8.0223e-02, 8.9135e-01, 1.9402e-02,
        4.4890e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,237][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0313, 0.0104, 0.0006, 0.0139, 0.0014, 0.0196, 0.0220, 0.0342, 0.0291,
        0.1066, 0.1975, 0.0705, 0.0304, 0.4324], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,243][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0177, 0.0088, 0.0018, 0.0113, 0.0028, 0.0106, 0.0141, 0.0410, 0.0412,
        0.1247, 0.2863, 0.1162, 0.0380, 0.2855], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,249][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1709, 0.1015, 0.0162, 0.1271, 0.0340, 0.0354, 0.0313, 0.0658, 0.0261,
        0.0577, 0.0591, 0.0775, 0.0798, 0.1175], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,249][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0069, 0.0057, 0.0045, 0.0080, 0.0053, 0.0251, 0.0332, 0.0583, 0.0816,
        0.0999, 0.2452, 0.0877, 0.0486, 0.2901], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,250][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.5563, 0.1632, 0.0062, 0.1796, 0.0079, 0.0054, 0.0035, 0.0049, 0.0025,
        0.0154, 0.0070, 0.0126, 0.0232, 0.0123], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,251][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0258, 0.0144, 0.0023, 0.0185, 0.0039, 0.0159, 0.0293, 0.0508, 0.0621,
        0.1113, 0.2592, 0.1033, 0.0439, 0.2592], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,255][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0300, 0.0195, 0.0050, 0.0261, 0.0114, 0.0350, 0.0394, 0.0639, 0.0620,
        0.0959, 0.1696, 0.0840, 0.0625, 0.2957], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,261][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0015, 0.0021, 0.0035, 0.0030, 0.0054, 0.0711, 0.0509, 0.0533, 0.1046,
        0.1029, 0.2632, 0.0434, 0.0254, 0.2697], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,267][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.3318, 0.1705, 0.0192, 0.1608, 0.0290, 0.0262, 0.0230, 0.0379, 0.0222,
        0.0289, 0.0138, 0.0487, 0.0361, 0.0518], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,269][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1040, 0.0476, 0.0069, 0.0546, 0.0135, 0.0258, 0.0253, 0.0796, 0.0970,
        0.0700, 0.0640, 0.1269, 0.0793, 0.2054], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,270][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.3781, 0.1846, 0.0233, 0.1828, 0.0298, 0.0148, 0.0164, 0.0194, 0.0125,
        0.0325, 0.0134, 0.0310, 0.0394, 0.0219], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,270][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([5.7729e-05, 2.2012e-05, 8.7771e-09, 2.4217e-05, 2.2258e-08, 1.8430e-05,
        1.8888e-06, 1.5557e-04, 2.5246e-05, 6.3518e-03, 1.0485e-02, 9.6254e-03,
        5.3187e-04, 9.7270e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,272][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2426e-02, 3.8109e-03, 7.9246e-05, 5.3736e-03, 2.1371e-04, 6.0063e-03,
        4.9282e-03, 5.3435e-03, 5.6125e-03, 3.0050e-02, 5.7459e-02, 1.6291e-02,
        6.0600e-03, 1.7487e-01, 6.7148e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,278][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0232, 0.0089, 0.0009, 0.0119, 0.0016, 0.0065, 0.0080, 0.0164, 0.0189,
        0.0712, 0.1332, 0.0691, 0.0235, 0.2426, 0.3639], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,284][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2510, 0.1237, 0.0080, 0.1547, 0.0197, 0.0231, 0.0235, 0.0418, 0.0152,
        0.0393, 0.0325, 0.0692, 0.0523, 0.0873, 0.0589], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,288][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0139, 0.0073, 0.0022, 0.0102, 0.0028, 0.0136, 0.0170, 0.0287, 0.0285,
        0.0639, 0.0983, 0.0657, 0.0294, 0.2086, 0.4098], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,289][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.6167, 0.1524, 0.0040, 0.1670, 0.0047, 0.0027, 0.0024, 0.0027, 0.0015,
        0.0096, 0.0038, 0.0088, 0.0128, 0.0066, 0.0044], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,290][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0325, 0.0145, 0.0011, 0.0193, 0.0021, 0.0081, 0.0135, 0.0249, 0.0212,
        0.0626, 0.1231, 0.0647, 0.0246, 0.2199, 0.3680], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,291][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0472, 0.0246, 0.0030, 0.0327, 0.0069, 0.0189, 0.0184, 0.0296, 0.0265,
        0.0541, 0.0704, 0.0608, 0.0452, 0.2381, 0.3239], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,294][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0020, 0.0022, 0.0016, 0.0031, 0.0029, 0.0342, 0.0238, 0.0294, 0.0480,
        0.0615, 0.1386, 0.0287, 0.0162, 0.1597, 0.4483], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,300][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4219, 0.1676, 0.0134, 0.1618, 0.0237, 0.0149, 0.0143, 0.0239, 0.0127,
        0.0193, 0.0079, 0.0391, 0.0304, 0.0328, 0.0163], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,306][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1477, 0.0574, 0.0052, 0.0666, 0.0102, 0.0156, 0.0160, 0.0446, 0.0382,
        0.0443, 0.0355, 0.0740, 0.0609, 0.1656, 0.2182], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,308][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4375, 0.1850, 0.0140, 0.1851, 0.0216, 0.0081, 0.0125, 0.0149, 0.0094,
        0.0217, 0.0075, 0.0244, 0.0309, 0.0140, 0.0134], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,309][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.2626e-04, 2.1803e-04, 6.4533e-10, 1.6325e-04, 2.8133e-09, 2.6042e-06,
        6.3950e-08, 9.8620e-06, 2.6099e-07, 7.4538e-04, 5.7918e-05, 2.8042e-03,
        1.4592e-04, 6.9023e-01, 3.0540e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,312][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:04,315][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13318],
        [ 8956],
        [ 8919],
        [12688],
        [13410],
        [ 9650],
        [10947],
        [ 8253],
        [ 4337],
        [ 5074],
        [ 8003],
        [ 8305],
        [ 4913],
        [ 7809],
        [ 8029]], device='cuda:0')
[2024-07-24 10:24:04,318][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14597],
        [12913],
        [19114],
        [16592],
        [22823],
        [22589],
        [22980],
        [18866],
        [12318],
        [13674],
        [18450],
        [17397],
        [10648],
        [18676],
        [18583]], device='cuda:0')
[2024-07-24 10:24:04,320][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19689],
        [18606],
        [13743],
        [14046],
        [15033],
        [14968],
        [15461],
        [15973],
        [17494],
        [17545],
        [17713],
        [17927],
        [17732],
        [17884],
        [18018]], device='cuda:0')
[2024-07-24 10:24:04,323][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[6734],
        [2387],
        [3183],
        [3860],
        [4351],
        [4044],
        [4437],
        [4812],
        [5283],
        [5628],
        [5471],
        [5416],
        [5268],
        [5843],
        [5574]], device='cuda:0')
[2024-07-24 10:24:04,325][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20080],
        [16418],
        [28016],
        [36953],
        [35511],
        [26527],
        [27831],
        [24399],
        [24487],
        [26243],
        [26911],
        [27436],
        [29571],
        [30021],
        [29291]], device='cuda:0')
[2024-07-24 10:24:04,328][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[   65],
        [  183],
        [31682],
        [39681],
        [35620],
        [10567],
        [15957],
        [13365],
        [14594],
        [10509],
        [ 9060],
        [ 9507],
        [ 9967],
        [ 6081],
        [ 3388]], device='cuda:0')
[2024-07-24 10:24:04,330][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7750],
        [ 8513],
        [ 8174],
        [ 8220],
        [ 8729],
        [ 9273],
        [ 9623],
        [10568],
        [11624],
        [11735],
        [11713],
        [11403],
        [11299],
        [11116],
        [11037]], device='cuda:0')
[2024-07-24 10:24:04,332][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[  765],
        [  478],
        [  797],
        [  602],
        [ 2327],
        [ 3701],
        [ 2437],
        [14433],
        [14876],
        [ 5508],
        [  525],
        [ 5929],
        [ 8918],
        [ 6024],
        [ 2616]], device='cuda:0')
[2024-07-24 10:24:04,334][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[49457],
        [49328],
        [49259],
        [49146],
        [49296],
        [49069],
        [49081],
        [49042],
        [47682],
        [48262],
        [49008],
        [48809],
        [48683],
        [47919],
        [48436]], device='cuda:0')
[2024-07-24 10:24:04,335][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[4865],
        [2628],
        [1432],
        [1689],
        [1482],
        [1324],
        [1328],
        [1229],
        [1158],
        [1298],
        [1460],
        [1366],
        [1215],
        [1293],
        [1410]], device='cuda:0')
[2024-07-24 10:24:04,337][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16481],
        [18026],
        [17183],
        [19500],
        [18032],
        [18457],
        [18888],
        [17864],
        [17759],
        [17792],
        [18419],
        [18829],
        [18985],
        [18640],
        [19252]], device='cuda:0')
[2024-07-24 10:24:04,339][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[7572],
        [7143],
        [7519],
        [7315],
        [8999],
        [4429],
        [5394],
        [5536],
        [6643],
        [6554],
        [6322],
        [6585],
        [7088],
        [7097],
        [8148]], device='cuda:0')
[2024-07-24 10:24:04,342][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14957],
        [20711],
        [20289],
        [22101],
        [12856],
        [16386],
        [16064],
        [20530],
        [19190],
        [20453],
        [19521],
        [20736],
        [16653],
        [16828],
        [16645]], device='cuda:0')
[2024-07-24 10:24:04,344][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[4745],
        [3976],
        [4629],
        [5574],
        [3697],
        [ 636],
        [ 585],
        [1861],
        [2049],
        [ 353],
        [ 363],
        [ 306],
        [ 313],
        [ 353],
        [ 259]], device='cuda:0')
[2024-07-24 10:24:04,347][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24841],
        [25151],
        [27141],
        [26809],
        [26747],
        [26337],
        [26968],
        [23822],
        [21995],
        [23382],
        [23029],
        [22512],
        [22140],
        [22425],
        [24584]], device='cuda:0')
[2024-07-24 10:24:04,349][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 2509],
        [ 2173],
        [ 6235],
        [11035],
        [10243],
        [ 6193],
        [ 6652],
        [ 8334],
        [ 9615],
        [ 9886],
        [ 7355],
        [ 8688],
        [ 8634],
        [ 4592],
        [ 4004]], device='cuda:0')
[2024-07-24 10:24:04,352][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15309],
        [12396],
        [ 2748],
        [ 2368],
        [ 2198],
        [ 1923],
        [ 1305],
        [  989],
        [ 1077],
        [ 1130],
        [ 1319],
        [  865],
        [  874],
        [  705],
        [  609]], device='cuda:0')
[2024-07-24 10:24:04,355][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10474],
        [ 6464],
        [ 7938],
        [ 7155],
        [ 9153],
        [ 8885],
        [ 9385],
        [16816],
        [18432],
        [17414],
        [13795],
        [14093],
        [13872],
        [14019],
        [13520]], device='cuda:0')
[2024-07-24 10:24:04,357][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[3320],
        [3036],
        [4086],
        [4252],
        [3416],
        [3799],
        [2508],
        [2280],
        [2925],
        [2380],
        [2441],
        [2479],
        [2476],
        [2134],
        [1862]], device='cuda:0')
[2024-07-24 10:24:04,358][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[36092],
        [35043],
        [34801],
        [27592],
        [29529],
        [31405],
        [31621],
        [31445],
        [31973],
        [29678],
        [30473],
        [26495],
        [20734],
        [26903],
        [29713]], device='cuda:0')
[2024-07-24 10:24:04,360][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33098],
        [31079],
        [28928],
        [27143],
        [25815],
        [11818],
        [17997],
        [15611],
        [14227],
        [21448],
        [21710],
        [18238],
        [17692],
        [12419],
        [11124]], device='cuda:0')
[2024-07-24 10:24:04,363][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[8700],
        [7815],
        [7568],
        [7268],
        [8045],
        [4940],
        [3699],
        [5225],
        [4129],
        [4238],
        [3629],
        [3685],
        [3778],
        [2911],
        [3662]], device='cuda:0')
[2024-07-24 10:24:04,365][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34113],
        [33562],
        [37189],
        [37269],
        [37197],
        [40405],
        [40744],
        [41966],
        [41348],
        [41585],
        [42563],
        [42442],
        [42394],
        [42623],
        [41435]], device='cuda:0')
[2024-07-24 10:24:04,368][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[1313],
        [1546],
        [1610],
        [4386],
        [2427],
        [2007],
        [2606],
        [3459],
        [2978],
        [4724],
        [2995],
        [8084],
        [9709],
        [6216],
        [4315]], device='cuda:0')
[2024-07-24 10:24:04,370][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 3746],
        [ 5242],
        [11372],
        [14606],
        [14684],
        [10015],
        [10724],
        [ 8653],
        [ 7750],
        [ 7377],
        [ 8962],
        [10867],
        [10785],
        [12733],
        [10021]], device='cuda:0')
[2024-07-24 10:24:04,373][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7464],
        [ 8248],
        [ 9321],
        [11305],
        [10209],
        [ 8878],
        [ 9462],
        [10090],
        [ 9932],
        [10351],
        [ 9602],
        [11955],
        [13722],
        [11907],
        [11063]], device='cuda:0')
[2024-07-24 10:24:04,376][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[42422],
        [43266],
        [42551],
        [31437],
        [42986],
        [45222],
        [44772],
        [39734],
        [38986],
        [43612],
        [44794],
        [42614],
        [42651],
        [47358],
        [47486]], device='cuda:0')
[2024-07-24 10:24:04,378][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44416],
        [45020],
        [44228],
        [42351],
        [43287],
        [44725],
        [44608],
        [44239],
        [44339],
        [43458],
        [44607],
        [42778],
        [42649],
        [44563],
        [45243]], device='cuda:0')
[2024-07-24 10:24:04,380][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[17480],
        [17841],
        [17091],
        [19531],
        [19254],
        [19225],
        [19052],
        [23346],
        [26436],
        [23789],
        [24447],
        [23745],
        [24524],
        [24429],
        [22035]], device='cuda:0')
[2024-07-24 10:24:04,382][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019],
        [5019]], device='cuda:0')
[2024-07-24 10:24:04,435][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:04,436][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,437][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,437][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,438][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,439][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,439][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,440][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,441][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,441][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,442][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,443][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,443][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,444][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0131, 0.9869], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,445][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3333, 0.6667], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,445][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9788, 0.0212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,447][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5502, 0.4498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,449][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7430, 0.2570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,453][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9523, 0.0477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,456][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9840, 0.0160], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,460][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5237, 0.4763], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,464][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4683, 0.5317], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,465][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6117, 0.3883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,466][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5708, 0.4292], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,466][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5991, 0.4009], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,467][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.0056, 0.3664, 0.6280], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,469][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.1336, 0.7660, 0.1004], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,471][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.4240, 0.0474, 0.5286], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,475][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.3230, 0.3234, 0.3535], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,479][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.6743, 0.2905, 0.0352], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,482][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.4483, 0.3582, 0.1936], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,486][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.1812, 0.0297, 0.7891], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,487][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.1863, 0.1428, 0.6709], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,488][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.5380, 0.3587, 0.1033], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,488][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.5746, 0.2850, 0.1404], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,489][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.4781, 0.2151, 0.3068], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,491][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.1524, 0.0916, 0.7560], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,493][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0010, 0.2832, 0.6363, 0.0796], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,497][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0453, 0.0869, 0.8168, 0.0510], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,499][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([3.5195e-01, 1.1401e-03, 6.4686e-01, 5.3542e-05], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,503][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2409, 0.2544, 0.2878, 0.2169], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,507][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5653, 0.1455, 0.0196, 0.2696], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,508][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1384, 0.0143, 0.8447, 0.0026], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,509][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0812, 0.0020, 0.9143, 0.0026], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,510][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2152, 0.1981, 0.3600, 0.2268], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,511][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2139, 0.2363, 0.2833, 0.2665], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,512][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3359, 0.2377, 0.1705, 0.2559], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,514][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2991, 0.2367, 0.2166, 0.2477], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,515][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1147, 0.1225, 0.6387, 0.1241], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,516][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0012, 0.1693, 0.3751, 0.0861, 0.3683], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,519][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0543, 0.5576, 0.2455, 0.0931, 0.0495], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,523][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.2833, 0.0199, 0.3755, 0.0056, 0.3157], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,527][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.1918, 0.1998, 0.2321, 0.1797, 0.1966], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,530][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.4840, 0.1601, 0.0149, 0.3124, 0.0286], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,532][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.4329, 0.2985, 0.2026, 0.0312, 0.0348], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,533][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.1082, 0.0156, 0.4427, 0.0187, 0.4149], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,533][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1683, 0.1113, 0.3392, 0.1338, 0.2473], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,534][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.3063, 0.2202, 0.0883, 0.2537, 0.1314], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,536][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.3535, 0.1926, 0.1059, 0.2254, 0.1226], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,538][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.3377, 0.1624, 0.1246, 0.1385, 0.2368], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,542][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0846, 0.0539, 0.4894, 0.0537, 0.3184], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:04,545][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0022, 0.1375, 0.2670, 0.0777, 0.2910, 0.2245], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,548][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([2.3932e-02, 2.4025e-02, 1.8358e-02, 6.2815e-02, 8.7059e-01, 2.8220e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,552][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2069, 0.0166, 0.2703, 0.0052, 0.2264, 0.2745], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,554][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1602, 0.1704, 0.2050, 0.1588, 0.1776, 0.1279], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,555][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7222, 0.0933, 0.0058, 0.1414, 0.0098, 0.0275], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,555][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1649, 0.0274, 0.2731, 0.0191, 0.3916, 0.1239], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,556][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0657, 0.0099, 0.2751, 0.0114, 0.2499, 0.3880], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,558][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1898, 0.1211, 0.2648, 0.1799, 0.1871, 0.0573], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,560][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3924, 0.1900, 0.0358, 0.2268, 0.0838, 0.0712], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,564][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3416, 0.1760, 0.0906, 0.2061, 0.1054, 0.0803], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,568][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3630, 0.1524, 0.0513, 0.1883, 0.0633, 0.1817], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,571][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0879, 0.0494, 0.3025, 0.0483, 0.1970, 0.3149], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:04,575][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0014, 0.1327, 0.2264, 0.0640, 0.2166, 0.2242, 0.1347],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,576][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0084, 0.1408, 0.0868, 0.1037, 0.6141, 0.0451, 0.0011],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,577][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1503, 0.0156, 0.2008, 0.0057, 0.1743, 0.2076, 0.2457],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,578][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1428, 0.1492, 0.1779, 0.1424, 0.1608, 0.1164, 0.1104],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,579][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6425, 0.0996, 0.0079, 0.1519, 0.0134, 0.0394, 0.0453],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,582][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1290, 0.0496, 0.2819, 0.0297, 0.2831, 0.1483, 0.0783],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,586][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0484, 0.0065, 0.1994, 0.0074, 0.1839, 0.2776, 0.2767],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,589][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0669, 0.0785, 0.1675, 0.0931, 0.1668, 0.3270, 0.1003],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,593][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3348, 0.1581, 0.0407, 0.2032, 0.0792, 0.1102, 0.0738],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,597][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3129, 0.1621, 0.0841, 0.1895, 0.0977, 0.0734, 0.0802],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,598][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6249, 0.1369, 0.0379, 0.1516, 0.0203, 0.0246, 0.0037],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,599][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0615, 0.0378, 0.2338, 0.0376, 0.1509, 0.2382, 0.2403],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:04,600][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0011, 0.0997, 0.1952, 0.0499, 0.2033, 0.1810, 0.1211, 0.1487],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,602][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0842, 0.1054, 0.0060, 0.1611, 0.5990, 0.0041, 0.0387, 0.0015],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,604][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1221, 0.0119, 0.1606, 0.0043, 0.1416, 0.1713, 0.2068, 0.1814],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,608][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1317, 0.1407, 0.1598, 0.1250, 0.1391, 0.1001, 0.0946, 0.1089],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,613][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.7021, 0.0868, 0.0056, 0.1213, 0.0090, 0.0264, 0.0296, 0.0192],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,617][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1366, 0.0179, 0.2038, 0.0198, 0.3214, 0.1263, 0.0996, 0.0747],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,620][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0476, 0.0065, 0.1539, 0.0072, 0.1408, 0.2166, 0.2136, 0.2138],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,620][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0850, 0.0812, 0.0918, 0.1382, 0.0427, 0.1353, 0.2289, 0.1970],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,621][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.2865, 0.1469, 0.0311, 0.1844, 0.0719, 0.1068, 0.0986, 0.0738],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,622][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2926, 0.1492, 0.0760, 0.1765, 0.0873, 0.0671, 0.0730, 0.0785],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,624][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.3655, 0.1580, 0.0572, 0.1906, 0.0427, 0.0718, 0.0110, 0.1033],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,626][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0435, 0.0346, 0.2054, 0.0328, 0.1334, 0.1983, 0.2015, 0.1506],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:04,631][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0005, 0.0823, 0.2081, 0.0355, 0.1860, 0.1548, 0.1039, 0.1456, 0.0834],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,635][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0813, 0.2228, 0.1636, 0.0849, 0.2078, 0.0163, 0.1940, 0.0279, 0.0013],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,638][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1037, 0.0100, 0.1365, 0.0037, 0.1221, 0.1496, 0.1800, 0.1597, 0.1346],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,642][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1275, 0.1248, 0.1346, 0.1086, 0.1194, 0.0893, 0.0846, 0.0970, 0.1141],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,643][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.5093, 0.0989, 0.0084, 0.1540, 0.0148, 0.0575, 0.0625, 0.0368, 0.0577],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,644][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0499, 0.0091, 0.4766, 0.0031, 0.2190, 0.0706, 0.0356, 0.1268, 0.0093],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,644][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0349, 0.0042, 0.1326, 0.0051, 0.1220, 0.1941, 0.1857, 0.1906, 0.1308],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,647][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0375, 0.0168, 0.1054, 0.0383, 0.3061, 0.0292, 0.1139, 0.2771, 0.0757],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,650][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.3145, 0.1346, 0.0275, 0.1768, 0.0730, 0.0814, 0.0793, 0.0634, 0.0495],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,653][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2666, 0.1384, 0.0699, 0.1630, 0.0819, 0.0642, 0.0698, 0.0745, 0.0719],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,657][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.4556, 0.1599, 0.0414, 0.1616, 0.0300, 0.0600, 0.0088, 0.0291, 0.0535],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,662][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0408, 0.0236, 0.1840, 0.0237, 0.1215, 0.1772, 0.1792, 0.1281, 0.1220],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:04,664][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0007, 0.0808, 0.1777, 0.0322, 0.1706, 0.1457, 0.0936, 0.1363, 0.0885,
        0.0740], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,665][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0084, 0.0089, 0.0994, 0.0073, 0.5532, 0.0138, 0.1081, 0.0134, 0.1857,
        0.0018], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,666][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0926, 0.0075, 0.1252, 0.0023, 0.1066, 0.1298, 0.1579, 0.1410, 0.1188,
        0.1183], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,666][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1066, 0.1054, 0.1242, 0.1004, 0.1125, 0.0818, 0.0770, 0.0929, 0.1097,
        0.0895], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,668][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4942, 0.0737, 0.0057, 0.1334, 0.0103, 0.0459, 0.0523, 0.0354, 0.0507,
        0.0984], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,671][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0621, 0.0044, 0.1818, 0.0074, 0.2087, 0.1321, 0.1140, 0.2026, 0.0595,
        0.0273], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,675][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0234, 0.0021, 0.1194, 0.0028, 0.1094, 0.1754, 0.1686, 0.1739, 0.1143,
        0.1108], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,679][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0131, 0.0091, 0.0313, 0.0177, 0.0398, 0.0140, 0.0671, 0.7056, 0.0865,
        0.0159], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,684][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2621, 0.1248, 0.0334, 0.1565, 0.0623, 0.0817, 0.0712, 0.0585, 0.0575,
        0.0919], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,686][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2576, 0.1319, 0.0648, 0.1527, 0.0744, 0.0588, 0.0642, 0.0702, 0.0682,
        0.0572], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,687][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5250, 0.1548, 0.0538, 0.1462, 0.0244, 0.0268, 0.0040, 0.0354, 0.0151,
        0.0144], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,688][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0393, 0.0217, 0.1612, 0.0216, 0.1008, 0.1531, 0.1538, 0.1088, 0.1020,
        0.1377], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:04,689][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0006, 0.0803, 0.1618, 0.0265, 0.1487, 0.1421, 0.0890, 0.1206, 0.0854,
        0.0722, 0.0728], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,691][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0063, 0.0168, 0.0708, 0.0050, 0.3131, 0.0081, 0.0963, 0.0231, 0.4415,
        0.0140, 0.0050], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,694][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0782, 0.0072, 0.1103, 0.0022, 0.0947, 0.1139, 0.1371, 0.1216, 0.1039,
        0.1050, 0.1261], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,698][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0947, 0.0954, 0.1115, 0.0910, 0.1028, 0.0752, 0.0712, 0.0871, 0.1048,
        0.0854, 0.0811], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,702][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3628, 0.0768, 0.0073, 0.1271, 0.0126, 0.0519, 0.0588, 0.0409, 0.0543,
        0.1066, 0.1008], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,706][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0485, 0.0118, 0.1812, 0.0034, 0.2567, 0.1276, 0.0799, 0.1732, 0.0545,
        0.0379, 0.0252], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,708][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0251, 0.0024, 0.1036, 0.0028, 0.0963, 0.1467, 0.1428, 0.1438, 0.0973,
        0.0962, 0.1430], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,709][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0305, 0.0220, 0.0234, 0.0221, 0.0398, 0.0397, 0.1116, 0.6002, 0.0445,
        0.0473, 0.0188], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,710][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3414, 0.1287, 0.0213, 0.1640, 0.0481, 0.0628, 0.0466, 0.0281, 0.0289,
        0.0711, 0.0590], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,711][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2387, 0.1249, 0.0622, 0.1416, 0.0708, 0.0554, 0.0606, 0.0681, 0.0659,
        0.0544, 0.0573], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,713][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5714, 0.1384, 0.0401, 0.1449, 0.0272, 0.0215, 0.0024, 0.0240, 0.0156,
        0.0093, 0.0051], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,716][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0393, 0.0202, 0.1360, 0.0216, 0.0942, 0.1358, 0.1325, 0.0973, 0.0893,
        0.1181, 0.1157], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:04,720][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0003, 0.0647, 0.1603, 0.0272, 0.1531, 0.1312, 0.0837, 0.1126, 0.0657,
        0.0694, 0.0771, 0.0547], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,724][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0015, 0.0134, 0.0715, 0.0132, 0.1109, 0.0239, 0.0729, 0.0045, 0.0318,
        0.5454, 0.1000, 0.0110], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,729][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0689, 0.0058, 0.0979, 0.0016, 0.0841, 0.1038, 0.1270, 0.1119, 0.0930,
        0.0948, 0.1171, 0.0941], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,731][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0855, 0.0904, 0.1064, 0.0845, 0.0942, 0.0694, 0.0653, 0.0797, 0.0966,
        0.0776, 0.0746, 0.0758], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,732][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.4991, 0.0751, 0.0044, 0.1190, 0.0074, 0.0315, 0.0376, 0.0195, 0.0318,
        0.0773, 0.0700, 0.0272], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,732][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0759, 0.0327, 0.1094, 0.0256, 0.1108, 0.1407, 0.1135, 0.1151, 0.0620,
        0.0827, 0.0755, 0.0560], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,734][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0208, 0.0019, 0.0927, 0.0023, 0.0865, 0.1359, 0.1306, 0.1316, 0.0872,
        0.0883, 0.1311, 0.0911], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,736][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0557, 0.0211, 0.0538, 0.0305, 0.0559, 0.0345, 0.0761, 0.1299, 0.0117,
        0.0187, 0.0182, 0.4937], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,740][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1032, 0.0682, 0.0263, 0.0804, 0.0468, 0.0981, 0.0850, 0.0617, 0.0658,
        0.1132, 0.1769, 0.0743], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,744][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.2098, 0.1145, 0.0603, 0.1285, 0.0667, 0.0531, 0.0587, 0.0671, 0.0654,
        0.0537, 0.0564, 0.0658], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,748][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.2456, 0.1318, 0.0765, 0.1376, 0.0575, 0.0745, 0.0139, 0.0567, 0.0355,
        0.0406, 0.0229, 0.1069], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,752][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0321, 0.0163, 0.1254, 0.0170, 0.0828, 0.1230, 0.1177, 0.0834, 0.0761,
        0.1090, 0.1079, 0.1093], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:04,753][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0003, 0.0575, 0.1363, 0.0251, 0.1258, 0.1137, 0.0724, 0.1105, 0.0632,
        0.0611, 0.0697, 0.0558, 0.1088], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,754][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0042, 0.0549, 0.0385, 0.0102, 0.0081, 0.0029, 0.0807, 0.0191, 0.1202,
        0.5453, 0.0385, 0.0722, 0.0051], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,755][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0808, 0.0047, 0.0858, 0.0014, 0.0740, 0.0939, 0.1152, 0.1024, 0.0851,
        0.0847, 0.1058, 0.0850, 0.0811], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,757][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0827, 0.0811, 0.0964, 0.0791, 0.0829, 0.0638, 0.0615, 0.0748, 0.0889,
        0.0730, 0.0709, 0.0747, 0.0701], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,760][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.3678, 0.0957, 0.0047, 0.1469, 0.0082, 0.0412, 0.0438, 0.0225, 0.0373,
        0.1046, 0.0885, 0.0304, 0.0086], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,764][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1279, 0.0890, 0.0927, 0.0117, 0.0250, 0.0686, 0.0564, 0.1584, 0.1118,
        0.0580, 0.0474, 0.1308, 0.0224], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,768][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0172, 0.0019, 0.0859, 0.0023, 0.0802, 0.1277, 0.1169, 0.1228, 0.0795,
        0.0832, 0.1244, 0.0873, 0.0707], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,773][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0245, 0.0160, 0.0541, 0.0200, 0.0403, 0.0249, 0.0318, 0.0729, 0.0153,
        0.0169, 0.0160, 0.6130, 0.0543], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,775][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0776, 0.0547, 0.0224, 0.0649, 0.0337, 0.0903, 0.0810, 0.0788, 0.0836,
        0.1043, 0.1513, 0.0896, 0.0679], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,776][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.1744, 0.1016, 0.0590, 0.1142, 0.0653, 0.0530, 0.0580, 0.0661, 0.0653,
        0.0537, 0.0556, 0.0645, 0.0692], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,776][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.1832, 0.0955, 0.0675, 0.0835, 0.1486, 0.0914, 0.0098, 0.0332, 0.0300,
        0.0290, 0.0082, 0.0505, 0.1697], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,778][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0283, 0.0103, 0.1264, 0.0112, 0.0782, 0.1216, 0.1171, 0.0747, 0.0689,
        0.0973, 0.0997, 0.0912, 0.0750], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:04,781][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0002, 0.0540, 0.1311, 0.0230, 0.1323, 0.1007, 0.0702, 0.0961, 0.0568,
        0.0585, 0.0651, 0.0486, 0.1135, 0.0497], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,785][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0093, 0.0409, 0.1088, 0.0209, 0.2377, 0.0028, 0.0227, 0.0058, 0.0044,
        0.0983, 0.0495, 0.1592, 0.2383, 0.0013], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,788][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0695, 0.0050, 0.0813, 0.0017, 0.0701, 0.0851, 0.1041, 0.0919, 0.0775,
        0.0777, 0.0952, 0.0778, 0.0749, 0.0882], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,792][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0817, 0.0815, 0.0904, 0.0724, 0.0782, 0.0585, 0.0555, 0.0664, 0.0806,
        0.0662, 0.0644, 0.0678, 0.0638, 0.0725], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,797][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.5856, 0.0689, 0.0042, 0.1009, 0.0063, 0.0203, 0.0242, 0.0180, 0.0269,
        0.0470, 0.0470, 0.0237, 0.0069, 0.0200], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,797][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0469, 0.0137, 0.2255, 0.0049, 0.1629, 0.0717, 0.0350, 0.1148, 0.0203,
        0.0404, 0.0404, 0.1115, 0.1000, 0.0121], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,798][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0172, 0.0021, 0.0805, 0.0027, 0.0748, 0.1142, 0.1068, 0.1131, 0.0737,
        0.0757, 0.1119, 0.0789, 0.0669, 0.0815], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,799][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0125, 0.0083, 0.0105, 0.0145, 0.0073, 0.0111, 0.0182, 0.2526, 0.0637,
        0.0234, 0.0410, 0.5244, 0.0094, 0.0031], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,801][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.1660, 0.0844, 0.0192, 0.1044, 0.0403, 0.0515, 0.0528, 0.0391, 0.0335,
        0.0785, 0.0919, 0.0692, 0.0685, 0.1008], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,804][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1866, 0.1007, 0.0525, 0.1146, 0.0592, 0.0472, 0.0512, 0.0564, 0.0548,
        0.0466, 0.0500, 0.0584, 0.0641, 0.0577], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,808][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.2601, 0.1013, 0.0311, 0.0997, 0.0433, 0.0662, 0.0128, 0.0492, 0.0903,
        0.0276, 0.0116, 0.0773, 0.0643, 0.0652], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,812][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0309, 0.0132, 0.1094, 0.0136, 0.0701, 0.1072, 0.1040, 0.0731, 0.0700,
        0.0891, 0.0847, 0.0772, 0.0653, 0.0921], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:04,815][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0004, 0.0547, 0.1185, 0.0217, 0.1087, 0.0968, 0.0658, 0.0926, 0.0607,
        0.0562, 0.0595, 0.0489, 0.0983, 0.0545, 0.0627], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,819][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0017, 0.0065, 0.0009, 0.1219, 0.0020, 0.0902, 0.0080, 0.2130,
        0.0083, 0.0039, 0.0319, 0.1994, 0.3111, 0.0009], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,820][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0586, 0.0051, 0.0744, 0.0017, 0.0650, 0.0773, 0.0921, 0.0824, 0.0710,
        0.0716, 0.0858, 0.0710, 0.0701, 0.0812, 0.0928], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,821][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0759, 0.0709, 0.0810, 0.0684, 0.0768, 0.0576, 0.0548, 0.0635, 0.0739,
        0.0638, 0.0615, 0.0639, 0.0629, 0.0695, 0.0557], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,823][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4840, 0.0583, 0.0041, 0.1013, 0.0065, 0.0260, 0.0310, 0.0220, 0.0298,
        0.0558, 0.0580, 0.0284, 0.0083, 0.0263, 0.0602], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,825][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0494, 0.0089, 0.1163, 0.0061, 0.1512, 0.0787, 0.0696, 0.1331, 0.0491,
        0.0353, 0.0441, 0.0958, 0.0936, 0.0430, 0.0259], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,830][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0171, 0.0020, 0.0720, 0.0024, 0.0667, 0.0996, 0.0978, 0.0980, 0.0679,
        0.0675, 0.0968, 0.0691, 0.0573, 0.0722, 0.1136], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,834][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0171, 0.0097, 0.0175, 0.0132, 0.0363, 0.0127, 0.0354, 0.3551, 0.1132,
        0.0179, 0.0164, 0.1650, 0.0526, 0.0994, 0.0385], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,837][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2565, 0.0953, 0.0145, 0.1241, 0.0308, 0.0306, 0.0266, 0.0217, 0.0225,
        0.0490, 0.0461, 0.0428, 0.0559, 0.0935, 0.0900], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,841][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1964, 0.0991, 0.0472, 0.1135, 0.0550, 0.0425, 0.0469, 0.0519, 0.0503,
        0.0416, 0.0437, 0.0527, 0.0592, 0.0546, 0.0453], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,842][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3968, 0.1252, 0.0413, 0.1127, 0.0307, 0.0365, 0.0050, 0.0331, 0.0227,
        0.0168, 0.0063, 0.0763, 0.0459, 0.0179, 0.0328], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,843][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0247, 0.0165, 0.0969, 0.0165, 0.0657, 0.0910, 0.0892, 0.0659, 0.0602,
        0.0807, 0.0761, 0.0741, 0.0613, 0.0817, 0.0994], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:04,907][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:04,909][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,909][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,910][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,911][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,912][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,912][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,913][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,914][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,914][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,915][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,915][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,916][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:04,917][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4947, 0.5053], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,918][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3975, 0.6025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,918][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4418, 0.5582], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,921][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4553, 0.5447], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,925][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4486, 0.5514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,928][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4297, 0.5703], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,932][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4429, 0.5571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,933][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4598, 0.5402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,934][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4683, 0.5317], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,934][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8430, 0.1570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,935][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4994, 0.5006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,937][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5222, 0.4778], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:04,940][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.5707, 0.3537, 0.0756], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,944][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.5924, 0.3465, 0.0611], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,948][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.4160, 0.4089, 0.1751], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,951][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.4300, 0.3789, 0.1911], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,955][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.3733, 0.3605, 0.2662], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,955][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.5401, 0.3518, 0.1081], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,956][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.5858, 0.3664, 0.0479], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,957][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.5146, 0.3765, 0.1089], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,958][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.5380, 0.3587, 0.1033], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,960][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.1837, 0.0872, 0.7291], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,963][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.5841, 0.2944, 0.1215], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,966][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.5249, 0.3281, 0.1469], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:04,970][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2504, 0.2455, 0.2537, 0.2504], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,974][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1215, 0.1743, 0.5236, 0.1806], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,977][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1861, 0.2263, 0.3403, 0.2474], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,978][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2009, 0.2319, 0.3218, 0.2454], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,979][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1885, 0.2268, 0.3179, 0.2668], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,979][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1720, 0.2217, 0.3797, 0.2266], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,980][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1704, 0.2148, 0.3802, 0.2346], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,982][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2028, 0.2315, 0.3101, 0.2557], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,986][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2139, 0.2363, 0.2833, 0.2665], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,989][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0829, 0.0122, 0.8994, 0.0054], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,993][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2577, 0.2506, 0.2316, 0.2602], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,997][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2887, 0.2581, 0.1871, 0.2660], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:04,999][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.3617, 0.2408, 0.0592, 0.2514, 0.0870], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,000][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.3688, 0.2407, 0.0702, 0.2428, 0.0776], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,001][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.2122, 0.2036, 0.1314, 0.2189, 0.2338], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,002][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2481, 0.2113, 0.1416, 0.2158, 0.1831], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,002][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.1783, 0.1809, 0.1811, 0.2155, 0.2442], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,004][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.3171, 0.2344, 0.1197, 0.2291, 0.0996], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,008][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.3345, 0.2475, 0.0733, 0.2597, 0.0849], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,011][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2926, 0.2266, 0.0833, 0.2442, 0.1533], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,015][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.3063, 0.2202, 0.0883, 0.2537, 0.1314], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,020][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.1097, 0.0501, 0.4341, 0.0354, 0.3707], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,022][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.3926, 0.2152, 0.0858, 0.2081, 0.0983], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,023][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.3390, 0.2179, 0.1057, 0.2245, 0.1129], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,023][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.5110, 0.2233, 0.0122, 0.2267, 0.0220, 0.0049], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,024][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4870, 0.2244, 0.0315, 0.2081, 0.0369, 0.0121], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,025][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2513, 0.1906, 0.0677, 0.2120, 0.1497, 0.1287], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,027][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3173, 0.2117, 0.0769, 0.2210, 0.1221, 0.0510], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,030][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1844, 0.1284, 0.0614, 0.1636, 0.1183, 0.3439], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,034][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3787, 0.2219, 0.0698, 0.2169, 0.0858, 0.0270], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,038][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4516, 0.2224, 0.0166, 0.2367, 0.0280, 0.0447], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,042][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3941, 0.1996, 0.0302, 0.2277, 0.0640, 0.0844], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,044][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3924, 0.1900, 0.0358, 0.2268, 0.0838, 0.0712], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,045][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0720, 0.0371, 0.3079, 0.0252, 0.2677, 0.2900], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,046][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.4972, 0.1959, 0.0461, 0.1938, 0.0446, 0.0223], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,047][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4298, 0.2100, 0.0489, 0.2238, 0.0538, 0.0337], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,047][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5183, 0.2104, 0.0119, 0.2260, 0.0226, 0.0051, 0.0057],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,049][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5524, 0.1980, 0.0187, 0.1987, 0.0243, 0.0057, 0.0021],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,053][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2143, 0.1503, 0.0476, 0.1767, 0.1198, 0.1186, 0.1727],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,056][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3227, 0.2066, 0.0589, 0.2243, 0.1051, 0.0542, 0.0283],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,060][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1392, 0.0938, 0.0351, 0.1262, 0.0771, 0.3023, 0.2263],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,065][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3955, 0.2002, 0.0715, 0.2041, 0.0800, 0.0295, 0.0192],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,067][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4599, 0.2135, 0.0124, 0.2253, 0.0246, 0.0459, 0.0185],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,068][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3196, 0.1688, 0.0182, 0.2001, 0.0525, 0.1046, 0.1361],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,068][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3348, 0.1581, 0.0407, 0.2032, 0.0792, 0.1102, 0.0738],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,069][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0528, 0.0279, 0.2333, 0.0190, 0.2059, 0.2277, 0.2333],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,071][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5426, 0.1862, 0.0308, 0.1812, 0.0366, 0.0133, 0.0094],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,074][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.4028, 0.2019, 0.0494, 0.2203, 0.0568, 0.0285, 0.0403],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,078][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.4713, 0.2202, 0.0181, 0.2256, 0.0316, 0.0087, 0.0109, 0.0136],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,082][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.4893, 0.2080, 0.0252, 0.2061, 0.0422, 0.0112, 0.0056, 0.0124],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,085][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1419, 0.1014, 0.0325, 0.1177, 0.0871, 0.1252, 0.2143, 0.1799],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,089][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.2306, 0.1592, 0.0579, 0.1777, 0.1036, 0.0890, 0.0585, 0.1236],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,090][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0870, 0.0580, 0.0205, 0.0814, 0.0484, 0.2611, 0.2401, 0.2036],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,091][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.3569, 0.2068, 0.0633, 0.1997, 0.0865, 0.0271, 0.0271, 0.0325],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,091][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2875, 0.1617, 0.0183, 0.1887, 0.0336, 0.1549, 0.0949, 0.0605],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,093][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.2240, 0.1200, 0.0207, 0.1437, 0.0502, 0.1090, 0.1314, 0.2010],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,096][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.2865, 0.1469, 0.0311, 0.1844, 0.0719, 0.1068, 0.0986, 0.0738],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,100][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0408, 0.0246, 0.1889, 0.0172, 0.1686, 0.1804, 0.1841, 0.1954],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,103][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.5201, 0.1880, 0.0349, 0.1776, 0.0385, 0.0140, 0.0100, 0.0170],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,107][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.4175, 0.2010, 0.0422, 0.2166, 0.0483, 0.0222, 0.0258, 0.0264],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,111][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.4901, 0.2145, 0.0122, 0.2263, 0.0222, 0.0054, 0.0089, 0.0114, 0.0091],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,112][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.5877, 0.1883, 0.0113, 0.1871, 0.0175, 0.0030, 0.0014, 0.0023, 0.0014],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,113][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1382, 0.0845, 0.0221, 0.1016, 0.0528, 0.1018, 0.1652, 0.1794, 0.1543],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,114][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.2725, 0.1667, 0.0499, 0.1843, 0.0779, 0.0552, 0.0331, 0.1048, 0.0555],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,115][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0663, 0.0417, 0.0114, 0.0591, 0.0267, 0.1792, 0.2151, 0.2253, 0.1752],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,117][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.4015, 0.2019, 0.0651, 0.1870, 0.0776, 0.0187, 0.0148, 0.0228, 0.0105],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,120][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.4052, 0.1963, 0.0096, 0.2157, 0.0176, 0.0666, 0.0368, 0.0267, 0.0255],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,124][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.2453, 0.1110, 0.0119, 0.1398, 0.0336, 0.0616, 0.1140, 0.1914, 0.0914],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,128][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.3145, 0.1346, 0.0275, 0.1768, 0.0730, 0.0814, 0.0793, 0.0634, 0.0495],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,132][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0351, 0.0202, 0.1559, 0.0146, 0.1434, 0.1523, 0.1553, 0.1660, 0.1571],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,134][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6157, 0.1688, 0.0190, 0.1548, 0.0241, 0.0057, 0.0031, 0.0054, 0.0034],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,135][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.4258, 0.1997, 0.0423, 0.2147, 0.0487, 0.0190, 0.0200, 0.0183, 0.0115],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,136][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4629, 0.2037, 0.0225, 0.2164, 0.0362, 0.0090, 0.0111, 0.0132, 0.0123,
        0.0127], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,137][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4643, 0.2036, 0.0380, 0.2100, 0.0435, 0.0108, 0.0057, 0.0109, 0.0082,
        0.0050], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,139][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1308, 0.0888, 0.0280, 0.0980, 0.0600, 0.0604, 0.0928, 0.1098, 0.1098,
        0.2216], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,141][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2406, 0.1624, 0.0557, 0.1697, 0.0841, 0.0479, 0.0280, 0.0718, 0.0485,
        0.0914], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,146][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0902, 0.0573, 0.0189, 0.0732, 0.0322, 0.1184, 0.1181, 0.1227, 0.1069,
        0.2621], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,150][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3096, 0.1746, 0.0722, 0.1808, 0.0790, 0.0319, 0.0272, 0.0452, 0.0338,
        0.0457], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,153][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4604, 0.1917, 0.0107, 0.1955, 0.0184, 0.0242, 0.0127, 0.0162, 0.0166,
        0.0535], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,157][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2240, 0.1200, 0.0159, 0.1356, 0.0374, 0.0472, 0.0737, 0.1501, 0.0653,
        0.1308], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,158][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2621, 0.1248, 0.0334, 0.1565, 0.0623, 0.0817, 0.0712, 0.0585, 0.0575,
        0.0919], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,159][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0301, 0.0144, 0.1392, 0.0096, 0.1222, 0.1355, 0.1378, 0.1483, 0.1417,
        0.1212], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,159][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4973, 0.1891, 0.0306, 0.1830, 0.0352, 0.0120, 0.0084, 0.0110, 0.0086,
        0.0247], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,161][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3838, 0.1957, 0.0431, 0.2057, 0.0454, 0.0212, 0.0236, 0.0170, 0.0114,
        0.0531], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,164][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5362, 0.1948, 0.0102, 0.2088, 0.0190, 0.0045, 0.0060, 0.0053, 0.0068,
        0.0062, 0.0021], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,167][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.1857e-01, 1.7634e-01, 9.4920e-03, 1.7577e-01, 1.3370e-02, 2.0200e-03,
        6.7753e-04, 1.7796e-03, 1.3300e-03, 5.4542e-04, 1.0671e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,171][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1875, 0.1013, 0.0178, 0.1136, 0.0489, 0.0331, 0.0459, 0.0514, 0.0381,
        0.1792, 0.1833], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,175][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3408, 0.1895, 0.0331, 0.1994, 0.0628, 0.0304, 0.0138, 0.0346, 0.0143,
        0.0650, 0.0162], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,178][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1182, 0.0601, 0.0113, 0.0820, 0.0219, 0.0896, 0.0742, 0.0615, 0.0389,
        0.2341, 0.2081], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,180][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4041, 0.1801, 0.0592, 0.1771, 0.0685, 0.0200, 0.0137, 0.0256, 0.0146,
        0.0280, 0.0089], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,181][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5546, 0.1836, 0.0037, 0.1833, 0.0067, 0.0134, 0.0044, 0.0047, 0.0030,
        0.0332, 0.0094], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,182][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3588, 0.1439, 0.0065, 0.1666, 0.0205, 0.0251, 0.0447, 0.0871, 0.0219,
        0.0954, 0.0295], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,182][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3414, 0.1287, 0.0213, 0.1640, 0.0481, 0.0628, 0.0466, 0.0281, 0.0289,
        0.0711, 0.0590], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,184][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0270, 0.0142, 0.1215, 0.0100, 0.1067, 0.1183, 0.1199, 0.1295, 0.1234,
        0.1059, 0.1236], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,187][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6239, 0.1637, 0.0146, 0.1541, 0.0181, 0.0042, 0.0029, 0.0043, 0.0023,
        0.0107, 0.0013], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,191][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4496, 0.1895, 0.0308, 0.2055, 0.0301, 0.0133, 0.0156, 0.0089, 0.0049,
        0.0362, 0.0155], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,195][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.3464, 0.1974, 0.0361, 0.2071, 0.0583, 0.0180, 0.0208, 0.0190, 0.0147,
        0.0288, 0.0133, 0.0401], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,198][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.3056, 0.1911, 0.0510, 0.1883, 0.0659, 0.0443, 0.0232, 0.0287, 0.0171,
        0.0243, 0.0139, 0.0467], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,202][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0272, 0.0240, 0.0143, 0.0267, 0.0270, 0.0520, 0.0780, 0.0800, 0.1209,
        0.1329, 0.3470, 0.0698], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,203][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0807, 0.0705, 0.0491, 0.0752, 0.0620, 0.0728, 0.0542, 0.0970, 0.0972,
        0.1192, 0.1118, 0.1104], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,204][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0174, 0.0147, 0.0080, 0.0188, 0.0148, 0.0740, 0.0867, 0.0789, 0.0989,
        0.1534, 0.3803, 0.0540], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,205][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1749, 0.1325, 0.0769, 0.1322, 0.0878, 0.0460, 0.0493, 0.0520, 0.0493,
        0.0681, 0.0453, 0.0856], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,207][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1303, 0.0848, 0.0213, 0.0929, 0.0315, 0.0743, 0.0505, 0.0502, 0.0816,
        0.1473, 0.1570, 0.0783], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,210][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0917, 0.0606, 0.0173, 0.0692, 0.0349, 0.0708, 0.0808, 0.1377, 0.0951,
        0.1307, 0.1288, 0.0824], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,214][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1032, 0.0682, 0.0263, 0.0804, 0.0468, 0.0981, 0.0850, 0.0617, 0.0658,
        0.1132, 0.1769, 0.0743], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,218][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0251, 0.0110, 0.1112, 0.0077, 0.0961, 0.1081, 0.1093, 0.1193, 0.1130,
        0.0954, 0.1139, 0.0900], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,221][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.3835, 0.1748, 0.0418, 0.1681, 0.0537, 0.0262, 0.0160, 0.0225, 0.0139,
        0.0363, 0.0114, 0.0518], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,225][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.2482, 0.1511, 0.0466, 0.1616, 0.0579, 0.0354, 0.0423, 0.0367, 0.0255,
        0.0741, 0.0458, 0.0749], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,226][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2470, 0.1617, 0.0415, 0.1715, 0.0624, 0.0332, 0.0339, 0.0321, 0.0259,
        0.0398, 0.0216, 0.0575, 0.0719], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,227][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.2347, 0.1601, 0.0525, 0.1650, 0.0602, 0.0532, 0.0329, 0.0307, 0.0282,
        0.0333, 0.0199, 0.0688, 0.0605], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,227][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0182, 0.0164, 0.0121, 0.0181, 0.0215, 0.0552, 0.0702, 0.0851, 0.1351,
        0.1270, 0.3147, 0.0704, 0.0560], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,229][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0614, 0.0530, 0.0389, 0.0556, 0.0505, 0.0669, 0.0519, 0.1001, 0.1040,
        0.1105, 0.1056, 0.1134, 0.0882], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,232][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0092, 0.0086, 0.0084, 0.0107, 0.0110, 0.0715, 0.0854, 0.0968, 0.1400,
        0.1365, 0.3351, 0.0585, 0.0283], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,236][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1539, 0.1116, 0.0635, 0.1136, 0.0571, 0.0500, 0.0468, 0.0710, 0.0659,
        0.0721, 0.0414, 0.0935, 0.0596], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,240][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0724, 0.0561, 0.0212, 0.0592, 0.0241, 0.0695, 0.0564, 0.0620, 0.1143,
        0.1537, 0.1616, 0.0992, 0.0504], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,243][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0659, 0.0493, 0.0189, 0.0550, 0.0359, 0.0552, 0.0758, 0.1271, 0.1139,
        0.1195, 0.1246, 0.0916, 0.0674], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,247][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0776, 0.0547, 0.0224, 0.0649, 0.0337, 0.0903, 0.0810, 0.0788, 0.0836,
        0.1043, 0.1513, 0.0896, 0.0679], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,248][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0234, 0.0110, 0.1025, 0.0076, 0.0867, 0.0974, 0.0983, 0.1083, 0.1045,
        0.0886, 0.1042, 0.0849, 0.0828], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,249][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.2279, 0.1396, 0.0636, 0.1393, 0.0726, 0.0403, 0.0279, 0.0337, 0.0303,
        0.0550, 0.0223, 0.0660, 0.0814], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,250][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.2092, 0.1368, 0.0591, 0.1444, 0.0630, 0.0411, 0.0413, 0.0310, 0.0247,
        0.0684, 0.0405, 0.0607, 0.0799], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,252][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.4534, 0.1976, 0.0125, 0.2107, 0.0258, 0.0045, 0.0086, 0.0084, 0.0051,
        0.0090, 0.0035, 0.0189, 0.0330, 0.0090], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,255][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.3804, 0.1936, 0.0394, 0.1940, 0.0512, 0.0176, 0.0110, 0.0121, 0.0082,
        0.0086, 0.0044, 0.0262, 0.0395, 0.0139], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,259][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0553, 0.0377, 0.0127, 0.0440, 0.0314, 0.0382, 0.0522, 0.0500, 0.0715,
        0.1205, 0.2035, 0.0698, 0.0799, 0.1330], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,263][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1366, 0.0896, 0.0347, 0.0985, 0.0500, 0.0404, 0.0262, 0.0596, 0.0402,
        0.0766, 0.0478, 0.1084, 0.0901, 0.1012], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,266][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0257, 0.0163, 0.0070, 0.0220, 0.0123, 0.0557, 0.0573, 0.0560, 0.0528,
        0.1372, 0.2610, 0.0596, 0.0301, 0.2070], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,270][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2128, 0.1320, 0.0609, 0.1327, 0.0718, 0.0297, 0.0301, 0.0333, 0.0265,
        0.0499, 0.0268, 0.0717, 0.0728, 0.0489], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,271][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2562, 0.1259, 0.0116, 0.1371, 0.0181, 0.0419, 0.0204, 0.0207, 0.0236,
        0.0914, 0.0531, 0.0656, 0.0371, 0.0973], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,272][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.1457, 0.0758, 0.0087, 0.0881, 0.0213, 0.0349, 0.0444, 0.1061, 0.0621,
        0.0918, 0.0564, 0.0987, 0.0448, 0.1213], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,272][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1660, 0.0844, 0.0192, 0.1044, 0.0403, 0.0515, 0.0528, 0.0391, 0.0335,
        0.0785, 0.0919, 0.0692, 0.0685, 0.1008], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,274][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0206, 0.0104, 0.0938, 0.0071, 0.0812, 0.0882, 0.0899, 0.0985, 0.0939,
        0.0819, 0.0957, 0.0785, 0.0779, 0.0824], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,277][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.4107, 0.1687, 0.0281, 0.1684, 0.0375, 0.0134, 0.0096, 0.0126, 0.0098,
        0.0273, 0.0061, 0.0316, 0.0469, 0.0293], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,281][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.3112, 0.1600, 0.0317, 0.1730, 0.0405, 0.0205, 0.0239, 0.0173, 0.0129,
        0.0479, 0.0244, 0.0432, 0.0596, 0.0337], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,285][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5503, 0.1807, 0.0082, 0.1908, 0.0173, 0.0019, 0.0025, 0.0032, 0.0028,
        0.0038, 0.0008, 0.0100, 0.0220, 0.0044, 0.0014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,287][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.6371e-01, 1.7916e-01, 1.6412e-02, 1.7596e-01, 2.1958e-02, 3.6387e-03,
        1.4562e-03, 3.2716e-03, 2.6023e-03, 1.3575e-03, 3.1165e-04, 8.4131e-03,
        1.7626e-02, 3.5973e-03, 5.3331e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,291][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1033, 0.0536, 0.0095, 0.0626, 0.0278, 0.0174, 0.0263, 0.0280, 0.0235,
        0.0843, 0.1031, 0.0593, 0.0746, 0.1063, 0.2205], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,293][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2390, 0.1275, 0.0267, 0.1415, 0.0468, 0.0233, 0.0115, 0.0270, 0.0135,
        0.0496, 0.0173, 0.1018, 0.0751, 0.0674, 0.0318], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,293][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0568, 0.0284, 0.0051, 0.0405, 0.0110, 0.0433, 0.0349, 0.0301, 0.0173,
        0.0998, 0.1037, 0.0537, 0.0270, 0.1748, 0.2737], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,294][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3311, 0.1556, 0.0530, 0.1539, 0.0548, 0.0150, 0.0119, 0.0215, 0.0145,
        0.0236, 0.0087, 0.0539, 0.0578, 0.0332, 0.0114], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,295][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3958, 0.1443, 0.0059, 0.1588, 0.0106, 0.0228, 0.0091, 0.0098, 0.0071,
        0.0515, 0.0233, 0.0343, 0.0237, 0.0587, 0.0441], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,297][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2158, 0.0922, 0.0058, 0.1127, 0.0198, 0.0248, 0.0355, 0.0643, 0.0238,
        0.0833, 0.0372, 0.0564, 0.0351, 0.1063, 0.0870], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,301][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2565, 0.0953, 0.0145, 0.1241, 0.0308, 0.0306, 0.0266, 0.0217, 0.0225,
        0.0490, 0.0461, 0.0428, 0.0559, 0.0935, 0.0900], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,304][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0199, 0.0108, 0.0844, 0.0078, 0.0740, 0.0810, 0.0824, 0.0900, 0.0858,
        0.0740, 0.0859, 0.0706, 0.0709, 0.0759, 0.0864], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,308][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6076, 0.1567, 0.0113, 0.1462, 0.0143, 0.0029, 0.0019, 0.0033, 0.0019,
        0.0086, 0.0010, 0.0147, 0.0192, 0.0083, 0.0021], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,312][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.4040, 0.1708, 0.0258, 0.1845, 0.0273, 0.0100, 0.0129, 0.0090, 0.0047,
        0.0315, 0.0119, 0.0277, 0.0388, 0.0182, 0.0230], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,316][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:05,317][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15508],
        [15533],
        [34205],
        [12156],
        [23317],
        [28038],
        [31356],
        [26600],
        [16675],
        [16789],
        [28100],
        [15720],
        [12983],
        [25761],
        [27267]], device='cuda:0')
[2024-07-24 10:24:05,319][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14681],
        [11816],
        [32881],
        [16296],
        [25602],
        [21237],
        [23419],
        [16361],
        [10054],
        [11794],
        [16894],
        [13234],
        [12346],
        [18065],
        [18402]], device='cuda:0')
[2024-07-24 10:24:05,322][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30375],
        [40439],
        [33083],
        [32595],
        [31271],
        [32690],
        [32985],
        [32566],
        [32660],
        [33410],
        [34048],
        [34158],
        [34148],
        [33835],
        [34379]], device='cuda:0')
[2024-07-24 10:24:05,324][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26926],
        [17878],
        [ 8722],
        [  126],
        [ 2423],
        [11107],
        [ 6789],
        [11323],
        [ 3578],
        [11366],
        [25605],
        [ 7496],
        [10455],
        [ 3923],
        [28849]], device='cuda:0')
[2024-07-24 10:24:05,327][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[33229],
        [33969],
        [38091],
        [37825],
        [36653],
        [37028],
        [37314],
        [37958],
        [38367],
        [38380],
        [38557],
        [38741],
        [38451],
        [38336],
        [38340]], device='cuda:0')
[2024-07-24 10:24:05,330][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29084],
        [31439],
        [35871],
        [37360],
        [38248],
        [37982],
        [37798],
        [38924],
        [39622],
        [40230],
        [40402],
        [40982],
        [41343],
        [41412],
        [41482]], device='cuda:0')
[2024-07-24 10:24:05,332][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[19607],
        [17090],
        [16843],
        [17379],
        [17520],
        [17854],
        [17574],
        [17612],
        [17606],
        [18353],
        [19076],
        [18841],
        [18910],
        [18445],
        [18798]], device='cuda:0')
[2024-07-24 10:24:05,335][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23990],
        [23388],
        [15613],
        [ 5632],
        [16161],
        [15035],
        [16607],
        [19476],
        [12903],
        [24901],
        [24481],
        [31338],
        [33242],
        [27004],
        [31399]], device='cuda:0')
[2024-07-24 10:24:05,337][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[36486],
        [36197],
        [22670],
        [20848],
        [21228],
        [20114],
        [19004],
        [20216],
        [19975],
        [20235],
        [20416],
        [20601],
        [20704],
        [20715],
        [21029]], device='cuda:0')
[2024-07-24 10:24:05,340][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[16270],
        [23740],
        [36081],
        [33467],
        [20853],
        [22541],
        [29670],
        [33051],
        [10716],
        [14671],
        [19301],
        [29694],
        [27712],
        [22858],
        [12245]], device='cuda:0')
[2024-07-24 10:24:05,341][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[25693],
        [25298],
        [20331],
        [11410],
        [14540],
        [11942],
        [ 6394],
        [ 5320],
        [ 6189],
        [ 5078],
        [ 6644],
        [ 3379],
        [ 3332],
        [ 4486],
        [ 6137]], device='cuda:0')
[2024-07-24 10:24:05,343][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43894],
        [45415],
        [44841],
        [44691],
        [44898],
        [45015],
        [44678],
        [44389],
        [44001],
        [44014],
        [44263],
        [44360],
        [44263],
        [44454],
        [44637]], device='cuda:0')
[2024-07-24 10:24:05,344][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[9438],
        [5833],
        [2826],
        [5375],
        [2045],
        [8976],
        [7782],
        [7718],
        [7199],
        [6700],
        [6932],
        [4671],
        [2024],
        [4502],
        [3906]], device='cuda:0')
[2024-07-24 10:24:05,347][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16986],
        [21208],
        [ 7880],
        [10001],
        [ 9402],
        [10140],
        [11121],
        [11959],
        [12778],
        [13627],
        [14099],
        [14792],
        [14554],
        [15184],
        [15850]], device='cuda:0')
[2024-07-24 10:24:05,350][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[36668],
        [25958],
        [43956],
        [26249],
        [41462],
        [46051],
        [45712],
        [44906],
        [45775],
        [43571],
        [41380],
        [37712],
        [35926],
        [45535],
        [41830]], device='cuda:0')
[2024-07-24 10:24:05,352][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21140],
        [20044],
        [18802],
        [15049],
        [17648],
        [19545],
        [19564],
        [19338],
        [19476],
        [19180],
        [19581],
        [18564],
        [18474],
        [18627],
        [19205]], device='cuda:0')
[2024-07-24 10:24:05,355][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7951],
        [ 7227],
        [ 7676],
        [16251],
        [ 8658],
        [ 8038],
        [ 7986],
        [ 8061],
        [ 7936],
        [ 8212],
        [ 7925],
        [ 8075],
        [ 8376],
        [ 8193],
        [ 7850]], device='cuda:0')
[2024-07-24 10:24:05,357][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21204],
        [22371],
        [13648],
        [ 8954],
        [16025],
        [18535],
        [22231],
        [21615],
        [24496],
        [23921],
        [18017],
        [18184],
        [18169],
        [19038],
        [19414]], device='cuda:0')
[2024-07-24 10:24:05,360][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[4322],
        [2291],
        [1992],
        [1985],
        [1870],
        [2042],
        [2060],
        [4611],
        [3618],
        [3230],
        [1997],
        [5717],
        [6553],
        [3230],
        [1747]], device='cuda:0')
[2024-07-24 10:24:05,363][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 9054],
        [13202],
        [19909],
        [25680],
        [22064],
        [36495],
        [38483],
        [41559],
        [42211],
        [43114],
        [40327],
        [39465],
        [40190],
        [39905],
        [38532]], device='cuda:0')
[2024-07-24 10:24:05,365][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14694],
        [16931],
        [18240],
        [23700],
        [20236],
        [19331],
        [19685],
        [21062],
        [20195],
        [22963],
        [20745],
        [20570],
        [20974],
        [21473],
        [23282]], device='cuda:0')
[2024-07-24 10:24:05,367][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32328],
        [35047],
        [32543],
        [22791],
        [30454],
        [33673],
        [34642],
        [36232],
        [35098],
        [34518],
        [34893],
        [39463],
        [37868],
        [38929],
        [40034]], device='cuda:0')
[2024-07-24 10:24:05,368][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13072],
        [19276],
        [20217],
        [25297],
        [21975],
        [24612],
        [28328],
        [28541],
        [28738],
        [30132],
        [30776],
        [30932],
        [30614],
        [29434],
        [30764]], device='cuda:0')
[2024-07-24 10:24:05,370][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36764],
        [37557],
        [38197],
        [38104],
        [38197],
        [38167],
        [37475],
        [38527],
        [38482],
        [37975],
        [38137],
        [34252],
        [34693],
        [36527],
        [37700]], device='cuda:0')
[2024-07-24 10:24:05,372][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24780],
        [28406],
        [33055],
        [31589],
        [31825],
        [31490],
        [30979],
        [30404],
        [29757],
        [29774],
        [29917],
        [30020],
        [29996],
        [30020],
        [29981]], device='cuda:0')
[2024-07-24 10:24:05,375][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20024],
        [17004],
        [19281],
        [18491],
        [16745],
        [16381],
        [16091],
        [16539],
        [16587],
        [16308],
        [16482],
        [16844],
        [15461],
        [16748],
        [16429]], device='cuda:0')
[2024-07-24 10:24:05,378][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[41277],
        [42624],
        [46430],
        [44406],
        [42581],
        [43554],
        [42168],
        [41563],
        [41642],
        [40077],
        [41264],
        [30130],
        [26624],
        [32380],
        [37686]], device='cuda:0')
[2024-07-24 10:24:05,380][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29650],
        [26612],
        [24231],
        [24108],
        [25423],
        [20881],
        [20057],
        [18564],
        [18870],
        [18469],
        [20542],
        [21771],
        [22121],
        [21956],
        [21011]], device='cuda:0')
[2024-07-24 10:24:05,383][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8237],
        [13728],
        [10050],
        [13715],
        [ 9817],
        [11478],
        [12318],
        [12663],
        [13110],
        [10023],
        [11898],
        [ 8684],
        [ 7729],
        [ 8190],
        [ 9219]], device='cuda:0')
[2024-07-24 10:24:05,385][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966],
        [32966]], device='cuda:0')
[2024-07-24 10:24:05,452][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:05,453][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,453][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,454][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,455][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,456][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,456][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,457][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,458][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,458][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,461][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,464][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,467][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,469][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9937e-01, 6.2780e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,473][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8115, 0.1885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,474][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4809, 0.5191], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,475][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4541, 0.5459], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,476][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6337, 0.3663], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,476][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4498, 0.5502], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,478][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5730, 0.4270], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,481][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4588, 0.5412], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,484][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4621, 0.5379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,488][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2054, 0.7946], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,492][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7342, 0.2658], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,496][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4454, 0.5546], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,496][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.4986, 0.0432, 0.4582], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,497][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.4713, 0.1331, 0.3956], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,498][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.3197, 0.3327, 0.3476], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,498][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.2606, 0.2651, 0.4743], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,500][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.7422, 0.2418, 0.0160], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,503][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.3341, 0.2729, 0.3930], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,507][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.5679, 0.2744, 0.1578], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,510][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.3748, 0.2910, 0.3342], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,514][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.5360, 0.3300, 0.1339], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,518][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.0929, 0.2100, 0.6971], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,518][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.7891, 0.1378, 0.0731], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,519][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.4457, 0.3566, 0.1977], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,520][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([8.0826e-01, 5.9432e-04, 1.9109e-01, 5.5653e-05], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,521][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3795, 0.1091, 0.2112, 0.3003], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,522][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2403, 0.2581, 0.2706, 0.2309], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,525][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1802, 0.2045, 0.3946, 0.2206], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,529][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4337, 0.2424, 0.0838, 0.2401], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,532][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1689, 0.2011, 0.3967, 0.2333], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,536][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3449, 0.2417, 0.1663, 0.2472], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,540][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1811, 0.2066, 0.3924, 0.2200], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,541][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1873, 0.2114, 0.3470, 0.2543], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,541][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0182, 0.0679, 0.8432, 0.0707], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,542][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5410, 0.1813, 0.1394, 0.1383], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,543][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1673, 0.2009, 0.4005, 0.2313], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,545][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.3093, 0.0256, 0.3488, 0.0127, 0.3036], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,547][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.3996, 0.0975, 0.1554, 0.2012, 0.1463], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,551][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.2055, 0.2113, 0.2203, 0.1846, 0.1783], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,555][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.2227, 0.1842, 0.2947, 0.1705, 0.1280], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,559][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.5958, 0.2160, 0.0197, 0.1562, 0.0123], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,562][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1632, 0.1387, 0.2572, 0.1571, 0.2838], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,563][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.4049, 0.1970, 0.1025, 0.1806, 0.1151], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,564][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1914, 0.1585, 0.2567, 0.1570, 0.2364], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,565][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.2663, 0.1871, 0.1311, 0.2222, 0.1932], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,565][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0541, 0.1176, 0.4330, 0.1220, 0.2734], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,568][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.6209, 0.1321, 0.0880, 0.1041, 0.0548], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,571][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.2272, 0.1893, 0.1766, 0.2007, 0.2062], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,575][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2796, 0.0175, 0.2326, 0.0084, 0.2213, 0.2406], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,578][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2175, 0.0464, 0.1409, 0.1069, 0.1324, 0.3559], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,582][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1782, 0.1774, 0.1857, 0.1603, 0.1546, 0.1438], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,586][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1212, 0.0964, 0.2520, 0.1196, 0.1731, 0.2376], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,587][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.6971, 0.1377, 0.0100, 0.1228, 0.0067, 0.0257], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,588][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1028, 0.0708, 0.1532, 0.0871, 0.1802, 0.4058], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,588][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.5180, 0.1821, 0.0611, 0.1569, 0.0651, 0.0168], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,590][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1552, 0.1130, 0.2329, 0.1226, 0.2070, 0.1692], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,593][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2306, 0.1228, 0.1091, 0.1691, 0.1942, 0.1742], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,597][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0276, 0.0558, 0.1557, 0.0559, 0.1446, 0.5603], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,601][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.7971, 0.0757, 0.0323, 0.0560, 0.0225, 0.0165], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,605][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.2473, 0.1385, 0.1091, 0.1680, 0.1726, 0.1646], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,609][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2124, 0.0330, 0.2063, 0.0190, 0.1988, 0.2184, 0.1121],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,610][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1283, 0.0282, 0.1051, 0.0702, 0.1019, 0.2746, 0.2917],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,610][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1601, 0.1571, 0.1626, 0.1412, 0.1362, 0.1244, 0.1184],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,611][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1052, 0.0819, 0.1805, 0.1049, 0.1437, 0.1973, 0.1864],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,612][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5761, 0.1843, 0.0156, 0.1484, 0.0104, 0.0463, 0.0188],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,615][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0699, 0.0456, 0.0904, 0.0594, 0.1296, 0.3252, 0.2798],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,618][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.5105, 0.1772, 0.0584, 0.1532, 0.0647, 0.0155, 0.0205],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,622][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1302, 0.0902, 0.1802, 0.1028, 0.1818, 0.1704, 0.1444],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,625][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1218, 0.0607, 0.0603, 0.0923, 0.1432, 0.2739, 0.2477],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,629][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0215, 0.0356, 0.1026, 0.0395, 0.0855, 0.3744, 0.3408],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,632][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7743, 0.0825, 0.0369, 0.0535, 0.0226, 0.0172, 0.0130],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,632][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1533, 0.0907, 0.0652, 0.1211, 0.1255, 0.2480, 0.1962],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:05,633][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1754, 0.0262, 0.1980, 0.0129, 0.1736, 0.2130, 0.1076, 0.0932],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,634][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1454, 0.0343, 0.0777, 0.0706, 0.0684, 0.1931, 0.2016, 0.2090],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,636][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1434, 0.1380, 0.1416, 0.1277, 0.1204, 0.1131, 0.1078, 0.1080],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,640][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0923, 0.0737, 0.1615, 0.0933, 0.1319, 0.1669, 0.1568, 0.1236],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,643][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.5877, 0.1550, 0.0165, 0.1482, 0.0108, 0.0256, 0.0332, 0.0231],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,647][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0385, 0.0260, 0.0489, 0.0341, 0.0786, 0.2934, 0.3064, 0.1740],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,651][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.4018, 0.1798, 0.0779, 0.1528, 0.0876, 0.0228, 0.0343, 0.0430],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,654][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0958, 0.0649, 0.1250, 0.0747, 0.1388, 0.1747, 0.1560, 0.1699],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,654][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0383, 0.0215, 0.0271, 0.0332, 0.0640, 0.2961, 0.3852, 0.1345],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,655][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0127, 0.0236, 0.0560, 0.0255, 0.0698, 0.2448, 0.3799, 0.1877],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,656][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.7184, 0.0888, 0.0410, 0.0641, 0.0285, 0.0215, 0.0195, 0.0182],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,658][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0951, 0.0563, 0.0467, 0.0765, 0.0954, 0.2705, 0.2256, 0.1338],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:05,661][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1281, 0.0156, 0.1692, 0.0098, 0.1553, 0.1855, 0.1040, 0.0974, 0.1350],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,665][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1090, 0.0239, 0.0623, 0.0540, 0.0568, 0.1702, 0.1808, 0.1930, 0.1499],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,669][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1301, 0.1251, 0.1286, 0.1167, 0.1074, 0.1010, 0.0951, 0.0974, 0.0985],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,672][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0654, 0.0583, 0.1484, 0.0703, 0.1123, 0.1510, 0.1479, 0.1234, 0.1230],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,676][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.4760, 0.1461, 0.0152, 0.1311, 0.0158, 0.0669, 0.0380, 0.0466, 0.0643],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,677][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0407, 0.0245, 0.0504, 0.0327, 0.0710, 0.2153, 0.2096, 0.1395, 0.2165],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,678][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.3330, 0.1646, 0.0798, 0.1463, 0.1090, 0.0276, 0.0485, 0.0454, 0.0458],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,679][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0857, 0.0551, 0.1174, 0.0616, 0.1163, 0.1462, 0.1524, 0.1537, 0.1115],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,681][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0563, 0.0260, 0.0277, 0.0406, 0.0637, 0.2508, 0.3301, 0.1203, 0.0845],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,684][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0104, 0.0162, 0.0492, 0.0176, 0.0583, 0.2168, 0.2675, 0.1410, 0.2228],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,688][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.6929, 0.0892, 0.0431, 0.0627, 0.0287, 0.0253, 0.0189, 0.0183, 0.0209],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,692][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1126, 0.0574, 0.0328, 0.0771, 0.0579, 0.2276, 0.2084, 0.1213, 0.1049],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:05,696][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1562, 0.0140, 0.1421, 0.0063, 0.1332, 0.1410, 0.0783, 0.0735, 0.1245,
        0.1310], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,698][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0786, 0.0156, 0.0512, 0.0429, 0.0500, 0.1474, 0.1591, 0.1703, 0.1267,
        0.1583], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,699][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1151, 0.1141, 0.1174, 0.1036, 0.0994, 0.0931, 0.0878, 0.0872, 0.0895,
        0.0928], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,700][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0727, 0.0540, 0.1388, 0.0716, 0.0878, 0.1373, 0.1392, 0.1015, 0.1017,
        0.0954], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,701][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4794, 0.1576, 0.0231, 0.1459, 0.0138, 0.0400, 0.0323, 0.0305, 0.0357,
        0.0418], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,703][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0403, 0.0280, 0.0573, 0.0344, 0.0658, 0.1509, 0.1385, 0.0984, 0.1430,
        0.2435], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,705][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4350, 0.1620, 0.0599, 0.1422, 0.0631, 0.0161, 0.0194, 0.0179, 0.0160,
        0.0684], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,709][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0776, 0.0579, 0.1152, 0.0631, 0.1109, 0.1118, 0.1085, 0.1229, 0.0972,
        0.1348], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,714][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0801, 0.0429, 0.0490, 0.0572, 0.0822, 0.1326, 0.1314, 0.0872, 0.0766,
        0.2608], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,717][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0058, 0.0108, 0.0458, 0.0116, 0.0349, 0.1683, 0.2013, 0.1167, 0.2554,
        0.1495], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,721][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8166, 0.0621, 0.0241, 0.0410, 0.0143, 0.0102, 0.0080, 0.0078, 0.0098,
        0.0061], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,722][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0954, 0.0577, 0.0441, 0.0707, 0.0673, 0.1119, 0.0967, 0.0787, 0.0827,
        0.2948], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:05,723][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1172, 0.0135, 0.1255, 0.0052, 0.1175, 0.1332, 0.0756, 0.0687, 0.1089,
        0.1310, 0.1039], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,723][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0830, 0.0173, 0.0447, 0.0447, 0.0428, 0.1202, 0.1270, 0.1358, 0.0993,
        0.1276, 0.1576], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,726][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1065, 0.1069, 0.1087, 0.0948, 0.0898, 0.0873, 0.0817, 0.0813, 0.0837,
        0.0869, 0.0725], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,729][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0668, 0.0492, 0.1135, 0.0671, 0.0858, 0.1247, 0.1211, 0.0898, 0.0903,
        0.0864, 0.1053], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,732][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4715, 0.1522, 0.0203, 0.1419, 0.0172, 0.0397, 0.0275, 0.0340, 0.0352,
        0.0389, 0.0216], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,736][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0299, 0.0169, 0.0403, 0.0225, 0.0468, 0.1176, 0.0811, 0.0437, 0.0561,
        0.2184, 0.3267], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,741][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3902, 0.1506, 0.0695, 0.1274, 0.0712, 0.0190, 0.0222, 0.0225, 0.0184,
        0.0751, 0.0338], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,743][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0893, 0.0543, 0.1264, 0.0634, 0.1209, 0.1053, 0.0922, 0.0888, 0.0509,
        0.1299, 0.0786], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,744][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0708, 0.0283, 0.0303, 0.0424, 0.0720, 0.1041, 0.0692, 0.0320, 0.0228,
        0.2195, 0.3085], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,745][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0128, 0.0176, 0.0459, 0.0191, 0.0419, 0.1419, 0.1156, 0.0791, 0.1337,
        0.0937, 0.2987], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,746][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8183, 0.0678, 0.0257, 0.0376, 0.0125, 0.0092, 0.0068, 0.0061, 0.0076,
        0.0061, 0.0023], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,748][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1154, 0.0535, 0.0339, 0.0738, 0.0598, 0.1079, 0.0749, 0.0323, 0.0241,
        0.3025, 0.1219], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:05,750][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0906, 0.0168, 0.1116, 0.0092, 0.1010, 0.1135, 0.0764, 0.0680, 0.0930,
        0.1241, 0.1173, 0.0784], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,754][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.1157, 0.0208, 0.0372, 0.0511, 0.0315, 0.1033, 0.1098, 0.1147, 0.0845,
        0.1135, 0.1413, 0.0766], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,758][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0971, 0.0980, 0.1010, 0.0889, 0.0854, 0.0797, 0.0755, 0.0750, 0.0805,
        0.0798, 0.0677, 0.0714], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,762][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0779, 0.0500, 0.1357, 0.0656, 0.0787, 0.1135, 0.1086, 0.0779, 0.0817,
        0.0787, 0.0909, 0.0407], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,766][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.5526, 0.1334, 0.0145, 0.1126, 0.0092, 0.0294, 0.0246, 0.0263, 0.0216,
        0.0356, 0.0140, 0.0262], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,767][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0120, 0.0100, 0.0212, 0.0123, 0.0251, 0.0952, 0.0997, 0.0737, 0.1155,
        0.1360, 0.3626, 0.0368], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,768][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.3169, 0.1442, 0.0612, 0.1293, 0.0708, 0.0237, 0.0298, 0.0251, 0.0230,
        0.0846, 0.0449, 0.0465], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,768][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0393, 0.0343, 0.0627, 0.0372, 0.0650, 0.0957, 0.1050, 0.1112, 0.1209,
        0.1178, 0.1493, 0.0615], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,771][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0170, 0.0121, 0.0141, 0.0159, 0.0247, 0.0751, 0.0951, 0.0699, 0.0879,
        0.1311, 0.4095, 0.0475], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,774][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0014, 0.0032, 0.0158, 0.0035, 0.0133, 0.0896, 0.1174, 0.0628, 0.1366,
        0.0823, 0.4571, 0.0171], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,777][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.6276, 0.1010, 0.0469, 0.0646, 0.0300, 0.0251, 0.0200, 0.0163, 0.0206,
        0.0167, 0.0088, 0.0224], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,781][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0128, 0.0101, 0.0130, 0.0125, 0.0201, 0.0861, 0.0946, 0.0545, 0.1042,
        0.1782, 0.3752, 0.0385], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:05,786][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0796, 0.0124, 0.1108, 0.0054, 0.0925, 0.1072, 0.0605, 0.0592, 0.0829,
        0.1230, 0.1127, 0.0761, 0.0779], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,788][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0701, 0.0131, 0.0299, 0.0335, 0.0276, 0.1061, 0.1145, 0.1215, 0.0878,
        0.1202, 0.1526, 0.0806, 0.0424], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,789][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0932, 0.0920, 0.0940, 0.0817, 0.0779, 0.0748, 0.0711, 0.0710, 0.0766,
        0.0766, 0.0633, 0.0652, 0.0627], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,790][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0516, 0.0443, 0.1338, 0.0472, 0.0781, 0.1141, 0.0938, 0.0687, 0.0745,
        0.0814, 0.0845, 0.0670, 0.0610], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,791][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.4746, 0.1602, 0.0154, 0.1273, 0.0105, 0.0398, 0.0138, 0.0363, 0.0286,
        0.0275, 0.0149, 0.0342, 0.0168], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,793][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0107, 0.0096, 0.0231, 0.0115, 0.0257, 0.0894, 0.0960, 0.0728, 0.1463,
        0.1229, 0.3208, 0.0411, 0.0300], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,795][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.2560, 0.1258, 0.0617, 0.1157, 0.0680, 0.0300, 0.0266, 0.0210, 0.0201,
        0.0665, 0.0404, 0.0376, 0.1306], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,799][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0274, 0.0251, 0.0571, 0.0265, 0.0576, 0.0916, 0.0948, 0.1064, 0.1405,
        0.1084, 0.1405, 0.0621, 0.0620], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,803][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0117, 0.0095, 0.0135, 0.0117, 0.0200, 0.0624, 0.0869, 0.0828, 0.1263,
        0.1282, 0.3650, 0.0548, 0.0272], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,806][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0021, 0.0044, 0.0155, 0.0048, 0.0115, 0.1013, 0.1295, 0.0663, 0.1514,
        0.0849, 0.3866, 0.0291, 0.0125], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,810][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.5872, 0.0918, 0.0496, 0.0673, 0.0317, 0.0278, 0.0228, 0.0201, 0.0255,
        0.0189, 0.0101, 0.0237, 0.0234], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,811][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0162, 0.0140, 0.0182, 0.0160, 0.0238, 0.0808, 0.0839, 0.0760, 0.1243,
        0.1681, 0.2874, 0.0543, 0.0371], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:05,812][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0692, 0.0077, 0.0995, 0.0040, 0.0994, 0.0981, 0.0554, 0.0504, 0.0843,
        0.1031, 0.1009, 0.0785, 0.0952, 0.0544], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,814][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0602, 0.0108, 0.0331, 0.0279, 0.0302, 0.0935, 0.1003, 0.1084, 0.0802,
        0.0993, 0.1259, 0.0722, 0.0400, 0.1179], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,817][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0846, 0.0847, 0.0892, 0.0794, 0.0782, 0.0675, 0.0653, 0.0665, 0.0705,
        0.0698, 0.0580, 0.0663, 0.0637, 0.0562], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,821][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0497, 0.0393, 0.0992, 0.0505, 0.0744, 0.0983, 0.0996, 0.0708, 0.0710,
        0.0766, 0.0907, 0.0554, 0.0501, 0.0746], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,825][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.2774, 0.1102, 0.0144, 0.0875, 0.0102, 0.0595, 0.0234, 0.0266, 0.0374,
        0.0375, 0.0168, 0.0627, 0.0137, 0.2228], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,828][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0080, 0.0060, 0.0171, 0.0080, 0.0203, 0.0900, 0.0904, 0.0513, 0.0776,
        0.1230, 0.3790, 0.0288, 0.0194, 0.0813], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,832][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.3304, 0.1251, 0.0518, 0.1090, 0.0566, 0.0157, 0.0153, 0.0133, 0.0111,
        0.0485, 0.0198, 0.0282, 0.1145, 0.0606], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,833][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0301, 0.0240, 0.0583, 0.0277, 0.0597, 0.1008, 0.1033, 0.0957, 0.0864,
        0.1073, 0.1208, 0.0544, 0.0500, 0.0815], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,834][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0169, 0.0095, 0.0137, 0.0141, 0.0268, 0.0725, 0.0682, 0.0417, 0.0424,
        0.1329, 0.3949, 0.0406, 0.0276, 0.0982], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,835][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0039, 0.0073, 0.0182, 0.0081, 0.0194, 0.0937, 0.1208, 0.0657, 0.0956,
        0.0852, 0.3910, 0.0259, 0.0164, 0.0487], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,837][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.6291, 0.0777, 0.0368, 0.0556, 0.0281, 0.0256, 0.0159, 0.0163, 0.0209,
        0.0133, 0.0082, 0.0225, 0.0233, 0.0268], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,840][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0231, 0.0141, 0.0170, 0.0189, 0.0288, 0.0907, 0.0714, 0.0507, 0.0642,
        0.1988, 0.2236, 0.0472, 0.0302, 0.1211], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:05,844][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0730, 0.0099, 0.0954, 0.0044, 0.0859, 0.0944, 0.0546, 0.0468, 0.0771,
        0.0996, 0.0873, 0.0689, 0.0779, 0.0573, 0.0673], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,848][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0566, 0.0091, 0.0323, 0.0262, 0.0308, 0.0835, 0.0906, 0.0965, 0.0716,
        0.0851, 0.1121, 0.0637, 0.0365, 0.1005, 0.1050], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,851][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0818, 0.0820, 0.0851, 0.0742, 0.0724, 0.0652, 0.0621, 0.0627, 0.0666,
        0.0664, 0.0556, 0.0596, 0.0566, 0.0527, 0.0572], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,855][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0505, 0.0371, 0.0845, 0.0493, 0.0734, 0.0868, 0.0849, 0.0667, 0.0663,
        0.0695, 0.0820, 0.0532, 0.0528, 0.0725, 0.0705], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,856][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3651, 0.1202, 0.0154, 0.1117, 0.0113, 0.0399, 0.0207, 0.0201, 0.0285,
        0.0295, 0.0174, 0.0281, 0.0148, 0.1604, 0.0168], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,857][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0133, 0.0077, 0.0177, 0.0109, 0.0243, 0.0787, 0.0666, 0.0352, 0.0443,
        0.1283, 0.2778, 0.0246, 0.0190, 0.0717, 0.1799], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,859][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3962, 0.1306, 0.0385, 0.1114, 0.0431, 0.0089, 0.0108, 0.0097, 0.0082,
        0.0380, 0.0148, 0.0194, 0.0944, 0.0384, 0.0378], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,861][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0484, 0.0310, 0.0734, 0.0375, 0.0800, 0.0939, 0.0801, 0.0714, 0.0472,
        0.1063, 0.0888, 0.0519, 0.0553, 0.0717, 0.0631], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,866][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0221, 0.0093, 0.0112, 0.0152, 0.0286, 0.0681, 0.0487, 0.0248, 0.0186,
        0.1302, 0.3018, 0.0346, 0.0228, 0.0818, 0.1823], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,870][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0059, 0.0084, 0.0346, 0.0092, 0.0253, 0.0938, 0.0876, 0.0597, 0.1267,
        0.0711, 0.2568, 0.0223, 0.0194, 0.0683, 0.1109], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,873][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7139, 0.0704, 0.0327, 0.0463, 0.0195, 0.0149, 0.0111, 0.0107, 0.0145,
        0.0086, 0.0046, 0.0145, 0.0137, 0.0155, 0.0091], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,877][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0289, 0.0145, 0.0140, 0.0219, 0.0287, 0.0922, 0.0705, 0.0290, 0.0311,
        0.2064, 0.1858, 0.0368, 0.0231, 0.1161, 0.1011], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:05,941][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:05,945][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,948][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,948][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,949][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,949][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,949][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,950][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,950][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,950][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,951][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,951][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,951][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:05,952][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4899, 0.5101], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,952][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.6617e-04, 9.9973e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,952][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3979, 0.6021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,953][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4700, 0.5300], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,953][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5367, 0.4633], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,953][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6746, 0.3254], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,954][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5692, 0.4308], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,954][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4588, 0.5412], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,954][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4621, 0.5379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,955][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2054, 0.7946], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,955][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7570, 0.2430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,955][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1645, 0.8355], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:05,956][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.4993, 0.3332, 0.1675], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,956][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([2.1751e-04, 4.6698e-01, 5.3281e-01], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,956][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.2483, 0.2622, 0.4895], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,957][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.5059, 0.3391, 0.1550], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,957][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.7035, 0.2573, 0.0393], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,957][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.1985, 0.1638, 0.6377], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,958][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.5525, 0.2482, 0.1993], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,958][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.3748, 0.2910, 0.3342], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,958][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.5360, 0.3300, 0.1339], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,959][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.0929, 0.2100, 0.6971], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,959][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.6473, 0.1881, 0.1646], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,961][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.0595, 0.1760, 0.7645], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:05,964][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2132, 0.2125, 0.3428, 0.2314], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,966][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([6.3230e-06, 3.8957e-01, 5.2941e-01, 8.1015e-02], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,966][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1608, 0.1839, 0.4396, 0.2156], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,967][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2075, 0.2241, 0.3301, 0.2383], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,967][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3208, 0.2637, 0.1558, 0.2597], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,967][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1628, 0.0794, 0.6306, 0.1272], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,968][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3167, 0.2330, 0.2064, 0.2439], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,968][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1811, 0.2066, 0.3924, 0.2200], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,968][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1873, 0.2114, 0.3470, 0.2543], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,970][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0182, 0.0679, 0.8432, 0.0707], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,973][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3578, 0.1984, 0.1946, 0.2493], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,977][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0083, 0.0582, 0.9181, 0.0153], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:05,981][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.3040, 0.2003, 0.1519, 0.1989, 0.1449], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,983][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([8.4661e-05, 3.0095e-01, 3.8825e-01, 8.9764e-02, 2.2095e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,986][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1287, 0.1561, 0.3045, 0.1532, 0.2576], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,988][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2988, 0.2109, 0.1384, 0.2006, 0.1513], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,988][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.5154, 0.2069, 0.0381, 0.1937, 0.0459], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,989][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1203, 0.0931, 0.3220, 0.1161, 0.3486], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,989][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.3590, 0.1732, 0.1435, 0.1740, 0.1503], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,989][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.1914, 0.1585, 0.2567, 0.1570, 0.2364], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,990][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.2663, 0.1871, 0.1311, 0.2222, 0.1932], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,990][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0541, 0.1176, 0.4330, 0.1220, 0.2734], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,990][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.4264, 0.1292, 0.1161, 0.1985, 0.1299], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,991][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0289, 0.0942, 0.4453, 0.0464, 0.3851], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:05,992][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2827, 0.1548, 0.1456, 0.1803, 0.1464, 0.0901], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,994][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.5007e-04, 2.3822e-01, 2.8584e-01, 7.8946e-02, 1.6627e-01, 2.3058e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:05,997][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1381, 0.1365, 0.2126, 0.1409, 0.1875, 0.1844], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,001][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3554, 0.1760, 0.0961, 0.1788, 0.1432, 0.0505], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,006][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6343, 0.1716, 0.0128, 0.1595, 0.0197, 0.0021], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,009][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0808, 0.0528, 0.2252, 0.0762, 0.2485, 0.3164], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,011][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4625, 0.1639, 0.0829, 0.1594, 0.0910, 0.0403], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,011][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1552, 0.1130, 0.2329, 0.1226, 0.2070, 0.1692], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,011][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2306, 0.1228, 0.1091, 0.1691, 0.1942, 0.1742], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,012][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0276, 0.0558, 0.1557, 0.0559, 0.1446, 0.5603], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,012][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3889, 0.1111, 0.0980, 0.1758, 0.1118, 0.1144], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,012][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0206, 0.0696, 0.3055, 0.0377, 0.2712, 0.2954], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,013][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2503, 0.1349, 0.1039, 0.1694, 0.1542, 0.1233, 0.0640],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,014][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.3716e-04, 1.7878e-01, 2.2111e-01, 6.0875e-02, 1.2593e-01, 1.7290e-01,
        2.4027e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,016][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1093, 0.0901, 0.1688, 0.0930, 0.1704, 0.1490, 0.2193],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,019][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3241, 0.1539, 0.0983, 0.1620, 0.1491, 0.0667, 0.0459],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,023][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6569, 0.1594, 0.0104, 0.1521, 0.0178, 0.0020, 0.0013],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,026][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0613, 0.0363, 0.1696, 0.0543, 0.1878, 0.2421, 0.2487],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,031][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4694, 0.1588, 0.0743, 0.1558, 0.0860, 0.0310, 0.0247],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,033][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1302, 0.0902, 0.1802, 0.1028, 0.1818, 0.1704, 0.1444],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,033][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1218, 0.0607, 0.0603, 0.0923, 0.1432, 0.2739, 0.2477],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,033][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0215, 0.0356, 0.1026, 0.0395, 0.0855, 0.3744, 0.3408],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,034][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3554, 0.0976, 0.0877, 0.1557, 0.1007, 0.1037, 0.0992],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,034][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0153, 0.0536, 0.2322, 0.0285, 0.2051, 0.2235, 0.2417],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,035][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2056, 0.1121, 0.0950, 0.1403, 0.1211, 0.1592, 0.1056, 0.0612],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,035][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([1.4783e-04, 1.3984e-01, 1.6838e-01, 4.4620e-02, 9.9624e-02, 1.3653e-01,
        1.8480e-01, 2.2606e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,035][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0960, 0.0996, 0.1528, 0.1000, 0.1249, 0.1369, 0.1822, 0.1077],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,036][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.2930, 0.1426, 0.0896, 0.1528, 0.1442, 0.0756, 0.0605, 0.0417],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,039][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.6445, 0.1628, 0.0125, 0.1544, 0.0193, 0.0020, 0.0014, 0.0030],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,042][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0555, 0.0318, 0.1327, 0.0453, 0.1459, 0.1915, 0.1975, 0.1998],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,046][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.4271, 0.1629, 0.0820, 0.1546, 0.0854, 0.0329, 0.0245, 0.0307],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,049][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0958, 0.0649, 0.1250, 0.0747, 0.1388, 0.1747, 0.1560, 0.1699],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,053][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0383, 0.0215, 0.0271, 0.0332, 0.0640, 0.2961, 0.3852, 0.1345],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,055][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0127, 0.0236, 0.0560, 0.0255, 0.0698, 0.2448, 0.3799, 0.1877],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,056][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.3999, 0.0800, 0.0673, 0.1440, 0.0800, 0.0809, 0.0768, 0.0710],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,056][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0132, 0.0414, 0.1866, 0.0221, 0.1650, 0.1817, 0.1974, 0.1926],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,056][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.2266, 0.1112, 0.0806, 0.1376, 0.0951, 0.1724, 0.1012, 0.0537, 0.0216],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,057][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([7.2051e-05, 1.1276e-01, 1.4094e-01, 3.7792e-02, 8.2183e-02, 1.2052e-01,
        1.6636e-01, 2.0477e-01, 1.3459e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,057][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0817, 0.0820, 0.1256, 0.0929, 0.1175, 0.1272, 0.1576, 0.0957, 0.1197],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,058][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.3856, 0.1584, 0.0705, 0.1569, 0.1148, 0.0395, 0.0300, 0.0248, 0.0195],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,059][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([7.3429e-01, 1.3063e-01, 5.0399e-03, 1.2012e-01, 8.1326e-03, 4.2031e-04,
        3.8066e-04, 8.6723e-04, 1.1797e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,061][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0377, 0.0252, 0.1134, 0.0351, 0.1275, 0.1682, 0.1722, 0.1761, 0.1447],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,064][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.4432, 0.1503, 0.0886, 0.1390, 0.0938, 0.0232, 0.0187, 0.0233, 0.0199],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,068][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0857, 0.0551, 0.1174, 0.0616, 0.1163, 0.1462, 0.1524, 0.1537, 0.1115],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,072][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0563, 0.0260, 0.0277, 0.0406, 0.0637, 0.2508, 0.3301, 0.1203, 0.0845],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,076][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0104, 0.0162, 0.0492, 0.0176, 0.0583, 0.2168, 0.2675, 0.1410, 0.2228],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,078][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.3572, 0.0764, 0.0651, 0.1344, 0.0770, 0.0797, 0.0766, 0.0702, 0.0632],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,078][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0091, 0.0362, 0.1600, 0.0190, 0.1408, 0.1552, 0.1681, 0.1649, 0.1467],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,078][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1893, 0.1113, 0.0948, 0.1301, 0.1219, 0.0876, 0.0542, 0.0432, 0.0247,
        0.1431], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,079][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([2.6812e-05, 1.0263e-01, 1.3146e-01, 3.0164e-02, 7.3614e-02, 1.0739e-01,
        1.5231e-01, 1.9150e-01, 1.1824e-01, 9.2675e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,079][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0758, 0.0719, 0.1133, 0.0771, 0.1096, 0.0990, 0.1461, 0.0816, 0.1064,
        0.1193], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,080][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2093, 0.1118, 0.0965, 0.1160, 0.1215, 0.0746, 0.0612, 0.0470, 0.0441,
        0.1180], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,080][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6179, 0.1749, 0.0142, 0.1610, 0.0196, 0.0021, 0.0017, 0.0037, 0.0007,
        0.0042], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,080][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0326, 0.0194, 0.0987, 0.0277, 0.1099, 0.1443, 0.1483, 0.1541, 0.1254,
        0.1398], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,082][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3834, 0.1428, 0.0769, 0.1408, 0.0817, 0.0318, 0.0223, 0.0211, 0.0171,
        0.0823], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,085][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0776, 0.0579, 0.1152, 0.0631, 0.1109, 0.1118, 0.1085, 0.1229, 0.0972,
        0.1348], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,089][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0801, 0.0429, 0.0490, 0.0572, 0.0822, 0.1326, 0.1314, 0.0872, 0.0766,
        0.2608], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,093][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0058, 0.0108, 0.0458, 0.0116, 0.0349, 0.1683, 0.2013, 0.1167, 0.2554,
        0.1495], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,096][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2660, 0.0803, 0.0721, 0.1252, 0.0812, 0.0833, 0.0796, 0.0756, 0.0685,
        0.0683], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,100][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0078, 0.0315, 0.1399, 0.0165, 0.1227, 0.1345, 0.1460, 0.1436, 0.1278,
        0.1298], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,101][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2614, 0.1204, 0.0759, 0.1558, 0.1106, 0.0615, 0.0337, 0.0176, 0.0056,
        0.1181, 0.0392], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,101][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.5811e-05, 8.1790e-02, 1.1439e-01, 2.6787e-02, 6.5735e-02, 1.0026e-01,
        1.4530e-01, 1.9091e-01, 1.1671e-01, 8.8136e-02, 6.9970e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,101][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0786, 0.0571, 0.1045, 0.0627, 0.0962, 0.0901, 0.1308, 0.0749, 0.0972,
        0.1044, 0.1035], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,102][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2756, 0.1096, 0.0811, 0.1190, 0.1209, 0.0600, 0.0466, 0.0244, 0.0209,
        0.1054, 0.0366], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,102][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([7.2118e-01, 1.3803e-01, 5.4486e-03, 1.2457e-01, 8.0473e-03, 3.6694e-04,
        3.0781e-04, 9.0556e-04, 9.4764e-05, 9.9767e-04, 5.4182e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,103][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0305, 0.0180, 0.0885, 0.0258, 0.0983, 0.1250, 0.1280, 0.1337, 0.1093,
        0.1210, 0.1219], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,104][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4175, 0.1335, 0.0679, 0.1279, 0.0744, 0.0241, 0.0159, 0.0146, 0.0124,
        0.0704, 0.0414], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,107][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0893, 0.0543, 0.1264, 0.0634, 0.1209, 0.1053, 0.0922, 0.0888, 0.0509,
        0.1299, 0.0786], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,111][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0708, 0.0283, 0.0303, 0.0424, 0.0720, 0.1041, 0.0692, 0.0320, 0.0228,
        0.2195, 0.3085], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,115][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0128, 0.0176, 0.0459, 0.0191, 0.0419, 0.1419, 0.1156, 0.0791, 0.1337,
        0.0937, 0.2987], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,118][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2565, 0.0738, 0.0663, 0.1171, 0.0760, 0.0758, 0.0722, 0.0685, 0.0629,
        0.0613, 0.0696], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,122][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0071, 0.0290, 0.1212, 0.0156, 0.1075, 0.1168, 0.1269, 0.1247, 0.1118,
        0.1136, 0.1258], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,123][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0629, 0.0460, 0.0507, 0.0533, 0.0645, 0.1050, 0.0920, 0.0664, 0.0706,
        0.1522, 0.1730, 0.0633], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,123][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.3511e-05, 8.4406e-02, 1.1109e-01, 2.4265e-02, 6.2289e-02, 9.3851e-02,
        1.3737e-01, 1.7870e-01, 1.0710e-01, 8.0604e-02, 6.5331e-02, 5.4969e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,124][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0562, 0.0608, 0.0991, 0.0668, 0.0841, 0.0875, 0.1089, 0.0720, 0.0940,
        0.1041, 0.1051, 0.0612], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,124][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0951, 0.0662, 0.0680, 0.0692, 0.0815, 0.0807, 0.0752, 0.0645, 0.0703,
        0.1242, 0.1163, 0.0888], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,125][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.4911, 0.1935, 0.0316, 0.1810, 0.0362, 0.0070, 0.0058, 0.0095, 0.0027,
        0.0116, 0.0023, 0.0277], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,125][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0293, 0.0151, 0.0773, 0.0212, 0.0838, 0.1141, 0.1183, 0.1210, 0.0974,
        0.1116, 0.1109, 0.1000], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,125][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.2718, 0.1238, 0.0750, 0.1225, 0.0843, 0.0416, 0.0317, 0.0310, 0.0254,
        0.0870, 0.0548, 0.0513], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,127][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0393, 0.0343, 0.0627, 0.0372, 0.0650, 0.0957, 0.1050, 0.1112, 0.1209,
        0.1178, 0.1493, 0.0615], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,130][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0170, 0.0121, 0.0141, 0.0159, 0.0247, 0.0751, 0.0951, 0.0699, 0.0879,
        0.1311, 0.4095, 0.0475], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,134][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0014, 0.0032, 0.0158, 0.0035, 0.0133, 0.0896, 0.1174, 0.0628, 0.1366,
        0.0823, 0.4571, 0.0171], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,138][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.2135, 0.0682, 0.0616, 0.1043, 0.0723, 0.0746, 0.0703, 0.0692, 0.0628,
        0.0599, 0.0681, 0.0754], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,141][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0061, 0.0247, 0.1106, 0.0123, 0.0962, 0.1065, 0.1153, 0.1123, 0.1005,
        0.1030, 0.1141, 0.0985], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,145][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0504, 0.0387, 0.0478, 0.0419, 0.0512, 0.0925, 0.0739, 0.0737, 0.0899,
        0.1441, 0.1628, 0.0667, 0.0663], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,146][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([1.3686e-05, 7.7213e-02, 9.9249e-02, 2.0721e-02, 5.6630e-02, 9.3252e-02,
        1.4008e-01, 1.7587e-01, 1.0435e-01, 7.7211e-02, 6.2032e-02, 5.2057e-02,
        4.1317e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,146][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0363, 0.0487, 0.0994, 0.0481, 0.0809, 0.0715, 0.1068, 0.0747, 0.0872,
        0.1021, 0.0931, 0.0741, 0.0772], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,146][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0715, 0.0542, 0.0608, 0.0555, 0.0649, 0.0886, 0.0743, 0.0654, 0.0852,
        0.1115, 0.1003, 0.0847, 0.0829], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,147][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.3580, 0.1696, 0.0452, 0.1642, 0.0508, 0.0172, 0.0157, 0.0213, 0.0096,
        0.0290, 0.0087, 0.0480, 0.0626], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,147][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0214, 0.0144, 0.0713, 0.0187, 0.0793, 0.1054, 0.1087, 0.1137, 0.0918,
        0.1027, 0.1006, 0.0965, 0.0753], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,148][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.1734, 0.0889, 0.0784, 0.0890, 0.0809, 0.0566, 0.0377, 0.0379, 0.0341,
        0.0909, 0.0680, 0.0478, 0.1164], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,149][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0274, 0.0251, 0.0571, 0.0265, 0.0576, 0.0916, 0.0948, 0.1064, 0.1405,
        0.1084, 0.1405, 0.0621, 0.0620], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,152][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0117, 0.0095, 0.0135, 0.0117, 0.0200, 0.0624, 0.0869, 0.0828, 0.1263,
        0.1282, 0.3650, 0.0548, 0.0272], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,156][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0021, 0.0044, 0.0155, 0.0048, 0.0115, 0.1013, 0.1295, 0.0663, 0.1514,
        0.0849, 0.3866, 0.0291, 0.0125], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,159][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.1911, 0.0647, 0.0574, 0.0960, 0.0659, 0.0695, 0.0664, 0.0657, 0.0599,
        0.0569, 0.0635, 0.0692, 0.0736], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,163][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0050, 0.0203, 0.1024, 0.0095, 0.0883, 0.0979, 0.1057, 0.1040, 0.0923,
        0.0943, 0.1054, 0.0918, 0.0832], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,167][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0532, 0.0352, 0.0616, 0.0450, 0.0778, 0.1121, 0.0706, 0.0451, 0.0347,
        0.1439, 0.1350, 0.0471, 0.0627, 0.0760], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,168][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.5064e-05, 8.8573e-02, 1.0879e-01, 2.2069e-02, 5.7630e-02, 8.4236e-02,
        1.2340e-01, 1.6106e-01, 9.2684e-02, 7.1806e-02, 5.5336e-02, 4.8455e-02,
        4.0370e-02, 4.5578e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,168][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0496, 0.0413, 0.0856, 0.0482, 0.0716, 0.0785, 0.1112, 0.0606, 0.0736,
        0.0872, 0.0891, 0.0483, 0.0655, 0.0897], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,169][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1003, 0.0589, 0.0613, 0.0636, 0.0783, 0.0628, 0.0572, 0.0389, 0.0466,
        0.1166, 0.0830, 0.0715, 0.0801, 0.0809], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,169][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.5424, 0.1684, 0.0157, 0.1629, 0.0253, 0.0033, 0.0028, 0.0056, 0.0012,
        0.0067, 0.0009, 0.0185, 0.0341, 0.0124], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,169][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0227, 0.0120, 0.0658, 0.0181, 0.0722, 0.0950, 0.0978, 0.1018, 0.0819,
        0.0918, 0.0931, 0.0865, 0.0697, 0.0917], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,170][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2690, 0.1054, 0.0605, 0.1037, 0.0678, 0.0341, 0.0221, 0.0216, 0.0164,
        0.0702, 0.0390, 0.0333, 0.0977, 0.0593], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,170][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0301, 0.0240, 0.0583, 0.0277, 0.0597, 0.1008, 0.1033, 0.0957, 0.0864,
        0.1073, 0.1208, 0.0544, 0.0500, 0.0815], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,170][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0169, 0.0095, 0.0137, 0.0141, 0.0268, 0.0725, 0.0682, 0.0417, 0.0424,
        0.1329, 0.3949, 0.0406, 0.0276, 0.0982], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,172][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0039, 0.0073, 0.0182, 0.0081, 0.0194, 0.0937, 0.1208, 0.0657, 0.0956,
        0.0852, 0.3910, 0.0259, 0.0164, 0.0487], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,175][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.2013, 0.0583, 0.0529, 0.0935, 0.0610, 0.0619, 0.0588, 0.0570, 0.0517,
        0.0508, 0.0577, 0.0645, 0.0683, 0.0624], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,179][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0052, 0.0207, 0.0931, 0.0108, 0.0819, 0.0892, 0.0965, 0.0950, 0.0847,
        0.0862, 0.0958, 0.0837, 0.0771, 0.0801], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,183][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1316, 0.0616, 0.0587, 0.0852, 0.0830, 0.0740, 0.0490, 0.0255, 0.0110,
        0.1194, 0.0710, 0.0465, 0.0595, 0.0570, 0.0669], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,185][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.9740e-05, 7.7717e-02, 1.0083e-01, 2.2656e-02, 5.3378e-02, 7.8644e-02,
        1.1246e-01, 1.4991e-01, 9.3564e-02, 7.1818e-02, 5.7596e-02, 4.8911e-02,
        4.0265e-02, 4.5133e-02, 4.7098e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,189][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0550, 0.0426, 0.0756, 0.0480, 0.0707, 0.0686, 0.0939, 0.0543, 0.0671,
        0.0776, 0.0791, 0.0484, 0.0647, 0.0846, 0.0699], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,190][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2198, 0.0877, 0.0562, 0.0970, 0.0898, 0.0415, 0.0292, 0.0193, 0.0159,
        0.0732, 0.0300, 0.0719, 0.0835, 0.0503, 0.0346], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,191][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.0121e-01, 1.3696e-01, 5.4527e-03, 1.2408e-01, 8.8296e-03, 4.4489e-04,
        3.6775e-04, 8.2972e-04, 1.0913e-04, 1.1713e-03, 7.1933e-05, 5.9162e-03,
        1.1941e-02, 2.4003e-03, 2.1956e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,191][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0227, 0.0117, 0.0604, 0.0177, 0.0668, 0.0854, 0.0877, 0.0908, 0.0740,
        0.0830, 0.0843, 0.0781, 0.0637, 0.0831, 0.0906], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,192][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3594, 0.1122, 0.0490, 0.1087, 0.0580, 0.0179, 0.0123, 0.0113, 0.0095,
        0.0537, 0.0264, 0.0221, 0.0899, 0.0361, 0.0337], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,192][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0484, 0.0310, 0.0734, 0.0375, 0.0800, 0.0939, 0.0801, 0.0714, 0.0472,
        0.1063, 0.0888, 0.0519, 0.0553, 0.0717, 0.0631], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,192][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0221, 0.0093, 0.0112, 0.0152, 0.0286, 0.0681, 0.0487, 0.0248, 0.0186,
        0.1302, 0.3018, 0.0346, 0.0228, 0.0818, 0.1823], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,193][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0059, 0.0084, 0.0346, 0.0092, 0.0253, 0.0938, 0.0876, 0.0597, 0.1267,
        0.0711, 0.2568, 0.0223, 0.0194, 0.0683, 0.1109], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,194][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2374, 0.0524, 0.0462, 0.0923, 0.0546, 0.0539, 0.0525, 0.0477, 0.0441,
        0.0438, 0.0515, 0.0581, 0.0637, 0.0562, 0.0458], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,197][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0049, 0.0194, 0.0837, 0.0104, 0.0741, 0.0815, 0.0884, 0.0866, 0.0775,
        0.0790, 0.0874, 0.0768, 0.0703, 0.0743, 0.0856], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,198][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:06,200][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16695],
        [24308],
        [27615],
        [21963],
        [21218],
        [28116],
        [27985],
        [24196],
        [13782],
        [19176],
        [27161],
        [20431],
        [12602],
        [25237],
        [25550]], device='cuda:0')
[2024-07-24 10:24:06,203][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17162],
        [22699],
        [42826],
        [16725],
        [32989],
        [36659],
        [38175],
        [35975],
        [27832],
        [26900],
        [36402],
        [27422],
        [24747],
        [35225],
        [36758]], device='cuda:0')
[2024-07-24 10:24:06,205][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[26715],
        [26710],
        [12397],
        [20193],
        [ 9491],
        [11303],
        [11273],
        [11106],
        [10407],
        [10654],
        [11151],
        [10914],
        [10252],
        [ 9872],
        [ 9828]], device='cuda:0')
[2024-07-24 10:24:06,208][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[26783],
        [23691],
        [17667],
        [17190],
        [16422],
        [14567],
        [14331],
        [15419],
        [15595],
        [15959],
        [16102],
        [15681],
        [15463],
        [15301],
        [15291]], device='cuda:0')
[2024-07-24 10:24:06,211][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12171],
        [13712],
        [15061],
        [17060],
        [18179],
        [19040],
        [19597],
        [19626],
        [19759],
        [20365],
        [20761],
        [21647],
        [22187],
        [22491],
        [22630]], device='cuda:0')
[2024-07-24 10:24:06,213][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6041],
        [ 5652],
        [10260],
        [ 9860],
        [10978],
        [12870],
        [12542],
        [12693],
        [13011],
        [12753],
        [12263],
        [11716],
        [11036],
        [10936],
        [10744]], device='cuda:0')
[2024-07-24 10:24:06,216][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22008],
        [23204],
        [20448],
        [13634],
        [18399],
        [20142],
        [19470],
        [18956],
        [18928],
        [18749],
        [19044],
        [19745],
        [18709],
        [18524],
        [18508]], device='cuda:0')
[2024-07-24 10:24:06,216][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[3112],
        [ 903],
        [ 630],
        [ 515],
        [ 380],
        [ 269],
        [ 195],
        [ 253],
        [ 315],
        [ 333],
        [ 413],
        [ 439],
        [ 407],
        [ 434],
        [ 329]], device='cuda:0')
[2024-07-24 10:24:06,217][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2907],
        [1403],
        [ 641],
        [ 709],
        [ 697],
        [ 688],
        [ 650],
        [ 665],
        [ 771],
        [ 723],
        [ 757],
        [ 878],
        [ 786],
        [ 763],
        [ 749]], device='cuda:0')
[2024-07-24 10:24:06,218][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13103],
        [36076],
        [49750],
        [49957],
        [49831],
        [49754],
        [49707],
        [49631],
        [49496],
        [49503],
        [49448],
        [49173],
        [49194],
        [49126],
        [49200]], device='cuda:0')
[2024-07-24 10:24:06,219][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21492],
        [21883],
        [18763],
        [14385],
        [15544],
        [16011],
        [18706],
        [18545],
        [19854],
        [18386],
        [18495],
        [19939],
        [20266],
        [21120],
        [21926]], device='cuda:0')
[2024-07-24 10:24:06,220][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34046],
        [44071],
        [50257],
        [50257],
        [50255],
        [50218],
        [50122],
        [49853],
        [49533],
        [49326],
        [49405],
        [48935],
        [48977],
        [49088],
        [49164]], device='cuda:0')
[2024-07-24 10:24:06,221][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[48293],
        [48431],
        [47815],
        [47267],
        [47421],
        [48119],
        [48052],
        [47932],
        [47858],
        [48234],
        [48236],
        [47771],
        [47506],
        [47497],
        [47832]], device='cuda:0')
[2024-07-24 10:24:06,224][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18967],
        [15702],
        [24140],
        [29995],
        [27679],
        [30052],
        [31882],
        [31210],
        [30438],
        [30218],
        [31354],
        [32321],
        [31911],
        [31643],
        [32402]], device='cuda:0')
[2024-07-24 10:24:06,225][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16815],
        [ 7132],
        [ 3002],
        [ 5488],
        [ 6230],
        [13224],
        [15155],
        [20275],
        [15086],
        [15744],
        [17026],
        [12643],
        [ 6481],
        [18501],
        [12883]], device='cuda:0')
[2024-07-24 10:24:06,227][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[31243],
        [30470],
        [33948],
        [34782],
        [34947],
        [35541],
        [35492],
        [33815],
        [34183],
        [31448],
        [30984],
        [31323],
        [31764],
        [30079],
        [29013]], device='cuda:0')
[2024-07-24 10:24:06,230][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[7751],
        [8100],
        [9652],
        [9681],
        [8089],
        [6650],
        [5939],
        [6680],
        [7213],
        [7405],
        [7158],
        [7020],
        [6780],
        [6836],
        [6755]], device='cuda:0')
[2024-07-24 10:24:06,232][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[24499],
        [26050],
        [33169],
        [33408],
        [32820],
        [30918],
        [30269],
        [29854],
        [30004],
        [29168],
        [29219],
        [29045],
        [29349],
        [28215],
        [27878]], device='cuda:0')
[2024-07-24 10:24:06,235][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9244],
        [17125],
        [19553],
        [17801],
        [19686],
        [21464],
        [22196],
        [23132],
        [23564],
        [28721],
        [30282],
        [33495],
        [32886],
        [32970],
        [32003]], device='cuda:0')
[2024-07-24 10:24:06,237][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[4840],
        [1961],
        [1826],
        [ 283],
        [1172],
        [2154],
        [2324],
        [2198],
        [2965],
        [2009],
        [2854],
        [1086],
        [ 649],
        [1385],
        [2544]], device='cuda:0')
[2024-07-24 10:24:06,240][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4840],
        [ 7578],
        [11093],
        [11508],
        [13723],
        [16909],
        [18943],
        [19374],
        [19557],
        [19164],
        [19188],
        [19218],
        [18821],
        [19185],
        [19433]], device='cuda:0')
[2024-07-24 10:24:06,242][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38104],
        [45085],
        [42404],
        [44062],
        [43765],
        [46966],
        [47455],
        [47606],
        [47534],
        [47654],
        [47853],
        [46523],
        [44242],
        [45500],
        [47087]], device='cuda:0')
[2024-07-24 10:24:06,243][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 6726],
        [ 6396],
        [ 4329],
        [ 3577],
        [ 4709],
        [ 7343],
        [ 9316],
        [ 9357],
        [11313],
        [12290],
        [13042],
        [15582],
        [15511],
        [14184],
        [14408]], device='cuda:0')
[2024-07-24 10:24:06,244][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14087],
        [ 9579],
        [ 8653],
        [ 5558],
        [ 6582],
        [ 3654],
        [ 4242],
        [ 5935],
        [ 5500],
        [ 4642],
        [ 5079],
        [ 5382],
        [ 5199],
        [ 5434],
        [ 5145]], device='cuda:0')
[2024-07-24 10:24:06,245][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20532],
        [16232],
        [ 5739],
        [ 5295],
        [ 9751],
        [19370],
        [18096],
        [17711],
        [16450],
        [17337],
        [19886],
        [19817],
        [19601],
        [20204],
        [19805]], device='cuda:0')
[2024-07-24 10:24:06,246][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[28404],
        [28435],
        [27151],
        [25290],
        [25101],
        [24370],
        [24016],
        [24612],
        [24413],
        [23582],
        [23411],
        [22825],
        [22287],
        [22310],
        [22575]], device='cuda:0')
[2024-07-24 10:24:06,247][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10597],
        [10364],
        [ 8865],
        [ 8680],
        [ 8633],
        [ 8595],
        [ 8188],
        [ 7999],
        [ 7698],
        [ 7650],
        [ 7597],
        [ 7830],
        [ 8252],
        [ 8295],
        [ 8260]], device='cuda:0')
[2024-07-24 10:24:06,249][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[39636],
        [37361],
        [39290],
        [42527],
        [39392],
        [33774],
        [32489],
        [31398],
        [30619],
        [31649],
        [28931],
        [30407],
        [32691],
        [30971],
        [29503]], device='cuda:0')
[2024-07-24 10:24:06,252][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39868],
        [44822],
        [35484],
        [44541],
        [34806],
        [32931],
        [33504],
        [31727],
        [35128],
        [36736],
        [37053],
        [38913],
        [41037],
        [33200],
        [38079]], device='cuda:0')
[2024-07-24 10:24:06,253][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245],
        [11245]], device='cuda:0')
[2024-07-24 10:24:06,279][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:06,280][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,280][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,281][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,281][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,281][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,281][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,282][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,282][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,282][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,283][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,283][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,283][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,284][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4357, 0.5643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,284][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2531, 0.7469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,284][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1646, 0.8354], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,285][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5973, 0.4027], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,285][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5025, 0.4975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,285][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5066, 0.4934], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,286][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5496, 0.4504], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,286][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3384, 0.6616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,286][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4037, 0.5963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,287][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4204, 0.5796], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,287][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9913, 0.0087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,287][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9743, 0.0257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,288][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.5213, 0.3504, 0.1284], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,288][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.0905, 0.6209, 0.2885], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,288][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.0034, 0.0129, 0.9837], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,289][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.5722, 0.3574, 0.0704], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,289][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.7820, 0.2043, 0.0137], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,289][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.5893, 0.2973, 0.1134], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,290][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.2554, 0.3597, 0.3849], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,290][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.3693, 0.6089, 0.0218], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,290][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.3845, 0.3236, 0.2919], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,293][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.0715, 0.0874, 0.8410], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,293][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.8911, 0.0291, 0.0798], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,294][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.4431, 0.0368, 0.5201], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,294][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1739, 0.2113, 0.3508, 0.2640], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,294][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0838, 0.4670, 0.2478, 0.2014], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,295][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.8643e-04, 8.8428e-04, 9.9150e-01, 7.3334e-03], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,295][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3685, 0.2797, 0.0919, 0.2599], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,295][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2654, 0.2446, 0.2101, 0.2799], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,296][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2639, 0.2619, 0.2379, 0.2364], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,299][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2152, 0.1921, 0.3351, 0.2576], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,303][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1536, 0.3312, 0.2665, 0.2487], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,309][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1498, 0.2100, 0.3927, 0.2475], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,313][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0402, 0.0886, 0.7927, 0.0785], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,313][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9187, 0.0165, 0.0619, 0.0029], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,314][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5228, 0.0271, 0.3879, 0.0622], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,314][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.2489, 0.1816, 0.1746, 0.2053, 0.1896], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,314][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0720, 0.3272, 0.1710, 0.1877, 0.2421], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,315][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0013, 0.0040, 0.5565, 0.0127, 0.4254], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,315][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.3731, 0.2855, 0.0795, 0.1953, 0.0666], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,316][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.6182, 0.1683, 0.0130, 0.1804, 0.0201], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,316][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.3733, 0.2289, 0.1148, 0.1990, 0.0840], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,319][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.1283, 0.1759, 0.2022, 0.2478, 0.2457], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,325][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.3063, 0.4335, 0.0145, 0.2379, 0.0078], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,329][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.1765, 0.1547, 0.2402, 0.1597, 0.2689], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,333][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0171, 0.0386, 0.5693, 0.0448, 0.3303], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,333][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.8420, 0.0293, 0.0874, 0.0060, 0.0353], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,334][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.2787, 0.0235, 0.3168, 0.0681, 0.3130], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,334][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3330, 0.1248, 0.1105, 0.1735, 0.1690, 0.0892], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,335][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0747, 0.2351, 0.1427, 0.1447, 0.1912, 0.2117], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,335][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([8.2705e-04, 2.3573e-03, 6.1153e-02, 6.3753e-03, 7.2592e-02, 8.5670e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,335][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.4151, 0.2574, 0.0440, 0.1991, 0.0419, 0.0425], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,336][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.7505, 0.1159, 0.0029, 0.1243, 0.0051, 0.0014], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,336][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.4855, 0.1835, 0.0913, 0.1696, 0.0606, 0.0094], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,339][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1153, 0.1874, 0.1492, 0.2592, 0.1933, 0.0956], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,345][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2243, 0.4073, 0.0330, 0.2502, 0.0311, 0.0541], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,349][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1501, 0.0836, 0.1777, 0.1095, 0.3282, 0.1509], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,353][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0488, 0.0563, 0.3708, 0.0995, 0.3149, 0.1097], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,354][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3992, 0.0181, 0.0592, 0.0042, 0.0225, 0.4968], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,354][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1806, 0.0255, 0.2382, 0.0654, 0.2256, 0.2646], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,354][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1959, 0.0793, 0.1061, 0.1295, 0.2175, 0.1867, 0.0851],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,355][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0481, 0.2296, 0.1299, 0.1403, 0.1529, 0.2017, 0.0977],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,355][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.7543e-05, 1.1521e-04, 9.4880e-03, 5.1523e-04, 9.1997e-03, 2.6081e-01,
        7.1983e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,355][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4126, 0.2354, 0.0458, 0.1897, 0.0388, 0.0367, 0.0410],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,356][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7698, 0.1058, 0.0022, 0.1161, 0.0041, 0.0010, 0.0010],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,357][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4035, 0.2019, 0.1009, 0.1791, 0.0669, 0.0148, 0.0330],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,363][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0985, 0.1627, 0.1424, 0.2371, 0.1879, 0.0912, 0.0801],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,368][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0957, 0.2238, 0.1289, 0.1503, 0.1263, 0.2637, 0.0113],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,373][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1023, 0.0565, 0.1094, 0.0815, 0.2967, 0.1769, 0.1766],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,374][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0149, 0.0352, 0.3587, 0.0493, 0.2910, 0.1663, 0.0846],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,374][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2897, 0.0125, 0.0382, 0.0030, 0.0150, 0.3092, 0.3323],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,374][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1777, 0.0200, 0.1875, 0.0472, 0.1714, 0.2096, 0.1865],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,375][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0617, 0.0306, 0.0468, 0.0521, 0.1158, 0.3202, 0.2812, 0.0916],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,375][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0418, 0.2189, 0.1118, 0.1283, 0.1387, 0.1654, 0.1027, 0.0923],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,376][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([2.1255e-05, 7.1483e-05, 3.9039e-03, 2.8750e-04, 4.7074e-03, 1.3470e-01,
        3.8087e-01, 4.7544e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,376][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.4258, 0.2318, 0.0317, 0.1698, 0.0269, 0.0286, 0.0383, 0.0471],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,378][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.7565, 0.1099, 0.0026, 0.1220, 0.0047, 0.0013, 0.0013, 0.0016],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,383][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3887, 0.1892, 0.1040, 0.1740, 0.0663, 0.0166, 0.0375, 0.0237],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,388][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0993, 0.1573, 0.1312, 0.2188, 0.1722, 0.0812, 0.0733, 0.0668],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,393][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1357, 0.3083, 0.0369, 0.1900, 0.0653, 0.2053, 0.0430, 0.0156],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,394][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0563, 0.0337, 0.0729, 0.0494, 0.1700, 0.2232, 0.3262, 0.0683],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,394][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0057, 0.0219, 0.2867, 0.0232, 0.2777, 0.1929, 0.1249, 0.0670],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,395][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2463, 0.0086, 0.0275, 0.0020, 0.0120, 0.2433, 0.2733, 0.1871],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,395][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1695, 0.0173, 0.1525, 0.0404, 0.1422, 0.1743, 0.1586, 0.1451],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,395][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1008, 0.0418, 0.0697, 0.0675, 0.1337, 0.2578, 0.1778, 0.0644, 0.0865],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,396][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0354, 0.1807, 0.0863, 0.1324, 0.1026, 0.1696, 0.1074, 0.0851, 0.1006],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,396][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([1.4334e-05, 5.0471e-05, 3.2349e-03, 1.6923e-04, 3.0224e-03, 9.7881e-02,
        2.8779e-01, 4.7359e-01, 1.3425e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,398][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.3100, 0.2281, 0.0395, 0.1588, 0.0339, 0.0345, 0.0580, 0.0834, 0.0538],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,402][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([7.9718e-01, 9.4251e-02, 1.3882e-03, 1.0222e-01, 2.6292e-03, 6.3021e-04,
        6.0431e-04, 7.6499e-04, 3.3556e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,406][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.4137, 0.2022, 0.0777, 0.1751, 0.0521, 0.0106, 0.0247, 0.0156, 0.0284],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,412][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0910, 0.1470, 0.1249, 0.2229, 0.1672, 0.0746, 0.0657, 0.0578, 0.0488],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,414][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1495, 0.2813, 0.0448, 0.1777, 0.0189, 0.1339, 0.1129, 0.0385, 0.0425],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,415][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1490, 0.0640, 0.0765, 0.0883, 0.2044, 0.1436, 0.1762, 0.0487, 0.0493],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,415][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0053, 0.0195, 0.2851, 0.0207, 0.1690, 0.1872, 0.1316, 0.0591, 0.1225],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,415][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1969, 0.0057, 0.0207, 0.0015, 0.0084, 0.1759, 0.1987, 0.1247, 0.2676],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,416][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1753, 0.0149, 0.1415, 0.0348, 0.1294, 0.1536, 0.1384, 0.1246, 0.0874],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,416][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1408, 0.0681, 0.1079, 0.0949, 0.1509, 0.1177, 0.0613, 0.0431, 0.0540,
        0.1613], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,417][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0510, 0.1510, 0.0931, 0.0916, 0.1204, 0.1298, 0.0888, 0.0833, 0.0994,
        0.0916], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,417][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.9236e-06, 2.3719e-05, 4.8140e-03, 1.1783e-04, 3.2180e-03, 1.5450e-01,
        3.1863e-01, 2.5926e-01, 7.9143e-02, 1.8029e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,420][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3457, 0.2142, 0.0482, 0.1572, 0.0379, 0.0240, 0.0415, 0.0581, 0.0387,
        0.0346], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,425][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7435, 0.1150, 0.0030, 0.1258, 0.0054, 0.0015, 0.0015, 0.0017, 0.0009,
        0.0017], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,431][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3229, 0.1841, 0.1052, 0.1520, 0.0643, 0.0149, 0.0276, 0.0213, 0.0354,
        0.0722], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,435][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0900, 0.1434, 0.1143, 0.2069, 0.1531, 0.0738, 0.0645, 0.0572, 0.0484,
        0.0484], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,435][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0609, 0.1480, 0.0891, 0.0850, 0.0423, 0.3097, 0.0768, 0.0754, 0.1092,
        0.0036], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,436][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0609, 0.0391, 0.0813, 0.0506, 0.1562, 0.1353, 0.1277, 0.0494, 0.0802,
        0.2191], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,436][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0063, 0.0127, 0.2498, 0.0175, 0.1835, 0.0801, 0.0858, 0.0458, 0.2032,
        0.1156], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,437][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2025, 0.0078, 0.0189, 0.0016, 0.0075, 0.1663, 0.1606, 0.0979, 0.2078,
        0.1290], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,437][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1407, 0.0201, 0.1209, 0.0456, 0.1204, 0.1251, 0.1108, 0.0974, 0.0683,
        0.1506], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,437][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1540, 0.0563, 0.1190, 0.0940, 0.1870, 0.0840, 0.0326, 0.0156, 0.0162,
        0.1717, 0.0698], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,438][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0404, 0.1424, 0.0901, 0.0718, 0.1115, 0.1208, 0.0787, 0.0750, 0.0942,
        0.0871, 0.0880], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,439][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.9470e-05, 6.8626e-05, 4.8136e-03, 2.6245e-04, 5.1244e-03, 8.8979e-02,
        1.8407e-01, 1.2226e-01, 2.9352e-02, 8.5078e-02, 4.7996e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,443][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2881, 0.1980, 0.0484, 0.1421, 0.0431, 0.0271, 0.0452, 0.0674, 0.0488,
        0.0417, 0.0500], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,447][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([8.2161e-01, 8.3284e-02, 9.3349e-04, 9.0525e-02, 1.8368e-03, 3.7023e-04,
        3.3702e-04, 4.1485e-04, 1.7346e-04, 4.1065e-04, 1.0950e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,452][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3265, 0.1820, 0.1096, 0.1491, 0.0606, 0.0122, 0.0241, 0.0169, 0.0284,
        0.0721, 0.0183], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,456][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0835, 0.1321, 0.1080, 0.2017, 0.1472, 0.0715, 0.0621, 0.0556, 0.0464,
        0.0470, 0.0449], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,456][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0368, 0.1018, 0.0356, 0.0527, 0.0426, 0.4158, 0.0727, 0.0580, 0.1562,
        0.0097, 0.0181], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,456][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0877, 0.0396, 0.0829, 0.0575, 0.2013, 0.0958, 0.0833, 0.0178, 0.0208,
        0.2119, 0.1014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,457][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0029, 0.0101, 0.2123, 0.0094, 0.1894, 0.0852, 0.0702, 0.0519, 0.1823,
        0.1268, 0.0597], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,457][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1309, 0.0080, 0.0180, 0.0023, 0.0076, 0.1258, 0.1152, 0.0791, 0.1438,
        0.0901, 0.2792], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,458][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1122, 0.0183, 0.1192, 0.0408, 0.1175, 0.1188, 0.1050, 0.0899, 0.0638,
        0.1401, 0.0744], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,458][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0106, 0.0083, 0.0205, 0.0114, 0.0309, 0.1124, 0.0958, 0.0555, 0.1318,
        0.1459, 0.3344, 0.0423], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,459][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0290, 0.1418, 0.0585, 0.0728, 0.0696, 0.1252, 0.0785, 0.0778, 0.0794,
        0.0861, 0.0862, 0.0953], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,460][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([1.8890e-06, 6.6756e-06, 1.6201e-03, 2.6265e-05, 1.0183e-03, 7.1788e-02,
        1.4035e-01, 9.2968e-02, 2.9352e-02, 7.9006e-02, 5.5199e-01, 3.1868e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,466][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.2439, 0.2007, 0.0463, 0.1220, 0.0401, 0.0245, 0.0475, 0.0504, 0.0429,
        0.0599, 0.0627, 0.0591], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,470][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.6410, 0.1430, 0.0074, 0.1583, 0.0126, 0.0049, 0.0050, 0.0057, 0.0033,
        0.0057, 0.0026, 0.0105], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,476][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2400, 0.1603, 0.0918, 0.1374, 0.0657, 0.0243, 0.0387, 0.0313, 0.0423,
        0.0801, 0.0331, 0.0550], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,477][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0813, 0.0900, 0.1100, 0.1337, 0.1423, 0.0754, 0.0701, 0.0608, 0.0549,
        0.0548, 0.0547, 0.0721], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,477][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1174, 0.2489, 0.0462, 0.1614, 0.0141, 0.2274, 0.0529, 0.0148, 0.0325,
        0.0130, 0.0663, 0.0051], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,477][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0085, 0.0081, 0.0212, 0.0103, 0.0373, 0.0972, 0.1298, 0.0452, 0.1107,
        0.1419, 0.3543, 0.0356], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,478][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0027, 0.0145, 0.2873, 0.0113, 0.1144, 0.1425, 0.0672, 0.0386, 0.0796,
        0.1374, 0.0837, 0.0207], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,478][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1177, 0.0037, 0.0130, 0.0009, 0.0047, 0.1020, 0.1008, 0.0580, 0.1301,
        0.0790, 0.3776, 0.0125], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,479][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0636, 0.0170, 0.0993, 0.0457, 0.1209, 0.1009, 0.0886, 0.0860, 0.0579,
        0.1267, 0.0633, 0.1301], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,479][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0075, 0.0070, 0.0215, 0.0088, 0.0241, 0.0876, 0.0836, 0.0715, 0.1663,
        0.1412, 0.3062, 0.0493, 0.0253], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,483][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0275, 0.1302, 0.0619, 0.0714, 0.0908, 0.1245, 0.0554, 0.0548, 0.0800,
        0.0739, 0.0897, 0.0685, 0.0712], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,486][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([1.1052e-05, 3.2390e-05, 2.8250e-03, 8.9208e-05, 2.0067e-03, 9.5895e-02,
        1.3526e-01, 1.0941e-01, 4.6809e-02, 9.8567e-02, 4.6667e-01, 3.3265e-02,
        9.1527e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,491][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.1922, 0.1560, 0.0507, 0.1096, 0.0394, 0.0340, 0.0476, 0.0753, 0.0472,
        0.0602, 0.0717, 0.0583, 0.0578], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,497][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.6061, 0.1454, 0.0089, 0.1608, 0.0147, 0.0059, 0.0062, 0.0073, 0.0044,
        0.0072, 0.0034, 0.0131, 0.0166], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,497][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1803, 0.1379, 0.0950, 0.1158, 0.0666, 0.0302, 0.0438, 0.0378, 0.0493,
        0.0831, 0.0359, 0.0558, 0.0685], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,498][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0725, 0.0928, 0.0965, 0.1234, 0.1209, 0.0649, 0.0612, 0.0554, 0.0512,
        0.0523, 0.0524, 0.0684, 0.0883], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,498][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1864, 0.2939, 0.0118, 0.1631, 0.0066, 0.1316, 0.0159, 0.0153, 0.1007,
        0.0144, 0.0480, 0.0109, 0.0015], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,498][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0107, 0.0112, 0.0273, 0.0130, 0.0390, 0.0864, 0.1082, 0.0774, 0.1457,
        0.1325, 0.2589, 0.0497, 0.0401], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,499][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0036, 0.0130, 0.2733, 0.0116, 0.1167, 0.1285, 0.0724, 0.0555, 0.0708,
        0.1293, 0.0744, 0.0299, 0.0211], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,499][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0923, 0.0022, 0.0086, 0.0005, 0.0030, 0.0906, 0.1078, 0.0490, 0.1259,
        0.0802, 0.4278, 0.0113, 0.0010], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,500][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0506, 0.0084, 0.0758, 0.0231, 0.0930, 0.0884, 0.0822, 0.0746, 0.0511,
        0.1232, 0.0597, 0.1144, 0.1553], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,505][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0295, 0.0142, 0.0286, 0.0220, 0.0545, 0.0989, 0.0692, 0.0397, 0.0684,
        0.1714, 0.2246, 0.0527, 0.0365, 0.0899], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,510][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0234, 0.1198, 0.0634, 0.0709, 0.0801, 0.0991, 0.0652, 0.0478, 0.0654,
        0.0696, 0.0816, 0.0633, 0.0614, 0.0890], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,513][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([1.4870e-05, 4.7003e-05, 2.9501e-03, 1.4088e-04, 1.8276e-03, 5.2981e-02,
        1.2466e-01, 9.8830e-02, 3.8416e-02, 1.0440e-01, 4.1903e-01, 6.6267e-02,
        1.5838e-02, 7.4595e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,518][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.2126, 0.1577, 0.0478, 0.1088, 0.0341, 0.0260, 0.0383, 0.0642, 0.0470,
        0.0528, 0.0656, 0.0507, 0.0493, 0.0453], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,518][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([7.3773e-01, 1.1117e-01, 2.8378e-03, 1.2409e-01, 5.1391e-03, 1.5157e-03,
        1.4603e-03, 1.7393e-03, 8.6371e-04, 1.6854e-03, 5.9215e-04, 3.7352e-03,
        5.3513e-03, 2.0833e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,518][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.2359, 0.1446, 0.0919, 0.1232, 0.0555, 0.0156, 0.0296, 0.0205, 0.0328,
        0.0826, 0.0267, 0.0433, 0.0624, 0.0354], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,519][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0746, 0.1148, 0.0908, 0.1590, 0.1211, 0.0538, 0.0479, 0.0418, 0.0355,
        0.0376, 0.0370, 0.0561, 0.0808, 0.0493], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,519][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.1358, 0.2075, 0.0567, 0.1385, 0.0527, 0.2288, 0.0389, 0.0661, 0.0220,
        0.0054, 0.0189, 0.0064, 0.0050, 0.0172], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,520][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0170, 0.0110, 0.0252, 0.0162, 0.0588, 0.0928, 0.1187, 0.0406, 0.0738,
        0.1505, 0.2510, 0.0438, 0.0377, 0.0628], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,520][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0020, 0.0059, 0.1523, 0.0094, 0.1244, 0.0777, 0.0882, 0.0413, 0.1192,
        0.1674, 0.1055, 0.0444, 0.0426, 0.0197], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,522][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1267, 0.0037, 0.0102, 0.0006, 0.0036, 0.0940, 0.1025, 0.0544, 0.1310,
        0.0761, 0.3720, 0.0103, 0.0011, 0.0139], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,528][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0596, 0.0103, 0.0759, 0.0255, 0.0851, 0.0882, 0.0761, 0.0681, 0.0447,
        0.1020, 0.0505, 0.0943, 0.1304, 0.0892], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,532][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0266, 0.0112, 0.0318, 0.0215, 0.0771, 0.1085, 0.0573, 0.0198, 0.0287,
        0.1728, 0.1993, 0.0448, 0.0314, 0.0688, 0.1004], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,538][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0304, 0.0975, 0.0599, 0.0655, 0.0723, 0.0865, 0.0566, 0.0520, 0.0670,
        0.0599, 0.0707, 0.0745, 0.0594, 0.0709, 0.0770], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,539][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.0573e-08, 5.2766e-08, 4.9383e-04, 8.3379e-07, 1.2171e-04, 7.1106e-02,
        1.7296e-01, 1.1185e-01, 3.7580e-02, 6.5856e-02, 4.9715e-01, 6.2292e-03,
        8.6474e-04, 2.9637e-02, 6.1481e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,539][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3073, 0.1762, 0.0358, 0.1314, 0.0283, 0.0182, 0.0334, 0.0321, 0.0275,
        0.0319, 0.0400, 0.0371, 0.0375, 0.0285, 0.0346], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,540][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([8.0693e-01, 8.6798e-02, 1.1116e-03, 9.6520e-02, 2.1728e-03, 4.4933e-04,
        4.1065e-04, 5.0260e-04, 2.1327e-04, 4.9048e-04, 1.3811e-04, 1.3133e-03,
        2.0715e-03, 6.0050e-04, 2.8205e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,540][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2445, 0.1438, 0.0963, 0.1211, 0.0586, 0.0136, 0.0255, 0.0182, 0.0307,
        0.0730, 0.0210, 0.0413, 0.0617, 0.0295, 0.0211], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,540][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0690, 0.1113, 0.0867, 0.1604, 0.1160, 0.0510, 0.0450, 0.0400, 0.0339,
        0.0346, 0.0325, 0.0541, 0.0797, 0.0486, 0.0370], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,541][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0270, 0.0643, 0.0499, 0.0421, 0.0224, 0.4949, 0.0353, 0.0327, 0.0726,
        0.0055, 0.0234, 0.0142, 0.0037, 0.1095, 0.0025], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,544][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0262, 0.0137, 0.0389, 0.0220, 0.1180, 0.1063, 0.0901, 0.0235, 0.0363,
        0.1657, 0.1676, 0.0423, 0.0443, 0.0462, 0.0588], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,549][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0022, 0.0082, 0.1387, 0.0102, 0.1149, 0.0937, 0.0735, 0.0340, 0.1408,
        0.1335, 0.0905, 0.0441, 0.0358, 0.0224, 0.0574], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,555][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0872, 0.0052, 0.0129, 0.0013, 0.0055, 0.0951, 0.0917, 0.0597, 0.1244,
        0.0744, 0.2928, 0.0144, 0.0021, 0.0178, 0.1155], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,559][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0643, 0.0112, 0.0804, 0.0255, 0.0823, 0.0815, 0.0743, 0.0620, 0.0438,
        0.0936, 0.0499, 0.0796, 0.1081, 0.0703, 0.0732], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,593][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:06,594][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,594][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,594][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,595][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,595][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,595][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,596][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,596][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,596][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,596][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,597][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,598][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,598][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4357, 0.5643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,598][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6366, 0.3634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,599][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3297, 0.6703], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,599][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5782, 0.4218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,599][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4520, 0.5480], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,600][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7348, 0.2652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,600][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7225, 0.2775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,600][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2936, 0.7064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,601][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4037, 0.5963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,601][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4203, 0.5797], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,601][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1408, 0.8592], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,602][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6847, 0.3153], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,602][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.5213, 0.3504, 0.1284], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,602][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.7594, 0.2383, 0.0023], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,603][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.0131, 0.0179, 0.9690], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,603][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.1764, 0.1252, 0.6984], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,603][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.1730, 0.0986, 0.7284], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,604][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.4345, 0.1460, 0.4195], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,605][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.4293, 0.2316, 0.3391], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,605][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.1116, 0.1971, 0.6913], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,605][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.3845, 0.3236, 0.2919], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,606][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.3248, 0.3332, 0.3420], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,606][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.0197, 0.0779, 0.9024], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,606][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.1389, 0.0620, 0.7991], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,607][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1739, 0.2113, 0.3508, 0.2640], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,607][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6702, 0.3012, 0.0116, 0.0169], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,607][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.5365e-04, 2.5022e-04, 9.8505e-01, 1.4543e-02], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,608][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0639, 0.0583, 0.8403, 0.0374], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,608][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1511, 0.1459, 0.6002, 0.1027], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,614][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2262, 0.1218, 0.5077, 0.1443], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,618][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3388, 0.2178, 0.3232, 0.1202], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,624][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0722, 0.1694, 0.5838, 0.1745], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,625][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1498, 0.2100, 0.3927, 0.2475], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,625][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1581, 0.2107, 0.3930, 0.2383], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,625][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0112, 0.0690, 0.8455, 0.0743], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,626][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2625, 0.1387, 0.2610, 0.3378], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,626][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2489, 0.1816, 0.1746, 0.2053, 0.1896], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,626][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.7152, 0.2738, 0.0022, 0.0064, 0.0024], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,627][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0117, 0.0164, 0.5882, 0.1291, 0.2546], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,627][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0923, 0.0740, 0.4067, 0.0584, 0.3686], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,630][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.1371, 0.0708, 0.3482, 0.0607, 0.3832], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,636][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.2738, 0.0910, 0.3133, 0.1358, 0.1861], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,641][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.2450, 0.1768, 0.2487, 0.1331, 0.1964], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,644][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0569, 0.1081, 0.4945, 0.0992, 0.2412], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,645][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1765, 0.1547, 0.2402, 0.1597, 0.2689], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,645][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.1824, 0.1675, 0.2559, 0.1679, 0.2262], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,645][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0108, 0.0440, 0.6407, 0.0429, 0.2617], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,646][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0860, 0.0345, 0.3852, 0.2416, 0.2526], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:06,646][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3330, 0.1248, 0.1105, 0.1735, 0.1690, 0.0892], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,647][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.7869, 0.1876, 0.0029, 0.0074, 0.0033, 0.0119], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,647][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0144, 0.0153, 0.3223, 0.0887, 0.1216, 0.4377], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,647][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0656, 0.0522, 0.2781, 0.0499, 0.2672, 0.2870], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,651][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1123, 0.0556, 0.2292, 0.0542, 0.2390, 0.3097], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,656][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1729, 0.0718, 0.2006, 0.1146, 0.2169, 0.2232], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,661][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2163, 0.1464, 0.2072, 0.1038, 0.1624, 0.1639], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,664][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1022, 0.1525, 0.4004, 0.1277, 0.1692, 0.0480], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,665][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1501, 0.0836, 0.1777, 0.1095, 0.3282, 0.1509], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,665][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0874, 0.0556, 0.2392, 0.0725, 0.2645, 0.2808], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,666][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0022, 0.0097, 0.2304, 0.0091, 0.1137, 0.6349], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,666][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0019, 0.0011, 0.0153, 0.0053, 0.0122, 0.9642], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:06,666][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1959, 0.0793, 0.1061, 0.1295, 0.2175, 0.1867, 0.0851],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,667][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.9205e-01, 1.9405e-01, 1.6046e-03, 3.7038e-03, 1.3096e-03, 6.9582e-03,
        3.3106e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,667][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0137, 0.0135, 0.2096, 0.0727, 0.0935, 0.2317, 0.3652],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,668][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0539, 0.0401, 0.2088, 0.0409, 0.2032, 0.2176, 0.2356],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,673][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0389, 0.0261, 0.1755, 0.0309, 0.1885, 0.2669, 0.2731],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,677][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1374, 0.0669, 0.1833, 0.1000, 0.1518, 0.2352, 0.1253],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,683][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1794, 0.1287, 0.1823, 0.0888, 0.1422, 0.1474, 0.1312],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,685][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0705, 0.1058, 0.4011, 0.0896, 0.1751, 0.0686, 0.0894],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,685][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1023, 0.0565, 0.1094, 0.0815, 0.2967, 0.1769, 0.1766],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,686][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0583, 0.0359, 0.1380, 0.0511, 0.1875, 0.2773, 0.2518],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,686][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0008, 0.0038, 0.1086, 0.0038, 0.0538, 0.3680, 0.4612],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,686][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0011, 0.0007, 0.0082, 0.0031, 0.0055, 0.5067, 0.4747],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:06,687][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0617, 0.0306, 0.0468, 0.0521, 0.1158, 0.3202, 0.2812, 0.0916],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,687][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([7.9533e-01, 1.9359e-01, 1.1157e-03, 3.5772e-03, 9.1818e-04, 3.7950e-03,
        3.2609e-04, 1.3460e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,688][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0038, 0.0035, 0.0948, 0.0279, 0.0431, 0.1866, 0.2741, 0.3661],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,691][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0410, 0.0322, 0.1706, 0.0321, 0.1650, 0.1792, 0.1949, 0.1850],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,697][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0719, 0.0417, 0.1404, 0.0365, 0.1419, 0.1932, 0.2158, 0.1586],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,701][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1120, 0.0341, 0.1596, 0.0660, 0.1301, 0.2387, 0.1258, 0.1337],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,705][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1509, 0.1155, 0.1552, 0.0837, 0.1250, 0.1264, 0.1163, 0.1270],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,705][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0574, 0.0891, 0.2998, 0.0745, 0.1295, 0.1035, 0.1165, 0.1298],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,706][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0563, 0.0337, 0.0729, 0.0494, 0.1700, 0.2232, 0.3262, 0.0683],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,706][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0328, 0.0219, 0.0750, 0.0314, 0.1321, 0.2981, 0.3190, 0.0897],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,707][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0014, 0.0060, 0.0993, 0.0062, 0.0563, 0.3420, 0.3944, 0.0944],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,707][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([7.2110e-04, 3.8974e-04, 5.9029e-03, 2.0672e-03, 3.5939e-03, 5.2424e-01,
        3.5456e-01, 1.0852e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:06,707][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1008, 0.0418, 0.0697, 0.0675, 0.1337, 0.2578, 0.1778, 0.0644, 0.0865],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,708][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([8.0768e-01, 1.7992e-01, 8.2071e-04, 3.6845e-03, 3.3739e-04, 5.0642e-03,
        5.6520e-04, 1.1532e-03, 7.7416e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,711][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0024, 0.0022, 0.0826, 0.0184, 0.0301, 0.1255, 0.1956, 0.2469, 0.2963],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,717][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0349, 0.0287, 0.1441, 0.0273, 0.1384, 0.1501, 0.1633, 0.1556, 0.1576],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,721][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0619, 0.0295, 0.1031, 0.0305, 0.1055, 0.1544, 0.1817, 0.1527, 0.1806],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,725][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0700, 0.0288, 0.1736, 0.0481, 0.1252, 0.2076, 0.1468, 0.1378, 0.0622],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,725][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1317, 0.0944, 0.1380, 0.0752, 0.1105, 0.1142, 0.1027, 0.1095, 0.1238],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,726][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0562, 0.0775, 0.3241, 0.0589, 0.1114, 0.0551, 0.0566, 0.0876, 0.1726],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,726][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1490, 0.0640, 0.0765, 0.0883, 0.2044, 0.1436, 0.1762, 0.0487, 0.0493],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,727][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0523, 0.0290, 0.0847, 0.0405, 0.1359, 0.2455, 0.2559, 0.0645, 0.0917],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,727][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0052, 0.0156, 0.2553, 0.0143, 0.1239, 0.1789, 0.1955, 0.0534, 0.1579],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,727][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([5.5199e-04, 3.1963e-04, 4.4657e-03, 1.6364e-03, 2.9732e-03, 3.3800e-01,
        3.0265e-01, 9.6532e-02, 2.5287e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:06,728][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1408, 0.0681, 0.1079, 0.0949, 0.1509, 0.1177, 0.0613, 0.0431, 0.0540,
        0.1613], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,729][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([8.2714e-01, 1.5860e-01, 1.4401e-03, 2.9031e-03, 9.7170e-04, 5.3609e-03,
        4.5150e-04, 1.3079e-03, 9.1062e-04, 9.0969e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,731][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0045, 0.0049, 0.0864, 0.0259, 0.0342, 0.1053, 0.1600, 0.1609, 0.1767,
        0.2412], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,731][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0338, 0.0242, 0.1267, 0.0239, 0.1201, 0.1283, 0.1390, 0.1317, 0.1346,
        0.1377], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,732][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0503, 0.0292, 0.0974, 0.0257, 0.1020, 0.1495, 0.1423, 0.1235, 0.1663,
        0.1139], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,732][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0875, 0.0326, 0.1450, 0.0507, 0.1089, 0.1886, 0.1165, 0.1238, 0.0676,
        0.0787], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,737][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1134, 0.0907, 0.1290, 0.0642, 0.1032, 0.1047, 0.0915, 0.0984, 0.1128,
        0.0923], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,741][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0389, 0.0617, 0.2390, 0.0524, 0.1000, 0.0703, 0.0837, 0.1086, 0.1753,
        0.0702], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,747][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0609, 0.0391, 0.0813, 0.0506, 0.1562, 0.1353, 0.1277, 0.0494, 0.0802,
        0.2191], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,748][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0390, 0.0271, 0.1143, 0.0341, 0.1278, 0.1646, 0.1312, 0.0470, 0.0835,
        0.2314], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,748][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0007, 0.0033, 0.0767, 0.0033, 0.0387, 0.1755, 0.2554, 0.0641, 0.2674,
        0.1149], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,748][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([5.0006e-04, 2.6410e-04, 3.5030e-03, 1.5692e-03, 2.1149e-03, 3.6114e-01,
        2.8835e-01, 7.3460e-02, 2.2367e-01, 4.5425e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:06,749][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1540, 0.0563, 0.1190, 0.0940, 0.1870, 0.0840, 0.0326, 0.0156, 0.0162,
        0.1717, 0.0698], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,749][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([7.5130e-01, 2.2645e-01, 2.1349e-03, 4.0135e-03, 1.4728e-03, 8.1720e-03,
        8.3610e-04, 1.7696e-03, 1.4186e-03, 1.9078e-03, 5.2687e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,750][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0392, 0.0330, 0.0848, 0.0838, 0.0416, 0.0780, 0.1009, 0.1028, 0.0964,
        0.1516, 0.1879], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,750][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0273, 0.0233, 0.1086, 0.0236, 0.1058, 0.1121, 0.1215, 0.1159, 0.1178,
        0.1220, 0.1221], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,753][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0371, 0.0234, 0.0967, 0.0192, 0.1001, 0.1343, 0.1353, 0.1171, 0.1520,
        0.1072, 0.0777], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,759][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0731, 0.0311, 0.1374, 0.0449, 0.0951, 0.1633, 0.1075, 0.1112, 0.0660,
        0.0779, 0.0927], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,764][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1139, 0.0796, 0.1215, 0.0553, 0.0952, 0.0972, 0.0843, 0.0907, 0.1046,
        0.0846, 0.0732], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,767][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0714, 0.0960, 0.3115, 0.0771, 0.1353, 0.0302, 0.0421, 0.0590, 0.1107,
        0.0472, 0.0197], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,768][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0877, 0.0396, 0.0829, 0.0575, 0.2013, 0.0958, 0.0833, 0.0178, 0.0208,
        0.2119, 0.1014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,768][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0288, 0.0148, 0.1115, 0.0222, 0.1407, 0.1337, 0.0948, 0.0198, 0.0358,
        0.2283, 0.1696], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,769][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0009, 0.0039, 0.0834, 0.0039, 0.0508, 0.1456, 0.1550, 0.0514, 0.1937,
        0.0748, 0.2366], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,769][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0005, 0.0003, 0.0033, 0.0015, 0.0021, 0.2047, 0.2188, 0.0674, 0.1905,
        0.0469, 0.2641], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:06,769][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0106, 0.0083, 0.0205, 0.0114, 0.0309, 0.1124, 0.0958, 0.0555, 0.1318,
        0.1459, 0.3344, 0.0423], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,770][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([8.4090e-01, 1.5006e-01, 5.8060e-04, 1.8285e-03, 2.5561e-04, 4.2604e-03,
        2.8575e-04, 5.5024e-04, 3.6638e-04, 5.7073e-04, 2.2417e-04, 1.1319e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,770][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0077, 0.0070, 0.0520, 0.0280, 0.0247, 0.0701, 0.1047, 0.1076, 0.1033,
        0.1476, 0.2339, 0.1133], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,774][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0212, 0.0177, 0.1020, 0.0161, 0.0954, 0.1024, 0.1126, 0.1074, 0.1086,
        0.1113, 0.1117, 0.0935], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,779][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0268, 0.0191, 0.0928, 0.0151, 0.0972, 0.1014, 0.1241, 0.1200, 0.1414,
        0.1104, 0.0890, 0.0626], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,784][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0291, 0.0097, 0.1435, 0.0186, 0.0853, 0.1948, 0.1125, 0.1049, 0.0461,
        0.0676, 0.1325, 0.0555], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,788][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0845, 0.0724, 0.1016, 0.0609, 0.0891, 0.0895, 0.0811, 0.0866, 0.0969,
        0.0811, 0.0713, 0.0849], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,788][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0136, 0.0238, 0.1280, 0.0214, 0.0539, 0.1050, 0.1123, 0.1194, 0.2130,
        0.0738, 0.0870, 0.0487], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,788][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0085, 0.0081, 0.0212, 0.0103, 0.0373, 0.0972, 0.1298, 0.0452, 0.1107,
        0.1419, 0.3543, 0.0356], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,789][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0073, 0.0068, 0.0212, 0.0085, 0.0270, 0.1135, 0.1332, 0.0534, 0.0992,
        0.1452, 0.3439, 0.0408], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,789][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0004, 0.0016, 0.0410, 0.0016, 0.0190, 0.1240, 0.1782, 0.0406, 0.1358,
        0.0717, 0.3681, 0.0179], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,790][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0007, 0.0003, 0.0030, 0.0020, 0.0016, 0.3073, 0.1778, 0.0534, 0.2053,
        0.0313, 0.2143, 0.0029], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:06,790][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0075, 0.0070, 0.0215, 0.0088, 0.0241, 0.0876, 0.0836, 0.0715, 0.1663,
        0.1412, 0.3062, 0.0493, 0.0253], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,791][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([7.6477e-01, 2.1876e-01, 9.7449e-04, 2.9646e-03, 6.8026e-04, 8.2341e-03,
        2.4315e-04, 7.3680e-04, 9.4618e-04, 8.5769e-04, 3.4867e-04, 1.2337e-04,
        3.6742e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,794][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0006, 0.0006, 0.0277, 0.0057, 0.0117, 0.0553, 0.0976, 0.0954, 0.1059,
        0.1314, 0.3011, 0.1134, 0.0535], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,800][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0173, 0.0140, 0.0965, 0.0116, 0.0873, 0.0949, 0.1045, 0.0984, 0.1006,
        0.1026, 0.1042, 0.0860, 0.0820], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,804][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0287, 0.0146, 0.0745, 0.0117, 0.0781, 0.0980, 0.1110, 0.1037, 0.1474,
        0.1068, 0.0804, 0.0529, 0.0922], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,808][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0332, 0.0093, 0.1138, 0.0210, 0.0630, 0.2448, 0.1008, 0.0902, 0.0467,
        0.0700, 0.1365, 0.0529, 0.0176], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,809][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0611, 0.0574, 0.0897, 0.0508, 0.0814, 0.0816, 0.0740, 0.0864, 0.0956,
        0.0797, 0.0666, 0.0944, 0.0813], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,809][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0082, 0.0164, 0.0834, 0.0151, 0.0417, 0.1085, 0.1081, 0.1054, 0.2163,
        0.0822, 0.1341, 0.0422, 0.0383], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,810][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0107, 0.0112, 0.0273, 0.0130, 0.0390, 0.0864, 0.1082, 0.0774, 0.1457,
        0.1325, 0.2589, 0.0497, 0.0401], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,810][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0104, 0.0102, 0.0305, 0.0112, 0.0292, 0.1039, 0.1136, 0.0607, 0.1247,
        0.1444, 0.2711, 0.0580, 0.0321], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,810][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0004, 0.0019, 0.0275, 0.0020, 0.0145, 0.1155, 0.1745, 0.0367, 0.1224,
        0.0777, 0.3953, 0.0201, 0.0114], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,811][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([6.0256e-04, 2.1294e-04, 2.1983e-03, 1.6988e-03, 1.1604e-03, 3.9619e-01,
        2.1249e-01, 4.3420e-02, 1.6483e-01, 2.4154e-02, 1.5096e-01, 1.7126e-03,
        3.5971e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:06,812][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0295, 0.0142, 0.0286, 0.0220, 0.0545, 0.0989, 0.0692, 0.0397, 0.0684,
        0.1714, 0.2246, 0.0527, 0.0365, 0.0899], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,815][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([8.6515e-01, 1.3000e-01, 5.4795e-04, 9.9735e-04, 1.8731e-04, 1.8572e-03,
        1.2955e-04, 2.0415e-04, 2.9759e-04, 3.1005e-04, 1.0729e-04, 1.4276e-05,
        5.9806e-05, 1.4497e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,820][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0015, 0.0015, 0.0349, 0.0090, 0.0133, 0.0551, 0.0861, 0.0937, 0.1083,
        0.1329, 0.2596, 0.0923, 0.0461, 0.0657], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,825][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0193, 0.0140, 0.0834, 0.0142, 0.0803, 0.0860, 0.0942, 0.0889, 0.0905,
        0.0939, 0.0948, 0.0784, 0.0760, 0.0860], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,829][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0220, 0.0139, 0.0636, 0.0140, 0.0722, 0.0943, 0.1025, 0.0884, 0.1129,
        0.0879, 0.0723, 0.0489, 0.0830, 0.1241], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,829][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0332, 0.0141, 0.1397, 0.0253, 0.1050, 0.1376, 0.0937, 0.0907, 0.0414,
        0.0637, 0.0980, 0.0646, 0.0409, 0.0522], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,830][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0760, 0.0591, 0.0847, 0.0461, 0.0730, 0.0757, 0.0683, 0.0748, 0.0832,
        0.0698, 0.0601, 0.0781, 0.0653, 0.0860], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,830][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0306, 0.0460, 0.2260, 0.0407, 0.0965, 0.0652, 0.0713, 0.0915, 0.1038,
        0.0541, 0.0339, 0.0437, 0.0603, 0.0366], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,831][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0170, 0.0110, 0.0252, 0.0162, 0.0588, 0.0928, 0.1187, 0.0406, 0.0738,
        0.1505, 0.2510, 0.0438, 0.0377, 0.0628], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,831][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0064, 0.0047, 0.0245, 0.0068, 0.0391, 0.1129, 0.1079, 0.0339, 0.0654,
        0.1505, 0.3084, 0.0402, 0.0269, 0.0723], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,832][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0005, 0.0021, 0.0394, 0.0021, 0.0233, 0.1201, 0.1482, 0.0414, 0.1409,
        0.0742, 0.3446, 0.0181, 0.0113, 0.0338], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,835][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0009, 0.0004, 0.0044, 0.0024, 0.0023, 0.3372, 0.1904, 0.0472, 0.1489,
        0.0311, 0.1894, 0.0031, 0.0007, 0.0415], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:06,839][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0266, 0.0112, 0.0318, 0.0215, 0.0771, 0.1085, 0.0573, 0.0198, 0.0287,
        0.1728, 0.1993, 0.0448, 0.0314, 0.0688, 0.1004], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,843][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.2065e-01, 1.6275e-01, 1.4399e-03, 3.3049e-03, 8.1622e-04, 5.2856e-03,
        4.8913e-04, 1.0010e-03, 1.0090e-03, 1.0922e-03, 4.5174e-04, 1.4610e-04,
        2.9652e-04, 4.0019e-04, 8.7033e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,846][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.6410e-05, 6.2401e-05, 1.5053e-02, 1.0995e-03, 5.0624e-03, 3.8355e-02,
        8.1040e-02, 7.7070e-02, 1.0126e-01, 1.0860e-01, 3.6672e-01, 7.6033e-02,
        3.2593e-02, 5.0256e-02, 4.6742e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,849][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0196, 0.0151, 0.0749, 0.0160, 0.0736, 0.0782, 0.0846, 0.0803, 0.0819,
        0.0851, 0.0852, 0.0717, 0.0701, 0.0786, 0.0852], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,850][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0199, 0.0123, 0.0634, 0.0130, 0.0649, 0.0858, 0.0983, 0.0823, 0.1026,
        0.0847, 0.0681, 0.0534, 0.0757, 0.0952, 0.0805], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,850][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0471, 0.0189, 0.1053, 0.0322, 0.0828, 0.1338, 0.0843, 0.0866, 0.0446,
        0.0598, 0.0833, 0.0764, 0.0361, 0.0498, 0.0589], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,851][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0819, 0.0495, 0.0749, 0.0507, 0.0643, 0.0724, 0.0653, 0.0722, 0.0795,
        0.0633, 0.0549, 0.0679, 0.0580, 0.0820, 0.0631], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,851][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0442, 0.0619, 0.2548, 0.0500, 0.0943, 0.0371, 0.0393, 0.0631, 0.1162,
        0.0428, 0.0216, 0.0465, 0.0731, 0.0326, 0.0225], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,852][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0262, 0.0137, 0.0389, 0.0220, 0.1180, 0.1063, 0.0901, 0.0235, 0.0363,
        0.1657, 0.1676, 0.0423, 0.0443, 0.0462, 0.0588], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,852][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0089, 0.0048, 0.0323, 0.0078, 0.0557, 0.1178, 0.0935, 0.0185, 0.0379,
        0.1614, 0.2237, 0.0319, 0.0248, 0.0579, 0.1230], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,855][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0007, 0.0027, 0.0861, 0.0026, 0.0360, 0.1025, 0.1243, 0.0395, 0.1500,
        0.0639, 0.2073, 0.0215, 0.0152, 0.0335, 0.1142], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,860][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0009, 0.0004, 0.0032, 0.0025, 0.0012, 0.3096, 0.2084, 0.0478, 0.1647,
        0.0264, 0.1832, 0.0016, 0.0004, 0.0353, 0.0143], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:06,862][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:06,864][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15400],
        [19782],
        [ 4580],
        [20720],
        [ 3125],
        [ 7723],
        [ 6713],
        [ 2768],
        [ 1082],
        [ 1972],
        [ 4921],
        [ 2304],
        [  975],
        [ 4665],
        [ 3729]], device='cuda:0')
[2024-07-24 10:24:06,867][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16997],
        [24226],
        [15887],
        [15337],
        [10692],
        [19317],
        [18499],
        [13244],
        [ 6355],
        [ 8190],
        [14411],
        [ 8792],
        [ 4417],
        [12903],
        [12525]], device='cuda:0')
[2024-07-24 10:24:06,869][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40853],
        [41253],
        [40248],
        [38331],
        [40382],
        [38169],
        [34223],
        [27216],
        [27493],
        [30504],
        [32240],
        [24147],
        [24178],
        [26194],
        [27497]], device='cuda:0')
[2024-07-24 10:24:06,872][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[14950],
        [20742],
        [45272],
        [42878],
        [46486],
        [45160],
        [44524],
        [42899],
        [39233],
        [40159],
        [39285],
        [36268],
        [41135],
        [41720],
        [40829]], device='cuda:0')
[2024-07-24 10:24:06,874][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[35910],
        [37051],
        [46189],
        [46174],
        [42794],
        [25988],
        [25044],
        [26582],
        [25326],
        [26188],
        [26794],
        [26787],
        [26683],
        [27146],
        [26598]], device='cuda:0')
[2024-07-24 10:24:06,875][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 4608],
        [ 4389],
        [ 7943],
        [ 9545],
        [10161],
        [ 6669],
        [ 6768],
        [ 5857],
        [ 5771],
        [ 7052],
        [ 7817],
        [ 9448],
        [10445],
        [10192],
        [ 9106]], device='cuda:0')
[2024-07-24 10:24:06,876][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10820],
        [17079],
        [14051],
        [29444],
        [18013],
        [14795],
        [14473],
        [14896],
        [13919],
        [15346],
        [13466],
        [19699],
        [21656],
        [16080],
        [13930]], device='cuda:0')
[2024-07-24 10:24:06,877][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37605],
        [30003],
        [35357],
        [35656],
        [36178],
        [36257],
        [35366],
        [35484],
        [34560],
        [33739],
        [33507],
        [31282],
        [31466],
        [32176],
        [32425]], device='cuda:0')
[2024-07-24 10:24:06,878][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10961],
        [ 3790],
        [ 3637],
        [ 2563],
        [ 1892],
        [ 2106],
        [ 2494],
        [ 2828],
        [ 2967],
        [ 3297],
        [ 3523],
        [ 4886],
        [ 4954],
        [ 4247],
        [ 4377]], device='cuda:0')
[2024-07-24 10:24:06,881][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[41917],
        [33681],
        [36702],
        [46161],
        [33750],
        [33636],
        [35294],
        [29719],
        [29959],
        [29690],
        [25702],
        [28631],
        [26991],
        [28947],
        [26121]], device='cuda:0')
[2024-07-24 10:24:06,883][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22885],
        [25620],
        [26158],
        [25778],
        [22135],
        [18906],
        [15886],
        [14357],
        [14515],
        [14576],
        [15005],
        [11649],
        [12125],
        [12554],
        [13543]], device='cuda:0')
[2024-07-24 10:24:06,886][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29433],
        [29076],
        [42518],
        [42112],
        [32509],
        [26783],
        [24713],
        [22392],
        [21685],
        [20053],
        [19024],
        [23450],
        [23146],
        [18004],
        [17173]], device='cuda:0')
[2024-07-24 10:24:06,888][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2587],
        [2571],
        [2372],
        [2431],
        [2271],
        [1352],
        [1100],
        [ 956],
        [ 793],
        [ 779],
        [ 649],
        [ 612],
        [ 595],
        [ 620],
        [ 641]], device='cuda:0')
[2024-07-24 10:24:06,891][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27374],
        [27058],
        [23848],
        [23659],
        [22721],
        [20173],
        [20103],
        [19552],
        [19626],
        [19075],
        [19034],
        [19328],
        [21080],
        [20953],
        [20651]], device='cuda:0')
[2024-07-24 10:24:06,894][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[30328],
        [ 2941],
        [15569],
        [ 2932],
        [20165],
        [35030],
        [32483],
        [25490],
        [26560],
        [26571],
        [29115],
        [18745],
        [20454],
        [31070],
        [30579]], device='cuda:0')
[2024-07-24 10:24:06,896][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15834],
        [14843],
        [15225],
        [14582],
        [11882],
        [12237],
        [ 9330],
        [ 5241],
        [ 7502],
        [12441],
        [12459],
        [ 5533],
        [ 6207],
        [ 7386],
        [ 7007]], device='cuda:0')
[2024-07-24 10:24:06,899][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[8014],
        [6017],
        [6709],
        [6218],
        [6498],
        [7015],
        [6973],
        [6942],
        [7013],
        [7121],
        [6757],
        [7188],
        [6834],
        [7300],
        [7099]], device='cuda:0')
[2024-07-24 10:24:06,900][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[1531],
        [ 730],
        [3113],
        [3173],
        [3050],
        [3664],
        [3554],
        [4188],
        [3844],
        [3728],
        [3032],
        [3522],
        [3522],
        [3658],
        [3468]], device='cuda:0')
[2024-07-24 10:24:06,901][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7020],
        [15802],
        [18157],
        [18233],
        [16865],
        [16906],
        [16845],
        [18131],
        [18609],
        [19307],
        [19591],
        [19953],
        [20207],
        [20615],
        [20798]], device='cuda:0')
[2024-07-24 10:24:06,902][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[36495],
        [13444],
        [ 9789],
        [ 9431],
        [11066],
        [12203],
        [10945],
        [11516],
        [11564],
        [10755],
        [10330],
        [10038],
        [10415],
        [ 9829],
        [ 9324]], device='cuda:0')
[2024-07-24 10:24:06,903][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[10256],
        [ 7086],
        [  400],
        [  423],
        [  663],
        [ 1860],
        [ 1984],
        [ 2070],
        [ 2189],
        [ 2045],
        [ 1951],
        [ 1879],
        [ 2123],
        [ 1397],
        [ 1250]], device='cuda:0')
[2024-07-24 10:24:06,906][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[5274],
        [7265],
        [7175],
        [9083],
        [9441],
        [8593],
        [8369],
        [7868],
        [6899],
        [6794],
        [6648],
        [6674],
        [6849],
        [6791],
        [6703]], device='cuda:0')
[2024-07-24 10:24:06,908][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13801],
        [30543],
        [ 1218],
        [ 1389],
        [ 1489],
        [ 2279],
        [ 3277],
        [ 6000],
        [ 4168],
        [ 6117],
        [ 4081],
        [ 9515],
        [10449],
        [ 7442],
        [ 6124]], device='cuda:0')
[2024-07-24 10:24:06,911][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38912],
        [38593],
        [41648],
        [41389],
        [42269],
        [43601],
        [41942],
        [38307],
        [39486],
        [35602],
        [35611],
        [21265],
        [22950],
        [23982],
        [28121]], device='cuda:0')
[2024-07-24 10:24:06,913][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16828],
        [10758],
        [10227],
        [11586],
        [13485],
        [12498],
        [15294],
        [15195],
        [13802],
        [14666],
        [20432],
        [24046],
        [22062],
        [23786],
        [23257]], device='cuda:0')
[2024-07-24 10:24:06,916][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23151],
        [41820],
        [47163],
        [47328],
        [46914],
        [43473],
        [40389],
        [40425],
        [44695],
        [43136],
        [41298],
        [39075],
        [38488],
        [39261],
        [41072]], device='cuda:0')
[2024-07-24 10:24:06,918][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5644],
        [ 6899],
        [14398],
        [15801],
        [14705],
        [ 8591],
        [ 8116],
        [ 8545],
        [10580],
        [10481],
        [12171],
        [11727],
        [10680],
        [11052],
        [11102]], device='cuda:0')
[2024-07-24 10:24:06,921][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44662],
        [43070],
        [47813],
        [47740],
        [47093],
        [46609],
        [46609],
        [46630],
        [46103],
        [46221],
        [46464],
        [47132],
        [46954],
        [47187],
        [47207]], device='cuda:0')
[2024-07-24 10:24:06,924][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[30876],
        [48089],
        [22318],
        [47614],
        [25199],
        [28961],
        [30878],
        [31853],
        [32608],
        [33495],
        [35040],
        [36924],
        [32850],
        [33338],
        [30409]], device='cuda:0')
[2024-07-24 10:24:06,926][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274],
        [4274]], device='cuda:0')
[2024-07-24 10:24:06,965][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:06,968][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,972][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,972][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,973][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,973][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,973][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,974][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,974][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,974][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,974][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,975][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,975][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:06,975][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6668, 0.3332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,976][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1387, 0.8613], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,976][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2771, 0.7229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,976][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3640, 0.6360], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,977][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3574, 0.6426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,977][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9856, 0.0144], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,977][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5549, 0.4451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,978][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6301, 0.3699], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,978][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5197, 0.4803], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,978][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5199, 0.4801], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,979][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4423, 0.5577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,979][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4234, 0.5766], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:06,979][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.2711, 0.1194, 0.6095], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,980][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.0899, 0.2174, 0.6927], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,980][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.2254, 0.2598, 0.5148], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,980][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.2122, 0.3494, 0.4384], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,981][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.7293, 0.2629, 0.0078], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,981][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.6587, 0.0477, 0.2936], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,981][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.0708, 0.1153, 0.8139], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,982][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.9205, 0.0632, 0.0163], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,982][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.4655, 0.4105, 0.1240], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,982][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.3216, 0.3714, 0.3070], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,983][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.3675, 0.2663, 0.3662], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,984][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.4102, 0.4735, 0.1163], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:06,986][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1332, 0.0363, 0.7418, 0.0887], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,987][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0104, 0.0662, 0.8438, 0.0796], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,988][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1787, 0.2284, 0.3082, 0.2848], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,990][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1490, 0.2549, 0.3221, 0.2740], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,991][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0361, 0.0631, 0.8170, 0.0838], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,993][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7720, 0.0088, 0.2108, 0.0084], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,994][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1622, 0.1361, 0.5461, 0.1556], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,995][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2132, 0.1168, 0.2302, 0.4398], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,997][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2995, 0.2849, 0.1657, 0.2500], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:06,998][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1661, 0.3156, 0.3052, 0.2132], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,000][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1751, 0.2123, 0.3626, 0.2500], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,001][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2135, 0.2953, 0.2428, 0.2484], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,002][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1349, 0.0611, 0.3701, 0.1050, 0.3289], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,004][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0602, 0.1239, 0.3429, 0.1312, 0.3418], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,004][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0845, 0.1315, 0.2583, 0.1793, 0.3464], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,005][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.1298, 0.1873, 0.2313, 0.1967, 0.2549], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,005][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.6161, 0.1363, 0.0024, 0.2209, 0.0244], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,005][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.2640, 0.0532, 0.4997, 0.0701, 0.1130], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,005][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0679, 0.0783, 0.3635, 0.1166, 0.3736], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,006][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.4365, 0.0208, 0.0053, 0.5345, 0.0030], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,006][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.3211, 0.3080, 0.1313, 0.1445, 0.0951], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,006][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.1916, 0.2766, 0.2273, 0.1595, 0.1450], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,007][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.1687, 0.1258, 0.2787, 0.1312, 0.2957], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,007][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.2048, 0.2645, 0.1502, 0.1499, 0.2307], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,009][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1084, 0.0410, 0.2259, 0.0751, 0.2085, 0.3411], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,010][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0074, 0.0135, 0.0917, 0.0123, 0.0884, 0.7866], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,011][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0368, 0.0820, 0.2294, 0.1504, 0.2785, 0.2228], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,013][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1005, 0.1462, 0.1792, 0.1562, 0.2022, 0.2158], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,014][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4774, 0.0869, 0.0020, 0.2179, 0.2041, 0.0116], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,015][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.6435, 0.0190, 0.1306, 0.0451, 0.1343, 0.0275], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,017][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0255, 0.0377, 0.2468, 0.0498, 0.2613, 0.3790], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,018][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2479, 0.0134, 0.0028, 0.3725, 0.0037, 0.3596], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,019][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4452, 0.2773, 0.0389, 0.1606, 0.0445, 0.0335], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,021][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2051, 0.2947, 0.2152, 0.1388, 0.1034, 0.0428], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,022][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0961, 0.0449, 0.2024, 0.0555, 0.3048, 0.2962], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,023][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0319, 0.0320, 0.0208, 0.0242, 0.0610, 0.8301], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,025][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0841, 0.0317, 0.1529, 0.0584, 0.1426, 0.2320, 0.2983],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,026][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0029, 0.0059, 0.0474, 0.0057, 0.0378, 0.5085, 0.3919],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,027][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0309, 0.0782, 0.1927, 0.1212, 0.2203, 0.2000, 0.1566],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,029][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0809, 0.1210, 0.1498, 0.1292, 0.1704, 0.1812, 0.1675],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,030][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3585, 0.0756, 0.0043, 0.2004, 0.3147, 0.0287, 0.0177],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,031][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6399, 0.0144, 0.1546, 0.0490, 0.0981, 0.0292, 0.0147],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,033][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0278, 0.0325, 0.1687, 0.0488, 0.1736, 0.2945, 0.2541],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,034][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2094, 0.0086, 0.0014, 0.2832, 0.0018, 0.1939, 0.3018],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,035][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3797, 0.2485, 0.0704, 0.1462, 0.0647, 0.0402, 0.0503],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,037][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2220, 0.2726, 0.1785, 0.1409, 0.0906, 0.0330, 0.0624],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,038][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0764, 0.0339, 0.1271, 0.0443, 0.2606, 0.2221, 0.2355],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,040][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1285, 0.1040, 0.0277, 0.0704, 0.1039, 0.5183, 0.0473],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,041][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0590, 0.0217, 0.1282, 0.0411, 0.1185, 0.1987, 0.2545, 0.1782],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,042][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0088, 0.0129, 0.0208, 0.0129, 0.0306, 0.4015, 0.3019, 0.2107],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,043][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0171, 0.0607, 0.1893, 0.1056, 0.2052, 0.1807, 0.1358, 0.1056],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,045][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0693, 0.1038, 0.1270, 0.1112, 0.1449, 0.1541, 0.1432, 0.1464],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,046][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.4527, 0.0659, 0.0009, 0.2071, 0.2291, 0.0241, 0.0151, 0.0050],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,048][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.6490, 0.0146, 0.1243, 0.0286, 0.0765, 0.0272, 0.0357, 0.0441],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,049][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0285, 0.0227, 0.1273, 0.0317, 0.1205, 0.2175, 0.2043, 0.2474],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,051][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0589, 0.0039, 0.0017, 0.1367, 0.0029, 0.3053, 0.4670, 0.0237],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,052][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.2612, 0.2291, 0.0615, 0.1150, 0.0763, 0.0650, 0.0882, 0.1037],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,052][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2039, 0.3171, 0.1626, 0.1287, 0.0718, 0.0229, 0.0370, 0.0559],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,052][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0520, 0.0267, 0.0878, 0.0349, 0.1845, 0.2507, 0.2538, 0.1096],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,053][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0328, 0.0437, 0.0199, 0.0254, 0.0540, 0.6821, 0.0567, 0.0854],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,053][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0511, 0.0181, 0.1082, 0.0344, 0.1000, 0.1673, 0.2166, 0.1471, 0.1571],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,053][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0173, 0.0200, 0.0260, 0.0192, 0.0343, 0.2994, 0.2291, 0.1611, 0.1934],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,054][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0140, 0.0538, 0.1632, 0.0912, 0.1839, 0.1606, 0.1235, 0.0950, 0.1147],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,054][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0597, 0.0892, 0.1098, 0.0951, 0.1247, 0.1339, 0.1237, 0.1263, 0.1377],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,054][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2781, 0.0696, 0.0051, 0.1649, 0.3114, 0.0794, 0.0572, 0.0211, 0.0131],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,055][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.7008, 0.0158, 0.0842, 0.0384, 0.0336, 0.0104, 0.0334, 0.0744, 0.0089],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,055][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0206, 0.0193, 0.0951, 0.0272, 0.0953, 0.1729, 0.1604, 0.2024, 0.2068],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,057][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0411, 0.0034, 0.0021, 0.1038, 0.0029, 0.3097, 0.4561, 0.0220, 0.0589],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,058][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1468, 0.1427, 0.0536, 0.0838, 0.0489, 0.0546, 0.1279, 0.2166, 0.1251],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,059][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1496, 0.3303, 0.1684, 0.1135, 0.0748, 0.0250, 0.0446, 0.0497, 0.0441],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,061][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0753, 0.0349, 0.1207, 0.0418, 0.2169, 0.1712, 0.1723, 0.0616, 0.1053],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,062][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0224, 0.0280, 0.0238, 0.0190, 0.0793, 0.4570, 0.0921, 0.1294, 0.1490],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,063][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0483, 0.0210, 0.0943, 0.0399, 0.0890, 0.1407, 0.1739, 0.1246, 0.1343,
        0.1339], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,064][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0009, 0.0019, 0.0153, 0.0019, 0.0151, 0.1870, 0.1532, 0.1038, 0.1379,
        0.3831], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,066][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0175, 0.0531, 0.1352, 0.0911, 0.1550, 0.1419, 0.1092, 0.0926, 0.1072,
        0.0971], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,067][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0531, 0.0790, 0.0970, 0.0854, 0.1102, 0.1179, 0.1087, 0.1113, 0.1204,
        0.1169], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,069][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5091, 0.0841, 0.0028, 0.2064, 0.1692, 0.0099, 0.0055, 0.0017, 0.0015,
        0.0097], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,069][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([6.0658e-01, 3.6912e-03, 1.2102e-01, 8.1557e-03, 7.0396e-02, 1.7534e-02,
        2.4907e-02, 1.1256e-01, 3.4798e-02, 3.5184e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,071][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0168, 0.0175, 0.0877, 0.0236, 0.0891, 0.1442, 0.1437, 0.1784, 0.1562,
        0.1428], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,072][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1325, 0.0066, 0.0019, 0.2081, 0.0022, 0.2293, 0.3170, 0.0137, 0.0410,
        0.0478], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,074][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3884, 0.2232, 0.0287, 0.1229, 0.0209, 0.0213, 0.0420, 0.0812, 0.0395,
        0.0318], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,075][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1290, 0.2335, 0.1698, 0.0997, 0.0879, 0.0331, 0.0735, 0.0799, 0.0553,
        0.0381], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,077][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0449, 0.0245, 0.1004, 0.0302, 0.1652, 0.1493, 0.1371, 0.0621, 0.0995,
        0.1868], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,078][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0612, 0.0497, 0.0188, 0.0340, 0.0352, 0.2625, 0.0663, 0.1756, 0.1629,
        0.1337], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,079][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0416, 0.0192, 0.0818, 0.0342, 0.0776, 0.1214, 0.1511, 0.1086, 0.1149,
        0.1161, 0.1336], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,081][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0004, 0.0011, 0.0156, 0.0011, 0.0140, 0.1781, 0.0968, 0.0781, 0.1231,
        0.2612, 0.2304], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,082][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0153, 0.0575, 0.1321, 0.0978, 0.1421, 0.1268, 0.0943, 0.0771, 0.0918,
        0.0860, 0.0793], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,084][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0485, 0.0711, 0.0870, 0.0769, 0.0991, 0.1050, 0.0971, 0.0989, 0.1068,
        0.1037, 0.1059], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,085][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2286, 0.0614, 0.0087, 0.1438, 0.3770, 0.0525, 0.0287, 0.0105, 0.0086,
        0.0589, 0.0214], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,087][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5952, 0.0057, 0.1817, 0.0038, 0.0939, 0.0153, 0.0283, 0.0543, 0.0189,
        0.0007, 0.0023], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,088][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0248, 0.0232, 0.0859, 0.0261, 0.0859, 0.1272, 0.1225, 0.1462, 0.1328,
        0.1133, 0.1120], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,089][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0427, 0.0028, 0.0013, 0.0815, 0.0019, 0.1559, 0.2247, 0.0110, 0.0333,
        0.0375, 0.4073], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,091][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3639, 0.2131, 0.0261, 0.1254, 0.0299, 0.0303, 0.0503, 0.0720, 0.0393,
        0.0293, 0.0205], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,092][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1246, 0.2276, 0.1616, 0.0934, 0.0798, 0.0382, 0.0758, 0.0772, 0.0549,
        0.0348, 0.0320], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,094][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0315, 0.0134, 0.0736, 0.0179, 0.1605, 0.1315, 0.1219, 0.0375, 0.0761,
        0.1757, 0.1605], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,095][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0443, 0.0396, 0.0147, 0.0262, 0.0294, 0.3271, 0.0498, 0.1457, 0.1417,
        0.1270, 0.0544], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,096][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0378, 0.0150, 0.0746, 0.0280, 0.0685, 0.1113, 0.1369, 0.0995, 0.1101,
        0.1079, 0.1237, 0.0868], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,098][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0022, 0.0038, 0.0110, 0.0036, 0.0092, 0.1637, 0.1299, 0.0715, 0.0805,
        0.2346, 0.2682, 0.0218], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,099][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0201, 0.0482, 0.1021, 0.0738, 0.1194, 0.1143, 0.0932, 0.0769, 0.0875,
        0.0818, 0.0814, 0.1015], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,099][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0417, 0.0635, 0.0787, 0.0685, 0.0902, 0.0960, 0.0887, 0.0898, 0.0978,
        0.0954, 0.0975, 0.0921], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,100][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.4796, 0.0707, 0.0024, 0.1902, 0.1906, 0.0188, 0.0102, 0.0030, 0.0026,
        0.0179, 0.0048, 0.0094], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,100][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2080, 0.0258, 0.3215, 0.0376, 0.1309, 0.0166, 0.0840, 0.0874, 0.0278,
        0.0069, 0.0211, 0.0324], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,101][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0193, 0.0190, 0.0639, 0.0251, 0.0620, 0.1118, 0.1032, 0.1418, 0.1265,
        0.1196, 0.1249, 0.0829], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,101][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0118, 0.0011, 0.0011, 0.0302, 0.0016, 0.1783, 0.2385, 0.0113, 0.0346,
        0.0336, 0.4547, 0.0032], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,101][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.3052, 0.1975, 0.0244, 0.1035, 0.0265, 0.0263, 0.0414, 0.0873, 0.0660,
        0.0386, 0.0262, 0.0572], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,102][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0969, 0.1739, 0.1452, 0.0858, 0.0727, 0.0460, 0.0798, 0.1038, 0.0765,
        0.0477, 0.0369, 0.0348], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,103][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0280, 0.0199, 0.0494, 0.0236, 0.0809, 0.1111, 0.1277, 0.0660, 0.1045,
        0.1489, 0.1729, 0.0671], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,104][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0513, 0.0511, 0.0233, 0.0331, 0.0515, 0.3160, 0.0313, 0.1092, 0.1324,
        0.1042, 0.0640, 0.0325], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,106][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0301, 0.0115, 0.0698, 0.0211, 0.0625, 0.1077, 0.1326, 0.0942, 0.1050,
        0.1035, 0.1191, 0.0803, 0.0628], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,107][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0011, 0.0024, 0.0095, 0.0026, 0.0092, 0.1578, 0.1088, 0.0697, 0.1179,
        0.1965, 0.2828, 0.0236, 0.0181], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,108][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0144, 0.0365, 0.0949, 0.0534, 0.1146, 0.1102, 0.0873, 0.0727, 0.0833,
        0.0785, 0.0742, 0.0929, 0.0870], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,110][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0392, 0.0587, 0.0732, 0.0625, 0.0824, 0.0880, 0.0811, 0.0829, 0.0910,
        0.0872, 0.0883, 0.0831, 0.0824], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,111][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.3836, 0.0864, 0.0080, 0.1724, 0.1785, 0.0292, 0.0191, 0.0094, 0.0055,
        0.0340, 0.0099, 0.0401, 0.0240], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,112][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.2468, 0.0271, 0.2939, 0.0333, 0.0524, 0.0239, 0.0633, 0.1115, 0.0339,
        0.0065, 0.0213, 0.0185, 0.0674], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,114][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0126, 0.0111, 0.0554, 0.0176, 0.0575, 0.1002, 0.1105, 0.1373, 0.1105,
        0.1234, 0.1248, 0.0673, 0.0718], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,115][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([9.4333e-03, 9.2222e-04, 1.2660e-03, 2.3170e-02, 1.2843e-03, 1.8906e-01,
        2.4684e-01, 1.0804e-02, 3.2074e-02, 3.2658e-02, 4.4929e-01, 3.1432e-03,
        6.6388e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,116][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.1061, 0.0999, 0.0311, 0.0539, 0.0313, 0.0512, 0.0454, 0.1312, 0.0941,
        0.0913, 0.0590, 0.1266, 0.0790], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,118][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0691, 0.1398, 0.1346, 0.0689, 0.0723, 0.0490, 0.0856, 0.0933, 0.0738,
        0.0610, 0.0529, 0.0524, 0.0473], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,119][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0247, 0.0197, 0.0517, 0.0226, 0.0737, 0.1056, 0.1163, 0.0640, 0.1034,
        0.1350, 0.1512, 0.0586, 0.0736], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,120][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0266, 0.0309, 0.0155, 0.0199, 0.0337, 0.3769, 0.0261, 0.0709, 0.1272,
        0.1149, 0.0682, 0.0435, 0.0456], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,122][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0317, 0.0134, 0.0616, 0.0255, 0.0581, 0.0947, 0.1185, 0.0848, 0.0909,
        0.0928, 0.1050, 0.0738, 0.0591, 0.0900], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,123][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0004, 0.0010, 0.0169, 0.0009, 0.0140, 0.1378, 0.0962, 0.0725, 0.0820,
        0.2007, 0.1737, 0.0168, 0.0129, 0.1742], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,125][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0118, 0.0369, 0.1002, 0.0592, 0.1077, 0.1010, 0.0771, 0.0652, 0.0737,
        0.0678, 0.0651, 0.0814, 0.0746, 0.0783], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,126][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0363, 0.0542, 0.0660, 0.0589, 0.0748, 0.0801, 0.0744, 0.0764, 0.0830,
        0.0803, 0.0818, 0.0761, 0.0752, 0.0825], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,128][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.4359, 0.0504, 0.0009, 0.1706, 0.2692, 0.0136, 0.0074, 0.0018, 0.0012,
        0.0161, 0.0039, 0.0090, 0.0127, 0.0073], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,129][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.5673, 0.0138, 0.0797, 0.0220, 0.0545, 0.0093, 0.0277, 0.0622, 0.0194,
        0.0029, 0.0153, 0.0347, 0.0749, 0.0163], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,131][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0070, 0.0092, 0.0508, 0.0127, 0.0551, 0.0959, 0.0945, 0.1224, 0.1047,
        0.1057, 0.1021, 0.0627, 0.0635, 0.1138], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,132][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([1.1577e-02, 1.0381e-03, 8.8486e-04, 3.3768e-02, 1.8001e-03, 1.6276e-01,
        2.4576e-01, 1.4331e-02, 3.8353e-02, 4.5263e-02, 4.3316e-01, 4.0654e-03,
        1.4624e-04, 7.0883e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,133][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.1269, 0.1009, 0.0276, 0.0499, 0.0208, 0.0309, 0.0410, 0.1295, 0.0805,
        0.0748, 0.0395, 0.1464, 0.0471, 0.0842], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,135][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0760, 0.2294, 0.1541, 0.0737, 0.0691, 0.0356, 0.0722, 0.0770, 0.0610,
        0.0417, 0.0321, 0.0217, 0.0292, 0.0272], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,136][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0116, 0.0068, 0.0330, 0.0092, 0.0689, 0.1170, 0.1199, 0.0503, 0.0917,
        0.1405, 0.1902, 0.0331, 0.0495, 0.0783], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,137][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0079, 0.0075, 0.0081, 0.0056, 0.0236, 0.3285, 0.0347, 0.1152, 0.1772,
        0.0788, 0.0687, 0.0175, 0.0351, 0.0917], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,139][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0313, 0.0130, 0.0565, 0.0241, 0.0541, 0.0858, 0.1093, 0.0770, 0.0802,
        0.0816, 0.0942, 0.0670, 0.0543, 0.0786, 0.0932], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,140][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0003, 0.0006, 0.0150, 0.0005, 0.0098, 0.1036, 0.0632, 0.0433, 0.0653,
        0.1696, 0.1392, 0.0158, 0.0102, 0.2373, 0.1262], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,142][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0082, 0.0368, 0.0962, 0.0531, 0.1035, 0.0919, 0.0704, 0.0580, 0.0671,
        0.0635, 0.0565, 0.0723, 0.0719, 0.0749, 0.0756], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,143][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0343, 0.0509, 0.0619, 0.0548, 0.0705, 0.0749, 0.0693, 0.0702, 0.0764,
        0.0740, 0.0753, 0.0705, 0.0702, 0.0760, 0.0711], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,145][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1661, 0.0318, 0.0042, 0.1002, 0.4727, 0.0438, 0.0213, 0.0061, 0.0040,
        0.0462, 0.0134, 0.0228, 0.0325, 0.0225, 0.0123], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,146][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3841, 0.0104, 0.1819, 0.0240, 0.0955, 0.0088, 0.0397, 0.0518, 0.0189,
        0.0024, 0.0153, 0.0313, 0.0963, 0.0149, 0.0248], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,146][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0065, 0.0075, 0.0540, 0.0104, 0.0574, 0.0881, 0.0862, 0.1046, 0.0951,
        0.0903, 0.0914, 0.0635, 0.0695, 0.0953, 0.0802], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,147][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.1567e-02, 1.5571e-03, 8.7520e-04, 4.8327e-02, 1.5444e-03, 1.3329e-01,
        2.0655e-01, 1.1234e-02, 3.3990e-02, 3.8332e-02, 4.2019e-01, 3.9482e-03,
        1.6419e-04, 6.1685e-03, 7.2259e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,147][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2821, 0.1633, 0.0331, 0.1001, 0.0344, 0.0197, 0.0250, 0.0522, 0.0409,
        0.0344, 0.0273, 0.0660, 0.0607, 0.0440, 0.0169], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,147][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1586, 0.1300, 0.0835, 0.0869, 0.0564, 0.0302, 0.0592, 0.0857, 0.0820,
        0.0378, 0.0294, 0.0397, 0.0386, 0.0339, 0.0483], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,148][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0191, 0.0085, 0.0430, 0.0118, 0.1074, 0.1028, 0.1019, 0.0316, 0.0629,
        0.1375, 0.1370, 0.0368, 0.0601, 0.0576, 0.0820], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,148][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0097, 0.0110, 0.0150, 0.0073, 0.0319, 0.3044, 0.0292, 0.0686, 0.1463,
        0.1449, 0.0643, 0.0354, 0.0374, 0.0712, 0.0234], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,184][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:07,184][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,185][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,185][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,185][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,185][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,186][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,186][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,186][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,187][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,187][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,187][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,188][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,188][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5215, 0.4785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,188][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1273, 0.8727], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,189][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4605, 0.5395], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,189][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3882, 0.6118], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,189][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3836, 0.6164], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,190][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5027, 0.4973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,190][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3481, 0.6519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,190][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4074, 0.5926], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,191][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4927, 0.5073], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,192][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4328, 0.5672], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,192][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4423, 0.5577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,193][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3522, 0.6478], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,193][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.5838, 0.3631, 0.0531], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,193][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.0272, 0.1032, 0.8696], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,194][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.5930, 0.3057, 0.1014], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,194][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.2990, 0.2686, 0.4324], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,194][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.2878, 0.3114, 0.4009], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,195][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.6388, 0.2732, 0.0880], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,195][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.2977, 0.2881, 0.4142], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,195][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.5042, 0.3676, 0.1283], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,196][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.5110, 0.2830, 0.2059], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,196][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.3378, 0.2634, 0.3988], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,196][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.3675, 0.2663, 0.3662], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,197][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.2798, 0.3115, 0.4087], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,197][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3235, 0.2864, 0.0932, 0.2970], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,197][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0149, 0.1029, 0.7704, 0.1118], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,198][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2407, 0.2694, 0.2368, 0.2531], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,198][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1475, 0.2294, 0.3942, 0.2289], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,199][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1314, 0.2003, 0.4083, 0.2600], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,199][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2656, 0.2475, 0.2240, 0.2629], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,199][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1246, 0.2244, 0.4206, 0.2304], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,200][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1642, 0.2190, 0.3259, 0.2909], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,202][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2400, 0.2413, 0.2752, 0.2434], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,203][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1804, 0.2280, 0.3483, 0.2434], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,205][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1751, 0.2123, 0.3626, 0.2500], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,206][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1348, 0.2378, 0.3872, 0.2402], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,207][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.3818, 0.2301, 0.0483, 0.2154, 0.1243], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,209][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0148, 0.0588, 0.6112, 0.0546, 0.2605], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,210][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.3684, 0.2137, 0.1139, 0.1803, 0.1237], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,212][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.1982, 0.1625, 0.3816, 0.1189, 0.1389], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,213][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.1531, 0.1394, 0.2292, 0.1675, 0.3108], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,214][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.4528, 0.1850, 0.1128, 0.1638, 0.0855], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,216][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.1751, 0.1816, 0.2830, 0.1635, 0.1968], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,217][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2428, 0.1735, 0.1554, 0.2009, 0.2274], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,219][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.3263, 0.1801, 0.2659, 0.1290, 0.0987], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,220][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.1869, 0.1501, 0.3385, 0.1355, 0.1890], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,220][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.1687, 0.1258, 0.2787, 0.1312, 0.2957], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,221][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.1472, 0.1517, 0.4232, 0.1170, 0.1609], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,221][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4158, 0.1864, 0.0417, 0.1819, 0.1502, 0.0240], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,221][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0126, 0.0395, 0.4711, 0.0329, 0.1845, 0.2594], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,222][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4414, 0.1826, 0.0927, 0.1488, 0.1119, 0.0226], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,222][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1837, 0.1026, 0.3995, 0.0818, 0.2093, 0.0231], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,223][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0536, 0.0268, 0.0751, 0.0489, 0.4245, 0.3711], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,224][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4368, 0.0970, 0.1083, 0.1230, 0.2028, 0.0321], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,225][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1724, 0.1338, 0.3094, 0.1198, 0.2223, 0.0422], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,226][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2141, 0.0645, 0.0685, 0.1189, 0.3925, 0.1414], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,228][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3176, 0.1084, 0.3100, 0.0869, 0.1685, 0.0087], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,229][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2017, 0.1011, 0.3177, 0.0937, 0.2032, 0.0826], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,231][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0961, 0.0449, 0.2024, 0.0555, 0.3048, 0.2962], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,232][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0532, 0.0344, 0.4914, 0.0311, 0.2404, 0.1495], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,233][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2354, 0.1037, 0.0218, 0.1038, 0.0814, 0.0140, 0.4401],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,235][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0070, 0.0240, 0.3929, 0.0209, 0.1397, 0.2602, 0.1553],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,236][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4114, 0.1692, 0.1037, 0.1437, 0.1221, 0.0320, 0.0178],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,237][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1845, 0.0916, 0.3469, 0.0802, 0.2398, 0.0274, 0.0295],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,239][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0249, 0.0125, 0.0452, 0.0252, 0.2845, 0.3365, 0.2712],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,240][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3421, 0.0772, 0.1010, 0.1136, 0.2826, 0.0657, 0.0177],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,242][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2756, 0.1586, 0.1934, 0.1427, 0.1655, 0.0376, 0.0268],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,243][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0953, 0.0310, 0.0422, 0.0662, 0.3691, 0.2212, 0.1750],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,245][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2868, 0.0969, 0.2999, 0.0829, 0.2141, 0.0115, 0.0080],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,246][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1892, 0.0906, 0.2825, 0.0895, 0.2137, 0.0831, 0.0515],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,247][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0764, 0.0339, 0.1271, 0.0443, 0.2606, 0.2221, 0.2355],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,249][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0427, 0.0248, 0.3452, 0.0245, 0.2373, 0.1858, 0.1396],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,250][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1835, 0.0946, 0.0251, 0.0964, 0.0888, 0.0203, 0.4325, 0.0589],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,252][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0104, 0.0336, 0.2850, 0.0294, 0.1295, 0.2570, 0.1554, 0.0996],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,253][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3736, 0.1657, 0.1079, 0.1373, 0.1257, 0.0353, 0.0218, 0.0325],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,255][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1505, 0.0834, 0.3748, 0.0721, 0.2383, 0.0330, 0.0323, 0.0156],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,256][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0103, 0.0057, 0.0159, 0.0115, 0.1192, 0.3620, 0.3611, 0.1144],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,257][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2409, 0.0620, 0.0798, 0.0915, 0.2500, 0.1705, 0.0681, 0.0372],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,259][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2127, 0.1284, 0.2344, 0.1132, 0.1527, 0.0721, 0.0515, 0.0349],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,260][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0225, 0.0089, 0.0172, 0.0192, 0.1464, 0.3360, 0.3905, 0.0592],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,262][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.2723, 0.1038, 0.2511, 0.0912, 0.2159, 0.0259, 0.0190, 0.0207],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,263][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1437, 0.0801, 0.2433, 0.0806, 0.2079, 0.1142, 0.0756, 0.0547],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,265][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0520, 0.0267, 0.0878, 0.0349, 0.1845, 0.2507, 0.2538, 0.1096],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,266][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0192, 0.0144, 0.2115, 0.0145, 0.1795, 0.2416, 0.2341, 0.0852],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,267][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1702, 0.0844, 0.0248, 0.0821, 0.0703, 0.0189, 0.4990, 0.0428, 0.0074],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,267][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0113, 0.0292, 0.4761, 0.0224, 0.1297, 0.1445, 0.0677, 0.0431, 0.0761],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,268][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.5062, 0.1739, 0.0662, 0.1325, 0.0780, 0.0116, 0.0063, 0.0114, 0.0140],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,268][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.2362, 0.1015, 0.3861, 0.0751, 0.1741, 0.0097, 0.0092, 0.0032, 0.0050],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,268][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0171, 0.0080, 0.0285, 0.0152, 0.1859, 0.2990, 0.2777, 0.0730, 0.0957],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,269][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.3489, 0.0727, 0.0919, 0.0985, 0.2264, 0.0921, 0.0346, 0.0188, 0.0162],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,269][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.2940, 0.1411, 0.2227, 0.1119, 0.1440, 0.0317, 0.0213, 0.0148, 0.0184],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,270][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0438, 0.0144, 0.0307, 0.0287, 0.2121, 0.2849, 0.2660, 0.0349, 0.0844],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,271][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.4769, 0.1224, 0.1760, 0.0909, 0.1192, 0.0043, 0.0025, 0.0040, 0.0038],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,272][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1871, 0.0871, 0.2921, 0.0773, 0.1915, 0.0578, 0.0291, 0.0264, 0.0517],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,273][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0753, 0.0349, 0.1207, 0.0418, 0.2169, 0.1712, 0.1723, 0.0616, 0.1053],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,275][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0390, 0.0216, 0.3929, 0.0198, 0.2028, 0.1165, 0.0967, 0.0347, 0.0760],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,276][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2122, 0.1099, 0.0318, 0.1079, 0.0967, 0.0162, 0.3453, 0.0488, 0.0080,
        0.0232], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,277][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0034, 0.0144, 0.2434, 0.0126, 0.0897, 0.2213, 0.1396, 0.0621, 0.1136,
        0.0998], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,279][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3654, 0.1688, 0.0965, 0.1384, 0.1015, 0.0315, 0.0176, 0.0255, 0.0322,
        0.0225], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,280][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1397, 0.0869, 0.3487, 0.0749, 0.2404, 0.0273, 0.0258, 0.0099, 0.0160,
        0.0303], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,282][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0190, 0.0110, 0.0466, 0.0187, 0.1710, 0.2117, 0.1484, 0.0620, 0.0851,
        0.2266], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,283][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3127, 0.0844, 0.1242, 0.1075, 0.2380, 0.0523, 0.0171, 0.0145, 0.0120,
        0.0372], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,284][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1272, 0.1059, 0.2600, 0.0963, 0.1959, 0.0610, 0.0449, 0.0239, 0.0380,
        0.0470], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,286][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0773, 0.0295, 0.0564, 0.0508, 0.2356, 0.1354, 0.1069, 0.0274, 0.0519,
        0.2289], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,287][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3417, 0.1145, 0.2158, 0.0965, 0.1658, 0.0116, 0.0082, 0.0130, 0.0153,
        0.0176], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,289][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1287, 0.0695, 0.2421, 0.0688, 0.1725, 0.0769, 0.0531, 0.0428, 0.0642,
        0.0815], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,290][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0449, 0.0245, 0.1004, 0.0302, 0.1652, 0.1493, 0.1371, 0.0621, 0.0995,
        0.1868], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,292][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0336, 0.0228, 0.2666, 0.0220, 0.1709, 0.1141, 0.1024, 0.0530, 0.1108,
        0.1039], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,293][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2009, 0.0937, 0.0241, 0.0936, 0.0939, 0.0140, 0.3990, 0.0420, 0.0061,
        0.0198, 0.0129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,295][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0043, 0.0164, 0.3210, 0.0143, 0.1074, 0.2058, 0.0869, 0.0442, 0.0801,
        0.0682, 0.0513], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,296][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4494, 0.1557, 0.0829, 0.1254, 0.0982, 0.0218, 0.0120, 0.0170, 0.0195,
        0.0137, 0.0043], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,298][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1398, 0.0669, 0.3412, 0.0614, 0.3045, 0.0176, 0.0206, 0.0057, 0.0093,
        0.0265, 0.0066], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,299][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0094, 0.0040, 0.0281, 0.0085, 0.2121, 0.1725, 0.0873, 0.0239, 0.0400,
        0.1977, 0.2164], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,300][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2975, 0.0534, 0.0971, 0.0824, 0.3321, 0.0597, 0.0138, 0.0085, 0.0077,
        0.0438, 0.0041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,302][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1706, 0.1096, 0.2748, 0.0979, 0.2032, 0.0324, 0.0263, 0.0127, 0.0182,
        0.0315, 0.0227], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,304][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0411, 0.0119, 0.0293, 0.0274, 0.2631, 0.1129, 0.0709, 0.0087, 0.0262,
        0.2394, 0.1690], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,305][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3354, 0.0888, 0.2154, 0.0790, 0.2248, 0.0090, 0.0072, 0.0093, 0.0133,
        0.0158, 0.0019], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,306][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1361, 0.0589, 0.2449, 0.0591, 0.1999, 0.0678, 0.0434, 0.0304, 0.0605,
        0.0732, 0.0258], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,308][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0315, 0.0134, 0.0736, 0.0179, 0.1605, 0.1315, 0.1219, 0.0375, 0.0761,
        0.1757, 0.1605], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,309][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0299, 0.0143, 0.3004, 0.0147, 0.2440, 0.1022, 0.0753, 0.0303, 0.0766,
        0.0899, 0.0224], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,311][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2025, 0.1157, 0.0239, 0.1127, 0.0714, 0.0179, 0.3052, 0.0595, 0.0140,
        0.0235, 0.0166, 0.0371], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,312][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0027, 0.0107, 0.1336, 0.0094, 0.0523, 0.2087, 0.1563, 0.0583, 0.1050,
        0.0965, 0.1315, 0.0350], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,314][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2424, 0.1491, 0.0867, 0.1290, 0.0977, 0.0401, 0.0235, 0.0353, 0.0416,
        0.0329, 0.0197, 0.1021], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,314][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.1231, 0.0933, 0.2325, 0.0825, 0.1841, 0.0444, 0.0512, 0.0216, 0.0323,
        0.0542, 0.0222, 0.0587], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,315][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0037, 0.0032, 0.0146, 0.0049, 0.0365, 0.1490, 0.1479, 0.0559, 0.1044,
        0.1418, 0.3036, 0.0345], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,315][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1073, 0.0518, 0.0819, 0.0635, 0.1419, 0.1323, 0.0831, 0.0574, 0.0677,
        0.1019, 0.0439, 0.0671], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,316][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1191, 0.1010, 0.1487, 0.0909, 0.1150, 0.0738, 0.0684, 0.0396, 0.0656,
        0.0583, 0.0481, 0.0715], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,316][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0103, 0.0075, 0.0167, 0.0119, 0.0509, 0.1164, 0.1439, 0.0387, 0.0847,
        0.1612, 0.3119, 0.0458], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,316][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.2676, 0.1253, 0.1287, 0.1116, 0.1309, 0.0261, 0.0229, 0.0326, 0.0374,
        0.0376, 0.0129, 0.0665], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,318][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1009, 0.0689, 0.1555, 0.0686, 0.1180, 0.0884, 0.0709, 0.0550, 0.0800,
        0.0849, 0.0488, 0.0602], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,319][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0280, 0.0199, 0.0494, 0.0236, 0.0809, 0.1111, 0.1277, 0.0660, 0.1045,
        0.1489, 0.1729, 0.0671], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,320][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0247, 0.0208, 0.0989, 0.0199, 0.0812, 0.1238, 0.1387, 0.0778, 0.1519,
        0.1130, 0.1023, 0.0469], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,322][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.1384, 0.0884, 0.0236, 0.0875, 0.0668, 0.0241, 0.3424, 0.0632, 0.0171,
        0.0300, 0.0249, 0.0349, 0.0588], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,323][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0017, 0.0074, 0.0873, 0.0070, 0.0411, 0.2249, 0.1556, 0.0495, 0.1016,
        0.0951, 0.1695, 0.0335, 0.0258], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,324][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1755, 0.1135, 0.0727, 0.0986, 0.0866, 0.0498, 0.0318, 0.0409, 0.0546,
        0.0383, 0.0263, 0.1032, 0.1083], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,326][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0892, 0.0789, 0.2679, 0.0671, 0.1552, 0.0491, 0.0464, 0.0226, 0.0434,
        0.0471, 0.0205, 0.0462, 0.0662], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,327][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0072, 0.0070, 0.0228, 0.0094, 0.0435, 0.1330, 0.1325, 0.0761, 0.0952,
        0.1433, 0.2350, 0.0609, 0.0341], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,329][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1526, 0.0752, 0.1001, 0.0785, 0.1217, 0.0840, 0.0494, 0.0474, 0.0485,
        0.0693, 0.0232, 0.0702, 0.0798], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,330][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0696, 0.0749, 0.1523, 0.0682, 0.1115, 0.0817, 0.0675, 0.0422, 0.0735,
        0.0598, 0.0505, 0.0643, 0.0837], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,332][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0086, 0.0076, 0.0224, 0.0103, 0.0448, 0.1097, 0.1243, 0.0503, 0.0994,
        0.1669, 0.2576, 0.0580, 0.0400], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,333][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1772, 0.1005, 0.1430, 0.0882, 0.1140, 0.0415, 0.0297, 0.0466, 0.0524,
        0.0456, 0.0166, 0.0696, 0.0750], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,335][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0563, 0.0462, 0.1262, 0.0465, 0.0988, 0.0917, 0.0803, 0.0588, 0.0915,
        0.0975, 0.0723, 0.0569, 0.0770], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,336][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0247, 0.0197, 0.0517, 0.0226, 0.0737, 0.1056, 0.1163, 0.0640, 0.1034,
        0.1350, 0.1512, 0.0586, 0.0736], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,338][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0272, 0.0270, 0.1059, 0.0254, 0.0772, 0.1158, 0.1190, 0.0782, 0.1415,
        0.1076, 0.0865, 0.0492, 0.0395], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,339][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1524, 0.0793, 0.0186, 0.0809, 0.0660, 0.0176, 0.3774, 0.0470, 0.0087,
        0.0235, 0.0177, 0.0260, 0.0433, 0.0416], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,340][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0028, 0.0123, 0.2098, 0.0110, 0.0794, 0.1840, 0.1115, 0.0605, 0.0848,
        0.0771, 0.0717, 0.0287, 0.0247, 0.0419], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,342][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2460, 0.1227, 0.0790, 0.1033, 0.0951, 0.0278, 0.0178, 0.0248, 0.0310,
        0.0227, 0.0104, 0.0836, 0.1008, 0.0350], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,343][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0887, 0.0620, 0.2399, 0.0574, 0.2048, 0.0449, 0.0482, 0.0197, 0.0345,
        0.0484, 0.0197, 0.0378, 0.0583, 0.0356], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,345][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0036, 0.0021, 0.0092, 0.0040, 0.0550, 0.1336, 0.1264, 0.0372, 0.0652,
        0.1505, 0.3003, 0.0318, 0.0234, 0.0577], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,346][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1198, 0.0367, 0.0743, 0.0528, 0.1988, 0.1148, 0.0505, 0.0323, 0.0348,
        0.0904, 0.0289, 0.0610, 0.0730, 0.0318], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,348][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1178, 0.0919, 0.1767, 0.0841, 0.1517, 0.0468, 0.0358, 0.0225, 0.0288,
        0.0430, 0.0299, 0.0518, 0.0738, 0.0453], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,349][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0093, 0.0039, 0.0105, 0.0076, 0.0759, 0.1155, 0.1045, 0.0204, 0.0569,
        0.1800, 0.2773, 0.0424, 0.0412, 0.0545], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,351][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.2215, 0.0786, 0.1546, 0.0756, 0.1741, 0.0268, 0.0207, 0.0276, 0.0322,
        0.0337, 0.0084, 0.0529, 0.0695, 0.0238], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,352][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0635, 0.0371, 0.1280, 0.0396, 0.1229, 0.0980, 0.0692, 0.0492, 0.0967,
        0.0896, 0.0513, 0.0459, 0.0677, 0.0413], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,354][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0116, 0.0068, 0.0330, 0.0092, 0.0689, 0.1170, 0.1199, 0.0503, 0.0917,
        0.1405, 0.1902, 0.0331, 0.0495, 0.0783], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,355][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0117, 0.0089, 0.1199, 0.0093, 0.0990, 0.1280, 0.1270, 0.0523, 0.1327,
        0.1140, 0.0722, 0.0333, 0.0269, 0.0648], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,357][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1639, 0.0736, 0.0154, 0.0744, 0.0668, 0.0122, 0.4197, 0.0415, 0.0048,
        0.0158, 0.0101, 0.0196, 0.0382, 0.0276, 0.0164], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,358][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0035, 0.0129, 0.3439, 0.0104, 0.0942, 0.1416, 0.0685, 0.0351, 0.0664,
        0.0548, 0.0399, 0.0315, 0.0250, 0.0421, 0.0302], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,360][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3821, 0.1335, 0.0652, 0.1062, 0.0770, 0.0158, 0.0078, 0.0124, 0.0157,
        0.0112, 0.0036, 0.0691, 0.0747, 0.0191, 0.0065], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,361][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1314, 0.0638, 0.3000, 0.0585, 0.2649, 0.0187, 0.0210, 0.0059, 0.0106,
        0.0249, 0.0060, 0.0266, 0.0485, 0.0133, 0.0059], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,361][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0017, 0.0008, 0.0090, 0.0020, 0.0785, 0.1501, 0.1006, 0.0211, 0.0410,
        0.1495, 0.2989, 0.0215, 0.0196, 0.0376, 0.0681], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,361][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1730, 0.0335, 0.0669, 0.0575, 0.3079, 0.1031, 0.0301, 0.0143, 0.0143,
        0.0597, 0.0112, 0.0405, 0.0649, 0.0169, 0.0061], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,362][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1733, 0.1027, 0.2100, 0.0874, 0.1593, 0.0294, 0.0223, 0.0111, 0.0169,
        0.0257, 0.0160, 0.0403, 0.0642, 0.0318, 0.0095], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,362][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0062, 0.0020, 0.0064, 0.0053, 0.0870, 0.1021, 0.0875, 0.0087, 0.0320,
        0.1777, 0.2787, 0.0271, 0.0338, 0.0334, 0.1121], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,363][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2921, 0.0769, 0.1690, 0.0721, 0.2187, 0.0101, 0.0077, 0.0108, 0.0151,
        0.0168, 0.0025, 0.0359, 0.0592, 0.0106, 0.0026], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,363][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1211, 0.0531, 0.1902, 0.0542, 0.1657, 0.0564, 0.0385, 0.0271, 0.0568,
        0.0626, 0.0218, 0.0444, 0.0695, 0.0227, 0.0158], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,364][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0191, 0.0085, 0.0430, 0.0118, 0.1074, 0.1028, 0.1019, 0.0316, 0.0629,
        0.1375, 0.1370, 0.0368, 0.0601, 0.0576, 0.0820], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,365][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0186, 0.0097, 0.1858, 0.0104, 0.1673, 0.1155, 0.0950, 0.0342, 0.0930,
        0.1008, 0.0367, 0.0337, 0.0254, 0.0437, 0.0302], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,367][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:07,368][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15581],
        [11334],
        [ 1287],
        [ 7843],
        [  264],
        [  874],
        [  737],
        [  209],
        [  111],
        [  165],
        [  676],
        [  352],
        [  143],
        [  586],
        [  276]], device='cuda:0')
[2024-07-24 10:24:07,370][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16303],
        [21867],
        [ 9372],
        [24599],
        [ 4404],
        [ 9222],
        [ 8658],
        [ 3474],
        [ 1802],
        [ 2198],
        [ 5567],
        [ 3407],
        [ 1961],
        [ 7572],
        [ 4670]], device='cuda:0')
[2024-07-24 10:24:07,371][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5590],
        [ 8612],
        [15665],
        [17238],
        [17377],
        [20445],
        [21719],
        [23462],
        [24599],
        [24413],
        [25199],
        [25577],
        [25458],
        [25546],
        [25643]], device='cuda:0')
[2024-07-24 10:24:07,372][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17332],
        [16196],
        [48460],
        [48778],
        [40332],
        [24462],
        [21721],
        [20132],
        [19258],
        [16523],
        [16883],
        [16920],
        [17014],
        [17098],
        [16260]], device='cuda:0')
[2024-07-24 10:24:07,374][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[9362],
        [4978],
        [2544],
        [2308],
        [1844],
        [1408],
        [1361],
        [1436],
        [1513],
        [1640],
        [1695],
        [1929],
        [2199],
        [2371],
        [2553]], device='cuda:0')
[2024-07-24 10:24:07,375][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[39112],
        [38711],
        [35559],
        [35271],
        [35779],
        [34827],
        [34387],
        [33806],
        [34177],
        [33565],
        [32725],
        [32527],
        [32987],
        [32720],
        [32620]], device='cuda:0')
[2024-07-24 10:24:07,377][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[35697],
        [32817],
        [34599],
        [22589],
        [32778],
        [28672],
        [25998],
        [27354],
        [23652],
        [28482],
        [22005],
        [26445],
        [23019],
        [25528],
        [21045]], device='cuda:0')
[2024-07-24 10:24:07,378][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[3288],
        [3275],
        [2393],
        [2632],
        [2255],
        [2714],
        [2704],
        [2906],
        [3136],
        [3240],
        [2833],
        [3236],
        [3351],
        [3395],
        [3241]], device='cuda:0')
[2024-07-24 10:24:07,379][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12611],
        [ 6592],
        [ 2997],
        [ 3561],
        [ 2068],
        [ 2221],
        [ 2270],
        [ 2469],
        [ 3734],
        [ 3480],
        [ 3422],
        [ 3539],
        [ 2987],
        [ 2720],
        [ 2569]], device='cuda:0')
[2024-07-24 10:24:07,381][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23636],
        [20638],
        [22721],
        [19654],
        [21115],
        [22479],
        [22038],
        [22217],
        [21921],
        [21783],
        [22640],
        [22786],
        [22816],
        [22670],
        [22618]], device='cuda:0')
[2024-07-24 10:24:07,382][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[42030],
        [38240],
        [ 8266],
        [ 4784],
        [ 6733],
        [18700],
        [10454],
        [11447],
        [12456],
        [18389],
        [17636],
        [17045],
        [14116],
        [14329],
        [15050]], device='cuda:0')
[2024-07-24 10:24:07,384][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 8728],
        [ 8868],
        [ 9057],
        [ 8825],
        [ 7621],
        [ 8221],
        [ 7793],
        [ 8907],
        [ 9006],
        [ 9288],
        [ 9556],
        [10606],
        [10575],
        [10003],
        [10262]], device='cuda:0')
[2024-07-24 10:24:07,385][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15480],
        [ 8775],
        [  810],
        [ 1091],
        [ 3276],
        [ 6802],
        [11682],
        [11484],
        [11611],
        [12370],
        [15223],
        [15498],
        [14460],
        [17441],
        [16995]], device='cuda:0')
[2024-07-24 10:24:07,386][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30823],
        [33637],
        [  255],
        [   14],
        [  581],
        [27516],
        [22939],
        [27319],
        [30915],
        [32470],
        [31306],
        [29025],
        [29450],
        [33785],
        [32098]], device='cuda:0')
[2024-07-24 10:24:07,388][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16490],
        [10490],
        [ 1732],
        [ 1706],
        [ 1721],
        [ 1490],
        [ 1154],
        [  937],
        [ 1248],
        [  985],
        [ 1236],
        [  842],
        [  636],
        [  625],
        [  407]], device='cuda:0')
[2024-07-24 10:24:07,389][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[39188],
        [28423],
        [26752],
        [19043],
        [16145],
        [14414],
        [10997],
        [10047],
        [10535],
        [ 9490],
        [ 9804],
        [ 9240],
        [ 8651],
        [ 9024],
        [ 9512]], device='cuda:0')
[2024-07-24 10:24:07,391][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15569],
        [19201],
        [20438],
        [20809],
        [19885],
        [23192],
        [23717],
        [22376],
        [21719],
        [20378],
        [20772],
        [16828],
        [15420],
        [19008],
        [20702]], device='cuda:0')
[2024-07-24 10:24:07,392][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38316],
        [40641],
        [34256],
        [31313],
        [36795],
        [37169],
        [36667],
        [36848],
        [39296],
        [39473],
        [39192],
        [40468],
        [41423],
        [40141],
        [39189]], device='cuda:0')
[2024-07-24 10:24:07,394][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[19882],
        [21787],
        [38642],
        [38610],
        [34947],
        [32475],
        [31228],
        [30921],
        [33884],
        [30764],
        [29238],
        [30818],
        [31393],
        [30057],
        [30314]], device='cuda:0')
[2024-07-24 10:24:07,395][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23850],
        [31659],
        [29240],
        [28640],
        [33496],
        [36965],
        [39874],
        [37953],
        [38201],
        [36647],
        [36806],
        [36205],
        [36193],
        [36527],
        [37041]], device='cuda:0')
[2024-07-24 10:24:07,396][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[45783],
        [44040],
        [41837],
        [36069],
        [37708],
        [34319],
        [31862],
        [28508],
        [31046],
        [31081],
        [30280],
        [25697],
        [27115],
        [26277],
        [27581]], device='cuda:0')
[2024-07-24 10:24:07,398][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21850],
        [20559],
        [10796],
        [11147],
        [10073],
        [ 9881],
        [10649],
        [10276],
        [10823],
        [ 9794],
        [10031],
        [11006],
        [11617],
        [11710],
        [11405]], device='cuda:0')
[2024-07-24 10:24:07,399][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13589],
        [17302],
        [14841],
        [14378],
        [12606],
        [10408],
        [11022],
        [12646],
        [12275],
        [11638],
        [11927],
        [13761],
        [13793],
        [13256],
        [12554]], device='cuda:0')
[2024-07-24 10:24:07,401][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11016],
        [ 8742],
        [ 4250],
        [ 5130],
        [ 5959],
        [ 6755],
        [ 7425],
        [ 8709],
        [ 6442],
        [ 8297],
        [ 8649],
        [13062],
        [14412],
        [12771],
        [10118]], device='cuda:0')
[2024-07-24 10:24:07,402][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[40532],
        [39414],
        [28052],
        [27110],
        [27457],
        [25034],
        [23907],
        [22428],
        [24950],
        [22019],
        [22137],
        [19492],
        [18575],
        [19338],
        [22493]], device='cuda:0')
[2024-07-24 10:24:07,403][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15533],
        [16197],
        [33686],
        [34380],
        [39299],
        [33857],
        [28654],
        [26313],
        [32420],
        [34257],
        [34170],
        [32695],
        [34516],
        [32955],
        [33995]], device='cuda:0')
[2024-07-24 10:24:07,405][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7228],
        [ 7660],
        [16901],
        [16207],
        [25845],
        [32850],
        [29122],
        [23896],
        [26522],
        [21416],
        [25385],
        [17573],
        [16101],
        [18340],
        [19738]], device='cuda:0')
[2024-07-24 10:24:07,406][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[16222],
        [14118],
        [15048],
        [20128],
        [16133],
        [18913],
        [20732],
        [24061],
        [19105],
        [23177],
        [21923],
        [26224],
        [24616],
        [23693],
        [21955]], device='cuda:0')
[2024-07-24 10:24:07,408][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[29362],
        [28852],
        [44830],
        [45887],
        [44508],
        [43929],
        [46913],
        [47298],
        [46276],
        [46243],
        [46043],
        [46332],
        [47324],
        [47764],
        [47950]], device='cuda:0')
[2024-07-24 10:24:07,409][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209],
        [15209]], device='cuda:0')
[2024-07-24 10:24:07,463][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:07,464][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,465][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,465][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,466][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,466][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,466][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,466][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,467][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,467][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,467][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,468][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,468][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,468][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4069, 0.5931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,469][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2390, 0.7610], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,469][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4542, 0.5458], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,469][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4552, 0.5448], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,470][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3978, 0.6022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,470][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5040, 0.4960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,470][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1128, 0.8872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,471][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4056, 0.5944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,471][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3792, 0.6208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,471][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4828, 0.5172], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,472][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3957, 0.6043], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,472][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3470, 0.6530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,473][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.3936, 0.2032, 0.4032], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,475][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.1039, 0.1952, 0.7009], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,476][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.6161, 0.2772, 0.1067], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,476][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.1443, 0.6040, 0.2517], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,476][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.1250, 0.1799, 0.6951], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,477][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.5227, 0.2803, 0.1971], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,477][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.0207, 0.1804, 0.7989], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,477][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.4816, 0.3689, 0.1495], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,478][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.3900, 0.3317, 0.2783], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,478][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.0604, 0.0587, 0.8809], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,478][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.4519, 0.4043, 0.1437], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,479][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.1693, 0.2637, 0.5670], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,480][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1630, 0.2246, 0.3705, 0.2419], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,481][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0497, 0.1568, 0.6202, 0.1733], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,482][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2415, 0.2781, 0.2156, 0.2648], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,483][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2016, 0.3119, 0.2909, 0.1956], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,485][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0413, 0.0632, 0.8298, 0.0658], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,486][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2620, 0.2520, 0.2207, 0.2652], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,487][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0087, 0.0625, 0.8464, 0.0824], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,489][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1949, 0.2625, 0.2688, 0.2738], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,490][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1481, 0.2348, 0.3812, 0.2360], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,492][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0394, 0.0385, 0.8644, 0.0577], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,493][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1699, 0.2414, 0.2393, 0.3495], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,494][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1026, 0.1903, 0.4937, 0.2135], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,496][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.2933, 0.1305, 0.3457, 0.1071, 0.1234], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,497][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0527, 0.0904, 0.4995, 0.0783, 0.2791], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,498][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.3241, 0.1762, 0.1465, 0.1200, 0.2331], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,499][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0886, 0.4122, 0.3306, 0.0636, 0.1051], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,501][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.1065, 0.1432, 0.3031, 0.1034, 0.3439], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,502][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.3651, 0.1921, 0.2026, 0.1668, 0.0734], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,504][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0057, 0.0349, 0.5665, 0.0412, 0.3516], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,505][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.2710, 0.1756, 0.2905, 0.1368, 0.1262], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,506][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.2026, 0.1714, 0.2910, 0.1396, 0.1953], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,508][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0443, 0.0426, 0.6465, 0.0533, 0.2132], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,509][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.2447, 0.1659, 0.1897, 0.1939, 0.2059], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,510][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0215, 0.0402, 0.3823, 0.0405, 0.5155], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,512][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3153, 0.0842, 0.3769, 0.0750, 0.1382, 0.0103], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,513][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0276, 0.0403, 0.5868, 0.0338, 0.2990, 0.0125], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,515][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2637, 0.0927, 0.2295, 0.0605, 0.2716, 0.0820], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,516][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0543, 0.2227, 0.2246, 0.0539, 0.1374, 0.3071], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,518][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0402, 0.0559, 0.2999, 0.0475, 0.3285, 0.2279], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,519][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.4141, 0.1524, 0.1764, 0.1456, 0.0805, 0.0309], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,520][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0028, 0.0138, 0.1933, 0.0180, 0.4004, 0.3718], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,522][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0959, 0.0374, 0.3524, 0.0411, 0.4465, 0.0267], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,523][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2090, 0.1037, 0.3113, 0.0850, 0.2582, 0.0328], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,524][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0176, 0.0209, 0.3859, 0.0302, 0.1664, 0.3790], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,524][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0252, 0.0086, 0.0314, 0.0225, 0.8372, 0.0751], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,525][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0882, 0.1010, 0.1760, 0.0902, 0.2674, 0.2772], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,525][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2809, 0.0715, 0.3552, 0.0706, 0.2048, 0.0113, 0.0058],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,525][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0281, 0.0399, 0.5477, 0.0351, 0.3130, 0.0212, 0.0150],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,526][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.5112, 0.1266, 0.1233, 0.0707, 0.1450, 0.0223, 0.0009],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,526][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0425, 0.1788, 0.2071, 0.0407, 0.1134, 0.2139, 0.2036],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,527][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0432, 0.0559, 0.2185, 0.0493, 0.2753, 0.1795, 0.1784],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,529][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4064, 0.1408, 0.1918, 0.1378, 0.0888, 0.0256, 0.0087],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,530][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0015, 0.0081, 0.1485, 0.0116, 0.3224, 0.4055, 0.1023],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,531][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0500, 0.0179, 0.3105, 0.0218, 0.5292, 0.0400, 0.0305],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,533][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1597, 0.0808, 0.3278, 0.0700, 0.3099, 0.0390, 0.0129],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,534][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0137, 0.0168, 0.1783, 0.0188, 0.0743, 0.1716, 0.5264],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,535][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0050, 0.0020, 0.0142, 0.0067, 0.7586, 0.1564, 0.0570],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,537][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0361, 0.0518, 0.3459, 0.0398, 0.3961, 0.0935, 0.0367],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,538][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1999, 0.0646, 0.3837, 0.0632, 0.2394, 0.0253, 0.0137, 0.0102],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,539][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0321, 0.0469, 0.5066, 0.0427, 0.3005, 0.0351, 0.0237, 0.0123],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,541][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3216, 0.1275, 0.1859, 0.0718, 0.1857, 0.0851, 0.0026, 0.0199],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,542][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0278, 0.1867, 0.2226, 0.0283, 0.1040, 0.2077, 0.1985, 0.0245],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,544][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0383, 0.0518, 0.1916, 0.0451, 0.2270, 0.1664, 0.1621, 0.1177],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,545][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3205, 0.1305, 0.2083, 0.1301, 0.1107, 0.0515, 0.0186, 0.0298],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,546][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0036, 0.0162, 0.1359, 0.0243, 0.2246, 0.3135, 0.2059, 0.0761],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,548][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0427, 0.0192, 0.2528, 0.0233, 0.4738, 0.0729, 0.0704, 0.0450],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,549][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1157, 0.0694, 0.3440, 0.0582, 0.2966, 0.0666, 0.0255, 0.0242],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,551][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0091, 0.0100, 0.1293, 0.0110, 0.0550, 0.1108, 0.4173, 0.2575],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,552][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0014, 0.0006, 0.0048, 0.0021, 0.3512, 0.3671, 0.2603, 0.0123],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,554][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0233, 0.0370, 0.1319, 0.0325, 0.2753, 0.2086, 0.1449, 0.1464],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,555][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3625, 0.0821, 0.3453, 0.0689, 0.1282, 0.0049, 0.0021, 0.0021, 0.0038],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,557][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0681, 0.0772, 0.5979, 0.0570, 0.1798, 0.0077, 0.0043, 0.0029, 0.0051],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,558][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0944, 0.0614, 0.4346, 0.0397, 0.1602, 0.0664, 0.0091, 0.0197, 0.1145],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,560][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0309, 0.1994, 0.2337, 0.0293, 0.0920, 0.1608, 0.1521, 0.0226, 0.0792],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,561][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0264, 0.0384, 0.1747, 0.0333, 0.1879, 0.1493, 0.1510, 0.1095, 0.1296],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,562][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.3708, 0.1353, 0.2121, 0.1231, 0.1014, 0.0249, 0.0085, 0.0143, 0.0096],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,564][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0016, 0.0083, 0.2393, 0.0107, 0.2378, 0.2371, 0.2070, 0.0260, 0.0323],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,565][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0662, 0.0237, 0.2884, 0.0253, 0.4905, 0.0258, 0.0244, 0.0193, 0.0365],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,567][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2051, 0.0989, 0.3557, 0.0740, 0.2275, 0.0174, 0.0056, 0.0068, 0.0091],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,568][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0040, 0.0054, 0.0876, 0.0064, 0.0394, 0.0792, 0.3027, 0.1839, 0.2913],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,570][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0070, 0.0029, 0.0261, 0.0073, 0.5923, 0.2028, 0.1000, 0.0072, 0.0544],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,570][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0500, 0.0715, 0.2071, 0.0547, 0.2113, 0.1191, 0.1225, 0.0792, 0.0846],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,571][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2096, 0.0706, 0.3806, 0.0676, 0.2158, 0.0149, 0.0060, 0.0064, 0.0147,
        0.0139], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,571][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0426, 0.0582, 0.4977, 0.0499, 0.2664, 0.0199, 0.0146, 0.0101, 0.0142,
        0.0263], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,571][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4012, 0.1337, 0.2413, 0.0771, 0.0874, 0.0175, 0.0029, 0.0107, 0.0208,
        0.0075], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,572][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0255, 0.1427, 0.1902, 0.0263, 0.1044, 0.1758, 0.1730, 0.0278, 0.0987,
        0.0356], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,572][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0324, 0.0428, 0.1492, 0.0363, 0.1975, 0.1193, 0.1126, 0.0882, 0.1064,
        0.1153], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,573][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3477, 0.1404, 0.1999, 0.1357, 0.0969, 0.0294, 0.0106, 0.0152, 0.0105,
        0.0138], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,573][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0003, 0.0021, 0.2024, 0.0029, 0.2738, 0.1455, 0.0848, 0.0451, 0.2262,
        0.0169], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,574][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0366, 0.0164, 0.2937, 0.0191, 0.4414, 0.0414, 0.0278, 0.0221, 0.0478,
        0.0536], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,576][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1383, 0.0796, 0.3467, 0.0664, 0.2635, 0.0292, 0.0098, 0.0145, 0.0262,
        0.0259], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,577][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0069, 0.0083, 0.0790, 0.0090, 0.0302, 0.0756, 0.2281, 0.1459, 0.1980,
        0.2191], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,579][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0080, 0.0034, 0.0427, 0.0083, 0.7576, 0.0620, 0.0231, 0.0023, 0.0164,
        0.0762], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,580][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0554, 0.0406, 0.0927, 0.0439, 0.1238, 0.1386, 0.0952, 0.2372, 0.1682,
        0.0044], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,581][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2526, 0.0657, 0.3608, 0.0635, 0.2137, 0.0117, 0.0041, 0.0045, 0.0112,
        0.0108, 0.0014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,582][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0562, 0.0610, 0.5239, 0.0504, 0.2627, 0.0105, 0.0069, 0.0048, 0.0068,
        0.0128, 0.0041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,584][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4688, 0.1502, 0.1609, 0.0820, 0.0936, 0.0101, 0.0013, 0.0076, 0.0204,
        0.0046, 0.0006], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,585][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0150, 0.0706, 0.1291, 0.0190, 0.0883, 0.1266, 0.1370, 0.0328, 0.0969,
        0.0404, 0.2442], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,587][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0309, 0.0400, 0.1181, 0.0354, 0.1737, 0.1028, 0.1029, 0.0864, 0.0985,
        0.1075, 0.1038], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,588][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3394, 0.1205, 0.2134, 0.1237, 0.1147, 0.0318, 0.0114, 0.0165, 0.0107,
        0.0137, 0.0042], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,590][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0008, 0.0034, 0.1743, 0.0045, 0.2451, 0.1464, 0.0507, 0.0236, 0.3078,
        0.0145, 0.0291], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,591][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0150, 0.0048, 0.1930, 0.0064, 0.5103, 0.0446, 0.0404, 0.0217, 0.0687,
        0.0754, 0.0197], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,593][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0911, 0.0477, 0.4274, 0.0400, 0.2875, 0.0291, 0.0093, 0.0131, 0.0232,
        0.0251, 0.0063], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,594][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0134, 0.0129, 0.0673, 0.0131, 0.0266, 0.0659, 0.1659, 0.1012, 0.1295,
        0.1580, 0.2462], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,596][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0030, 0.0010, 0.0145, 0.0033, 0.7193, 0.0653, 0.0223, 0.0011, 0.0139,
        0.0945, 0.0618], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,597][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0979, 0.0983, 0.1493, 0.0879, 0.1432, 0.0865, 0.1227, 0.0780, 0.0595,
        0.0204, 0.0562], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,598][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2133, 0.1039, 0.2686, 0.0980, 0.1736, 0.0197, 0.0120, 0.0146, 0.0252,
        0.0258, 0.0071, 0.0382], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,600][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0406, 0.0637, 0.3904, 0.0553, 0.2085, 0.0412, 0.0308, 0.0204, 0.0313,
        0.0418, 0.0222, 0.0539], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,601][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2317, 0.1357, 0.1659, 0.0995, 0.1591, 0.0309, 0.0054, 0.0121, 0.0642,
        0.0263, 0.0156, 0.0537], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,603][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0101, 0.0819, 0.1309, 0.0116, 0.0706, 0.1283, 0.1395, 0.0180, 0.0711,
        0.0249, 0.2853, 0.0277], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,604][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0432, 0.0524, 0.1290, 0.0433, 0.1552, 0.0849, 0.0805, 0.0656, 0.0791,
        0.0848, 0.0879, 0.0941], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,606][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2966, 0.1479, 0.1253, 0.1435, 0.0793, 0.0358, 0.0180, 0.0230, 0.0156,
        0.0194, 0.0075, 0.0882], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,607][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0011, 0.0071, 0.0624, 0.0082, 0.0758, 0.1669, 0.1452, 0.0342, 0.1389,
        0.1253, 0.1831, 0.0519], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,609][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0696, 0.0408, 0.2092, 0.0439, 0.2729, 0.0585, 0.0404, 0.0350, 0.0689,
        0.0672, 0.0241, 0.0693], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,610][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1635, 0.1142, 0.2271, 0.0959, 0.1743, 0.0401, 0.0228, 0.0204, 0.0287,
        0.0381, 0.0171, 0.0577], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,612][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0041, 0.0040, 0.0416, 0.0042, 0.0163, 0.0408, 0.1375, 0.0818, 0.1268,
        0.1294, 0.2830, 0.1303], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,613][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0010, 0.0008, 0.0148, 0.0016, 0.1678, 0.1970, 0.1361, 0.0141, 0.0858,
        0.1502, 0.2023, 0.0285], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,614][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0146, 0.0259, 0.2454, 0.0194, 0.2282, 0.0942, 0.0737, 0.0594, 0.0803,
        0.0759, 0.0445, 0.0386], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,616][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1062, 0.0617, 0.2764, 0.0594, 0.1794, 0.0452, 0.0289, 0.0215, 0.0488,
        0.0456, 0.0168, 0.0459, 0.0642], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,617][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0236, 0.0435, 0.2720, 0.0392, 0.1740, 0.0699, 0.0551, 0.0285, 0.0457,
        0.0676, 0.0494, 0.0560, 0.0755], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,618][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.1002, 0.0617, 0.1463, 0.0503, 0.2475, 0.0440, 0.0045, 0.0231, 0.1447,
        0.0201, 0.0134, 0.0394, 0.1046], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,618][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0075, 0.0852, 0.1768, 0.0078, 0.0687, 0.1236, 0.1233, 0.0131, 0.0633,
        0.0200, 0.2771, 0.0256, 0.0078], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,619][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0231, 0.0309, 0.1320, 0.0260, 0.1608, 0.0828, 0.0766, 0.0575, 0.0715,
        0.0774, 0.0791, 0.0723, 0.1099], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,619][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.2107, 0.1172, 0.1576, 0.1137, 0.0843, 0.0550, 0.0237, 0.0305, 0.0221,
        0.0257, 0.0117, 0.0905, 0.0572], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,619][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0006, 0.0038, 0.0629, 0.0045, 0.0471, 0.2538, 0.1843, 0.0826, 0.0946,
        0.0541, 0.1324, 0.0510, 0.0283], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,620][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0763, 0.0508, 0.2185, 0.0498, 0.2243, 0.0448, 0.0294, 0.0341, 0.0499,
        0.0502, 0.0170, 0.0672, 0.0877], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,621][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0894, 0.0800, 0.1936, 0.0711, 0.1666, 0.0629, 0.0367, 0.0312, 0.0500,
        0.0589, 0.0344, 0.0583, 0.0670], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,623][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0021, 0.0022, 0.0359, 0.0027, 0.0139, 0.0344, 0.1314, 0.0808, 0.1260,
        0.1186, 0.3170, 0.1167, 0.0182], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,624][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0094, 0.0082, 0.0581, 0.0121, 0.2017, 0.1057, 0.0854, 0.0206, 0.0763,
        0.1594, 0.1121, 0.0805, 0.0704], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,626][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0031, 0.0068, 0.0885, 0.0069, 0.1126, 0.1337, 0.1188, 0.0897, 0.0662,
        0.0885, 0.1340, 0.0186, 0.1325], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,626][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1470, 0.0565, 0.3023, 0.0569, 0.2234, 0.0316, 0.0140, 0.0123, 0.0318,
        0.0255, 0.0061, 0.0335, 0.0445, 0.0146], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,628][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0228, 0.0403, 0.4402, 0.0352, 0.2561, 0.0253, 0.0179, 0.0122, 0.0176,
        0.0277, 0.0110, 0.0314, 0.0518, 0.0105], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,629][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2974, 0.0934, 0.1860, 0.0654, 0.1211, 0.0280, 0.0016, 0.0118, 0.0379,
        0.0081, 0.0030, 0.0787, 0.0324, 0.0351], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,631][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0117, 0.0806, 0.1249, 0.0129, 0.0757, 0.1352, 0.1387, 0.0155, 0.0664,
        0.0217, 0.2647, 0.0220, 0.0136, 0.0165], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,632][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0146, 0.0202, 0.1088, 0.0177, 0.1338, 0.0786, 0.0802, 0.0639, 0.0758,
        0.0833, 0.0861, 0.0759, 0.0974, 0.0636], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,634][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.2226, 0.1012, 0.1684, 0.1063, 0.0998, 0.0548, 0.0213, 0.0280, 0.0198,
        0.0214, 0.0090, 0.0708, 0.0491, 0.0275], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,635][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0007, 0.0037, 0.0626, 0.0052, 0.1353, 0.1695, 0.1191, 0.0636, 0.1153,
        0.0375, 0.0943, 0.0596, 0.0461, 0.0877], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,637][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0152, 0.0073, 0.1276, 0.0096, 0.2889, 0.0742, 0.0624, 0.0363, 0.0947,
        0.0915, 0.0432, 0.0566, 0.0576, 0.0351], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,638][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0813, 0.0537, 0.2687, 0.0471, 0.2261, 0.0581, 0.0242, 0.0207, 0.0400,
        0.0421, 0.0157, 0.0435, 0.0582, 0.0207], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,640][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0009, 0.0013, 0.0326, 0.0017, 0.0144, 0.0315, 0.1246, 0.0753, 0.1228,
        0.1256, 0.2945, 0.1303, 0.0212, 0.0234], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,641][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0007, 0.0003, 0.0060, 0.0009, 0.2840, 0.1438, 0.0677, 0.0047, 0.0374,
        0.1846, 0.1918, 0.0293, 0.0303, 0.0185], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,643][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0028, 0.0057, 0.1096, 0.0052, 0.1167, 0.0922, 0.0715, 0.0658, 0.0472,
        0.0859, 0.0972, 0.0197, 0.1960, 0.0847], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,644][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2477, 0.0630, 0.3323, 0.0613, 0.2103, 0.0088, 0.0036, 0.0036, 0.0089,
        0.0092, 0.0012, 0.0171, 0.0274, 0.0049, 0.0009], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,645][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0362, 0.0452, 0.5187, 0.0375, 0.2459, 0.0092, 0.0074, 0.0042, 0.0071,
        0.0118, 0.0037, 0.0256, 0.0412, 0.0041, 0.0023], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,647][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3287, 0.0928, 0.3431, 0.0536, 0.0851, 0.0057, 0.0007, 0.0047, 0.0159,
        0.0027, 0.0006, 0.0331, 0.0211, 0.0112, 0.0010], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,648][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0105, 0.0545, 0.0919, 0.0126, 0.0647, 0.0948, 0.1038, 0.0181, 0.0665,
        0.0257, 0.1911, 0.0275, 0.0199, 0.0207, 0.1978], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,650][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0185, 0.0253, 0.0900, 0.0218, 0.1216, 0.0723, 0.0724, 0.0575, 0.0684,
        0.0757, 0.0776, 0.0745, 0.0966, 0.0607, 0.0669], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,651][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3574, 0.1215, 0.1596, 0.1229, 0.0789, 0.0205, 0.0073, 0.0113, 0.0073,
        0.0087, 0.0024, 0.0545, 0.0321, 0.0116, 0.0039], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,653][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0005, 0.0022, 0.0780, 0.0029, 0.2232, 0.1465, 0.0396, 0.0155, 0.1670,
        0.0182, 0.0404, 0.0507, 0.0536, 0.0833, 0.0785], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,654][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0089, 0.0030, 0.1409, 0.0042, 0.4333, 0.0565, 0.0413, 0.0196, 0.0793,
        0.0751, 0.0223, 0.0360, 0.0489, 0.0164, 0.0142], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,656][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1160, 0.0555, 0.3809, 0.0456, 0.2387, 0.0241, 0.0077, 0.0091, 0.0167,
        0.0202, 0.0048, 0.0298, 0.0383, 0.0079, 0.0048], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,657][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0060, 0.0062, 0.0453, 0.0058, 0.0180, 0.0396, 0.1199, 0.0739, 0.1117,
        0.1196, 0.2204, 0.1098, 0.0230, 0.0273, 0.0735], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,658][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.6654e-04, 6.5770e-05, 3.0097e-03, 2.7830e-04, 3.6304e-01, 1.6853e-01,
        6.3466e-02, 1.7121e-03, 2.0519e-02, 1.3521e-01, 1.8758e-01, 1.4171e-02,
        1.8763e-02, 9.8035e-03, 1.3679e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,660][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0300, 0.0396, 0.1360, 0.0306, 0.1013, 0.0498, 0.0602, 0.0649, 0.0297,
        0.0270, 0.0335, 0.0178, 0.2682, 0.0801, 0.0312], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,715][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:07,715][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,716][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,716][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,716][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,717][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,717][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,717][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,718][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,718][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,718][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,719][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,719][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:07,719][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4069, 0.5931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,719][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2390, 0.7610], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,720][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4266, 0.5734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,721][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5095, 0.4905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,722][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3099, 0.6901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,724][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5040, 0.4960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,725][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1297, 0.8703], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,726][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4056, 0.5944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,728][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3792, 0.6208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,729][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0531, 0.9469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,731][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3996, 0.6004], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,732][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2522, 0.7478], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:07,733][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.3936, 0.2032, 0.4032], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,735][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.1039, 0.1952, 0.7009], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,736][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.3403, 0.1710, 0.4887], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,737][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.7017, 0.2847, 0.0136], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,739][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.1684, 0.2120, 0.6197], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,740][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.5227, 0.2803, 0.1971], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,742][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.0082, 0.0412, 0.9507], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,743][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.4816, 0.3689, 0.1495], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,744][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.3900, 0.3317, 0.2783], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,746][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.0029, 0.0367, 0.9604], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,747][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.4592, 0.3941, 0.1467], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,748][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.0949, 0.2059, 0.6992], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:07,750][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1630, 0.2246, 0.3705, 0.2419], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,751][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0497, 0.1568, 0.6202, 0.1733], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,752][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1683, 0.2185, 0.3984, 0.2147], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,754][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3058, 0.2747, 0.1204, 0.2992], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,755][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0807, 0.1717, 0.5738, 0.1739], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,756][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2620, 0.2520, 0.2207, 0.2652], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,758][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0110, 0.0708, 0.8309, 0.0874], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,759][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1949, 0.2625, 0.2688, 0.2738], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,761][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1481, 0.2348, 0.3812, 0.2360], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,762][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0040, 0.0735, 0.8379, 0.0846], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,763][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1745, 0.2465, 0.2322, 0.3468], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,763][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0587, 0.1676, 0.5980, 0.1756], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:07,764][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2933, 0.1305, 0.3457, 0.1071, 0.1234], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,764][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0527, 0.0904, 0.4995, 0.0783, 0.2791], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,765][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.2076, 0.0999, 0.5094, 0.0723, 0.1108], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,765][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.5590, 0.2043, 0.0490, 0.1594, 0.0283], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,765][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.1594, 0.1719, 0.3083, 0.1428, 0.2177], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,766][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.3651, 0.1921, 0.2026, 0.1668, 0.0734], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,766][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0051, 0.0213, 0.6265, 0.0228, 0.3243], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,766][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2710, 0.1756, 0.2905, 0.1368, 0.1262], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,767][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.2026, 0.1714, 0.2910, 0.1396, 0.1953], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,769][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0017, 0.0223, 0.7019, 0.0200, 0.2542], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,770][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.2359, 0.1673, 0.1605, 0.1962, 0.2400], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,771][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0315, 0.0645, 0.4242, 0.0646, 0.4152], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:07,773][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3153, 0.0842, 0.3769, 0.0750, 0.1382, 0.0103], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,774][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0276, 0.0403, 0.5868, 0.0338, 0.2990, 0.0125], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,775][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1269, 0.0351, 0.6371, 0.0281, 0.1660, 0.0068], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,777][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5107, 0.0833, 0.0472, 0.1264, 0.2291, 0.0033], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,778][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2174, 0.1429, 0.3036, 0.1162, 0.1982, 0.0218], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,779][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4141, 0.1524, 0.1764, 0.1456, 0.0805, 0.0309], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,781][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0021, 0.0069, 0.5725, 0.0077, 0.2148, 0.1959], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,782][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0959, 0.0374, 0.3524, 0.0411, 0.4465, 0.0267], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,784][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2090, 0.1037, 0.3113, 0.0850, 0.2582, 0.0328], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,785][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.3953e-04, 3.4980e-03, 5.2314e-01, 3.1841e-03, 1.2614e-01, 3.4380e-01],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,786][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0731, 0.0252, 0.0439, 0.0573, 0.6750, 0.1255], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,787][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0147, 0.0268, 0.1989, 0.0245, 0.1541, 0.5810], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:07,789][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2809, 0.0715, 0.3552, 0.0706, 0.2048, 0.0113, 0.0058],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,790][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0281, 0.0399, 0.5477, 0.0351, 0.3130, 0.0212, 0.0150],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,792][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0983, 0.0274, 0.6236, 0.0236, 0.2082, 0.0130, 0.0059],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,793][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3167, 0.0536, 0.0579, 0.0971, 0.4586, 0.0138, 0.0023],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,795][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2556, 0.1362, 0.2486, 0.1169, 0.2082, 0.0234, 0.0110],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,796][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4064, 0.1408, 0.1918, 0.1378, 0.0888, 0.0256, 0.0087],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,797][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0019, 0.0055, 0.3924, 0.0064, 0.1949, 0.2441, 0.1549],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,799][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0500, 0.0179, 0.3105, 0.0218, 0.5292, 0.0400, 0.0305],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,800][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1597, 0.0808, 0.3278, 0.0700, 0.3099, 0.0390, 0.0129],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,801][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.4859e-04, 3.4629e-03, 3.3896e-01, 3.2531e-03, 1.2609e-01, 2.9939e-01,
        2.2860e-01], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,803][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0212, 0.0082, 0.0243, 0.0226, 0.5961, 0.2077, 0.1199],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,804][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0108, 0.0213, 0.1472, 0.0191, 0.1278, 0.3877, 0.2861],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:07,806][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1999, 0.0646, 0.3837, 0.0632, 0.2394, 0.0253, 0.0137, 0.0102],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,807][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0321, 0.0469, 0.5066, 0.0427, 0.3005, 0.0351, 0.0237, 0.0123],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,808][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0958, 0.0312, 0.5939, 0.0256, 0.2207, 0.0185, 0.0086, 0.0058],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,810][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.2030, 0.0469, 0.0458, 0.0884, 0.4736, 0.0974, 0.0326, 0.0121],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,810][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.2097, 0.1471, 0.2467, 0.1251, 0.1964, 0.0396, 0.0187, 0.0168],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,811][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.3205, 0.1305, 0.2083, 0.1301, 0.1107, 0.0515, 0.0186, 0.0298],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,811][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0022, 0.0067, 0.3725, 0.0076, 0.1692, 0.2252, 0.1508, 0.0659],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,812][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0427, 0.0192, 0.2528, 0.0233, 0.4738, 0.0729, 0.0704, 0.0450],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,812][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1157, 0.0694, 0.3440, 0.0582, 0.2966, 0.0666, 0.0255, 0.0242],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,812][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0005, 0.0060, 0.3361, 0.0057, 0.1108, 0.2870, 0.2095, 0.0445],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,813][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0056, 0.0027, 0.0094, 0.0073, 0.2538, 0.3404, 0.3409, 0.0398],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,814][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0085, 0.0171, 0.1038, 0.0156, 0.0764, 0.3641, 0.2768, 0.1378],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:07,815][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3625, 0.0821, 0.3453, 0.0689, 0.1282, 0.0049, 0.0021, 0.0021, 0.0038],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,816][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0681, 0.0772, 0.5979, 0.0570, 0.1798, 0.0077, 0.0043, 0.0029, 0.0051],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,818][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1905, 0.0430, 0.6201, 0.0295, 0.1110, 0.0025, 0.0010, 0.0010, 0.0014],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,819][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.3418, 0.0718, 0.0550, 0.1155, 0.3777, 0.0236, 0.0068, 0.0032, 0.0047],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,820][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.3123, 0.1793, 0.1922, 0.1406, 0.1431, 0.0145, 0.0058, 0.0056, 0.0066],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,822][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.3708, 0.1353, 0.2121, 0.1231, 0.1014, 0.0249, 0.0085, 0.0143, 0.0096],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,823][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0045, 0.0121, 0.5764, 0.0119, 0.2023, 0.1011, 0.0494, 0.0181, 0.0243],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,825][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0662, 0.0237, 0.2884, 0.0253, 0.4905, 0.0258, 0.0244, 0.0193, 0.0365],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,826][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2051, 0.0989, 0.3557, 0.0740, 0.2275, 0.0174, 0.0056, 0.0068, 0.0091],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,828][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0008, 0.0087, 0.6987, 0.0070, 0.1355, 0.0881, 0.0390, 0.0075, 0.0146],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,829][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0213, 0.0086, 0.0325, 0.0193, 0.4386, 0.1919, 0.1400, 0.0227, 0.1249],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,831][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0094, 0.0183, 0.1260, 0.0155, 0.0704, 0.3464, 0.2493, 0.0921, 0.0726],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:07,832][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2096, 0.0706, 0.3806, 0.0676, 0.2158, 0.0149, 0.0060, 0.0064, 0.0147,
        0.0139], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,833][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0426, 0.0582, 0.4977, 0.0499, 0.2664, 0.0199, 0.0146, 0.0101, 0.0142,
        0.0263], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,835][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1267, 0.0412, 0.6057, 0.0330, 0.1611, 0.0101, 0.0040, 0.0036, 0.0066,
        0.0080], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,836][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3313, 0.0726, 0.1051, 0.1001, 0.3660, 0.0099, 0.0018, 0.0015, 0.0020,
        0.0098], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,838][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1343, 0.0997, 0.2809, 0.0851, 0.2428, 0.0467, 0.0204, 0.0175, 0.0367,
        0.0359], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,839][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3477, 0.1404, 0.1999, 0.1357, 0.0969, 0.0294, 0.0106, 0.0152, 0.0105,
        0.0138], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,841][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0014, 0.0049, 0.3550, 0.0054, 0.1667, 0.1699, 0.0935, 0.0355, 0.0888,
        0.0788], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,842][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0366, 0.0164, 0.2937, 0.0191, 0.4414, 0.0414, 0.0278, 0.0221, 0.0478,
        0.0536], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,844][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1383, 0.0796, 0.3467, 0.0664, 0.2635, 0.0292, 0.0098, 0.0145, 0.0262,
        0.0259], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,845][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.7008e-04, 2.7614e-03, 3.4719e-01, 2.6696e-03, 1.0108e-01, 2.3560e-01,
        1.7703e-01, 2.1160e-02, 4.3074e-02, 6.9270e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,846][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0247, 0.0113, 0.0489, 0.0238, 0.4859, 0.1012, 0.0598, 0.0148, 0.0674,
        0.1622], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,848][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0061, 0.0127, 0.0861, 0.0118, 0.0646, 0.2819, 0.2240, 0.1038, 0.0758,
        0.1333], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:07,849][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2526, 0.0657, 0.3608, 0.0635, 0.2137, 0.0117, 0.0041, 0.0045, 0.0112,
        0.0108, 0.0014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,850][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0562, 0.0610, 0.5239, 0.0504, 0.2627, 0.0105, 0.0069, 0.0048, 0.0068,
        0.0128, 0.0041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,851][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.0395e-01, 2.8080e-02, 6.7974e-01, 2.1958e-02, 1.5006e-01, 5.0191e-03,
        1.8634e-03, 1.6528e-03, 3.6870e-03, 3.5231e-03, 4.5965e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,852][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.4066e-01, 2.4863e-02, 7.4827e-02, 4.6955e-02, 6.7941e-01, 1.2070e-02,
        1.4944e-03, 6.3943e-04, 1.8584e-03, 1.3754e-02, 3.4690e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,854][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2542, 0.1257, 0.2029, 0.1077, 0.2188, 0.0195, 0.0107, 0.0116, 0.0180,
        0.0219, 0.0090], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,855][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3394, 0.1205, 0.2134, 0.1237, 0.1147, 0.0318, 0.0114, 0.0165, 0.0107,
        0.0137, 0.0042], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,857][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0027, 0.0066, 0.3957, 0.0073, 0.1935, 0.1289, 0.0637, 0.0236, 0.0631,
        0.0613, 0.0537], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,858][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0150, 0.0048, 0.1930, 0.0064, 0.5103, 0.0446, 0.0404, 0.0217, 0.0687,
        0.0754, 0.0197], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,858][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0911, 0.0477, 0.4274, 0.0400, 0.2875, 0.0291, 0.0093, 0.0131, 0.0232,
        0.0251, 0.0063], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,858][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.7593e-04, 3.5196e-03, 4.8225e-01, 3.3886e-03, 1.1275e-01, 1.7126e-01,
        1.0373e-01, 1.2821e-02, 2.5891e-02, 4.3805e-02, 4.0312e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,859][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0099, 0.0033, 0.0200, 0.0093, 0.5164, 0.0886, 0.0416, 0.0055, 0.0450,
        0.1475, 0.1129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,859][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0050, 0.0098, 0.0737, 0.0090, 0.0616, 0.2133, 0.1699, 0.0794, 0.0570,
        0.1051, 0.2163], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:07,860][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2133, 0.1039, 0.2686, 0.0980, 0.1736, 0.0197, 0.0120, 0.0146, 0.0252,
        0.0258, 0.0071, 0.0382], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,860][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0406, 0.0637, 0.3904, 0.0553, 0.2085, 0.0412, 0.0308, 0.0204, 0.0313,
        0.0418, 0.0222, 0.0539], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,860][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2033, 0.0798, 0.3970, 0.0627, 0.1531, 0.0163, 0.0098, 0.0088, 0.0151,
        0.0187, 0.0050, 0.0303], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,861][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2044, 0.0844, 0.0891, 0.1073, 0.2622, 0.0574, 0.0265, 0.0154, 0.0225,
        0.0545, 0.0408, 0.0356], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,863][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.1069, 0.1082, 0.2410, 0.0905, 0.1748, 0.0461, 0.0289, 0.0248, 0.0400,
        0.0467, 0.0270, 0.0651], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,864][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2966, 0.1479, 0.1253, 0.1435, 0.0793, 0.0358, 0.0180, 0.0230, 0.0156,
        0.0194, 0.0075, 0.0882], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,865][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0021, 0.0075, 0.1558, 0.0081, 0.0991, 0.1853, 0.1340, 0.0453, 0.0939,
        0.0954, 0.1442, 0.0293], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,867][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0696, 0.0408, 0.2092, 0.0439, 0.2729, 0.0585, 0.0404, 0.0350, 0.0689,
        0.0672, 0.0241, 0.0693], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,868][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1635, 0.1142, 0.2271, 0.0959, 0.1743, 0.0401, 0.0228, 0.0204, 0.0287,
        0.0381, 0.0171, 0.0577], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,870][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0003, 0.0033, 0.1859, 0.0031, 0.0602, 0.2361, 0.2087, 0.0267, 0.0520,
        0.0755, 0.1291, 0.0192], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,871][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0027, 0.0021, 0.0130, 0.0038, 0.0938, 0.1465, 0.1413, 0.0298, 0.1386,
        0.1431, 0.2507, 0.0345], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,873][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0055, 0.0111, 0.0562, 0.0102, 0.0500, 0.2420, 0.1754, 0.0865, 0.0820,
        0.0931, 0.1626, 0.0254], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:07,874][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.1062, 0.0617, 0.2764, 0.0594, 0.1794, 0.0452, 0.0289, 0.0215, 0.0488,
        0.0456, 0.0168, 0.0459, 0.0642], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,876][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0236, 0.0435, 0.2720, 0.0392, 0.1740, 0.0699, 0.0551, 0.0285, 0.0457,
        0.0676, 0.0494, 0.0560, 0.0755], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,877][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1026, 0.0583, 0.4182, 0.0495, 0.1530, 0.0364, 0.0255, 0.0178, 0.0272,
        0.0307, 0.0112, 0.0334, 0.0361], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,879][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2602, 0.1229, 0.1072, 0.1208, 0.1437, 0.0296, 0.0155, 0.0140, 0.0186,
        0.0372, 0.0199, 0.0366, 0.0740], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,880][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0584, 0.0668, 0.2318, 0.0581, 0.1617, 0.0645, 0.0411, 0.0281, 0.0508,
        0.0528, 0.0320, 0.0459, 0.1081], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,882][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.2107, 0.1172, 0.1576, 0.1137, 0.0843, 0.0550, 0.0237, 0.0305, 0.0221,
        0.0257, 0.0117, 0.0905, 0.0572], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,883][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0006, 0.0025, 0.1063, 0.0028, 0.0650, 0.2212, 0.1635, 0.0433, 0.0909,
        0.0901, 0.1687, 0.0194, 0.0256], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,885][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0763, 0.0508, 0.2185, 0.0498, 0.2243, 0.0448, 0.0294, 0.0341, 0.0499,
        0.0502, 0.0170, 0.0672, 0.0877], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,886][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0894, 0.0800, 0.1936, 0.0711, 0.1666, 0.0629, 0.0367, 0.0312, 0.0500,
        0.0589, 0.0344, 0.0583, 0.0670], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,887][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([1.2067e-04, 1.8701e-03, 9.2324e-02, 1.8477e-03, 4.0274e-02, 2.8010e-01,
        2.1985e-01, 2.9647e-02, 5.1270e-02, 8.3010e-02, 1.7153e-01, 1.4714e-02,
        1.3431e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,889][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0132, 0.0117, 0.0391, 0.0164, 0.1218, 0.0949, 0.0981, 0.0406, 0.1146,
        0.1592, 0.1412, 0.0762, 0.0730], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,890][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0021, 0.0049, 0.0298, 0.0048, 0.0300, 0.2255, 0.1827, 0.0634, 0.0748,
        0.0916, 0.2335, 0.0215, 0.0354], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:07,891][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1470, 0.0565, 0.3023, 0.0569, 0.2234, 0.0316, 0.0140, 0.0123, 0.0318,
        0.0255, 0.0061, 0.0335, 0.0445, 0.0146], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,893][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0228, 0.0403, 0.4402, 0.0352, 0.2561, 0.0253, 0.0179, 0.0122, 0.0176,
        0.0277, 0.0110, 0.0314, 0.0518, 0.0105], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,894][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1115, 0.0402, 0.5185, 0.0346, 0.1911, 0.0162, 0.0076, 0.0061, 0.0122,
        0.0124, 0.0027, 0.0189, 0.0214, 0.0066], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,896][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1481, 0.0351, 0.0611, 0.0602, 0.4492, 0.0362, 0.0104, 0.0052, 0.0096,
        0.0414, 0.0220, 0.0204, 0.0944, 0.0066], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,897][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.1193, 0.0972, 0.2378, 0.0846, 0.1740, 0.0347, 0.0205, 0.0200, 0.0363,
        0.0330, 0.0136, 0.0317, 0.0768, 0.0205], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,899][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2226, 0.1012, 0.1684, 0.1063, 0.0998, 0.0548, 0.0213, 0.0280, 0.0198,
        0.0214, 0.0090, 0.0708, 0.0491, 0.0275], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,900][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0007, 0.0029, 0.2127, 0.0033, 0.1235, 0.1894, 0.1051, 0.0350, 0.0902,
        0.0749, 0.0892, 0.0193, 0.0273, 0.0265], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,902][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0152, 0.0073, 0.1276, 0.0096, 0.2889, 0.0742, 0.0624, 0.0363, 0.0947,
        0.0915, 0.0432, 0.0566, 0.0576, 0.0351], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,903][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0813, 0.0537, 0.2687, 0.0471, 0.2261, 0.0581, 0.0242, 0.0207, 0.0400,
        0.0421, 0.0157, 0.0435, 0.0582, 0.0207], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,904][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([6.4421e-05, 1.2927e-03, 1.4340e-01, 1.2985e-03, 5.2184e-02, 2.6696e-01,
        2.1929e-01, 2.3252e-02, 4.7757e-02, 7.2340e-02, 1.3541e-01, 1.0703e-02,
        8.5604e-03, 1.7493e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,905][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0026, 0.0012, 0.0068, 0.0031, 0.1330, 0.1153, 0.0869, 0.0159, 0.0889,
        0.1767, 0.2604, 0.0372, 0.0414, 0.0304], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,905][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0037, 0.0073, 0.0425, 0.0070, 0.0347, 0.2082, 0.1675, 0.0612, 0.0547,
        0.0877, 0.2004, 0.0187, 0.0318, 0.0745], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:07,906][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2477, 0.0630, 0.3323, 0.0613, 0.2103, 0.0088, 0.0036, 0.0036, 0.0089,
        0.0092, 0.0012, 0.0171, 0.0274, 0.0049, 0.0009], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,906][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0362, 0.0452, 0.5187, 0.0375, 0.2459, 0.0092, 0.0074, 0.0042, 0.0071,
        0.0118, 0.0037, 0.0256, 0.0412, 0.0041, 0.0023], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,906][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.3384e-01, 3.5563e-02, 5.8469e-01, 2.8530e-02, 1.7516e-01, 5.8764e-03,
        2.6948e-03, 1.9812e-03, 3.7573e-03, 4.8675e-03, 6.2565e-04, 9.2254e-03,
        1.0688e-02, 2.0127e-03, 4.9333e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,907][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0480, 0.0092, 0.0375, 0.0220, 0.6596, 0.0454, 0.0099, 0.0026, 0.0081,
        0.0406, 0.0252, 0.0130, 0.0740, 0.0036, 0.0014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,908][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2144, 0.1157, 0.2019, 0.0955, 0.1860, 0.0146, 0.0079, 0.0080, 0.0131,
        0.0158, 0.0060, 0.0290, 0.0788, 0.0091, 0.0042], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,909][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3574, 0.1215, 0.1596, 0.1229, 0.0789, 0.0205, 0.0073, 0.0113, 0.0073,
        0.0087, 0.0024, 0.0545, 0.0321, 0.0116, 0.0039], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,910][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0015, 0.0045, 0.3562, 0.0048, 0.1599, 0.1259, 0.0649, 0.0234, 0.0633,
        0.0529, 0.0466, 0.0197, 0.0308, 0.0192, 0.0264], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,912][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0089, 0.0030, 0.1409, 0.0042, 0.4333, 0.0565, 0.0413, 0.0196, 0.0793,
        0.0751, 0.0223, 0.0360, 0.0489, 0.0164, 0.0142], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,913][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1160, 0.0555, 0.3809, 0.0456, 0.2387, 0.0241, 0.0077, 0.0091, 0.0167,
        0.0202, 0.0048, 0.0298, 0.0383, 0.0079, 0.0048], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,914][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.7087e-04, 2.5222e-03, 4.5339e-01, 2.3098e-03, 9.0410e-02, 1.5858e-01,
        1.1447e-01, 1.3247e-02, 2.8943e-02, 4.3350e-02, 4.1568e-02, 1.0108e-02,
        1.0228e-02, 8.1618e-03, 2.2543e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,916][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0010, 0.0004, 0.0043, 0.0013, 0.2006, 0.1374, 0.0804, 0.0067, 0.0595,
        0.1526, 0.2550, 0.0207, 0.0319, 0.0169, 0.0313], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,917][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0033, 0.0070, 0.0634, 0.0061, 0.0468, 0.1967, 0.1276, 0.0648, 0.0454,
        0.0705, 0.1414, 0.0205, 0.0363, 0.0605, 0.1097], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:07,919][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:07,921][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[35577],
        [25474],
        [ 4549],
        [12420],
        [  122],
        [  124],
        [   72],
        [   58],
        [   16],
        [   26],
        [   69],
        [   30],
        [   18],
        [   72],
        [   29]], device='cuda:0')
[2024-07-24 10:24:07,922][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[24594],
        [23408],
        [ 3200],
        [ 4160],
        [  519],
        [ 1503],
        [ 1801],
        [ 1364],
        [  634],
        [  869],
        [ 1466],
        [ 1213],
        [  520],
        [ 1935],
        [ 1327]], device='cuda:0')
[2024-07-24 10:24:07,923][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18837],
        [12566],
        [40145],
        [38242],
        [34279],
        [34673],
        [31824],
        [31135],
        [34453],
        [32038],
        [31707],
        [29869],
        [28225],
        [28467],
        [30342]], device='cuda:0')
[2024-07-24 10:24:07,925][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[10635],
        [13667],
        [27254],
        [28277],
        [29103],
        [29516],
        [30284],
        [31365],
        [29133],
        [31122],
        [30191],
        [34324],
        [37771],
        [32711],
        [30763]], device='cuda:0')
[2024-07-24 10:24:07,926][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[44523],
        [47345],
        [ 7102],
        [ 1624],
        [ 1882],
        [ 1690],
        [ 2714],
        [ 2862],
        [ 1275],
        [ 1452],
        [ 2457],
        [ 4082],
        [ 4647],
        [ 3036],
        [  815]], device='cuda:0')
[2024-07-24 10:24:07,928][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[18065],
        [11830],
        [ 6704],
        [ 7249],
        [ 5824],
        [ 5556],
        [ 5638],
        [ 5440],
        [ 5277],
        [ 5276],
        [ 5379],
        [ 5499],
        [ 5457],
        [ 5613],
        [ 4517]], device='cuda:0')
[2024-07-24 10:24:07,929][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13948],
        [23419],
        [ 6576],
        [ 5632],
        [ 5677],
        [ 5755],
        [ 6663],
        [ 8066],
        [ 9614],
        [ 9661],
        [10513],
        [11391],
        [10732],
        [12176],
        [12544]], device='cuda:0')
[2024-07-24 10:24:07,931][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38178],
        [34549],
        [31211],
        [31397],
        [33181],
        [34865],
        [34610],
        [34739],
        [33782],
        [34444],
        [34327],
        [35845],
        [34248],
        [34648],
        [34824]], device='cuda:0')
[2024-07-24 10:24:07,932][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[20995],
        [10794],
        [50257],
        [50257],
        [50219],
        [34992],
        [23615],
        [18983],
        [40524],
        [34429],
        [28813],
        [ 7447],
        [ 6140],
        [ 6464],
        [ 8538]], device='cuda:0')
[2024-07-24 10:24:07,933][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[  201],
        [  886],
        [ 1576],
        [ 4542],
        [ 8583],
        [20252],
        [21548],
        [18297],
        [21419],
        [20247],
        [22175],
        [15123],
        [14857],
        [15979],
        [20133]], device='cuda:0')
[2024-07-24 10:24:07,935][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20839],
        [23363],
        [50030],
        [50073],
        [50002],
        [49950],
        [49929],
        [49853],
        [49996],
        [49892],
        [49949],
        [49551],
        [49184],
        [49551],
        [49911]], device='cuda:0')
[2024-07-24 10:24:07,936][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[4061],
        [1032],
        [4195],
        [3879],
        [2705],
        [1521],
        [1178],
        [1412],
        [1845],
        [1383],
        [1033],
        [ 838],
        [ 840],
        [ 831],
        [ 871]], device='cuda:0')
[2024-07-24 10:24:07,938][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[9621],
        [8958],
        [6704],
        [6179],
        [5546],
        [5775],
        [6039],
        [7544],
        [6715],
        [5983],
        [6187],
        [9131],
        [8491],
        [8289],
        [7725]], device='cuda:0')
[2024-07-24 10:24:07,939][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25148],
        [22329],
        [  526],
        [  660],
        [  262],
        [ 1826],
        [  484],
        [ 2489],
        [ 2036],
        [ 5547],
        [ 3375],
        [ 1887],
        [ 3672],
        [ 2791],
        [ 1442]], device='cuda:0')
[2024-07-24 10:24:07,940][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[35523],
        [29564],
        [10920],
        [23568],
        [ 6080],
        [ 5279],
        [ 2769],
        [ 2439],
        [ 2086],
        [ 1407],
        [  829],
        [ 2176],
        [ 3283],
        [ 2675],
        [ 1785]], device='cuda:0')
[2024-07-24 10:24:07,942][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 2053],
        [ 2025],
        [29150],
        [28074],
        [31085],
        [31147],
        [31352],
        [30445],
        [30851],
        [30563],
        [30806],
        [28134],
        [26333],
        [28527],
        [30963]], device='cuda:0')
[2024-07-24 10:24:07,943][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14857],
        [22310],
        [33391],
        [33089],
        [27943],
        [29020],
        [28954],
        [29541],
        [30912],
        [30374],
        [29584],
        [33220],
        [35478],
        [31002],
        [29838]], device='cuda:0')
[2024-07-24 10:24:07,945][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3099],
        [ 469],
        [3125],
        [2523],
        [3131],
        [3593],
        [3422],
        [3248],
        [3571],
        [3327],
        [3731],
        [2191],
        [2270],
        [2770],
        [3252]], device='cuda:0')
[2024-07-24 10:24:07,946][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16016],
        [11832],
        [12897],
        [ 7329],
        [10385],
        [ 6947],
        [ 2810],
        [ 1301],
        [ 3298],
        [ 2666],
        [  960],
        [  749],
        [ 1096],
        [  519],
        [  439]], device='cuda:0')
[2024-07-24 10:24:07,948][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[8762],
        [8841],
        [ 985],
        [1011],
        [1659],
        [1576],
        [1675],
        [1526],
        [1882],
        [1440],
        [1723],
        [1464],
        [1488],
        [1561],
        [1831]], device='cuda:0')
[2024-07-24 10:24:07,949][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5350],
        [6472],
        [3017],
        [2614],
        [2928],
        [2681],
        [2731],
        [3046],
        [3068],
        [3089],
        [3228],
        [3911],
        [4914],
        [4611],
        [3779]], device='cuda:0')
[2024-07-24 10:24:07,950][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13065],
        [ 3820],
        [17952],
        [16880],
        [17786],
        [20133],
        [21057],
        [22917],
        [19300],
        [20726],
        [18921],
        [20125],
        [20492],
        [21358],
        [19817]], device='cuda:0')
[2024-07-24 10:24:07,952][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[4063],
        [6198],
        [4268],
        [3397],
        [2220],
        [1122],
        [ 941],
        [ 847],
        [ 854],
        [ 763],
        [ 624],
        [ 860],
        [ 906],
        [ 851],
        [ 671]], device='cuda:0')
[2024-07-24 10:24:07,953][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38443],
        [18929],
        [  970],
        [  692],
        [ 1062],
        [ 1171],
        [ 1230],
        [ 1192],
        [ 1073],
        [ 1160],
        [ 1102],
        [ 1368],
        [ 1638],
        [ 1516],
        [ 1232]], device='cuda:0')
[2024-07-24 10:24:07,954][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9385],
        [12063],
        [34615],
        [34514],
        [33987],
        [40201],
        [39581],
        [39143],
        [36538],
        [38245],
        [38887],
        [35262],
        [34024],
        [35083],
        [38618]], device='cuda:0')
[2024-07-24 10:24:07,955][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[16254],
        [11962],
        [ 5089],
        [ 3096],
        [ 4626],
        [ 6752],
        [ 5643],
        [ 3792],
        [ 5956],
        [ 6300],
        [ 6425],
        [ 5018],
        [ 5184],
        [ 5063],
        [ 5131]], device='cuda:0')
[2024-07-24 10:24:07,956][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22972],
        [26067],
        [ 9411],
        [10437],
        [11879],
        [12345],
        [14873],
        [16411],
        [15976],
        [17348],
        [18485],
        [18565],
        [19031],
        [18481],
        [17549]], device='cuda:0')
[2024-07-24 10:24:07,957][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[46771],
        [48555],
        [49441],
        [49860],
        [49658],
        [49500],
        [49659],
        [49813],
        [49439],
        [49716],
        [49655],
        [49953],
        [49854],
        [49763],
        [49732]], device='cuda:0')
[2024-07-24 10:24:07,959][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[20946],
        [24518],
        [47811],
        [38246],
        [48407],
        [49358],
        [49741],
        [49907],
        [49995],
        [49654],
        [50112],
        [48027],
        [46013],
        [49678],
        [49985]], device='cuda:0')
[2024-07-24 10:24:07,960][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372],
        [9372]], device='cuda:0')
[2024-07-24 10:24:08,020][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:08,021][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,022][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,023][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,025][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,026][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,027][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,028][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,029][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,030][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,031][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,032][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,034][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,035][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2055, 0.7945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,037][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0987, 0.9013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,038][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2346, 0.7654], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,039][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3495, 0.6505], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,041][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5307, 0.4693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,042][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4963, 0.5037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,044][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1264, 0.8736], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,045][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1647, 0.8353], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,046][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2909, 0.7091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,048][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3796, 0.6204], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,048][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3779, 0.6221], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,049][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1783, 0.8217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,049][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.0077, 0.0171, 0.9753], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,049][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.0034, 0.0189, 0.9777], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,050][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.1910, 0.2663, 0.5427], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,050][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.0338, 0.1007, 0.8655], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,050][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.3116, 0.2441, 0.4443], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,051][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.1015, 0.2127, 0.6857], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,051][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.0459, 0.1111, 0.8430], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,052][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.0031, 0.0188, 0.9782], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,053][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([0.1071, 0.1574, 0.7356], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,054][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.5069, 0.4230, 0.0701], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,056][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.1035, 0.0571, 0.8394], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,057][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.1031, 0.1140, 0.7829], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,058][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0248, 0.0946, 0.7761, 0.1044], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,059][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0091, 0.0826, 0.8104, 0.0979], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,061][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0419, 0.1343, 0.6778, 0.1460], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,062][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1019, 0.1925, 0.5143, 0.1913], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,063][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3188, 0.2713, 0.1631, 0.2468], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,065][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1353, 0.1367, 0.4875, 0.2405], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,066][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0115, 0.0733, 0.8284, 0.0868], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,068][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0108, 0.0513, 0.8896, 0.0483], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,069][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0948, 0.2260, 0.4562, 0.2230], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,070][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1842, 0.2699, 0.1302, 0.4156], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,071][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0733, 0.1145, 0.6998, 0.1124], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,073][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0313, 0.1371, 0.6749, 0.1567], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,074][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0038, 0.0081, 0.8054, 0.0065, 0.1762], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,076][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0011, 0.0063, 0.5275, 0.0053, 0.4598], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,077][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0954, 0.1316, 0.3608, 0.1263, 0.2859], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,079][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0194, 0.0574, 0.6943, 0.0491, 0.1797], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,080][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.1208, 0.1064, 0.4359, 0.0717, 0.2652], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,081][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0886, 0.1107, 0.2942, 0.1207, 0.3857], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,083][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0248, 0.0617, 0.5064, 0.0633, 0.3437], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,084][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0041, 0.0187, 0.5502, 0.0184, 0.4086], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,086][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0525, 0.0734, 0.5646, 0.0623, 0.2473], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,087][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.2871, 0.1704, 0.2303, 0.1757, 0.1365], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,089][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0370, 0.0229, 0.7792, 0.0161, 0.1448], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,090][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0747, 0.0733, 0.6024, 0.0682, 0.1814], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,091][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0010, 0.0016, 0.7544, 0.0015, 0.1737, 0.0678], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,092][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.9595e-04, 1.6164e-03, 4.8783e-01, 1.4819e-03, 4.3429e-01, 7.4388e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,093][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1831, 0.1547, 0.2405, 0.1494, 0.2258, 0.0465], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,095][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0054, 0.0149, 0.2418, 0.0162, 0.1202, 0.6016], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,095][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1672, 0.1072, 0.2245, 0.0801, 0.4023, 0.0188], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,096][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0487, 0.0603, 0.1539, 0.0804, 0.2697, 0.3870], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,096][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0255, 0.0380, 0.2648, 0.0422, 0.2556, 0.3739], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,096][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0021, 0.0118, 0.4700, 0.0106, 0.3928, 0.1127], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,097][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0406, 0.0477, 0.6053, 0.0375, 0.1911, 0.0777], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,097][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0144, 0.0034, 0.0278, 0.0109, 0.9083, 0.0353], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,097][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([1.6721e-02, 6.5976e-03, 8.4872e-01, 4.4942e-03, 1.2262e-01, 8.4691e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,098][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0768, 0.0298, 0.6890, 0.0299, 0.1497, 0.0248], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,099][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0009, 0.0013, 0.5726, 0.0013, 0.2659, 0.1088, 0.0492],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,100][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.7542e-04, 1.1132e-03, 3.7305e-01, 1.0979e-03, 4.6908e-01, 1.0022e-01,
        5.5168e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,101][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1872, 0.1497, 0.2039, 0.1475, 0.2265, 0.0456, 0.0396],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,103][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0031, 0.0090, 0.1331, 0.0102, 0.0812, 0.4301, 0.3334],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,104][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1690, 0.0989, 0.1830, 0.0748, 0.4469, 0.0139, 0.0136],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,105][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0439, 0.0489, 0.1002, 0.0585, 0.1658, 0.2275, 0.3553],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,107][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0219, 0.0302, 0.1561, 0.0341, 0.1913, 0.2631, 0.3032],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,108][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0017, 0.0111, 0.4198, 0.0092, 0.3752, 0.1018, 0.0813],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,110][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0334, 0.0412, 0.5358, 0.0348, 0.2145, 0.0982, 0.0422],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,111][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.4029e-03, 8.2442e-04, 1.2025e-02, 3.1950e-03, 9.1189e-01, 5.7826e-02,
        1.0838e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,111][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.2923e-02, 4.5664e-03, 8.0906e-01, 3.2916e-03, 1.6879e-01, 1.0579e-03,
        3.1310e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,113][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0838, 0.0255, 0.6206, 0.0274, 0.2114, 0.0215, 0.0098],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,114][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0009, 0.0014, 0.5528, 0.0014, 0.2422, 0.1165, 0.0636, 0.0211],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,116][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0006, 0.0023, 0.4588, 0.0022, 0.3887, 0.0842, 0.0507, 0.0126],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,117][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1680, 0.1392, 0.2543, 0.1317, 0.2019, 0.0406, 0.0313, 0.0332],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,119][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0034, 0.0094, 0.1114, 0.0100, 0.0621, 0.4029, 0.3338, 0.0670],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,120][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1418, 0.0996, 0.2248, 0.0686, 0.3888, 0.0228, 0.0208, 0.0328],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,122][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0543, 0.0437, 0.0695, 0.0527, 0.1158, 0.1709, 0.2819, 0.2113],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,123][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0172, 0.0253, 0.1359, 0.0283, 0.1440, 0.2131, 0.2603, 0.1758],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,124][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0019, 0.0093, 0.3436, 0.0080, 0.2414, 0.0841, 0.0634, 0.2482],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,126][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0492, 0.0576, 0.4272, 0.0480, 0.1825, 0.0894, 0.0415, 0.1046],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,127][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.7779e-03, 6.0053e-04, 7.3094e-03, 2.2832e-03, 6.3507e-01, 2.6510e-01,
        8.0714e-02, 7.1444e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,128][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([1.1732e-02, 6.3435e-03, 8.0229e-01, 4.7882e-03, 1.7131e-01, 1.6476e-03,
        5.5413e-04, 1.3341e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,129][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0823, 0.0288, 0.6324, 0.0293, 0.1754, 0.0300, 0.0123, 0.0095],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,131][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0020, 0.0025, 0.7163, 0.0022, 0.2086, 0.0351, 0.0144, 0.0064, 0.0125],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,132][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0007, 0.0024, 0.5619, 0.0020, 0.3629, 0.0279, 0.0129, 0.0032, 0.0261],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,133][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2858, 0.1859, 0.1706, 0.1653, 0.1331, 0.0178, 0.0132, 0.0152, 0.0132],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,135][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0065, 0.0174, 0.1225, 0.0169, 0.0566, 0.3592, 0.2739, 0.0511, 0.0958],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,136][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0556, 0.0477, 0.2374, 0.0326, 0.2866, 0.0519, 0.0475, 0.1561, 0.0844],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,138][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0335, 0.0399, 0.0771, 0.0373, 0.1093, 0.1492, 0.2299, 0.1698, 0.1540],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,139][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0774, 0.0617, 0.1909, 0.0647, 0.1818, 0.1260, 0.1425, 0.0892, 0.0659],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,141][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0029, 0.0112, 0.2366, 0.0101, 0.1695, 0.0860, 0.0624, 0.1821, 0.2391],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,141][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0649, 0.0689, 0.5121, 0.0502, 0.1455, 0.0353, 0.0124, 0.0293, 0.0813],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,142][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0059, 0.0019, 0.0357, 0.0053, 0.8150, 0.0843, 0.0186, 0.0023, 0.0310],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,142][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([1.5397e-02, 6.8333e-03, 8.5331e-01, 4.5778e-03, 1.1640e-01, 5.1190e-04,
        1.4105e-04, 3.0592e-04, 2.5228e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,143][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1943, 0.0444, 0.6243, 0.0377, 0.0827, 0.0064, 0.0022, 0.0021, 0.0058],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,143][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0012, 0.0022, 0.5685, 0.0022, 0.2368, 0.0740, 0.0309, 0.0149, 0.0476,
        0.0217], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,143][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.2523e-04, 1.5876e-03, 4.1192e-01, 1.5726e-03, 3.8371e-01, 6.8525e-02,
        3.0623e-02, 6.8025e-03, 5.5730e-02, 3.9198e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,144][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1124, 0.1083, 0.2360, 0.1063, 0.2187, 0.0493, 0.0392, 0.0359, 0.0395,
        0.0542], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,144][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0031, 0.0094, 0.1158, 0.0100, 0.0677, 0.3153, 0.2449, 0.0473, 0.0894,
        0.0970], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,145][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1582, 0.0756, 0.2279, 0.0570, 0.3590, 0.0097, 0.0126, 0.0492, 0.0468,
        0.0039], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,146][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0198, 0.0216, 0.0436, 0.0303, 0.0894, 0.1222, 0.2168, 0.1810, 0.1534,
        0.1220], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,147][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0072, 0.0130, 0.1109, 0.0143, 0.1090, 0.1422, 0.1488, 0.1013, 0.1403,
        0.2131], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,149][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0005, 0.0038, 0.2670, 0.0031, 0.2021, 0.0504, 0.0357, 0.1444, 0.1944,
        0.0987], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,150][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0356, 0.0501, 0.3748, 0.0400, 0.1843, 0.0667, 0.0305, 0.0514, 0.1071,
        0.0594], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,152][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0037, 0.0014, 0.0405, 0.0038, 0.8510, 0.0373, 0.0063, 0.0011, 0.0151,
        0.0397], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,152][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.1714e-02, 5.9100e-03, 8.0988e-01, 4.3964e-03, 1.5873e-01, 1.1555e-03,
        3.1978e-04, 6.1340e-04, 7.1484e-03, 1.3394e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,154][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0700, 0.0355, 0.5888, 0.0348, 0.1892, 0.0198, 0.0083, 0.0075, 0.0215,
        0.0246], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,155][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0012, 0.0019, 0.5525, 0.0019, 0.2466, 0.0725, 0.0328, 0.0141, 0.0439,
        0.0210, 0.0114], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,157][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0005, 0.0016, 0.4156, 0.0017, 0.4107, 0.0562, 0.0214, 0.0054, 0.0435,
        0.0296, 0.0137], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,158][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2109, 0.1424, 0.1732, 0.1408, 0.1899, 0.0266, 0.0208, 0.0236, 0.0223,
        0.0347, 0.0147], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,160][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0032, 0.0087, 0.0758, 0.0096, 0.0540, 0.2680, 0.2045, 0.0477, 0.0835,
        0.0913, 0.1537], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,161][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2973, 0.1470, 0.1435, 0.0966, 0.2191, 0.0071, 0.0073, 0.0398, 0.0363,
        0.0030, 0.0030], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,163][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0151, 0.0184, 0.0454, 0.0253, 0.0851, 0.1115, 0.1913, 0.1559, 0.1279,
        0.1075, 0.1167], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,164][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0122, 0.0158, 0.0973, 0.0174, 0.1144, 0.1079, 0.1237, 0.0825, 0.1041,
        0.2071, 0.1176], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,166][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0005, 0.0046, 0.2376, 0.0035, 0.2156, 0.0520, 0.0391, 0.1363, 0.1752,
        0.0955, 0.0402], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,167][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0435, 0.0493, 0.3765, 0.0401, 0.2035, 0.0584, 0.0223, 0.0540, 0.0902,
        0.0441, 0.0181], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,168][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.5976e-04, 1.6463e-04, 1.0355e-02, 6.6423e-04, 8.8350e-01, 3.1248e-02,
        5.0369e-03, 4.0556e-04, 1.0340e-02, 3.8208e-02, 1.9517e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,169][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.3805e-02, 5.3147e-03, 8.1396e-01, 4.1005e-03, 1.5651e-01, 9.9495e-04,
        2.4340e-04, 4.6009e-04, 4.5028e-03, 8.5078e-05, 2.0609e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,170][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0681, 0.0240, 0.6730, 0.0240, 0.1514, 0.0139, 0.0038, 0.0047, 0.0145,
        0.0164, 0.0062], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,172][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0026, 0.0045, 0.4394, 0.0042, 0.1919, 0.1069, 0.0619, 0.0264, 0.0675,
        0.0375, 0.0291, 0.0283], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,173][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0008, 0.0033, 0.3246, 0.0031, 0.2627, 0.1045, 0.0625, 0.0131, 0.0801,
        0.0601, 0.0463, 0.0390], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,175][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0609, 0.0737, 0.1758, 0.0738, 0.1658, 0.0719, 0.0680, 0.0514, 0.0606,
        0.0707, 0.0604, 0.0672], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,176][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0050, 0.0138, 0.1317, 0.0141, 0.0599, 0.2689, 0.1945, 0.0384, 0.0718,
        0.0718, 0.1166, 0.0135], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,178][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1075, 0.0785, 0.2678, 0.0504, 0.1853, 0.0250, 0.0220, 0.0618, 0.0817,
        0.0168, 0.0206, 0.0827], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,179][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0090, 0.0132, 0.0311, 0.0154, 0.0638, 0.0984, 0.1926, 0.1643, 0.1265,
        0.1038, 0.0979, 0.0839], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,180][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0054, 0.0111, 0.0691, 0.0117, 0.0608, 0.1356, 0.1327, 0.0843, 0.0988,
        0.1506, 0.1566, 0.0834], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,182][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0017, 0.0076, 0.1915, 0.0065, 0.1263, 0.0481, 0.0389, 0.1380, 0.1554,
        0.1012, 0.0404, 0.1443], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,184][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0473, 0.0618, 0.2567, 0.0503, 0.1420, 0.0725, 0.0446, 0.0502, 0.1011,
        0.0571, 0.0372, 0.0792], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,185][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0024, 0.0018, 0.0402, 0.0040, 0.3701, 0.1450, 0.0628, 0.0075, 0.0717,
        0.1315, 0.1311, 0.0319], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,186][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.4377e-02, 1.0003e-02, 7.5236e-01, 7.6945e-03, 1.7130e-01, 5.6106e-03,
        2.6294e-03, 2.8918e-03, 2.5430e-02, 1.0079e-03, 4.7922e-04, 6.2210e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,187][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0624, 0.0385, 0.4843, 0.0371, 0.1350, 0.0307, 0.0251, 0.0121, 0.0311,
        0.0406, 0.0335, 0.0697], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,189][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0008, 0.0019, 0.3659, 0.0019, 0.1747, 0.1413, 0.0840, 0.0254, 0.0758,
        0.0420, 0.0356, 0.0211, 0.0296], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,189][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([1.7324e-04, 1.0882e-03, 2.2677e-01, 1.0723e-03, 2.0113e-01, 1.6134e-01,
        1.0414e-01, 1.4205e-02, 8.4054e-02, 7.0968e-02, 7.2247e-02, 2.5332e-02,
        3.7479e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,190][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0387, 0.0544, 0.1711, 0.0531, 0.1483, 0.0788, 0.0654, 0.0479, 0.0543,
        0.0677, 0.0629, 0.0550, 0.1024], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,190][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0016, 0.0060, 0.1248, 0.0062, 0.0518, 0.2732, 0.2203, 0.0345, 0.0671,
        0.0692, 0.1093, 0.0122, 0.0237], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,190][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0806, 0.0631, 0.1758, 0.0495, 0.1589, 0.0189, 0.0241, 0.0420, 0.0336,
        0.0063, 0.0163, 0.0343, 0.2968], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,191][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0082, 0.0124, 0.0389, 0.0130, 0.0637, 0.0837, 0.1635, 0.1691, 0.1096,
        0.0941, 0.0803, 0.0988, 0.0646], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,191][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0029, 0.0069, 0.0630, 0.0073, 0.0509, 0.1145, 0.1334, 0.0799, 0.1197,
        0.1426, 0.1596, 0.0741, 0.0452], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,193][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0012, 0.0045, 0.1643, 0.0041, 0.1315, 0.0410, 0.0296, 0.1073, 0.1290,
        0.1004, 0.0351, 0.1015, 0.1504], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,194][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0151, 0.0235, 0.2880, 0.0196, 0.1430, 0.0790, 0.0504, 0.0452, 0.1005,
        0.0670, 0.0440, 0.0531, 0.0717], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,195][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0199, 0.0162, 0.1286, 0.0233, 0.3596, 0.0528, 0.0208, 0.0093, 0.0493,
        0.0973, 0.0464, 0.0565, 0.1199], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,197][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0093, 0.0077, 0.7148, 0.0065, 0.1984, 0.0096, 0.0048, 0.0042, 0.0297,
        0.0015, 0.0008, 0.0059, 0.0068], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,198][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0151, 0.0146, 0.3469, 0.0153, 0.1339, 0.0733, 0.0682, 0.0195, 0.0527,
        0.0679, 0.0681, 0.0570, 0.0674], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,199][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0006, 0.0012, 0.4359, 0.0013, 0.2040, 0.1093, 0.0520, 0.0213, 0.0747,
        0.0306, 0.0208, 0.0177, 0.0200, 0.0104], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,200][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.8735e-04, 1.0305e-03, 2.7223e-01, 1.0676e-03, 3.3327e-01, 1.0353e-01,
        4.7499e-02, 9.7985e-03, 7.8942e-02, 4.9006e-02, 3.3716e-02, 2.0638e-02,
        3.2610e-02, 1.6477e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,202][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0779, 0.0808, 0.1668, 0.0803, 0.1684, 0.0461, 0.0403, 0.0351, 0.0357,
        0.0512, 0.0324, 0.0503, 0.0975, 0.0372], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,203][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0021, 0.0062, 0.0903, 0.0072, 0.0547, 0.2619, 0.1877, 0.0396, 0.0635,
        0.0703, 0.1060, 0.0132, 0.0284, 0.0689], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,205][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0372, 0.0217, 0.0966, 0.0166, 0.2168, 0.0080, 0.0096, 0.0350, 0.0279,
        0.0035, 0.0051, 0.0344, 0.4712, 0.0163], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,206][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0143, 0.0152, 0.0333, 0.0196, 0.0640, 0.0945, 0.1663, 0.1142, 0.1045,
        0.0854, 0.0898, 0.0582, 0.0544, 0.0861], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,208][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0037, 0.0072, 0.0571, 0.0079, 0.0622, 0.1068, 0.1126, 0.0769, 0.1065,
        0.1461, 0.1273, 0.0748, 0.0483, 0.0627], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,209][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0010, 0.0050, 0.1553, 0.0040, 0.1365, 0.0409, 0.0305, 0.1211, 0.1460,
        0.0784, 0.0327, 0.0913, 0.1058, 0.0515], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,211][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0234, 0.0312, 0.2877, 0.0259, 0.1510, 0.0840, 0.0351, 0.0429, 0.0889,
        0.0523, 0.0263, 0.0619, 0.0574, 0.0321], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,212][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([5.7265e-04, 2.1292e-04, 7.8384e-03, 7.7282e-04, 5.0616e-01, 1.1649e-01,
        3.1725e-02, 3.0884e-03, 4.2843e-02, 1.1384e-01, 1.0432e-01, 1.4636e-02,
        4.9207e-02, 8.2917e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,213][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([7.8623e-03, 5.0360e-03, 7.6706e-01, 3.9519e-03, 1.8754e-01, 3.5064e-03,
        1.1182e-03, 1.6103e-03, 1.5034e-02, 3.7796e-04, 1.1219e-04, 2.0951e-03,
        2.9165e-03, 1.7779e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,214][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0570, 0.0279, 0.4575, 0.0285, 0.1415, 0.0381, 0.0169, 0.0120, 0.0354,
        0.0426, 0.0217, 0.0503, 0.0528, 0.0177], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,216][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0008, 0.0013, 0.5530, 0.0013, 0.2442, 0.0606, 0.0262, 0.0105, 0.0381,
        0.0156, 0.0071, 0.0126, 0.0177, 0.0051, 0.0060], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,217][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3693e-04, 9.8408e-04, 4.2410e-01, 9.4468e-04, 3.6997e-01, 4.5144e-02,
        2.0221e-02, 3.9746e-03, 3.9261e-02, 2.3871e-02, 1.0744e-02, 1.4928e-02,
        2.5577e-02, 7.5594e-03, 1.2484e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,218][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1424, 0.1067, 0.1618, 0.1042, 0.1628, 0.0251, 0.0213, 0.0219, 0.0220,
        0.0330, 0.0167, 0.0455, 0.0985, 0.0255, 0.0129], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,220][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0022, 0.0060, 0.0742, 0.0066, 0.0502, 0.2327, 0.1677, 0.0350, 0.0591,
        0.0640, 0.1008, 0.0138, 0.0284, 0.0678, 0.0915], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,221][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0945, 0.0462, 0.1078, 0.0333, 0.2188, 0.0063, 0.0070, 0.0199, 0.0291,
        0.0022, 0.0036, 0.0328, 0.3827, 0.0141, 0.0015], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,223][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0156, 0.0149, 0.0322, 0.0215, 0.0606, 0.0818, 0.1318, 0.1098, 0.0951,
        0.0709, 0.0801, 0.0605, 0.0609, 0.0827, 0.0816], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,224][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0099, 0.0133, 0.0840, 0.0141, 0.0912, 0.0761, 0.0778, 0.0569, 0.0848,
        0.1276, 0.0706, 0.0862, 0.0612, 0.0485, 0.0977], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,226][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0014, 0.0061, 0.1233, 0.0053, 0.0962, 0.0371, 0.0323, 0.1138, 0.1226,
        0.0810, 0.0383, 0.1028, 0.1018, 0.0490, 0.0890], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,227][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0231, 0.0316, 0.3443, 0.0243, 0.1664, 0.0529, 0.0200, 0.0391, 0.0651,
        0.0319, 0.0143, 0.0985, 0.0589, 0.0199, 0.0097], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,228][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.4447e-05, 1.8341e-05, 2.3388e-03, 9.8851e-05, 6.0314e-01, 1.1452e-01,
        2.3491e-02, 1.0060e-03, 3.0188e-02, 8.7913e-02, 9.4274e-02, 6.2756e-03,
        3.0775e-02, 2.7774e-03, 3.1368e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,229][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.1348e-02, 3.8380e-03, 8.3317e-01, 2.7217e-03, 1.4183e-01, 6.2912e-04,
        1.5838e-04, 2.8490e-04, 3.9078e-03, 4.6422e-05, 1.0004e-05, 7.1627e-04,
        9.2957e-04, 4.0988e-04, 3.3607e-06], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,231][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0612, 0.0190, 0.6039, 0.0192, 0.1391, 0.0144, 0.0054, 0.0049, 0.0164,
        0.0169, 0.0068, 0.0391, 0.0390, 0.0061, 0.0086], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,292][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:08,293][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,294][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,295][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,296][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,298][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,299][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,300][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,301][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,302][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,303][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,314][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,315][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,316][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2055, 0.7945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,317][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0987, 0.9013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,319][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2617, 0.7383], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,320][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3879, 0.6121], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,322][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4583, 0.5417], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,323][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4542, 0.5458], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,324][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1738, 0.8262], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,325][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4559, 0.5441], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,327][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2910, 0.7090], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,328][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3796, 0.6204], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,329][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3779, 0.6221], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,331][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1783, 0.8217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,332][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.0077, 0.0171, 0.9753], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,334][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.0034, 0.0189, 0.9777], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,335][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.0800, 0.1234, 0.7966], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,336][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.1208, 0.0791, 0.8000], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,338][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.4530, 0.2502, 0.2968], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,339][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.4855, 0.3693, 0.1451], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,340][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.0358, 0.0718, 0.8924], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,342][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.2495, 0.1326, 0.6179], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,343][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.1094, 0.1594, 0.7312], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,345][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.5069, 0.4230, 0.0701], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,345][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.1035, 0.0571, 0.8394], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,345][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.1031, 0.1140, 0.7829], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,346][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0248, 0.0946, 0.7761, 0.1044], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,346][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0091, 0.0826, 0.8104, 0.0979], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,346][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0585, 0.1630, 0.6041, 0.1743], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,347][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1431, 0.2215, 0.4274, 0.2080], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,347][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2261, 0.2573, 0.2717, 0.2449], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,347][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2204, 0.2467, 0.1733, 0.3596], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,348][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0255, 0.1169, 0.7216, 0.1359], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,349][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1735, 0.2015, 0.4322, 0.1928], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,350][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0941, 0.2243, 0.4597, 0.2219], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,351][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1842, 0.2699, 0.1302, 0.4156], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,353][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0733, 0.1145, 0.6998, 0.1124], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,354][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0313, 0.1371, 0.6749, 0.1567], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,354][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0038, 0.0081, 0.8054, 0.0065, 0.1762], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,356][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0011, 0.0063, 0.5275, 0.0053, 0.4598], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,357][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0338, 0.0494, 0.6503, 0.0426, 0.2240], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,359][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0685, 0.0479, 0.7510, 0.0307, 0.1019], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,360][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.2188, 0.1229, 0.4808, 0.0809, 0.0965], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,361][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1982, 0.1242, 0.2722, 0.1355, 0.2699], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,363][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0145, 0.0295, 0.7189, 0.0243, 0.2128], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,364][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.1994, 0.1086, 0.4242, 0.0846, 0.1833], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,365][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0539, 0.0745, 0.5644, 0.0632, 0.2440], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,367][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.2871, 0.1704, 0.2303, 0.1757, 0.1365], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,368][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0370, 0.0229, 0.7792, 0.0161, 0.1448], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,370][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0747, 0.0733, 0.6024, 0.0682, 0.1814], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,371][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0010, 0.0016, 0.7544, 0.0015, 0.1737, 0.0678], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,371][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.9595e-04, 1.6164e-03, 4.8783e-01, 1.4819e-03, 4.3429e-01, 7.4388e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,373][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0232, 0.0249, 0.6913, 0.0224, 0.2130, 0.0252], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,374][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0447, 0.0181, 0.7886, 0.0130, 0.1309, 0.0046], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,376][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1699, 0.0738, 0.5560, 0.0564, 0.1373, 0.0067], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,377][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0144, 0.0053, 0.0392, 0.0142, 0.8645, 0.0625], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,379][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0073, 0.0095, 0.7336, 0.0086, 0.1956, 0.0455], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,380][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1594, 0.0673, 0.4942, 0.0575, 0.1834, 0.0382], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,381][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0421, 0.0491, 0.6061, 0.0385, 0.1895, 0.0746], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,383][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0144, 0.0034, 0.0278, 0.0109, 0.9083, 0.0353], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,384][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.6721e-02, 6.5976e-03, 8.4872e-01, 4.4942e-03, 1.2262e-01, 8.4691e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,385][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0768, 0.0298, 0.6890, 0.0299, 0.1497, 0.0248], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,386][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0009, 0.0013, 0.5726, 0.0013, 0.2659, 0.1088, 0.0492],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,387][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.7542e-04, 1.1132e-03, 3.7305e-01, 1.0979e-03, 4.6908e-01, 1.0022e-01,
        5.5168e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,389][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0204, 0.0219, 0.5924, 0.0206, 0.2767, 0.0452, 0.0228],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,390][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0346, 0.0157, 0.7473, 0.0117, 0.1799, 0.0087, 0.0021],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,392][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1148, 0.0545, 0.5610, 0.0459, 0.1996, 0.0161, 0.0081],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,392][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0051, 0.0019, 0.0224, 0.0060, 0.8357, 0.0992, 0.0296],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,393][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0070, 0.0086, 0.5503, 0.0088, 0.2851, 0.0961, 0.0440],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,393][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1522, 0.0655, 0.4406, 0.0635, 0.2128, 0.0487, 0.0167],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,393][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0354, 0.0431, 0.5365, 0.0363, 0.2128, 0.0944, 0.0416],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,394][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.4029e-03, 8.2442e-04, 1.2025e-02, 3.1950e-03, 9.1189e-01, 5.7826e-02,
        1.0838e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,394][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.2923e-02, 4.5664e-03, 8.0906e-01, 3.2916e-03, 1.6879e-01, 1.0579e-03,
        3.1310e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,394][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0838, 0.0255, 0.6206, 0.0274, 0.2114, 0.0215, 0.0098],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,395][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0009, 0.0014, 0.5528, 0.0014, 0.2422, 0.1165, 0.0636, 0.0211],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,395][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0006, 0.0023, 0.4588, 0.0022, 0.3887, 0.0842, 0.0507, 0.0126],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,396][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0122, 0.0145, 0.7162, 0.0127, 0.1860, 0.0333, 0.0137, 0.0114],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,397][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0490, 0.0214, 0.7280, 0.0155, 0.1697, 0.0112, 0.0030, 0.0022],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,399][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1431, 0.0651, 0.5037, 0.0563, 0.1922, 0.0193, 0.0112, 0.0090],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,400][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0029, 0.0012, 0.0125, 0.0038, 0.5790, 0.2608, 0.1196, 0.0202],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,401][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0075, 0.0108, 0.5871, 0.0103, 0.2356, 0.0799, 0.0352, 0.0336],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,403][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1191, 0.0542, 0.4885, 0.0508, 0.2025, 0.0558, 0.0149, 0.0142],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,404][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0518, 0.0600, 0.4282, 0.0498, 0.1814, 0.0868, 0.0412, 0.1009],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,405][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.7779e-03, 6.0053e-04, 7.3094e-03, 2.2832e-03, 6.3507e-01, 2.6510e-01,
        8.0714e-02, 7.1444e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,406][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([1.1732e-02, 6.3435e-03, 8.0229e-01, 4.7882e-03, 1.7131e-01, 1.6476e-03,
        5.5413e-04, 1.3341e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,407][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0823, 0.0288, 0.6324, 0.0293, 0.1754, 0.0300, 0.0123, 0.0095],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,409][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0020, 0.0025, 0.7163, 0.0022, 0.2086, 0.0351, 0.0144, 0.0064, 0.0125],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,410][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0007, 0.0024, 0.5619, 0.0020, 0.3629, 0.0279, 0.0129, 0.0032, 0.0261],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,412][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0256, 0.0263, 0.7482, 0.0209, 0.1420, 0.0159, 0.0057, 0.0055, 0.0100],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,413][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([6.8043e-02, 2.6450e-02, 7.7269e-01, 1.6454e-02, 1.0936e-01, 3.7142e-03,
        8.2786e-04, 5.4262e-04, 1.9165e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,414][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.2347, 0.0919, 0.4450, 0.0654, 0.1448, 0.0073, 0.0036, 0.0031, 0.0043],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,415][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0092, 0.0039, 0.0421, 0.0099, 0.7359, 0.0898, 0.0461, 0.0072, 0.0558],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,417][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0144, 0.0141, 0.7473, 0.0116, 0.1738, 0.0185, 0.0059, 0.0063, 0.0080],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,418][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1872, 0.0742, 0.4552, 0.0648, 0.1653, 0.0320, 0.0064, 0.0088, 0.0061],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,420][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0687, 0.0719, 0.5143, 0.0522, 0.1430, 0.0338, 0.0121, 0.0279, 0.0761],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,421][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0059, 0.0019, 0.0357, 0.0053, 0.8150, 0.0843, 0.0186, 0.0023, 0.0310],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,422][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([1.5397e-02, 6.8333e-03, 8.5331e-01, 4.5778e-03, 1.1640e-01, 5.1190e-04,
        1.4105e-04, 3.0592e-04, 2.5228e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,423][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1943, 0.0444, 0.6243, 0.0377, 0.0827, 0.0064, 0.0022, 0.0021, 0.0058],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,425][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0012, 0.0022, 0.5685, 0.0022, 0.2368, 0.0740, 0.0309, 0.0149, 0.0476,
        0.0217], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,426][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.2523e-04, 1.5876e-03, 4.1192e-01, 1.5726e-03, 3.8371e-01, 6.8525e-02,
        3.0623e-02, 6.8025e-03, 5.5730e-02, 3.9198e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,427][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0120, 0.0154, 0.6410, 0.0140, 0.2162, 0.0360, 0.0153, 0.0108, 0.0226,
        0.0165], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,428][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0455, 0.0241, 0.7022, 0.0180, 0.1900, 0.0083, 0.0023, 0.0017, 0.0052,
        0.0027], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,430][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1401, 0.0681, 0.4663, 0.0563, 0.1959, 0.0202, 0.0112, 0.0083, 0.0180,
        0.0157], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,431][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0062, 0.0028, 0.0501, 0.0069, 0.7643, 0.0664, 0.0235, 0.0050, 0.0301,
        0.0447], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,433][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0043, 0.0070, 0.5690, 0.0069, 0.2247, 0.0632, 0.0241, 0.0198, 0.0404,
        0.0405], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,434][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1108, 0.0539, 0.4794, 0.0506, 0.2033, 0.0457, 0.0138, 0.0112, 0.0104,
        0.0209], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,435][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0376, 0.0523, 0.3785, 0.0417, 0.1843, 0.0644, 0.0303, 0.0498, 0.1024,
        0.0586], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,437][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.0014, 0.0405, 0.0038, 0.8510, 0.0373, 0.0063, 0.0011, 0.0151,
        0.0397], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,438][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.1714e-02, 5.9100e-03, 8.0988e-01, 4.3964e-03, 1.5873e-01, 1.1555e-03,
        3.1978e-04, 6.1340e-04, 7.1484e-03, 1.3394e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,439][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0700, 0.0355, 0.5888, 0.0348, 0.1892, 0.0198, 0.0083, 0.0075, 0.0215,
        0.0246], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,440][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0012, 0.0019, 0.5525, 0.0019, 0.2466, 0.0725, 0.0328, 0.0141, 0.0439,
        0.0210, 0.0114], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,440][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0005, 0.0016, 0.4156, 0.0017, 0.4107, 0.0562, 0.0214, 0.0054, 0.0435,
        0.0296, 0.0137], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,441][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0219, 0.0215, 0.6149, 0.0196, 0.2340, 0.0277, 0.0116, 0.0102, 0.0194,
        0.0144, 0.0048], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,441][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.9331e-02, 2.4191e-02, 6.7361e-01, 1.8099e-02, 2.0874e-01, 6.9011e-03,
        1.4321e-03, 1.2962e-03, 4.2525e-03, 1.9061e-03, 2.3674e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,441][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1390, 0.0633, 0.4871, 0.0525, 0.1911, 0.0187, 0.0106, 0.0077, 0.0142,
        0.0132, 0.0027], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,442][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.9572e-03, 6.8421e-04, 1.8598e-02, 2.3217e-03, 8.4509e-01, 4.7769e-02,
        1.2606e-02, 1.6334e-03, 1.6219e-02, 3.2314e-02, 2.0804e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,442][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0050, 0.0065, 0.5844, 0.0066, 0.2310, 0.0522, 0.0206, 0.0161, 0.0302,
        0.0367, 0.0106], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,443][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1149, 0.0519, 0.4663, 0.0514, 0.2107, 0.0422, 0.0148, 0.0104, 0.0090,
        0.0193, 0.0090], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,444][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0467, 0.0521, 0.3793, 0.0423, 0.2029, 0.0561, 0.0220, 0.0521, 0.0855,
        0.0432, 0.0178], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,445][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.5976e-04, 1.6463e-04, 1.0355e-02, 6.6423e-04, 8.8350e-01, 3.1248e-02,
        5.0369e-03, 4.0556e-04, 1.0340e-02, 3.8208e-02, 1.9517e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,446][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.3805e-02, 5.3147e-03, 8.1396e-01, 4.1005e-03, 1.5651e-01, 9.9495e-04,
        2.4340e-04, 4.6009e-04, 4.5028e-03, 8.5078e-05, 2.0609e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,448][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0681, 0.0240, 0.6730, 0.0240, 0.1514, 0.0139, 0.0038, 0.0047, 0.0145,
        0.0164, 0.0062], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,449][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0026, 0.0045, 0.4394, 0.0042, 0.1919, 0.1069, 0.0619, 0.0264, 0.0675,
        0.0375, 0.0291, 0.0283], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,450][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0033, 0.3246, 0.0031, 0.2627, 0.1045, 0.0625, 0.0131, 0.0801,
        0.0601, 0.0463, 0.0390], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,452][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0140, 0.0204, 0.4991, 0.0184, 0.2058, 0.0672, 0.0368, 0.0199, 0.0413,
        0.0293, 0.0197, 0.0280], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,453][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0493, 0.0331, 0.6585, 0.0244, 0.1807, 0.0168, 0.0053, 0.0043, 0.0103,
        0.0060, 0.0014, 0.0099], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,455][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.1748, 0.0972, 0.3349, 0.0768, 0.1639, 0.0291, 0.0200, 0.0118, 0.0251,
        0.0286, 0.0081, 0.0296], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,456][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0047, 0.0033, 0.0363, 0.0064, 0.3354, 0.1829, 0.1002, 0.0207, 0.0811,
        0.1047, 0.1031, 0.0212], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,458][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0068, 0.0113, 0.4686, 0.0105, 0.1658, 0.0885, 0.0418, 0.0301, 0.0474,
        0.0531, 0.0250, 0.0512], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,459][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1448, 0.0858, 0.3769, 0.0770, 0.1556, 0.0447, 0.0186, 0.0153, 0.0125,
        0.0237, 0.0122, 0.0329], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,461][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0495, 0.0641, 0.2589, 0.0521, 0.1412, 0.0710, 0.0444, 0.0491, 0.0980,
        0.0563, 0.0368, 0.0785], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,462][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0024, 0.0018, 0.0402, 0.0040, 0.3701, 0.1450, 0.0628, 0.0075, 0.0717,
        0.1315, 0.1311, 0.0319], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,463][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.4377e-02, 1.0003e-02, 7.5236e-01, 7.6945e-03, 1.7130e-01, 5.6106e-03,
        2.6294e-03, 2.8918e-03, 2.5430e-02, 1.0079e-03, 4.7922e-04, 6.2210e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,465][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0624, 0.0385, 0.4843, 0.0371, 0.1350, 0.0307, 0.0251, 0.0121, 0.0311,
        0.0406, 0.0335, 0.0697], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,466][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0008, 0.0019, 0.3659, 0.0019, 0.1747, 0.1413, 0.0840, 0.0254, 0.0758,
        0.0420, 0.0356, 0.0211, 0.0296], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,467][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([1.7324e-04, 1.0882e-03, 2.2677e-01, 1.0723e-03, 2.0113e-01, 1.6134e-01,
        1.0414e-01, 1.4205e-02, 8.4054e-02, 7.0968e-02, 7.2247e-02, 2.5332e-02,
        3.7479e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,468][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0058, 0.0112, 0.4503, 0.0100, 0.1819, 0.0903, 0.0447, 0.0223, 0.0447,
        0.0327, 0.0258, 0.0234, 0.0568], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,470][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0189, 0.0177, 0.6978, 0.0132, 0.1636, 0.0226, 0.0086, 0.0045, 0.0127,
        0.0073, 0.0017, 0.0100, 0.0214], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,472][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.1172, 0.0742, 0.2966, 0.0599, 0.1578, 0.0498, 0.0376, 0.0198, 0.0306,
        0.0409, 0.0149, 0.0367, 0.0640], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,473][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0199, 0.0149, 0.0896, 0.0217, 0.3219, 0.0939, 0.0599, 0.0294, 0.0683,
        0.0888, 0.0555, 0.0378, 0.0984], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,475][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0024, 0.0052, 0.3567, 0.0052, 0.1634, 0.1196, 0.0610, 0.0345, 0.0729,
        0.0625, 0.0378, 0.0382, 0.0406], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,476][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0767, 0.0484, 0.3774, 0.0425, 0.2136, 0.0468, 0.0180, 0.0155, 0.0174,
        0.0250, 0.0128, 0.0157, 0.0902], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,477][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0156, 0.0239, 0.2918, 0.0200, 0.1439, 0.0769, 0.0502, 0.0442, 0.0985,
        0.0669, 0.0438, 0.0525, 0.0718], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,479][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0199, 0.0162, 0.1286, 0.0233, 0.3596, 0.0528, 0.0208, 0.0093, 0.0493,
        0.0973, 0.0464, 0.0565, 0.1199], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,480][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0093, 0.0077, 0.7148, 0.0065, 0.1984, 0.0096, 0.0048, 0.0042, 0.0297,
        0.0015, 0.0008, 0.0059, 0.0068], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,482][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0151, 0.0146, 0.3469, 0.0153, 0.1339, 0.0733, 0.0682, 0.0195, 0.0527,
        0.0679, 0.0681, 0.0570, 0.0674], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,483][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0006, 0.0012, 0.4359, 0.0013, 0.2040, 0.1093, 0.0520, 0.0213, 0.0747,
        0.0306, 0.0208, 0.0177, 0.0200, 0.0104], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,484][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.8735e-04, 1.0305e-03, 2.7223e-01, 1.0676e-03, 3.3327e-01, 1.0353e-01,
        4.7499e-02, 9.7985e-03, 7.8942e-02, 4.9006e-02, 3.3716e-02, 2.0638e-02,
        3.2610e-02, 1.6477e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,486][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0110, 0.0153, 0.5078, 0.0143, 0.2316, 0.0471, 0.0223, 0.0142, 0.0270,
        0.0210, 0.0102, 0.0176, 0.0502, 0.0104], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,487][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([3.1656e-02, 1.8474e-02, 6.8659e-01, 1.4255e-02, 1.9272e-01, 1.3085e-02,
        3.3141e-03, 2.7972e-03, 6.6036e-03, 3.5313e-03, 5.4627e-04, 6.3784e-03,
        1.7268e-02, 2.7788e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,487][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.1114, 0.0549, 0.3892, 0.0498, 0.2100, 0.0279, 0.0166, 0.0106, 0.0197,
        0.0242, 0.0067, 0.0244, 0.0467, 0.0078], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,488][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0015, 0.0007, 0.0119, 0.0021, 0.4076, 0.1593, 0.0747, 0.0103, 0.0580,
        0.0963, 0.1098, 0.0118, 0.0434, 0.0126], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,488][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0034, 0.0058, 0.4181, 0.0059, 0.2111, 0.0946, 0.0391, 0.0234, 0.0453,
        0.0510, 0.0197, 0.0356, 0.0322, 0.0149], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,488][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0870, 0.0445, 0.4047, 0.0428, 0.1798, 0.0592, 0.0200, 0.0141, 0.0138,
        0.0274, 0.0134, 0.0141, 0.0585, 0.0207], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,489][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0244, 0.0321, 0.2926, 0.0267, 0.1515, 0.0825, 0.0352, 0.0418, 0.0859,
        0.0517, 0.0261, 0.0614, 0.0566, 0.0315], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,489][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([5.7265e-04, 2.1292e-04, 7.8384e-03, 7.7282e-04, 5.0616e-01, 1.1649e-01,
        3.1725e-02, 3.0884e-03, 4.2843e-02, 1.1384e-01, 1.0432e-01, 1.4636e-02,
        4.9207e-02, 8.2917e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,490][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([7.8623e-03, 5.0360e-03, 7.6706e-01, 3.9519e-03, 1.8754e-01, 3.5064e-03,
        1.1182e-03, 1.6103e-03, 1.5034e-02, 3.7796e-04, 1.1219e-04, 2.0951e-03,
        2.9165e-03, 1.7779e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,491][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0570, 0.0279, 0.4575, 0.0285, 0.1415, 0.0381, 0.0169, 0.0120, 0.0354,
        0.0426, 0.0217, 0.0503, 0.0528, 0.0177], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,493][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0008, 0.0013, 0.5530, 0.0013, 0.2442, 0.0606, 0.0262, 0.0105, 0.0381,
        0.0156, 0.0071, 0.0126, 0.0177, 0.0051, 0.0060], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,494][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3693e-04, 9.8408e-04, 4.2410e-01, 9.4468e-04, 3.6997e-01, 4.5144e-02,
        2.0221e-02, 3.9746e-03, 3.9261e-02, 2.3871e-02, 1.0744e-02, 1.4928e-02,
        2.5577e-02, 7.5594e-03, 1.2484e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,495][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0087, 0.0100, 0.6142, 0.0090, 0.2085, 0.0292, 0.0124, 0.0077, 0.0178,
        0.0117, 0.0053, 0.0135, 0.0433, 0.0062, 0.0025], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,496][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.1929e-02, 1.3464e-02, 7.3070e-01, 9.8053e-03, 1.8552e-01, 6.6740e-03,
        1.2945e-03, 9.6291e-04, 2.8627e-03, 1.3482e-03, 1.4850e-04, 3.5634e-03,
        1.0309e-02, 1.1783e-03, 2.4018e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,498][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1157, 0.0493, 0.3948, 0.0426, 0.2221, 0.0278, 0.0180, 0.0090, 0.0238,
        0.0195, 0.0045, 0.0269, 0.0358, 0.0060, 0.0041], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,498][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.3323e-04, 1.5675e-04, 5.2870e-03, 6.6050e-04, 5.9788e-01, 1.3395e-01,
        4.2180e-02, 3.9730e-03, 3.3487e-02, 6.5612e-02, 7.2145e-02, 4.8670e-03,
        3.0627e-02, 5.5498e-03, 3.1893e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,500][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0032, 0.0043, 0.5920, 0.0042, 0.2183, 0.0415, 0.0147, 0.0107, 0.0257,
        0.0234, 0.0059, 0.0217, 0.0239, 0.0057, 0.0049], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,502][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0966, 0.0404, 0.4418, 0.0399, 0.1882, 0.0408, 0.0133, 0.0086, 0.0080,
        0.0172, 0.0076, 0.0128, 0.0607, 0.0129, 0.0111], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,503][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0249, 0.0334, 0.3503, 0.0256, 0.1669, 0.0511, 0.0197, 0.0377, 0.0617,
        0.0310, 0.0138, 0.0975, 0.0580, 0.0192, 0.0092], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,504][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.4447e-05, 1.8341e-05, 2.3388e-03, 9.8851e-05, 6.0314e-01, 1.1452e-01,
        2.3491e-02, 1.0060e-03, 3.0188e-02, 8.7913e-02, 9.4274e-02, 6.2756e-03,
        3.0775e-02, 2.7774e-03, 3.1368e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,505][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.1348e-02, 3.8380e-03, 8.3317e-01, 2.7217e-03, 1.4183e-01, 6.2912e-04,
        1.5838e-04, 2.8490e-04, 3.9078e-03, 4.6422e-05, 1.0004e-05, 7.1627e-04,
        9.2957e-04, 4.0988e-04, 3.3607e-06], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,507][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0612, 0.0190, 0.6039, 0.0192, 0.1391, 0.0144, 0.0054, 0.0049, 0.0164,
        0.0169, 0.0068, 0.0391, 0.0390, 0.0061, 0.0086], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,508][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:08,510][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10303],
        [ 4793],
        [  147],
        [  527],
        [   20],
        [   18],
        [    4],
        [    3],
        [   11],
        [    6],
        [    3],
        [    7],
        [    7],
        [    2],
        [    1]], device='cuda:0')
[2024-07-24 10:24:08,511][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[9792],
        [4655],
        [  18],
        [ 290],
        [   4],
        [   5],
        [   2],
        [   1],
        [   2],
        [   3],
        [   1],
        [   5],
        [   3],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:24:08,513][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 8596],
        [ 1653],
        [50250],
        [50247],
        [50208],
        [50147],
        [49201],
        [48804],
        [50101],
        [49174],
        [48942],
        [45294],
        [39114],
        [45121],
        [49062]], device='cuda:0')
[2024-07-24 10:24:08,514][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5824],
        [ 6237],
        [50127],
        [50099],
        [47510],
        [46438],
        [41808],
        [45643],
        [48079],
        [43892],
        [44240],
        [40025],
        [32976],
        [36078],
        [44786]], device='cuda:0')
[2024-07-24 10:24:08,515][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5445],
        [ 6558],
        [50254],
        [50255],
        [50227],
        [50045],
        [49715],
        [49974],
        [49193],
        [49479],
        [48777],
        [45463],
        [46879],
        [47963],
        [48613]], device='cuda:0')
[2024-07-24 10:24:08,517][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[37210],
        [29906],
        [31012],
        [31241],
        [29815],
        [ 9864],
        [ 7680],
        [ 6816],
        [ 6663],
        [ 6425],
        [ 5467],
        [ 6583],
        [ 6587],
        [ 6164],
        [ 5780]], device='cuda:0')
[2024-07-24 10:24:08,518][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[19105],
        [22257],
        [ 6695],
        [ 9633],
        [ 5352],
        [ 6018],
        [ 5988],
        [ 6096],
        [ 7028],
        [ 5855],
        [ 6721],
        [ 7996],
        [ 6283],
        [ 6062],
        [ 6024]], device='cuda:0')
[2024-07-24 10:24:08,520][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[13857],
        [17827],
        [19253],
        [18813],
        [20055],
        [17934],
        [17982],
        [19371],
        [20244],
        [20056],
        [19615],
        [19780],
        [20522],
        [20023],
        [20265]], device='cuda:0')
[2024-07-24 10:24:08,521][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24266],
        [17846],
        [45223],
        [45151],
        [39846],
        [32033],
        [30491],
        [29228],
        [30890],
        [30157],
        [32053],
        [31603],
        [31377],
        [31301],
        [32624]], device='cuda:0')
[2024-07-24 10:24:08,523][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45580],
        [29325],
        [  537],
        [  631],
        [ 5255],
        [ 7428],
        [ 9264],
        [12985],
        [21913],
        [19882],
        [21234],
        [24009],
        [23483],
        [24954],
        [27057]], device='cuda:0')
[2024-07-24 10:24:08,524][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24513],
        [18234],
        [ 3930],
        [ 4789],
        [ 4350],
        [ 4458],
        [ 4898],
        [ 4899],
        [ 4298],
        [ 4548],
        [ 4510],
        [ 4821],
        [ 4610],
        [ 4735],
        [ 4454]], device='cuda:0')
[2024-07-24 10:24:08,525][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20931],
        [26644],
        [31281],
        [39293],
        [45878],
        [48749],
        [48739],
        [48504],
        [48628],
        [48628],
        [48606],
        [46879],
        [47202],
        [47445],
        [47836]], device='cuda:0')
[2024-07-24 10:24:08,527][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13064],
        [ 9158],
        [49982],
        [49921],
        [49640],
        [49754],
        [49600],
        [49574],
        [49759],
        [49598],
        [49619],
        [49267],
        [48956],
        [49316],
        [49684]], device='cuda:0')
[2024-07-24 10:24:08,528][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29626],
        [30978],
        [43337],
        [42777],
        [42376],
        [42522],
        [42108],
        [41971],
        [42581],
        [41447],
        [42083],
        [39256],
        [35263],
        [39185],
        [41605]], device='cuda:0')
[2024-07-24 10:24:08,530][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[23339],
        [14889],
        [27005],
        [ 5510],
        [27181],
        [22855],
        [17025],
        [27591],
        [30320],
        [14954],
        [19694],
        [16354],
        [26470],
        [26114],
        [13835]], device='cuda:0')
[2024-07-24 10:24:08,531][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23596],
        [15303],
        [27067],
        [27448],
        [28428],
        [28105],
        [28538],
        [28350],
        [28679],
        [29249],
        [29317],
        [29399],
        [29419],
        [29435],
        [29321]], device='cuda:0')
[2024-07-24 10:24:08,532][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[37591],
        [22782],
        [22468],
        [23035],
        [29613],
        [28150],
        [26704],
        [26048],
        [26958],
        [24181],
        [25234],
        [19256],
        [15687],
        [20164],
        [25324]], device='cuda:0')
[2024-07-24 10:24:08,534][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37135],
        [33304],
        [18520],
        [17590],
        [14836],
        [15496],
        [14857],
        [16235],
        [16679],
        [16162],
        [15650],
        [17264],
        [17379],
        [15380],
        [15249]], device='cuda:0')
[2024-07-24 10:24:08,535][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[30354],
        [27881],
        [30435],
        [29735],
        [29793],
        [29720],
        [29332],
        [29355],
        [29823],
        [29150],
        [28904],
        [29378],
        [29664],
        [29206],
        [29277]], device='cuda:0')
[2024-07-24 10:24:08,537][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[11854],
        [13266],
        [ 3871],
        [ 5465],
        [ 2593],
        [ 2391],
        [ 2340],
        [ 2562],
        [ 2532],
        [ 2882],
        [ 2804],
        [ 4475],
        [ 5830],
        [ 3572],
        [ 3501]], device='cuda:0')
[2024-07-24 10:24:08,538][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[29515],
        [28926],
        [22032],
        [21829],
        [17180],
        [15827],
        [15992],
        [16792],
        [17135],
        [17025],
        [16756],
        [20874],
        [20793],
        [20429],
        [18539]], device='cuda:0')
[2024-07-24 10:24:08,538][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[11796],
        [ 7187],
        [28039],
        [27810],
        [28957],
        [28544],
        [27450],
        [27917],
        [28565],
        [27002],
        [27432],
        [24944],
        [22611],
        [24537],
        [27428]], device='cuda:0')
[2024-07-24 10:24:08,540][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24872],
        [27229],
        [34989],
        [34462],
        [34885],
        [34814],
        [34317],
        [34243],
        [34303],
        [33823],
        [33673],
        [32372],
        [32128],
        [32016],
        [32862]], device='cuda:0')
[2024-07-24 10:24:08,541][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18910],
        [15724],
        [24449],
        [22484],
        [24969],
        [24110],
        [23501],
        [23465],
        [24357],
        [23810],
        [23804],
        [23333],
        [23415],
        [23549],
        [24496]], device='cuda:0')
[2024-07-24 10:24:08,542][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[45748],
        [42939],
        [41954],
        [36196],
        [30341],
        [15770],
        [15276],
        [14050],
        [15217],
        [15238],
        [14821],
        [12957],
        [15576],
        [13410],
        [13579]], device='cuda:0')
[2024-07-24 10:24:08,544][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[12922],
        [17868],
        [15279],
        [15890],
        [16962],
        [16664],
        [17177],
        [17271],
        [16659],
        [17251],
        [17155],
        [18333],
        [19172],
        [18059],
        [16992]], device='cuda:0')
[2024-07-24 10:24:08,545][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[20389],
        [22736],
        [15603],
        [16830],
        [17082],
        [16592],
        [17220],
        [17308],
        [17209],
        [17808],
        [16703],
        [19270],
        [23017],
        [20058],
        [17393]], device='cuda:0')
[2024-07-24 10:24:08,546][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10377],
        [16733],
        [11031],
        [11703],
        [14249],
        [18028],
        [19108],
        [18316],
        [16436],
        [17887],
        [18437],
        [16863],
        [16286],
        [18147],
        [17543]], device='cuda:0')
[2024-07-24 10:24:08,548][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[16761],
        [27201],
        [30997],
        [40994],
        [26113],
        [32488],
        [31998],
        [28931],
        [31598],
        [33279],
        [32285],
        [31781],
        [26372],
        [28044],
        [30277]], device='cuda:0')
[2024-07-24 10:24:08,549][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964],
        [20964]], device='cuda:0')
[2024-07-24 10:24:08,611][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:08,612][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,613][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,614][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,614][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,615][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,615][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,615][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,616][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,616][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,616][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,616][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,617][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,617][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6514, 0.3486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,617][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5166, 0.4834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,618][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3388, 0.6612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,618][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4616, 0.5384], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,618][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3325, 0.6675], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,619][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3607, 0.6393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,619][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2783, 0.7217], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,619][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4349, 0.5651], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,620][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8668, 0.1332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,621][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2919, 0.7081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,622][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3816, 0.6184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,624][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5550, 0.4450], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,625][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Heather] are: tensor([0.4948, 0.2887, 0.2165], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,626][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Heather] are: tensor([0.7320, 0.2117, 0.0564], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,626][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Heather] are: tensor([0.1048, 0.1187, 0.7766], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,626][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Heather] are: tensor([0.6547, 0.3090, 0.0363], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,627][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Heather] are: tensor([0.0255, 0.0324, 0.9420], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,627][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Heather] are: tensor([0.6205, 0.3087, 0.0707], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,627][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Heather] are: tensor([0.2632, 0.1855, 0.5513], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,628][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Heather] are: tensor([0.3233, 0.2097, 0.4670], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,628][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Heather] are: tensor([1.8364e-04, 9.9843e-01, 1.3827e-03], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,628][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Heather] are: tensor([0.0433, 0.2007, 0.7559], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,629][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Heather] are: tensor([0.2655, 0.0757, 0.6588], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,629][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Heather] are: tensor([0.4193, 0.0736, 0.5071], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,629][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4200, 0.2251, 0.1326, 0.2223], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,630][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2707, 0.2617, 0.1797, 0.2879], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,630][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1114, 0.2116, 0.4183, 0.2586], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,630][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2079, 0.2247, 0.2619, 0.3055], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,631][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0853, 0.1690, 0.5100, 0.2357], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,631][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1034, 0.2014, 0.4505, 0.2448], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,631][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0517, 0.1655, 0.6052, 0.1776], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,632][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1623, 0.2075, 0.4106, 0.2196], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,632][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6370, 0.1303, 0.1046, 0.1282], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,632][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0973, 0.2219, 0.4317, 0.2491], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,633][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0815, 0.1243, 0.6287, 0.1655], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,633][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1051, 0.0854, 0.7055, 0.1040], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,633][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.2316, 0.1121, 0.5157, 0.0879, 0.0527], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,634][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.3563, 0.1745, 0.2186, 0.1295, 0.1211], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,634][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0749, 0.0753, 0.5593, 0.0687, 0.2218], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,634][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.2352, 0.1034, 0.5707, 0.0542, 0.0365], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,635][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0043, 0.0047, 0.7218, 0.0042, 0.2650], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,636][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.3436, 0.2494, 0.1481, 0.1504, 0.1085], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,638][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0876, 0.0865, 0.4151, 0.0845, 0.3262], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,639][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1195, 0.0866, 0.4650, 0.0700, 0.2590], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,640][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0046, 0.5987, 0.0202, 0.3657, 0.0108], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,642][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0200, 0.0874, 0.4389, 0.0891, 0.3646], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,643][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0681, 0.0184, 0.8589, 0.0107, 0.0439], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,645][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0387, 0.0091, 0.9276, 0.0046, 0.0199], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,646][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0474, 0.0291, 0.5843, 0.0319, 0.2750, 0.0322], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,648][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0491, 0.0161, 0.5522, 0.0154, 0.3664, 0.0008], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,649][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0041, 0.0041, 0.6988, 0.0043, 0.2347, 0.0539], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,650][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0033, 0.0010, 0.2463, 0.0013, 0.7446, 0.0034], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,651][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([1.8699e-04, 2.7045e-04, 5.9193e-01, 2.8391e-04, 3.5532e-01, 5.2013e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,653][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1674, 0.1580, 0.2476, 0.0980, 0.1551, 0.1739], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,654][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0524, 0.0431, 0.3405, 0.0573, 0.3491, 0.1575], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,655][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0372, 0.0262, 0.5690, 0.0217, 0.3226, 0.0233], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,656][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([2.7301e-04, 5.4804e-01, 2.4205e-02, 3.9146e-01, 3.4122e-02, 1.8961e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,656][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0084, 0.0361, 0.1514, 0.0396, 0.1750, 0.5896], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,657][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([4.8854e-03, 7.0645e-04, 7.8751e-01, 6.7255e-04, 2.0588e-01, 3.4119e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,657][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([2.7297e-03, 4.1124e-04, 9.4265e-01, 3.5496e-04, 5.3839e-02, 1.3532e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,657][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0158, 0.0114, 0.5693, 0.0134, 0.2832, 0.0817, 0.0252],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,658][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.9884e-02, 1.7282e-02, 5.9982e-01, 1.5686e-02, 2.8647e-01, 6.7079e-04,
        1.8855e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,658][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0022, 0.0025, 0.4722, 0.0030, 0.3084, 0.1556, 0.0560],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,658][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.1987e-04, 6.5614e-05, 7.9295e-02, 1.1216e-04, 9.1690e-01, 3.0903e-03,
        3.1242e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,659][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([4.6409e-05, 8.0742e-05, 4.0949e-01, 9.3520e-05, 4.2763e-01, 9.1656e-02,
        7.1004e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,660][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4980, 0.2379, 0.0439, 0.1369, 0.0231, 0.0567, 0.0034],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,661][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0504, 0.0399, 0.2995, 0.0564, 0.3465, 0.1244, 0.0829],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,662][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0347, 0.0239, 0.4986, 0.0212, 0.3411, 0.0337, 0.0468],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,663][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.1266e-04, 4.9640e-01, 2.7918e-02, 3.9287e-01, 6.5550e-02, 6.4779e-03,
        1.0671e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,665][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0045, 0.0182, 0.0676, 0.0204, 0.0934, 0.3638, 0.4322],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,665][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.6968e-03, 3.0914e-04, 5.9890e-01, 3.7085e-04, 3.9773e-01, 7.9183e-04,
        2.0311e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,666][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.8746e-04, 9.6571e-05, 8.5901e-01, 1.0547e-04, 1.4009e-01, 1.0098e-04,
        3.9490e-06], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,668][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0327, 0.0159, 0.5459, 0.0189, 0.2848, 0.0585, 0.0192, 0.0240],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,669][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0602, 0.0210, 0.4269, 0.0190, 0.4589, 0.0041, 0.0051, 0.0048],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,671][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0047, 0.0055, 0.4693, 0.0061, 0.3446, 0.1006, 0.0359, 0.0333],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,672][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([3.8648e-04, 1.2740e-04, 6.8023e-02, 2.2268e-04, 9.0066e-01, 2.2885e-02,
        5.3944e-03, 2.2984e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,672][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([1.0849e-04, 1.7093e-04, 5.5036e-01, 1.9060e-04, 3.2214e-01, 6.3985e-02,
        4.8140e-02, 1.4908e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,674][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1586, 0.1503, 0.1921, 0.0900, 0.1065, 0.1975, 0.0271, 0.0779],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,675][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0317, 0.0314, 0.2023, 0.0428, 0.3684, 0.1037, 0.0719, 0.1477],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,677][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0296, 0.0220, 0.4781, 0.0204, 0.3311, 0.0330, 0.0435, 0.0423],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,677][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([1.4263e-04, 5.4084e-01, 1.7861e-02, 3.8560e-01, 2.9774e-02, 6.6974e-03,
        1.5969e-02, 3.1147e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,679][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0032, 0.0144, 0.0711, 0.0162, 0.0915, 0.3048, 0.3146, 0.1842],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,680][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([1.1095e-03, 2.5328e-04, 7.4581e-01, 2.8704e-04, 2.5101e-01, 9.6652e-04,
        1.1844e-04, 4.4123e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,681][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([9.8511e-04, 1.9799e-04, 8.7227e-01, 2.1318e-04, 1.2609e-01, 2.0356e-04,
        1.2695e-05, 3.3911e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,682][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0456, 0.0255, 0.5075, 0.0283, 0.2602, 0.0671, 0.0239, 0.0251, 0.0170],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,683][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0192, 0.0112, 0.6140, 0.0081, 0.3362, 0.0022, 0.0041, 0.0038, 0.0012],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,685][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0062, 0.0075, 0.5977, 0.0070, 0.3163, 0.0322, 0.0097, 0.0097, 0.0137],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,686][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0025, 0.0009, 0.4558, 0.0010, 0.5310, 0.0043, 0.0006, 0.0007, 0.0032],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,687][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([2.3803e-04, 3.6035e-04, 8.2673e-01, 3.0292e-04, 1.4951e-01, 1.1878e-02,
        5.6253e-03, 2.6161e-03, 2.7360e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,689][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0976, 0.0977, 0.2039, 0.0575, 0.0720, 0.1883, 0.0230, 0.0562, 0.2038],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,690][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0532, 0.0429, 0.2067, 0.0508, 0.2158, 0.0864, 0.0725, 0.1315, 0.1401],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,692][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0287, 0.0228, 0.5448, 0.0193, 0.3263, 0.0159, 0.0145, 0.0128, 0.0150],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,693][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([4.3308e-04, 5.5821e-01, 4.5496e-02, 3.2413e-01, 4.1357e-02, 4.6072e-03,
        9.4362e-03, 1.9141e-03, 1.4419e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,694][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0042, 0.0183, 0.0659, 0.0192, 0.0793, 0.2868, 0.2775, 0.1909, 0.0580],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,695][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([4.8648e-03, 7.8562e-04, 8.7568e-01, 6.5896e-04, 1.1782e-01, 6.5991e-05,
        7.5528e-06, 7.0905e-05, 5.2150e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,696][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.0788e-03, 2.5495e-04, 9.4786e-01, 1.8906e-04, 5.0549e-02, 1.7239e-05,
        1.3946e-06, 6.7731e-06, 3.9235e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,697][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0175, 0.0112, 0.5703, 0.0129, 0.2475, 0.0534, 0.0193, 0.0226, 0.0198,
        0.0255], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,698][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.0511e-02, 2.5070e-02, 7.3739e-01, 2.2581e-02, 1.2169e-01, 1.1301e-03,
        6.0016e-04, 3.1174e-04, 3.6572e-04, 3.4925e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,700][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0024, 0.0032, 0.5198, 0.0038, 0.2924, 0.0702, 0.0195, 0.0225, 0.0457,
        0.0206], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,701][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.1065e-04, 7.4926e-05, 1.7463e-01, 1.1963e-04, 8.1436e-01, 4.9975e-03,
        5.2462e-04, 4.7344e-04, 3.8560e-03, 7.4881e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,702][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([5.1594e-05, 1.1693e-04, 5.3615e-01, 1.2394e-04, 2.9505e-01, 7.2570e-02,
        4.7602e-02, 1.3903e-02, 1.4225e-02, 2.0208e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,703][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3492, 0.2141, 0.0869, 0.1321, 0.0242, 0.0553, 0.0104, 0.0139, 0.0957,
        0.0182], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,703][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0271, 0.0280, 0.2868, 0.0337, 0.2486, 0.0695, 0.0563, 0.0897, 0.1189,
        0.0413], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,704][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0192, 0.0155, 0.5277, 0.0151, 0.3143, 0.0281, 0.0238, 0.0181, 0.0256,
        0.0126], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,704][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0007, 0.4940, 0.0506, 0.3694, 0.0677, 0.0028, 0.0030, 0.0013, 0.0076,
        0.0030], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,705][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0032, 0.0141, 0.0541, 0.0149, 0.0652, 0.2110, 0.2223, 0.1185, 0.0485,
        0.2483], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,705][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.6356e-03, 3.5454e-04, 6.7458e-01, 3.9618e-04, 3.2176e-01, 3.1382e-04,
        4.2351e-05, 1.6298e-04, 2.2036e-04, 5.3358e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,705][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([7.0764e-04, 1.6266e-04, 9.1795e-01, 1.5194e-04, 8.0905e-02, 4.3703e-05,
        2.9019e-06, 1.0582e-05, 5.2748e-05, 1.1013e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,706][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0062, 0.0042, 0.5390, 0.0054, 0.2678, 0.0636, 0.0236, 0.0249, 0.0263,
        0.0205, 0.0186], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,706][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.5396e-02, 1.5611e-02, 8.1382e-01, 1.2586e-02, 1.0717e-01, 1.3147e-03,
        2.0823e-03, 5.5666e-04, 6.8171e-04, 5.7168e-04, 2.1357e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,708][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0016, 0.0020, 0.5409, 0.0025, 0.2562, 0.0792, 0.0252, 0.0227, 0.0436,
        0.0169, 0.0093], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,708][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.0128e-05, 7.3611e-06, 6.1252e-02, 1.4711e-05, 9.3134e-01, 3.4546e-03,
        3.9675e-04, 3.0754e-04, 2.6112e-03, 5.0765e-04, 8.5718e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,709][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([4.6248e-05, 9.8759e-05, 5.1289e-01, 1.0958e-04, 3.0725e-01, 7.4461e-02,
        4.8503e-02, 1.5421e-02, 1.4509e-02, 1.9300e-02, 7.4105e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,711][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1777, 0.1446, 0.0807, 0.0889, 0.0395, 0.1094, 0.0127, 0.0304, 0.2607,
        0.0407, 0.0148], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,712][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0244, 0.0260, 0.2286, 0.0304, 0.1746, 0.0892, 0.0835, 0.1053, 0.1293,
        0.0549, 0.0539], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,713][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0214, 0.0159, 0.5569, 0.0151, 0.2896, 0.0221, 0.0238, 0.0176, 0.0206,
        0.0090, 0.0077], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,714][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([3.3092e-04, 4.1119e-01, 5.8843e-02, 3.5196e-01, 1.2925e-01, 7.1664e-03,
        8.9338e-03, 2.3039e-03, 1.9907e-02, 6.7851e-03, 3.3259e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,715][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0022, 0.0091, 0.0319, 0.0099, 0.0471, 0.1677, 0.1971, 0.1160, 0.0414,
        0.2080, 0.1697], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,716][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.6803e-04, 2.0712e-04, 5.0694e-01, 2.8053e-04, 4.8850e-01, 7.4600e-04,
        1.8040e-04, 3.1244e-04, 5.8169e-04, 1.1557e-03, 1.2851e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,717][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.7518e-04, 4.8023e-05, 8.4382e-01, 5.2885e-05, 1.5561e-01, 7.9270e-05,
        7.4220e-06, 2.3019e-05, 1.5069e-04, 2.3850e-05, 1.7503e-06],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,718][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0836, 0.0424, 0.5720, 0.0442, 0.1684, 0.0261, 0.0086, 0.0082, 0.0100,
        0.0122, 0.0110, 0.0132], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,719][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([5.9793e-02, 3.0096e-02, 5.3874e-01, 1.9995e-02, 3.2716e-01, 8.5159e-03,
        4.6100e-03, 1.5111e-03, 1.7418e-03, 1.7038e-03, 5.2842e-04, 5.6059e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,721][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0063, 0.0083, 0.2928, 0.0100, 0.2847, 0.1207, 0.0580, 0.0369, 0.0710,
        0.0497, 0.0356, 0.0260], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,722][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0016, 0.0008, 0.1528, 0.0011, 0.7710, 0.0251, 0.0086, 0.0053, 0.0243,
        0.0048, 0.0024, 0.0022], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,723][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([2.5717e-04, 4.6488e-04, 5.5869e-01, 4.4466e-04, 2.0055e-01, 8.2669e-02,
        7.6060e-02, 1.4694e-02, 1.6709e-02, 2.5911e-02, 1.3766e-02, 9.7836e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,725][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0935, 0.1007, 0.0986, 0.0533, 0.0266, 0.1512, 0.0163, 0.0349, 0.2335,
        0.0527, 0.0277, 0.1111], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,726][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0323, 0.0281, 0.3370, 0.0288, 0.2020, 0.0465, 0.0514, 0.0661, 0.0909,
        0.0280, 0.0256, 0.0634], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,728][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0306, 0.0243, 0.4682, 0.0240, 0.2751, 0.0375, 0.0319, 0.0202, 0.0239,
        0.0145, 0.0108, 0.0389], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,729][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0083, 0.1716, 0.1954, 0.1626, 0.2360, 0.0294, 0.0358, 0.0101, 0.0644,
        0.0170, 0.0097, 0.0597], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,730][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0038, 0.0148, 0.0394, 0.0139, 0.0566, 0.1616, 0.1848, 0.0929, 0.0429,
        0.1934, 0.1535, 0.0423], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,731][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.6371e-03, 6.7701e-04, 5.7366e-01, 7.1240e-04, 4.1077e-01, 3.1798e-03,
        1.7377e-03, 9.0590e-04, 1.1019e-03, 2.7842e-03, 4.4123e-04, 2.3916e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,732][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([6.2255e-04, 2.5212e-04, 8.6503e-01, 2.3156e-04, 1.3181e-01, 8.3295e-04,
        1.5454e-04, 1.3542e-04, 5.9223e-04, 9.7757e-05, 2.1499e-05, 2.1495e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,734][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0921, 0.0536, 0.5089, 0.0532, 0.1414, 0.0403, 0.0122, 0.0103, 0.0100,
        0.0180, 0.0155, 0.0124, 0.0321], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,735][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0263, 0.0191, 0.3702, 0.0185, 0.3177, 0.0623, 0.0378, 0.0128, 0.0153,
        0.0561, 0.0287, 0.0239, 0.0115], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,737][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0059, 0.0083, 0.2937, 0.0098, 0.2654, 0.1117, 0.0508, 0.0380, 0.0702,
        0.0531, 0.0313, 0.0214, 0.0405], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,738][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0119, 0.0064, 0.3395, 0.0066, 0.5368, 0.0250, 0.0103, 0.0071, 0.0186,
        0.0100, 0.0039, 0.0042, 0.0198], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,739][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([1.2094e-04, 2.6878e-04, 4.4388e-01, 2.8189e-04, 2.5693e-01, 1.1012e-01,
        9.5622e-02, 1.4878e-02, 1.5768e-02, 3.2685e-02, 1.4457e-02, 8.3650e-03,
        6.6299e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,741][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1307, 0.0948, 0.0847, 0.0666, 0.0475, 0.0873, 0.0120, 0.0277, 0.1465,
        0.0480, 0.0306, 0.1441, 0.0796], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,742][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0187, 0.0146, 0.1817, 0.0184, 0.1967, 0.0426, 0.0341, 0.0529, 0.0630,
        0.0199, 0.0242, 0.0606, 0.2726], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,744][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0206, 0.0188, 0.3421, 0.0182, 0.2706, 0.0700, 0.0669, 0.0267, 0.0322,
        0.0266, 0.0215, 0.0382, 0.0475], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,745][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0055, 0.1893, 0.2309, 0.1453, 0.1599, 0.0159, 0.0226, 0.0062, 0.0346,
        0.0108, 0.0060, 0.0503, 0.1227], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,746][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0029, 0.0134, 0.0552, 0.0138, 0.0656, 0.1608, 0.1501, 0.0809, 0.0418,
        0.1882, 0.1371, 0.0329, 0.0574], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,747][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([2.1009e-03, 1.0705e-03, 7.2035e-01, 1.0100e-03, 2.4034e-01, 2.1270e-03,
        1.0618e-03, 8.2403e-04, 7.3310e-04, 2.3831e-03, 2.6228e-04, 1.4377e-03,
        2.6301e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,748][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([1.7281e-03, 8.3586e-04, 8.5874e-01, 6.4473e-04, 1.3296e-01, 6.6079e-04,
        1.8920e-04, 2.9366e-04, 9.1382e-04, 1.7984e-04, 3.2001e-05, 2.4164e-04,
        2.5765e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,750][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0232, 0.0126, 0.3432, 0.0161, 0.3799, 0.0425, 0.0170, 0.0184, 0.0232,
        0.0211, 0.0218, 0.0172, 0.0467, 0.0171], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,750][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([3.9782e-02, 1.2348e-02, 5.4868e-01, 1.1374e-02, 3.5760e-01, 2.2406e-03,
        2.0239e-03, 2.1268e-03, 2.0183e-03, 8.1434e-04, 7.5662e-04, 9.3623e-03,
        1.0500e-02, 3.7839e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,751][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0019, 0.0023, 0.3656, 0.0030, 0.2665, 0.1045, 0.0365, 0.0368, 0.0790,
        0.0324, 0.0190, 0.0155, 0.0279, 0.0090], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,751][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([7.3454e-05, 2.3707e-05, 2.3460e-02, 5.2593e-05, 9.1552e-01, 1.9737e-02,
        4.0500e-03, 1.6495e-03, 1.5860e-02, 3.6974e-03, 2.0320e-03, 1.1580e-03,
        1.2494e-02, 1.9271e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,752][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([4.2371e-05, 8.1846e-05, 3.6636e-01, 9.7906e-05, 3.6156e-01, 1.1652e-01,
        8.1941e-02, 1.4425e-02, 1.6245e-02, 2.0113e-02, 8.4154e-03, 4.1223e-03,
        4.9060e-03, 5.1657e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,752][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0677, 0.0560, 0.1072, 0.0313, 0.0511, 0.1368, 0.0111, 0.0340, 0.1577,
        0.0365, 0.0151, 0.1107, 0.0610, 0.1238], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,753][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0163, 0.0126, 0.1637, 0.0185, 0.1584, 0.0498, 0.0403, 0.0600, 0.0666,
        0.0231, 0.0283, 0.0718, 0.2503, 0.0403], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,753][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0117, 0.0096, 0.4258, 0.0102, 0.3107, 0.0379, 0.0325, 0.0234, 0.0333,
        0.0147, 0.0107, 0.0290, 0.0440, 0.0064], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,754][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0011, 0.2935, 0.0731, 0.2466, 0.0965, 0.0103, 0.0141, 0.0042, 0.0246,
        0.0079, 0.0052, 0.0637, 0.1483, 0.0109], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,755][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0017, 0.0074, 0.0296, 0.0084, 0.0463, 0.1448, 0.1549, 0.0785, 0.0362,
        0.1683, 0.1319, 0.0317, 0.0431, 0.1172], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,756][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([7.9979e-04, 1.6773e-04, 4.4100e-01, 2.3946e-04, 5.3003e-01, 1.2400e-03,
        3.3863e-04, 5.5382e-04, 6.4904e-04, 2.0269e-03, 2.3837e-04, 1.4449e-03,
        2.1040e-02, 2.3512e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,757][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([7.2269e-04, 1.3885e-04, 7.1885e-01, 1.6892e-04, 2.7505e-01, 1.0786e-03,
        7.9449e-05, 1.0992e-04, 8.4497e-04, 1.1035e-04, 1.6882e-05, 3.0401e-04,
        2.5043e-03, 2.3380e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,758][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0026, 0.0020, 0.2908, 0.0029, 0.3190, 0.0917, 0.0537, 0.0289, 0.0382,
        0.0339, 0.0408, 0.0196, 0.0402, 0.0222, 0.0135], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,759][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([7.7573e-03, 3.2428e-03, 7.9814e-01, 2.9072e-03, 1.7642e-01, 2.8038e-03,
        1.9550e-03, 5.4854e-04, 6.2487e-04, 1.2423e-03, 3.2306e-04, 1.7807e-03,
        2.0250e-03, 1.1924e-04, 1.0544e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,760][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0012, 0.0014, 0.4188, 0.0018, 0.2925, 0.0936, 0.0321, 0.0258, 0.0553,
        0.0190, 0.0125, 0.0114, 0.0187, 0.0048, 0.0110], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,761][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.0864e-06, 1.3695e-06, 1.5654e-02, 3.6328e-06, 9.6038e-01, 8.7828e-03,
        1.2491e-03, 5.1626e-04, 7.4093e-03, 1.1938e-03, 5.4360e-04, 4.4189e-04,
        3.7631e-03, 4.6927e-05, 1.5232e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,762][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.0135e-05, 2.3866e-05, 5.1773e-01, 2.6175e-05, 3.3273e-01, 6.7321e-02,
        3.9725e-02, 9.4777e-03, 1.2202e-02, 8.9996e-03, 2.9734e-03, 3.4014e-03,
        2.9157e-03, 1.7522e-03, 7.1544e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,764][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1446, 0.1254, 0.0729, 0.0729, 0.0325, 0.1122, 0.0116, 0.0219, 0.1481,
        0.0288, 0.0122, 0.0631, 0.0275, 0.0952, 0.0309], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,765][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0142, 0.0164, 0.1822, 0.0192, 0.1319, 0.0637, 0.0638, 0.0783, 0.0778,
        0.0372, 0.0353, 0.0502, 0.1328, 0.0442, 0.0528], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,767][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0223, 0.0140, 0.4928, 0.0134, 0.2845, 0.0202, 0.0232, 0.0163, 0.0221,
        0.0073, 0.0056, 0.0305, 0.0388, 0.0035, 0.0055], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,768][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.0846e-05, 2.3740e-01, 3.7892e-02, 2.1557e-01, 1.1578e-01, 1.0661e-02,
        1.7505e-02, 3.1443e-03, 2.9702e-02, 1.1318e-02, 6.9279e-03, 7.7956e-02,
        2.2391e-01, 1.0108e-02, 2.0462e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,769][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0015, 0.0065, 0.0221, 0.0067, 0.0346, 0.1173, 0.1460, 0.0702, 0.0289,
        0.1417, 0.1115, 0.0322, 0.0403, 0.1028, 0.1377], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,770][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.9461e-04, 7.5194e-05, 3.5757e-01, 1.1995e-04, 6.1777e-01, 7.5737e-04,
        2.1285e-04, 2.5526e-04, 5.0166e-04, 1.0276e-03, 1.1468e-04, 9.4302e-04,
        2.0132e-02, 9.4945e-05, 2.8863e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,771][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0296e-04, 1.9817e-05, 6.8578e-01, 2.6211e-05, 3.1218e-01, 2.2323e-04,
        1.2044e-05, 2.3142e-05, 2.0477e-04, 2.4219e-05, 2.0990e-06, 1.4492e-04,
        1.2584e-03, 3.3065e-06, 4.8160e-07], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,835][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:24:08,836][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,837][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,838][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,840][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,841][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,841][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,841][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,842][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,842][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,842][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,843][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,843][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:24:08,843][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6514, 0.3486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,844][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5180, 0.4820], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,844][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3828, 0.6172], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,844][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4616, 0.5384], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,844][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3325, 0.6675], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,845][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3921, 0.6079], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,845][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3618, 0.6382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,845][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4751, 0.5249], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,846][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8200, 0.1800], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,846][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3814, 0.6186], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,846][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3816, 0.6184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,847][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5550, 0.4450], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:24:08,847][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Heather] are: tensor([0.4948, 0.2887, 0.2165], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,847][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Heather] are: tensor([0.2086, 0.0698, 0.7215], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,848][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Heather] are: tensor([0.0915, 0.0524, 0.8561], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,848][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Heather] are: tensor([0.6547, 0.3090, 0.0363], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,848][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Heather] are: tensor([0.0255, 0.0324, 0.9420], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,849][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Heather] are: tensor([0.1287, 0.0924, 0.7789], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,849][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Heather] are: tensor([0.0990, 0.0715, 0.8295], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,849][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Heather] are: tensor([0.6595, 0.2370, 0.1036], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,850][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Heather] are: tensor([0.0022, 0.9639, 0.0339], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,850][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Heather] are: tensor([0.2408, 0.1113, 0.6479], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,850][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Heather] are: tensor([0.2655, 0.0757, 0.6588], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,851][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Heather] are: tensor([0.4193, 0.0736, 0.5071], device='cuda:0') for source tokens [Then, Heather]
[2024-07-24 10:24:08,851][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4200, 0.2251, 0.1326, 0.2223], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,852][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1601, 0.1442, 0.5319, 0.1638], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,853][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1120, 0.1767, 0.4844, 0.2270], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,853][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2079, 0.2247, 0.2619, 0.3055], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,853][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0853, 0.1690, 0.5100, 0.2357], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,854][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1334, 0.2093, 0.4089, 0.2484], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,854][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0421, 0.0736, 0.7940, 0.0904], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,854][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2250, 0.2455, 0.2872, 0.2424], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,855][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6430, 0.1215, 0.1269, 0.1085], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,855][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1017, 0.1586, 0.5555, 0.1842], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,855][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0815, 0.1243, 0.6287, 0.1655], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,856][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1051, 0.0854, 0.7055, 0.1040], device='cuda:0') for source tokens [Then, Heather and]
[2024-07-24 10:24:08,856][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2316, 0.1121, 0.5157, 0.0879, 0.0527], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,857][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0245, 0.0088, 0.9176, 0.0050, 0.0441], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,858][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0168, 0.0103, 0.8213, 0.0080, 0.1435], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,860][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2352, 0.1034, 0.5707, 0.0542, 0.0365], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,861][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0043, 0.0047, 0.7218, 0.0042, 0.2650], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,862][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0368, 0.0294, 0.7915, 0.0179, 0.1244], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,864][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0020, 0.0015, 0.8771, 0.0011, 0.1183], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,865][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2252, 0.1038, 0.4670, 0.0502, 0.1538], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,867][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0181, 0.3462, 0.4252, 0.1974, 0.0131], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,868][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0143, 0.0081, 0.8371, 0.0049, 0.1356], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,870][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0681, 0.0184, 0.8589, 0.0107, 0.0439], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,871][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0387, 0.0091, 0.9276, 0.0046, 0.0199], device='cuda:0') for source tokens [Then, Heather and Katie]
[2024-07-24 10:24:08,871][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0474, 0.0291, 0.5843, 0.0319, 0.2750, 0.0322], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,872][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.2559e-03, 3.5601e-04, 9.1255e-01, 2.8270e-04, 8.5261e-02, 2.9325e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,872][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([3.0106e-04, 1.6546e-04, 8.0591e-01, 1.5209e-04, 1.8851e-01, 4.9605e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,872][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0033, 0.0010, 0.2463, 0.0013, 0.7446, 0.0034], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,873][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([1.8699e-04, 2.7045e-04, 5.9193e-01, 2.8391e-04, 3.5532e-01, 5.2013e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,873][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0046, 0.0032, 0.8507, 0.0020, 0.1311, 0.0084], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,874][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([1.7084e-04, 1.0089e-04, 7.5654e-01, 1.0764e-04, 2.4069e-01, 2.3940e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,874][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0194, 0.0094, 0.6613, 0.0045, 0.3030, 0.0024], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,874][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0012, 0.1454, 0.6836, 0.1177, 0.0504, 0.0016], device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,875][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.0964e-03, 4.7513e-04, 8.0149e-01, 3.9394e-04, 1.9479e-01, 1.7509e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,876][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([4.8854e-03, 7.0645e-04, 7.8751e-01, 6.7255e-04, 2.0588e-01, 3.4119e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,877][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([2.7297e-03, 4.1124e-04, 9.4265e-01, 3.5496e-04, 5.3839e-02, 1.3532e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had]
[2024-07-24 10:24:08,878][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0158, 0.0114, 0.5693, 0.0134, 0.2832, 0.0817, 0.0252],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,879][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3890e-04, 1.2290e-04, 8.0096e-01, 1.1961e-04, 1.9740e-01, 8.7966e-04,
        7.4248e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,880][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.0745e-04, 7.6620e-05, 5.9872e-01, 8.0930e-05, 3.8293e-01, 1.5751e-02,
        2.3340e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,880][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.1987e-04, 6.5614e-05, 7.9295e-02, 1.1216e-04, 9.1690e-01, 3.0903e-03,
        3.1242e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,881][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.6409e-05, 8.0742e-05, 4.0949e-01, 9.3520e-05, 4.2763e-01, 9.1656e-02,
        7.1004e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,883][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0036, 0.0026, 0.7534, 0.0018, 0.2151, 0.0187, 0.0048],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,883][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([4.2005e-05, 2.6514e-05, 6.3585e-01, 2.9208e-05, 3.5645e-01, 6.1585e-03,
        1.4499e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,885][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0059, 0.0031, 0.6260, 0.0017, 0.3583, 0.0038, 0.0011],
       device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,886][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.6998e-04, 6.2369e-02, 6.7483e-01, 6.1915e-02, 1.8720e-01, 7.3203e-03,
        5.9014e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,887][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.6495e-04, 1.9239e-04, 6.8085e-01, 1.7713e-04, 3.1294e-01, 4.4767e-03,
        9.0579e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,888][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.6968e-03, 3.0914e-04, 5.9890e-01, 3.7085e-04, 3.9773e-01, 7.9183e-04,
        2.0311e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,888][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.8746e-04, 9.6571e-05, 8.5901e-01, 1.0547e-04, 1.4009e-01, 1.0098e-04,
        3.9490e-06], device='cuda:0') for source tokens [Then, Heather and Katie had a]
[2024-07-24 10:24:08,890][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0327, 0.0159, 0.5459, 0.0189, 0.2848, 0.0585, 0.0192, 0.0240],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,891][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([7.6853e-04, 2.3548e-04, 7.6453e-01, 2.2280e-04, 2.3221e-01, 1.7141e-03,
        1.3322e-04, 1.9195e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,892][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.8464e-05, 7.4258e-05, 6.0498e-01, 7.6624e-05, 3.8622e-01, 6.7045e-03,
        8.9705e-04, 9.5482e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,893][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([3.8648e-04, 1.2740e-04, 6.8023e-02, 2.2268e-04, 9.0066e-01, 2.2885e-02,
        5.3944e-03, 2.2984e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,893][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([1.0849e-04, 1.7093e-04, 5.5036e-01, 1.9060e-04, 3.2214e-01, 6.3985e-02,
        4.8140e-02, 1.4908e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,895][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0029, 0.0024, 0.7678, 0.0017, 0.2014, 0.0196, 0.0027, 0.0016],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,896][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([4.2265e-05, 3.7014e-05, 6.1887e-01, 4.1752e-05, 3.7212e-01, 6.1182e-03,
        1.3986e-03, 1.3761e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,897][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0074, 0.0040, 0.5743, 0.0023, 0.4048, 0.0033, 0.0012, 0.0028],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,899][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0014, 0.1122, 0.6821, 0.0908, 0.0906, 0.0064, 0.0075, 0.0090],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,899][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([6.1537e-04, 2.9311e-04, 6.7548e-01, 2.6971e-04, 3.1627e-01, 4.8599e-03,
        5.6167e-04, 1.6567e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,900][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([1.1095e-03, 2.5328e-04, 7.4581e-01, 2.8704e-04, 2.5101e-01, 9.6652e-04,
        1.1844e-04, 4.4123e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,901][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([9.8511e-04, 1.9799e-04, 8.7227e-01, 2.1318e-04, 1.2609e-01, 2.0356e-04,
        1.2695e-05, 3.3911e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long]
[2024-07-24 10:24:08,903][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0456, 0.0255, 0.5075, 0.0283, 0.2602, 0.0671, 0.0239, 0.0251, 0.0170],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,904][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([2.0732e-03, 5.9793e-04, 8.6119e-01, 4.5469e-04, 1.3524e-01, 3.5120e-04,
        1.3477e-05, 2.8575e-05, 5.3386e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,904][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([1.3312e-04, 9.4574e-05, 7.2969e-01, 7.8583e-05, 2.6758e-01, 1.7999e-03,
        1.2586e-04, 2.0616e-04, 2.9101e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,906][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0025, 0.0009, 0.4558, 0.0010, 0.5310, 0.0043, 0.0006, 0.0007, 0.0032],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,907][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([2.3803e-04, 3.6035e-04, 8.2673e-01, 3.0292e-04, 1.4951e-01, 1.1878e-02,
        5.6253e-03, 2.6161e-03, 2.7360e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,908][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([4.2106e-03, 3.2183e-03, 8.7629e-01, 1.7405e-03, 1.0866e-01, 3.4547e-03,
        4.8335e-04, 4.7033e-04, 1.4660e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,909][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([1.0114e-04, 7.5188e-05, 8.0472e-01, 6.6369e-05, 1.9122e-01, 1.2402e-03,
        1.8607e-04, 2.3766e-04, 2.1529e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,910][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([1.2999e-02, 6.9209e-03, 6.3962e-01, 3.3823e-03, 3.3245e-01, 1.4124e-03,
        2.6846e-04, 8.3461e-04, 2.1152e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,911][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0012, 0.0942, 0.7799, 0.0629, 0.0501, 0.0018, 0.0016, 0.0028, 0.0056],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,912][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([2.4818e-03, 1.2036e-03, 7.8626e-01, 7.9185e-04, 2.0576e-01, 1.2851e-03,
        7.2768e-05, 3.1332e-04, 1.8323e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,913][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([4.8648e-03, 7.8562e-04, 8.7568e-01, 6.5896e-04, 1.1782e-01, 6.5991e-05,
        7.5528e-06, 7.0905e-05, 5.2150e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,914][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([1.0788e-03, 2.5495e-04, 9.4786e-01, 1.8906e-04, 5.0549e-02, 1.7239e-05,
        1.3946e-06, 6.7731e-06, 3.9235e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument]
[2024-07-24 10:24:08,915][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0175, 0.0112, 0.5703, 0.0129, 0.2475, 0.0534, 0.0193, 0.0226, 0.0198,
        0.0255], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,916][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.9051e-04, 1.2102e-04, 8.3902e-01, 1.1212e-04, 1.5987e-01, 3.4295e-04,
        1.6079e-05, 2.7325e-05, 8.5793e-05, 1.8599e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,917][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.2924e-05, 5.7770e-05, 7.0266e-01, 6.0719e-05, 2.8755e-01, 5.5320e-03,
        4.6680e-04, 7.0610e-04, 2.0318e-03, 8.7341e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,918][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.1065e-04, 7.4926e-05, 1.7463e-01, 1.1963e-04, 8.1436e-01, 4.9975e-03,
        5.2462e-04, 4.7344e-04, 3.8560e-03, 7.4881e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,919][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([5.1594e-05, 1.1693e-04, 5.3615e-01, 1.2394e-04, 2.9505e-01, 7.2570e-02,
        4.7602e-02, 1.3903e-02, 1.4225e-02, 2.0208e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,919][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.6444e-03, 2.2097e-03, 7.7425e-01, 1.5198e-03, 2.0606e-01, 6.1583e-03,
        1.3791e-03, 7.3706e-04, 3.5634e-03, 1.4787e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,919][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([4.8891e-05, 4.3392e-05, 7.6895e-01, 4.4271e-05, 2.1893e-01, 3.1429e-03,
        5.6228e-04, 5.1749e-04, 6.3457e-03, 1.4165e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,920][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0042, 0.0025, 0.5932, 0.0015, 0.3865, 0.0046, 0.0008, 0.0014, 0.0042,
        0.0010], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,920][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([6.5031e-04, 4.7734e-02, 7.9065e-01, 3.8907e-02, 1.0940e-01, 1.6701e-03,
        8.5600e-04, 2.4872e-03, 4.6640e-03, 2.9886e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,921][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([7.9229e-04, 4.4381e-04, 7.8067e-01, 3.7038e-04, 2.1044e-01, 1.8613e-03,
        2.4470e-04, 3.2870e-04, 3.8788e-03, 9.7525e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,921][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.6356e-03, 3.5454e-04, 6.7458e-01, 3.9618e-04, 3.2176e-01, 3.1382e-04,
        4.2351e-05, 1.6298e-04, 2.2036e-04, 5.3358e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,921][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([7.0764e-04, 1.6266e-04, 9.1795e-01, 1.5194e-04, 8.0905e-02, 4.3703e-05,
        2.9019e-06, 1.0582e-05, 5.2748e-05, 1.1013e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument,]
[2024-07-24 10:24:08,922][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0062, 0.0042, 0.5390, 0.0054, 0.2678, 0.0636, 0.0236, 0.0249, 0.0263,
        0.0205, 0.0186], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,923][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.0043e-04, 1.2981e-04, 7.1470e-01, 1.2905e-04, 2.8328e-01, 9.6259e-04,
        4.9978e-05, 6.2233e-05, 2.2245e-04, 5.2379e-05, 1.1138e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,923][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([4.5851e-05, 4.2996e-05, 6.5983e-01, 4.8320e-05, 3.2192e-01, 9.8361e-03,
        1.1709e-03, 1.4353e-03, 3.9298e-03, 1.4042e-03, 3.3708e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,924][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.0128e-05, 7.3611e-06, 6.1252e-02, 1.4711e-05, 9.3134e-01, 3.4546e-03,
        3.9675e-04, 3.0754e-04, 2.6112e-03, 5.0765e-04, 8.5718e-05],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,925][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([4.6248e-05, 9.8759e-05, 5.1289e-01, 1.0958e-04, 3.0725e-01, 7.4461e-02,
        4.8503e-02, 1.5421e-02, 1.4509e-02, 1.9300e-02, 7.4105e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,926][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([2.6194e-03, 2.3731e-03, 7.5702e-01, 1.6390e-03, 2.2018e-01, 7.2848e-03,
        1.6418e-03, 1.0212e-03, 4.4429e-03, 1.1429e-03, 6.3481e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,927][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([3.3218e-05, 3.1410e-05, 7.1471e-01, 3.3823e-05, 2.6905e-01, 4.0254e-03,
        8.8148e-04, 7.6270e-04, 8.2267e-03, 1.7808e-03, 4.5709e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,928][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([4.5630e-03, 2.9140e-03, 5.8945e-01, 1.7527e-03, 3.8524e-01, 5.2733e-03,
        1.3572e-03, 2.3659e-03, 5.6553e-03, 1.1477e-03, 2.8408e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,930][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0009, 0.0319, 0.7525, 0.0284, 0.1603, 0.0031, 0.0019, 0.0040, 0.0107,
        0.0049, 0.0014], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,930][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.9552e-04, 3.2020e-04, 6.8974e-01, 2.8714e-04, 2.9758e-01, 2.5313e-03,
        4.5645e-04, 7.5194e-04, 6.0433e-03, 1.3796e-03, 3.1508e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,931][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.6803e-04, 2.0712e-04, 5.0694e-01, 2.8053e-04, 4.8850e-01, 7.4600e-04,
        1.8040e-04, 3.1244e-04, 5.8169e-04, 1.1557e-03, 1.2851e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,932][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.7518e-04, 4.8023e-05, 8.4382e-01, 5.2885e-05, 1.5561e-01, 7.9270e-05,
        7.4220e-06, 2.3019e-05, 1.5069e-04, 2.3850e-05, 1.7503e-06],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and]
[2024-07-24 10:24:08,934][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0836, 0.0424, 0.5720, 0.0442, 0.1684, 0.0261, 0.0086, 0.0082, 0.0100,
        0.0122, 0.0110, 0.0132], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,935][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7698e-03, 6.4166e-04, 8.0812e-01, 5.2759e-04, 1.8562e-01, 2.0379e-03,
        1.5753e-04, 1.6583e-04, 5.2214e-04, 1.2110e-04, 3.3251e-05, 2.7639e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,936][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([3.3528e-04, 3.2404e-04, 5.4949e-01, 3.2425e-04, 3.9501e-01, 2.3107e-02,
        5.0433e-03, 2.8530e-03, 8.7032e-03, 6.1714e-03, 2.0042e-03, 6.6335e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,937][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0016, 0.0008, 0.1528, 0.0011, 0.7710, 0.0251, 0.0086, 0.0053, 0.0243,
        0.0048, 0.0024, 0.0022], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,938][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([2.5717e-04, 4.6488e-04, 5.5869e-01, 4.4466e-04, 2.0055e-01, 8.2669e-02,
        7.6060e-02, 1.4694e-02, 1.6709e-02, 2.5911e-02, 1.3766e-02, 9.7836e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,940][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0093, 0.0080, 0.7206, 0.0053, 0.2022, 0.0214, 0.0058, 0.0030, 0.0102,
        0.0035, 0.0021, 0.0087], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,940][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([1.3115e-04, 1.3077e-04, 7.7235e-01, 1.1503e-04, 2.0379e-01, 5.6020e-03,
        1.3444e-03, 9.6651e-04, 1.1658e-02, 1.9954e-03, 4.8614e-04, 1.4268e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,941][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([1.0315e-02, 6.4997e-03, 6.0350e-01, 3.7650e-03, 3.4623e-01, 6.9103e-03,
        1.7257e-03, 2.1038e-03, 5.3412e-03, 1.3678e-03, 3.0966e-04, 1.1928e-02],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,943][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0015, 0.0059, 0.7559, 0.0054, 0.1837, 0.0085, 0.0038, 0.0034, 0.0148,
        0.0031, 0.0013, 0.0127], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,944][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([4.8167e-03, 2.8303e-03, 6.7633e-01, 1.9764e-03, 2.9362e-01, 4.5641e-03,
        1.1518e-03, 1.2046e-03, 7.7723e-03, 1.7515e-03, 4.5589e-04, 3.5311e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,945][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.6371e-03, 6.7701e-04, 5.7366e-01, 7.1240e-04, 4.1077e-01, 3.1798e-03,
        1.7377e-03, 9.0590e-04, 1.1019e-03, 2.7842e-03, 4.4123e-04, 2.3916e-03],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,946][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([6.2255e-04, 2.5212e-04, 8.6503e-01, 2.3156e-04, 1.3181e-01, 8.3295e-04,
        1.5454e-04, 1.3542e-04, 5.9223e-04, 9.7757e-05, 2.1499e-05, 2.1495e-04],
       device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards]
[2024-07-24 10:24:08,947][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0921, 0.0536, 0.5089, 0.0532, 0.1414, 0.0403, 0.0122, 0.0103, 0.0100,
        0.0180, 0.0155, 0.0124, 0.0321], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,948][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([7.3215e-04, 3.7277e-04, 7.9822e-01, 3.0717e-04, 1.9180e-01, 3.2152e-03,
        4.4750e-04, 3.8206e-04, 1.0124e-03, 3.7251e-04, 9.2819e-05, 5.6665e-04,
        2.4756e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,949][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([7.0247e-05, 9.2635e-05, 5.7354e-01, 9.9584e-05, 3.6230e-01, 2.6474e-02,
        5.6947e-03, 3.5745e-03, 8.8118e-03, 7.6366e-03, 2.0654e-03, 3.7059e-03,
        5.9367e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,950][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0119, 0.0064, 0.3395, 0.0066, 0.5368, 0.0250, 0.0103, 0.0071, 0.0186,
        0.0100, 0.0039, 0.0042, 0.0198], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,951][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([1.2094e-04, 2.6878e-04, 4.4388e-01, 2.8189e-04, 2.5693e-01, 1.1012e-01,
        9.5622e-02, 1.4878e-02, 1.5768e-02, 3.2685e-02, 1.4457e-02, 8.3650e-03,
        6.6299e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,953][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0028, 0.0033, 0.6793, 0.0025, 0.2164, 0.0398, 0.0126, 0.0035, 0.0122,
        0.0070, 0.0038, 0.0050, 0.0117], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,954][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([4.2467e-05, 5.9506e-05, 7.3207e-01, 6.1597e-05, 2.2284e-01, 1.0940e-02,
        3.2591e-03, 1.9035e-03, 1.9094e-02, 4.8572e-03, 1.1107e-03, 1.2967e-03,
        2.4615e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,956][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0059, 0.0045, 0.4736, 0.0028, 0.4343, 0.0198, 0.0081, 0.0043, 0.0104,
        0.0060, 0.0011, 0.0128, 0.0164], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,957][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0013, 0.0133, 0.7081, 0.0107, 0.1165, 0.0039, 0.0030, 0.0029, 0.0082,
        0.0027, 0.0010, 0.0136, 0.1149], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,958][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([9.4647e-04, 8.7443e-04, 6.8018e-01, 6.7167e-04, 2.7677e-01, 1.0673e-02,
        1.5982e-03, 1.3470e-03, 1.1143e-02, 4.3385e-03, 8.9453e-04, 1.5704e-03,
        8.9937e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,959][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([2.1009e-03, 1.0705e-03, 7.2035e-01, 1.0100e-03, 2.4034e-01, 2.1270e-03,
        1.0618e-03, 8.2403e-04, 7.3310e-04, 2.3831e-03, 2.6228e-04, 1.4377e-03,
        2.6301e-02], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,960][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([1.7281e-03, 8.3586e-04, 8.5874e-01, 6.4473e-04, 1.3296e-01, 6.6079e-04,
        1.8920e-04, 2.9366e-04, 9.1382e-04, 1.7984e-04, 3.2001e-05, 2.4164e-04,
        2.5765e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie]
[2024-07-24 10:24:08,961][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0232, 0.0126, 0.3432, 0.0161, 0.3799, 0.0425, 0.0170, 0.0184, 0.0232,
        0.0211, 0.0218, 0.0172, 0.0467, 0.0171], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,962][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([2.3741e-04, 7.5482e-05, 7.6002e-01, 7.4858e-05, 2.3686e-01, 1.1356e-03,
        5.4799e-05, 7.9605e-05, 2.8464e-04, 5.3367e-05, 1.0565e-05, 1.4330e-04,
        9.4119e-04, 2.2457e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,963][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([4.6849e-05, 3.9284e-05, 4.6998e-01, 4.7436e-05, 4.8292e-01, 1.8750e-02,
        2.5325e-03, 2.7445e-03, 8.8241e-03, 3.2387e-03, 7.4477e-04, 3.7754e-03,
        5.3355e-03, 1.0160e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,964][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([7.3454e-05, 2.3707e-05, 2.3460e-02, 5.2593e-05, 9.1552e-01, 1.9737e-02,
        4.0500e-03, 1.6495e-03, 1.5860e-02, 3.6974e-03, 2.0320e-03, 1.1580e-03,
        1.2494e-02, 1.9271e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,965][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([4.2371e-05, 8.1846e-05, 3.6636e-01, 9.7906e-05, 3.6156e-01, 1.1652e-01,
        8.1941e-02, 1.4425e-02, 1.6245e-02, 2.0113e-02, 8.4154e-03, 4.1223e-03,
        4.9060e-03, 5.1657e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,966][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0033, 0.0030, 0.6139, 0.0023, 0.2868, 0.0318, 0.0087, 0.0038, 0.0174,
        0.0048, 0.0031, 0.0079, 0.0106, 0.0024], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,967][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([2.2684e-05, 2.0160e-05, 5.6515e-01, 2.5727e-05, 3.8688e-01, 1.0189e-02,
        2.8111e-03, 1.8128e-03, 2.2504e-02, 3.9769e-03, 1.1979e-03, 1.5131e-03,
        3.1033e-03, 7.9204e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,967][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([3.2323e-03, 2.0579e-03, 4.2621e-01, 1.3016e-03, 5.1908e-01, 7.9917e-03,
        1.8280e-03, 2.1007e-03, 7.2657e-03, 1.5848e-03, 2.4618e-04, 9.1676e-03,
        1.7274e-02, 6.6528e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,967][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([3.6488e-04, 2.5187e-02, 5.1782e-01, 2.4136e-02, 1.2591e-01, 7.9358e-03,
        6.5876e-03, 7.6447e-03, 1.3549e-02, 7.5312e-03, 4.1887e-03, 5.7382e-02,
        1.9766e-01, 4.1058e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,968][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([6.2477e-04, 3.8860e-04, 5.5363e-01, 3.6369e-04, 4.0042e-01, 9.1282e-03,
        1.3274e-03, 1.3160e-03, 1.7190e-02, 2.6773e-03, 5.6678e-04, 1.6574e-03,
        1.0146e-02, 5.6192e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,968][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([7.9979e-04, 1.6773e-04, 4.4100e-01, 2.3946e-04, 5.3003e-01, 1.2400e-03,
        3.3863e-04, 5.5382e-04, 6.4904e-04, 2.0269e-03, 2.3837e-04, 1.4449e-03,
        2.1040e-02, 2.3512e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,969][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([7.2269e-04, 1.3885e-04, 7.1885e-01, 1.6892e-04, 2.7505e-01, 1.0786e-03,
        7.9449e-05, 1.0992e-04, 8.4497e-04, 1.1035e-04, 1.6882e-05, 3.0401e-04,
        2.5043e-03, 2.3380e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said]
[2024-07-24 10:24:08,969][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0026, 0.0020, 0.2908, 0.0029, 0.3190, 0.0917, 0.0537, 0.0289, 0.0382,
        0.0339, 0.0408, 0.0196, 0.0402, 0.0222, 0.0135], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,970][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3421e-04, 3.8419e-05, 7.1842e-01, 3.9232e-05, 2.7954e-01, 8.5151e-04,
        3.9451e-05, 3.7469e-05, 1.7539e-04, 3.3427e-05, 6.7472e-06, 8.9272e-05,
        5.8064e-04, 1.2131e-05, 2.3209e-06], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,971][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.4410e-06, 8.7945e-06, 5.7526e-01, 9.6830e-06, 4.0745e-01, 7.9976e-03,
        8.6290e-04, 7.8752e-04, 2.8758e-03, 8.4055e-04, 1.9797e-04, 1.4134e-03,
        1.9731e-03, 2.0139e-04, 1.1560e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,972][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.0864e-06, 1.3695e-06, 1.5654e-02, 3.6328e-06, 9.6038e-01, 8.7828e-03,
        1.2491e-03, 5.1626e-04, 7.4093e-03, 1.1938e-03, 5.4360e-04, 4.4189e-04,
        3.7631e-03, 4.6927e-05, 1.5232e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,973][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.0135e-05, 2.3866e-05, 5.1773e-01, 2.6175e-05, 3.3273e-01, 6.7321e-02,
        3.9725e-02, 9.4777e-03, 1.2202e-02, 8.9996e-03, 2.9734e-03, 3.4014e-03,
        2.9157e-03, 1.7522e-03, 7.1544e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,974][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.2671e-03, 1.0619e-03, 7.5509e-01, 6.9802e-04, 2.1691e-01, 6.7060e-03,
        1.6227e-03, 9.4749e-04, 4.9849e-03, 9.3515e-04, 4.3616e-04, 3.4364e-03,
        5.1326e-03, 4.1653e-04, 3.4752e-04], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,975][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.0995e-05, 9.4049e-06, 6.5207e-01, 1.0319e-05, 3.2980e-01, 5.3085e-03,
        1.0081e-03, 4.6748e-04, 7.9751e-03, 1.2009e-03, 3.2288e-04, 5.3042e-04,
        9.3856e-04, 2.6907e-04, 7.7420e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,975][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.6290e-03, 1.7458e-03, 5.5333e-01, 1.0207e-03, 4.1377e-01, 3.3396e-03,
        8.8075e-04, 9.7095e-04, 3.0542e-03, 4.5714e-04, 9.4683e-05, 7.6124e-03,
        9.8348e-03, 1.9418e-04, 6.1662e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,977][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.7398e-05, 1.6508e-02, 2.2509e-01, 1.8228e-02, 1.8259e-01, 6.6582e-03,
        8.1555e-03, 7.7086e-03, 1.8808e-02, 1.3931e-02, 6.9238e-03, 6.4096e-02,
        4.2505e-01, 3.1124e-03, 3.0708e-03], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,977][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6763e-04, 9.5947e-05, 6.1075e-01, 8.0549e-05, 3.6960e-01, 3.0040e-03,
        5.1546e-04, 4.1877e-04, 5.9856e-03, 7.6708e-04, 1.5510e-04, 1.2865e-03,
        6.9727e-03, 1.3730e-04, 6.2871e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,978][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.9461e-04, 7.5194e-05, 3.5757e-01, 1.1995e-04, 6.1777e-01, 7.5737e-04,
        2.1285e-04, 2.5526e-04, 5.0166e-04, 1.0276e-03, 1.1468e-04, 9.4302e-04,
        2.0132e-02, 9.4945e-05, 2.8863e-05], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,979][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0296e-04, 1.9817e-05, 6.8578e-01, 2.6211e-05, 3.1218e-01, 2.2323e-04,
        1.2044e-05, 2.3142e-05, 2.0477e-04, 2.4219e-05, 2.0990e-06, 1.4492e-04,
        1.2584e-03, 3.3065e-06, 4.8160e-07], device='cuda:0') for source tokens [Then, Heather and Katie had a long argument, and afterwards Katie said to]
[2024-07-24 10:24:08,981][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:24:08,983][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7231],
        [10665],
        [   70],
        [  222],
        [   21],
        [    5],
        [    4],
        [   23],
        [   34],
        [    5],
        [    1],
        [   40],
        [  114],
        [    2],
        [    1]], device='cuda:0')
[2024-07-24 10:24:08,984][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[7161],
        [9968],
        [ 138],
        [ 420],
        [  90],
        [  30],
        [  19],
        [  86],
        [ 118],
        [  35],
        [   9],
        [ 134],
        [ 316],
        [  34],
        [  10]], device='cuda:0')
[2024-07-24 10:24:08,985][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13915],
        [14991],
        [10965],
        [12786],
        [10374],
        [12528],
        [13559],
        [13629],
        [14078],
        [13677],
        [14461],
        [12639],
        [13313],
        [16508],
        [18203]], device='cuda:0')
[2024-07-24 10:24:08,987][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[456],
        [838],
        [151],
        [106],
        [ 44],
        [ 31],
        [ 32],
        [ 33],
        [ 34],
        [ 35],
        [ 35],
        [ 37],
        [122],
        [ 34],
        [ 35]], device='cuda:0')
[2024-07-24 10:24:08,988][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18328],
        [14599],
        [50146],
        [49931],
        [49300],
        [49348],
        [44606],
        [44989],
        [48350],
        [46200],
        [46667],
        [29044],
        [30229],
        [37063],
        [41376]], device='cuda:0')
[2024-07-24 10:24:08,990][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16339],
        [23052],
        [28162],
        [39935],
        [42219],
        [37511],
        [35623],
        [35465],
        [39624],
        [36720],
        [35398],
        [36509],
        [38609],
        [34994],
        [34845]], device='cuda:0')
[2024-07-24 10:24:08,991][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[40558],
        [42948],
        [18500],
        [23184],
        [19741],
        [20764],
        [21949],
        [20890],
        [18958],
        [20474],
        [20493],
        [19770],
        [20422],
        [21332],
        [20673]], device='cuda:0')
[2024-07-24 10:24:08,993][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[22737],
        [10385],
        [19857],
        [27936],
        [19512],
        [14887],
        [11454],
        [11343],
        [11057],
        [11720],
        [ 9193],
        [ 9240],
        [10340],
        [ 9167],
        [ 8752]], device='cuda:0')
[2024-07-24 10:24:08,994][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10125],
        [ 3472],
        [  216],
        [  207],
        [  683],
        [  765],
        [  886],
        [ 1175],
        [  936],
        [  786],
        [  797],
        [  620],
        [ 1491],
        [ 1384],
        [  998]], device='cuda:0')
[2024-07-24 10:24:08,995][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40293],
        [37616],
        [ 5794],
        [ 5548],
        [ 3342],
        [ 2714],
        [ 2695],
        [ 2730],
        [ 2747],
        [ 2732],
        [ 2752],
        [ 3107],
        [ 3622],
        [ 3255],
        [ 3163]], device='cuda:0')
[2024-07-24 10:24:08,997][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14050],
        [14059],
        [15061],
        [14023],
        [14188],
        [14014],
        [13824],
        [13971],
        [13960],
        [13831],
        [13595],
        [13298],
        [13530],
        [13804],
        [13918]], device='cuda:0')
[2024-07-24 10:24:08,998][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30537],
        [16713],
        [42409],
        [40255],
        [39199],
        [33721],
        [30440],
        [29888],
        [29551],
        [30878],
        [31482],
        [31878],
        [32141],
        [31017],
        [30549]], device='cuda:0')
[2024-07-24 10:24:09,000][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27906],
        [20265],
        [   60],
        [   72],
        [   70],
        [  165],
        [  520],
        [  207],
        [   93],
        [  320],
        [ 1077],
        [  684],
        [  253],
        [ 1768],
        [ 3206]], device='cuda:0')
[2024-07-24 10:24:09,001][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 8040],
        [ 5460],
        [45438],
        [45934],
        [46585],
        [46585],
        [46394],
        [46432],
        [46595],
        [46530],
        [46364],
        [46427],
        [46410],
        [45965],
        [45834]], device='cuda:0')
[2024-07-24 10:24:09,002][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[27792],
        [22043],
        [ 9332],
        [23207],
        [ 8043],
        [10307],
        [18190],
        [14977],
        [13766],
        [12400],
        [10038],
        [13269],
        [14007],
        [14249],
        [15695]], device='cuda:0')
[2024-07-24 10:24:09,004][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21115],
        [21164],
        [21244],
        [21411],
        [21235],
        [21949],
        [22712],
        [22906],
        [23264],
        [23383],
        [23746],
        [22746],
        [23357],
        [24244],
        [25035]], device='cuda:0')
[2024-07-24 10:24:09,005][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29827],
        [36447],
        [20019],
        [21034],
        [20048],
        [20166],
        [20738],
        [20945],
        [20394],
        [20533],
        [21270],
        [20680],
        [20737],
        [20977],
        [21253]], device='cuda:0')
[2024-07-24 10:24:09,007][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37288],
        [33018],
        [22762],
        [23460],
        [23525],
        [23863],
        [25777],
        [25693],
        [24524],
        [24779],
        [25196],
        [26357],
        [26125],
        [27099],
        [26004]], device='cuda:0')
[2024-07-24 10:24:09,008][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22329],
        [21405],
        [19865],
        [14232],
        [14136],
        [13014],
        [12323],
        [12408],
        [13470],
        [12753],
        [12215],
        [12809],
        [13301],
        [12142],
        [12005]], device='cuda:0')
[2024-07-24 10:24:09,010][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17584],
        [10460],
        [30097],
        [24486],
        [32447],
        [33022],
        [32644],
        [32679],
        [31814],
        [32458],
        [32345],
        [31600],
        [31194],
        [31629],
        [32644]], device='cuda:0')
[2024-07-24 10:24:09,011][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8195],
        [14764],
        [28058],
        [25449],
        [31315],
        [31596],
        [33401],
        [33115],
        [31171],
        [33165],
        [33495],
        [33588],
        [34305],
        [35801],
        [33589]], device='cuda:0')
[2024-07-24 10:24:09,012][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[19427],
        [31906],
        [ 4513],
        [ 4513],
        [ 4907],
        [ 5372],
        [ 5831],
        [ 5898],
        [ 5188],
        [ 5345],
        [ 5558],
        [ 5359],
        [ 5554],
        [ 6205],
        [ 5794]], device='cuda:0')
[2024-07-24 10:24:09,014][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31372],
        [25355],
        [26449],
        [22487],
        [25623],
        [27777],
        [29220],
        [30688],
        [28558],
        [30183],
        [30241],
        [29603],
        [33345],
        [34781],
        [31289]], device='cuda:0')
[2024-07-24 10:24:09,015][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33923],
        [33876],
        [32030],
        [33774],
        [32506],
        [32510],
        [32630],
        [32512],
        [32516],
        [32581],
        [32588],
        [32572],
        [32354],
        [31940],
        [30597]], device='cuda:0')
[2024-07-24 10:24:09,016][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9796],
        [ 7721],
        [18951],
        [18586],
        [17740],
        [17177],
        [15783],
        [15725],
        [16979],
        [16870],
        [15814],
        [15662],
        [15655],
        [14086],
        [14880]], device='cuda:0')
[2024-07-24 10:24:09,017][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18288],
        [10654],
        [25178],
        [24600],
        [25639],
        [22730],
        [17706],
        [21588],
        [24667],
        [19689],
        [15521],
        [17182],
        [20876],
        [14088],
        [12665]], device='cuda:0')
[2024-07-24 10:24:09,018][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9014],
        [13599],
        [ 8120],
        [ 8513],
        [ 8538],
        [ 8678],
        [ 9118],
        [ 9043],
        [ 8668],
        [ 8815],
        [ 9198],
        [ 9090],
        [ 9123],
        [ 9895],
        [10086]], device='cuda:0')
[2024-07-24 10:24:09,019][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[19346],
        [19878],
        [22129],
        [25899],
        [23292],
        [23349],
        [23170],
        [22092],
        [22585],
        [22922],
        [23548],
        [23132],
        [21274],
        [22018],
        [23745]], device='cuda:0')
[2024-07-24 10:24:09,021][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[16000],
        [22651],
        [22007],
        [20464],
        [27839],
        [28678],
        [21114],
        [25820],
        [25321],
        [26554],
        [28709],
        [29875],
        [28007],
        [25991],
        [23962]], device='cuda:0')
[2024-07-24 10:24:09,022][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500],
        [16500]], device='cuda:0')
