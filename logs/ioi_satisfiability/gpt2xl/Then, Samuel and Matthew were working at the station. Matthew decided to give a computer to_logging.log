[2024-07-24 10:30:13,445][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Samuel and Matthew were working at the station. Matthew decided to give a computer to
[2024-07-24 10:30:13,445][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Samuel
[2024-07-24 10:30:13,445][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:30:13,445][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:30:13,445][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:30:13,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,446][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:30:13,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,446][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:30:13,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,446][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:30:13,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:30:13,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:30:13,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:30:13,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,447][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:30:13,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,449][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:30:13,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,449][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:30:13,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,449][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:30:13,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,450][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:30:13,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,451][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:30:13,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,451][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:30:13,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,451][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:30:13,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,452][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:30:13,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,452][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:30:13,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,452][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:30:13,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,453][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:30:13,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,453][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:30:13,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,453][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:30:13,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,454][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:30:13,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,454][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:30:13,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,454][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:30:13,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,455][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:30:13,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,455][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:30:13,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,456][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:30:13,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,456][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:30:13,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,457][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:30:13,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,457][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:30:13,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,458][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:30:13,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4']
[2024-07-24 10:30:13,458][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:30:13,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,460][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:30:13,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,460][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:30:13,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,462][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:30:13,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit23']
[2024-07-24 10:30:13,462][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:30:13,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,463][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:30:13,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,463][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:30:13,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,464][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:30:13,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,464][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,464][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:30:13,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:30:13,464][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,465][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:30:13,465][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,465][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:30:13,465][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,466][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:30:13,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,466][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,466][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:30:13,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,466][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,467][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:30:13,467][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,467][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:30:13,467][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,468][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:30:13,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,468][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:30:13,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,469][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:30:13,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,469][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,469][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:30:13,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,469][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,470][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:30:13,470][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,470][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit28']
[2024-07-24 10:30:13,470][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:30:13,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,471][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,471][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:30:13,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:30:13,472][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,473][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,473][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,473][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:30:13,473][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,473][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,473][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,474][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:30:13,474][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,474][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:30:13,474][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:30:13,474][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:30:13,474][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit26']
[2024-07-24 10:30:13,475][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,475][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,475][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:30:13,475][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,475][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:30:13,475][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,476][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:30:13,476][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,476][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,476][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,476][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:30:13,476][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,477][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,477][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,477][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:30:13,477][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:30:13,477][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,477][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:30:13,478][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:30:13,478][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,478][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,478][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,478][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:30:13,478][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,479][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:30:13,479][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,479][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:30:13,479][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,479][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,479][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,480][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:30:13,480][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,480][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,480][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,480][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:30:13,480][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,481][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:30:13,482][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,482][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,482][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:30:13,482][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:30:13,482][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,482][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,483][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,483][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:30:13,483][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,483][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,483][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,483][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:30:13,484][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,484][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,484][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:30:13,484][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:30:13,484][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,484][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,485][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,485][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:30:13,485][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,485][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,485][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit7', 'circuit17', 'circuit26']
[2024-07-24 10:30:13,485][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:30:13,486][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,486][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,486][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:30:13,486][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:30:13,486][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,486][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,487][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,487][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:30:13,487][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,487][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,487][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,487][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:30:13,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,488][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,488][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,488][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:30:13,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,488][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,489][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,489][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,489][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:30:13,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,489][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,489][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,490][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:30:13,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,491][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,491][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,491][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,491][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:30:13,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10']
[2024-07-24 10:30:13,492][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit27']
[2024-07-24 10:30:13,492][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,492][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,492][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:30:13,492][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,492][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:30:13,493][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18']
[2024-07-24 10:30:13,493][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,493][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:30:13,493][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,493][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,493][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit24']
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit3']
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,494][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:30:13,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,495][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,495][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,495][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,495][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:30:13,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,496][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,496][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,496][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:30:13,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,497][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,497][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,497][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:30:13,497][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,497][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,497][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,498][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:30:13,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,499][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,499][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,499][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:30:13,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,500][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,500][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5']
[2024-07-24 10:30:13,500][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:30:13,500][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:30:13,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,500][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,501][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-24 10:30:13,501][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:30:13,501][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:30:13,501][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:30:13,501][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,501][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,502][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16']
[2024-07-24 10:30:13,502][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:30:13,502][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,502][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,502][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,503][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:30:13,503][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,503][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:30:13,503][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,503][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:30:13,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,504][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,504][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,504][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,504][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:30:13,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,505][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,506][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,506][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:30:13,506][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,506][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:30:13,506][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:30:13,506][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:30:13,507][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:30:13,507][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,507][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:30:13,507][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,507][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:30:13,507][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:30:13,508][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,508][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,508][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,508][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:30:13,508][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:30:13,508][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10']
[2024-07-24 10:30:13,509][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,509][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7']
[2024-07-24 10:30:13,509][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:30:13,509][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,510][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,510][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,510][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:30:13,510][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,510][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,510][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,511][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,511][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:30:13,511][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,511][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,511][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,511][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,512][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:30:13,512][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,512][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,512][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,512][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,512][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,513][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:30:13,514][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:30:13,514][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:30:13,514][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,514][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,514][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,514][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:30:13,515][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,515][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13']
[2024-07-24 10:30:13,515][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,515][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,515][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,515][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:30:13,516][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,516][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:30:13,516][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:30:13,516][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,516][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:30:13,516][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:30:13,517][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:30:13,517][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,517][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,517][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,517][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,517][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:30:13,518][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,519][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,519][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,519][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,519][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,519][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:30:13,519][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,520][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,520][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,520][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,520][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,520][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:30:13,520][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,521][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,521][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:30:13,521][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,521][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,521][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:30:13,521][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,522][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,522][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,522][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,522][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:30:13,522][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit19', 'circuit23']
[2024-07-24 10:30:13,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit26']
[2024-07-24 10:30:13,524][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,524][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,524][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,524][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:30:13,524][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,524][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,525][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,525][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit19', 'circuit25']
[2024-07-24 10:30:13,525][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,525][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:30:13,525][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,525][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,526][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,526][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,526][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,526][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:30:13,526][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,526][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,527][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,527][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,527][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,527][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:30:13,527][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,527][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,528][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,529][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,529][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,529][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:30:13,529][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,529][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,529][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,530][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,530][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,530][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:30:13,530][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,530][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,530][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,531][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,532][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,532][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:30:13,532][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,532][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,532][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,532][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,533][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,533][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:30:13,533][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,533][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,533][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,533][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,534][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,534][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:30:13,534][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,534][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,534][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,534][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,535][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,536][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:30:13,536][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,536][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,536][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,536][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,536][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,537][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:30:13,537][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,537][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,537][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,537][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,537][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,538][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:30:13,538][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,538][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,538][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,538][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,538][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,539][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:30:13,539][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,539][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,539][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,539][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,539][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,540][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:30:13,540][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,540][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,540][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,540][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,540][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,541][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,541][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:30:13,541][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,541][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit13', 'circuit16']
[2024-07-24 10:30:13,541][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,541][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,542][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,542][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit27']
[2024-07-24 10:30:13,542][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:30:13,542][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:30:13,542][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit22']
[2024-07-24 10:30:13,542][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,543][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,543][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,543][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,543][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:30:13,543][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,543][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit21']
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:30:13,544][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,545][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,545][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,545][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,545][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,545][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:30:13,545][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20']
[2024-07-24 10:30:13,546][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,546][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit25', 'circuit27']
[2024-07-24 10:30:13,546][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,546][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,546][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,546][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:30:13,547][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,547][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:30:13,547][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18']
[2024-07-24 10:30:13,547][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,547][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,547][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,548][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:30:13,548][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,548][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit20']
[2024-07-24 10:30:13,548][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,548][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:30:13,548][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:30:13,549][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,549][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:30:13,549][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,549][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-24 10:30:13,549][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,549][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit23', 'circuit26']
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:30:13,550][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,551][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,551][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,551][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:30:13,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,551][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,551][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,552][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:30:13,552][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:30:13,552][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,552][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:30:13,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,552][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,553][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,553][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,553][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,553][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,553][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:30:13,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:30:13,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,555][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,555][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,555][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,555][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,555][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,555][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:30:13,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,556][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:30:13,556][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,556][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:30:13,556][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit26']
[2024-07-24 10:30:13,556][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,557][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:30:13,557][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:30:13,557][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:30:13,557][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,557][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,557][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,558][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,558][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:30:13,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit16', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,558][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,558][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,558][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit22', 'circuit25']
[2024-07-24 10:30:13,559][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,559][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,559][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:30:13,559][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,559][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,559][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,560][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,560][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,560][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,560][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:30:13,560][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:30:13,560][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,562][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,562][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,562][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,562][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,562][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:30:13,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,563][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,563][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,563][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,563][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,563][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,563][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:30:13,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,564][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,564][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,564][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,564][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,564][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,565][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,566][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:30:13,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,566][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit5']
[2024-07-24 10:30:13,566][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:30:13,566][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,567][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,567][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:30:13,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:30:13,567][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,567][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,567][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,568][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,568][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-24 10:30:13,568][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:30:13,568][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,568][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,569][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,569][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,569][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,569][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:30:13,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,569][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,570][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,570][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,570][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,570][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,570][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:30:13,570][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,571][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,571][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,571][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,571][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,571][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,571][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:30:13,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,572][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,572][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,572][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,572][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,573][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:30:13,573][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,573][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,573][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,573][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,573][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,574][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,574][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,574][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:30:13,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit23']
[2024-07-24 10:30:13,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:30:13,574][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,575][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,575][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,575][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,575][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,575][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:30:13,575][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,576][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:30:13,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:30:13,577][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,577][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,577][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,577][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,577][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,578][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:30:13,578][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:30:13,578][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:13,578][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,578][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,578][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,579][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,579][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,579][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,579][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:30:13,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,580][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,580][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,580][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,580][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,580][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,580][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:30:13,581][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,581][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,581][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,581][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,581][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,582][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,582][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:30:13,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,582][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit26']
[2024-07-24 10:30:13,583][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,584][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,584][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,584][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,584][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,584][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:30:13,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,585][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,585][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,585][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,585][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,585][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15']
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit21', 'circuit24']
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,586][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,587][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,587][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:30:13,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,587][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,588][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,588][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,588][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,588][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:30:13,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:30:13,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:30:13,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,590][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,590][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,590][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,590][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,591][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:30:13,591][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,591][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,592][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,593][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,593][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,593][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,593][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:30:13,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:30:13,594][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,595][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,595][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,595][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,596][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:30:13,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,596][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,596][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,596][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,598][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,598][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,598][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,598][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:30:13,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,599][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,599][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,599][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,599][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,600][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,601][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:30:13,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,601][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,601][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,602][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,603][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,603][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,603][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,603][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:30:13,603][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,603][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,604][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,604][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,604][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,604][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,605][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,606][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:30:13,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,606][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,606][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,606][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,606][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,607][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,607][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,607][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:30:13,607][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,608][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,608][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,608][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:30:13,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,609][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,609][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,609][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,609][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,609][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,610][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:30:13,610][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,610][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,612][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,612][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,612][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,612][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,612][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,612][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:30:13,613][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,613][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,613][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,613][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,615][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18']
[2024-07-24 10:30:13,615][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,615][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,615][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,615][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:30:13,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,616][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,616][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,616][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,618][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,618][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,618][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,618][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:30:13,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,618][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,619][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:30:13,620][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,620][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,620][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,621][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,621][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,621][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:30:13,621][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,621][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,621][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:30:13,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,623][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,623][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,623][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,623][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,625][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,625][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,625][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,625][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:30:13,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:30:13,625][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,626][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,626][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,626][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-24 10:30:13,626][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit26']
[2024-07-24 10:30:13,626][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,626][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,627][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,628][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,628][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,628][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:30:13,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:30:13,629][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:30:13,629][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,629][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:30:13,629][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,629][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:30:13,629][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,630][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,631][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,631][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:30:13,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,631][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,632][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,632][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,632][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,632][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:30:13,632][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,633][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,634][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:30:13,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,634][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,634][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,634][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,635][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,635][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,635][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:30:13,635][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,635][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,636][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:30:13,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,637][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,637][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,637][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,637][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,638][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,639][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,639][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,639][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,639][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:30:13,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,640][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,640][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,640][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,640][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,640][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,640][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,642][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,642][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,642][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,642][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:30:13,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,643][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:30:13,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,644][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,645][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,645][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,645][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:30:13,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:30:13,646][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,647][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,647][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,647][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,648][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,648][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:30:13,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,648][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,648][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,649][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,649][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,649][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,649][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,649][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:30:13,649][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,650][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,650][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,650][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,651][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,651][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:30:13,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,651][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,651][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,651][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,652][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,652][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,652][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,652][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:30:13,652][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,652][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:30:13,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:30:13,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,653][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,653][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,654][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,654][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,654][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,654][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:30:13,654][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,654][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,655][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,655][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,655][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,656][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,656][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:30:13,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,656][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:30:13,657][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit21', 'circuit25']
[2024-07-24 10:30:13,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:30:13,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,658][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21']
[2024-07-24 10:30:13,658][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,659][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit12', 'circuit14', 'circuit15', 'circuit19']
[2024-07-24 10:30:13,659][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit21']
[2024-07-24 10:30:13,659][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:30:13,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,659][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,659][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,660][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,660][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,660][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit19', 'circuit21', 'circuit23', 'circuit27']
[2024-07-24 10:30:13,661][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:30:13,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit23']
[2024-07-24 10:30:13,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,661][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,662][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,662][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,662][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,662][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:30:13,662][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,663][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,664][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,664][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:30:13,664][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,664][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,664][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:30:13,664][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,665][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,665][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:30:13,665][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,665][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,665][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,665][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:30:13,666][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,666][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,666][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,666][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,666][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,666][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,667][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,667][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,667][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,667][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:30:13,667][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,667][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,668][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,668][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,668][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,668][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,668][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,668][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit10', 'circuit13']
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,669][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,670][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,670][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:30:13,670][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,670][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,670][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:30:13,670][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:30:13,671][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,671][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:30:13,671][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,671][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,671][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,671][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,672][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:30:13,673][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,673][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,673][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,673][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:30:13,673][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit16', 'circuit23']
[2024-07-24 10:30:13,673][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:30:13,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,674][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,674][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,674][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,674][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,674][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,675][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,676][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,676][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,676][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,676][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,676][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,676][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,677][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:30:13,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,677][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,677][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,677][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,679][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,679][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,679][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,679][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,679][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,679][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,680][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,680][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:30:13,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,680][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,680][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:30:13,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,682][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,682][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,682][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,682][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,683][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,683][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,683][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:30:13,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,684][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:30:13,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,685][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,685][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,685][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,686][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,686][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,686][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,686][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:30:13,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,687][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,688][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:30:13,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,688][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,689][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,689][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,689][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,689][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,689][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:30:13,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,690][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,691][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,691][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:30:13,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,692][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,692][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,692][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,692][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,692][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,692][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:30:13,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,693][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,694][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,694][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,694][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,694][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:30:13,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,695][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,695][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,695][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,697][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,697][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,697][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,697][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,697][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:30:13,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit26']
[2024-07-24 10:30:13,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,698][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,698][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,699][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:30:13,699][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,699][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,699][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:30:13,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,700][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,700][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,700][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,702][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,702][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,702][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,702][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,702][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,703][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:30:13,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,703][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:30:13,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,705][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,706][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,706][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,706][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,706][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:30:13,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,707][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,708][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,708][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:30:13,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,708][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,709][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,709][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,709][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,709][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,711][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,711][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,711][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,711][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,711][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:30:13,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,712][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,713][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,713][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,713][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,713][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:30:13,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,714][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,715][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,715][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:30:13,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,716][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,716][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,716][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,717][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:30:13,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:30:13,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,720][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,720][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,720][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,720][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:30:13,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,721][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,722][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,722][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:30:13,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,723][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,723][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,723][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,725][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,725][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,725][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,725][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:30:13,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,728][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,728][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,728][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,729][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,729][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:30:13,729][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,729][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,730][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:30:13,731][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,731][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,731][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,731][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,731][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,731][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,732][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,732][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,732][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,732][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,732][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:30:13,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,733][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,733][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,733][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,733][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,735][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,735][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,735][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,735][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,735][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,736][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,736][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:30:13,736][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,736][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,737][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:30:13,738][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,738][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,738][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,738][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,738][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,739][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,739][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,739][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,739][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,739][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:30:13,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,740][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,740][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,740][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,740][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,740][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,742][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,742][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,742][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,742][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,742][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,743][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,743][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:30:13,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,743][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,743][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,744][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:30:13,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,745][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,745][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,745][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,745][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,745][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,746][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,746][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,746][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,746][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,746][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:30:13,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,747][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,747][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,747][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,747][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,747][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,747][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,748][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,748][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,748][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,748][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:30:13,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:13,748][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:13,749][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,749][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit12']
[2024-07-24 10:30:13,749][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit18', 'circuit24', 'circuit26']
[2024-07-24 10:30:13,749][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:13,749][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit25', 'circuit27']
[2024-07-24 10:30:13,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,750][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,750][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:13,750][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:30:13,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,751][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,752][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,752][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,752][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:30:13,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,752][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,753][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,753][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,753][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,753][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,753][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,754][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,755][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,755][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,755][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,755][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,755][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,756][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,756][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:30:13,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,756][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,756][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,757][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,757][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,757][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,757][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,758][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,759][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,759][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,759][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,759][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,759][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,759][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,760][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:30:13,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,760][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,760][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,761][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:30:13,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,762][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,762][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,762][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,762][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:30:13,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,764][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,764][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,764][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,764][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,764][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,765][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,765][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,765][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,765][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,765][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:30:13,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,766][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,767][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,767][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,767][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,767][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:30:13,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,767][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,768][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,768][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,768][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,768][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,768][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,770][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,770][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,770][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,770][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,770][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,770][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,771][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,771][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,771][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:30:13,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,772][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,773][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,773][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:30:13,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,773][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:30:13,774][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,774][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:30:13,774][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,774][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:30:13,774][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:30:13,774][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit25']
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,775][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,776][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,776][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,776][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,776][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,776][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,776][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,777][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:30:13,777][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,777][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,777][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,778][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,778][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,778][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,778][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,778][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,778][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,779][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:30:13,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,779][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,779][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,779][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,779][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,780][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:30:13,781][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,781][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,781][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,781][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,781][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,782][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,782][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,782][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,782][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,782][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,782][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:30:13,783][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,783][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,783][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,783][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,784][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,784][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,784][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,784][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,784][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,784][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:30:13,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,785][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,785][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,785][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,785][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,785][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:30:13,786][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,787][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,787][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,787][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,787][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,787][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,788][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,788][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,788][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,788][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,788][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:30:13,788][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,789][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,789][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,789][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,789][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,789][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,789][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,791][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,791][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,791][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,791][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,791][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,792][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,792][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,792][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,792][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:30:13,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,792][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,793][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,793][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,793][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,793][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,793][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,793][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,794][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,794][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,794][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,794][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:30:13,794][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,794][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,795][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,795][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,795][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,795][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,795][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,795][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,796][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,796][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,796][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,796][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:30:13,796][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:13,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:13,797][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:13,798][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:13,798][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:13,798][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:30:13,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,798][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,798][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,799][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,799][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,799][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,799][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,799][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,799][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,800][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,800][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,800][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:30:13,800][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,800][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,801][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,801][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,801][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,801][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,802][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,802][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,802][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,802][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:30:13,802][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,802][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,803][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,803][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,803][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,803][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,803][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,803][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,804][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,804][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:13,804][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:14,650][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:14,652][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,652][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,652][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,653][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,653][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,653][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,654][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,654][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,654][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,656][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,658][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,662][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,664][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,665][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,665][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,665][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,666][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,666][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,666][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,667][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,667][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,669][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,671][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,675][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,678][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.4942, 0.3661, 0.1398], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,678][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([1.3703e-03, 2.0245e-04, 9.9843e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,679][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.4914, 0.3280, 0.1806], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,679][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([1.0959e-02, 2.5505e-04, 9.8879e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,679][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.0450, 0.0075, 0.9475], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,680][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([2.1286e-01, 2.0449e-05, 7.8712e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,680][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.4489, 0.2731, 0.2780], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,680][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.4806, 0.3944, 0.1250], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,681][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.4762, 0.2734, 0.2503], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,682][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.6505, 0.3136, 0.0359], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,685][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.5047, 0.2159, 0.2794], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,689][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.4778, 0.3661, 0.1561], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,691][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7299, 0.0827, 0.1229, 0.0645], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,692][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3031e-03, 3.9257e-02, 2.3236e-04, 9.5821e-01], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,692][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2360, 0.1767, 0.0434, 0.5438], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,692][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1126, 0.3850, 0.0313, 0.4710], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,693][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3303, 0.1497, 0.2490, 0.2710], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,693][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1233, 0.1974, 0.0050, 0.6743], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,693][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6576, 0.0314, 0.2871, 0.0238], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,694][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2755, 0.2095, 0.1997, 0.3154], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,694][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0668, 0.4675, 0.0274, 0.4383], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,696][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4384, 0.2448, 0.0894, 0.2274], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,698][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4188, 0.3120, 0.0634, 0.2058], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,702][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4578, 0.2000, 0.0810, 0.2613], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,705][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.3054, 0.2553, 0.0666, 0.2077, 0.1650], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,705][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([6.7743e-04, 5.4478e-04, 3.2716e-04, 1.2114e-03, 9.9724e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,706][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.3772, 0.2339, 0.1904, 0.0935, 0.1050], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,706][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([2.6380e-03, 3.4526e-05, 3.7545e-03, 1.3386e-04, 9.9344e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,706][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0111, 0.0020, 0.0360, 0.0037, 0.9472], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,707][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([1.3548e-02, 4.8763e-06, 2.1789e-04, 1.6826e-06, 9.8623e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,707][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.2264, 0.2041, 0.2511, 0.1220, 0.1964], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,707][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.1823, 0.1488, 0.1890, 0.2936, 0.1863], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,708][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.2729, 0.2080, 0.2246, 0.1664, 0.1281], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,709][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.4155, 0.2348, 0.1216, 0.2036, 0.0245], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,712][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.3112, 0.2194, 0.0736, 0.1388, 0.2569], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,716][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.2627, 0.2391, 0.0722, 0.2715, 0.1546], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,718][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.4174, 0.0406, 0.0414, 0.0375, 0.0955, 0.3676], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,719][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ were] are: tensor([1.2444e-03, 8.3454e-03, 2.4576e-03, 7.9883e-03, 8.6765e-04, 9.7910e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,719][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.4060, 0.1364, 0.0591, 0.1423, 0.0995, 0.1567], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,720][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0324, 0.0157, 0.0015, 0.0295, 0.0094, 0.9116], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,720][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3023, 0.0607, 0.0766, 0.0967, 0.1496, 0.3142], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,720][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ were] are: tensor([4.4465e-02, 3.7320e-03, 1.5845e-03, 1.0994e-03, 3.2373e-04, 9.4879e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,721][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.2361, 0.0343, 0.3156, 0.0333, 0.3528, 0.0280], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,721][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1410, 0.1144, 0.1386, 0.2163, 0.1549, 0.2347], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,722][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0863, 0.2877, 0.0305, 0.3580, 0.0405, 0.1970], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,724][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.3236, 0.1840, 0.0803, 0.1897, 0.0842, 0.1383], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,727][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2579, 0.1962, 0.0522, 0.1526, 0.0553, 0.2858], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,732][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.3559, 0.1755, 0.0570, 0.1991, 0.0867, 0.1257], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,732][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.3980, 0.0839, 0.1119, 0.0960, 0.1077, 0.1446, 0.0579],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,733][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ working] are: tensor([1.2298e-04, 1.0628e-03, 1.3287e-04, 2.3741e-03, 1.1541e-04, 4.5858e-04,
        9.9573e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,733][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.3385, 0.1320, 0.0568, 0.1395, 0.0673, 0.1184, 0.1475],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,733][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ working] are: tensor([5.7512e-03, 2.6414e-04, 7.1042e-04, 6.5362e-04, 3.2112e-03, 2.8317e-03,
        9.8658e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,734][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0846, 0.0224, 0.0280, 0.0239, 0.0718, 0.0370, 0.7323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,734][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ working] are: tensor([4.9274e-03, 4.2461e-05, 3.4688e-05, 2.7755e-05, 8.4050e-06, 9.2174e-06,
        9.9495e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,734][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.3161, 0.0389, 0.2146, 0.0301, 0.2470, 0.0382, 0.1150],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,735][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.1366, 0.0894, 0.0141, 0.1912, 0.1080, 0.3492, 0.1116],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,737][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.1736, 0.1528, 0.0696, 0.2505, 0.0890, 0.2095, 0.0550],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,739][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.2991, 0.1705, 0.0764, 0.1661, 0.0927, 0.1462, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,743][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.2140, 0.1690, 0.0478, 0.1365, 0.0454, 0.0787, 0.3087],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,746][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.3513, 0.1416, 0.0610, 0.1465, 0.0759, 0.0651, 0.1586],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,746][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.3677, 0.0586, 0.1447, 0.0537, 0.0977, 0.0549, 0.1875, 0.0352],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,746][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.2528e-04, 1.9082e-03, 1.5415e-04, 4.3583e-03, 2.3702e-04, 9.0219e-05,
        4.5215e-04, 9.9207e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,747][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2851, 0.1608, 0.0414, 0.1679, 0.0393, 0.1117, 0.0431, 0.1507],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,747][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0029, 0.0021, 0.0032, 0.0058, 0.0045, 0.0129, 0.0617, 0.9068],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,748][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1050, 0.0139, 0.0199, 0.0225, 0.0393, 0.1399, 0.4071, 0.2525],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,748][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0646, 0.0257, 0.0022, 0.0101, 0.0015, 0.0143, 0.0053, 0.8764],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,748][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2266, 0.0195, 0.2546, 0.0181, 0.2441, 0.0531, 0.1591, 0.0249],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,750][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0639, 0.0336, 0.0324, 0.0842, 0.0821, 0.1300, 0.2817, 0.2921],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,753][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0416, 0.2054, 0.0172, 0.3471, 0.0136, 0.1827, 0.0377, 0.1548],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,757][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2175, 0.1520, 0.0625, 0.1600, 0.0586, 0.1147, 0.0975, 0.1371],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,759][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.2093, 0.1652, 0.0456, 0.1492, 0.0486, 0.0706, 0.0615, 0.2501],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,759][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3028, 0.1061, 0.0527, 0.1170, 0.0829, 0.0668, 0.1251, 0.1466],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:14,760][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4829, 0.0472, 0.0860, 0.0306, 0.1497, 0.0526, 0.0962, 0.0255, 0.0292],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,760][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.4390e-03, 2.5084e-02, 2.0904e-04, 5.3048e-02, 4.9569e-04, 1.0957e-03,
        5.3044e-04, 5.8436e-02, 8.5766e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,761][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.2274, 0.1198, 0.0309, 0.1236, 0.0459, 0.1498, 0.0762, 0.1912, 0.0351],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,761][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0211, 0.0064, 0.0032, 0.0100, 0.0144, 0.0716, 0.0694, 0.1800, 0.6238],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,762][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1372, 0.0193, 0.0256, 0.0277, 0.0625, 0.1369, 0.2861, 0.1679, 0.1369],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,762][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1004, 0.1348, 0.0140, 0.1035, 0.0176, 0.0797, 0.0822, 0.0843, 0.3835],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,762][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2386, 0.0046, 0.2674, 0.0042, 0.2920, 0.0248, 0.1576, 0.0081, 0.0028],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,764][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0643, 0.0230, 0.0255, 0.0510, 0.0623, 0.0801, 0.1268, 0.2792, 0.2879],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,767][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0140, 0.1206, 0.0137, 0.1855, 0.0077, 0.1248, 0.0231, 0.0710, 0.4397],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,771][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2230, 0.1280, 0.0527, 0.1297, 0.0636, 0.0982, 0.0740, 0.1173, 0.1134],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,773][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2252, 0.1424, 0.0691, 0.1278, 0.0555, 0.0626, 0.0689, 0.0844, 0.1641],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,774][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2322, 0.0970, 0.0547, 0.1060, 0.0906, 0.0801, 0.1242, 0.0995, 0.1156],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:14,774][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1908, 0.1101, 0.0894, 0.1148, 0.1086, 0.0733, 0.0453, 0.0799, 0.0945,
        0.0931], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,774][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ station] are: tensor([4.5607e-04, 1.1388e-03, 4.1348e-04, 2.8763e-03, 2.0833e-04, 1.0575e-03,
        3.9483e-03, 4.2310e-03, 3.6656e-04, 9.8530e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,775][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1744, 0.0819, 0.0366, 0.0736, 0.1506, 0.0661, 0.0607, 0.0991, 0.0700,
        0.1869], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,775][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ station] are: tensor([9.8553e-03, 4.3671e-05, 2.2799e-04, 8.7042e-05, 3.1970e-05, 1.5226e-03,
        7.3359e-03, 1.2933e-03, 8.8032e-04, 9.7872e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,776][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0336, 0.0030, 0.0126, 0.0041, 0.0022, 0.0105, 0.1280, 0.0227, 0.0157,
        0.7675], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,776][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ station] are: tensor([4.2090e-02, 3.5240e-05, 4.1267e-04, 1.0847e-05, 2.3069e-05, 3.3361e-06,
        4.9590e-05, 2.2656e-05, 2.9244e-06, 9.5735e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,777][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1925, 0.0548, 0.2300, 0.0293, 0.1234, 0.0148, 0.1069, 0.0142, 0.0277,
        0.2064], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,780][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0315, 0.0387, 0.0064, 0.0464, 0.0077, 0.0656, 0.1324, 0.2080, 0.3137,
        0.1495], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,783][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1209, 0.1319, 0.0965, 0.1230, 0.0404, 0.0580, 0.1071, 0.0904, 0.0848,
        0.1468], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,787][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1903, 0.1262, 0.1052, 0.1124, 0.0889, 0.0858, 0.0749, 0.0939, 0.1074,
        0.0150], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,789][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1148, 0.1004, 0.0510, 0.1107, 0.0452, 0.0620, 0.0668, 0.1040, 0.0798,
        0.2655], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,790][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.2130, 0.1004, 0.0476, 0.0901, 0.0479, 0.0854, 0.1034, 0.0964, 0.0411,
        0.1748], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:14,790][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.5267, 0.0187, 0.0730, 0.0153, 0.0816, 0.0564, 0.0645, 0.0193, 0.0423,
        0.0902, 0.0121], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,790][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.4263e-03, 4.1871e-02, 1.1797e-04, 7.7838e-03, 4.3201e-04, 3.0500e-04,
        1.6618e-03, 1.8154e-03, 3.6541e-04, 1.5507e-04, 9.4207e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,791][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.4055, 0.0561, 0.0329, 0.0460, 0.0518, 0.2006, 0.0502, 0.0582, 0.0248,
        0.0218, 0.0522], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,791][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0203, 0.0041, 0.0022, 0.0054, 0.0053, 0.0322, 0.0329, 0.0592, 0.1569,
        0.2450, 0.4365], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,792][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0529, 0.0201, 0.0102, 0.0415, 0.0208, 0.0468, 0.0652, 0.1392, 0.1189,
        0.1406, 0.3437], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,795][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1261, 0.1934, 0.0250, 0.1173, 0.0142, 0.0812, 0.0223, 0.0694, 0.0759,
        0.0163, 0.2590], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,798][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.3447, 0.0096, 0.1499, 0.0070, 0.2213, 0.0265, 0.0997, 0.0110, 0.0060,
        0.1200, 0.0042], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,802][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0331, 0.0112, 0.0115, 0.0236, 0.0242, 0.0363, 0.0481, 0.1038, 0.1558,
        0.1245, 0.4281], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,803][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0186, 0.1696, 0.0093, 0.1311, 0.0052, 0.0318, 0.0140, 0.0463, 0.1541,
        0.0072, 0.4129], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,803][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1841, 0.1056, 0.0595, 0.1074, 0.0694, 0.0851, 0.0648, 0.0873, 0.0885,
        0.0447, 0.1035], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,803][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1467, 0.1289, 0.0465, 0.1287, 0.0536, 0.0923, 0.0693, 0.0909, 0.0728,
        0.0302, 0.1401], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,804][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2401, 0.0849, 0.0482, 0.0838, 0.0623, 0.0601, 0.1007, 0.0905, 0.0412,
        0.0700, 0.1182], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:14,804][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.1676, 0.1100, 0.0392, 0.0947, 0.1094, 0.0276, 0.0351, 0.0958, 0.0708,
        0.0413, 0.0900, 0.1184], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,805][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([2.8048e-04, 1.1835e-04, 7.6797e-05, 3.2693e-04, 5.1662e-01, 1.2708e-04,
        1.1640e-04, 2.6870e-04, 7.7803e-05, 3.2990e-05, 2.5447e-05, 4.8193e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,805][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.1843, 0.1026, 0.1185, 0.0515, 0.0822, 0.0629, 0.0195, 0.0903, 0.0845,
        0.0272, 0.1004, 0.0761], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,806][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([1.9299e-04, 3.3357e-07, 2.5147e-05, 6.4265e-07, 7.6839e-03, 3.5877e-06,
        1.0278e-05, 2.6651e-05, 3.6275e-05, 1.2800e-04, 4.6594e-05, 9.9185e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,808][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([2.0366e-03, 2.4396e-04, 3.1482e-03, 3.9286e-04, 8.9300e-02, 5.6734e-04,
        4.9398e-04, 1.2965e-03, 8.9969e-04, 7.1590e-04, 2.4146e-03, 8.9849e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,809][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([2.7363e-03, 8.2364e-07, 7.0165e-05, 3.0604e-07, 5.6645e-01, 3.1478e-07,
        9.0366e-07, 2.2078e-07, 2.0264e-07, 2.4008e-07, 1.2042e-08, 4.3074e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,813][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.1182, 0.0972, 0.1663, 0.0663, 0.1371, 0.0273, 0.0408, 0.0203, 0.0526,
        0.0996, 0.0527, 0.1216], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,816][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0528, 0.0175, 0.0222, 0.0300, 0.0169, 0.0382, 0.0148, 0.1088, 0.1264,
        0.0641, 0.3179, 0.1905], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,816][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.1369, 0.0975, 0.1314, 0.0897, 0.0768, 0.0450, 0.0388, 0.0705, 0.0857,
        0.0266, 0.1129, 0.0882], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,817][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.1970, 0.1157, 0.0721, 0.1055, 0.0149, 0.0765, 0.0623, 0.0875, 0.0897,
        0.0670, 0.0977, 0.0142], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,817][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.1152, 0.0860, 0.0464, 0.0769, 0.2302, 0.0485, 0.0254, 0.0560, 0.0536,
        0.0147, 0.0540, 0.1931], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,818][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.1071, 0.0955, 0.0329, 0.0956, 0.0724, 0.0787, 0.0745, 0.0951, 0.0640,
        0.0663, 0.1211, 0.0968], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:14,818][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.2814, 0.0373, 0.0444, 0.0315, 0.0838, 0.0891, 0.0554, 0.0343, 0.0356,
        0.0334, 0.0398, 0.1119, 0.1220], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,818][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([8.7293e-04, 2.9659e-04, 2.6381e-03, 1.5314e-04, 1.0243e-04, 1.6859e-03,
        9.7762e-03, 1.3313e-04, 9.4497e-05, 2.4151e-04, 4.6263e-05, 5.6032e-05,
        9.8390e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,820][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.2476, 0.0468, 0.0518, 0.0859, 0.0466, 0.0868, 0.0652, 0.0741, 0.0733,
        0.0460, 0.0659, 0.0427, 0.0672], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,822][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.0469e-04, 1.4812e-05, 6.8932e-06, 1.1871e-05, 1.0379e-06, 1.6301e-04,
        2.8488e-04, 1.0296e-04, 1.5240e-04, 5.9425e-04, 7.1349e-04, 5.9899e-05,
        9.9699e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,824][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([3.3858e-02, 4.0242e-03, 2.6638e-03, 6.0698e-03, 5.3735e-04, 1.2969e-02,
        1.9584e-02, 2.3620e-02, 1.4535e-02, 3.1546e-02, 2.0500e-02, 2.7556e-03,
        8.2734e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,827][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([5.0326e-02, 4.0875e-05, 4.1241e-04, 2.4073e-05, 2.2540e-06, 9.6136e-05,
        5.4004e-04, 1.8342e-05, 1.7621e-06, 1.0043e-05, 2.2209e-06, 7.2084e-07,
        9.4853e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,829][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1569, 0.0202, 0.1048, 0.0186, 0.1669, 0.0240, 0.0581, 0.0178, 0.0164,
        0.0925, 0.0205, 0.2018, 0.1015], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,830][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0412, 0.0117, 0.0043, 0.0197, 0.0046, 0.0233, 0.0101, 0.0648, 0.1009,
        0.0743, 0.3711, 0.0694, 0.2046], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,830][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.1212, 0.0747, 0.0398, 0.1135, 0.0305, 0.1228, 0.0751, 0.0906, 0.1440,
        0.0380, 0.0892, 0.0369, 0.0236], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,830][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1653, 0.0783, 0.0513, 0.0803, 0.0629, 0.0802, 0.0730, 0.0661, 0.0692,
        0.0491, 0.0969, 0.0713, 0.0560], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,831][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1560, 0.0779, 0.0516, 0.0742, 0.0340, 0.0866, 0.0561, 0.0554, 0.0651,
        0.0254, 0.0719, 0.0309, 0.2149], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,831][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.2773, 0.0875, 0.0402, 0.0742, 0.0477, 0.0426, 0.0636, 0.1022, 0.0308,
        0.0493, 0.0796, 0.0487, 0.0563], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:14,832][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2475, 0.0247, 0.0433, 0.0207, 0.0717, 0.0756, 0.0523, 0.0194, 0.0294,
        0.0582, 0.0201, 0.0975, 0.2238, 0.0158], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,833][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.3053e-03, 1.2867e-02, 1.6668e-04, 3.6907e-02, 2.3971e-05, 2.5915e-04,
        1.2310e-03, 1.9365e-02, 1.8908e-03, 1.9389e-04, 7.7359e-03, 1.4096e-05,
        2.9478e-05, 9.1501e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,836][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1278, 0.0575, 0.0174, 0.0788, 0.0234, 0.0575, 0.0545, 0.1087, 0.0229,
        0.0126, 0.2228, 0.0238, 0.0535, 0.1388], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,838][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.7739e-03, 5.1801e-04, 5.5704e-05, 3.8618e-04, 2.3513e-05, 1.9233e-03,
        4.9763e-04, 3.5635e-03, 1.5331e-02, 2.9842e-03, 2.5436e-02, 1.4362e-03,
        1.0083e-01, 8.4224e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,840][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3849e-02, 9.6747e-04, 6.9227e-04, 1.6583e-03, 3.0222e-04, 1.0947e-02,
        2.7975e-02, 7.7614e-03, 6.1559e-03, 1.3554e-02, 1.0446e-02, 2.4886e-03,
        8.0540e-01, 9.7806e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,843][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0504, 0.0688, 0.0038, 0.0854, 0.0014, 0.0209, 0.0230, 0.0262, 0.2203,
        0.0024, 0.0284, 0.0006, 0.0072, 0.4612], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,843][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1212, 0.0062, 0.0445, 0.0052, 0.0616, 0.0201, 0.0709, 0.0206, 0.0039,
        0.0869, 0.0063, 0.0938, 0.1509, 0.3080], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,844][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0218, 0.0047, 0.0054, 0.0079, 0.0058, 0.0098, 0.0167, 0.0234, 0.0388,
        0.0279, 0.1827, 0.0865, 0.3180, 0.2505], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,844][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0092, 0.0694, 0.0044, 0.1193, 0.0036, 0.0582, 0.0116, 0.0504, 0.2214,
        0.0127, 0.1702, 0.0050, 0.0078, 0.2570], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,845][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1306, 0.0823, 0.0352, 0.0901, 0.0450, 0.0668, 0.0537, 0.0787, 0.0826,
        0.0397, 0.0822, 0.0489, 0.0578, 0.1064], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,845][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1140, 0.0952, 0.0360, 0.1114, 0.0305, 0.0704, 0.0597, 0.0876, 0.0872,
        0.0291, 0.0847, 0.0260, 0.0478, 0.1203], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,847][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1810, 0.0723, 0.0437, 0.0735, 0.0514, 0.0591, 0.0792, 0.0743, 0.0354,
        0.0585, 0.0817, 0.0530, 0.0620, 0.0750], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:14,849][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2693, 0.0278, 0.0538, 0.0291, 0.0453, 0.0513, 0.0520, 0.0190, 0.0313,
        0.0726, 0.0202, 0.0546, 0.1951, 0.0287, 0.0499], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,852][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([2.8054e-04, 5.0198e-04, 5.2927e-05, 4.3017e-04, 3.6037e-04, 1.6400e-04,
        6.5000e-04, 7.7862e-04, 2.1430e-04, 4.6131e-05, 4.8486e-05, 2.4877e-04,
        1.3324e-03, 5.6639e-04, 9.9432e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,856][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1418, 0.0388, 0.0148, 0.0489, 0.0237, 0.0793, 0.1678, 0.0731, 0.0476,
        0.0148, 0.0762, 0.0228, 0.1010, 0.1032, 0.0465], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,856][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([6.5444e-04, 6.5712e-06, 1.3065e-06, 8.2677e-06, 5.6169e-06, 3.9850e-05,
        8.2328e-05, 6.5443e-05, 2.1152e-04, 8.8629e-05, 3.5357e-04, 4.6955e-04,
        8.8142e-03, 8.6146e-03, 9.8058e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,857][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0403, 0.0056, 0.0060, 0.0071, 0.0018, 0.0181, 0.0217, 0.0237, 0.0163,
        0.0124, 0.0222, 0.0097, 0.1313, 0.1236, 0.5604], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,857][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([1.4317e-02, 6.4282e-05, 8.7276e-05, 3.0903e-05, 5.4216e-05, 3.8636e-05,
        1.7581e-04, 3.3031e-05, 2.2160e-05, 3.8980e-07, 4.5964e-06, 1.9607e-05,
        1.6421e-04, 8.3687e-06, 9.8498e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,858][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1203, 0.0126, 0.0946, 0.0112, 0.1769, 0.0143, 0.0665, 0.0110, 0.0112,
        0.1269, 0.0101, 0.2300, 0.0816, 0.0103, 0.0225], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,858][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0190, 0.0049, 0.0034, 0.0067, 0.0057, 0.0078, 0.0058, 0.0240, 0.0313,
        0.0151, 0.1223, 0.0661, 0.1446, 0.3097, 0.2335], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,859][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0659, 0.0703, 0.0125, 0.1055, 0.0149, 0.1027, 0.0440, 0.0715, 0.1026,
        0.0427, 0.0845, 0.0183, 0.0461, 0.1699, 0.0486], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,860][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1212, 0.0675, 0.0357, 0.0736, 0.0441, 0.0724, 0.0590, 0.0622, 0.0646,
        0.0456, 0.0861, 0.0500, 0.0705, 0.0923, 0.0550], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,863][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0912, 0.0620, 0.0251, 0.0722, 0.0333, 0.0579, 0.0473, 0.0705, 0.0606,
        0.0250, 0.0701, 0.0327, 0.0654, 0.0855, 0.2011], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,866][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2444, 0.0695, 0.0313, 0.0822, 0.0365, 0.0347, 0.0769, 0.0746, 0.0191,
        0.0498, 0.0700, 0.0340, 0.0468, 0.0588, 0.0714], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:14,870][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2818, 0.0225, 0.0474, 0.0176, 0.0657, 0.0258, 0.0511, 0.0136, 0.0246,
        0.0591, 0.0180, 0.0874, 0.1577, 0.0170, 0.0878, 0.0231],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,870][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.7230e-04, 2.0360e-03, 1.5602e-04, 2.2684e-03, 1.8339e-04, 7.8969e-05,
        2.3348e-04, 6.4602e-03, 2.5996e-02, 4.2891e-05, 5.0523e-04, 1.3086e-04,
        8.8128e-05, 6.8428e-03, 1.0195e-03, 9.5319e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,871][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0986, 0.0511, 0.0202, 0.0760, 0.0236, 0.0592, 0.0631, 0.1089, 0.0171,
        0.0125, 0.1511, 0.0257, 0.0622, 0.1477, 0.0655, 0.0175],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,871][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.2560e-03, 3.6561e-04, 5.6360e-05, 2.4969e-04, 2.0896e-04, 6.8502e-04,
        6.6350e-04, 1.3240e-03, 5.3123e-03, 2.3183e-03, 8.0411e-03, 9.9389e-03,
        1.7114e-02, 6.4354e-02, 1.2707e-01, 7.5805e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,872][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0252, 0.0031, 0.0018, 0.0034, 0.0029, 0.0142, 0.0276, 0.0128, 0.0099,
        0.0085, 0.0114, 0.0180, 0.2257, 0.0704, 0.3714, 0.1937],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,872][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0276, 0.0835, 0.0024, 0.0734, 0.0015, 0.0117, 0.0323, 0.0618, 0.1928,
        0.0017, 0.0246, 0.0006, 0.0056, 0.0503, 0.0101, 0.4201],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,874][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1309, 0.0031, 0.1009, 0.0030, 0.1162, 0.0192, 0.0944, 0.0058, 0.0025,
        0.1155, 0.0025, 0.1733, 0.1363, 0.0087, 0.0828, 0.0049],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,876][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0177, 0.0035, 0.0031, 0.0056, 0.0050, 0.0060, 0.0064, 0.0150, 0.0178,
        0.0136, 0.0951, 0.0568, 0.0986, 0.1403, 0.2252, 0.2903],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,880][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0082, 0.0414, 0.0043, 0.0716, 0.0034, 0.0507, 0.0101, 0.0357, 0.1870,
        0.0103, 0.1003, 0.0050, 0.0091, 0.1213, 0.0189, 0.3228],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,883][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1169, 0.0721, 0.0288, 0.0787, 0.0399, 0.0579, 0.0438, 0.0678, 0.0683,
        0.0359, 0.0710, 0.0434, 0.0497, 0.0923, 0.0573, 0.0762],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,883][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0874, 0.0693, 0.0349, 0.0805, 0.0322, 0.0397, 0.0470, 0.0794, 0.0915,
        0.0273, 0.0618, 0.0301, 0.0426, 0.0839, 0.0379, 0.1545],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,884][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1730, 0.0662, 0.0401, 0.0626, 0.0501, 0.0496, 0.0718, 0.0564, 0.0367,
        0.0512, 0.0719, 0.0497, 0.0508, 0.0685, 0.0520, 0.0495],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:14,884][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1775, 0.0611, 0.0295, 0.0468, 0.0654, 0.0463, 0.0642, 0.0453, 0.0231,
        0.0590, 0.0413, 0.0744, 0.0764, 0.0322, 0.0422, 0.0335, 0.0817],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,885][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([2.1271e-04, 5.6321e-04, 3.2564e-05, 3.2375e-04, 1.6010e-04, 7.4734e-05,
        2.0829e-03, 1.6061e-04, 2.7383e-04, 2.8942e-04, 2.2655e-04, 1.0443e-04,
        1.7327e-04, 2.3363e-04, 1.6488e-05, 8.4163e-05, 9.9499e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,885][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1457, 0.0412, 0.0281, 0.0538, 0.0505, 0.0468, 0.0850, 0.0625, 0.0668,
        0.0330, 0.0558, 0.0498, 0.0362, 0.0590, 0.0294, 0.0608, 0.0955],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,886][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([1.2694e-04, 1.3745e-07, 1.6282e-06, 2.4839e-07, 5.2942e-06, 8.3873e-07,
        6.8864e-05, 2.8720e-06, 4.0288e-06, 3.9418e-05, 5.5025e-06, 2.7306e-04,
        1.1850e-04, 1.1798e-04, 4.3648e-04, 2.9580e-04, 9.9850e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,887][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([2.4583e-02, 1.8408e-03, 3.8913e-04, 1.0582e-03, 2.9623e-03, 8.9375e-04,
        9.9458e-03, 2.2717e-03, 2.5418e-03, 2.4804e-03, 4.4755e-03, 1.2093e-02,
        3.9147e-03, 8.5383e-03, 2.5057e-02, 2.2258e-02, 8.7470e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,888][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([2.5569e-03, 3.1632e-05, 2.9522e-05, 4.6013e-06, 5.4559e-05, 1.0945e-06,
        2.8187e-04, 2.4149e-06, 1.0845e-05, 1.4941e-05, 5.8895e-07, 1.9692e-05,
        6.1000e-06, 4.1780e-07, 1.8723e-07, 4.6784e-06, 9.9698e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,891][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1034, 0.0257, 0.1250, 0.0142, 0.0686, 0.0108, 0.0881, 0.0145, 0.0114,
        0.1545, 0.0215, 0.0652, 0.0247, 0.0146, 0.0258, 0.0139, 0.2181],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,894][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0436, 0.0054, 0.0043, 0.0085, 0.0062, 0.0113, 0.0199, 0.0144, 0.0188,
        0.0232, 0.0598, 0.0490, 0.0725, 0.1280, 0.1554, 0.2783, 0.1012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,896][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1195, 0.0642, 0.0255, 0.0683, 0.0255, 0.0456, 0.0894, 0.0537, 0.0785,
        0.0436, 0.0559, 0.0281, 0.0209, 0.0656, 0.0386, 0.0646, 0.1127],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,897][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1149, 0.0675, 0.0636, 0.0619, 0.0475, 0.0451, 0.0547, 0.0508, 0.0633,
        0.0713, 0.0640, 0.0514, 0.0440, 0.0621, 0.0478, 0.0757, 0.0145],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,897][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0948, 0.0563, 0.0233, 0.0578, 0.0322, 0.0397, 0.0579, 0.0413, 0.0594,
        0.0343, 0.0514, 0.0303, 0.0331, 0.0503, 0.0227, 0.0494, 0.2658],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,898][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.2134, 0.0829, 0.0300, 0.0659, 0.0408, 0.0428, 0.0611, 0.0668, 0.0230,
        0.0478, 0.0618, 0.0393, 0.0360, 0.0565, 0.0709, 0.0242, 0.0367],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:14,898][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2086, 0.0186, 0.0348, 0.0157, 0.0577, 0.0602, 0.0404, 0.0143, 0.0225,
        0.0456, 0.0154, 0.0773, 0.1883, 0.0118, 0.0697, 0.0250, 0.0795, 0.0145],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,899][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.1829e-03, 5.3197e-03, 6.8686e-05, 1.5308e-02, 1.0231e-05, 1.1442e-04,
        4.8415e-04, 8.3643e-03, 8.6545e-04, 9.3956e-05, 3.8233e-03, 6.7928e-06,
        1.3165e-05, 4.5318e-01, 3.8031e-04, 5.9033e-04, 2.9523e-05, 5.0917e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,900][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1021, 0.0428, 0.0136, 0.0619, 0.0198, 0.0468, 0.0446, 0.0854, 0.0176,
        0.0108, 0.1751, 0.0206, 0.0447, 0.1096, 0.0468, 0.0175, 0.0216, 0.1186],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,902][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.3472e-03, 7.6092e-05, 7.4101e-06, 3.9779e-05, 2.1343e-06, 1.2725e-04,
        3.0241e-05, 1.6718e-04, 6.7706e-04, 1.5482e-04, 1.1534e-03, 6.6964e-05,
        4.1753e-03, 3.0275e-02, 2.7022e-01, 6.8845e-02, 1.4778e-02, 6.0785e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,904][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.5368e-02, 8.6635e-04, 5.6262e-04, 1.3175e-03, 2.0093e-04, 6.7139e-03,
        1.5158e-02, 3.7956e-03, 2.8627e-03, 6.3750e-03, 4.6140e-03, 1.0527e-03,
        3.4524e-01, 3.9212e-02, 1.8575e-01, 5.8043e-02, 1.2515e-01, 1.8773e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,908][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0261, 0.0379, 0.0024, 0.0518, 0.0009, 0.0134, 0.0140, 0.0171, 0.1385,
        0.0014, 0.0165, 0.0004, 0.0044, 0.2919, 0.0099, 0.1022, 0.0032, 0.2681],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,909][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0725, 0.0033, 0.0263, 0.0029, 0.0370, 0.0113, 0.0424, 0.0118, 0.0021,
        0.0518, 0.0034, 0.0571, 0.0924, 0.1826, 0.0492, 0.0043, 0.1209, 0.2288],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,910][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0166, 0.0026, 0.0029, 0.0037, 0.0023, 0.0033, 0.0054, 0.0060, 0.0093,
        0.0070, 0.0431, 0.0198, 0.0662, 0.0486, 0.1009, 0.1774, 0.1845, 0.3003],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,910][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0057, 0.0415, 0.0028, 0.0746, 0.0023, 0.0366, 0.0074, 0.0303, 0.1306,
        0.0077, 0.1027, 0.0032, 0.0050, 0.1545, 0.0127, 0.1721, 0.0106, 0.1998],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,911][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0985, 0.0594, 0.0272, 0.0668, 0.0360, 0.0500, 0.0410, 0.0573, 0.0598,
        0.0312, 0.0623, 0.0393, 0.0454, 0.0776, 0.0530, 0.0703, 0.0371, 0.0878],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,911][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0770, 0.0602, 0.0255, 0.0764, 0.0230, 0.0517, 0.0454, 0.0653, 0.0653,
        0.0252, 0.0688, 0.0223, 0.0410, 0.0979, 0.0500, 0.0729, 0.0310, 0.1010],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,912][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1555, 0.0605, 0.0385, 0.0614, 0.0432, 0.0491, 0.0626, 0.0597, 0.0291,
        0.0460, 0.0619, 0.0413, 0.0486, 0.0579, 0.0463, 0.0377, 0.0427, 0.0581],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:14,924][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:14,925][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,925][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,925][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,926][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,926][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,926][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,927][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,927][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,927][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,928][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,928][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,928][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:14,929][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,931][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,932][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,932][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,932][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,933][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,933][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,933][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,934][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,935][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,938][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,942][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:14,944][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.4942, 0.3661, 0.1398], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,945][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([1.3703e-03, 2.0245e-04, 9.9843e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,945][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.4914, 0.3280, 0.1806], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,945][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([1.0959e-02, 2.5505e-04, 9.8879e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,946][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.0450, 0.0075, 0.9475], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,946][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([2.1286e-01, 2.0449e-05, 7.8712e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,946][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.4489, 0.2731, 0.2780], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,947][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.4806, 0.3944, 0.1250], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,947][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.4762, 0.2734, 0.2503], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,948][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.6505, 0.3136, 0.0359], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,951][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.5047, 0.2159, 0.2794], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,954][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.4778, 0.3661, 0.1561], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:14,958][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7299, 0.0827, 0.1229, 0.0645], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,958][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3031e-03, 3.9257e-02, 2.3236e-04, 9.5821e-01], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,959][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2360, 0.1767, 0.0434, 0.5438], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,959][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1126, 0.3850, 0.0313, 0.4710], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,959][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3303, 0.1497, 0.2490, 0.2710], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,960][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1233, 0.1974, 0.0050, 0.6743], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,960][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6576, 0.0314, 0.2871, 0.0238], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,961][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2755, 0.2095, 0.1997, 0.3154], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,963][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0668, 0.4675, 0.0274, 0.4383], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,966][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4384, 0.2448, 0.0894, 0.2274], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,969][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4188, 0.3120, 0.0634, 0.2058], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,971][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4578, 0.2000, 0.0810, 0.2613], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:14,971][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.3054, 0.2553, 0.0666, 0.2077, 0.1650], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,972][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([6.7743e-04, 5.4478e-04, 3.2716e-04, 1.2114e-03, 9.9724e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,972][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.3772, 0.2339, 0.1904, 0.0935, 0.1050], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,972][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([2.6380e-03, 3.4526e-05, 3.7545e-03, 1.3386e-04, 9.9344e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,973][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0111, 0.0020, 0.0360, 0.0037, 0.9472], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,973][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([1.3548e-02, 4.8763e-06, 2.1789e-04, 1.6826e-06, 9.8623e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,974][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.2264, 0.2041, 0.2511, 0.1220, 0.1964], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,977][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1823, 0.1488, 0.1890, 0.2936, 0.1863], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,980][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.2729, 0.2080, 0.2246, 0.1664, 0.1281], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,984][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.4155, 0.2348, 0.1216, 0.2036, 0.0245], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,984][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.3112, 0.2194, 0.0736, 0.1388, 0.2569], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,985][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.2627, 0.2391, 0.0722, 0.2715, 0.1546], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:14,985][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.4174, 0.0406, 0.0414, 0.0375, 0.0955, 0.3676], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,985][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([1.2444e-03, 8.3454e-03, 2.4576e-03, 7.9883e-03, 8.6765e-04, 9.7910e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,986][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.4060, 0.1364, 0.0591, 0.1423, 0.0995, 0.1567], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,986][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0324, 0.0157, 0.0015, 0.0295, 0.0094, 0.9116], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,987][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.3023, 0.0607, 0.0766, 0.0967, 0.1496, 0.3142], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,987][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([4.4465e-02, 3.7320e-03, 1.5845e-03, 1.0994e-03, 3.2373e-04, 9.4879e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,989][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.2361, 0.0343, 0.3156, 0.0333, 0.3528, 0.0280], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,991][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1410, 0.1144, 0.1386, 0.2163, 0.1549, 0.2347], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,995][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0863, 0.2877, 0.0305, 0.3580, 0.0405, 0.1970], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,998][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.3236, 0.1840, 0.0803, 0.1897, 0.0842, 0.1383], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,998][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2579, 0.1962, 0.0522, 0.1526, 0.0553, 0.2858], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,998][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.3559, 0.1755, 0.0570, 0.1991, 0.0867, 0.1257], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:14,999][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.3980, 0.0839, 0.1119, 0.0960, 0.1077, 0.1446, 0.0579],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:14,999][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([1.2298e-04, 1.0628e-03, 1.3287e-04, 2.3741e-03, 1.1541e-04, 4.5858e-04,
        9.9573e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,000][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.3385, 0.1320, 0.0568, 0.1395, 0.0673, 0.1184, 0.1475],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,000][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([5.7512e-03, 2.6414e-04, 7.1042e-04, 6.5362e-04, 3.2112e-03, 2.8317e-03,
        9.8658e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,000][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0846, 0.0224, 0.0280, 0.0239, 0.0718, 0.0370, 0.7323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,001][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([4.9274e-03, 4.2461e-05, 3.4688e-05, 2.7755e-05, 8.4050e-06, 9.2174e-06,
        9.9495e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,004][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.3161, 0.0389, 0.2146, 0.0301, 0.2470, 0.0382, 0.1150],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,007][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.1366, 0.0894, 0.0141, 0.1912, 0.1080, 0.3492, 0.1116],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,011][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.1736, 0.1528, 0.0696, 0.2505, 0.0890, 0.2095, 0.0550],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,011][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.2991, 0.1705, 0.0764, 0.1661, 0.0927, 0.1462, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,012][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.2140, 0.1690, 0.0478, 0.1365, 0.0454, 0.0787, 0.3087],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,012][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.3513, 0.1416, 0.0610, 0.1465, 0.0759, 0.0651, 0.1586],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,013][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.3677, 0.0586, 0.1447, 0.0537, 0.0977, 0.0549, 0.1875, 0.0352],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,013][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.2528e-04, 1.9082e-03, 1.5415e-04, 4.3583e-03, 2.3702e-04, 9.0219e-05,
        4.5215e-04, 9.9207e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,013][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2851, 0.1608, 0.0414, 0.1679, 0.0393, 0.1117, 0.0431, 0.1507],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,015][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0029, 0.0021, 0.0032, 0.0058, 0.0045, 0.0129, 0.0617, 0.9068],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,018][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1050, 0.0139, 0.0199, 0.0225, 0.0393, 0.1399, 0.4071, 0.2525],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,022][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0646, 0.0257, 0.0022, 0.0101, 0.0015, 0.0143, 0.0053, 0.8764],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,024][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2266, 0.0195, 0.2546, 0.0181, 0.2441, 0.0531, 0.1591, 0.0249],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,024][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0639, 0.0336, 0.0324, 0.0842, 0.0821, 0.1300, 0.2817, 0.2921],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,025][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0416, 0.2054, 0.0172, 0.3471, 0.0136, 0.1827, 0.0377, 0.1548],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,025][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2175, 0.1520, 0.0625, 0.1600, 0.0586, 0.1147, 0.0975, 0.1371],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,026][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2093, 0.1652, 0.0456, 0.1492, 0.0486, 0.0706, 0.0615, 0.2501],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,026][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.3028, 0.1061, 0.0527, 0.1170, 0.0829, 0.0668, 0.1251, 0.1466],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,026][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4829, 0.0472, 0.0860, 0.0306, 0.1497, 0.0526, 0.0962, 0.0255, 0.0292],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,027][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.4390e-03, 2.5084e-02, 2.0904e-04, 5.3048e-02, 4.9569e-04, 1.0957e-03,
        5.3044e-04, 5.8436e-02, 8.5766e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,029][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2274, 0.1198, 0.0309, 0.1236, 0.0459, 0.1498, 0.0762, 0.1912, 0.0351],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,031][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0211, 0.0064, 0.0032, 0.0100, 0.0144, 0.0716, 0.0694, 0.1800, 0.6238],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,035][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1372, 0.0193, 0.0256, 0.0277, 0.0625, 0.1369, 0.2861, 0.1679, 0.1369],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,038][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1004, 0.1348, 0.0140, 0.1035, 0.0176, 0.0797, 0.0822, 0.0843, 0.3835],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,038][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2386, 0.0046, 0.2674, 0.0042, 0.2920, 0.0248, 0.1576, 0.0081, 0.0028],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,038][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0643, 0.0230, 0.0255, 0.0510, 0.0623, 0.0801, 0.1268, 0.2792, 0.2879],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,039][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0140, 0.1206, 0.0137, 0.1855, 0.0077, 0.1248, 0.0231, 0.0710, 0.4397],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,039][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2230, 0.1280, 0.0527, 0.1297, 0.0636, 0.0982, 0.0740, 0.1173, 0.1134],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,040][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2252, 0.1424, 0.0691, 0.1278, 0.0555, 0.0626, 0.0689, 0.0844, 0.1641],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,040][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2322, 0.0970, 0.0547, 0.1060, 0.0906, 0.0801, 0.1242, 0.0995, 0.1156],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,042][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1908, 0.1101, 0.0894, 0.1148, 0.1086, 0.0733, 0.0453, 0.0799, 0.0945,
        0.0931], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,044][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([4.5607e-04, 1.1388e-03, 4.1348e-04, 2.8763e-03, 2.0833e-04, 1.0575e-03,
        3.9483e-03, 4.2310e-03, 3.6656e-04, 9.8530e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,048][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1744, 0.0819, 0.0366, 0.0736, 0.1506, 0.0661, 0.0607, 0.0991, 0.0700,
        0.1869], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,050][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([9.8553e-03, 4.3671e-05, 2.2799e-04, 8.7042e-05, 3.1970e-05, 1.5226e-03,
        7.3359e-03, 1.2933e-03, 8.8032e-04, 9.7872e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,051][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0336, 0.0030, 0.0126, 0.0041, 0.0022, 0.0105, 0.1280, 0.0227, 0.0157,
        0.7675], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,051][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([4.2090e-02, 3.5240e-05, 4.1267e-04, 1.0847e-05, 2.3069e-05, 3.3361e-06,
        4.9590e-05, 2.2656e-05, 2.9244e-06, 9.5735e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,052][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.1925, 0.0548, 0.2300, 0.0293, 0.1234, 0.0148, 0.1069, 0.0142, 0.0277,
        0.2064], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,052][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0315, 0.0387, 0.0064, 0.0464, 0.0077, 0.0656, 0.1324, 0.2080, 0.3137,
        0.1495], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,052][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1209, 0.1319, 0.0965, 0.1230, 0.0404, 0.0580, 0.1071, 0.0904, 0.0848,
        0.1468], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,053][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1903, 0.1262, 0.1052, 0.1124, 0.0889, 0.0858, 0.0749, 0.0939, 0.1074,
        0.0150], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,053][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1148, 0.1004, 0.0510, 0.1107, 0.0452, 0.0620, 0.0668, 0.1040, 0.0798,
        0.2655], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,055][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.2130, 0.1004, 0.0476, 0.0901, 0.0479, 0.0854, 0.1034, 0.0964, 0.0411,
        0.1748], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,058][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.5267, 0.0187, 0.0730, 0.0153, 0.0816, 0.0564, 0.0645, 0.0193, 0.0423,
        0.0902, 0.0121], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,060][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.4263e-03, 4.1871e-02, 1.1797e-04, 7.7838e-03, 4.3201e-04, 3.0500e-04,
        1.6618e-03, 1.8154e-03, 3.6541e-04, 1.5507e-04, 9.4207e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,064][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.4055, 0.0561, 0.0329, 0.0460, 0.0518, 0.2006, 0.0502, 0.0582, 0.0248,
        0.0218, 0.0522], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,064][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0203, 0.0041, 0.0022, 0.0054, 0.0053, 0.0322, 0.0329, 0.0592, 0.1569,
        0.2450, 0.4365], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,065][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0529, 0.0201, 0.0102, 0.0415, 0.0208, 0.0468, 0.0652, 0.1392, 0.1189,
        0.1406, 0.3437], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,065][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1261, 0.1934, 0.0250, 0.1173, 0.0142, 0.0812, 0.0223, 0.0694, 0.0759,
        0.0163, 0.2590], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,066][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.3447, 0.0096, 0.1499, 0.0070, 0.2213, 0.0265, 0.0997, 0.0110, 0.0060,
        0.1200, 0.0042], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,066][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0331, 0.0112, 0.0115, 0.0236, 0.0242, 0.0363, 0.0481, 0.1038, 0.1558,
        0.1245, 0.4281], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,066][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0186, 0.1696, 0.0093, 0.1311, 0.0052, 0.0318, 0.0140, 0.0463, 0.1541,
        0.0072, 0.4129], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,068][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1841, 0.1056, 0.0595, 0.1074, 0.0694, 0.0851, 0.0648, 0.0873, 0.0885,
        0.0447, 0.1035], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,072][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1467, 0.1289, 0.0465, 0.1287, 0.0536, 0.0923, 0.0693, 0.0909, 0.0728,
        0.0302, 0.1401], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,075][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2401, 0.0849, 0.0482, 0.0838, 0.0623, 0.0601, 0.1007, 0.0905, 0.0412,
        0.0700, 0.1182], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,077][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.1676, 0.1100, 0.0392, 0.0947, 0.1094, 0.0276, 0.0351, 0.0958, 0.0708,
        0.0413, 0.0900, 0.1184], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,077][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([2.8048e-04, 1.1835e-04, 7.6797e-05, 3.2693e-04, 5.1662e-01, 1.2708e-04,
        1.1640e-04, 2.6870e-04, 7.7803e-05, 3.2990e-05, 2.5447e-05, 4.8193e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,078][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.1843, 0.1026, 0.1185, 0.0515, 0.0822, 0.0629, 0.0195, 0.0903, 0.0845,
        0.0272, 0.1004, 0.0761], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,078][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([1.9299e-04, 3.3357e-07, 2.5147e-05, 6.4265e-07, 7.6839e-03, 3.5877e-06,
        1.0278e-05, 2.6651e-05, 3.6275e-05, 1.2800e-04, 4.6594e-05, 9.9185e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,079][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([2.0366e-03, 2.4396e-04, 3.1482e-03, 3.9286e-04, 8.9300e-02, 5.6734e-04,
        4.9398e-04, 1.2965e-03, 8.9969e-04, 7.1590e-04, 2.4146e-03, 8.9849e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,079][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([2.7363e-03, 8.2364e-07, 7.0165e-05, 3.0604e-07, 5.6645e-01, 3.1478e-07,
        9.0366e-07, 2.2078e-07, 2.0264e-07, 2.4008e-07, 1.2042e-08, 4.3074e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,080][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.1182, 0.0972, 0.1663, 0.0663, 0.1371, 0.0273, 0.0408, 0.0203, 0.0526,
        0.0996, 0.0527, 0.1216], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,081][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0528, 0.0175, 0.0222, 0.0300, 0.0169, 0.0382, 0.0148, 0.1088, 0.1264,
        0.0641, 0.3179, 0.1905], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,084][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1369, 0.0975, 0.1314, 0.0897, 0.0768, 0.0450, 0.0388, 0.0705, 0.0857,
        0.0266, 0.1129, 0.0882], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,087][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.1970, 0.1157, 0.0721, 0.1055, 0.0149, 0.0765, 0.0623, 0.0875, 0.0897,
        0.0670, 0.0977, 0.0142], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,091][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.1152, 0.0860, 0.0464, 0.0769, 0.2302, 0.0485, 0.0254, 0.0560, 0.0536,
        0.0147, 0.0540, 0.1931], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,091][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.1071, 0.0955, 0.0329, 0.0956, 0.0724, 0.0787, 0.0745, 0.0951, 0.0640,
        0.0663, 0.1211, 0.0968], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,092][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.2814, 0.0373, 0.0444, 0.0315, 0.0838, 0.0891, 0.0554, 0.0343, 0.0356,
        0.0334, 0.0398, 0.1119, 0.1220], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,092][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([8.7293e-04, 2.9659e-04, 2.6381e-03, 1.5314e-04, 1.0243e-04, 1.6859e-03,
        9.7762e-03, 1.3313e-04, 9.4497e-05, 2.4151e-04, 4.6263e-05, 5.6032e-05,
        9.8390e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,092][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.2476, 0.0468, 0.0518, 0.0859, 0.0466, 0.0868, 0.0652, 0.0741, 0.0733,
        0.0460, 0.0659, 0.0427, 0.0672], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,093][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.0469e-04, 1.4812e-05, 6.8932e-06, 1.1871e-05, 1.0379e-06, 1.6301e-04,
        2.8488e-04, 1.0296e-04, 1.5240e-04, 5.9425e-04, 7.1349e-04, 5.9899e-05,
        9.9699e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,094][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([3.3858e-02, 4.0242e-03, 2.6638e-03, 6.0698e-03, 5.3735e-04, 1.2969e-02,
        1.9584e-02, 2.3620e-02, 1.4535e-02, 3.1546e-02, 2.0500e-02, 2.7556e-03,
        8.2734e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,095][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([5.0326e-02, 4.0875e-05, 4.1241e-04, 2.4073e-05, 2.2540e-06, 9.6136e-05,
        5.4004e-04, 1.8342e-05, 1.7621e-06, 1.0043e-05, 2.2209e-06, 7.2084e-07,
        9.4853e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,099][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1569, 0.0202, 0.1048, 0.0186, 0.1669, 0.0240, 0.0581, 0.0178, 0.0164,
        0.0925, 0.0205, 0.2018, 0.1015], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,102][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0412, 0.0117, 0.0043, 0.0197, 0.0046, 0.0233, 0.0101, 0.0648, 0.1009,
        0.0743, 0.3711, 0.0694, 0.2046], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,104][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.1212, 0.0747, 0.0398, 0.1135, 0.0305, 0.1228, 0.0751, 0.0906, 0.1440,
        0.0380, 0.0892, 0.0369, 0.0236], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,104][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.1653, 0.0783, 0.0513, 0.0803, 0.0629, 0.0802, 0.0730, 0.0661, 0.0692,
        0.0491, 0.0969, 0.0713, 0.0560], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,105][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1560, 0.0779, 0.0516, 0.0742, 0.0340, 0.0866, 0.0561, 0.0554, 0.0651,
        0.0254, 0.0719, 0.0309, 0.2149], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,105][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.2773, 0.0875, 0.0402, 0.0742, 0.0477, 0.0426, 0.0636, 0.1022, 0.0308,
        0.0493, 0.0796, 0.0487, 0.0563], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,105][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2475, 0.0247, 0.0433, 0.0207, 0.0717, 0.0756, 0.0523, 0.0194, 0.0294,
        0.0582, 0.0201, 0.0975, 0.2238, 0.0158], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,106][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.3053e-03, 1.2867e-02, 1.6668e-04, 3.6907e-02, 2.3971e-05, 2.5915e-04,
        1.2310e-03, 1.9365e-02, 1.8908e-03, 1.9389e-04, 7.7359e-03, 1.4096e-05,
        2.9478e-05, 9.1501e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,106][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1278, 0.0575, 0.0174, 0.0788, 0.0234, 0.0575, 0.0545, 0.1087, 0.0229,
        0.0126, 0.2228, 0.0238, 0.0535, 0.1388], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,108][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.7739e-03, 5.1801e-04, 5.5704e-05, 3.8618e-04, 2.3513e-05, 1.9233e-03,
        4.9763e-04, 3.5635e-03, 1.5331e-02, 2.9842e-03, 2.5436e-02, 1.4362e-03,
        1.0083e-01, 8.4224e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,109][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3849e-02, 9.6747e-04, 6.9227e-04, 1.6583e-03, 3.0222e-04, 1.0947e-02,
        2.7975e-02, 7.7614e-03, 6.1559e-03, 1.3554e-02, 1.0446e-02, 2.4886e-03,
        8.0540e-01, 9.7806e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,112][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0504, 0.0688, 0.0038, 0.0854, 0.0014, 0.0209, 0.0230, 0.0262, 0.2203,
        0.0024, 0.0284, 0.0006, 0.0072, 0.4612], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,115][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1212, 0.0062, 0.0445, 0.0052, 0.0616, 0.0201, 0.0709, 0.0206, 0.0039,
        0.0869, 0.0063, 0.0938, 0.1509, 0.3080], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,117][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0218, 0.0047, 0.0054, 0.0079, 0.0058, 0.0098, 0.0167, 0.0234, 0.0388,
        0.0279, 0.1827, 0.0865, 0.3180, 0.2505], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,118][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0092, 0.0694, 0.0044, 0.1193, 0.0036, 0.0582, 0.0116, 0.0504, 0.2214,
        0.0127, 0.1702, 0.0050, 0.0078, 0.2570], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,118][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1306, 0.0823, 0.0352, 0.0901, 0.0450, 0.0668, 0.0537, 0.0787, 0.0826,
        0.0397, 0.0822, 0.0489, 0.0578, 0.1064], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,119][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1140, 0.0952, 0.0360, 0.1114, 0.0305, 0.0704, 0.0597, 0.0876, 0.0872,
        0.0291, 0.0847, 0.0260, 0.0478, 0.1203], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,119][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1810, 0.0723, 0.0437, 0.0735, 0.0514, 0.0591, 0.0792, 0.0743, 0.0354,
        0.0585, 0.0817, 0.0530, 0.0620, 0.0750], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,120][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2693, 0.0278, 0.0538, 0.0291, 0.0453, 0.0513, 0.0520, 0.0190, 0.0313,
        0.0726, 0.0202, 0.0546, 0.1951, 0.0287, 0.0499], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,121][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.8054e-04, 5.0198e-04, 5.2927e-05, 4.3017e-04, 3.6037e-04, 1.6400e-04,
        6.5000e-04, 7.7862e-04, 2.1430e-04, 4.6131e-05, 4.8486e-05, 2.4877e-04,
        1.3324e-03, 5.6639e-04, 9.9432e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,123][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1418, 0.0388, 0.0148, 0.0489, 0.0237, 0.0793, 0.1678, 0.0731, 0.0476,
        0.0148, 0.0762, 0.0228, 0.1010, 0.1032, 0.0465], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,125][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([6.5444e-04, 6.5712e-06, 1.3065e-06, 8.2677e-06, 5.6169e-06, 3.9850e-05,
        8.2328e-05, 6.5443e-05, 2.1152e-04, 8.8629e-05, 3.5357e-04, 4.6955e-04,
        8.8142e-03, 8.6146e-03, 9.8058e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,129][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0403, 0.0056, 0.0060, 0.0071, 0.0018, 0.0181, 0.0217, 0.0237, 0.0163,
        0.0124, 0.0222, 0.0097, 0.1313, 0.1236, 0.5604], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,131][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.4317e-02, 6.4282e-05, 8.7276e-05, 3.0903e-05, 5.4216e-05, 3.8636e-05,
        1.7581e-04, 3.3031e-05, 2.2160e-05, 3.8980e-07, 4.5964e-06, 1.9607e-05,
        1.6421e-04, 8.3687e-06, 9.8498e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,131][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1203, 0.0126, 0.0946, 0.0112, 0.1769, 0.0143, 0.0665, 0.0110, 0.0112,
        0.1269, 0.0101, 0.2300, 0.0816, 0.0103, 0.0225], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,131][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0190, 0.0049, 0.0034, 0.0067, 0.0057, 0.0078, 0.0058, 0.0240, 0.0313,
        0.0151, 0.1223, 0.0661, 0.1446, 0.3097, 0.2335], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,132][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0659, 0.0703, 0.0125, 0.1055, 0.0149, 0.1027, 0.0440, 0.0715, 0.1026,
        0.0427, 0.0845, 0.0183, 0.0461, 0.1699, 0.0486], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,132][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1212, 0.0675, 0.0357, 0.0736, 0.0441, 0.0724, 0.0590, 0.0622, 0.0646,
        0.0456, 0.0861, 0.0500, 0.0705, 0.0923, 0.0550], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,133][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0912, 0.0620, 0.0251, 0.0722, 0.0333, 0.0579, 0.0473, 0.0705, 0.0606,
        0.0250, 0.0701, 0.0327, 0.0654, 0.0855, 0.2011], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,133][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2444, 0.0695, 0.0313, 0.0822, 0.0365, 0.0347, 0.0769, 0.0746, 0.0191,
        0.0498, 0.0700, 0.0340, 0.0468, 0.0588, 0.0714], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,135][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2818, 0.0225, 0.0474, 0.0176, 0.0657, 0.0258, 0.0511, 0.0136, 0.0246,
        0.0591, 0.0180, 0.0874, 0.1577, 0.0170, 0.0878, 0.0231],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,137][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.7230e-04, 2.0360e-03, 1.5602e-04, 2.2684e-03, 1.8339e-04, 7.8969e-05,
        2.3348e-04, 6.4602e-03, 2.5996e-02, 4.2891e-05, 5.0523e-04, 1.3086e-04,
        8.8128e-05, 6.8428e-03, 1.0195e-03, 9.5319e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,140][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0986, 0.0511, 0.0202, 0.0760, 0.0236, 0.0592, 0.0631, 0.1089, 0.0171,
        0.0125, 0.1511, 0.0257, 0.0622, 0.1477, 0.0655, 0.0175],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,142][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.2560e-03, 3.6561e-04, 5.6360e-05, 2.4969e-04, 2.0896e-04, 6.8502e-04,
        6.6350e-04, 1.3240e-03, 5.3123e-03, 2.3183e-03, 8.0411e-03, 9.9389e-03,
        1.7114e-02, 6.4354e-02, 1.2707e-01, 7.5805e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,144][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0252, 0.0031, 0.0018, 0.0034, 0.0029, 0.0142, 0.0276, 0.0128, 0.0099,
        0.0085, 0.0114, 0.0180, 0.2257, 0.0704, 0.3714, 0.1937],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,145][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0276, 0.0835, 0.0024, 0.0734, 0.0015, 0.0117, 0.0323, 0.0618, 0.1928,
        0.0017, 0.0246, 0.0006, 0.0056, 0.0503, 0.0101, 0.4201],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,145][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1309, 0.0031, 0.1009, 0.0030, 0.1162, 0.0192, 0.0944, 0.0058, 0.0025,
        0.1155, 0.0025, 0.1733, 0.1363, 0.0087, 0.0828, 0.0049],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,146][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0177, 0.0035, 0.0031, 0.0056, 0.0050, 0.0060, 0.0064, 0.0150, 0.0178,
        0.0136, 0.0951, 0.0568, 0.0986, 0.1403, 0.2252, 0.2903],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,146][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0082, 0.0414, 0.0043, 0.0716, 0.0034, 0.0507, 0.0101, 0.0357, 0.1870,
        0.0103, 0.1003, 0.0050, 0.0091, 0.1213, 0.0189, 0.3228],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,147][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1169, 0.0721, 0.0288, 0.0787, 0.0399, 0.0579, 0.0438, 0.0678, 0.0683,
        0.0359, 0.0710, 0.0434, 0.0497, 0.0923, 0.0573, 0.0762],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,148][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0874, 0.0693, 0.0349, 0.0805, 0.0322, 0.0397, 0.0470, 0.0794, 0.0915,
        0.0273, 0.0618, 0.0301, 0.0426, 0.0839, 0.0379, 0.1545],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,151][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1730, 0.0662, 0.0401, 0.0626, 0.0501, 0.0496, 0.0718, 0.0564, 0.0367,
        0.0512, 0.0719, 0.0497, 0.0508, 0.0685, 0.0520, 0.0495],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,155][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1775, 0.0611, 0.0295, 0.0468, 0.0654, 0.0463, 0.0642, 0.0453, 0.0231,
        0.0590, 0.0413, 0.0744, 0.0764, 0.0322, 0.0422, 0.0335, 0.0817],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,157][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([2.1271e-04, 5.6321e-04, 3.2564e-05, 3.2375e-04, 1.6010e-04, 7.4734e-05,
        2.0829e-03, 1.6061e-04, 2.7383e-04, 2.8942e-04, 2.2655e-04, 1.0443e-04,
        1.7327e-04, 2.3363e-04, 1.6488e-05, 8.4163e-05, 9.9499e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,158][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1457, 0.0412, 0.0281, 0.0538, 0.0505, 0.0468, 0.0850, 0.0625, 0.0668,
        0.0330, 0.0558, 0.0498, 0.0362, 0.0590, 0.0294, 0.0608, 0.0955],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,158][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([1.2694e-04, 1.3745e-07, 1.6282e-06, 2.4839e-07, 5.2942e-06, 8.3873e-07,
        6.8864e-05, 2.8720e-06, 4.0288e-06, 3.9418e-05, 5.5025e-06, 2.7306e-04,
        1.1850e-04, 1.1798e-04, 4.3648e-04, 2.9580e-04, 9.9850e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,159][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([2.4583e-02, 1.8408e-03, 3.8913e-04, 1.0582e-03, 2.9623e-03, 8.9375e-04,
        9.9458e-03, 2.2717e-03, 2.5418e-03, 2.4804e-03, 4.4755e-03, 1.2093e-02,
        3.9147e-03, 8.5383e-03, 2.5057e-02, 2.2258e-02, 8.7470e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,159][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.5569e-03, 3.1632e-05, 2.9522e-05, 4.6013e-06, 5.4559e-05, 1.0945e-06,
        2.8187e-04, 2.4149e-06, 1.0845e-05, 1.4941e-05, 5.8895e-07, 1.9692e-05,
        6.1000e-06, 4.1780e-07, 1.8723e-07, 4.6784e-06, 9.9698e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,160][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1034, 0.0257, 0.1250, 0.0142, 0.0686, 0.0108, 0.0881, 0.0145, 0.0114,
        0.1545, 0.0215, 0.0652, 0.0247, 0.0146, 0.0258, 0.0139, 0.2181],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,160][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0436, 0.0054, 0.0043, 0.0085, 0.0062, 0.0113, 0.0199, 0.0144, 0.0188,
        0.0232, 0.0598, 0.0490, 0.0725, 0.1280, 0.1554, 0.2783, 0.1012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,162][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1195, 0.0642, 0.0255, 0.0683, 0.0255, 0.0456, 0.0894, 0.0537, 0.0785,
        0.0436, 0.0559, 0.0281, 0.0209, 0.0656, 0.0386, 0.0646, 0.1127],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,164][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1149, 0.0675, 0.0636, 0.0619, 0.0475, 0.0451, 0.0547, 0.0508, 0.0633,
        0.0713, 0.0640, 0.0514, 0.0440, 0.0621, 0.0478, 0.0757, 0.0145],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,169][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0948, 0.0563, 0.0233, 0.0578, 0.0322, 0.0397, 0.0579, 0.0413, 0.0594,
        0.0343, 0.0514, 0.0303, 0.0331, 0.0503, 0.0227, 0.0494, 0.2658],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,171][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.2134, 0.0829, 0.0300, 0.0659, 0.0408, 0.0428, 0.0611, 0.0668, 0.0230,
        0.0478, 0.0618, 0.0393, 0.0360, 0.0565, 0.0709, 0.0242, 0.0367],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,171][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2086, 0.0186, 0.0348, 0.0157, 0.0577, 0.0602, 0.0404, 0.0143, 0.0225,
        0.0456, 0.0154, 0.0773, 0.1883, 0.0118, 0.0697, 0.0250, 0.0795, 0.0145],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,172][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.1829e-03, 5.3197e-03, 6.8686e-05, 1.5308e-02, 1.0231e-05, 1.1442e-04,
        4.8415e-04, 8.3643e-03, 8.6545e-04, 9.3956e-05, 3.8233e-03, 6.7928e-06,
        1.3165e-05, 4.5318e-01, 3.8031e-04, 5.9033e-04, 2.9523e-05, 5.0917e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,172][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1021, 0.0428, 0.0136, 0.0619, 0.0198, 0.0468, 0.0446, 0.0854, 0.0176,
        0.0108, 0.1751, 0.0206, 0.0447, 0.1096, 0.0468, 0.0175, 0.0216, 0.1186],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,173][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.3472e-03, 7.6092e-05, 7.4101e-06, 3.9779e-05, 2.1343e-06, 1.2725e-04,
        3.0241e-05, 1.6718e-04, 6.7706e-04, 1.5482e-04, 1.1534e-03, 6.6964e-05,
        4.1753e-03, 3.0275e-02, 2.7022e-01, 6.8845e-02, 1.4778e-02, 6.0785e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,173][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.5368e-02, 8.6635e-04, 5.6262e-04, 1.3175e-03, 2.0093e-04, 6.7139e-03,
        1.5158e-02, 3.7956e-03, 2.8627e-03, 6.3750e-03, 4.6140e-03, 1.0527e-03,
        3.4524e-01, 3.9212e-02, 1.8575e-01, 5.8043e-02, 1.2515e-01, 1.8773e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,176][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0261, 0.0379, 0.0024, 0.0518, 0.0009, 0.0134, 0.0140, 0.0171, 0.1385,
        0.0014, 0.0165, 0.0004, 0.0044, 0.2919, 0.0099, 0.1022, 0.0032, 0.2681],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,179][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0725, 0.0033, 0.0263, 0.0029, 0.0370, 0.0113, 0.0424, 0.0118, 0.0021,
        0.0518, 0.0034, 0.0571, 0.0924, 0.1826, 0.0492, 0.0043, 0.1209, 0.2288],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,183][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0166, 0.0026, 0.0029, 0.0037, 0.0023, 0.0033, 0.0054, 0.0060, 0.0093,
        0.0070, 0.0431, 0.0198, 0.0662, 0.0486, 0.1009, 0.1774, 0.1845, 0.3003],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,186][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0057, 0.0415, 0.0028, 0.0746, 0.0023, 0.0366, 0.0074, 0.0303, 0.1306,
        0.0077, 0.1027, 0.0032, 0.0050, 0.1545, 0.0127, 0.1721, 0.0106, 0.1998],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,186][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0985, 0.0594, 0.0272, 0.0668, 0.0360, 0.0500, 0.0410, 0.0573, 0.0598,
        0.0312, 0.0623, 0.0393, 0.0454, 0.0776, 0.0530, 0.0703, 0.0371, 0.0878],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,187][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0770, 0.0602, 0.0255, 0.0764, 0.0230, 0.0517, 0.0454, 0.0653, 0.0653,
        0.0252, 0.0688, 0.0223, 0.0410, 0.0979, 0.0500, 0.0729, 0.0310, 0.1010],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,187][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1555, 0.0605, 0.0385, 0.0614, 0.0432, 0.0491, 0.0626, 0.0597, 0.0291,
        0.0460, 0.0619, 0.0413, 0.0486, 0.0579, 0.0463, 0.0377, 0.0427, 0.0581],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,188][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:15,190][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9897],
        [29944],
        [    1],
        [20338],
        [  639],
        [20774],
        [39509],
        [36055],
        [37810],
        [30016],
        [16395],
        [  525],
        [35055],
        [24707],
        [33315],
        [36079],
        [38487],
        [26703]], device='cuda:0')
[2024-07-24 10:30:15,193][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[47996],
        [47761],
        [    1],
        [45974],
        [ 1084],
        [46768],
        [44869],
        [45013],
        [36312],
        [43454],
        [43293],
        [  542],
        [41292],
        [38244],
        [39452],
        [26973],
        [45047],
        [32955]], device='cuda:0')
[2024-07-24 10:30:15,195][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18212],
        [17539],
        [ 8858],
        [12117],
        [ 6772],
        [28910],
        [13847],
        [10402],
        [ 9540],
        [ 8242],
        [12429],
        [ 6573],
        [ 8769],
        [ 9508],
        [10006],
        [ 7182],
        [11762],
        [11909]], device='cuda:0')
[2024-07-24 10:30:15,198][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12768],
        [ 8809],
        [  777],
        [28570],
        [12510],
        [41763],
        [46570],
        [38832],
        [49721],
        [20608],
        [11641],
        [12589],
        [33756],
        [34649],
        [37484],
        [48123],
        [28272],
        [34811]], device='cuda:0')
[2024-07-24 10:30:15,201][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23734],
        [20555],
        [17158],
        [13232],
        [12965],
        [21726],
        [26845],
        [26071],
        [30640],
        [30805],
        [31708],
        [26451],
        [31860],
        [39042],
        [39689],
        [36708],
        [31931],
        [37976]], device='cuda:0')
[2024-07-24 10:30:15,202][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[31083],
        [32500],
        [ 1011],
        [18158],
        [ 3216],
        [ 1995],
        [ 6742],
        [24504],
        [16664],
        [12703],
        [32313],
        [ 1770],
        [21137],
        [17211],
        [30456],
        [11934],
        [11871],
        [17553]], device='cuda:0')
[2024-07-24 10:30:15,203][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32428],
        [31673],
        [  770],
        [ 5922],
        [ 4404],
        [11055],
        [26031],
        [22777],
        [17577],
        [33701],
        [ 4313],
        [ 4122],
        [21306],
        [20968],
        [12084],
        [12510],
        [11995],
        [14701]], device='cuda:0')
[2024-07-24 10:30:15,204][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[27390],
        [36212],
        [20177],
        [36392],
        [32336],
        [34963],
        [47361],
        [35860],
        [34906],
        [41030],
        [39016],
        [32263],
        [40212],
        [36233],
        [36111],
        [31948],
        [25134],
        [35685]], device='cuda:0')
[2024-07-24 10:30:15,205][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[22547],
        [22455],
        [ 3948],
        [ 3747],
        [ 1672],
        [  391],
        [ 1066],
        [  894],
        [  779],
        [ 2750],
        [ 2344],
        [ 1921],
        [ 1479],
        [ 5166],
        [ 1201],
        [ 2893],
        [25923],
        [ 7483]], device='cuda:0')
[2024-07-24 10:30:15,208][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[11394],
        [10846],
        [ 4743],
        [13364],
        [ 6384],
        [18079],
        [41507],
        [38742],
        [35749],
        [43823],
        [23157],
        [ 5412],
        [13486],
        [24837],
        [31958],
        [40127],
        [41742],
        [43097]], device='cuda:0')
[2024-07-24 10:30:15,211][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17505],
        [24658],
        [13869],
        [21468],
        [11468],
        [28471],
        [27052],
        [24881],
        [19048],
        [21214],
        [11505],
        [10441],
        [17159],
        [14096],
        [16260],
        [19233],
        [23775],
        [17108]], device='cuda:0')
[2024-07-24 10:30:15,213][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[33137],
        [36878],
        [37385],
        [37982],
        [38166],
        [38997],
        [38747],
        [38105],
        [35763],
        [35896],
        [35678],
        [35815],
        [35316],
        [36308],
        [35550],
        [34357],
        [33678],
        [35279]], device='cuda:0')
[2024-07-24 10:30:15,216][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 4278],
        [ 4009],
        [ 8692],
        [ 6008],
        [18622],
        [ 6313],
        [ 8095],
        [ 3873],
        [14499],
        [12968],
        [ 7433],
        [38409],
        [11560],
        [ 7629],
        [ 9076],
        [18256],
        [35812],
        [ 9856]], device='cuda:0')
[2024-07-24 10:30:15,217][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23497],
        [27487],
        [29895],
        [28667],
        [31371],
        [29419],
        [24948],
        [26049],
        [31737],
        [27502],
        [30943],
        [33199],
        [30663],
        [29803],
        [27683],
        [30864],
        [29224],
        [29662]], device='cuda:0')
[2024-07-24 10:30:15,218][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10703],
        [11585],
        [    1],
        [ 7157],
        [ 1007],
        [22791],
        [33469],
        [26495],
        [33006],
        [42134],
        [ 7779],
        [  903],
        [44286],
        [10228],
        [31124],
        [29023],
        [36507],
        [10249]], device='cuda:0')
[2024-07-24 10:30:15,219][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25373],
        [25980],
        [26667],
        [25878],
        [26697],
        [17456],
        [22449],
        [27511],
        [26921],
        [25869],
        [24962],
        [27516],
        [22295],
        [21201],
        [22923],
        [23968],
        [23602],
        [20930]], device='cuda:0')
[2024-07-24 10:30:15,221][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14687],
        [27016],
        [38377],
        [14767],
        [26622],
        [14441],
        [18409],
        [ 6057],
        [ 4691],
        [25180],
        [21601],
        [24951],
        [21247],
        [ 3143],
        [15287],
        [ 3308],
        [23114],
        [ 2753]], device='cuda:0')
[2024-07-24 10:30:15,223][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[36890],
        [31526],
        [33334],
        [47157],
        [40930],
        [46425],
        [43318],
        [43758],
        [43231],
        [43081],
        [43187],
        [43492],
        [43860],
        [37497],
        [37189],
        [39079],
        [39962],
        [36212]], device='cuda:0')
[2024-07-24 10:30:15,226][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[26165],
        [23827],
        [18032],
        [17655],
        [14597],
        [18582],
        [19799],
        [18097],
        [14327],
        [22503],
        [18458],
        [19586],
        [17117],
        [21613],
        [21284],
        [17850],
        [21317],
        [21726]], device='cuda:0')
[2024-07-24 10:30:15,229][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20721],
        [20769],
        [23084],
        [21948],
        [25047],
        [16087],
        [20634],
        [20882],
        [18728],
        [20448],
        [18199],
        [20406],
        [34071],
        [34251],
        [16975],
        [19667],
        [35342],
        [25465]], device='cuda:0')
[2024-07-24 10:30:15,231][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19874],
        [ 2593],
        [ 1824],
        [ 1736],
        [ 5688],
        [  946],
        [ 1341],
        [ 1512],
        [  481],
        [ 2222],
        [ 1237],
        [ 6306],
        [ 2710],
        [ 1297],
        [ 1271],
        [  791],
        [ 4419],
        [ 1496]], device='cuda:0')
[2024-07-24 10:30:15,232][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[42708],
        [42771],
        [15745],
        [15075],
        [ 5531],
        [ 1990],
        [ 3455],
        [ 2779],
        [ 2734],
        [ 3974],
        [ 5384],
        [ 3143],
        [ 2694],
        [27814],
        [ 2863],
        [ 4988],
        [14998],
        [42410]], device='cuda:0')
[2024-07-24 10:30:15,233][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5965],
        [ 6588],
        [10359],
        [ 7445],
        [ 9991],
        [14923],
        [10648],
        [14397],
        [12918],
        [12357],
        [22062],
        [21356],
        [16819],
        [ 7572],
        [ 6772],
        [10390],
        [ 9378],
        [ 4649]], device='cuda:0')
[2024-07-24 10:30:15,235][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[40145],
        [28498],
        [30183],
        [26194],
        [27808],
        [27928],
        [28654],
        [29695],
        [25420],
        [26402],
        [28559],
        [25885],
        [27943],
        [28628],
        [29633],
        [24660],
        [23329],
        [27426]], device='cuda:0')
[2024-07-24 10:30:15,236][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9094],
        [ 9000],
        [ 9164],
        [ 9701],
        [ 9879],
        [13652],
        [15305],
        [17812],
        [17519],
        [17558],
        [15746],
        [15317],
        [17673],
        [17405],
        [19389],
        [19093],
        [18640],
        [18750]], device='cuda:0')
[2024-07-24 10:30:15,238][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[35917],
        [37899],
        [34163],
        [36630],
        [31333],
        [36983],
        [33303],
        [36947],
        [34931],
        [33837],
        [34715],
        [29255],
        [30854],
        [34375],
        [33596],
        [32337],
        [30971],
        [33791]], device='cuda:0')
[2024-07-24 10:30:15,241][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18350],
        [12151],
        [ 9560],
        [ 5095],
        [11303],
        [ 7650],
        [ 5877],
        [ 8228],
        [ 5483],
        [ 5475],
        [ 5288],
        [ 8249],
        [ 7611],
        [ 7352],
        [ 6463],
        [ 6270],
        [ 6394],
        [ 6038]], device='cuda:0')
[2024-07-24 10:30:15,244][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5513],
        [ 7902],
        [12195],
        [14256],
        [14761],
        [17538],
        [15952],
        [16254],
        [19307],
        [13924],
        [16058],
        [14671],
        [15848],
        [16482],
        [18330],
        [21143],
        [14314],
        [16912]], device='cuda:0')
[2024-07-24 10:30:15,246][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26286],
        [27290],
        [50255],
        [33421],
        [46789],
        [17395],
        [10069],
        [14482],
        [ 8772],
        [ 4302],
        [34293],
        [47094],
        [ 2742],
        [30573],
        [11531],
        [12515],
        [ 8067],
        [30459]], device='cuda:0')
[2024-07-24 10:30:15,247][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097],
        [40097]], device='cuda:0')
[2024-07-24 10:30:15,273][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:15,276][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,278][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,278][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,279][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,279][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,279][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,280][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,280][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,280][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,281][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,281][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,282][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,285][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,289][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8906, 0.1094], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,291][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6456, 0.3544], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,292][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5192, 0.4808], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,292][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2894, 0.7106], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,292][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8965, 0.1035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,293][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9539, 0.0461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,293][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9913, 0.0087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,293][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8996, 0.1004], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,294][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8932, 0.1068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,294][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2380, 0.7620], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,294][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8281, 0.1719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,296][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.9789, 0.0193, 0.0018], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,299][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.3488, 0.6332, 0.0180], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,303][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.4505, 0.2799, 0.2695], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,305][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.3640, 0.3351, 0.3010], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,305][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.1453, 0.4245, 0.4303], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,306][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([9.9200e-01, 8.0003e-03, 3.6827e-06], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,306][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.9707, 0.0182, 0.0111], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,306][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.7442, 0.0984, 0.1574], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,307][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.7180, 0.2120, 0.0699], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,307][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.5934, 0.3977, 0.0089], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,307][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.1413, 0.4173, 0.4413], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,308][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.0270, 0.0108, 0.9622], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,308][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9100e-01, 7.9662e-03, 8.9031e-04, 1.4711e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,311][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7765, 0.1257, 0.0523, 0.0455], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,314][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3445, 0.2002, 0.2235, 0.2319], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,318][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2732, 0.2408, 0.2405, 0.2454], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,318][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1135, 0.2792, 0.3559, 0.2514], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,319][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.7429e-01, 2.5285e-02, 8.0786e-05, 3.4307e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,319][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9454, 0.0158, 0.0280, 0.0108], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,319][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5160, 0.0426, 0.2258, 0.2155], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,320][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6306, 0.0987, 0.0524, 0.2183], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,320][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7325, 0.0970, 0.0168, 0.1537], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,320][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1045, 0.3024, 0.3427, 0.2505], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,321][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4567, 0.1016, 0.0347, 0.4071], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,321][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.9231e-01, 6.9178e-03, 5.1691e-04, 1.4465e-04, 1.0611e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,323][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0691, 0.2602, 0.0332, 0.6211, 0.0165], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,325][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.2835, 0.1720, 0.1723, 0.1887, 0.1835], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,329][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.2258, 0.2039, 0.1881, 0.2073, 0.1749], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,332][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0791, 0.2282, 0.2443, 0.1955, 0.2529], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,332][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([9.7837e-01, 2.1541e-02, 9.8575e-06, 6.8194e-05, 7.0467e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,332][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.6993, 0.0229, 0.0634, 0.0535, 0.1609], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,333][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.5856, 0.0508, 0.1286, 0.2155, 0.0195], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,333][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.4839, 0.1727, 0.0702, 0.2286, 0.0445], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,333][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.2639, 0.4235, 0.0198, 0.2572, 0.0357], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,334][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0804, 0.2316, 0.2506, 0.1884, 0.2490], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,334][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0230, 0.0150, 0.0072, 0.0057, 0.9492], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,335][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ were] are: tensor([9.9642e-01, 3.4240e-03, 1.0202e-04, 3.1878e-05, 1.4890e-05, 3.1971e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,336][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.3561, 0.2798, 0.0195, 0.2923, 0.0078, 0.0445], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,339][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.2302, 0.1434, 0.1492, 0.1570, 0.1609, 0.1593], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,343][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.1811, 0.1625, 0.1625, 0.1652, 0.1535, 0.1753], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,345][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0641, 0.1833, 0.2021, 0.1536, 0.2179, 0.1789], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,346][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ were] are: tensor([9.7783e-01, 2.2016e-02, 2.1831e-05, 1.0717e-04, 1.3826e-05, 1.1514e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,346][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.4820, 0.0139, 0.0650, 0.0409, 0.2575, 0.1408], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,346][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.2726, 0.0371, 0.1678, 0.1862, 0.1186, 0.2176], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,347][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.4508, 0.1199, 0.0773, 0.1479, 0.0655, 0.1386], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,347][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.4533, 0.1445, 0.0313, 0.1765, 0.0835, 0.1110], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,348][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0645, 0.1866, 0.2042, 0.1497, 0.2047, 0.1902], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,348][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0090, 0.0053, 0.0026, 0.0066, 0.0016, 0.9750], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,348][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ working] are: tensor([9.9493e-01, 4.7702e-03, 2.0014e-04, 5.3940e-05, 3.5697e-05, 8.1632e-06,
        4.7816e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,350][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.4342, 0.1542, 0.0546, 0.2008, 0.0329, 0.1061, 0.0172],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,353][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.2128, 0.1256, 0.1264, 0.1315, 0.1373, 0.1335, 0.1329],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,357][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.1569, 0.1426, 0.1319, 0.1426, 0.1272, 0.1501, 0.1486],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,359][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0542, 0.1595, 0.1667, 0.1339, 0.1767, 0.1453, 0.1637],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,359][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ working] are: tensor([9.8481e-01, 1.5116e-02, 1.0485e-05, 4.6757e-05, 7.9833e-06, 4.6338e-06,
        4.7235e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,360][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.3979, 0.0143, 0.0597, 0.0366, 0.3022, 0.0756, 0.1136],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,360][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.2319, 0.0666, 0.1324, 0.1187, 0.2443, 0.1809, 0.0251],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,360][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.3990, 0.0889, 0.0519, 0.1823, 0.0509, 0.1698, 0.0572],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,361][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.4709, 0.1855, 0.0137, 0.1395, 0.0553, 0.0889, 0.0462],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,361][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0543, 0.1530, 0.1700, 0.1231, 0.1737, 0.1543, 0.1716],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,361][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ working] are: tensor([1.9085e-02, 2.6114e-02, 1.6109e-04, 9.3017e-03, 1.2234e-03, 9.8837e-04,
        9.4313e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,362][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.9618e-01, 3.5357e-03, 1.7524e-04, 5.4753e-05, 3.3468e-05, 9.0736e-06,
        6.6015e-06, 2.1871e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,364][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.5946, 0.1492, 0.0481, 0.1051, 0.0167, 0.0497, 0.0124, 0.0243],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,367][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1858, 0.1060, 0.1151, 0.1173, 0.1269, 0.1195, 0.1199, 0.1094],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,370][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1378, 0.1222, 0.1206, 0.1221, 0.1170, 0.1279, 0.1289, 0.1235],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,372][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0501, 0.1275, 0.1490, 0.1120, 0.1640, 0.1256, 0.1447, 0.1271],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,373][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([9.6527e-01, 3.4218e-02, 5.1749e-05, 2.3333e-04, 3.5318e-05, 3.2264e-05,
        2.4819e-05, 1.3489e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,373][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.6191, 0.0175, 0.0447, 0.0245, 0.0965, 0.0959, 0.0754, 0.0264],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,373][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1393, 0.0165, 0.1266, 0.0775, 0.1577, 0.2758, 0.1201, 0.0864],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,374][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3920, 0.0865, 0.0491, 0.1291, 0.0640, 0.1148, 0.0663, 0.0982],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,374][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.5756, 0.0679, 0.0158, 0.0990, 0.0613, 0.1086, 0.0200, 0.0517],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,375][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0472, 0.1304, 0.1483, 0.1067, 0.1511, 0.1360, 0.1526, 0.1277],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,375][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([8.3960e-03, 8.6081e-03, 8.7291e-04, 5.6707e-03, 8.8240e-03, 1.8923e-03,
        1.4135e-03, 9.6432e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,376][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9725e-01, 2.5138e-03, 1.3811e-04, 4.4568e-05, 3.1461e-05, 8.5568e-06,
        6.3603e-06, 2.5930e-06, 2.1179e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,378][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.6529, 0.1528, 0.0192, 0.0989, 0.0098, 0.0279, 0.0052, 0.0218, 0.0116],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,381][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1593, 0.0963, 0.1050, 0.1072, 0.1164, 0.1107, 0.1087, 0.0975, 0.0991],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,385][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1238, 0.1073, 0.1075, 0.1090, 0.1053, 0.1159, 0.1168, 0.1084, 0.1058],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,386][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0452, 0.1123, 0.1329, 0.0972, 0.1450, 0.1123, 0.1296, 0.1103, 0.1153],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,386][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.8019e-01, 1.9472e-02, 3.1948e-05, 1.5822e-04, 1.9942e-05, 2.0696e-05,
        1.3667e-05, 7.1730e-05, 1.8430e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,387][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3848, 0.0357, 0.0764, 0.0365, 0.1530, 0.1082, 0.0847, 0.0482, 0.0725],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,387][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1518, 0.0151, 0.0690, 0.0633, 0.0722, 0.1260, 0.1215, 0.1070, 0.2741],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,387][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3063, 0.0720, 0.0444, 0.0988, 0.0530, 0.0858, 0.0579, 0.0708, 0.2110],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,388][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.4490, 0.0530, 0.0236, 0.1284, 0.0569, 0.0845, 0.0332, 0.0386, 0.1329],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,388][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0421, 0.1167, 0.1332, 0.0958, 0.1366, 0.1229, 0.1355, 0.1130, 0.1042],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,389][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0244, 0.0074, 0.0039, 0.0145, 0.0050, 0.0087, 0.0052, 0.0108, 0.9202],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,390][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ station] are: tensor([9.9242e-01, 7.0249e-03, 3.2361e-04, 1.0747e-04, 6.8445e-05, 1.9422e-05,
        1.5506e-05, 6.3052e-06, 5.4042e-06, 1.2416e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,392][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0577, 0.1221, 0.0116, 0.2801, 0.0123, 0.0495, 0.0165, 0.2982, 0.1500,
        0.0021], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,395][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1571, 0.0918, 0.0903, 0.0987, 0.1004, 0.0968, 0.0933, 0.0866, 0.0848,
        0.1003], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,399][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1145, 0.1027, 0.0901, 0.1041, 0.0913, 0.1057, 0.1022, 0.1012, 0.0953,
        0.0928], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,400][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0359, 0.1100, 0.1088, 0.0920, 0.1170, 0.0989, 0.1054, 0.0978, 0.1016,
        0.1326], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,400][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ station] are: tensor([9.9103e-01, 8.9260e-03, 2.8024e-06, 2.4118e-05, 2.3571e-06, 1.3570e-06,
        1.1945e-06, 8.1270e-06, 1.4502e-06, 6.4970e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,400][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.3663, 0.0079, 0.0245, 0.0137, 0.3694, 0.0441, 0.0595, 0.0241, 0.0208,
        0.0698], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,401][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1556, 0.0134, 0.1470, 0.0663, 0.0882, 0.1159, 0.1033, 0.1314, 0.1580,
        0.0209], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,401][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2204, 0.0963, 0.0417, 0.0950, 0.0521, 0.1156, 0.0457, 0.0631, 0.2409,
        0.0293], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,402][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.3319, 0.0894, 0.0313, 0.0757, 0.0655, 0.1355, 0.0531, 0.0889, 0.1070,
        0.0217], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,402][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0374, 0.1080, 0.1142, 0.0876, 0.1179, 0.1067, 0.1175, 0.1006, 0.0896,
        0.1206], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,403][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ station] are: tensor([4.0616e-03, 2.9860e-03, 4.5731e-03, 4.3884e-03, 5.9916e-04, 5.5725e-03,
        1.4854e-03, 1.8813e-02, 3.4983e-03, 9.5402e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,404][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.9663e-01, 3.0628e-03, 1.8936e-04, 5.4254e-05, 3.6353e-05, 1.0854e-05,
        7.3776e-06, 2.8045e-06, 2.3771e-06, 5.9619e-06, 1.3550e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,408][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.5426, 0.1434, 0.0212, 0.1046, 0.0106, 0.0251, 0.0055, 0.0228, 0.0232,
        0.0057, 0.0953], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,411][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1288, 0.0768, 0.0875, 0.0868, 0.0940, 0.0910, 0.0907, 0.0785, 0.0792,
        0.0990, 0.0878], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,413][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1030, 0.0899, 0.0901, 0.0915, 0.0878, 0.0942, 0.0998, 0.0908, 0.0851,
        0.0951, 0.0728], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,413][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0356, 0.0855, 0.1081, 0.0759, 0.1115, 0.0876, 0.1079, 0.0859, 0.0883,
        0.1290, 0.0846], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,414][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([9.7919e-01, 2.0227e-02, 4.0037e-05, 2.5082e-04, 2.7105e-05, 3.7820e-05,
        1.7862e-05, 1.1486e-04, 3.7134e-05, 9.9852e-06, 4.5230e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,414][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.4575, 0.0329, 0.1105, 0.0322, 0.0888, 0.0584, 0.0367, 0.0434, 0.0541,
        0.0307, 0.0548], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,414][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0968, 0.0091, 0.0688, 0.0567, 0.1231, 0.1173, 0.0857, 0.0675, 0.1159,
        0.1933, 0.0657], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,415][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2961, 0.0789, 0.0386, 0.1177, 0.0332, 0.0574, 0.0342, 0.0440, 0.1234,
        0.0304, 0.1460], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,415][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.4334, 0.0451, 0.0237, 0.0739, 0.0412, 0.0903, 0.0236, 0.0332, 0.0999,
        0.0202, 0.1155], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,416][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0333, 0.0955, 0.1082, 0.0780, 0.1100, 0.0998, 0.1108, 0.0937, 0.0825,
        0.1171, 0.0710], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,417][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1033, 0.0342, 0.0367, 0.0375, 0.0646, 0.0880, 0.0422, 0.0350, 0.1299,
        0.0569, 0.3718], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,419][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.9477e-01, 4.6924e-03, 2.5218e-04, 1.1556e-04, 6.2726e-05, 2.5628e-05,
        1.9005e-05, 8.1082e-06, 7.9404e-06, 1.5543e-05, 5.4195e-06, 2.3218e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,422][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0102, 0.0643, 0.0088, 0.1573, 0.0036, 0.0468, 0.0112, 0.1136, 0.1330,
        0.0050, 0.4400, 0.0062], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,426][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.1241, 0.0755, 0.0768, 0.0822, 0.0815, 0.0819, 0.0808, 0.0721, 0.0718,
        0.0867, 0.0804, 0.0861], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,427][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0967, 0.0864, 0.0799, 0.0889, 0.0739, 0.0914, 0.0882, 0.0855, 0.0820,
        0.0828, 0.0712, 0.0731], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,427][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0289, 0.0845, 0.0906, 0.0717, 0.0942, 0.0784, 0.0865, 0.0793, 0.0821,
        0.1077, 0.0804, 0.1156], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,427][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([9.7072e-01, 2.9024e-02, 1.6959e-05, 1.3367e-04, 1.3283e-05, 1.1048e-05,
        7.5656e-06, 4.4750e-05, 9.1944e-06, 3.4689e-06, 9.1794e-06, 9.8274e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,428][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.4075, 0.0197, 0.0393, 0.0455, 0.0978, 0.0798, 0.0415, 0.0404, 0.0716,
        0.0241, 0.0692, 0.0637], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,428][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0585, 0.0149, 0.0189, 0.0349, 0.0039, 0.1727, 0.1237, 0.0361, 0.2252,
        0.1030, 0.2062, 0.0019], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,429][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.1758, 0.0893, 0.0216, 0.0697, 0.0125, 0.1039, 0.0202, 0.0330, 0.2377,
        0.0169, 0.2032, 0.0163], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,429][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0910, 0.1542, 0.0158, 0.0660, 0.0265, 0.0641, 0.1032, 0.0853, 0.1832,
        0.0264, 0.1361, 0.0483], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,431][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0314, 0.0883, 0.0969, 0.0717, 0.0965, 0.0901, 0.0981, 0.0825, 0.0753,
        0.1029, 0.0646, 0.1018], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,433][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([7.4224e-05, 2.3735e-04, 3.4944e-04, 7.3876e-05, 4.6885e-02, 9.7549e-05,
        1.0925e-04, 1.3094e-03, 2.0001e-04, 7.1706e-05, 2.5093e-02, 9.2550e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,435][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([9.9587e-01, 3.9005e-03, 1.3137e-04, 4.9768e-05, 2.1556e-05, 7.2566e-06,
        4.4336e-06, 1.9774e-06, 1.4513e-06, 2.9603e-06, 9.0269e-07, 3.8343e-06,
        1.0582e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,438][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0474, 0.1474, 0.0144, 0.2520, 0.0084, 0.0520, 0.0086, 0.0471, 0.0666,
        0.0039, 0.3405, 0.0073, 0.0044], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,440][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1131, 0.0674, 0.0707, 0.0723, 0.0765, 0.0726, 0.0747, 0.0660, 0.0638,
        0.0796, 0.0724, 0.0800, 0.0907], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,440][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0882, 0.0782, 0.0744, 0.0792, 0.0712, 0.0815, 0.0829, 0.0777, 0.0750,
        0.0771, 0.0648, 0.0700, 0.0798], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,441][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0266, 0.0776, 0.0821, 0.0645, 0.0884, 0.0691, 0.0847, 0.0722, 0.0714,
        0.0966, 0.0717, 0.1077, 0.0875], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,441][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([9.8139e-01, 1.8454e-02, 1.1122e-05, 7.2157e-05, 8.9943e-06, 6.5973e-06,
        4.9966e-06, 2.7946e-05, 5.7751e-06, 2.1581e-06, 6.1521e-06, 7.1434e-06,
        3.1724e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,442][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.4508, 0.0092, 0.0374, 0.0266, 0.1296, 0.1002, 0.0676, 0.0213, 0.0245,
        0.0263, 0.0153, 0.0828, 0.0085], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,442][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.1099, 0.0196, 0.0335, 0.0549, 0.0952, 0.1465, 0.1104, 0.0476, 0.1127,
        0.1079, 0.0920, 0.0461, 0.0237], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,442][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.2006, 0.0551, 0.0249, 0.0980, 0.0255, 0.0913, 0.0233, 0.0389, 0.1962,
        0.0240, 0.1523, 0.0322, 0.0378], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,444][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.1516, 0.1079, 0.0324, 0.0660, 0.0787, 0.1132, 0.0662, 0.0465, 0.0844,
        0.0165, 0.0910, 0.1139, 0.0318], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,447][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0267, 0.0784, 0.0870, 0.0644, 0.0896, 0.0809, 0.0888, 0.0758, 0.0679,
        0.0935, 0.0577, 0.0944, 0.0947], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,449][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([1.0583e-02, 2.3719e-03, 1.1005e-03, 2.4006e-03, 1.0028e-03, 1.6130e-03,
        5.9655e-03, 8.7946e-04, 6.1458e-03, 3.3374e-03, 4.8627e-02, 1.5830e-03,
        9.1439e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,451][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9438e-01, 5.2315e-03, 2.1134e-04, 8.7024e-05, 4.0225e-05, 1.4270e-05,
        1.0017e-05, 4.5548e-06, 3.3595e-06, 6.9205e-06, 2.1682e-06, 8.2104e-06,
        2.4841e-06, 1.7454e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,453][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4398, 0.1299, 0.0286, 0.1170, 0.0137, 0.0350, 0.0069, 0.0264, 0.0264,
        0.0035, 0.1355, 0.0085, 0.0102, 0.0187], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,454][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0984, 0.0603, 0.0676, 0.0663, 0.0714, 0.0711, 0.0705, 0.0617, 0.0610,
        0.0739, 0.0676, 0.0751, 0.0861, 0.0690], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,454][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0812, 0.0708, 0.0702, 0.0721, 0.0678, 0.0771, 0.0770, 0.0728, 0.0679,
        0.0728, 0.0586, 0.0673, 0.0752, 0.0692], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,455][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0279, 0.0665, 0.0795, 0.0584, 0.0819, 0.0678, 0.0795, 0.0660, 0.0679,
        0.0930, 0.0645, 0.0982, 0.0831, 0.0657], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,455][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.3936e-01, 5.8185e-02, 1.3041e-04, 7.6891e-04, 1.0219e-04, 1.2688e-04,
        6.5486e-05, 3.7311e-04, 1.0493e-04, 3.4306e-05, 1.3360e-04, 9.6707e-05,
        5.9376e-05, 4.6153e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,456][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.5840, 0.0160, 0.0292, 0.0138, 0.0654, 0.0636, 0.0809, 0.0183, 0.0296,
        0.0138, 0.0188, 0.0505, 0.0096, 0.0064], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,456][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0798, 0.0260, 0.0579, 0.0520, 0.0760, 0.0720, 0.0657, 0.0673, 0.1282,
        0.1062, 0.0886, 0.0306, 0.0547, 0.0952], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,457][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2341, 0.0502, 0.0210, 0.0874, 0.0287, 0.0552, 0.0307, 0.0495, 0.1195,
        0.0204, 0.1321, 0.0396, 0.0469, 0.0846], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,460][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3860, 0.0210, 0.0181, 0.0364, 0.0325, 0.0963, 0.0277, 0.0312, 0.1217,
        0.0163, 0.0517, 0.0523, 0.0531, 0.0556], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,463][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0255, 0.0721, 0.0830, 0.0586, 0.0834, 0.0762, 0.0847, 0.0711, 0.0622,
        0.0872, 0.0532, 0.0883, 0.0907, 0.0639], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,467][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0325, 0.0116, 0.0011, 0.0136, 0.0029, 0.0042, 0.0065, 0.0097, 0.0068,
        0.0046, 0.2785, 0.0073, 0.0081, 0.6127], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,467][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.9528e-01, 4.3757e-03, 2.0034e-04, 6.9797e-05, 3.6732e-05, 1.1111e-05,
        7.8449e-06, 3.3993e-06, 2.4131e-06, 4.9475e-06, 1.5104e-06, 6.0264e-06,
        1.8813e-06, 1.3923e-06, 9.8345e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,468][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0632, 0.0981, 0.0190, 0.2147, 0.0076, 0.0498, 0.0115, 0.0703, 0.0899,
        0.0058, 0.2915, 0.0063, 0.0134, 0.0552, 0.0037], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,468][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0943, 0.0588, 0.0618, 0.0628, 0.0658, 0.0636, 0.0651, 0.0568, 0.0549,
        0.0696, 0.0624, 0.0689, 0.0816, 0.0631, 0.0705], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,469][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0761, 0.0666, 0.0627, 0.0682, 0.0625, 0.0715, 0.0718, 0.0675, 0.0633,
        0.0667, 0.0552, 0.0623, 0.0700, 0.0649, 0.0707], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,469][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0235, 0.0654, 0.0694, 0.0545, 0.0743, 0.0611, 0.0707, 0.0614, 0.0607,
        0.0834, 0.0609, 0.0894, 0.0796, 0.0588, 0.0869], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,470][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([9.6804e-01, 3.1524e-02, 3.1673e-05, 1.5689e-04, 1.9644e-05, 1.6104e-05,
        1.1905e-05, 5.9629e-05, 1.3453e-05, 5.7285e-06, 1.4718e-05, 1.5607e-05,
        8.6114e-06, 5.3589e-05, 2.3839e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,472][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.6101, 0.0069, 0.0196, 0.0136, 0.1365, 0.0321, 0.0531, 0.0120, 0.0110,
        0.0120, 0.0061, 0.0760, 0.0048, 0.0031, 0.0031], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,474][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0416, 0.0188, 0.0535, 0.0564, 0.0580, 0.1054, 0.1037, 0.0606, 0.1127,
        0.0755, 0.1075, 0.0323, 0.0756, 0.0724, 0.0260], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,478][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.1662, 0.0415, 0.0154, 0.0869, 0.0227, 0.0665, 0.0216, 0.0429, 0.1697,
        0.0152, 0.1348, 0.0308, 0.0407, 0.0947, 0.0501], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,481][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.2014, 0.0501, 0.0118, 0.0326, 0.0363, 0.0736, 0.0293, 0.0456, 0.1787,
        0.0103, 0.0815, 0.0756, 0.0433, 0.0917, 0.0381], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,481][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0234, 0.0666, 0.0753, 0.0541, 0.0777, 0.0702, 0.0778, 0.0648, 0.0577,
        0.0811, 0.0497, 0.0820, 0.0838, 0.0580, 0.0780], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,482][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.1973e-03, 2.0620e-03, 1.8211e-04, 1.0418e-03, 2.8589e-04, 2.0031e-04,
        2.5553e-04, 2.8330e-04, 4.8429e-04, 9.1876e-04, 2.3332e-02, 2.5192e-04,
        5.7375e-04, 1.3223e-03, 9.6661e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,482][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9634e-01, 3.4379e-03, 1.1758e-04, 4.9421e-05, 2.2638e-05, 7.4206e-06,
        5.5663e-06, 2.5627e-06, 1.9655e-06, 3.8562e-06, 1.1754e-06, 4.7395e-06,
        1.4431e-06, 1.1575e-06, 9.1086e-07, 6.0931e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,482][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4274, 0.1523, 0.0177, 0.1224, 0.0081, 0.0235, 0.0052, 0.0208, 0.0228,
        0.0035, 0.1479, 0.0052, 0.0063, 0.0236, 0.0041, 0.0094],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,483][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0862, 0.0538, 0.0580, 0.0595, 0.0633, 0.0617, 0.0595, 0.0539, 0.0540,
        0.0659, 0.0596, 0.0667, 0.0746, 0.0596, 0.0654, 0.0583],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,483][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0705, 0.0617, 0.0610, 0.0629, 0.0598, 0.0677, 0.0674, 0.0630, 0.0608,
        0.0638, 0.0515, 0.0596, 0.0660, 0.0590, 0.0658, 0.0593],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,485][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0236, 0.0588, 0.0654, 0.0514, 0.0719, 0.0579, 0.0645, 0.0570, 0.0597,
        0.0840, 0.0575, 0.0866, 0.0696, 0.0547, 0.0794, 0.0581],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,487][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.6130e-01, 3.7370e-02, 6.6793e-05, 3.9477e-04, 4.2325e-05, 5.7865e-05,
        3.1122e-05, 1.8478e-04, 5.5376e-05, 1.7414e-05, 6.9084e-05, 4.4304e-05,
        3.0343e-05, 2.1617e-04, 7.6539e-05, 4.3001e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,490][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3834, 0.0194, 0.0462, 0.0184, 0.1782, 0.0561, 0.0627, 0.0231, 0.0292,
        0.0180, 0.0184, 0.1143, 0.0077, 0.0091, 0.0058, 0.0098],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,494][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0677, 0.0209, 0.0453, 0.0388, 0.0554, 0.0482, 0.0588, 0.0504, 0.1242,
        0.0560, 0.1000, 0.0240, 0.0464, 0.0717, 0.0599, 0.1323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,495][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1812, 0.0418, 0.0186, 0.0686, 0.0258, 0.0529, 0.0258, 0.0434, 0.1195,
        0.0170, 0.1134, 0.0370, 0.0380, 0.0733, 0.0443, 0.0993],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,495][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2276, 0.0206, 0.0201, 0.0405, 0.0458, 0.0900, 0.0323, 0.0284, 0.1121,
        0.0146, 0.0562, 0.0802, 0.0441, 0.0542, 0.0347, 0.0985],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,496][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0228, 0.0623, 0.0717, 0.0515, 0.0731, 0.0664, 0.0730, 0.0604, 0.0548,
        0.0768, 0.0466, 0.0776, 0.0795, 0.0549, 0.0740, 0.0545],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,496][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.6147e-03, 5.4131e-04, 5.7832e-05, 4.3226e-04, 2.1199e-04, 2.6901e-04,
        8.1930e-04, 1.4446e-03, 1.8014e-03, 1.5636e-04, 1.8285e-02, 9.1057e-04,
        1.7873e-03, 4.9206e-03, 7.8661e-04, 9.6596e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,497][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([9.9648e-01, 3.2904e-03, 1.2591e-04, 4.9334e-05, 2.5174e-05, 6.9758e-06,
        5.2506e-06, 2.6503e-06, 1.9798e-06, 4.5395e-06, 1.1962e-06, 5.6893e-06,
        1.4894e-06, 1.1564e-06, 8.3086e-07, 6.5035e-07, 6.8663e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,497][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0389, 0.0413, 0.0174, 0.0971, 0.0105, 0.0441, 0.0125, 0.1021, 0.0940,
        0.0056, 0.3104, 0.0104, 0.0189, 0.0706, 0.0099, 0.1033, 0.0131],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,499][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0875, 0.0525, 0.0534, 0.0568, 0.0584, 0.0574, 0.0551, 0.0498, 0.0490,
        0.0607, 0.0565, 0.0614, 0.0699, 0.0569, 0.0633, 0.0523, 0.0590],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,502][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0693, 0.0606, 0.0563, 0.0615, 0.0532, 0.0643, 0.0628, 0.0597, 0.0569,
        0.0587, 0.0505, 0.0528, 0.0625, 0.0580, 0.0635, 0.0552, 0.0540],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,506][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0198, 0.0605, 0.0594, 0.0510, 0.0643, 0.0543, 0.0584, 0.0548, 0.0555,
        0.0722, 0.0578, 0.0789, 0.0647, 0.0522, 0.0748, 0.0535, 0.0679],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,508][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([9.7660e-01, 2.3149e-02, 1.3855e-05, 9.0707e-05, 1.1836e-05, 7.8705e-06,
        6.8802e-06, 3.4109e-05, 7.0952e-06, 3.3336e-06, 6.7382e-06, 8.5637e-06,
        4.2567e-06, 2.8496e-05, 1.2434e-05, 3.9833e-06, 1.2230e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,508][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.2188, 0.0284, 0.0470, 0.0615, 0.1379, 0.0306, 0.0601, 0.0479, 0.0522,
        0.0319, 0.0368, 0.0864, 0.0036, 0.0223, 0.0053, 0.0207, 0.1086],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,509][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0702, 0.0402, 0.0463, 0.0633, 0.0581, 0.0379, 0.0086, 0.0627, 0.1222,
        0.1223, 0.0718, 0.0197, 0.0848, 0.0605, 0.0578, 0.0658, 0.0077],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,509][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1205, 0.0330, 0.0126, 0.0728, 0.0173, 0.0493, 0.0180, 0.0396, 0.1495,
        0.0156, 0.1195, 0.0237, 0.0494, 0.0901, 0.0531, 0.1193, 0.0166],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,510][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1670, 0.0297, 0.0214, 0.0376, 0.0553, 0.0824, 0.0473, 0.0404, 0.1044,
        0.0130, 0.0450, 0.0942, 0.0649, 0.0484, 0.0545, 0.0658, 0.0287],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,510][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0214, 0.0601, 0.0658, 0.0486, 0.0675, 0.0616, 0.0668, 0.0567, 0.0509,
        0.0692, 0.0442, 0.0713, 0.0719, 0.0512, 0.0671, 0.0500, 0.0757],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,511][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([6.8613e-03, 4.3687e-03, 3.1961e-04, 2.5612e-03, 1.3918e-03, 1.7563e-03,
        3.7292e-03, 2.1845e-03, 1.4030e-03, 4.6908e-03, 5.1924e-02, 1.9194e-03,
        7.9417e-03, 1.4656e-02, 7.6343e-04, 3.1914e-03, 8.9034e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,512][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9637e-01, 3.4084e-03, 1.1848e-04, 5.1734e-05, 2.1656e-05, 7.6545e-06,
        5.2215e-06, 2.4886e-06, 1.8946e-06, 3.8455e-06, 1.1690e-06, 4.6244e-06,
        1.3342e-06, 9.5236e-07, 8.2847e-07, 5.9268e-07, 6.8325e-07, 5.2417e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,514][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3998, 0.1422, 0.0245, 0.1198, 0.0096, 0.0308, 0.0053, 0.0241, 0.0245,
        0.0025, 0.1406, 0.0056, 0.0071, 0.0171, 0.0043, 0.0206, 0.0083, 0.0133],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,517][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0740, 0.0470, 0.0533, 0.0512, 0.0559, 0.0556, 0.0556, 0.0480, 0.0474,
        0.0583, 0.0524, 0.0588, 0.0674, 0.0536, 0.0611, 0.0512, 0.0576, 0.0515],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,521][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0636, 0.0548, 0.0547, 0.0562, 0.0530, 0.0602, 0.0605, 0.0567, 0.0529,
        0.0573, 0.0458, 0.0527, 0.0590, 0.0542, 0.0595, 0.0520, 0.0545, 0.0523],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,522][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0213, 0.0504, 0.0602, 0.0442, 0.0622, 0.0515, 0.0606, 0.0502, 0.0516,
        0.0704, 0.0491, 0.0747, 0.0633, 0.0499, 0.0742, 0.0511, 0.0689, 0.0463],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,522][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.2795e-01, 6.7257e-02, 1.8852e-04, 1.0953e-03, 1.3286e-04, 1.8770e-04,
        9.2896e-05, 5.1956e-04, 1.5991e-04, 5.2143e-05, 2.0832e-04, 1.3077e-04,
        9.1478e-05, 6.5805e-04, 2.0622e-04, 1.2467e-04, 1.5875e-04, 7.8705e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,523][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4819, 0.0191, 0.0406, 0.0164, 0.0733, 0.0647, 0.0768, 0.0196, 0.0292,
        0.0190, 0.0206, 0.0550, 0.0121, 0.0074, 0.0073, 0.0115, 0.0395, 0.0061],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,523][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0488, 0.0201, 0.0313, 0.0338, 0.0492, 0.0451, 0.0458, 0.0475, 0.0919,
        0.0670, 0.0712, 0.0180, 0.0322, 0.0605, 0.0499, 0.1165, 0.1110, 0.0602],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,524][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1729, 0.0459, 0.0169, 0.0603, 0.0237, 0.0419, 0.0241, 0.0381, 0.0926,
        0.0155, 0.1060, 0.0341, 0.0354, 0.0693, 0.0416, 0.0874, 0.0258, 0.0686],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,524][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2522, 0.0138, 0.0179, 0.0303, 0.0333, 0.0804, 0.0248, 0.0230, 0.1193,
        0.0128, 0.0337, 0.0512, 0.0450, 0.0396, 0.0344, 0.1119, 0.0382, 0.0383],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,526][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0197, 0.0549, 0.0636, 0.0448, 0.0640, 0.0584, 0.0650, 0.0542, 0.0477,
        0.0673, 0.0408, 0.0679, 0.0695, 0.0492, 0.0654, 0.0472, 0.0734, 0.0471],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,529][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0103, 0.0041, 0.0005, 0.0050, 0.0015, 0.0023, 0.0032, 0.0061, 0.0032,
        0.0022, 0.1588, 0.0086, 0.0046, 0.2708, 0.0030, 0.0278, 0.0141, 0.4738],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,542][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:15,542][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,543][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,543][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,544][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,544][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,545][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,545][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,545][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,546][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,546][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,546][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,547][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,547][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8323, 0.1677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,547][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9360, 0.0640], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,548][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9782, 0.0218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,548][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5908, 0.4092], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,548][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2936, 0.7064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,550][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7403, 0.2597], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,553][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9946, 0.0054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,557][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9777, 0.0223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,558][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8630, 0.1370], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,559][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9168, 0.0832], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,559][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.9926e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,559][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7906, 0.2094], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,560][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.7832, 0.1483, 0.0685], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,560][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([9.8751e-01, 1.2463e-02, 2.4776e-05], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,560][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.7782, 0.0936, 0.1282], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,561][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.3995, 0.2442, 0.3563], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,561][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.1527, 0.4380, 0.4093], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,563][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.4821, 0.4706, 0.0473], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,565][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.8033, 0.0048, 0.1919], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,569][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.7011, 0.0851, 0.2138], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,572][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.6494, 0.1425, 0.2082], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,572][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.5395, 0.4506, 0.0098], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,572][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([3.3965e-04, 5.3181e-01, 4.6785e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,573][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.0227, 0.0111, 0.9662], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,573][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5710, 0.1210, 0.0739, 0.2341], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,573][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5887, 0.2454, 0.1249, 0.0410], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,574][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3653, 0.0323, 0.0539, 0.5485], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,574][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2442, 0.1253, 0.1912, 0.4394], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,575][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1184, 0.2860, 0.3409, 0.2547], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,576][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4279, 0.3999, 0.0167, 0.1555], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,579][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8792, 0.0143, 0.0714, 0.0352], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,583][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6007, 0.0520, 0.2514, 0.0959], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,585][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7407, 0.1255, 0.1207, 0.0131], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,586][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6080, 0.0891, 0.0201, 0.2828], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,586][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0004, 0.3046, 0.3788, 0.3162], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,586][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4523, 0.0852, 0.0385, 0.4241], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,587][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.5748, 0.0961, 0.0423, 0.2319, 0.0549], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,587][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.6567, 0.0876, 0.0735, 0.1556, 0.0266], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,587][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.2112, 0.0420, 0.0806, 0.5007, 0.1656], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,588][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.1705, 0.0838, 0.1281, 0.2948, 0.3228], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,588][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0827, 0.2334, 0.2306, 0.1980, 0.2552], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,590][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0862, 0.1288, 0.5444, 0.0257, 0.2148], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,594][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.2860, 0.0039, 0.0483, 0.1616, 0.5002], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,597][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.6140, 0.0453, 0.1843, 0.1055, 0.0509], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,601][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.6713, 0.1630, 0.1412, 0.0133, 0.0112], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,601][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.1706, 0.3820, 0.0184, 0.4036, 0.0255], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,602][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0004, 0.2166, 0.2694, 0.2528, 0.2608], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,602][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0224, 0.0181, 0.0098, 0.0077, 0.9420], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,602][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.4832, 0.1017, 0.0490, 0.2277, 0.0598, 0.0784], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,603][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.3333, 0.1461, 0.1492, 0.1831, 0.0716, 0.1168], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,603][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1860, 0.0252, 0.0449, 0.3366, 0.1100, 0.2973], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,603][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1140, 0.0541, 0.0911, 0.2251, 0.2545, 0.2613], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,605][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0667, 0.1861, 0.1921, 0.1541, 0.2194, 0.1816], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,608][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.3173, 0.3262, 0.0642, 0.0738, 0.0309, 0.1876], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,612][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.3676, 0.0043, 0.0138, 0.3906, 0.0939, 0.1297], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,614][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.3327, 0.0327, 0.2193, 0.0824, 0.1992, 0.1336], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,615][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.5917, 0.1163, 0.0510, 0.0186, 0.0080, 0.2144], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,615][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.2670, 0.1817, 0.0389, 0.3337, 0.0874, 0.0913], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,615][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0004, 0.1324, 0.1954, 0.1666, 0.2102, 0.2950], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,616][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0106, 0.0078, 0.0041, 0.0071, 0.0023, 0.9681], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,616][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.4744, 0.0883, 0.0396, 0.2251, 0.0562, 0.0833, 0.0331],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,616][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.3351, 0.0786, 0.1710, 0.1441, 0.0505, 0.2049, 0.0158],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,617][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.1053, 0.0065, 0.0259, 0.1692, 0.0836, 0.2018, 0.4076],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,618][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0944, 0.0460, 0.0777, 0.1923, 0.2169, 0.2206, 0.1521],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,620][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0564, 0.1617, 0.1566, 0.1344, 0.1770, 0.1471, 0.1669],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,623][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.3447, 0.3744, 0.0280, 0.0702, 0.0236, 0.0837, 0.0754],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,627][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.1105, 0.0011, 0.0435, 0.2292, 0.5170, 0.0799, 0.0188],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,628][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.2828, 0.0543, 0.1789, 0.0569, 0.2900, 0.1095, 0.0277],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,628][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.6666, 0.0565, 0.0247, 0.0074, 0.0044, 0.2372, 0.0033],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,629][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.3637, 0.1997, 0.0112, 0.1810, 0.0487, 0.0700, 0.1257],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,629][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0004, 0.0916, 0.1579, 0.1262, 0.1788, 0.2151, 0.2300],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,629][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([2.2749e-02, 3.9497e-02, 3.0237e-04, 1.1874e-02, 1.9188e-03, 1.6858e-03,
        9.2197e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,630][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.4440, 0.0949, 0.0533, 0.1911, 0.0594, 0.0684, 0.0326, 0.0562],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,630][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0907, 0.0486, 0.5289, 0.0992, 0.0430, 0.1258, 0.0307, 0.0331],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,632][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0847, 0.0098, 0.0240, 0.1464, 0.0659, 0.1615, 0.3169, 0.1908],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,635][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0794, 0.0333, 0.0569, 0.1455, 0.1683, 0.1843, 0.1245, 0.2079],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,639][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0516, 0.1285, 0.1407, 0.1118, 0.1641, 0.1268, 0.1469, 0.1296],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,641][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0619, 0.0432, 0.0079, 0.0091, 0.0025, 0.0038, 0.0117, 0.8599],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,641][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5748, 0.0164, 0.0431, 0.0846, 0.1304, 0.0665, 0.0158, 0.0685],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,642][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2077, 0.0250, 0.1686, 0.0478, 0.2103, 0.1675, 0.1244, 0.0487],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,642][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([6.7666e-01, 8.6567e-02, 5.3240e-02, 8.8895e-03, 1.0766e-02, 1.5723e-01,
        5.9789e-03, 6.6645e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,642][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.3948, 0.1041, 0.0195, 0.1979, 0.0689, 0.0901, 0.0684, 0.0564],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,643][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0007, 0.0617, 0.1179, 0.0937, 0.1328, 0.1733, 0.1661, 0.2537],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,643][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0105, 0.0139, 0.0016, 0.0083, 0.0121, 0.0032, 0.0021, 0.9482],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,644][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4282, 0.0836, 0.0425, 0.1830, 0.0517, 0.0675, 0.0302, 0.0568, 0.0564],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,645][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1000, 0.0574, 0.2824, 0.1047, 0.0489, 0.2016, 0.0389, 0.1020, 0.0641],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,648][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0542, 0.0085, 0.0242, 0.1223, 0.0589, 0.1471, 0.2154, 0.1527, 0.2167],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,652][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0667, 0.0254, 0.0454, 0.1171, 0.1374, 0.1447, 0.0960, 0.1669, 0.2005],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,654][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0464, 0.1130, 0.1252, 0.0968, 0.1446, 0.1131, 0.1313, 0.1123, 0.1174],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,655][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2362, 0.2954, 0.0556, 0.0439, 0.0812, 0.0464, 0.0342, 0.0872, 0.1198],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,655][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.3725, 0.0103, 0.0465, 0.1427, 0.1355, 0.0579, 0.0149, 0.1092, 0.1104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,656][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2473, 0.0239, 0.1289, 0.0448, 0.1372, 0.0967, 0.1438, 0.0586, 0.1188],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,656][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3212, 0.0954, 0.0322, 0.0070, 0.0093, 0.1209, 0.0044, 0.0004, 0.4091],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,656][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2484, 0.0481, 0.0235, 0.2438, 0.0514, 0.0581, 0.0923, 0.0326, 0.2020],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,657][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0006, 0.0457, 0.0909, 0.0749, 0.1095, 0.1451, 0.1335, 0.2027, 0.1970],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,659][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0310, 0.0116, 0.0065, 0.0192, 0.0075, 0.0142, 0.0085, 0.0159, 0.8856],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:15,661][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.4159, 0.0721, 0.0320, 0.1833, 0.0473, 0.0722, 0.0306, 0.0601, 0.0600,
        0.0265], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,664][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([9.2272e-01, 9.3083e-03, 9.9638e-05, 2.9437e-03, 1.5746e-02, 4.9815e-03,
        1.0595e-02, 2.1695e-02, 1.1851e-02, 6.2288e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,667][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0587, 0.0103, 0.0253, 0.1273, 0.0571, 0.1378, 0.1680, 0.1377, 0.1929,
        0.0847], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,668][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0541, 0.0215, 0.0378, 0.0971, 0.1135, 0.1222, 0.0815, 0.1421, 0.1715,
        0.1587], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,668][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0373, 0.1114, 0.1017, 0.0920, 0.1165, 0.0998, 0.1070, 0.1003, 0.1045,
        0.1294], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,669][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0882, 0.1019, 0.0200, 0.0356, 0.0083, 0.0241, 0.0468, 0.4754, 0.1264,
        0.0733], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,669][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.1240, 0.0015, 0.0399, 0.0956, 0.3666, 0.0661, 0.0082, 0.1142, 0.1612,
        0.0227], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,670][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1804, 0.0211, 0.2083, 0.0501, 0.1380, 0.1087, 0.1088, 0.0658, 0.0753,
        0.0435], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,670][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([1.5941e-01, 3.3952e-02, 3.3116e-02, 3.0805e-03, 2.7843e-03, 1.7242e-01,
        9.5999e-04, 1.3492e-04, 5.7963e-01, 1.4520e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,670][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1595, 0.0804, 0.0277, 0.1118, 0.0629, 0.1180, 0.2006, 0.0920, 0.1271,
        0.0200], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,672][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0004, 0.0443, 0.0727, 0.0697, 0.0910, 0.1173, 0.1191, 0.1854, 0.1499,
        0.1503], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,674][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([5.3579e-03, 4.7435e-03, 6.5232e-03, 6.0561e-03, 9.2852e-04, 7.5069e-03,
        2.0989e-03, 2.1399e-02, 4.2822e-03, 9.4110e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:15,677][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.3583, 0.0823, 0.0436, 0.1754, 0.0536, 0.0666, 0.0304, 0.0548, 0.0554,
        0.0282, 0.0516], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,681][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.7545, 0.0636, 0.0037, 0.0066, 0.0470, 0.0416, 0.0208, 0.0305, 0.0289,
        0.0012, 0.0017], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,682][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0533, 0.0136, 0.0242, 0.1164, 0.0484, 0.1169, 0.1716, 0.1214, 0.1662,
        0.0710, 0.0970], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,682][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0482, 0.0176, 0.0322, 0.0892, 0.1021, 0.1117, 0.0732, 0.1293, 0.1612,
        0.1498, 0.0855], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,682][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0366, 0.0864, 0.1020, 0.0760, 0.1108, 0.0884, 0.1089, 0.0874, 0.0899,
        0.1261, 0.0873], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,683][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1943, 0.1241, 0.0313, 0.0355, 0.0573, 0.0805, 0.0217, 0.0266, 0.1695,
        0.0085, 0.2508], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,683][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6419, 0.0088, 0.0090, 0.1035, 0.0156, 0.0195, 0.0015, 0.1051, 0.0807,
        0.0023, 0.0122], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,684][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1447, 0.0131, 0.0664, 0.0292, 0.1423, 0.0750, 0.0821, 0.0387, 0.0536,
        0.2549, 0.1000], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,685][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([2.3151e-01, 4.7967e-02, 1.8360e-02, 3.9061e-03, 5.3236e-03, 1.0985e-01,
        2.5760e-03, 2.8335e-04, 4.5397e-01, 2.8713e-02, 9.7534e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,687][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.2566, 0.0506, 0.0223, 0.1244, 0.0400, 0.0788, 0.0659, 0.0329, 0.1836,
        0.0227, 0.1222], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,690][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0009, 0.0278, 0.0570, 0.0477, 0.0728, 0.0966, 0.0940, 0.1330, 0.1153,
        0.1249, 0.2300], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,694][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0919, 0.0407, 0.0444, 0.0376, 0.0704, 0.0982, 0.0475, 0.0366, 0.1194,
        0.0623, 0.3510], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:15,695][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.4114, 0.0684, 0.0266, 0.1667, 0.0370, 0.0610, 0.0259, 0.0523, 0.0514,
        0.0225, 0.0525, 0.0242], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,695][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.2639, 0.0498, 0.0295, 0.0667, 0.0144, 0.0682, 0.0316, 0.0936, 0.0924,
        0.0411, 0.2317, 0.0171], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,696][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0384, 0.0115, 0.0305, 0.1177, 0.0507, 0.1328, 0.1030, 0.1081, 0.1342,
        0.0811, 0.1356, 0.0564], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,696][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0435, 0.0160, 0.0294, 0.0815, 0.0927, 0.1023, 0.0664, 0.1180, 0.1477,
        0.1357, 0.0792, 0.0876], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,697][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0299, 0.0854, 0.0843, 0.0718, 0.0936, 0.0788, 0.0875, 0.0811, 0.0842,
        0.1047, 0.0837, 0.1151], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,697][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0086, 0.0461, 0.5143, 0.0103, 0.1053, 0.0158, 0.0016, 0.0199, 0.0404,
        0.0008, 0.0730, 0.1638], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,698][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.1057, 0.0022, 0.0169, 0.1367, 0.2582, 0.0474, 0.0050, 0.1176, 0.1743,
        0.0090, 0.0286, 0.0985], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,699][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1065, 0.0202, 0.0448, 0.0298, 0.0182, 0.1557, 0.1409, 0.0237, 0.0910,
        0.1633, 0.1938, 0.0120], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,701][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([2.1816e-01, 5.0563e-02, 3.6089e-02, 2.4045e-03, 2.6259e-03, 1.1343e-01,
        1.1903e-03, 1.3848e-04, 4.1229e-01, 1.4456e-02, 1.4426e-01, 4.3990e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,704][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0408, 0.1046, 0.0082, 0.0608, 0.0131, 0.0401, 0.3074, 0.0669, 0.2264,
        0.0182, 0.0976, 0.0160], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,708][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0006, 0.0285, 0.0552, 0.0482, 0.0585, 0.0890, 0.0813, 0.1242, 0.1064,
        0.1004, 0.1836, 0.1240], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,708][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([1.2673e-04, 7.9510e-04, 8.3389e-04, 2.0060e-04, 7.0336e-02, 2.6101e-04,
        2.3476e-04, 2.5855e-03, 4.1483e-04, 1.7577e-04, 4.7856e-02, 8.7618e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:15,709][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.3663, 0.0734, 0.0336, 0.1733, 0.0455, 0.0623, 0.0252, 0.0503, 0.0503,
        0.0245, 0.0490, 0.0286, 0.0178], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,709][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0967, 0.0372, 0.0855, 0.0623, 0.0551, 0.0938, 0.0300, 0.0519, 0.0530,
        0.0381, 0.2863, 0.0816, 0.0285], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,710][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0529, 0.0059, 0.0173, 0.0836, 0.0402, 0.0912, 0.1342, 0.0976, 0.1397,
        0.0629, 0.0859, 0.0618, 0.1269], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,710][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0367, 0.0136, 0.0265, 0.0770, 0.0888, 0.0954, 0.0616, 0.1134, 0.1428,
        0.1320, 0.0759, 0.0822, 0.0541], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,711][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0276, 0.0785, 0.0765, 0.0645, 0.0878, 0.0697, 0.0855, 0.0737, 0.0733,
        0.0940, 0.0745, 0.1070, 0.0873], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,712][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.2865, 0.1226, 0.0164, 0.0249, 0.0342, 0.0758, 0.0274, 0.0589, 0.1210,
        0.0071, 0.1587, 0.0321, 0.0344], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,715][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.1247, 0.0009, 0.0222, 0.1345, 0.2557, 0.1000, 0.0092, 0.0820, 0.1340,
        0.0216, 0.0179, 0.0954, 0.0020], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,719][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.1883, 0.0145, 0.0546, 0.0254, 0.1362, 0.0915, 0.1022, 0.0203, 0.0313,
        0.1599, 0.0602, 0.0790, 0.0366], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,721][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.3003, 0.0303, 0.0185, 0.0036, 0.0027, 0.1458, 0.0017, 0.0004, 0.3733,
        0.0128, 0.1022, 0.0048, 0.0035], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,722][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0513, 0.1085, 0.0229, 0.0673, 0.0749, 0.0875, 0.2175, 0.0484, 0.1160,
        0.0112, 0.0772, 0.0795, 0.0376], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,722][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0005, 0.0201, 0.0435, 0.0370, 0.0514, 0.0660, 0.0670, 0.1015, 0.0851,
        0.0925, 0.1584, 0.1280, 0.1489], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,723][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0148, 0.0041, 0.0020, 0.0041, 0.0017, 0.0027, 0.0087, 0.0014, 0.0078,
        0.0053, 0.0603, 0.0022, 0.8849], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:15,723][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3372, 0.0758, 0.0385, 0.1547, 0.0464, 0.0610, 0.0271, 0.0491, 0.0503,
        0.0250, 0.0479, 0.0304, 0.0193, 0.0373], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,724][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0498, 0.0363, 0.1578, 0.0619, 0.0348, 0.1006, 0.0207, 0.0601, 0.0565,
        0.0355, 0.2344, 0.0535, 0.0730, 0.0252], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,724][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0360, 0.0062, 0.0193, 0.0745, 0.0394, 0.0911, 0.0985, 0.0844, 0.1177,
        0.0680, 0.0997, 0.0554, 0.1040, 0.1059], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,726][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0348, 0.0123, 0.0250, 0.0727, 0.0846, 0.0904, 0.0574, 0.1055, 0.1314,
        0.1206, 0.0676, 0.0755, 0.0493, 0.0730], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,729][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0287, 0.0670, 0.0746, 0.0583, 0.0815, 0.0681, 0.0802, 0.0670, 0.0691,
        0.0908, 0.0665, 0.0978, 0.0831, 0.0673], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,733][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0790, 0.0221, 0.0477, 0.0156, 0.0272, 0.0289, 0.0148, 0.0154, 0.1483,
        0.0035, 0.0893, 0.0243, 0.0116, 0.4724], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,735][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3242, 0.0090, 0.0823, 0.0643, 0.1520, 0.0552, 0.0214, 0.0411, 0.0711,
        0.0332, 0.0291, 0.0812, 0.0158, 0.0201], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,735][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1501, 0.0359, 0.0707, 0.0350, 0.0943, 0.0441, 0.0661, 0.0449, 0.0589,
        0.1492, 0.0957, 0.0426, 0.0601, 0.0524], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,736][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.2712e-01, 3.2679e-02, 2.8274e-02, 2.9744e-03, 3.2851e-03, 1.2185e-01,
        1.8083e-03, 1.2958e-04, 2.0242e-01, 2.8975e-02, 1.0878e-01, 6.7340e-03,
        9.5396e-03, 2.5423e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,736][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1770, 0.0197, 0.0151, 0.0510, 0.0296, 0.0803, 0.0996, 0.0437, 0.2881,
        0.0182, 0.0521, 0.0280, 0.0780, 0.0195], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,737][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0010, 0.0142, 0.0349, 0.0265, 0.0410, 0.0601, 0.0542, 0.0789, 0.0692,
        0.0643, 0.1273, 0.1068, 0.1366, 0.1850], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,737][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0358, 0.0175, 0.0017, 0.0187, 0.0033, 0.0058, 0.0080, 0.0129, 0.0082,
        0.0059, 0.2965, 0.0077, 0.0100, 0.5682], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:15,739][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.3253, 0.0710, 0.0350, 0.1603, 0.0455, 0.0590, 0.0265, 0.0489, 0.0489,
        0.0250, 0.0478, 0.0289, 0.0185, 0.0404, 0.0189], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,741][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0558, 0.0465, 0.1224, 0.0563, 0.0239, 0.1039, 0.0169, 0.0554, 0.0719,
        0.0359, 0.2326, 0.0342, 0.0563, 0.0429, 0.0452], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,746][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0405, 0.0094, 0.0174, 0.0827, 0.0346, 0.0834, 0.1189, 0.0868, 0.1124,
        0.0532, 0.0741, 0.0446, 0.1009, 0.0920, 0.0492], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,748][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0318, 0.0112, 0.0222, 0.0618, 0.0734, 0.0807, 0.0528, 0.0955, 0.1177,
        0.1089, 0.0653, 0.0728, 0.0494, 0.0710, 0.0857], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,748][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0242, 0.0657, 0.0646, 0.0543, 0.0739, 0.0614, 0.0713, 0.0624, 0.0619,
        0.0812, 0.0628, 0.0890, 0.0794, 0.0603, 0.0877], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,749][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1035, 0.0854, 0.0281, 0.0232, 0.0070, 0.0489, 0.0816, 0.0314, 0.1653,
        0.0064, 0.2450, 0.0072, 0.0464, 0.0296, 0.0910], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,749][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1034, 0.0008, 0.0310, 0.0753, 0.4001, 0.0474, 0.0150, 0.0352, 0.0527,
        0.0427, 0.0087, 0.1742, 0.0031, 0.0090, 0.0015], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,750][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0739, 0.0224, 0.0912, 0.0326, 0.0985, 0.0683, 0.1060, 0.0288, 0.0391,
        0.1484, 0.0851, 0.0679, 0.0841, 0.0290, 0.0246], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,750][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([3.0654e-01, 2.2091e-02, 1.7950e-02, 3.0094e-03, 1.9915e-03, 1.3740e-01,
        2.0801e-03, 2.3655e-04, 3.4425e-01, 1.5454e-02, 1.1057e-01, 4.0521e-03,
        5.4714e-03, 2.4003e-02, 4.9053e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,751][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1007, 0.0475, 0.0067, 0.0291, 0.0235, 0.0537, 0.0725, 0.0572, 0.3746,
        0.0068, 0.0773, 0.0320, 0.0487, 0.0366, 0.0330], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,752][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0006, 0.0123, 0.0292, 0.0245, 0.0360, 0.0499, 0.0460, 0.0714, 0.0596,
        0.0619, 0.1209, 0.0903, 0.1146, 0.1498, 0.1332], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,754][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([3.3244e-03, 4.4303e-03, 3.8775e-04, 2.0921e-03, 5.3776e-04, 4.6127e-04,
        5.4196e-04, 5.9157e-04, 9.3113e-04, 1.5427e-03, 3.6143e-02, 4.6180e-04,
        1.0576e-03, 2.3205e-03, 9.4518e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:15,757][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3247, 0.0739, 0.0373, 0.1458, 0.0445, 0.0560, 0.0259, 0.0461, 0.0457,
        0.0233, 0.0442, 0.0285, 0.0183, 0.0361, 0.0184, 0.0315],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,761][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0287, 0.0323, 0.1633, 0.0485, 0.0377, 0.1069, 0.0189, 0.0392, 0.0613,
        0.0281, 0.1818, 0.0671, 0.0441, 0.0427, 0.0800, 0.0195],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,762][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0319, 0.0079, 0.0178, 0.0732, 0.0344, 0.0806, 0.0881, 0.0780, 0.1026,
        0.0585, 0.0870, 0.0450, 0.0878, 0.0867, 0.0531, 0.0674],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,762][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0306, 0.0104, 0.0209, 0.0577, 0.0700, 0.0739, 0.0481, 0.0880, 0.1068,
        0.0996, 0.0585, 0.0655, 0.0441, 0.0622, 0.0772, 0.0864],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,763][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0241, 0.0589, 0.0613, 0.0511, 0.0714, 0.0582, 0.0650, 0.0578, 0.0606,
        0.0818, 0.0591, 0.0862, 0.0694, 0.0559, 0.0800, 0.0592],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,763][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1176, 0.1574, 0.0098, 0.0279, 0.0124, 0.0280, 0.0475, 0.0518, 0.1096,
        0.0219, 0.1427, 0.0080, 0.0604, 0.0497, 0.0989, 0.0564],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,764][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1487, 0.0030, 0.0729, 0.0676, 0.3143, 0.0428, 0.0170, 0.0479, 0.0625,
        0.0248, 0.0126, 0.1401, 0.0084, 0.0170, 0.0047, 0.0158],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,766][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1242, 0.0258, 0.0814, 0.0270, 0.0913, 0.0385, 0.0690, 0.0300, 0.0507,
        0.1305, 0.0926, 0.0464, 0.0629, 0.0352, 0.0497, 0.0448],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,768][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.1732e-01, 2.1651e-02, 1.3245e-02, 2.2168e-03, 2.2885e-03, 7.6167e-02,
        1.3977e-03, 1.3339e-04, 1.2109e-01, 1.7712e-02, 9.3789e-02, 5.4776e-03,
        3.8444e-03, 2.0088e-02, 3.3356e-03, 4.0025e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,771][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1115, 0.0168, 0.0162, 0.0546, 0.0421, 0.0806, 0.0919, 0.0364, 0.2375,
        0.0151, 0.0581, 0.0460, 0.0555, 0.0204, 0.0343, 0.0831],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,775][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0007, 0.0097, 0.0249, 0.0201, 0.0311, 0.0450, 0.0389, 0.0597, 0.0543,
        0.0478, 0.1025, 0.0796, 0.0985, 0.1332, 0.1216, 0.1324],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,775][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.4959e-03, 1.1283e-03, 1.2020e-04, 8.7965e-04, 3.3897e-04, 5.1034e-04,
        1.4238e-03, 2.5098e-03, 2.8043e-03, 2.9530e-04, 2.7799e-02, 1.2798e-03,
        2.8238e-03, 8.5061e-03, 1.4536e-03, 9.4563e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:15,776][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.3354, 0.0589, 0.0215, 0.1592, 0.0335, 0.0590, 0.0241, 0.0490, 0.0470,
        0.0201, 0.0485, 0.0210, 0.0165, 0.0419, 0.0194, 0.0355, 0.0095],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,776][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0873, 0.0318, 0.0891, 0.0802, 0.0181, 0.0505, 0.0157, 0.0404, 0.0662,
        0.0393, 0.2495, 0.0244, 0.0430, 0.0236, 0.0438, 0.0827, 0.0144],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,777][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0345, 0.0089, 0.0183, 0.0728, 0.0347, 0.0798, 0.0879, 0.0762, 0.0981,
        0.0535, 0.0781, 0.0433, 0.0844, 0.0819, 0.0508, 0.0636, 0.0334],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,777][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0259, 0.0092, 0.0180, 0.0493, 0.0594, 0.0650, 0.0426, 0.0778, 0.0967,
        0.0897, 0.0554, 0.0616, 0.0424, 0.0596, 0.0729, 0.0816, 0.0928],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,777][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0205, 0.0608, 0.0548, 0.0507, 0.0636, 0.0544, 0.0589, 0.0558, 0.0566,
        0.0699, 0.0598, 0.0780, 0.0643, 0.0535, 0.0755, 0.0548, 0.0681],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,779][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.1360, 0.1782, 0.0250, 0.0128, 0.0177, 0.0520, 0.0351, 0.0867, 0.1174,
        0.0637, 0.0969, 0.0070, 0.0097, 0.0122, 0.0149, 0.0747, 0.0598],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,782][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0847, 0.0020, 0.0237, 0.1542, 0.2921, 0.0258, 0.0096, 0.0951, 0.0912,
        0.0334, 0.0094, 0.1155, 0.0015, 0.0213, 0.0011, 0.0133, 0.0261],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,786][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.1047, 0.0337, 0.0666, 0.0414, 0.0835, 0.0359, 0.0130, 0.0393, 0.0501,
        0.2056, 0.0723, 0.0402, 0.0889, 0.0336, 0.0458, 0.0285, 0.0169],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,788][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([1.8171e-01, 1.2252e-02, 4.8256e-03, 1.0237e-03, 9.4112e-04, 7.5579e-02,
        8.8931e-04, 1.5167e-04, 1.1448e-01, 7.6518e-03, 6.2211e-02, 2.5024e-03,
        1.7911e-03, 2.2323e-02, 2.1930e-03, 3.7690e-01, 1.3258e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,789][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0548, 0.0236, 0.0147, 0.0426, 0.0524, 0.0523, 0.1678, 0.0474, 0.1930,
        0.0099, 0.0387, 0.0651, 0.0935, 0.0155, 0.0695, 0.0493, 0.0100],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,789][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0005, 0.0090, 0.0228, 0.0184, 0.0290, 0.0404, 0.0349, 0.0552, 0.0478,
        0.0439, 0.0944, 0.0750, 0.0827, 0.1191, 0.1041, 0.1056, 0.1173],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,790][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([9.7315e-03, 9.0372e-03, 6.3467e-04, 4.5146e-03, 2.2481e-03, 3.0094e-03,
        6.2526e-03, 3.6052e-03, 2.1291e-03, 7.5570e-03, 7.5330e-02, 2.5413e-03,
        1.1794e-02, 1.9740e-02, 1.2635e-03, 4.4032e-03, 8.3621e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:15,790][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3066, 0.0675, 0.0332, 0.1438, 0.0409, 0.0563, 0.0244, 0.0455, 0.0459,
        0.0225, 0.0445, 0.0266, 0.0175, 0.0346, 0.0184, 0.0328, 0.0115, 0.0273],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,791][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0356, 0.0443, 0.1645, 0.0550, 0.0286, 0.1254, 0.0160, 0.0450, 0.0446,
        0.0242, 0.1319, 0.0426, 0.0480, 0.0207, 0.0675, 0.0523, 0.0222, 0.0316],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,792][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0296, 0.0081, 0.0177, 0.0659, 0.0316, 0.0736, 0.0783, 0.0688, 0.0896,
        0.0540, 0.0810, 0.0406, 0.0780, 0.0760, 0.0492, 0.0598, 0.0328, 0.0653],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,795][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0231, 0.0077, 0.0154, 0.0423, 0.0509, 0.0578, 0.0377, 0.0681, 0.0854,
        0.0778, 0.0480, 0.0546, 0.0381, 0.0546, 0.0657, 0.0738, 0.0825, 0.1164],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,799][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0218, 0.0505, 0.0563, 0.0439, 0.0617, 0.0516, 0.0609, 0.0507, 0.0522,
        0.0686, 0.0503, 0.0741, 0.0630, 0.0508, 0.0745, 0.0519, 0.0692, 0.0478],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,801][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0210, 0.0139, 0.0217, 0.0070, 0.0107, 0.0145, 0.0094, 0.0136, 0.0921,
        0.0034, 0.0631, 0.0118, 0.0061, 0.2593, 0.0132, 0.1176, 0.0464, 0.2753],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,802][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3287, 0.0060, 0.0703, 0.0576, 0.1594, 0.0464, 0.0179, 0.0315, 0.0550,
        0.0296, 0.0141, 0.0834, 0.0146, 0.0165, 0.0073, 0.0205, 0.0324, 0.0086],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,802][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1024, 0.0284, 0.0457, 0.0242, 0.0702, 0.0330, 0.0513, 0.0334, 0.0440,
        0.1137, 0.0850, 0.0289, 0.0422, 0.0358, 0.0434, 0.0463, 0.1330, 0.0389],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,803][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.8731e-01, 1.1704e-02, 1.2442e-02, 1.0717e-03, 1.2214e-03, 6.1628e-02,
        7.9151e-04, 4.9167e-05, 8.0840e-02, 1.3700e-02, 4.3985e-02, 2.5603e-03,
        4.2462e-03, 9.4020e-03, 3.4183e-03, 4.4612e-01, 1.0774e-01, 1.1769e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,803][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1182, 0.0105, 0.0119, 0.0372, 0.0266, 0.0612, 0.0670, 0.0295, 0.3186,
        0.0120, 0.0319, 0.0248, 0.0592, 0.0135, 0.0374, 0.1157, 0.0138, 0.0108],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,804][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0010, 0.0070, 0.0193, 0.0145, 0.0222, 0.0337, 0.0296, 0.0439, 0.0377,
        0.0336, 0.0735, 0.0563, 0.0720, 0.1016, 0.0918, 0.0887, 0.0950, 0.1787],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,804][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0113, 0.0068, 0.0008, 0.0069, 0.0017, 0.0031, 0.0041, 0.0083, 0.0042,
        0.0029, 0.1821, 0.0083, 0.0058, 0.2655, 0.0041, 0.0314, 0.0139, 0.4387],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:15,806][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:15,807][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5525],
        [16642],
        [   14],
        [14099],
        [ 1651],
        [15529],
        [18724],
        [26164],
        [23762],
        [15168],
        [13231],
        [ 3868],
        [24864],
        [22229],
        [23432],
        [28269],
        [24170],
        [23453]], device='cuda:0')
[2024-07-24 10:30:15,810][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5863],
        [25508],
        [    1],
        [19296],
        [ 1498],
        [20149],
        [32465],
        [30981],
        [29976],
        [25541],
        [17426],
        [ 1953],
        [33997],
        [22148],
        [29351],
        [31530],
        [36594],
        [22146]], device='cuda:0')
[2024-07-24 10:30:15,812][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[177],
        [177],
        [178],
        [177],
        [177],
        [176],
        [176],
        [176],
        [176],
        [177],
        [176],
        [176],
        [176],
        [176],
        [176],
        [176],
        [176],
        [176]], device='cuda:0')
[2024-07-24 10:30:15,815][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43098],
        [42934],
        [35785],
        [42562],
        [38348],
        [42342],
        [45354],
        [44402],
        [44091],
        [37898],
        [42897],
        [34677],
        [36837],
        [42762],
        [37960],
        [42263],
        [38482],
        [42527]], device='cuda:0')
[2024-07-24 10:30:15,818][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[29512],
        [33068],
        [37010],
        [37472],
        [38378],
        [37568],
        [37413],
        [37039],
        [37039],
        [36778],
        [36859],
        [37303],
        [37431],
        [37643],
        [37538],
        [37590],
        [37562],
        [37716]], device='cuda:0')
[2024-07-24 10:30:15,819][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8885],
        [ 9160],
        [13311],
        [13593],
        [13955],
        [14799],
        [13770],
        [13675],
        [13628],
        [13981],
        [14556],
        [14733],
        [14730],
        [15063],
        [15114],
        [15141],
        [15175],
        [15420]], device='cuda:0')
[2024-07-24 10:30:15,820][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26641],
        [29301],
        [23657],
        [24562],
        [26248],
        [27020],
        [26077],
        [26472],
        [27266],
        [26970],
        [27253],
        [27703],
        [27189],
        [27210],
        [27100],
        [27392],
        [27398],
        [27302]], device='cuda:0')
[2024-07-24 10:30:15,821][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15189],
        [13477],
        [15049],
        [14740],
        [14809],
        [14795],
        [14926],
        [14587],
        [14834],
        [15032],
        [14821],
        [14670],
        [14864],
        [14170],
        [14628],
        [14525],
        [14773],
        [13972]], device='cuda:0')
[2024-07-24 10:30:15,822][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13465],
        [13282],
        [13031],
        [12410],
        [ 9530],
        [ 8114],
        [ 9382],
        [ 9944],
        [ 9746],
        [10974],
        [ 9327],
        [10453],
        [ 9969],
        [10787],
        [10614],
        [ 9975],
        [11937],
        [10904]], device='cuda:0')
[2024-07-24 10:30:15,825][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38687],
        [38473],
        [ 6830],
        [ 7672],
        [15579],
        [10425],
        [ 5310],
        [10651],
        [23139],
        [12123],
        [19976],
        [28589],
        [17384],
        [15239],
        [14616],
        [14604],
        [18238],
        [25142]], device='cuda:0')
[2024-07-24 10:30:15,828][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4368],
        [ 5443],
        [11512],
        [ 8189],
        [13758],
        [17424],
        [14796],
        [14788],
        [15024],
        [16605],
        [13625],
        [15053],
        [15194],
        [15756],
        [15516],
        [16631],
        [15555],
        [18134]], device='cuda:0')
[2024-07-24 10:30:15,830][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19099],
        [18065],
        [12716],
        [20558],
        [14668],
        [25505],
        [23744],
        [25994],
        [19916],
        [22095],
        [18872],
        [12505],
        [22698],
        [20657],
        [13781],
        [14135],
        [16683],
        [11813]], device='cuda:0')
[2024-07-24 10:30:15,833][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2880],
        [5064],
        [3766],
        [4173],
        [3738],
        [3925],
        [3698],
        [3669],
        [3820],
        [3690],
        [3799],
        [3668],
        [3664],
        [3740],
        [3805],
        [3848],
        [3652],
        [3715]], device='cuda:0')
[2024-07-24 10:30:15,834][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21375],
        [24087],
        [43295],
        [32893],
        [44689],
        [44988],
        [40625],
        [43688],
        [43385],
        [19845],
        [36827],
        [48761],
        [43474],
        [32587],
        [37781],
        [29832],
        [ 9037],
        [32754]], device='cuda:0')
[2024-07-24 10:30:15,835][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7333],
        [ 9963],
        [ 1043],
        [ 6889],
        [ 8033],
        [16187],
        [12661],
        [21062],
        [16843],
        [12423],
        [14547],
        [ 9194],
        [ 7384],
        [10169],
        [12411],
        [21333],
        [20644],
        [12555]], device='cuda:0')
[2024-07-24 10:30:15,836][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[17379],
        [17060],
        [17078],
        [19288],
        [19407],
        [20391],
        [20446],
        [20268],
        [20340],
        [20416],
        [20513],
        [20292],
        [20393],
        [20487],
        [20451],
        [20198],
        [20273],
        [20107]], device='cuda:0')
[2024-07-24 10:30:15,838][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 586],
        [ 617],
        [ 583],
        [1243],
        [ 809],
        [1575],
        [1445],
        [5349],
        [3034],
        [ 584],
        [ 668],
        [2459],
        [4517],
        [4045],
        [3459],
        [3419],
        [2353],
        [2631]], device='cuda:0')
[2024-07-24 10:30:15,840][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[5396],
        [5350],
        [4702],
        [3835],
        [3797],
        [4001],
        [3974],
        [4026],
        [4194],
        [4267],
        [4202],
        [4208],
        [4072],
        [4108],
        [4041],
        [4146],
        [4139],
        [4183]], device='cuda:0')
[2024-07-24 10:30:15,843][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12366],
        [11475],
        [11152],
        [13802],
        [15839],
        [18876],
        [20095],
        [21619],
        [23565],
        [24687],
        [24712],
        [25014],
        [25152],
        [25343],
        [25860],
        [26339],
        [26943],
        [27053]], device='cuda:0')
[2024-07-24 10:30:15,846][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20111],
        [19223],
        [20146],
        [21053],
        [20278],
        [20620],
        [20893],
        [20734],
        [21348],
        [21333],
        [21471],
        [21163],
        [21298],
        [21680],
        [21879],
        [21965],
        [21666],
        [21854]], device='cuda:0')
[2024-07-24 10:30:15,848][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27268],
        [28873],
        [29244],
        [34382],
        [11672],
        [38002],
        [38612],
        [48436],
        [40869],
        [46041],
        [37571],
        [16285],
        [38962],
        [46744],
        [40021],
        [41581],
        [41940],
        [48036]], device='cuda:0')
[2024-07-24 10:30:15,849][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36292],
        [36295],
        [36593],
        [36567],
        [30367],
        [29412],
        [26010],
        [35418],
        [31553],
        [26107],
        [35706],
        [24641],
        [24746],
        [30651],
        [26745],
        [28207],
        [25560],
        [31764]], device='cuda:0')
[2024-07-24 10:30:15,850][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17456],
        [16863],
        [37320],
        [30812],
        [25571],
        [31992],
        [31109],
        [33541],
        [33056],
        [35567],
        [38949],
        [39503],
        [38122],
        [37558],
        [39937],
        [39450],
        [39010],
        [34890]], device='cuda:0')
[2024-07-24 10:30:15,851][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21543],
        [20769],
        [23708],
        [22128],
        [22564],
        [22657],
        [21615],
        [21538],
        [26393],
        [30022],
        [30844],
        [32396],
        [30243],
        [27954],
        [30640],
        [34538],
        [34668],
        [33868]], device='cuda:0')
[2024-07-24 10:30:15,853][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 6608],
        [ 6997],
        [18751],
        [ 7425],
        [10624],
        [ 7623],
        [ 9782],
        [ 9229],
        [ 8497],
        [10942],
        [ 8062],
        [15319],
        [12092],
        [ 7502],
        [ 8449],
        [ 7228],
        [ 7787],
        [ 6274]], device='cuda:0')
[2024-07-24 10:30:15,855][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7124],
        [ 9856],
        [12068],
        [10493],
        [13013],
        [14337],
        [15552],
        [15939],
        [16462],
        [18452],
        [18326],
        [18962],
        [20499],
        [20974],
        [21055],
        [21724],
        [22261],
        [22043]], device='cuda:0')
[2024-07-24 10:30:15,858][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[32806],
        [32979],
        [27563],
        [33351],
        [22910],
        [31546],
        [37749],
        [30925],
        [34045],
        [34270],
        [36151],
        [39437],
        [31802],
        [36155],
        [46353],
        [36476],
        [36570],
        [37667]], device='cuda:0')
[2024-07-24 10:30:15,861][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[10005],
        [13842],
        [21018],
        [18880],
        [29822],
        [15738],
        [16058],
        [ 8753],
        [11378],
        [10724],
        [ 9651],
        [10197],
        [ 6853],
        [ 4935],
        [ 4571],
        [ 6517],
        [ 6404],
        [ 4190]], device='cuda:0')
[2024-07-24 10:30:15,863][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[10021],
        [38882],
        [46240],
        [42434],
        [41286],
        [31184],
        [34768],
        [21984],
        [30867],
        [31257],
        [27734],
        [40548],
        [39460],
        [35764],
        [32561],
        [26074],
        [22962],
        [31185]], device='cuda:0')
[2024-07-24 10:30:15,864][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062],
        [26062]], device='cuda:0')
[2024-07-24 10:30:15,891][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:15,894][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,898][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,898][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,899][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,899][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,899][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,900][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,900][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,900][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,901][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,901][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,901][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:15,903][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5653, 0.4347], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,905][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4805, 0.5195], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,908][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.2304e-08, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,912][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7070, 0.2930], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,912][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6131, 0.3869], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,912][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2830, 0.7170], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,913][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5687, 0.4313], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,913][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3724, 0.6276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,913][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([4.4214e-14, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,914][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9486, 0.0514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,914][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0215, 0.9785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,916][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5265, 0.4735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:15,918][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.4589, 0.4215, 0.1195], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,922][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.2502, 0.2707, 0.4791], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,925][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([1.8881e-06, 9.8654e-05, 9.9990e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,925][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.7694, 0.1895, 0.0411], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,925][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.6465, 0.3074, 0.0461], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,926][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.1502, 0.4341, 0.4157], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,926][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.1720, 0.6445, 0.1835], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,926][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.1003, 0.5376, 0.3621], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,927][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([7.3301e-05, 9.9772e-01, 2.2023e-03], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,927][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.4044, 0.5306, 0.0650], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,927][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.1267, 0.4177, 0.4556], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,929][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.3607, 0.2965, 0.3428], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:15,931][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3162, 0.2910, 0.2294, 0.1634], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,934][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1782, 0.2198, 0.3588, 0.2432], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,936][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.0923e-07, 6.8195e-05, 6.1526e-01, 3.8467e-01], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,938][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7493, 0.1725, 0.0376, 0.0405], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,939][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6470, 0.2564, 0.0517, 0.0449], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,939][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1166, 0.2826, 0.3163, 0.2846], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,939][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1200, 0.5092, 0.1217, 0.2491], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,940][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1469, 0.5753, 0.2008, 0.0770], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,940][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([4.0659e-07, 9.9978e-01, 2.2315e-04, 6.3981e-07], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,940][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4032, 0.3881, 0.1346, 0.0741], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,942][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1823, 0.1560, 0.3242, 0.3375], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,944][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2529, 0.2561, 0.2516, 0.2394], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:15,947][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.2849, 0.2126, 0.1596, 0.2090, 0.1339], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,951][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.1335, 0.1895, 0.2709, 0.2163, 0.1898], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,951][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([1.5984e-04, 3.2261e-06, 6.0580e-03, 2.1107e-02, 9.7267e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,952][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.8088, 0.1353, 0.0225, 0.0241, 0.0092], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,952][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.7034, 0.2436, 0.0237, 0.0268, 0.0026], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,953][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0536, 0.1590, 0.1509, 0.1614, 0.4750], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,953][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0870, 0.3232, 0.1221, 0.3193, 0.1484], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,953][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0874, 0.4115, 0.2195, 0.0896, 0.1920], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,954][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([2.5216e-02, 8.9987e-01, 7.3475e-02, 1.2371e-03, 2.0282e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,954][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.2060, 0.2233, 0.1751, 0.3443, 0.0513], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,956][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.3980, 0.0741, 0.0958, 0.1833, 0.2489], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,958][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.2174, 0.1883, 0.2077, 0.1746, 0.2121], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:15,962][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.2194, 0.1866, 0.1750, 0.1570, 0.2340, 0.0280], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,965][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1049, 0.1709, 0.2433, 0.1896, 0.1523, 0.1390], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,965][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ were] are: tensor([1.6228e-05, 3.7586e-06, 8.6016e-03, 1.5517e-02, 9.3784e-02, 8.8208e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,965][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.7811, 0.1291, 0.0269, 0.0261, 0.0121, 0.0246], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,966][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.7160, 0.2233, 0.0262, 0.0266, 0.0030, 0.0049], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,966][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0503, 0.1183, 0.1278, 0.1164, 0.3651, 0.2222], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,966][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0980, 0.3774, 0.0846, 0.2248, 0.1032, 0.1120], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,967][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1322, 0.3550, 0.1727, 0.0801, 0.1561, 0.1039], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,968][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ were] are: tensor([6.1022e-05, 9.9473e-01, 5.1846e-03, 2.8842e-05, 3.8177e-07, 1.3290e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,969][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2057, 0.2820, 0.1740, 0.1598, 0.1253, 0.0532], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,973][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2423, 0.0735, 0.1122, 0.1214, 0.1653, 0.2853], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,976][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.1765, 0.1546, 0.1888, 0.1380, 0.2189, 0.1232], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:15,978][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.1682, 0.1277, 0.2677, 0.1209, 0.2556, 0.0447, 0.0152],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,978][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0834, 0.1893, 0.2148, 0.1935, 0.1111, 0.1173, 0.0906],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,978][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ working] are: tensor([1.8188e-04, 1.8630e-05, 7.2493e-03, 1.4532e-02, 1.0096e-01, 7.1894e-01,
        1.5812e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,979][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.8158, 0.1077, 0.0195, 0.0181, 0.0079, 0.0178, 0.0132],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,979][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.7573, 0.1945, 0.0212, 0.0197, 0.0022, 0.0037, 0.0014],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,980][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0334, 0.0892, 0.0859, 0.0918, 0.2550, 0.1731, 0.2716],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,980][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0627, 0.2417, 0.0979, 0.1961, 0.1097, 0.1472, 0.1448],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,980][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.1273, 0.2940, 0.1469, 0.0879, 0.1466, 0.1142, 0.0831],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,982][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ working] are: tensor([2.6425e-04, 9.8544e-01, 1.4217e-02, 6.8220e-05, 4.1477e-06, 2.0577e-06,
        7.9601e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,984][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.3065, 0.1782, 0.2023, 0.1390, 0.0922, 0.0651, 0.0167],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,987][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.1779, 0.0960, 0.1049, 0.1043, 0.1146, 0.2041, 0.1983],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,991][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.1727, 0.1213, 0.1710, 0.1002, 0.1998, 0.1300, 0.1048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:15,991][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1820, 0.1603, 0.1519, 0.1181, 0.1651, 0.0506, 0.0667, 0.1054],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,992][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0698, 0.1743, 0.1818, 0.1745, 0.0960, 0.1099, 0.0942, 0.0996],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,992][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.7301e-03, 6.4882e-05, 2.3707e-02, 3.2769e-02, 3.4847e-02, 3.0266e-01,
        1.4497e-01, 4.5925e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,993][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.7985, 0.1079, 0.0199, 0.0173, 0.0071, 0.0162, 0.0122, 0.0208],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,993][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.7474, 0.1968, 0.0254, 0.0194, 0.0027, 0.0039, 0.0016, 0.0028],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,993][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0282, 0.0687, 0.0751, 0.0712, 0.2278, 0.1410, 0.2455, 0.1425],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,995][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0973, 0.1833, 0.0896, 0.1523, 0.1056, 0.1068, 0.1296, 0.1355],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:15,999][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1554, 0.2402, 0.1293, 0.0777, 0.1334, 0.1095, 0.0790, 0.0755],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,000][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([1.1866e-03, 9.6914e-01, 2.9522e-02, 1.2333e-04, 1.2988e-05, 5.4032e-06,
        8.6989e-06, 1.2856e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,004][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2484, 0.1473, 0.1975, 0.1122, 0.1143, 0.0838, 0.0535, 0.0430],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,006][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.3745, 0.0381, 0.0725, 0.0495, 0.0627, 0.1297, 0.1217, 0.1513],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,007][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.1435, 0.1061, 0.1195, 0.1102, 0.1615, 0.1002, 0.1107, 0.1484],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,007][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1605, 0.1294, 0.1436, 0.1246, 0.1351, 0.0408, 0.0396, 0.1917, 0.0347],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,007][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0589, 0.1927, 0.1838, 0.1965, 0.0821, 0.0972, 0.0645, 0.0710, 0.0533],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,008][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.9962e-03, 4.7247e-06, 3.6083e-04, 9.1208e-04, 2.0297e-03, 1.2719e-02,
        8.5869e-03, 7.0464e-02, 9.0193e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,008][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.8000, 0.0973, 0.0167, 0.0142, 0.0058, 0.0129, 0.0098, 0.0180, 0.0253],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,009][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7427, 0.1920, 0.0265, 0.0217, 0.0034, 0.0051, 0.0022, 0.0040, 0.0024],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,009][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0248, 0.0597, 0.0647, 0.0607, 0.2037, 0.1234, 0.2201, 0.1300, 0.1128],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,011][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0275, 0.1561, 0.0599, 0.1459, 0.0907, 0.1145, 0.1202, 0.1447, 0.1406],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,013][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1191, 0.2699, 0.1152, 0.0805, 0.1096, 0.0979, 0.0734, 0.0704, 0.0641],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,016][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([6.8853e-02, 8.8434e-01, 4.5059e-02, 8.1849e-04, 3.7222e-04, 1.9201e-04,
        1.9456e-04, 9.0926e-05, 8.2978e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,020][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1538, 0.1941, 0.1633, 0.1167, 0.0915, 0.0621, 0.0461, 0.0630, 0.1093],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,020][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.5759, 0.0239, 0.0399, 0.0262, 0.0325, 0.0689, 0.0664, 0.0689, 0.0974],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,020][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1235, 0.1095, 0.0972, 0.1074, 0.1240, 0.1056, 0.0902, 0.1533, 0.0894],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,021][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1619, 0.1276, 0.1441, 0.0965, 0.1444, 0.0328, 0.0433, 0.1899, 0.0375,
        0.0220], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,021][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0326, 0.1178, 0.1395, 0.1647, 0.0784, 0.1060, 0.1091, 0.1166, 0.0849,
        0.0503], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,022][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ station] are: tensor([8.5560e-04, 4.5291e-08, 4.0722e-06, 2.5421e-05, 4.4966e-05, 4.8935e-04,
        2.4476e-04, 5.6477e-03, 7.2892e-02, 9.1980e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,022][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.7123, 0.1089, 0.0227, 0.0200, 0.0092, 0.0198, 0.0154, 0.0267, 0.0367,
        0.0284], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,022][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.7233, 0.2062, 0.0254, 0.0252, 0.0035, 0.0051, 0.0023, 0.0039, 0.0023,
        0.0027], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,024][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0162, 0.0455, 0.0440, 0.0482, 0.1386, 0.0939, 0.1543, 0.0979, 0.0845,
        0.2769], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,027][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0250, 0.0959, 0.0449, 0.1586, 0.0705, 0.1070, 0.1321, 0.1481, 0.1468,
        0.0712], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,031][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0830, 0.1468, 0.0976, 0.0944, 0.1067, 0.1215, 0.0881, 0.1023, 0.0880,
        0.0716], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,033][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ station] are: tensor([2.9991e-01, 6.1189e-01, 8.4005e-02, 9.9181e-04, 4.1625e-04, 1.1725e-04,
        1.4858e-04, 7.3582e-05, 8.8779e-05, 2.3617e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,033][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0659, 0.1074, 0.1817, 0.1442, 0.1097, 0.1064, 0.0473, 0.0584, 0.1633,
        0.0156], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,034][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.6019, 0.0096, 0.0110, 0.0135, 0.0121, 0.0413, 0.0454, 0.0669, 0.0863,
        0.1121], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,034][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1284, 0.0849, 0.1413, 0.0677, 0.1400, 0.0860, 0.1061, 0.0818, 0.0826,
        0.0812], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,035][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1775, 0.1226, 0.0721, 0.1020, 0.1196, 0.0551, 0.0449, 0.1659, 0.0586,
        0.0293, 0.0525], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,035][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0559, 0.1890, 0.1875, 0.1879, 0.0730, 0.0871, 0.0509, 0.0583, 0.0406,
        0.0224, 0.0473], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,036][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([1.6509e-03, 2.4880e-09, 2.2581e-07, 1.1482e-06, 1.2926e-06, 1.6504e-05,
        9.7287e-06, 1.7174e-04, 2.6657e-03, 4.8197e-02, 9.4729e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,036][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.7281, 0.1026, 0.0188, 0.0159, 0.0066, 0.0131, 0.0099, 0.0165, 0.0220,
        0.0188, 0.0478], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,038][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.6790, 0.2013, 0.0404, 0.0283, 0.0063, 0.0077, 0.0039, 0.0069, 0.0046,
        0.0059, 0.0158], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,040][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0187, 0.0430, 0.0469, 0.0430, 0.1331, 0.0818, 0.1433, 0.0859, 0.0743,
        0.2565, 0.0735], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,044][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0443, 0.1379, 0.0433, 0.0912, 0.0603, 0.0727, 0.0920, 0.1054, 0.0989,
        0.0607, 0.1933], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,047][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1308, 0.2158, 0.1159, 0.0617, 0.1147, 0.0822, 0.0628, 0.0553, 0.0515,
        0.0583, 0.0510], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,047][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([6.2271e-02, 8.6535e-01, 6.5738e-02, 1.4781e-03, 4.6392e-04, 2.1532e-04,
        2.0857e-04, 1.1804e-04, 1.1540e-04, 3.5565e-03, 4.8793e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,047][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1517, 0.0741, 0.1016, 0.1051, 0.0977, 0.0779, 0.0530, 0.0689, 0.1346,
        0.0538, 0.0816], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,048][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2227, 0.0333, 0.0450, 0.0279, 0.0333, 0.0517, 0.0560, 0.0656, 0.0861,
        0.1222, 0.2561], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,048][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1002, 0.0761, 0.0904, 0.0805, 0.1222, 0.0825, 0.0854, 0.1119, 0.0933,
        0.0909, 0.0665], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,049][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.1527, 0.1080, 0.0670, 0.1026, 0.0457, 0.0347, 0.0680, 0.2116, 0.0570,
        0.0341, 0.0793, 0.0394], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,049][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0421, 0.1495, 0.1498, 0.1755, 0.0730, 0.0951, 0.0653, 0.0720, 0.0481,
        0.0263, 0.0806, 0.0226], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,050][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([1.5659e-02, 3.7136e-11, 4.3810e-10, 1.4413e-08, 4.4977e-08, 6.4086e-07,
        6.4214e-07, 5.2141e-05, 9.0091e-04, 2.5274e-02, 3.0803e-01, 6.5008e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,051][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.8122, 0.0769, 0.0107, 0.0087, 0.0033, 0.0079, 0.0056, 0.0105, 0.0143,
        0.0107, 0.0327, 0.0064], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,054][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.6952, 0.2100, 0.0291, 0.0282, 0.0047, 0.0059, 0.0027, 0.0050, 0.0032,
        0.0042, 0.0100, 0.0018], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,058][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0092, 0.0289, 0.0279, 0.0300, 0.1015, 0.0656, 0.1172, 0.0677, 0.0611,
        0.2302, 0.0584, 0.2025], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,060][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0163, 0.0750, 0.0365, 0.0837, 0.0414, 0.0554, 0.0761, 0.0963, 0.0754,
        0.0557, 0.2249, 0.1633], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,060][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0629, 0.1755, 0.0804, 0.0768, 0.0834, 0.0935, 0.0663, 0.0711, 0.0685,
        0.0606, 0.0620, 0.0990], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,061][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([8.7569e-01, 1.0430e-03, 1.3279e-03, 1.9792e-04, 9.2590e-04, 3.6453e-04,
        2.7749e-04, 3.9816e-04, 1.4280e-03, 1.3605e-02, 5.9898e-03, 9.8756e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,061][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0284, 0.0724, 0.0913, 0.2144, 0.0210, 0.0843, 0.0589, 0.0613, 0.2448,
        0.0276, 0.0848, 0.0110], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,062][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.3096, 0.0031, 0.0040, 0.0065, 0.0062, 0.0258, 0.0270, 0.0551, 0.0757,
        0.1066, 0.2132, 0.1671], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,062][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.1169, 0.0904, 0.1043, 0.0705, 0.0868, 0.0756, 0.0710, 0.0680, 0.0701,
        0.0823, 0.0605, 0.1036], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,063][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0765, 0.0968, 0.0705, 0.0902, 0.0660, 0.0350, 0.0520, 0.2156, 0.0439,
        0.0508, 0.1268, 0.0692, 0.0066], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,063][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0406, 0.1742, 0.1641, 0.1726, 0.0610, 0.0825, 0.0566, 0.0693, 0.0472,
        0.0227, 0.0692, 0.0185, 0.0213], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,064][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([9.7747e-05, 1.9566e-11, 7.7468e-10, 9.7898e-09, 4.1864e-09, 6.9445e-08,
        2.6005e-08, 1.2972e-06, 1.3282e-05, 2.0111e-04, 9.7696e-03, 4.1845e-03,
        9.8573e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,067][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.6623, 0.0929, 0.0201, 0.0160, 0.0079, 0.0151, 0.0112, 0.0193, 0.0256,
        0.0212, 0.0514, 0.0154, 0.0416], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,070][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.7263, 0.1976, 0.0266, 0.0220, 0.0033, 0.0048, 0.0020, 0.0037, 0.0019,
        0.0024, 0.0066, 0.0011, 0.0018], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,074][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0120, 0.0324, 0.0327, 0.0343, 0.0929, 0.0632, 0.1033, 0.0653, 0.0579,
        0.1816, 0.0570, 0.1634, 0.1041], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,074][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0190, 0.0708, 0.0405, 0.0676, 0.0545, 0.0449, 0.0644, 0.0853, 0.0837,
        0.0547, 0.1777, 0.1722, 0.0647], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,075][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0831, 0.1375, 0.0882, 0.0681, 0.0995, 0.0814, 0.0643, 0.0609, 0.0580,
        0.0578, 0.0566, 0.0933, 0.0513], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,075][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([1.5385e-01, 8.0329e-01, 3.9861e-02, 7.3089e-04, 1.1747e-04, 4.3060e-05,
        2.7970e-05, 1.8904e-05, 1.6115e-05, 5.4263e-04, 1.4117e-04, 6.1997e-04,
        7.4513e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,076][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0185, 0.1112, 0.1535, 0.1723, 0.0689, 0.0510, 0.0398, 0.0553, 0.1726,
        0.0265, 0.0809, 0.0306, 0.0190], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,076][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.2890, 0.0144, 0.0162, 0.0132, 0.0116, 0.0287, 0.0313, 0.0408, 0.0565,
        0.0663, 0.1639, 0.0785, 0.1898], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,076][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0988, 0.0768, 0.1011, 0.0563, 0.0979, 0.0716, 0.0651, 0.0629, 0.0580,
        0.0800, 0.0477, 0.1099, 0.0740], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,078][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1205, 0.0976, 0.0568, 0.0927, 0.0674, 0.0424, 0.0455, 0.2036, 0.0349,
        0.0247, 0.0670, 0.0720, 0.0199, 0.0549], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,080][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0532, 0.2360, 0.2015, 0.2029, 0.0615, 0.0781, 0.0360, 0.0442, 0.0245,
        0.0090, 0.0254, 0.0074, 0.0068, 0.0135], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,082][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.8723e-04, 5.0764e-10, 4.3977e-08, 9.3727e-08, 9.7009e-09, 9.5768e-08,
        5.7263e-08, 4.8732e-07, 6.3247e-06, 4.2593e-05, 3.2379e-03, 4.5233e-04,
        1.2652e-01, 8.6955e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,086][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6846, 0.0889, 0.0170, 0.0132, 0.0061, 0.0117, 0.0086, 0.0148, 0.0191,
        0.0155, 0.0407, 0.0103, 0.0313, 0.0382], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,088][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7125, 0.1967, 0.0327, 0.0225, 0.0041, 0.0051, 0.0023, 0.0036, 0.0024,
        0.0031, 0.0085, 0.0014, 0.0020, 0.0030], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,088][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0096, 0.0243, 0.0273, 0.0257, 0.0905, 0.0522, 0.0974, 0.0528, 0.0468,
        0.1855, 0.0479, 0.1841, 0.1029, 0.0531], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,088][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0133, 0.0674, 0.0265, 0.0527, 0.0397, 0.0609, 0.0582, 0.0652, 0.0658,
        0.0374, 0.1572, 0.1167, 0.0574, 0.1816], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,089][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1304, 0.1237, 0.0812, 0.0537, 0.0907, 0.0776, 0.0544, 0.0528, 0.0506,
        0.0509, 0.0535, 0.0788, 0.0518, 0.0498], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,089][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.8580e-01, 1.4231e-01, 1.5968e-02, 1.0743e-03, 9.4056e-04, 3.5159e-04,
        2.7736e-04, 2.1528e-04, 3.8747e-04, 9.2178e-03, 1.7472e-03, 1.9228e-02,
        8.7378e-03, 1.3747e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,090][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0569, 0.0913, 0.1409, 0.0881, 0.0863, 0.0537, 0.0455, 0.0473, 0.1326,
        0.0349, 0.0707, 0.0498, 0.0457, 0.0564], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,090][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4586, 0.0019, 0.0084, 0.0026, 0.0038, 0.0088, 0.0074, 0.0068, 0.0146,
        0.0222, 0.0767, 0.0211, 0.0949, 0.2721], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,092][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0707, 0.0679, 0.0663, 0.0598, 0.0817, 0.0674, 0.0596, 0.0936, 0.0701,
        0.0459, 0.0536, 0.1020, 0.0881, 0.0733], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,095][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0984, 0.0816, 0.0929, 0.0698, 0.0513, 0.0322, 0.0770, 0.1329, 0.0409,
        0.0319, 0.0795, 0.0526, 0.0419, 0.1074, 0.0096], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,099][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0471, 0.1797, 0.1484, 0.1648, 0.0563, 0.0761, 0.0528, 0.0707, 0.0419,
        0.0148, 0.0491, 0.0139, 0.0173, 0.0386, 0.0286], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,101][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([3.9035e-04, 1.3546e-10, 6.1660e-09, 2.7834e-08, 3.3023e-09, 4.3496e-08,
        2.4257e-08, 3.9256e-07, 4.5125e-06, 3.1732e-05, 1.6427e-03, 3.8936e-04,
        8.3403e-02, 6.8186e-01, 2.3228e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,101][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.5500, 0.0905, 0.0213, 0.0175, 0.0089, 0.0158, 0.0122, 0.0202, 0.0268,
        0.0228, 0.0526, 0.0162, 0.0410, 0.0532, 0.0508], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,102][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.6401, 0.2201, 0.0425, 0.0326, 0.0070, 0.0084, 0.0038, 0.0067, 0.0040,
        0.0052, 0.0121, 0.0028, 0.0034, 0.0058, 0.0055], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,102][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0097, 0.0254, 0.0272, 0.0269, 0.0801, 0.0495, 0.0878, 0.0515, 0.0453,
        0.1623, 0.0466, 0.1486, 0.0918, 0.0541, 0.0930], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,103][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0173, 0.0582, 0.0178, 0.0486, 0.0354, 0.0399, 0.0562, 0.0687, 0.0590,
        0.0415, 0.1434, 0.1067, 0.0545, 0.1636, 0.0892], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,103][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0897, 0.1159, 0.0774, 0.0602, 0.0850, 0.0803, 0.0568, 0.0577, 0.0541,
        0.0492, 0.0531, 0.0775, 0.0499, 0.0486, 0.0446], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,104][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([3.8197e-01, 5.1662e-01, 8.2127e-02, 2.4100e-03, 9.1612e-04, 2.1387e-04,
        3.0919e-04, 1.2815e-04, 1.7583e-04, 3.0349e-03, 6.8607e-04, 3.8114e-03,
        2.6346e-03, 3.4797e-03, 1.4846e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,106][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0117, 0.0590, 0.2492, 0.1175, 0.1019, 0.0593, 0.0293, 0.0483, 0.1239,
        0.0159, 0.0494, 0.0409, 0.0353, 0.0459, 0.0123], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,108][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.3162, 0.0073, 0.0109, 0.0054, 0.0049, 0.0116, 0.0122, 0.0127, 0.0212,
        0.0230, 0.0734, 0.0218, 0.0792, 0.2324, 0.1679], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,112][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0854, 0.0665, 0.0859, 0.0476, 0.0881, 0.0538, 0.0605, 0.0650, 0.0591,
        0.0572, 0.0379, 0.1011, 0.0858, 0.0545, 0.0516], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,115][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1032, 0.0854, 0.0824, 0.0960, 0.0869, 0.0170, 0.0293, 0.1397, 0.0312,
        0.0223, 0.0691, 0.0856, 0.0243, 0.0770, 0.0221, 0.0287],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,115][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0358, 0.1705, 0.1557, 0.1717, 0.0546, 0.0742, 0.0492, 0.0599, 0.0365,
        0.0169, 0.0611, 0.0129, 0.0162, 0.0348, 0.0246, 0.0255],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,115][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([4.1336e-04, 2.0351e-10, 4.2920e-09, 1.0578e-08, 1.7110e-09, 9.2273e-09,
        8.1718e-09, 1.0307e-07, 1.1667e-06, 8.6218e-06, 3.3113e-04, 1.2182e-04,
        1.0531e-02, 9.5169e-02, 4.9027e-02, 8.4440e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,116][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6453, 0.0882, 0.0169, 0.0133, 0.0062, 0.0110, 0.0077, 0.0126, 0.0158,
        0.0136, 0.0338, 0.0089, 0.0262, 0.0330, 0.0318, 0.0356],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,116][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6790, 0.2115, 0.0368, 0.0268, 0.0054, 0.0064, 0.0027, 0.0045, 0.0025,
        0.0035, 0.0080, 0.0016, 0.0022, 0.0034, 0.0032, 0.0026],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,117][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0085, 0.0209, 0.0240, 0.0217, 0.0788, 0.0437, 0.0848, 0.0448, 0.0381,
        0.1625, 0.0393, 0.1605, 0.0900, 0.0470, 0.0870, 0.0484],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,117][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0080, 0.0400, 0.0164, 0.0382, 0.0280, 0.0407, 0.0437, 0.0542, 0.0554,
        0.0321, 0.1284, 0.1045, 0.0525, 0.1576, 0.0939, 0.1066],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,119][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1087, 0.1334, 0.0663, 0.0573, 0.0749, 0.0718, 0.0513, 0.0505, 0.0478,
        0.0460, 0.0490, 0.0689, 0.0417, 0.0456, 0.0391, 0.0477],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,121][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([8.0782e-01, 7.5568e-02, 1.6002e-02, 1.1420e-03, 1.4380e-03, 4.2045e-04,
        4.1650e-04, 2.9601e-04, 5.0771e-04, 8.7683e-03, 2.0636e-03, 2.5225e-02,
        9.4865e-03, 2.0233e-02, 1.5681e-02, 1.4931e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,124][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0263, 0.0765, 0.1157, 0.1088, 0.0762, 0.0526, 0.0416, 0.0494, 0.0907,
        0.0247, 0.0617, 0.0377, 0.0379, 0.0709, 0.0637, 0.0657],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,126][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([7.5945e-01, 6.8883e-04, 2.1838e-03, 7.6955e-04, 8.8952e-04, 2.8413e-03,
        2.5506e-03, 2.1961e-03, 4.4962e-03, 5.4939e-03, 2.1203e-02, 4.5971e-03,
        2.2908e-02, 4.7188e-02, 5.3894e-02, 6.8646e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,128][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0802, 0.0644, 0.0693, 0.0543, 0.0742, 0.0694, 0.0533, 0.0723, 0.0502,
        0.0482, 0.0399, 0.0870, 0.0715, 0.0580, 0.0552, 0.0526],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,129][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1027, 0.0833, 0.0992, 0.0775, 0.0641, 0.0338, 0.0235, 0.1229, 0.0296,
        0.0259, 0.0542, 0.0620, 0.0407, 0.0797, 0.0344, 0.0396, 0.0270],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,129][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0318, 0.1617, 0.1717, 0.1788, 0.0563, 0.0772, 0.0526, 0.0629, 0.0343,
        0.0141, 0.0560, 0.0106, 0.0134, 0.0346, 0.0208, 0.0190, 0.0044],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,130][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([6.3709e-04, 1.2807e-11, 2.2188e-10, 1.1054e-09, 2.1094e-10, 1.7505e-09,
        1.3340e-09, 3.6660e-08, 4.3663e-07, 3.6055e-06, 1.0092e-04, 5.7939e-05,
        3.8303e-03, 3.5600e-02, 2.2780e-02, 5.2547e-01, 4.1152e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,130][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.5896, 0.0883, 0.0181, 0.0146, 0.0071, 0.0125, 0.0089, 0.0150, 0.0179,
        0.0150, 0.0353, 0.0102, 0.0283, 0.0345, 0.0338, 0.0385, 0.0323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,131][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.6786, 0.2158, 0.0337, 0.0271, 0.0050, 0.0061, 0.0026, 0.0040, 0.0024,
        0.0032, 0.0076, 0.0015, 0.0022, 0.0032, 0.0031, 0.0025, 0.0016],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,131][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0076, 0.0217, 0.0219, 0.0236, 0.0691, 0.0445, 0.0748, 0.0449, 0.0382,
        0.1327, 0.0379, 0.1233, 0.0755, 0.0411, 0.0780, 0.0459, 0.1191],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,133][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0114, 0.0350, 0.0217, 0.0380, 0.0335, 0.0388, 0.0393, 0.0433, 0.0495,
        0.0354, 0.1068, 0.0970, 0.0391, 0.1353, 0.0778, 0.0977, 0.1003],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,137][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0832, 0.0839, 0.0511, 0.0595, 0.0607, 0.0760, 0.0504, 0.0585, 0.0545,
        0.0430, 0.0572, 0.0705, 0.0465, 0.0553, 0.0489, 0.0583, 0.0425],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,139][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([5.4486e-01, 3.8629e-01, 3.7013e-02, 1.3719e-03, 6.1136e-04, 1.6143e-04,
        2.3757e-04, 1.0733e-04, 1.3835e-04, 2.9724e-03, 6.4714e-04, 5.4249e-03,
        3.5657e-03, 5.0211e-03, 3.0382e-03, 5.4748e-03, 3.0679e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,141][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0087, 0.0742, 0.1210, 0.1135, 0.0555, 0.0529, 0.0322, 0.0294, 0.1129,
        0.0112, 0.0504, 0.0274, 0.0374, 0.0633, 0.0616, 0.1425, 0.0058],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,142][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([6.7778e-01, 7.6308e-04, 1.2759e-03, 8.0820e-04, 6.1947e-04, 2.7142e-03,
        2.7740e-03, 2.9705e-03, 5.7381e-03, 5.4011e-03, 1.8717e-02, 4.2345e-03,
        2.0788e-02, 5.0172e-02, 5.1025e-02, 6.4361e-02, 8.9854e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,142][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0915, 0.0545, 0.0712, 0.0437, 0.0776, 0.0589, 0.0497, 0.0424, 0.0429,
        0.0728, 0.0341, 0.0894, 0.0760, 0.0453, 0.0557, 0.0438, 0.0505],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,143][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1108, 0.0848, 0.0506, 0.0778, 0.0569, 0.0402, 0.0415, 0.1514, 0.0282,
        0.0223, 0.0502, 0.0578, 0.0196, 0.0418, 0.0308, 0.0414, 0.0414, 0.0524],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,143][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0385, 0.2105, 0.2114, 0.2096, 0.0637, 0.0773, 0.0370, 0.0414, 0.0209,
        0.0100, 0.0286, 0.0067, 0.0060, 0.0129, 0.0083, 0.0080, 0.0021, 0.0072],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,144][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.0685e-04, 1.1164e-10, 3.4700e-09, 3.8709e-09, 4.0137e-10, 1.4866e-09,
        1.4999e-09, 8.5225e-09, 1.1067e-07, 4.3605e-07, 1.6527e-05, 5.1022e-06,
        2.3077e-04, 2.0962e-03, 1.2189e-03, 3.2402e-02, 2.3810e-02, 9.4001e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,144][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4602, 0.0858, 0.0221, 0.0174, 0.0094, 0.0149, 0.0114, 0.0171, 0.0203,
        0.0177, 0.0391, 0.0122, 0.0302, 0.0350, 0.0352, 0.0404, 0.0349, 0.0967],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,146][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6038, 0.2173, 0.0520, 0.0343, 0.0094, 0.0093, 0.0046, 0.0062, 0.0044,
        0.0065, 0.0133, 0.0032, 0.0035, 0.0050, 0.0054, 0.0046, 0.0032, 0.0140],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,149][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0065, 0.0161, 0.0187, 0.0172, 0.0638, 0.0347, 0.0685, 0.0357, 0.0313,
        0.1393, 0.0335, 0.1376, 0.0763, 0.0381, 0.0734, 0.0407, 0.1333, 0.0354],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,153][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0037, 0.0303, 0.0127, 0.0282, 0.0204, 0.0337, 0.0338, 0.0367, 0.0387,
        0.0197, 0.0981, 0.0820, 0.0342, 0.1267, 0.0733, 0.0785, 0.0862, 0.1632],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,155][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0958, 0.1142, 0.0581, 0.0526, 0.0650, 0.0688, 0.0474, 0.0487, 0.0459,
        0.0410, 0.0472, 0.0629, 0.0408, 0.0437, 0.0389, 0.0458, 0.0387, 0.0445],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,156][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([8.1122e-01, 4.3105e-02, 5.1983e-03, 6.3399e-04, 7.4167e-04, 3.1990e-04,
        2.4276e-04, 1.8873e-04, 4.0540e-04, 7.4901e-03, 1.5161e-03, 1.9946e-02,
        7.1507e-03, 1.3295e-02, 1.2238e-02, 2.0783e-02, 1.1431e-02, 4.4093e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,156][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0159, 0.0777, 0.0960, 0.1018, 0.0502, 0.0441, 0.0375, 0.0382, 0.1152,
        0.0171, 0.0529, 0.0238, 0.0298, 0.0402, 0.0621, 0.1363, 0.0164, 0.0447],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,156][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.9334e-01, 9.9846e-05, 5.4394e-04, 1.1194e-04, 1.5657e-04, 5.1002e-04,
        4.0244e-04, 2.6175e-04, 6.4036e-04, 7.9614e-04, 3.9601e-03, 5.7087e-04,
        4.1121e-03, 5.2053e-03, 9.4497e-03, 1.1506e-02, 2.5157e-02, 4.3175e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,157][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0548, 0.0518, 0.0516, 0.0463, 0.0620, 0.0525, 0.0461, 0.0717, 0.0544,
        0.0364, 0.0419, 0.0774, 0.0691, 0.0573, 0.0481, 0.0602, 0.0587, 0.0598],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,185][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:16,186][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,188][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,192][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,195][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,195][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,195][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,196][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,196][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,196][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,197][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,197][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,197][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,198][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4933, 0.5067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,199][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6676, 0.3324], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,202][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4787, 0.5213], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,206][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7933, 0.2067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,208][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6252, 0.3748], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,208][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4148, 0.5852], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,209][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9546, 0.0454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,209][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4457, 0.5543], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,209][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5394, 0.4606], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,210][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4483, 0.5517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,210][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2341, 0.7659], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,211][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4775, 0.5225], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,211][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.2553, 0.3808, 0.3640], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,212][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([8.2043e-01, 1.7882e-01, 7.4928e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,214][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.1368, 0.2439, 0.6193], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,217][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.0305, 0.8012, 0.1683], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,221][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.6608, 0.2950, 0.0442], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,222][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.1742, 0.5139, 0.3118], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,222][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.2921, 0.3640, 0.3438], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,223][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.2879, 0.3573, 0.3548], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,223][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.3582, 0.3907, 0.2512], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,223][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.1480, 0.2252, 0.6269], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,224][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.0847, 0.3637, 0.5516], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,224][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.3214, 0.3400, 0.3386], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,224][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1792, 0.2290, 0.3474, 0.2443], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,225][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5453, 0.2756, 0.0230, 0.1561], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,226][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0607, 0.0859, 0.7433, 0.1101], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,229][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0342, 0.1742, 0.7322, 0.0594], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,233][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6629, 0.2399, 0.0492, 0.0481], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,235][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1517, 0.2939, 0.4069, 0.1475], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,236][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5139, 0.0733, 0.0882, 0.3246], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,236][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2418, 0.2763, 0.4444, 0.0375], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,236][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3101, 0.2838, 0.2356, 0.1705], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,237][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0328, 0.0591, 0.7789, 0.1293], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,237][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0784, 0.2568, 0.4322, 0.2325], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,238][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2468, 0.2497, 0.2383, 0.2652], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,238][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.1092, 0.1421, 0.2347, 0.2235, 0.2905], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,238][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.3512, 0.3333, 0.0104, 0.3015, 0.0036], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,240][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0656, 0.0897, 0.6356, 0.1457, 0.0634], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,243][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0170, 0.2338, 0.3962, 0.2356, 0.1175], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,247][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.7140, 0.2335, 0.0203, 0.0295, 0.0026], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,249][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0786, 0.2336, 0.3298, 0.1583, 0.1997], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,249][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0860, 0.1023, 0.1218, 0.4103, 0.2796], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,250][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.2083, 0.2700, 0.3025, 0.0698, 0.1494], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,250][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.2121, 0.2163, 0.1938, 0.1877, 0.1901], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,250][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0264, 0.0420, 0.4512, 0.1822, 0.2981], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,251][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0445, 0.1885, 0.2958, 0.1542, 0.3170], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,251][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.2048, 0.1989, 0.1774, 0.2067, 0.2122], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,252][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1019, 0.1265, 0.2109, 0.1655, 0.3088, 0.0863], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,252][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([7.7156e-01, 1.7439e-01, 1.2134e-03, 5.0540e-02, 1.8822e-04, 2.1071e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,254][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0531, 0.0767, 0.4791, 0.1545, 0.1684, 0.0682], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,256][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0675, 0.1166, 0.1613, 0.1350, 0.5008, 0.0188], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,260][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.7398, 0.2105, 0.0199, 0.0242, 0.0026, 0.0029], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,263][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0844, 0.1900, 0.2329, 0.1153, 0.3051, 0.0724], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,263][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.2015, 0.0736, 0.0529, 0.2704, 0.1824, 0.2193], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,263][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1822, 0.2272, 0.2714, 0.0488, 0.1357, 0.1347], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,264][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.2002, 0.1908, 0.1427, 0.1372, 0.1786, 0.1505], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,264][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0296, 0.0486, 0.3794, 0.1334, 0.2902, 0.1189], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,265][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0363, 0.1381, 0.2235, 0.1157, 0.2420, 0.2444], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,265][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.2081, 0.1804, 0.1318, 0.1547, 0.1478, 0.1771], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,265][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0661, 0.0873, 0.2100, 0.1358, 0.2808, 0.1018, 0.1182],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,266][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([7.3567e-01, 2.1289e-01, 6.3499e-05, 5.1016e-02, 1.8660e-05, 2.7214e-04,
        7.2412e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,267][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0302, 0.0482, 0.3186, 0.0994, 0.1445, 0.2245, 0.1347],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,270][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0288, 0.0986, 0.2469, 0.0915, 0.4944, 0.0297, 0.0101],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,274][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.7684, 0.1877, 0.0182, 0.0197, 0.0024, 0.0027, 0.0009],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,276][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0461, 0.1171, 0.2580, 0.0964, 0.2696, 0.1344, 0.0783],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,277][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.1564, 0.0452, 0.0586, 0.2033, 0.1664, 0.2065, 0.1636],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,277][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.1535, 0.1981, 0.2557, 0.0559, 0.1142, 0.1349, 0.0876],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,277][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.1453, 0.1242, 0.1196, 0.0948, 0.1635, 0.1940, 0.1585],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,278][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0109, 0.0174, 0.2780, 0.0750, 0.2553, 0.1880, 0.1754],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,278][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0239, 0.0980, 0.1607, 0.0831, 0.1898, 0.2064, 0.2381],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,279][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.2120, 0.1667, 0.1014, 0.1248, 0.1077, 0.1379, 0.1496],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,279][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0692, 0.0915, 0.1434, 0.1138, 0.2071, 0.0782, 0.1483, 0.1485],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,280][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([9.3230e-01, 6.4226e-02, 4.5284e-08, 3.4406e-03, 1.8556e-08, 3.2762e-07,
        2.4100e-07, 2.9194e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,283][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0302, 0.0575, 0.2748, 0.0968, 0.0903, 0.1680, 0.2521, 0.0304],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,286][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0300, 0.0402, 0.2240, 0.0578, 0.3857, 0.1600, 0.0971, 0.0051],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,290][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.7500, 0.1932, 0.0253, 0.0211, 0.0034, 0.0033, 0.0013, 0.0025],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,290][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0661, 0.1453, 0.1959, 0.1010, 0.1794, 0.1364, 0.1090, 0.0669],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,291][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2145, 0.0283, 0.0452, 0.1311, 0.1528, 0.1389, 0.1161, 0.1732],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,291][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1781, 0.1604, 0.2425, 0.0344, 0.1062, 0.1299, 0.0887, 0.0598],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,291][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1380, 0.1099, 0.1090, 0.0710, 0.0921, 0.1936, 0.1958, 0.0906],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,292][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0232, 0.0310, 0.2194, 0.0636, 0.2043, 0.1563, 0.2445, 0.0577],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,292][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0263, 0.0872, 0.1433, 0.0783, 0.1698, 0.1767, 0.2013, 0.1171],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,293][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2113, 0.1570, 0.0861, 0.1059, 0.0849, 0.1104, 0.1155, 0.1289],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,294][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0608, 0.0724, 0.1306, 0.1028, 0.1841, 0.0687, 0.1295, 0.1771, 0.0739],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,296][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.3547e-01, 5.9024e-02, 1.3493e-08, 2.5316e-03, 7.4732e-09, 8.1609e-08,
        4.2861e-08, 1.0496e-05, 2.9605e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,299][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0322, 0.0373, 0.2118, 0.1041, 0.0816, 0.1844, 0.2161, 0.1050, 0.0276],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,303][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0686, 0.1208, 0.1217, 0.1682, 0.1705, 0.0639, 0.0618, 0.1401, 0.0844],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,304][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.7449, 0.1929, 0.0247, 0.0229, 0.0039, 0.0039, 0.0016, 0.0034, 0.0019],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,304][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0569, 0.1333, 0.1808, 0.0989, 0.1731, 0.1178, 0.0938, 0.0893, 0.0562],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,304][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0933, 0.0214, 0.0280, 0.1244, 0.1266, 0.1427, 0.1145, 0.1775, 0.1715],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,305][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1487, 0.1249, 0.2496, 0.0291, 0.1017, 0.1190, 0.0749, 0.0534, 0.0986],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,305][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0998, 0.0863, 0.0763, 0.0736, 0.1015, 0.1363, 0.1677, 0.1904, 0.0682],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,306][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0274, 0.0360, 0.1739, 0.0694, 0.1763, 0.1086, 0.2158, 0.1176, 0.0750],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,306][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0236, 0.0824, 0.1323, 0.0745, 0.1535, 0.1558, 0.1762, 0.1041, 0.0976],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,308][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2091, 0.1473, 0.0757, 0.0922, 0.0722, 0.0925, 0.0943, 0.1044, 0.1123],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,310][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0434, 0.0590, 0.1184, 0.0849, 0.1663, 0.0604, 0.1205, 0.1644, 0.0745,
        0.1083], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,313][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([9.2646e-01, 6.9748e-02, 3.5948e-09, 1.7180e-03, 5.6276e-09, 2.5224e-08,
        2.6075e-08, 3.1450e-06, 4.2179e-04, 1.6505e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,317][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0221, 0.0310, 0.2124, 0.0775, 0.0637, 0.1650, 0.1712, 0.1047, 0.0610,
        0.0915], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,317][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0113, 0.0431, 0.2950, 0.0845, 0.1964, 0.0838, 0.0492, 0.0327, 0.2008,
        0.0032], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,318][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.7143, 0.2142, 0.0245, 0.0290, 0.0044, 0.0043, 0.0017, 0.0036, 0.0021,
        0.0020], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,318][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0335, 0.1029, 0.1584, 0.0743, 0.1378, 0.1130, 0.1014, 0.1085, 0.0762,
        0.0941], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,318][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0456, 0.0214, 0.0209, 0.1216, 0.0857, 0.1599, 0.1415, 0.1444, 0.1611,
        0.0980], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,319][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1176, 0.1296, 0.1796, 0.0272, 0.0815, 0.1103, 0.0771, 0.0463, 0.0707,
        0.1600], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,319][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0838, 0.0779, 0.0580, 0.0573, 0.0708, 0.1129, 0.1341, 0.1986, 0.0780,
        0.1285], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,320][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0050, 0.0085, 0.1927, 0.0407, 0.1524, 0.0992, 0.1954, 0.1113, 0.1246,
        0.0703], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,321][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0154, 0.0684, 0.1108, 0.0560, 0.1213, 0.1335, 0.1663, 0.0801, 0.0751,
        0.1731], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,323][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1754, 0.1262, 0.0665, 0.0823, 0.0667, 0.0838, 0.0874, 0.0976, 0.1060,
        0.1081], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,326][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0582, 0.0625, 0.0843, 0.0762, 0.1589, 0.0610, 0.0988, 0.1347, 0.0696,
        0.1020, 0.0937], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,329][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([8.0574e-01, 6.2271e-02, 2.6970e-07, 5.7431e-03, 6.1168e-08, 1.2545e-06,
        7.2396e-07, 2.1257e-04, 6.7661e-02, 4.6934e-02, 1.1438e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,331][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0177, 0.0163, 0.1971, 0.0452, 0.0622, 0.1617, 0.1513, 0.0624, 0.0491,
        0.2245, 0.0125], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,331][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0105, 0.1047, 0.1716, 0.1016, 0.1575, 0.2665, 0.0275, 0.0301, 0.1181,
        0.0079, 0.0041], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,331][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.6714, 0.2134, 0.0430, 0.0313, 0.0072, 0.0066, 0.0029, 0.0063, 0.0037,
        0.0041, 0.0102], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,332][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0533, 0.1160, 0.1381, 0.0819, 0.1127, 0.0815, 0.0583, 0.0786, 0.0597,
        0.1439, 0.0762], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,332][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1199, 0.0150, 0.0202, 0.0712, 0.1038, 0.0929, 0.0874, 0.1105, 0.1140,
        0.0766, 0.1885], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,333][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1097, 0.0769, 0.2256, 0.0196, 0.0892, 0.0876, 0.0683, 0.0409, 0.0819,
        0.1832, 0.0171], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,333][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1172, 0.0858, 0.0826, 0.0560, 0.0865, 0.0847, 0.1170, 0.1213, 0.0726,
        0.1138, 0.0624], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,334][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0184, 0.0208, 0.1505, 0.0553, 0.1219, 0.0925, 0.1429, 0.0957, 0.1008,
        0.1263, 0.0749], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,336][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0189, 0.0629, 0.1083, 0.0570, 0.1207, 0.1184, 0.1389, 0.0794, 0.0779,
        0.1593, 0.0583], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,339][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1965, 0.1343, 0.0644, 0.0776, 0.0573, 0.0690, 0.0677, 0.0729, 0.0785,
        0.0792, 0.1026], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,342][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.0368, 0.0478, 0.0750, 0.0716, 0.0917, 0.0500, 0.1170, 0.1352, 0.0679,
        0.1056, 0.0986, 0.1030], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,344][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([7.1601e-01, 1.8141e-01, 3.1532e-05, 5.1387e-02, 1.2767e-05, 1.0320e-04,
        2.1160e-05, 1.4529e-03, 8.1586e-03, 1.7652e-02, 2.2782e-02, 9.7874e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,344][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0255, 0.0337, 0.2235, 0.0579, 0.0214, 0.1826, 0.1388, 0.0463, 0.0683,
        0.1602, 0.0245, 0.0172], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,345][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0187, 0.0515, 0.1405, 0.0631, 0.0419, 0.1275, 0.0812, 0.2223, 0.1624,
        0.0467, 0.0221, 0.0219], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,345][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.6606, 0.2424, 0.0301, 0.0363, 0.0052, 0.0050, 0.0019, 0.0049, 0.0029,
        0.0031, 0.0067, 0.0008], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,346][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0251, 0.0765, 0.1191, 0.0550, 0.0663, 0.0748, 0.0887, 0.0905, 0.0636,
        0.1352, 0.1072, 0.0979], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,346][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0049, 0.0129, 0.0181, 0.0913, 0.0596, 0.1142, 0.0814, 0.1030, 0.0950,
        0.0897, 0.1714, 0.1585], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,347][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1003, 0.1222, 0.1506, 0.0329, 0.0707, 0.0966, 0.0625, 0.0450, 0.0853,
        0.1298, 0.0243, 0.0799], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,348][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.0605, 0.0556, 0.0482, 0.0464, 0.0438, 0.1079, 0.1281, 0.1605, 0.0727,
        0.1213, 0.0688, 0.0862], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,349][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0053, 0.0082, 0.1132, 0.0438, 0.0668, 0.1022, 0.1681, 0.1085, 0.1135,
        0.1193, 0.0947, 0.0565], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,353][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0142, 0.0608, 0.0951, 0.0496, 0.1025, 0.1156, 0.1312, 0.0699, 0.0646,
        0.1465, 0.0506, 0.0994], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,356][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.1571, 0.1035, 0.0500, 0.0610, 0.0460, 0.0650, 0.0682, 0.0764, 0.0823,
        0.0804, 0.1088, 0.1013], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,358][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0250, 0.0477, 0.0750, 0.0674, 0.0976, 0.0501, 0.0971, 0.1294, 0.0574,
        0.1031, 0.1032, 0.1098, 0.0371], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,358][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([8.3755e-01, 1.3041e-01, 1.7071e-07, 1.0562e-02, 2.0736e-07, 2.2402e-06,
        1.7482e-06, 9.8197e-05, 7.9372e-03, 8.0853e-03, 4.5813e-03, 6.2109e-05,
        7.0856e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,359][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0242, 0.0356, 0.1420, 0.0874, 0.0568, 0.1316, 0.1120, 0.0454, 0.0731,
        0.1381, 0.0381, 0.0467, 0.0690], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,359][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0487, 0.0353, 0.1153, 0.0579, 0.2577, 0.0283, 0.0224, 0.1081, 0.1744,
        0.0272, 0.0125, 0.1025, 0.0098], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,359][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([7.3368e-01, 2.0579e-01, 2.2816e-02, 2.1554e-02, 3.0388e-03, 3.1766e-03,
        1.0805e-03, 2.5457e-03, 1.1762e-03, 1.1836e-03, 2.9965e-03, 3.8028e-04,
        5.8472e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,360][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0208, 0.0514, 0.0731, 0.0492, 0.0777, 0.0788, 0.0598, 0.0818, 0.0669,
        0.1549, 0.0913, 0.1073, 0.0868], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,360][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0100, 0.0086, 0.0157, 0.0553, 0.0797, 0.0684, 0.0622, 0.0974, 0.1139,
        0.0765, 0.1519, 0.2104, 0.0499], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,362][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0886, 0.1251, 0.1255, 0.0310, 0.0783, 0.0695, 0.0669, 0.0414, 0.0622,
        0.1112, 0.0201, 0.0809, 0.0994], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,365][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0531, 0.0601, 0.0470, 0.0382, 0.0645, 0.1049, 0.0808, 0.0872, 0.0532,
        0.0812, 0.0550, 0.1150, 0.1598], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,369][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0074, 0.0123, 0.0917, 0.0416, 0.1008, 0.0797, 0.1297, 0.0964, 0.0889,
        0.1004, 0.1001, 0.0808, 0.0702], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,371][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0128, 0.0529, 0.0800, 0.0445, 0.0941, 0.1010, 0.1191, 0.0640, 0.0584,
        0.1313, 0.0459, 0.0912, 0.1047], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,372][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.1548, 0.1053, 0.0523, 0.0620, 0.0469, 0.0596, 0.0582, 0.0632, 0.0665,
        0.0662, 0.0848, 0.0785, 0.1018], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,372][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0362, 0.0425, 0.0657, 0.0606, 0.0950, 0.0497, 0.0906, 0.1126, 0.0452,
        0.0840, 0.0783, 0.1110, 0.0521, 0.0765], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,372][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.5246e-01, 3.0183e-02, 5.7184e-07, 3.2059e-03, 2.6683e-07, 1.9073e-06,
        1.1359e-06, 1.0724e-04, 5.8188e-03, 6.7572e-03, 3.3781e-03, 1.7335e-05,
        3.9725e-04, 6.9767e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,373][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0197, 0.0238, 0.0961, 0.0611, 0.0290, 0.1223, 0.1436, 0.0478, 0.0471,
        0.1680, 0.0154, 0.0248, 0.1923, 0.0091], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,373][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0434, 0.0744, 0.1041, 0.0581, 0.1883, 0.0619, 0.0672, 0.0290, 0.2336,
        0.0118, 0.0287, 0.0739, 0.0238, 0.0016], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,374][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.2088e-01, 2.0412e-01, 2.9631e-02, 2.2608e-02, 4.2824e-03, 3.9048e-03,
        1.5754e-03, 2.8326e-03, 1.6930e-03, 2.0054e-03, 4.0837e-03, 5.8865e-04,
        7.9594e-04, 1.0022e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,376][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0221, 0.0497, 0.1046, 0.0512, 0.1047, 0.0728, 0.0501, 0.0521, 0.0467,
        0.1205, 0.0625, 0.1330, 0.1048, 0.0252], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,378][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0334, 0.0074, 0.0151, 0.0418, 0.0702, 0.0835, 0.0554, 0.0766, 0.0853,
        0.0562, 0.1470, 0.1230, 0.0544, 0.1510], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,382][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0955, 0.0794, 0.1600, 0.0155, 0.0632, 0.0732, 0.0542, 0.0304, 0.0552,
        0.1221, 0.0117, 0.0701, 0.1474, 0.0222], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,385][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0534, 0.0498, 0.0410, 0.0379, 0.0590, 0.0742, 0.1063, 0.0690, 0.0433,
        0.0798, 0.0441, 0.0985, 0.2000, 0.0436], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,385][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0115, 0.0134, 0.1224, 0.0311, 0.1008, 0.0684, 0.1266, 0.0505, 0.0755,
        0.0998, 0.0642, 0.0959, 0.1294, 0.0105], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,386][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0146, 0.0510, 0.0786, 0.0463, 0.0885, 0.0929, 0.1051, 0.0627, 0.0591,
        0.1215, 0.0456, 0.0877, 0.0998, 0.0466], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,386][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1340, 0.0930, 0.0480, 0.0566, 0.0448, 0.0531, 0.0532, 0.0576, 0.0612,
        0.0617, 0.0779, 0.0753, 0.0900, 0.0936], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,386][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0276, 0.0373, 0.0677, 0.0522, 0.0740, 0.0442, 0.1041, 0.0993, 0.0506,
        0.0744, 0.0778, 0.0896, 0.0712, 0.1018, 0.0284], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,387][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.0641e-01, 3.0414e-02, 8.7849e-07, 4.6015e-03, 4.5033e-07, 2.7433e-06,
        1.1368e-06, 1.1938e-04, 6.1363e-03, 7.6132e-03, 5.0907e-03, 1.6924e-05,
        2.5143e-04, 6.7374e-01, 6.5601e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,387][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0218, 0.0260, 0.1137, 0.0485, 0.0508, 0.1008, 0.1062, 0.0380, 0.0461,
        0.1131, 0.0235, 0.0414, 0.1914, 0.0413, 0.0374], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,389][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0232, 0.0391, 0.1594, 0.0480, 0.0708, 0.0819, 0.0834, 0.0419, 0.3297,
        0.0231, 0.0283, 0.0280, 0.0356, 0.0047, 0.0028], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,393][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.6376, 0.2371, 0.0399, 0.0361, 0.0080, 0.0074, 0.0030, 0.0062, 0.0035,
        0.0039, 0.0080, 0.0017, 0.0019, 0.0027, 0.0029], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,396][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0278, 0.0605, 0.0918, 0.0501, 0.0906, 0.0536, 0.0481, 0.0535, 0.0635,
        0.1061, 0.0820, 0.1147, 0.1013, 0.0344, 0.0221], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,400][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0171, 0.0068, 0.0064, 0.0395, 0.0511, 0.0657, 0.0558, 0.0851, 0.0791,
        0.0609, 0.1352, 0.1129, 0.0472, 0.1491, 0.0880], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,400][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0840, 0.0906, 0.1130, 0.0208, 0.0546, 0.0681, 0.0487, 0.0338, 0.0547,
        0.1025, 0.0134, 0.0588, 0.1362, 0.0284, 0.0923], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,401][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0702, 0.0593, 0.0452, 0.0360, 0.0471, 0.0706, 0.0691, 0.0575, 0.0448,
        0.0698, 0.0396, 0.0734, 0.1920, 0.0623, 0.0632], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,401][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0114, 0.0123, 0.1147, 0.0312, 0.0842, 0.0587, 0.1289, 0.0903, 0.0784,
        0.0842, 0.0732, 0.0813, 0.1086, 0.0150, 0.0275], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,402][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0119, 0.0467, 0.0695, 0.0393, 0.0825, 0.0857, 0.1058, 0.0570, 0.0511,
        0.1137, 0.0394, 0.0803, 0.0974, 0.0391, 0.0805], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,402][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1302, 0.0891, 0.0438, 0.0527, 0.0404, 0.0485, 0.0478, 0.0514, 0.0547,
        0.0557, 0.0706, 0.0664, 0.0825, 0.0875, 0.0786], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,403][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0323, 0.0367, 0.0623, 0.0565, 0.0961, 0.0315, 0.0750, 0.0921, 0.0435,
        0.0728, 0.0746, 0.1109, 0.0545, 0.0827, 0.0374, 0.0410],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,404][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.7202e-01, 1.6404e-02, 2.1622e-08, 1.2731e-03, 7.7518e-09, 1.0228e-07,
        3.2308e-08, 8.2375e-06, 5.7165e-04, 3.8468e-04, 1.3351e-03, 1.0965e-06,
        2.3510e-05, 4.3402e-01, 2.6568e-02, 2.4738e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,407][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0249, 0.0233, 0.1155, 0.0608, 0.0256, 0.1009, 0.1009, 0.0502, 0.0301,
        0.1799, 0.0157, 0.0222, 0.1082, 0.0205, 0.1126, 0.0087],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,410][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0222, 0.0401, 0.0529, 0.0676, 0.1890, 0.0218, 0.0381, 0.0497, 0.3148,
        0.0179, 0.0141, 0.0762, 0.0460, 0.0117, 0.0214, 0.0164],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,413][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6831, 0.2266, 0.0324, 0.0279, 0.0055, 0.0048, 0.0018, 0.0035, 0.0019,
        0.0023, 0.0045, 0.0007, 0.0010, 0.0013, 0.0014, 0.0014],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,414][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0224, 0.0512, 0.0805, 0.0423, 0.0882, 0.0647, 0.0460, 0.0466, 0.0408,
        0.1267, 0.0728, 0.1189, 0.1051, 0.0297, 0.0444, 0.0196],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,414][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0148, 0.0047, 0.0088, 0.0333, 0.0444, 0.0592, 0.0434, 0.0676, 0.0744,
        0.0490, 0.1169, 0.1157, 0.0519, 0.1316, 0.0867, 0.0976],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,415][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0854, 0.0826, 0.1424, 0.0165, 0.0609, 0.0625, 0.0481, 0.0270, 0.0454,
        0.0977, 0.0105, 0.0644, 0.1010, 0.0172, 0.0712, 0.0672],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,415][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0515, 0.0395, 0.0328, 0.0321, 0.0419, 0.0580, 0.0773, 0.0754, 0.0352,
        0.0912, 0.0373, 0.0767, 0.1417, 0.0512, 0.1216, 0.0365],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,416][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0167, 0.0197, 0.0799, 0.0400, 0.0881, 0.0632, 0.1098, 0.0639, 0.0468,
        0.0944, 0.0712, 0.0827, 0.1072, 0.0214, 0.0655, 0.0295],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,416][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0131, 0.0437, 0.0705, 0.0392, 0.0799, 0.0840, 0.0947, 0.0564, 0.0518,
        0.1080, 0.0400, 0.0790, 0.0855, 0.0390, 0.0722, 0.0428],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,418][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1390, 0.0894, 0.0412, 0.0486, 0.0359, 0.0448, 0.0427, 0.0463, 0.0479,
        0.0480, 0.0624, 0.0578, 0.0752, 0.0764, 0.0680, 0.0763],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,420][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0226, 0.0304, 0.0630, 0.0466, 0.0740, 0.0387, 0.0600, 0.0792, 0.0401,
        0.0703, 0.0666, 0.0859, 0.0665, 0.0787, 0.0474, 0.0432, 0.0866],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,423][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([2.6956e-01, 3.0099e-02, 1.8778e-07, 2.5580e-03, 1.6367e-07, 1.0790e-06,
        7.7442e-07, 2.2799e-05, 6.6339e-04, 5.1167e-04, 1.8500e-03, 1.5158e-05,
        3.9917e-04, 3.6685e-01, 4.5605e-02, 2.2306e-01, 5.8808e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,427][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0119, 0.0147, 0.1668, 0.0371, 0.0462, 0.0751, 0.0770, 0.0363, 0.0310,
        0.1132, 0.0127, 0.0356, 0.1515, 0.0222, 0.1045, 0.0353, 0.0289],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,427][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0029, 0.0505, 0.1243, 0.0790, 0.1166, 0.0777, 0.0327, 0.0256, 0.1049,
        0.0157, 0.0118, 0.0629, 0.0576, 0.0172, 0.0520, 0.1660, 0.0027],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,428][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.6628, 0.2394, 0.0322, 0.0318, 0.0061, 0.0052, 0.0020, 0.0038, 0.0022,
        0.0025, 0.0047, 0.0008, 0.0011, 0.0014, 0.0016, 0.0015, 0.0009],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,428][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0222, 0.0602, 0.0720, 0.0400, 0.0857, 0.0588, 0.0474, 0.0634, 0.0377,
        0.0904, 0.0652, 0.1139, 0.0853, 0.0268, 0.0665, 0.0348, 0.0298],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,429][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0101, 0.0053, 0.0090, 0.0290, 0.0419, 0.0527, 0.0386, 0.0445, 0.0597,
        0.0494, 0.0938, 0.1081, 0.0328, 0.1197, 0.0828, 0.1039, 0.1185],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,429][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0706, 0.0942, 0.0916, 0.0264, 0.0491, 0.0571, 0.0447, 0.0292, 0.0445,
        0.1017, 0.0156, 0.0532, 0.0902, 0.0267, 0.0733, 0.0736, 0.0584],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,431][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0468, 0.0353, 0.0329, 0.0281, 0.0360, 0.0516, 0.0724, 0.0742, 0.0319,
        0.0603, 0.0319, 0.0677, 0.1706, 0.0513, 0.0876, 0.0469, 0.0745],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,433][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0024, 0.0043, 0.0948, 0.0245, 0.0772, 0.0674, 0.1186, 0.0682, 0.0677,
        0.0761, 0.0499, 0.0664, 0.1279, 0.0126, 0.0590, 0.0539, 0.0291],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,438][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0104, 0.0410, 0.0647, 0.0342, 0.0712, 0.0808, 0.0942, 0.0485, 0.0452,
        0.1033, 0.0346, 0.0702, 0.0830, 0.0329, 0.0736, 0.0382, 0.0739],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,440][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.1203, 0.0769, 0.0354, 0.0422, 0.0316, 0.0412, 0.0397, 0.0438, 0.0453,
        0.0452, 0.0591, 0.0559, 0.0731, 0.0749, 0.0655, 0.0746, 0.0752],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,440][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0298, 0.0332, 0.0499, 0.0461, 0.0705, 0.0409, 0.0711, 0.0844, 0.0345,
        0.0653, 0.0592, 0.0835, 0.0433, 0.0577, 0.0386, 0.0412, 0.0891, 0.0617],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,441][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.4191e-02, 2.3145e-02, 6.0105e-05, 6.9447e-03, 2.1363e-05, 9.2608e-05,
        5.2775e-05, 1.8886e-03, 2.0928e-02, 1.7082e-02, 1.9874e-02, 2.9610e-04,
        1.8483e-03, 2.3765e-01, 5.8706e-02, 3.2314e-01, 8.0676e-02, 1.1340e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,441][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0157, 0.0185, 0.0754, 0.0490, 0.0222, 0.1011, 0.1106, 0.0381, 0.0388,
        0.1291, 0.0121, 0.0189, 0.1456, 0.0068, 0.1096, 0.0420, 0.0618, 0.0048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,442][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0251, 0.0619, 0.0854, 0.0602, 0.1424, 0.0461, 0.0490, 0.0217, 0.2689,
        0.0077, 0.0230, 0.0476, 0.0201, 0.0011, 0.0193, 0.1136, 0.0057, 0.0011],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,442][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.5856, 0.2381, 0.0557, 0.0401, 0.0122, 0.0090, 0.0043, 0.0065, 0.0046,
        0.0065, 0.0093, 0.0023, 0.0023, 0.0028, 0.0036, 0.0036, 0.0025, 0.0110],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,443][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0229, 0.0474, 0.0897, 0.0426, 0.0894, 0.0587, 0.0435, 0.0437, 0.0369,
        0.1013, 0.0486, 0.1086, 0.0819, 0.0200, 0.0475, 0.0323, 0.0686, 0.0162],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,444][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0092, 0.0043, 0.0081, 0.0259, 0.0356, 0.0534, 0.0366, 0.0471, 0.0546,
        0.0338, 0.0883, 0.0882, 0.0380, 0.1073, 0.0758, 0.0746, 0.0995, 0.1197],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,447][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0754, 0.0695, 0.1325, 0.0112, 0.0493, 0.0552, 0.0438, 0.0217, 0.0384,
        0.0934, 0.0074, 0.0525, 0.1158, 0.0139, 0.0714, 0.0578, 0.0721, 0.0187],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,451][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0437, 0.0392, 0.0317, 0.0291, 0.0428, 0.0540, 0.0793, 0.0493, 0.0304,
        0.0604, 0.0320, 0.0682, 0.1360, 0.0301, 0.1084, 0.0474, 0.0874, 0.0306],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,453][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0113, 0.0123, 0.0920, 0.0288, 0.0767, 0.0577, 0.0946, 0.0438, 0.0694,
        0.0688, 0.0570, 0.0746, 0.0927, 0.0112, 0.0614, 0.0673, 0.0724, 0.0082],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,454][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0116, 0.0404, 0.0627, 0.0365, 0.0697, 0.0726, 0.0832, 0.0490, 0.0465,
        0.0963, 0.0359, 0.0691, 0.0790, 0.0365, 0.0681, 0.0394, 0.0717, 0.0317],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,454][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0984, 0.0696, 0.0385, 0.0435, 0.0355, 0.0402, 0.0398, 0.0423, 0.0439,
        0.0443, 0.0549, 0.0531, 0.0626, 0.0625, 0.0583, 0.0636, 0.0653, 0.0838],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,456][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:16,457][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 6062],
        [12603],
        [   63],
        [16559],
        [ 4463],
        [21543],
        [20273],
        [29419],
        [32387],
        [27841],
        [21305],
        [ 9506],
        [27878],
        [29607],
        [23707],
        [37882],
        [42246],
        [34415]], device='cuda:0')
[2024-07-24 10:30:16,460][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5552],
        [16233],
        [    9],
        [14518],
        [ 1654],
        [16173],
        [15794],
        [26383],
        [23490],
        [13459],
        [11615],
        [ 3673],
        [23776],
        [19974],
        [20701],
        [27750],
        [24822],
        [21145]], device='cuda:0')
[2024-07-24 10:30:16,463][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[34238],
        [30164],
        [28410],
        [27365],
        [27545],
        [26493],
        [24725],
        [25446],
        [26823],
        [26013],
        [27452],
        [26149],
        [24067],
        [25230],
        [23498],
        [25240],
        [25326],
        [25860]], device='cuda:0')
[2024-07-24 10:30:16,465][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38473],
        [40806],
        [40806],
        [40707],
        [38906],
        [37463],
        [36428],
        [36262],
        [36761],
        [33143],
        [35211],
        [32144],
        [32473],
        [36381],
        [32371],
        [32063],
        [32405],
        [35830]], device='cuda:0')
[2024-07-24 10:30:16,468][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3721],
        [17995],
        [24420],
        [23584],
        [24991],
        [24587],
        [24278],
        [24433],
        [26736],
        [33291],
        [24658],
        [25287],
        [18037],
        [25754],
        [25959],
        [29154],
        [27821],
        [28151]], device='cuda:0')
[2024-07-24 10:30:16,469][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11255],
        [11539],
        [11574],
        [11640],
        [11561],
        [11693],
        [11608],
        [11688],
        [11699],
        [12045],
        [11836],
        [11660],
        [12068],
        [11932],
        [12388],
        [12154],
        [12507],
        [13143]], device='cuda:0')
[2024-07-24 10:30:16,470][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[8337],
        [9386],
        [9191],
        [9131],
        [9079],
        [9058],
        [8938],
        [8980],
        [9023],
        [9042],
        [9186],
        [9157],
        [9050],
        [9079],
        [9321],
        [9133],
        [9133],
        [9438]], device='cuda:0')
[2024-07-24 10:30:16,471][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[34067],
        [41283],
        [45060],
        [44964],
        [47565],
        [47102],
        [47249],
        [46802],
        [46561],
        [47397],
        [47253],
        [47676],
        [47513],
        [47522],
        [47361],
        [47310],
        [47408],
        [47468]], device='cuda:0')
[2024-07-24 10:30:16,472][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11063],
        [22881],
        [22189],
        [23302],
        [20340],
        [22834],
        [24012],
        [23342],
        [23899],
        [24370],
        [25111],
        [22928],
        [23479],
        [23483],
        [24590],
        [23761],
        [23392],
        [22151]], device='cuda:0')
[2024-07-24 10:30:16,475][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[29152],
        [22217],
        [21765],
        [20961],
        [20280],
        [19206],
        [18227],
        [16955],
        [16410],
        [13258],
        [15380],
        [13436],
        [12648],
        [12136],
        [11180],
        [11243],
        [ 9610],
        [10177]], device='cuda:0')
[2024-07-24 10:30:16,477][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11566],
        [ 5461],
        [ 5448],
        [ 5461],
        [ 5104],
        [ 5422],
        [ 5381],
        [ 5309],
        [ 5247],
        [ 5339],
        [ 5106],
        [ 9005],
        [ 5344],
        [ 8097],
        [ 5456],
        [ 7711],
        [ 6238],
        [ 7673]], device='cuda:0')
[2024-07-24 10:30:16,480][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37991],
        [38000],
        [31505],
        [33650],
        [36349],
        [30269],
        [31490],
        [29185],
        [29079],
        [28003],
        [30035],
        [32086],
        [29121],
        [27281],
        [26185],
        [27752],
        [28174],
        [28681]], device='cuda:0')
[2024-07-24 10:30:16,483][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22102],
        [20844],
        [18824],
        [18363],
        [20664],
        [18507],
        [18960],
        [20319],
        [20947],
        [21007],
        [20672],
        [20644],
        [19905],
        [19683],
        [18682],
        [18568],
        [17603],
        [19426]], device='cuda:0')
[2024-07-24 10:30:16,484][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[32556],
        [33149],
        [37123],
        [38873],
        [39036],
        [38502],
        [36309],
        [36426],
        [36118],
        [35818],
        [35688],
        [35592],
        [35704],
        [34709],
        [34821],
        [33757],
        [33591],
        [32333]], device='cuda:0')
[2024-07-24 10:30:16,485][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5560],
        [ 2444],
        [  684],
        [ 1907],
        [  765],
        [ 1259],
        [  952],
        [ 2470],
        [  378],
        [ 5208],
        [ 2152],
        [  522],
        [ 1017],
        [ 1545],
        [ 1471],
        [ 1977],
        [15246],
        [ 2816]], device='cuda:0')
[2024-07-24 10:30:16,486][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 8157],
        [11980],
        [16846],
        [16378],
        [18976],
        [18989],
        [18002],
        [16505],
        [15765],
        [16150],
        [16722],
        [16878],
        [17253],
        [16784],
        [15852],
        [16160],
        [15097],
        [14850]], device='cuda:0')
[2024-07-24 10:30:16,488][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5083],
        [ 4951],
        [ 5013],
        [ 4939],
        [ 4438],
        [ 4933],
        [ 4886],
        [ 5046],
        [ 5066],
        [ 5051],
        [ 5914],
        [ 5232],
        [ 5120],
        [ 8362],
        [ 8955],
        [10736],
        [ 9394],
        [ 9937]], device='cuda:0')
[2024-07-24 10:30:16,490][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[16426],
        [23007],
        [22461],
        [26171],
        [26711],
        [25003],
        [20207],
        [21159],
        [21747],
        [21090],
        [19030],
        [19980],
        [20948],
        [19737],
        [18964],
        [16804],
        [16441],
        [16382]], device='cuda:0')
[2024-07-24 10:30:16,492][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1862],
        [ 1910],
        [10907],
        [20284],
        [30728],
        [27408],
        [25792],
        [22356],
        [34709],
        [14055],
        [19047],
        [24287],
        [18200],
        [14606],
        [10859],
        [11857],
        [ 6655],
        [ 6823]], device='cuda:0')
[2024-07-24 10:30:16,495][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13315],
        [14472],
        [14703],
        [15133],
        [14549],
        [14450],
        [14312],
        [14508],
        [14588],
        [14799],
        [15547],
        [15314],
        [14641],
        [14860],
        [15863],
        [15194],
        [15365],
        [16913]], device='cuda:0')
[2024-07-24 10:30:16,498][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5262],
        [5457],
        [5019],
        [5285],
        [4731],
        [4498],
        [4476],
        [4915],
        [5099],
        [5484],
        [5653],
        [5634],
        [5602],
        [5213],
        [5421],
        [5497],
        [5623],
        [5500]], device='cuda:0')
[2024-07-24 10:30:16,499][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 5563],
        [ 6231],
        [12126],
        [ 6140],
        [11730],
        [ 7355],
        [ 8392],
        [ 8888],
        [ 7341],
        [ 7878],
        [11324],
        [15598],
        [18371],
        [15521],
        [15329],
        [15499],
        [17154],
        [16877]], device='cuda:0')
[2024-07-24 10:30:16,500][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[19485],
        [12721],
        [11592],
        [10895],
        [14022],
        [14308],
        [13927],
        [14907],
        [15054],
        [15548],
        [15057],
        [16495],
        [17014],
        [16135],
        [16610],
        [15621],
        [14925],
        [13940]], device='cuda:0')
[2024-07-24 10:30:16,501][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[1996],
        [2398],
        [2629],
        [2851],
        [2861],
        [2850],
        [2759],
        [2794],
        [2945],
        [3101],
        [3023],
        [3107],
        [3111],
        [3088],
        [3322],
        [3592],
        [3481],
        [3520]], device='cuda:0')
[2024-07-24 10:30:16,502][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[15145],
        [16030],
        [17563],
        [17890],
        [19366],
        [19401],
        [20951],
        [21621],
        [22238],
        [23151],
        [22571],
        [22957],
        [22399],
        [22212],
        [22035],
        [21787],
        [22122],
        [21878]], device='cuda:0')
[2024-07-24 10:30:16,505][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13895],
        [19167],
        [20444],
        [19705],
        [18931],
        [19898],
        [19174],
        [18555],
        [18226],
        [18436],
        [18637],
        [18575],
        [19510],
        [19406],
        [19083],
        [18796],
        [18800],
        [18698]], device='cuda:0')
[2024-07-24 10:30:16,507][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22133],
        [25697],
        [24945],
        [26428],
        [26085],
        [26719],
        [27554],
        [29229],
        [30158],
        [30828],
        [31817],
        [32198],
        [32300],
        [33012],
        [33325],
        [33719],
        [34036],
        [34208]], device='cuda:0')
[2024-07-24 10:30:16,510][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21373],
        [19398],
        [15676],
        [16400],
        [14863],
        [15512],
        [15690],
        [15241],
        [14253],
        [15561],
        [14291],
        [12534],
        [13109],
        [13414],
        [13278],
        [13038],
        [13978],
        [14088]], device='cuda:0')
[2024-07-24 10:30:16,512][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31657],
        [18191],
        [29019],
        [11872],
        [18499],
        [11687],
        [11677],
        [ 7325],
        [17335],
        [ 5462],
        [ 8405],
        [22729],
        [11391],
        [ 6935],
        [ 6629],
        [ 4853],
        [ 2141],
        [ 6527]], device='cuda:0')
[2024-07-24 10:30:16,514][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473],
        [29473]], device='cuda:0')
[2024-07-24 10:30:16,547][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:16,550][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,550][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,551][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,551][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,551][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,552][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,552][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,552][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,553][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,553][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,554][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,557][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,559][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8504, 0.1496], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,563][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5316, 0.4684], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,564][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0022, 0.9978], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,564][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.7361e-15, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,564][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9627, 0.0373], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,565][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8270, 0.1730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,565][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4652, 0.5348], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,565][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([2.1492e-04, 9.9979e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,566][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7183, 0.2817], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,567][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5275, 0.4725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,570][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8800, 0.1200], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,574][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9603, 0.0397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,576][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([9.9732e-01, 2.3242e-03, 3.5237e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,576][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.4703, 0.3299, 0.1997], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,577][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([8.3730e-05, 8.4203e-01, 1.5788e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,577][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([1.7959e-17, 9.3776e-01, 6.2242e-02], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,577][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.6792, 0.3094, 0.0113], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,578][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.1566, 0.4071, 0.4363], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,578][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.2724, 0.4155, 0.3121], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,579][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([3.7588e-03, 9.9566e-01, 5.7630e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,579][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.5786, 0.2171, 0.2042], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,581][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.2702, 0.2272, 0.5026], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,583][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.0854, 0.4485, 0.4661], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,587][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.8633, 0.1161, 0.0206], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,589][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2842, 0.0756, 0.0881, 0.5521], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,590][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2601, 0.2232, 0.2618, 0.2549], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,590][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([3.6376e-07, 8.0153e-01, 1.9662e-01, 1.8528e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,590][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([4.0147e-17, 9.5271e-03, 7.7250e-04, 9.8970e-01], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,591][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8624, 0.1077, 0.0024, 0.0275], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,591][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3900, 0.1109, 0.2108, 0.2883], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,591][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2155, 0.3033, 0.2540, 0.2272], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,592][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0131, 0.6071, 0.0963, 0.2835], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,593][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4348, 0.1626, 0.1827, 0.2199], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,596][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2197, 0.1906, 0.3468, 0.2429], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,600][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2389, 0.3595, 0.0970, 0.3046], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,602][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9041, 0.0619, 0.0134, 0.0206], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,603][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.5288e-01, 3.9436e-03, 6.0593e-04, 4.2283e-02, 2.8896e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,603][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.3015, 0.2155, 0.1498, 0.1996, 0.1336], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,603][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([3.2539e-06, 7.7115e-01, 1.9195e-01, 7.5720e-03, 2.9326e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,604][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([4.3598e-18, 8.6122e-03, 6.8682e-04, 9.8671e-01, 3.9908e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,604][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.3375, 0.5362, 0.0353, 0.0606, 0.0304], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,604][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.1075, 0.1764, 0.2663, 0.2171, 0.2327], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,605][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.1562, 0.2427, 0.2098, 0.1968, 0.1945], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,605][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0116, 0.5032, 0.0060, 0.4410, 0.0382], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,607][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.3399, 0.1241, 0.1373, 0.1808, 0.2179], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,609][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.1582, 0.1330, 0.2651, 0.1791, 0.2646], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,613][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0845, 0.2529, 0.2033, 0.2803, 0.1789], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,615][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.8393, 0.0862, 0.0173, 0.0323, 0.0249], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,616][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.9110, 0.0108, 0.0061, 0.0673, 0.0012, 0.0036], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,616][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.2452, 0.1793, 0.1381, 0.1710, 0.1248, 0.1417], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,617][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ were] are: tensor([5.2707e-07, 5.5363e-01, 1.4238e-01, 7.3381e-04, 4.5463e-03, 2.9871e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,617][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ were] are: tensor([8.6390e-21, 4.5390e-03, 4.7556e-04, 9.8895e-01, 6.0272e-03, 1.2262e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,617][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.7916, 0.1632, 0.0082, 0.0172, 0.0119, 0.0080], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,618][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.1973, 0.0759, 0.1496, 0.2112, 0.2163, 0.1498], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,619][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.1433, 0.2127, 0.1699, 0.1721, 0.1861, 0.1159], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,622][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0034, 0.2848, 0.0167, 0.2843, 0.4036, 0.0072], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,626][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.2833, 0.1002, 0.1089, 0.1445, 0.1687, 0.1944], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,628][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.1477, 0.1254, 0.2056, 0.1502, 0.2130, 0.1582], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,629][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.1612, 0.2818, 0.0620, 0.1372, 0.0542, 0.3035], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,629][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.8232, 0.0905, 0.0176, 0.0276, 0.0247, 0.0165], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,629][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.8875, 0.0143, 0.0089, 0.0798, 0.0016, 0.0038, 0.0040],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,630][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.1913, 0.1517, 0.1271, 0.1521, 0.1173, 0.1351, 0.1252],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,630][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ working] are: tensor([1.9616e-06, 2.9097e-01, 3.2325e-02, 2.8620e-04, 7.2351e-04, 6.6563e-01,
        1.0068e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,630][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ working] are: tensor([3.7317e-16, 4.0524e-04, 3.2431e-05, 4.2662e-02, 5.2475e-04, 1.1569e-06,
        9.5637e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,631][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.4857, 0.2502, 0.0333, 0.1146, 0.0177, 0.0690, 0.0295],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,632][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.1980, 0.0890, 0.1070, 0.1525, 0.1780, 0.1274, 0.1480],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,635][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.1198, 0.1764, 0.1513, 0.1596, 0.1828, 0.1266, 0.0835],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,638][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0041, 0.4125, 0.0080, 0.3308, 0.1842, 0.0527, 0.0075],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,642][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.2206, 0.0804, 0.0808, 0.1052, 0.1262, 0.1604, 0.2264],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,642][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.1311, 0.1084, 0.1750, 0.1344, 0.1780, 0.1387, 0.1346],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,642][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.1270, 0.2845, 0.0319, 0.1343, 0.0196, 0.1310, 0.2717],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,643][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.7727, 0.0945, 0.0214, 0.0347, 0.0319, 0.0236, 0.0212],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,643][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.8520, 0.0245, 0.0128, 0.0553, 0.0027, 0.0019, 0.0014, 0.0494],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,644][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1784, 0.1368, 0.1131, 0.1373, 0.1030, 0.1207, 0.1102, 0.1006],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,644][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.5475e-07, 2.3019e-01, 1.0996e-01, 6.9272e-04, 5.8159e-04, 5.6113e-01,
        9.6819e-02, 6.2619e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,645][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([3.6138e-20, 3.2552e-04, 3.5923e-05, 4.6971e-02, 2.3723e-04, 4.5799e-07,
        9.5239e-01, 3.6186e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,648][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.8324, 0.0947, 0.0082, 0.0121, 0.0069, 0.0112, 0.0107, 0.0237],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,650][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.3852, 0.0541, 0.0725, 0.0750, 0.1767, 0.0719, 0.1147, 0.0499],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,654][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1171, 0.1654, 0.1310, 0.1360, 0.1513, 0.1126, 0.0813, 0.1053],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,655][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0011, 0.0312, 0.0057, 0.0588, 0.6795, 0.0217, 0.2008, 0.0012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,655][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1538, 0.0514, 0.0548, 0.0739, 0.0950, 0.1205, 0.1767, 0.2740],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,655][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1124, 0.0905, 0.1607, 0.1146, 0.1571, 0.1245, 0.1206, 0.1195],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,656][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1596, 0.1788, 0.0394, 0.0703, 0.0224, 0.1418, 0.1263, 0.2613],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,656][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.8557, 0.0505, 0.0135, 0.0196, 0.0200, 0.0131, 0.0117, 0.0159],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,657][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.7046, 0.0400, 0.0102, 0.1117, 0.0051, 0.0100, 0.0074, 0.0925, 0.0183],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,657][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1584, 0.1232, 0.0964, 0.1169, 0.0922, 0.1032, 0.0979, 0.0881, 0.1237],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,658][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.2708e-08, 1.3479e-01, 3.4087e-02, 1.0679e-04, 5.1626e-04, 7.2905e-01,
        6.3947e-02, 3.1072e-03, 3.4396e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,659][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([5.3839e-20, 6.9177e-03, 6.1989e-05, 9.8689e-01, 3.1235e-03, 9.3788e-08,
        2.9259e-03, 8.4446e-05, 4.1902e-08], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,663][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7999, 0.1200, 0.0063, 0.0092, 0.0052, 0.0087, 0.0074, 0.0120, 0.0313],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,666][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.4242, 0.0474, 0.0446, 0.0551, 0.0998, 0.0828, 0.1107, 0.0857, 0.0499],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,668][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1031, 0.1528, 0.1176, 0.1247, 0.1220, 0.0961, 0.0734, 0.1027, 0.1075],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,668][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0010, 0.1870, 0.0099, 0.1784, 0.3599, 0.0253, 0.1995, 0.0176, 0.0214],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,668][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1146, 0.0426, 0.0487, 0.0616, 0.0753, 0.0942, 0.1471, 0.2308, 0.1853],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,669][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1007, 0.0781, 0.1440, 0.0973, 0.1355, 0.1072, 0.1024, 0.1021, 0.1327],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,669][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1587, 0.0937, 0.0109, 0.0326, 0.0107, 0.1067, 0.1298, 0.1401, 0.3168],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,670][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.8483, 0.0566, 0.0129, 0.0192, 0.0166, 0.0102, 0.0087, 0.0124, 0.0151],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,670][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.8114, 0.0179, 0.0028, 0.0651, 0.0011, 0.0020, 0.0021, 0.0712, 0.0066,
        0.0198], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,672][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.1485, 0.1143, 0.0857, 0.1064, 0.0804, 0.0904, 0.0861, 0.0770, 0.1089,
        0.1022], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,674][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ station] are: tensor([1.3796e-06, 4.4747e-01, 8.0239e-03, 2.3563e-04, 7.9440e-05, 4.1880e-01,
        2.2710e-02, 4.6419e-03, 1.4707e-02, 8.3336e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,676][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.2887e-17, 1.5728e-02, 4.9576e-05, 9.8140e-01, 2.4687e-03, 1.3671e-07,
        2.8620e-04, 6.1476e-05, 1.3559e-06, 1.3361e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,679][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.6418, 0.1382, 0.0156, 0.0184, 0.0087, 0.0361, 0.0223, 0.0334, 0.0671,
        0.0183], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,680][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.4060, 0.0637, 0.0342, 0.0623, 0.0883, 0.0812, 0.1011, 0.0697, 0.0590,
        0.0346], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,681][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0762, 0.1225, 0.1106, 0.1124, 0.1227, 0.0923, 0.0715, 0.1076, 0.1040,
        0.0802], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,681][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ station] are: tensor([3.6772e-03, 4.8146e-01, 3.5901e-03, 1.6851e-01, 2.0205e-01, 3.5204e-02,
        1.0089e-02, 7.5738e-02, 1.9399e-02, 2.7539e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,682][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0897, 0.0337, 0.0399, 0.0543, 0.0671, 0.0785, 0.1171, 0.1970, 0.1563,
        0.1663], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,682][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0895, 0.0724, 0.1290, 0.0910, 0.1229, 0.0949, 0.0929, 0.0910, 0.1090,
        0.1075], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,683][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.2496, 0.1135, 0.0051, 0.0253, 0.0076, 0.0716, 0.0921, 0.1184, 0.1084,
        0.2085], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,683][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.7974, 0.0582, 0.0132, 0.0251, 0.0201, 0.0148, 0.0128, 0.0204, 0.0229,
        0.0152], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,684][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.3833, 0.0530, 0.0069, 0.2193, 0.0116, 0.0190, 0.0227, 0.0536, 0.0372,
        0.0826, 0.1106], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,687][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0977, 0.0840, 0.0904, 0.0914, 0.0809, 0.0915, 0.0862, 0.0778, 0.1051,
        0.1027, 0.0922], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,689][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([1.9212e-06, 1.9329e-01, 7.7970e-03, 4.4422e-05, 7.8444e-05, 2.7253e-01,
        1.2712e-02, 7.5810e-04, 1.6995e-02, 4.7979e-02, 4.4782e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,691][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([3.5547e-17, 1.3591e-02, 1.9765e-04, 9.7805e-01, 5.4929e-03, 2.9049e-07,
        2.5752e-03, 9.2183e-05, 3.8128e-08, 2.6668e-09, 6.0867e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,694][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.9083, 0.0381, 0.0013, 0.0026, 0.0016, 0.0024, 0.0020, 0.0061, 0.0102,
        0.0060, 0.0214], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,694][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.3311, 0.0387, 0.0598, 0.0571, 0.1504, 0.0671, 0.0813, 0.0687, 0.0260,
        0.0309, 0.0888], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,694][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0915, 0.1246, 0.0881, 0.1003, 0.1034, 0.0747, 0.0498, 0.0856, 0.1068,
        0.0798, 0.0954], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,695][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0014, 0.0803, 0.0057, 0.1016, 0.3996, 0.0205, 0.0691, 0.0157, 0.2668,
        0.0080, 0.0313], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,695][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0791, 0.0306, 0.0384, 0.0447, 0.0584, 0.0664, 0.1027, 0.1679, 0.1387,
        0.1565, 0.1167], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,696][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0869, 0.0680, 0.1175, 0.0780, 0.1068, 0.0856, 0.0769, 0.0736, 0.0939,
        0.0910, 0.1219], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,697][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1445, 0.0819, 0.0231, 0.0323, 0.0192, 0.0699, 0.0902, 0.0800, 0.2083,
        0.1110, 0.1395], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,700][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.8227, 0.0529, 0.0132, 0.0212, 0.0174, 0.0111, 0.0099, 0.0135, 0.0152,
        0.0112, 0.0117], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,704][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.5118, 0.0197, 0.0012, 0.1587, 0.0015, 0.0059, 0.0036, 0.1294, 0.0241,
        0.0229, 0.1199, 0.0012], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,706][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.1337, 0.1001, 0.0743, 0.0949, 0.0650, 0.0771, 0.0728, 0.0657, 0.0911,
        0.0846, 0.0896, 0.0510], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,707][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([1.0063e-05, 7.6002e-02, 2.1151e-03, 8.1983e-05, 4.8560e-05, 7.1810e-02,
        2.2430e-02, 1.9406e-03, 8.1887e-03, 2.1481e-01, 6.0093e-01, 1.6287e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,707][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([1.3529e-15, 2.2732e-02, 2.2311e-04, 9.6799e-01, 3.9325e-03, 3.9851e-07,
        4.9839e-03, 1.0763e-04, 1.6405e-08, 2.3989e-09, 8.3189e-07, 2.9741e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,708][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.1424, 0.3663, 0.0201, 0.0081, 0.0114, 0.0124, 0.0094, 0.0672, 0.0643,
        0.0285, 0.1961, 0.0737], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,708][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.2672, 0.0479, 0.0537, 0.0458, 0.0696, 0.0476, 0.0682, 0.0723, 0.0409,
        0.0640, 0.1220, 0.1008], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,708][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0667, 0.1056, 0.0935, 0.0887, 0.0900, 0.0771, 0.0662, 0.0835, 0.0793,
        0.0725, 0.0976, 0.0794], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,709][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0022, 0.1624, 0.0017, 0.1920, 0.0102, 0.0691, 0.0560, 0.1978, 0.1160,
        0.0220, 0.1607, 0.0100], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,710][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0818, 0.0326, 0.0334, 0.0402, 0.0489, 0.0629, 0.0937, 0.1421, 0.1139,
        0.1161, 0.1025, 0.1318], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,713][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0644, 0.0550, 0.1015, 0.0719, 0.0980, 0.0770, 0.0745, 0.0721, 0.0884,
        0.0857, 0.1107, 0.1008], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,716][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0575, 0.1123, 0.0298, 0.0413, 0.0109, 0.0496, 0.0464, 0.1152, 0.2149,
        0.1222, 0.1420, 0.0580], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,720][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.8110, 0.0480, 0.0101, 0.0212, 0.0147, 0.0119, 0.0118, 0.0165, 0.0175,
        0.0129, 0.0139, 0.0104], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,720][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.6604, 0.0288, 0.0034, 0.0844, 0.0023, 0.0060, 0.0048, 0.0670, 0.0164,
        0.0284, 0.0829, 0.0020, 0.0132], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,720][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.1098, 0.0866, 0.0673, 0.0845, 0.0632, 0.0724, 0.0693, 0.0617, 0.0863,
        0.0815, 0.0838, 0.0519, 0.0817], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,721][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([7.7554e-06, 2.9652e-02, 1.7124e-03, 6.0132e-06, 5.1766e-05, 2.4125e-02,
        3.2003e-03, 2.0034e-04, 1.2691e-03, 5.2573e-03, 2.8847e-02, 5.3571e-04,
        9.0514e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,721][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([5.4897e-17, 1.1251e-02, 1.8720e-04, 9.6028e-01, 7.8302e-03, 5.0142e-07,
        1.5022e-02, 2.6974e-04, 2.9919e-06, 1.0894e-06, 6.9290e-05, 5.0723e-03,
        1.0506e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,722][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.4981, 0.0974, 0.0084, 0.0086, 0.0126, 0.0091, 0.0183, 0.0241, 0.0464,
        0.1119, 0.0875, 0.0673, 0.0102], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,724][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.2237, 0.0351, 0.0523, 0.0421, 0.0925, 0.0438, 0.0547, 0.0759, 0.0393,
        0.0379, 0.1066, 0.1166, 0.0796], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,726][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0636, 0.0893, 0.0899, 0.0755, 0.1073, 0.0605, 0.0522, 0.0726, 0.0832,
        0.0753, 0.0764, 0.1020, 0.0521], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,730][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0008, 0.1758, 0.0057, 0.2246, 0.0424, 0.0119, 0.0105, 0.1185, 0.1213,
        0.0064, 0.2427, 0.0388, 0.0006], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,732][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0801, 0.0320, 0.0314, 0.0385, 0.0466, 0.0551, 0.0846, 0.1281, 0.1023,
        0.1043, 0.0925, 0.1217, 0.0828], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,733][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0692, 0.0567, 0.0945, 0.0664, 0.0877, 0.0684, 0.0645, 0.0631, 0.0787,
        0.0778, 0.0996, 0.0917, 0.0818], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,733][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0793, 0.0734, 0.0104, 0.0281, 0.0104, 0.0597, 0.0701, 0.0745, 0.1517,
        0.1328, 0.0806, 0.0588, 0.1701], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,734][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.7425, 0.0626, 0.0143, 0.0276, 0.0207, 0.0164, 0.0145, 0.0212, 0.0223,
        0.0153, 0.0172, 0.0127, 0.0127], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,734][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4327, 0.0389, 0.0055, 0.1108, 0.0062, 0.0131, 0.0112, 0.1130, 0.0275,
        0.0554, 0.1059, 0.0078, 0.0255, 0.0465], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,735][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0857, 0.0717, 0.0700, 0.0743, 0.0621, 0.0705, 0.0679, 0.0607, 0.0826,
        0.0803, 0.0747, 0.0501, 0.0793, 0.0702], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,735][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.8821e-08, 1.5561e-02, 1.6911e-03, 3.0492e-05, 1.1505e-05, 3.3009e-02,
        1.7176e-03, 1.5429e-04, 5.3092e-03, 8.1906e-03, 2.1766e-01, 1.2752e-04,
        7.1610e-01, 4.3680e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,736][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.2113e-18, 6.5574e-03, 1.7640e-04, 8.6837e-01, 1.9215e-03, 6.1671e-07,
        1.2277e-01, 1.6384e-04, 2.5396e-10, 1.7107e-11, 3.7242e-09, 2.1116e-07,
        2.5295e-08, 3.1245e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,738][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8182, 0.0576, 0.0036, 0.0045, 0.0020, 0.0054, 0.0054, 0.0076, 0.0191,
        0.0127, 0.0277, 0.0068, 0.0078, 0.0216], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,741][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3311, 0.0367, 0.0381, 0.0376, 0.0844, 0.0450, 0.0493, 0.0421, 0.0230,
        0.0206, 0.0798, 0.0882, 0.0712, 0.0529], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,745][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0607, 0.0903, 0.0755, 0.0778, 0.0896, 0.0622, 0.0505, 0.0665, 0.0773,
        0.0732, 0.0763, 0.0851, 0.0637, 0.0514], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,746][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0013, 0.0895, 0.0043, 0.1014, 0.1577, 0.0160, 0.0727, 0.0118, 0.1781,
        0.0153, 0.1035, 0.1700, 0.0293, 0.0491], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,746][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0670, 0.0241, 0.0257, 0.0326, 0.0390, 0.0488, 0.0730, 0.1130, 0.0926,
        0.0932, 0.0917, 0.1083, 0.0775, 0.1134], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,747][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0642, 0.0512, 0.0902, 0.0587, 0.0823, 0.0634, 0.0579, 0.0564, 0.0729,
        0.0711, 0.0960, 0.0848, 0.0778, 0.0730], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,747][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2281, 0.0621, 0.0127, 0.0261, 0.0063, 0.0410, 0.0511, 0.0573, 0.0889,
        0.0538, 0.0802, 0.0159, 0.0786, 0.1979], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,748][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.8349, 0.0372, 0.0080, 0.0152, 0.0127, 0.0088, 0.0090, 0.0125, 0.0125,
        0.0106, 0.0118, 0.0083, 0.0078, 0.0107], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:16,748][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.6684, 0.0315, 0.0010, 0.1081, 0.0012, 0.0022, 0.0020, 0.0238, 0.0096,
        0.0168, 0.1033, 0.0019, 0.0068, 0.0116, 0.0117], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,750][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1103, 0.0816, 0.0586, 0.0760, 0.0530, 0.0619, 0.0574, 0.0524, 0.0740,
        0.0696, 0.0745, 0.0427, 0.0717, 0.0698, 0.0465], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,752][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([9.0628e-08, 2.3881e-02, 8.6993e-04, 9.5328e-06, 1.4579e-05, 1.8470e-02,
        2.1116e-03, 2.7414e-04, 1.8222e-03, 5.9347e-03, 9.9232e-02, 1.7058e-04,
        8.4287e-01, 1.3117e-03, 3.0265e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,754][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([2.7001e-16, 1.4925e-02, 1.6445e-04, 9.7348e-01, 2.9626e-03, 2.3640e-07,
        7.6685e-03, 8.6572e-05, 4.1338e-09, 3.9599e-10, 1.3259e-07, 6.3989e-06,
        7.2323e-08, 6.7386e-04, 3.6447e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,757][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.6548, 0.0471, 0.0024, 0.0062, 0.0021, 0.0128, 0.0133, 0.0108, 0.0346,
        0.0317, 0.0481, 0.0076, 0.0307, 0.0585, 0.0392], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,759][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.2998, 0.0396, 0.0393, 0.0477, 0.0642, 0.0422, 0.0492, 0.0553, 0.0244,
        0.0324, 0.0759, 0.0630, 0.0795, 0.0731, 0.0145], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,759][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0562, 0.0841, 0.0693, 0.0759, 0.0823, 0.0564, 0.0464, 0.0752, 0.0773,
        0.0667, 0.0758, 0.0784, 0.0566, 0.0583, 0.0410], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,759][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0009, 0.2983, 0.0052, 0.1047, 0.0643, 0.0262, 0.0234, 0.0298, 0.0683,
        0.0048, 0.1853, 0.0635, 0.0052, 0.1196, 0.0006], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,760][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0698, 0.0273, 0.0247, 0.0317, 0.0364, 0.0456, 0.0678, 0.1015, 0.0821,
        0.0869, 0.0792, 0.0955, 0.0688, 0.1084, 0.0744], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,760][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0571, 0.0475, 0.0792, 0.0558, 0.0717, 0.0587, 0.0559, 0.0544, 0.0692,
        0.0678, 0.0881, 0.0759, 0.0714, 0.0691, 0.0781], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,761][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0935, 0.0509, 0.0079, 0.0146, 0.0047, 0.0306, 0.0437, 0.0463, 0.0766,
        0.0526, 0.0575, 0.0142, 0.0585, 0.1767, 0.2715], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,761][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.7413, 0.0607, 0.0131, 0.0245, 0.0184, 0.0143, 0.0117, 0.0171, 0.0187,
        0.0135, 0.0154, 0.0110, 0.0107, 0.0211, 0.0084], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:16,763][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6080, 0.0296, 0.0016, 0.0879, 0.0022, 0.0062, 0.0053, 0.0468, 0.0191,
        0.0278, 0.0996, 0.0035, 0.0129, 0.0220, 0.0172, 0.0103],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,766][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0920, 0.0738, 0.0534, 0.0697, 0.0515, 0.0595, 0.0565, 0.0500, 0.0710,
        0.0663, 0.0701, 0.0407, 0.0686, 0.0653, 0.0450, 0.0666],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,768][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.1805e-09, 2.4591e-03, 4.8208e-04, 6.9012e-06, 3.0435e-05, 1.4299e-02,
        2.5189e-03, 1.4674e-04, 3.8217e-03, 1.4792e-02, 1.4329e-01, 2.0769e-03,
        7.9237e-01, 1.1812e-03, 2.2416e-02, 1.0388e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,770][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.4806e-08, 3.4694e-04, 2.0195e-06, 1.9516e-03, 1.8457e-06, 4.8030e-10,
        9.0825e-07, 5.3138e-08, 2.2527e-16, 6.3068e-18, 2.8764e-14, 3.2259e-13,
        3.9437e-15, 6.9736e-09, 1.3299e-11, 9.9770e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,772][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7217, 0.0841, 0.0049, 0.0037, 0.0026, 0.0042, 0.0064, 0.0100, 0.0188,
        0.0166, 0.0354, 0.0103, 0.0067, 0.0253, 0.0220, 0.0273],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,772][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2658, 0.0208, 0.0187, 0.0198, 0.0512, 0.0361, 0.0479, 0.0421, 0.0322,
        0.0256, 0.0821, 0.1455, 0.0856, 0.0692, 0.0301, 0.0273],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,773][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0594, 0.0862, 0.0657, 0.0757, 0.0673, 0.0624, 0.0428, 0.0583, 0.0643,
        0.0637, 0.0778, 0.0638, 0.0578, 0.0543, 0.0466, 0.0538],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,773][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0004, 0.0897, 0.0021, 0.0596, 0.0934, 0.0082, 0.1204, 0.0174, 0.0559,
        0.0277, 0.2045, 0.1219, 0.0391, 0.1284, 0.0268, 0.0045],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,774][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0604, 0.0240, 0.0237, 0.0294, 0.0332, 0.0432, 0.0647, 0.0931, 0.0748,
        0.0806, 0.0734, 0.0854, 0.0645, 0.0980, 0.0716, 0.0800],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,774][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0548, 0.0447, 0.0748, 0.0519, 0.0695, 0.0553, 0.0516, 0.0500, 0.0626,
        0.0623, 0.0804, 0.0717, 0.0663, 0.0626, 0.0718, 0.0698],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,776][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1091, 0.0424, 0.0041, 0.0107, 0.0021, 0.0152, 0.0288, 0.0325, 0.0554,
        0.0437, 0.0353, 0.0086, 0.0421, 0.1567, 0.1856, 0.2276],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,780][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.7601, 0.0633, 0.0120, 0.0218, 0.0154, 0.0106, 0.0092, 0.0135, 0.0152,
        0.0123, 0.0140, 0.0101, 0.0098, 0.0177, 0.0075, 0.0077],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:16,782][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.6777, 0.0254, 0.0015, 0.0844, 0.0019, 0.0042, 0.0036, 0.0437, 0.0115,
        0.0201, 0.0704, 0.0024, 0.0087, 0.0149, 0.0127, 0.0066, 0.0104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,786][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0842, 0.0701, 0.0485, 0.0673, 0.0479, 0.0556, 0.0543, 0.0478, 0.0667,
        0.0604, 0.0666, 0.0382, 0.0638, 0.0634, 0.0433, 0.0621, 0.0595],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,787][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([3.6356e-06, 4.9560e-02, 5.9014e-04, 7.0949e-05, 2.3459e-05, 2.4101e-02,
        4.5262e-03, 1.3407e-03, 2.5191e-03, 2.2575e-02, 7.6913e-02, 5.1688e-04,
        7.3716e-01, 6.9792e-03, 7.0982e-02, 8.3128e-04, 1.3045e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,787][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([2.7260e-08, 1.1571e-07, 7.2580e-10, 2.5851e-07, 1.0146e-09, 2.2440e-13,
        4.1357e-11, 2.0750e-11, 3.2179e-17, 8.7068e-18, 5.5664e-15, 5.8988e-14,
        1.2500e-16, 5.6852e-11, 9.7203e-13, 9.6817e-01, 3.1827e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,788][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.3691, 0.0832, 0.0118, 0.0101, 0.0104, 0.0163, 0.0150, 0.0214, 0.0502,
        0.0377, 0.0808, 0.0444, 0.0435, 0.0521, 0.1061, 0.0365, 0.0114],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,788][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.1880, 0.0280, 0.0149, 0.0267, 0.0384, 0.0356, 0.0428, 0.0379, 0.0415,
        0.0310, 0.0901, 0.1062, 0.0738, 0.0946, 0.0346, 0.0496, 0.0663],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,789][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0460, 0.0701, 0.0699, 0.0655, 0.0786, 0.0589, 0.0408, 0.0608, 0.0653,
        0.0591, 0.0632, 0.0734, 0.0512, 0.0479, 0.0416, 0.0543, 0.0535],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,789][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0016, 0.0793, 0.0052, 0.1520, 0.0584, 0.0189, 0.0132, 0.1243, 0.0289,
        0.0045, 0.1507, 0.0436, 0.0060, 0.1523, 0.0179, 0.1417, 0.0015],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,791][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0503, 0.0193, 0.0196, 0.0251, 0.0295, 0.0388, 0.0558, 0.0842, 0.0659,
        0.0674, 0.0671, 0.0803, 0.0611, 0.0940, 0.0687, 0.0760, 0.0969],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,794][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0504, 0.0406, 0.0669, 0.0488, 0.0636, 0.0511, 0.0490, 0.0468, 0.0577,
        0.0557, 0.0746, 0.0664, 0.0620, 0.0575, 0.0691, 0.0650, 0.0750],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,797][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.1372, 0.0337, 0.0035, 0.0081, 0.0019, 0.0159, 0.0167, 0.0308, 0.0347,
        0.0440, 0.0268, 0.0073, 0.0301, 0.1513, 0.1673, 0.1399, 0.1508],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,800][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.6772, 0.0598, 0.0135, 0.0288, 0.0206, 0.0168, 0.0151, 0.0235, 0.0219,
        0.0164, 0.0184, 0.0127, 0.0130, 0.0239, 0.0113, 0.0113, 0.0158],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:16,800][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5001, 0.0237, 0.0016, 0.0720, 0.0022, 0.0065, 0.0055, 0.0898, 0.0195,
        0.0343, 0.1038, 0.0039, 0.0195, 0.0388, 0.0249, 0.0140, 0.0225, 0.0172],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,801][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0671, 0.0580, 0.0521, 0.0595, 0.0477, 0.0544, 0.0533, 0.0467, 0.0640,
        0.0607, 0.0591, 0.0377, 0.0615, 0.0546, 0.0414, 0.0595, 0.0590, 0.0640],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,801][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.0548e-10, 1.1828e-03, 4.7663e-04, 2.6594e-05, 9.7726e-06, 1.1383e-02,
        1.8361e-03, 1.0064e-04, 3.9326e-03, 2.3676e-02, 2.8054e-01, 4.0885e-04,
        6.4752e-01, 6.3501e-04, 2.7788e-02, 3.2866e-04, 1.4711e-04, 1.0843e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,802][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.3394e-07, 1.0825e-06, 7.4133e-09, 2.0344e-06, 2.9019e-09, 9.2876e-13,
        1.1485e-10, 5.3509e-11, 1.3149e-19, 6.6749e-21, 2.7490e-17, 2.2739e-16,
        1.4137e-18, 4.9790e-12, 9.6045e-15, 2.0577e-03, 6.1009e-05, 9.9788e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,802][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8373, 0.0545, 0.0024, 0.0026, 0.0013, 0.0034, 0.0028, 0.0047, 0.0112,
        0.0078, 0.0192, 0.0040, 0.0038, 0.0126, 0.0115, 0.0093, 0.0035, 0.0081],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,803][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3118, 0.0222, 0.0221, 0.0198, 0.0502, 0.0354, 0.0471, 0.0394, 0.0334,
        0.0237, 0.0728, 0.0949, 0.0612, 0.0522, 0.0209, 0.0268, 0.0473, 0.0187],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,804][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0473, 0.0729, 0.0616, 0.0633, 0.0723, 0.0513, 0.0404, 0.0540, 0.0616,
        0.0601, 0.0616, 0.0676, 0.0509, 0.0411, 0.0386, 0.0548, 0.0573, 0.0433],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,807][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0006, 0.0421, 0.0032, 0.0646, 0.1204, 0.0110, 0.0628, 0.0072, 0.1430,
        0.0138, 0.0759, 0.1395, 0.0205, 0.0343, 0.0296, 0.1165, 0.0776, 0.0375],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,811][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0471, 0.0191, 0.0194, 0.0236, 0.0264, 0.0360, 0.0512, 0.0720, 0.0645,
        0.0653, 0.0634, 0.0725, 0.0554, 0.0817, 0.0661, 0.0737, 0.0862, 0.0764],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,813][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0489, 0.0397, 0.0667, 0.0452, 0.0623, 0.0487, 0.0451, 0.0431, 0.0531,
        0.0528, 0.0692, 0.0632, 0.0582, 0.0537, 0.0619, 0.0594, 0.0691, 0.0597],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,813][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1756, 0.0369, 0.0051, 0.0101, 0.0022, 0.0160, 0.0212, 0.0271, 0.0470,
        0.0319, 0.0421, 0.0054, 0.0322, 0.1112, 0.1506, 0.0984, 0.0968, 0.0901],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,814][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.8359, 0.0341, 0.0072, 0.0134, 0.0104, 0.0071, 0.0067, 0.0098, 0.0107,
        0.0089, 0.0102, 0.0069, 0.0064, 0.0084, 0.0046, 0.0046, 0.0076, 0.0071],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:16,844][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:16,847][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,850][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,852][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,852][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,853][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,853][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,853][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,854][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,854][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,854][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,855][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,855][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:16,856][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9942e-01, 5.8398e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,858][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5544, 0.4456], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,859][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([7.5210e-05, 9.9992e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,859][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9557, 0.0443], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,860][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8944, 0.1056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,860][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4653, 0.5347], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,860][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9075, 0.0925], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,861][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3258, 0.6742], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,861][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5426, 0.4574], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,861][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1543, 0.8457], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,862][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4962, 0.5038], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,862][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3275, 0.6725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:16,862][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([9.9979e-01, 4.7346e-05, 1.6631e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,863][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.4354, 0.3152, 0.2493], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,863][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([1.0947e-09, 9.9859e-01, 1.4092e-03], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,863][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.4843, 0.2137, 0.3020], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,864][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.5794, 0.3654, 0.0552], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,864][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.3112, 0.3851, 0.3037], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,865][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.9564, 0.0418, 0.0019], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,865][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.2389, 0.4397, 0.3214], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,865][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.4006, 0.5551, 0.0444], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,866][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.0529, 0.6645, 0.2825], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,868][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.3519, 0.3639, 0.2842], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,872][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.1985, 0.5016, 0.2999], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:16,872][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9277e-01, 7.8261e-04, 5.3379e-05, 6.3928e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,873][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3433, 0.2514, 0.2022, 0.2032], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,873][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.1900e-05, 7.0433e-02, 6.2512e-05, 9.2949e-01], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,873][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3079, 0.0305, 0.6117, 0.0498], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,874][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4044, 0.0728, 0.0236, 0.4992], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,874][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2384, 0.2809, 0.2302, 0.2506], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,874][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.8837e-01, 5.1895e-03, 3.9432e-04, 6.0461e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,875][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1180, 0.2164, 0.5348, 0.1308], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,876][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3460, 0.3720, 0.2223, 0.0597], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,879][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0365, 0.2872, 0.1746, 0.5017], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,882][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2718, 0.2803, 0.2181, 0.2298], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,885][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1360, 0.3515, 0.2249, 0.2876], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:16,886][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([9.9944e-01, 6.3175e-05, 5.3525e-06, 3.0368e-04, 1.9049e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,886][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.2977, 0.2099, 0.1651, 0.1652, 0.1621], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,886][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([2.7374e-09, 7.3958e-02, 2.3027e-04, 9.2449e-01, 1.3214e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,887][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0652, 0.0220, 0.6981, 0.0436, 0.1712], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,887][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.3075, 0.2463, 0.0759, 0.2191, 0.1511], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,887][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.1861, 0.2331, 0.1916, 0.2000, 0.1893], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,888][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([9.3747e-01, 4.5050e-02, 6.9572e-04, 1.0258e-02, 6.5250e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,888][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1787, 0.2257, 0.2870, 0.1720, 0.1366], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,890][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.2812, 0.3483, 0.1313, 0.1894, 0.0499], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,892][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0216, 0.2262, 0.1883, 0.4003, 0.1636], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,896][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.2204, 0.2286, 0.1791, 0.1877, 0.1842], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,898][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0975, 0.2760, 0.1926, 0.2662, 0.1677], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:16,899][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([9.9924e-01, 7.6100e-05, 2.8860e-06, 4.4515e-04, 4.5134e-06, 2.2953e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,899][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.2595, 0.1824, 0.1436, 0.1432, 0.1407, 0.1307], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,899][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([4.9236e-07, 9.0527e-02, 2.1256e-04, 8.8943e-01, 2.0658e-03, 1.7761e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,900][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1184, 0.0242, 0.3372, 0.1160, 0.3269, 0.0773], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,900][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.4107, 0.1115, 0.0497, 0.2345, 0.1563, 0.0373], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,901][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1514, 0.1814, 0.1576, 0.1777, 0.1749, 0.1568], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,901][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([9.1197e-01, 1.8095e-02, 2.4831e-04, 6.5851e-03, 1.0148e-02, 5.2957e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,903][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0802, 0.1740, 0.3208, 0.1187, 0.2573, 0.0490], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,905][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.2623, 0.3304, 0.1290, 0.1482, 0.0976, 0.0325], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,909][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0206, 0.1990, 0.0877, 0.3446, 0.0579, 0.2902], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,912][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.1852, 0.1919, 0.1505, 0.1577, 0.1550, 0.1598], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,912][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0808, 0.2032, 0.1198, 0.2059, 0.1610, 0.2294], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:16,912][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([9.9904e-01, 1.4173e-04, 8.8631e-07, 7.3165e-04, 7.1942e-06, 6.0247e-05,
        2.0934e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,913][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.2369, 0.1627, 0.1247, 0.1243, 0.1207, 0.1126, 0.1181],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,913][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([4.7289e-07, 6.5076e-02, 3.1725e-04, 8.5794e-01, 2.8589e-03, 2.7276e-02,
        4.6528e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,913][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0791, 0.0108, 0.2514, 0.0508, 0.3765, 0.1290, 0.1024],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,914][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.2404, 0.0847, 0.0525, 0.3893, 0.0587, 0.1126, 0.0619],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,914][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.1333, 0.1589, 0.1325, 0.1448, 0.1526, 0.1369, 0.1410],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,915][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([9.5041e-01, 7.3814e-03, 9.7548e-05, 1.7077e-03, 3.8987e-03, 1.3833e-02,
        2.2670e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,918][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0664, 0.1282, 0.2524, 0.1199, 0.2454, 0.0906, 0.0972],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,920][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.1747, 0.2415, 0.1324, 0.1850, 0.0891, 0.1687, 0.0086],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,924][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0114, 0.1196, 0.0790, 0.1937, 0.0521, 0.3505, 0.1936],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,925][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.1600, 0.1657, 0.1296, 0.1362, 0.1337, 0.1378, 0.1370],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,925][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0617, 0.1547, 0.1086, 0.1700, 0.1363, 0.2687, 0.1001],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:16,926][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.9386e-01, 3.9359e-04, 7.5900e-06, 1.8807e-03, 2.1779e-05, 2.2177e-04,
        1.1630e-05, 3.6018e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,926][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2095, 0.1458, 0.1109, 0.1118, 0.1078, 0.1016, 0.1066, 0.1060],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,926][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.1646e-05, 6.9025e-02, 2.3852e-04, 6.6875e-01, 3.1026e-03, 2.9465e-02,
        6.7736e-02, 1.6167e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,927][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0285, 0.0139, 0.2887, 0.0332, 0.2057, 0.1612, 0.2485, 0.0204],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,927][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3755, 0.0571, 0.0480, 0.1535, 0.1432, 0.0698, 0.0548, 0.0981],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,928][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1159, 0.1334, 0.1185, 0.1240, 0.1377, 0.1155, 0.1317, 0.1232],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,929][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([8.9029e-01, 8.0437e-03, 7.9371e-05, 1.7835e-03, 3.9131e-03, 2.0702e-02,
        3.4570e-02, 4.0621e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,931][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0492, 0.1105, 0.1849, 0.0842, 0.2573, 0.0716, 0.2276, 0.0148],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,934][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0966, 0.3371, 0.0896, 0.0925, 0.0954, 0.1769, 0.0493, 0.0627],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,938][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0083, 0.1207, 0.0775, 0.1910, 0.0262, 0.3110, 0.2047, 0.0606],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,938][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1412, 0.1461, 0.1137, 0.1198, 0.1177, 0.1214, 0.1205, 0.1198],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,939][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0461, 0.1476, 0.1050, 0.1410, 0.1022, 0.2379, 0.0897, 0.1305],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:16,939][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.9707e-01, 1.5234e-04, 1.9039e-05, 1.0174e-03, 3.4670e-05, 1.7538e-04,
        6.6003e-06, 1.8749e-04, 1.3379e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,939][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1894, 0.1323, 0.1007, 0.1017, 0.0972, 0.0918, 0.0957, 0.0957, 0.0955],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,940][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([3.9541e-06, 7.6187e-02, 1.2678e-04, 6.9669e-01, 1.5028e-03, 1.6267e-02,
        4.4070e-02, 1.3898e-01, 2.6172e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,940][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0663, 0.0104, 0.2408, 0.0232, 0.2336, 0.1064, 0.2264, 0.0439, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,941][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.4569, 0.0524, 0.0259, 0.0863, 0.0596, 0.0347, 0.0308, 0.0330, 0.2204],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,942][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1036, 0.1212, 0.1053, 0.1102, 0.1183, 0.1023, 0.1136, 0.1156, 0.1098],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,943][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([5.6410e-01, 1.5156e-03, 1.6091e-06, 3.0064e-05, 2.7953e-04, 1.4773e-03,
        1.1803e-03, 1.8338e-03, 4.2959e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,945][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0540, 0.1277, 0.2140, 0.0779, 0.1550, 0.0577, 0.1710, 0.0257, 0.1170],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,949][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1266, 0.2345, 0.1262, 0.0929, 0.0494, 0.1375, 0.0625, 0.1557, 0.0147],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,951][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0129, 0.0879, 0.0742, 0.1735, 0.0533, 0.2630, 0.2184, 0.0693, 0.0475],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,952][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1264, 0.1306, 0.1016, 0.1070, 0.1054, 0.1087, 0.1077, 0.1069, 0.1057],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,952][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0413, 0.1389, 0.0881, 0.1220, 0.0943, 0.1741, 0.0756, 0.1613, 0.1044],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:16,953][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([9.9945e-01, 3.7597e-05, 2.4776e-06, 2.5529e-04, 8.3281e-06, 1.2681e-05,
        1.4248e-06, 7.6483e-05, 1.4365e-04, 1.6678e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,953][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.1722, 0.1213, 0.0905, 0.0929, 0.0893, 0.0842, 0.0881, 0.0887, 0.0885,
        0.0842], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,953][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([2.2270e-07, 5.3844e-02, 5.6962e-04, 7.6050e-01, 2.3948e-03, 1.9030e-02,
        3.8268e-02, 9.1396e-02, 3.3321e-02, 6.7589e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,954][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0605, 0.0088, 0.0995, 0.0353, 0.1711, 0.1654, 0.1879, 0.0707, 0.1149,
        0.0859], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,954][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.2479, 0.0322, 0.0145, 0.0525, 0.0257, 0.0675, 0.0554, 0.0519, 0.4119,
        0.0405], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,956][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0933, 0.1132, 0.0871, 0.1016, 0.1015, 0.1023, 0.1039, 0.1040, 0.1032,
        0.0899], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,958][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([1.3377e-01, 8.5823e-03, 4.3519e-05, 4.2258e-04, 2.7977e-03, 6.2321e-03,
        4.3522e-03, 2.1846e-03, 2.2060e-02, 8.1956e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,961][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0383, 0.0931, 0.1321, 0.0711, 0.2368, 0.0588, 0.1137, 0.0539, 0.1285,
        0.0738], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,964][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1210, 0.0867, 0.0696, 0.0912, 0.1809, 0.1077, 0.0483, 0.2654, 0.0234,
        0.0056], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,965][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0059, 0.0890, 0.0865, 0.1648, 0.0507, 0.1790, 0.1345, 0.1273, 0.0530,
        0.1094], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,965][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1133, 0.1173, 0.0917, 0.0963, 0.0952, 0.0979, 0.0971, 0.0961, 0.0949,
        0.1003], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,966][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0287, 0.0980, 0.0735, 0.1016, 0.0982, 0.1571, 0.0793, 0.1615, 0.1082,
        0.0940], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:16,966][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.8473e-01, 7.0856e-04, 4.5543e-05, 3.6591e-03, 1.2308e-04, 3.6650e-04,
        5.4285e-05, 8.0053e-04, 2.4517e-03, 9.5151e-05, 6.9658e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,967][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1589, 0.1123, 0.0842, 0.0860, 0.0814, 0.0772, 0.0802, 0.0808, 0.0809,
        0.0774, 0.0807], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,967][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.4774e-05, 5.0170e-02, 1.5009e-04, 5.6955e-01, 1.9476e-03, 2.0893e-02,
        6.4677e-02, 1.7560e-01, 2.8979e-02, 6.5540e-04, 8.7362e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,967][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0667, 0.0060, 0.2060, 0.0144, 0.1775, 0.0905, 0.1235, 0.0204, 0.0917,
        0.1918, 0.0113], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,969][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.4964, 0.0196, 0.0080, 0.0540, 0.0385, 0.0231, 0.0169, 0.0456, 0.1336,
        0.0244, 0.1399], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,972][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0869, 0.1004, 0.0854, 0.0906, 0.0980, 0.0871, 0.0942, 0.0934, 0.0944,
        0.0846, 0.0849], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,974][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([5.4544e-02, 1.5563e-05, 6.8889e-08, 5.7498e-07, 5.4962e-06, 2.7406e-05,
        1.7687e-05, 9.7120e-05, 1.2106e-01, 8.2243e-01, 1.8016e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,978][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0231, 0.0484, 0.1033, 0.0365, 0.1166, 0.0337, 0.1190, 0.0157, 0.1299,
        0.3220, 0.0519], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,978][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1058, 0.1805, 0.0991, 0.0650, 0.0416, 0.0972, 0.0408, 0.1357, 0.0507,
        0.1008, 0.0827], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,979][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0092, 0.0726, 0.0594, 0.1502, 0.0438, 0.1971, 0.1424, 0.0574, 0.0692,
        0.1129, 0.0858], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,979][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1056, 0.1088, 0.0838, 0.0885, 0.0867, 0.0895, 0.0888, 0.0886, 0.0879,
        0.0927, 0.0791], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,979][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0405, 0.1015, 0.0769, 0.0855, 0.0929, 0.1355, 0.0539, 0.1291, 0.1055,
        0.0946, 0.0841], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:16,980][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([9.9879e-01, 4.2954e-05, 3.1794e-06, 2.1327e-04, 1.1796e-04, 1.5668e-05,
        5.9353e-07, 3.1749e-05, 9.0685e-05, 2.5252e-06, 6.3378e-04, 6.1068e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,980][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.1539, 0.1058, 0.0779, 0.0789, 0.0745, 0.0704, 0.0735, 0.0742, 0.0738,
        0.0703, 0.0740, 0.0729], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,981][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([5.9947e-08, 6.7461e-02, 1.1125e-03, 7.0733e-01, 4.0645e-03, 2.3058e-02,
        4.4475e-02, 6.7675e-02, 2.8451e-02, 6.7352e-04, 5.5252e-02, 4.5094e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,984][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0251, 0.0059, 0.2194, 0.0124, 0.0500, 0.0453, 0.1408, 0.0415, 0.0639,
        0.1647, 0.0296, 0.2012], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,986][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0406, 0.0291, 0.0080, 0.0076, 0.0205, 0.0091, 0.0110, 0.0471, 0.2402,
        0.0397, 0.4616, 0.0856], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,989][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0769, 0.0947, 0.0791, 0.0806, 0.0762, 0.0869, 0.0879, 0.0908, 0.0831,
        0.0853, 0.0807, 0.0777], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,991][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([2.4547e-01, 3.6060e-02, 4.7754e-04, 1.5960e-03, 5.0996e-03, 7.5353e-03,
        5.9222e-03, 5.0262e-03, 3.1922e-02, 5.6299e-01, 1.2987e-03, 9.6608e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,991][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0432, 0.0554, 0.0664, 0.0443, 0.0280, 0.0447, 0.0749, 0.0314, 0.1097,
        0.3913, 0.0763, 0.0344], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,992][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1290, 0.1311, 0.0621, 0.0855, 0.0214, 0.0674, 0.0587, 0.2121, 0.0277,
        0.0620, 0.1206, 0.0224], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,992][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0067, 0.0711, 0.0607, 0.1247, 0.0495, 0.1759, 0.1227, 0.0437, 0.0489,
        0.1549, 0.0933, 0.0481], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,993][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0959, 0.0994, 0.0778, 0.0815, 0.0803, 0.0825, 0.0819, 0.0812, 0.0801,
        0.0844, 0.0725, 0.0825], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,993][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0291, 0.0857, 0.0613, 0.0839, 0.0536, 0.1278, 0.0703, 0.1477, 0.0930,
        0.1220, 0.0759, 0.0495], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:16,994][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([9.9690e-01, 1.1503e-04, 7.0893e-06, 9.0519e-04, 1.0061e-05, 8.8065e-05,
        8.5082e-06, 2.0221e-04, 4.0099e-04, 1.5267e-05, 1.1548e-03, 5.7034e-06,
        1.8957e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,995][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.1413, 0.0974, 0.0733, 0.0741, 0.0704, 0.0668, 0.0692, 0.0690, 0.0683,
        0.0650, 0.0681, 0.0676, 0.0697], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:16,997][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([8.8260e-07, 6.1231e-02, 5.7482e-04, 6.3120e-01, 2.7898e-03, 1.8686e-02,
        4.6764e-02, 1.1304e-01, 3.1655e-02, 8.6327e-04, 8.8945e-02, 6.4072e-04,
        3.6128e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,000][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0239, 0.0033, 0.0808, 0.0136, 0.1228, 0.0397, 0.0397, 0.0222, 0.0306,
        0.0505, 0.0153, 0.5542, 0.0033], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,004][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0915, 0.0198, 0.0059, 0.0276, 0.0349, 0.0114, 0.0233, 0.0401, 0.2325,
        0.1519, 0.3022, 0.0542, 0.0046], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,004][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0733, 0.0822, 0.0694, 0.0775, 0.0812, 0.0749, 0.0744, 0.0789, 0.0794,
        0.0736, 0.0719, 0.0838, 0.0796], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,005][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([1.2311e-01, 9.6307e-03, 3.0521e-05, 6.7686e-05, 7.0656e-04, 4.4981e-04,
        2.9271e-04, 1.8728e-04, 9.7134e-04, 5.4918e-02, 4.2309e-05, 2.1609e-02,
        7.8798e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,005][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0273, 0.0625, 0.1072, 0.0502, 0.0527, 0.0269, 0.0491, 0.0371, 0.1231,
        0.2787, 0.1003, 0.0780, 0.0070], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,006][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0793, 0.1098, 0.0454, 0.0968, 0.0832, 0.0992, 0.0348, 0.1878, 0.0166,
        0.0619, 0.0862, 0.0909, 0.0081], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,006][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0100, 0.0759, 0.0653, 0.1254, 0.0564, 0.1548, 0.1385, 0.0542, 0.0409,
        0.0862, 0.0909, 0.0535, 0.0479], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,006][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0880, 0.0913, 0.0717, 0.0751, 0.0741, 0.0762, 0.0757, 0.0750, 0.0739,
        0.0779, 0.0667, 0.0762, 0.0782], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,007][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0428, 0.0830, 0.0524, 0.0834, 0.0701, 0.1294, 0.0630, 0.1250, 0.0909,
        0.0811, 0.0709, 0.0634, 0.0445], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,008][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9165e-01, 2.3574e-04, 2.9395e-05, 1.2398e-03, 3.5738e-05, 1.4429e-04,
        1.1165e-05, 4.6932e-04, 6.8055e-04, 4.1706e-05, 3.3020e-03, 2.1901e-05,
        4.1132e-05, 2.0925e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,010][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1319, 0.0924, 0.0694, 0.0702, 0.0666, 0.0629, 0.0650, 0.0645, 0.0635,
        0.0603, 0.0631, 0.0628, 0.0647, 0.0628], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,011][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.9443e-05, 2.2049e-03, 4.7642e-06, 2.2736e-02, 1.1713e-04, 1.8166e-03,
        5.8430e-03, 1.7403e-02, 2.1752e-03, 4.9433e-05, 5.7938e-03, 7.8273e-05,
        3.1476e-04, 9.4144e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,015][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0364, 0.0052, 0.1153, 0.0120, 0.0505, 0.0828, 0.1604, 0.0110, 0.0672,
        0.1747, 0.0262, 0.2091, 0.0381, 0.0110], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,018][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2585, 0.0375, 0.0211, 0.0848, 0.0406, 0.0319, 0.0294, 0.0276, 0.1389,
        0.0312, 0.1409, 0.0149, 0.0092, 0.1335], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,018][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0683, 0.0804, 0.0652, 0.0708, 0.0775, 0.0670, 0.0742, 0.0740, 0.0742,
        0.0633, 0.0701, 0.0792, 0.0733, 0.0626], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,018][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.7567e-02, 5.2405e-05, 7.2565e-08, 2.5789e-07, 4.5258e-06, 8.0241e-06,
        3.2744e-06, 5.5754e-06, 3.6191e-04, 8.7785e-02, 1.9716e-06, 2.1025e-03,
        7.2258e-01, 1.6953e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,019][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0159, 0.0486, 0.0658, 0.0338, 0.0665, 0.0241, 0.0862, 0.0103, 0.1060,
        0.3125, 0.0697, 0.0998, 0.0358, 0.0250], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,019][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0596, 0.1830, 0.0501, 0.0900, 0.0534, 0.1375, 0.0388, 0.0437, 0.0430,
        0.0590, 0.0969, 0.0582, 0.0563, 0.0305], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,020][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0071, 0.0584, 0.0389, 0.1188, 0.0275, 0.1733, 0.1695, 0.0323, 0.0422,
        0.0812, 0.0702, 0.0274, 0.1051, 0.0480], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,020][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0827, 0.0854, 0.0662, 0.0696, 0.0687, 0.0706, 0.0700, 0.0694, 0.0686,
        0.0726, 0.0614, 0.0707, 0.0725, 0.0717], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,022][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0272, 0.0816, 0.0491, 0.0861, 0.0673, 0.1073, 0.0547, 0.1047, 0.0793,
        0.0754, 0.0777, 0.0604, 0.0627, 0.0668], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,024][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([9.9368e-01, 2.3708e-04, 3.3964e-06, 1.5600e-03, 2.0783e-05, 6.0333e-05,
        1.9124e-05, 2.9749e-04, 3.7261e-04, 2.0479e-05, 1.7617e-03, 1.2379e-05,
        1.3681e-05, 1.3118e-03, 6.3037e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,026][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1196, 0.0855, 0.0637, 0.0656, 0.0623, 0.0591, 0.0611, 0.0613, 0.0611,
        0.0586, 0.0607, 0.0602, 0.0621, 0.0610, 0.0582], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,029][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([1.1485e-06, 2.7787e-03, 5.1676e-05, 3.1504e-02, 4.1380e-04, 2.3027e-03,
        6.9710e-03, 1.6915e-02, 2.9902e-03, 8.8350e-05, 7.8903e-03, 1.1928e-04,
        4.0556e-04, 9.1619e-01, 1.1375e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,031][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0420, 0.0064, 0.0972, 0.0294, 0.0934, 0.0471, 0.0363, 0.0379, 0.0483,
        0.0689, 0.0272, 0.3845, 0.0125, 0.0584, 0.0103], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,031][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0664, 0.0127, 0.0034, 0.0377, 0.0102, 0.0277, 0.0267, 0.0200, 0.2113,
        0.0519, 0.2363, 0.0067, 0.0205, 0.2062, 0.0621], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,032][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0592, 0.0739, 0.0612, 0.0681, 0.0688, 0.0684, 0.0700, 0.0704, 0.0672,
        0.0638, 0.0652, 0.0702, 0.0716, 0.0587, 0.0633], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,032][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([5.0842e-02, 1.2780e-03, 5.4572e-06, 1.8054e-05, 9.3182e-05, 1.4869e-04,
        1.2365e-04, 1.3023e-04, 1.8089e-03, 1.0419e-01, 4.4730e-05, 6.5924e-03,
        6.2387e-01, 1.6963e-01, 4.1233e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,033][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0199, 0.0642, 0.0935, 0.0390, 0.0608, 0.0344, 0.0793, 0.0223, 0.1035,
        0.2220, 0.0895, 0.0889, 0.0189, 0.0507, 0.0130], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,033][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1169, 0.0865, 0.0273, 0.0508, 0.0657, 0.0604, 0.0666, 0.1089, 0.0149,
        0.0641, 0.0852, 0.0721, 0.1044, 0.0681, 0.0081], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,034][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0057, 0.0573, 0.0412, 0.0923, 0.0289, 0.1508, 0.1828, 0.0360, 0.0412,
        0.0722, 0.0725, 0.0291, 0.0731, 0.0823, 0.0347], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,035][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0775, 0.0800, 0.0620, 0.0651, 0.0641, 0.0659, 0.0654, 0.0649, 0.0642,
        0.0678, 0.0576, 0.0660, 0.0677, 0.0672, 0.0646], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,038][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0300, 0.0741, 0.0475, 0.0707, 0.0615, 0.1026, 0.0592, 0.1168, 0.0759,
        0.0727, 0.0684, 0.0598, 0.0588, 0.0686, 0.0335], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,040][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.8790e-01, 2.0865e-04, 2.7365e-05, 1.5748e-03, 2.3846e-05, 2.4955e-04,
        9.0783e-06, 4.8816e-04, 1.1117e-03, 3.4945e-05, 3.1116e-03, 1.2350e-05,
        2.7242e-05, 1.1475e-03, 4.0929e-05, 4.0300e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,044][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1166, 0.0825, 0.0613, 0.0626, 0.0595, 0.0561, 0.0576, 0.0574, 0.0569,
        0.0541, 0.0563, 0.0560, 0.0578, 0.0565, 0.0539, 0.0550],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,044][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.6640e-06, 3.3015e-03, 3.1107e-05, 2.4550e-02, 2.7406e-04, 1.4136e-03,
        5.8395e-03, 1.4869e-02, 1.7140e-03, 4.8495e-05, 6.9120e-03, 8.2772e-05,
        2.5020e-04, 9.2330e-01, 1.1228e-02, 6.1825e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,045][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0261, 0.0063, 0.0994, 0.0119, 0.0608, 0.0548, 0.1544, 0.0224, 0.0307,
        0.1390, 0.0167, 0.2601, 0.0171, 0.0378, 0.0484, 0.0140],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,045][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1561, 0.0293, 0.0193, 0.0418, 0.0456, 0.0167, 0.0293, 0.0252, 0.1289,
        0.0343, 0.1565, 0.0225, 0.0083, 0.1032, 0.0561, 0.1269],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,046][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0595, 0.0709, 0.0589, 0.0614, 0.0702, 0.0586, 0.0656, 0.0673, 0.0650,
        0.0571, 0.0619, 0.0727, 0.0653, 0.0544, 0.0575, 0.0536],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,046][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.7670e-02, 1.7570e-03, 3.9088e-06, 1.3619e-05, 1.2125e-04, 1.2254e-04,
        8.1520e-05, 4.1677e-05, 3.0596e-04, 4.9429e-02, 4.5223e-06, 7.5354e-03,
        5.4433e-01, 2.3356e-02, 1.8559e-02, 3.1666e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,047][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0232, 0.0593, 0.0612, 0.0325, 0.0508, 0.0223, 0.0740, 0.0144, 0.0692,
        0.2781, 0.0866, 0.0770, 0.0393, 0.0402, 0.0522, 0.0196],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,048][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1010, 0.1331, 0.0489, 0.0678, 0.0379, 0.0710, 0.0311, 0.0861, 0.0087,
        0.0432, 0.1027, 0.0447, 0.0993, 0.0827, 0.0375, 0.0044],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,051][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0092, 0.0570, 0.0370, 0.1076, 0.0278, 0.1374, 0.1241, 0.0426, 0.0266,
        0.0710, 0.0579, 0.0303, 0.0899, 0.0672, 0.0936, 0.0207],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,055][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0723, 0.0748, 0.0583, 0.0611, 0.0604, 0.0620, 0.0614, 0.0608, 0.0599,
        0.0634, 0.0538, 0.0620, 0.0636, 0.0626, 0.0603, 0.0634],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,057][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0261, 0.0807, 0.0474, 0.0743, 0.0504, 0.1107, 0.0499, 0.0946, 0.0694,
        0.0773, 0.0713, 0.0480, 0.0570, 0.0674, 0.0428, 0.0328],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,057][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.9832e-01, 5.3499e-05, 6.5010e-07, 3.6706e-04, 7.3891e-06, 8.5714e-06,
        2.1485e-06, 4.3088e-05, 1.9594e-04, 3.9128e-06, 7.4745e-04, 4.3872e-06,
        4.6725e-06, 1.1512e-04, 5.4343e-06, 7.5418e-05, 4.3044e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,058][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.1088, 0.0773, 0.0571, 0.0589, 0.0558, 0.0529, 0.0545, 0.0546, 0.0543,
        0.0517, 0.0538, 0.0535, 0.0550, 0.0540, 0.0518, 0.0528, 0.0533],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,058][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.1787e-06, 1.9432e-03, 9.1931e-05, 1.7173e-02, 3.6292e-04, 1.4824e-03,
        4.5100e-03, 1.3076e-02, 2.1748e-03, 6.3449e-05, 7.0697e-03, 1.2194e-04,
        2.8904e-04, 9.2684e-01, 1.0595e-02, 1.0369e-02, 3.8322e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,059][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0332, 0.0033, 0.1019, 0.0096, 0.0816, 0.0276, 0.0534, 0.0291, 0.0375,
        0.0999, 0.0120, 0.3472, 0.0165, 0.0313, 0.0303, 0.0411, 0.0446],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,059][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0352, 0.0118, 0.0072, 0.0210, 0.0262, 0.0178, 0.0201, 0.0262, 0.2118,
        0.0375, 0.1953, 0.0362, 0.0243, 0.0876, 0.0810, 0.1325, 0.0284],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,059][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0541, 0.0686, 0.0577, 0.0573, 0.0662, 0.0587, 0.0593, 0.0621, 0.0638,
        0.0578, 0.0563, 0.0678, 0.0618, 0.0526, 0.0549, 0.0525, 0.0485],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,060][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.8351e-02, 3.4710e-03, 1.0833e-05, 3.7505e-05, 3.2783e-04, 2.8111e-04,
        2.0695e-04, 4.5965e-05, 9.0712e-05, 1.2587e-02, 3.2199e-06, 6.8579e-03,
        2.5393e-01, 2.6692e-03, 6.8850e-03, 5.7323e-02, 6.3693e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,061][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0285, 0.0421, 0.0981, 0.0392, 0.0586, 0.0248, 0.0536, 0.0303, 0.0759,
        0.2057, 0.0725, 0.0753, 0.0152, 0.0432, 0.0497, 0.0613, 0.0261],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,064][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0968, 0.0773, 0.0861, 0.0673, 0.0458, 0.0333, 0.0311, 0.1525, 0.0132,
        0.0353, 0.0677, 0.0497, 0.0770, 0.0898, 0.0548, 0.0181, 0.0042],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,067][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0074, 0.0582, 0.0491, 0.0982, 0.0329, 0.1042, 0.1295, 0.0269, 0.0394,
        0.1123, 0.0645, 0.0307, 0.0447, 0.0614, 0.0431, 0.0307, 0.0670],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,070][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0677, 0.0702, 0.0549, 0.0574, 0.0568, 0.0583, 0.0577, 0.0571, 0.0562,
        0.0594, 0.0506, 0.0581, 0.0596, 0.0586, 0.0565, 0.0593, 0.0615],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,071][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0234, 0.0585, 0.0485, 0.0655, 0.0594, 0.1028, 0.0503, 0.1026, 0.0712,
        0.0748, 0.0493, 0.0560, 0.0436, 0.0610, 0.0456, 0.0393, 0.0483],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,071][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8411e-01, 3.0177e-04, 3.2967e-05, 1.5887e-03, 4.0249e-05, 1.7279e-04,
        1.4205e-05, 5.7164e-04, 8.9804e-04, 5.3496e-05, 4.0900e-03, 2.4742e-05,
        5.0252e-05, 2.6281e-03, 6.9404e-05, 7.9168e-04, 2.9618e-05, 4.5314e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,071][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1021, 0.0735, 0.0550, 0.0564, 0.0534, 0.0504, 0.0519, 0.0518, 0.0513,
        0.0489, 0.0507, 0.0503, 0.0517, 0.0509, 0.0485, 0.0496, 0.0501, 0.0536],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,072][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.0517e-05, 2.1824e-03, 1.3034e-04, 2.0603e-02, 7.9222e-04, 3.1784e-03,
        1.2680e-02, 2.8757e-02, 3.6770e-03, 1.3231e-04, 1.1594e-02, 2.8477e-04,
        6.2683e-04, 8.5393e-01, 2.2061e-02, 1.2615e-02, 6.3697e-03, 2.0333e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,072][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0272, 0.0038, 0.0961, 0.0098, 0.0419, 0.0660, 0.1360, 0.0090, 0.0554,
        0.1444, 0.0206, 0.1740, 0.0295, 0.0091, 0.0549, 0.0439, 0.0721, 0.0066],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,073][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1962, 0.0314, 0.0139, 0.0604, 0.0317, 0.0218, 0.0164, 0.0211, 0.1101,
        0.0211, 0.1375, 0.0098, 0.0047, 0.0935, 0.0423, 0.0714, 0.0156, 0.1010],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,073][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0544, 0.0641, 0.0519, 0.0565, 0.0614, 0.0533, 0.0593, 0.0597, 0.0588,
        0.0507, 0.0558, 0.0628, 0.0579, 0.0500, 0.0536, 0.0502, 0.0513, 0.0483],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,074][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.8719e-03, 3.6371e-04, 3.7205e-06, 6.2329e-06, 5.1774e-05, 5.7688e-05,
        3.4414e-05, 2.8473e-05, 1.8549e-04, 2.0866e-02, 4.4689e-06, 2.8165e-03,
        1.0190e-01, 1.1169e-02, 7.0461e-03, 9.5491e-02, 6.5780e-01, 9.3304e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,076][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0120, 0.0351, 0.0522, 0.0250, 0.0475, 0.0180, 0.0624, 0.0074, 0.0824,
        0.2334, 0.0515, 0.0729, 0.0250, 0.0182, 0.0493, 0.0418, 0.1464, 0.0194],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,079][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0512, 0.1571, 0.0432, 0.0791, 0.0474, 0.1355, 0.0333, 0.0369, 0.0351,
        0.0522, 0.0758, 0.0511, 0.0497, 0.0236, 0.0456, 0.0157, 0.0472, 0.0202],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,083][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0054, 0.0501, 0.0336, 0.1046, 0.0231, 0.1386, 0.1334, 0.0256, 0.0372,
        0.0669, 0.0611, 0.0229, 0.0768, 0.0398, 0.0650, 0.0340, 0.0472, 0.0346],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,084][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0642, 0.0664, 0.0514, 0.0540, 0.0533, 0.0548, 0.0542, 0.0537, 0.0530,
        0.0561, 0.0475, 0.0547, 0.0561, 0.0554, 0.0533, 0.0561, 0.0581, 0.0578],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,084][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0211, 0.0670, 0.0398, 0.0692, 0.0556, 0.0875, 0.0426, 0.0838, 0.0632,
        0.0621, 0.0636, 0.0497, 0.0520, 0.0530, 0.0461, 0.0368, 0.0599, 0.0472],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,085][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:17,086][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5668],
        [ 3144],
        [  658],
        [ 4447],
        [ 2748],
        [11559],
        [ 5829],
        [ 5670],
        [21073],
        [14745],
        [ 5114],
        [ 8525],
        [12612],
        [ 5553],
        [ 7904],
        [17070],
        [21861],
        [ 7267]], device='cuda:0')
[2024-07-24 10:30:17,087][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5909],
        [ 9851],
        [ 1353],
        [13306],
        [ 6398],
        [16192],
        [16946],
        [27162],
        [31446],
        [24247],
        [19650],
        [14464],
        [27020],
        [28422],
        [22235],
        [37703],
        [39988],
        [32718]], device='cuda:0')
[2024-07-24 10:30:17,088][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[4647],
        [4444],
        [4645],
        [7673],
        [4530],
        [4488],
        [4509],
        [4539],
        [4896],
        [4689],
        [7177],
        [6579],
        [5822],
        [7161],
        [5939],
        [6304],
        [5848],
        [7054]], device='cuda:0')
[2024-07-24 10:30:17,090][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[9410],
        [7906],
        [7343],
        [6974],
        [7166],
        [6547],
        [7005],
        [6886],
        [7120],
        [7434],
        [7763],
        [7194],
        [7230],
        [7338],
        [6791],
        [6747],
        [6934],
        [6978]], device='cuda:0')
[2024-07-24 10:30:17,092][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[22675],
        [ 6896],
        [ 5401],
        [ 5109],
        [ 5038],
        [ 5381],
        [ 6735],
        [ 6113],
        [ 7127],
        [ 7770],
        [ 5547],
        [ 6984],
        [ 5872],
        [ 5306],
        [ 5667],
        [ 5684],
        [ 6029],
        [ 5335]], device='cuda:0')
[2024-07-24 10:30:17,093][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[18420],
        [ 7213],
        [ 6984],
        [ 5179],
        [ 5170],
        [ 5168],
        [ 5921],
        [ 5914],
        [ 5171],
        [ 5177],
        [ 5166],
        [ 5168],
        [ 5074],
        [ 4890],
        [ 5152],
        [ 6585],
        [ 6391],
        [ 5309]], device='cuda:0')
[2024-07-24 10:30:17,095][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24750],
        [19599],
        [ 6041],
        [10372],
        [ 4261],
        [ 8389],
        [ 4326],
        [10449],
        [ 8670],
        [ 5701],
        [14570],
        [ 5193],
        [ 5712],
        [10204],
        [ 6724],
        [ 7250],
        [ 5434],
        [10656]], device='cuda:0')
[2024-07-24 10:30:17,098][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26718],
        [ 6928],
        [ 4189],
        [ 7787],
        [ 5420],
        [ 6809],
        [ 7616],
        [ 7718],
        [ 9678],
        [ 9797],
        [ 7851],
        [ 6665],
        [ 6164],
        [ 6205],
        [ 7170],
        [ 6242],
        [ 7667],
        [ 7154]], device='cuda:0')
[2024-07-24 10:30:17,100][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[25911],
        [25997],
        [23690],
        [23120],
        [22318],
        [22219],
        [22373],
        [22654],
        [22575],
        [22774],
        [23420],
        [23155],
        [23340],
        [23690],
        [23745],
        [23982],
        [23807],
        [23974]], device='cuda:0')
[2024-07-24 10:30:17,101][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[11293],
        [14444],
        [14421],
        [21580],
        [28444],
        [19935],
        [25064],
        [10930],
        [16548],
        [19599],
        [17195],
        [30276],
        [30448],
        [18779],
        [24928],
        [21826],
        [31488],
        [19843]], device='cuda:0')
[2024-07-24 10:30:17,102][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15739],
        [16394],
        [20085],
        [23959],
        [28602],
        [32471],
        [36278],
        [39214],
        [40121],
        [41043],
        [41019],
        [40967],
        [41190],
        [41532],
        [41461],
        [41763],
        [42168],
        [42021]], device='cuda:0')
[2024-07-24 10:30:17,103][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[17721],
        [11696],
        [ 8844],
        [ 8171],
        [ 7912],
        [ 7778],
        [ 7498],
        [ 7288],
        [ 7294],
        [ 6947],
        [ 7425],
        [ 7472],
        [ 7548],
        [ 7501],
        [ 7491],
        [ 7503],
        [ 7501],
        [ 7355]], device='cuda:0')
[2024-07-24 10:30:17,105][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17799],
        [14173],
        [31686],
        [23348],
        [31422],
        [23413],
        [22766],
        [24195],
        [23664],
        [19017],
        [21496],
        [22782],
        [20634],
        [21249],
        [17638],
        [16764],
        [17689],
        [18302]], device='cuda:0')
[2024-07-24 10:30:17,106][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[1691],
        [1822],
        [2168],
        [1973],
        [2239],
        [2300],
        [2483],
        [2204],
        [2242],
        [2433],
        [2335],
        [2372],
        [2620],
        [2288],
        [2636],
        [2534],
        [2898],
        [2283]], device='cuda:0')
[2024-07-24 10:30:17,108][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12079],
        [31653],
        [16875],
        [11148],
        [24280],
        [18580],
        [ 5661],
        [13357],
        [19112],
        [21755],
        [19255],
        [18402],
        [ 6435],
        [14584],
        [12371],
        [15745],
        [17966],
        [19311]], device='cuda:0')
[2024-07-24 10:30:17,109][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12963],
        [12981],
        [12970],
        [13204],
        [12979],
        [12980],
        [12993],
        [13085],
        [13061],
        [12978],
        [13528],
        [13010],
        [13073],
        [13293],
        [13174],
        [13413],
        [13029],
        [13604]], device='cuda:0')
[2024-07-24 10:30:17,112][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13634],
        [13167],
        [14119],
        [14754],
        [15252],
        [15381],
        [15463],
        [15331],
        [15256],
        [15131],
        [14962],
        [14888],
        [14768],
        [14561],
        [14356],
        [14210],
        [14089],
        [13949]], device='cuda:0')
[2024-07-24 10:30:17,114][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[43103],
        [10227],
        [10213],
        [ 8350],
        [ 8355],
        [ 8343],
        [ 8303],
        [ 7540],
        [ 7660],
        [ 7840],
        [ 7249],
        [ 7902],
        [ 7594],
        [ 5697],
        [ 5674],
        [ 5630],
        [ 5579],
        [ 5488]], device='cuda:0')
[2024-07-24 10:30:17,117][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7685],
        [ 7678],
        [ 3397],
        [ 3693],
        [ 6109],
        [ 7691],
        [ 8130],
        [ 7374],
        [ 8257],
        [ 8859],
        [ 5647],
        [ 6829],
        [11990],
        [ 6522],
        [10014],
        [ 7963],
        [ 9212],
        [ 6690]], device='cuda:0')
[2024-07-24 10:30:17,118][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24297],
        [25748],
        [42695],
        [46713],
        [47448],
        [47656],
        [46982],
        [47192],
        [45006],
        [43488],
        [44754],
        [43621],
        [44134],
        [45687],
        [44763],
        [45070],
        [44301],
        [45583]], device='cuda:0')
[2024-07-24 10:30:17,119][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18930],
        [26164],
        [37086],
        [33450],
        [38876],
        [37048],
        [37468],
        [38054],
        [37181],
        [36737],
        [37049],
        [38541],
        [38250],
        [38455],
        [38431],
        [39153],
        [39672],
        [39708]], device='cuda:0')
[2024-07-24 10:30:17,120][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[19921],
        [20717],
        [20318],
        [20116],
        [20649],
        [21842],
        [21093],
        [22650],
        [27691],
        [25116],
        [23965],
        [25106],
        [28742],
        [27061],
        [26535],
        [26617],
        [22915],
        [20373]], device='cuda:0')
[2024-07-24 10:30:17,121][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[25364],
        [30480],
        [29529],
        [28662],
        [29650],
        [28796],
        [29170],
        [30044],
        [29261],
        [30240],
        [34119],
        [34833],
        [32952],
        [34076],
        [32264],
        [32969],
        [31531],
        [33296]], device='cuda:0')
[2024-07-24 10:30:17,122][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26369],
        [33704],
        [34695],
        [32462],
        [32455],
        [32290],
        [30852],
        [33570],
        [34603],
        [35797],
        [34609],
        [35947],
        [35425],
        [32495],
        [34213],
        [34230],
        [34381],
        [32885]], device='cuda:0')
[2024-07-24 10:30:17,124][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35262],
        [22475],
        [22067],
        [18695],
        [17442],
        [18206],
        [19879],
        [20551],
        [20276],
        [20193],
        [20013],
        [19684],
        [19935],
        [21205],
        [21842],
        [21966],
        [21357],
        [21724]], device='cuda:0')
[2024-07-24 10:30:17,126][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[7650],
        [8799],
        [7169],
        [7003],
        [6414],
        [6052],
        [5821],
        [5864],
        [5881],
        [5850],
        [5850],
        [5773],
        [5656],
        [5616],
        [5539],
        [5450],
        [5392],
        [5347]], device='cuda:0')
[2024-07-24 10:30:17,128][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34346],
        [29314],
        [28584],
        [30083],
        [29912],
        [28868],
        [28582],
        [30516],
        [31286],
        [31284],
        [30672],
        [30970],
        [30860],
        [31232],
        [31464],
        [31408],
        [31464],
        [31493]], device='cuda:0')
[2024-07-24 10:30:17,130][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4166],
        [6708],
        [6546],
        [7061],
        [5574],
        [5450],
        [5707],
        [5043],
        [4716],
        [4903],
        [4977],
        [4830],
        [4059],
        [4497],
        [4497],
        [4479],
        [4828],
        [5185]], device='cuda:0')
[2024-07-24 10:30:17,133][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5928],
        [ 4083],
        [ 9550],
        [14039],
        [ 8575],
        [18294],
        [23669],
        [12913],
        [20927],
        [20855],
        [15383],
        [16088],
        [28962],
        [15770],
        [19545],
        [19701],
        [19624],
        [11525]], device='cuda:0')
[2024-07-24 10:30:17,134][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880],
        [22880]], device='cuda:0')
[2024-07-24 10:30:17,154][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:17,157][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,158][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,158][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,158][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,159][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,159][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,159][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,160][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,160][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,161][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,161][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,162][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,162][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0321, 0.9679], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,162][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2315, 0.7685], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,163][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7885, 0.2115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,163][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0433, 0.9567], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,163][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4552, 0.5448], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,164][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5186, 0.4814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,164][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1056, 0.8944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,164][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0384, 0.9616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,165][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9226, 0.0774], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,165][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5247, 0.4753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,165][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5090, 0.4910], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,166][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.3519e-08, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,166][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.0024, 0.8652, 0.1324], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,167][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.1077, 0.4636, 0.4287], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,167][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.4843, 0.3517, 0.1640], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,167][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([6.7476e-04, 9.8447e-01, 1.4855e-02], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,168][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.5960, 0.3288, 0.0752], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,168][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.1601, 0.4018, 0.4381], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,168][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.3550, 0.6180, 0.0270], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,169][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.0331, 0.6538, 0.3131], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,169][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.8734, 0.0729, 0.0537], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,169][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.2318, 0.4265, 0.3417], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,170][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.3324, 0.3330, 0.3346], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,170][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([9.2798e-09, 9.9947e-01, 5.3141e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,170][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0042, 0.5209, 0.1169, 0.3581], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,171][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0324, 0.3198, 0.3187, 0.3291], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,173][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4825, 0.2300, 0.1059, 0.1815], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,176][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0015, 0.8213, 0.0120, 0.1651], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,179][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3115, 0.2276, 0.1503, 0.3106], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,180][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1613, 0.3082, 0.2103, 0.3202], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,181][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1953, 0.3554, 0.0309, 0.4183], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,181][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0345, 0.4943, 0.2321, 0.2391], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,181][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8391, 0.0667, 0.0488, 0.0454], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,182][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2424, 0.2645, 0.3041, 0.1891], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,182][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2663, 0.2618, 0.2422, 0.2297], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,183][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.1248e-08, 9.8920e-01, 8.9514e-04, 9.9045e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,183][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.0026, 0.4774, 0.0615, 0.3075, 0.1509], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,183][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0282, 0.2387, 0.2511, 0.2930, 0.1891], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,185][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.2924, 0.2465, 0.1123, 0.1738, 0.1750], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,187][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([4.2894e-04, 7.2497e-01, 7.0672e-03, 2.5664e-01, 1.0889e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,189][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.5624, 0.2347, 0.0265, 0.1589, 0.0175], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,193][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0662, 0.1586, 0.0551, 0.3822, 0.3379], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,194][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.1609, 0.3234, 0.0254, 0.4607, 0.0296], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,194][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0355, 0.4069, 0.1979, 0.2022, 0.1575], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,194][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.8004, 0.0653, 0.0479, 0.0440, 0.0425], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,195][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.1522, 0.2501, 0.2270, 0.1766, 0.1942], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,195][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.2046, 0.2030, 0.1973, 0.1884, 0.2067], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,195][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([4.5706e-09, 9.9101e-01, 4.0950e-04, 7.7787e-03, 7.9803e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,196][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0027, 0.4269, 0.0580, 0.2919, 0.1238, 0.0966], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,196][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0232, 0.1878, 0.1981, 0.2280, 0.1805, 0.1823], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,196][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.3162, 0.1981, 0.0823, 0.1480, 0.1433, 0.1121], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,196][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ were] are: tensor([3.4284e-04, 7.3546e-01, 8.5321e-03, 1.8068e-01, 1.4906e-02, 6.0079e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,198][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.6101, 0.2144, 0.0182, 0.1315, 0.0120, 0.0137], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,202][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0426, 0.0919, 0.0567, 0.2574, 0.2685, 0.2828], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,204][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3114, 0.2821, 0.0123, 0.1730, 0.0127, 0.2085], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,208][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0307, 0.3344, 0.1709, 0.1789, 0.1395, 0.1456], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,209][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.7719, 0.0620, 0.0454, 0.0419, 0.0403, 0.0385], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,209][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.1545, 0.2030, 0.2046, 0.1495, 0.1831, 0.1053], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,209][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.1711, 0.1713, 0.1602, 0.1557, 0.1650, 0.1767], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,210][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ were] are: tensor([3.1774e-08, 9.9248e-01, 5.5229e-04, 5.0457e-03, 6.4616e-04, 1.2720e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,210][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0021, 0.3607, 0.0423, 0.2735, 0.1111, 0.1041, 0.1061],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,210][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0261, 0.1482, 0.1678, 0.2018, 0.1549, 0.1674, 0.1338],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,211][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.2974, 0.1777, 0.0793, 0.1285, 0.1260, 0.0918, 0.0993],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,211][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ working] are: tensor([4.6059e-04, 6.7827e-01, 9.4311e-03, 1.6464e-01, 1.4215e-02, 8.6315e-02,
        4.6672e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,213][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.6696, 0.1937, 0.0115, 0.1027, 0.0061, 0.0086, 0.0079],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,215][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0909, 0.0697, 0.0139, 0.1107, 0.0529, 0.1117, 0.5502],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,219][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.1553, 0.2214, 0.0180, 0.2264, 0.0187, 0.3267, 0.0335],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,221][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0237, 0.3144, 0.1515, 0.1563, 0.1213, 0.1126, 0.1201],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,222][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.7351, 0.0609, 0.0451, 0.0418, 0.0399, 0.0384, 0.0389],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,222][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.1479, 0.1741, 0.1823, 0.1231, 0.1608, 0.1030, 0.1087],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,222][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.1473, 0.1505, 0.1405, 0.1343, 0.1434, 0.1494, 0.1345],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,223][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ working] are: tensor([3.6525e-08, 9.8760e-01, 6.8392e-04, 7.1782e-03, 9.5567e-04, 2.2365e-03,
        1.3413e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,223][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0025, 0.2626, 0.0407, 0.2122, 0.0940, 0.0762, 0.0716, 0.2401],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,223][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0140, 0.1446, 0.1536, 0.1654, 0.1291, 0.1512, 0.1408, 0.1012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,224][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2915, 0.1502, 0.0801, 0.1082, 0.1167, 0.0724, 0.0782, 0.1025],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,224][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0013, 0.6272, 0.0077, 0.0781, 0.0059, 0.0495, 0.0384, 0.1918],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,226][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.6847, 0.2000, 0.0090, 0.0820, 0.0048, 0.0058, 0.0046, 0.0091],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,228][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0636, 0.0381, 0.0101, 0.0476, 0.0282, 0.1622, 0.4736, 0.1767],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,232][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.3273, 0.2096, 0.0055, 0.0909, 0.0055, 0.1152, 0.0137, 0.2323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,234][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0233, 0.3053, 0.1320, 0.1427, 0.1019, 0.1020, 0.1032, 0.0896],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,235][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.7312, 0.0557, 0.0407, 0.0375, 0.0359, 0.0345, 0.0348, 0.0296],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,235][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1282, 0.1577, 0.1660, 0.1108, 0.1469, 0.0885, 0.0931, 0.1087],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,235][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1330, 0.1329, 0.1235, 0.1160, 0.1249, 0.1289, 0.1149, 0.1259],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,236][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([2.6727e-07, 9.8086e-01, 1.2902e-03, 1.0130e-02, 1.8640e-03, 3.1162e-03,
        1.9627e-03, 7.8032e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,236][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0021, 0.2351, 0.0345, 0.1648, 0.0719, 0.0597, 0.0536, 0.1936, 0.1847],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,236][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0131, 0.1316, 0.1292, 0.1469, 0.1119, 0.1362, 0.1298, 0.0913, 0.1100],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,237][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3013, 0.1269, 0.0658, 0.0967, 0.1003, 0.0687, 0.0707, 0.0978, 0.0717],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,238][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0010, 0.7087, 0.0056, 0.0394, 0.0046, 0.0249, 0.0123, 0.0721, 0.1313],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,241][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6471, 0.1938, 0.0107, 0.1046, 0.0061, 0.0078, 0.0069, 0.0133, 0.0097],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,245][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0363, 0.0216, 0.0081, 0.0350, 0.0379, 0.0965, 0.3051, 0.2571, 0.2024],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,247][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.3478, 0.1472, 0.0031, 0.0490, 0.0032, 0.0707, 0.0087, 0.1429, 0.2273],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,248][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0186, 0.2900, 0.1169, 0.1245, 0.0928, 0.0923, 0.0934, 0.0784, 0.0930],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,248][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.7012, 0.0562, 0.0406, 0.0374, 0.0358, 0.0343, 0.0347, 0.0295, 0.0304],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,248][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1240, 0.1289, 0.1456, 0.0865, 0.1283, 0.0771, 0.0777, 0.1007, 0.1313],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,249][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1146, 0.1150, 0.1151, 0.1050, 0.1156, 0.1150, 0.1054, 0.1113, 0.1030],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,249][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.6520e-08, 9.9187e-01, 5.9523e-04, 4.9973e-03, 5.9679e-04, 1.0024e-03,
        5.9247e-04, 2.3702e-04, 1.1315e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,249][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0027, 0.1985, 0.0202, 0.1411, 0.0442, 0.0483, 0.0475, 0.2033, 0.1769,
        0.1173], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,250][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0148, 0.1036, 0.1124, 0.1379, 0.1002, 0.1312, 0.1184, 0.0899, 0.1103,
        0.0813], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,250][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2162, 0.1291, 0.0582, 0.0949, 0.0967, 0.0687, 0.0715, 0.0984, 0.0732,
        0.0932], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,251][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ station] are: tensor([5.2829e-04, 6.4864e-01, 3.3974e-03, 4.3676e-02, 4.2435e-03, 2.0327e-02,
        1.3194e-02, 8.4777e-02, 1.3683e-01, 4.4391e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,253][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.6510, 0.1933, 0.0104, 0.0997, 0.0056, 0.0071, 0.0063, 0.0122, 0.0087,
        0.0056], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,256][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0570, 0.0103, 0.0030, 0.0171, 0.0132, 0.0337, 0.1818, 0.1756, 0.2065,
        0.3018], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,260][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1054, 0.0913, 0.0038, 0.0646, 0.0045, 0.1002, 0.0114, 0.2089, 0.3708,
        0.0392], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,261][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0197, 0.2625, 0.1015, 0.1129, 0.0840, 0.0803, 0.0888, 0.0749, 0.0868,
        0.0885], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,261][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.6865, 0.0540, 0.0392, 0.0359, 0.0344, 0.0330, 0.0334, 0.0281, 0.0293,
        0.0262], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,261][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0996, 0.1306, 0.1213, 0.0872, 0.1053, 0.0655, 0.0699, 0.0845, 0.1087,
        0.1275], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,262][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1115, 0.1067, 0.1068, 0.0953, 0.1077, 0.1047, 0.0933, 0.1003, 0.0896,
        0.0840], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,262][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ station] are: tensor([2.3141e-08, 9.9157e-01, 5.7599e-04, 5.3038e-03, 4.9628e-04, 1.0193e-03,
        5.5336e-04, 2.5761e-04, 1.5265e-04, 6.8494e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,262][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0017, 0.2111, 0.0332, 0.1417, 0.0596, 0.0436, 0.0382, 0.1417, 0.1460,
        0.0948, 0.0886], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,263][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0111, 0.1094, 0.1129, 0.1151, 0.0900, 0.1064, 0.0998, 0.0771, 0.1013,
        0.0869, 0.0900], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,264][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.2706, 0.1045, 0.0480, 0.0801, 0.0735, 0.0580, 0.0593, 0.0829, 0.0610,
        0.0679, 0.0942], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,266][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([3.5976e-04, 5.6802e-01, 1.0012e-02, 3.3704e-02, 8.6915e-03, 2.2732e-02,
        1.2473e-02, 5.2178e-02, 1.4081e-01, 9.0215e-02, 6.0807e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,269][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.4450, 0.1927, 0.0247, 0.1359, 0.0166, 0.0182, 0.0171, 0.0319, 0.0241,
        0.0171, 0.0765], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,272][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0319, 0.0104, 0.0061, 0.0250, 0.0134, 0.0466, 0.1409, 0.1275, 0.1646,
        0.2142, 0.2193], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,274][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2219, 0.1162, 0.0027, 0.0332, 0.0022, 0.0499, 0.0060, 0.1010, 0.1904,
        0.0293, 0.2471], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,274][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0194, 0.2430, 0.1045, 0.1071, 0.0787, 0.0786, 0.0774, 0.0651, 0.0768,
        0.0734, 0.0759], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,274][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.6604, 0.0536, 0.0389, 0.0357, 0.0341, 0.0327, 0.0329, 0.0278, 0.0289,
        0.0258, 0.0293], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,275][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0939, 0.1087, 0.1164, 0.0701, 0.0969, 0.0582, 0.0583, 0.0744, 0.0940,
        0.1129, 0.1163], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,275][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1056, 0.0993, 0.0976, 0.0881, 0.0948, 0.0964, 0.0843, 0.0924, 0.0821,
        0.0774, 0.0819], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,276][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([7.8254e-08, 9.8768e-01, 9.9458e-04, 6.9135e-03, 9.9882e-04, 1.4204e-03,
        8.6444e-04, 4.1258e-04, 2.0576e-04, 8.6733e-05, 4.2333e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,276][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.0025, 0.1682, 0.0179, 0.0967, 0.0418, 0.0439, 0.0461, 0.1455, 0.1293,
        0.1016, 0.0933, 0.1131], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,276][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0118, 0.0897, 0.0986, 0.1143, 0.0770, 0.1139, 0.1023, 0.0786, 0.0949,
        0.0707, 0.0865, 0.0618], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,277][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.1936, 0.1038, 0.0455, 0.0748, 0.0748, 0.0564, 0.0562, 0.0765, 0.0565,
        0.0760, 0.0916, 0.0945], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,278][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([3.3192e-04, 4.8459e-01, 2.5597e-03, 7.4885e-02, 2.8627e-03, 2.2397e-02,
        1.9014e-02, 1.7694e-01, 1.2321e-01, 3.3932e-02, 3.9261e-02, 2.0021e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,280][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.7207, 0.1701, 0.0052, 0.0653, 0.0022, 0.0030, 0.0025, 0.0050, 0.0034,
        0.0020, 0.0190, 0.0015], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,283][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0298, 0.0037, 0.0006, 0.0074, 0.0015, 0.0154, 0.0700, 0.0770, 0.1063,
        0.1170, 0.3744, 0.1970], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,287][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0803, 0.0696, 0.0027, 0.0435, 0.0028, 0.0669, 0.0076, 0.1296, 0.2303,
        0.0289, 0.2928, 0.0449], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,288][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0227, 0.1996, 0.0945, 0.0944, 0.0764, 0.0665, 0.0782, 0.0688, 0.0743,
        0.0813, 0.0776, 0.0657], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,288][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.6401, 0.0522, 0.0378, 0.0345, 0.0330, 0.0317, 0.0320, 0.0271, 0.0281,
        0.0252, 0.0285, 0.0297], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,289][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0674, 0.1019, 0.0897, 0.0716, 0.0819, 0.0508, 0.0610, 0.0670, 0.0840,
        0.1027, 0.1132, 0.1087], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,289][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0842, 0.0831, 0.0895, 0.0804, 0.0924, 0.0876, 0.0835, 0.0854, 0.0806,
        0.0709, 0.0783, 0.0842], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,289][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([1.2760e-08, 9.9106e-01, 4.6395e-04, 5.7240e-03, 5.4006e-04, 1.0144e-03,
        5.2797e-04, 2.2171e-04, 1.1262e-04, 4.8685e-05, 2.2111e-04, 6.3389e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,290][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0010, 0.1495, 0.0212, 0.1087, 0.0490, 0.0401, 0.0402, 0.1362, 0.1362,
        0.0880, 0.0886, 0.1177, 0.0236], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,290][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0168, 0.0845, 0.0848, 0.1047, 0.0755, 0.0966, 0.0863, 0.0750, 0.0820,
        0.0619, 0.0834, 0.0621, 0.0865], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,292][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.1907, 0.0948, 0.0467, 0.0698, 0.0734, 0.0501, 0.0562, 0.0711, 0.0546,
        0.0734, 0.0873, 0.0891, 0.0426], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,294][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([9.0216e-05, 4.9551e-01, 5.2980e-03, 5.6180e-02, 8.2884e-03, 2.4393e-02,
        1.8306e-02, 7.8690e-02, 1.2480e-01, 5.6072e-02, 4.0402e-02, 7.3455e-02,
        1.8510e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,297][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.6668, 0.1854, 0.0086, 0.0788, 0.0047, 0.0045, 0.0037, 0.0073, 0.0049,
        0.0030, 0.0213, 0.0028, 0.0083], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,301][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0136, 0.0039, 0.0012, 0.0086, 0.0030, 0.0124, 0.0452, 0.0308, 0.0728,
        0.0572, 0.1825, 0.4128, 0.1559], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,301][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1544, 0.0848, 0.0024, 0.0342, 0.0026, 0.0538, 0.0068, 0.1047, 0.1747,
        0.0266, 0.2292, 0.0517, 0.0741], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,301][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0218, 0.2112, 0.0891, 0.0941, 0.0730, 0.0703, 0.0724, 0.0600, 0.0683,
        0.0678, 0.0675, 0.0575, 0.0470], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,302][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.6085, 0.0513, 0.0377, 0.0348, 0.0332, 0.0319, 0.0323, 0.0273, 0.0284,
        0.0254, 0.0287, 0.0297, 0.0308], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,302][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0589, 0.0858, 0.0834, 0.0596, 0.0733, 0.0445, 0.0511, 0.0622, 0.0834,
        0.0989, 0.1029, 0.1032, 0.0930], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,303][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0824, 0.0820, 0.0810, 0.0752, 0.0831, 0.0824, 0.0757, 0.0813, 0.0724,
        0.0655, 0.0706, 0.0723, 0.0763], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,303][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([3.9898e-08, 9.9375e-01, 6.0784e-04, 3.7287e-03, 5.5495e-04, 5.8871e-04,
        3.4844e-04, 1.1907e-04, 5.4066e-05, 2.7056e-05, 1.4524e-04, 6.1651e-05,
        1.0405e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,303][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0039, 0.1304, 0.0198, 0.0848, 0.0404, 0.0365, 0.0337, 0.1058, 0.1034,
        0.0695, 0.0688, 0.0872, 0.0177, 0.1982], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,304][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0084, 0.0771, 0.0858, 0.0900, 0.0724, 0.0848, 0.0836, 0.0615, 0.0767,
        0.0668, 0.0716, 0.0617, 0.0971, 0.0626], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,305][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2074, 0.0942, 0.0447, 0.0656, 0.0698, 0.0476, 0.0496, 0.0655, 0.0479,
        0.0625, 0.0799, 0.0811, 0.0394, 0.0449], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,308][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0016, 0.3468, 0.0037, 0.0185, 0.0022, 0.0149, 0.0060, 0.0361, 0.1035,
        0.0340, 0.0954, 0.0167, 0.0167, 0.3041], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,312][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5254, 0.1732, 0.0161, 0.0964, 0.0087, 0.0105, 0.0094, 0.0170, 0.0125,
        0.0084, 0.0410, 0.0087, 0.0221, 0.0506], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,314][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0307, 0.0037, 0.0013, 0.0082, 0.0021, 0.0095, 0.0436, 0.0260, 0.0453,
        0.0457, 0.1833, 0.2069, 0.2002, 0.1933], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,315][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1342, 0.0455, 0.0007, 0.0122, 0.0007, 0.0188, 0.0019, 0.0363, 0.0681,
        0.0081, 0.0883, 0.0172, 0.0299, 0.5381], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,315][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0195, 0.2246, 0.0836, 0.0885, 0.0697, 0.0678, 0.0663, 0.0552, 0.0635,
        0.0635, 0.0607, 0.0522, 0.0425, 0.0424], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,315][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5818, 0.0504, 0.0370, 0.0341, 0.0325, 0.0312, 0.0316, 0.0268, 0.0278,
        0.0250, 0.0282, 0.0292, 0.0302, 0.0341], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,316][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0670, 0.0670, 0.0851, 0.0437, 0.0713, 0.0434, 0.0407, 0.0565, 0.0793,
        0.0926, 0.0930, 0.1057, 0.0920, 0.0628], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,316][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0805, 0.0768, 0.0779, 0.0694, 0.0765, 0.0749, 0.0687, 0.0737, 0.0666,
        0.0591, 0.0644, 0.0675, 0.0709, 0.0732], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,317][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.5109e-08, 9.9424e-01, 5.3734e-04, 3.1159e-03, 4.6049e-04, 4.9750e-04,
        3.3685e-04, 9.5512e-05, 2.6315e-05, 9.8155e-06, 7.6859e-05, 3.2474e-05,
        5.1673e-06, 5.6659e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,318][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0016, 0.1122, 0.0119, 0.0732, 0.0295, 0.0309, 0.0271, 0.1058, 0.0971,
        0.0696, 0.0658, 0.0745, 0.0164, 0.2193, 0.0650], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,321][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0093, 0.0748, 0.0784, 0.0927, 0.0687, 0.0805, 0.0716, 0.0631, 0.0745,
        0.0572, 0.0718, 0.0580, 0.0817, 0.0694, 0.0484], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,325][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1675, 0.0858, 0.0391, 0.0617, 0.0649, 0.0451, 0.0478, 0.0651, 0.0484,
        0.0656, 0.0821, 0.0842, 0.0411, 0.0462, 0.0554], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,327][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([3.2528e-05, 1.7292e-01, 1.9932e-03, 1.9484e-02, 2.9295e-03, 1.2415e-02,
        6.2889e-03, 4.4093e-02, 1.2131e-01, 3.5413e-02, 6.2436e-02, 4.1155e-02,
        1.4183e-02, 4.4856e-01, 1.6782e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,328][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.5468, 0.1975, 0.0142, 0.0993, 0.0087, 0.0074, 0.0059, 0.0119, 0.0084,
        0.0052, 0.0302, 0.0052, 0.0135, 0.0356, 0.0103], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,328][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0117, 0.0018, 0.0005, 0.0031, 0.0010, 0.0034, 0.0183, 0.0156, 0.0238,
        0.0124, 0.1011, 0.1094, 0.1264, 0.3565, 0.2150], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,329][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([3.6558e-02, 2.3307e-02, 5.0898e-04, 1.0313e-02, 5.8158e-04, 1.5901e-02,
        1.5451e-03, 3.3394e-02, 6.5706e-02, 7.3048e-03, 8.0751e-02, 1.5286e-02,
        2.5888e-02, 6.2830e-01, 5.4651e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,329][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0152, 0.1875, 0.0812, 0.0824, 0.0677, 0.0640, 0.0657, 0.0559, 0.0640,
        0.0656, 0.0632, 0.0551, 0.0446, 0.0438, 0.0440], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,329][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.5745, 0.0480, 0.0349, 0.0321, 0.0306, 0.0294, 0.0297, 0.0252, 0.0263,
        0.0236, 0.0266, 0.0276, 0.0285, 0.0322, 0.0309], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,330][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0541, 0.0691, 0.0709, 0.0468, 0.0618, 0.0372, 0.0398, 0.0495, 0.0747,
        0.0915, 0.0953, 0.0931, 0.0886, 0.0677, 0.0601], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,330][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0780, 0.0715, 0.0739, 0.0650, 0.0732, 0.0708, 0.0633, 0.0681, 0.0606,
        0.0548, 0.0612, 0.0627, 0.0660, 0.0685, 0.0623], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,330][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([4.8376e-08, 9.8868e-01, 6.2199e-04, 5.0172e-03, 6.8417e-04, 9.2473e-04,
        5.3464e-04, 2.1217e-04, 6.9824e-05, 2.3425e-05, 1.7918e-04, 6.7268e-05,
        1.0573e-05, 1.6208e-03, 1.3540e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,332][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0013, 0.1177, 0.0162, 0.0717, 0.0333, 0.0303, 0.0277, 0.0900, 0.0898,
        0.0660, 0.0581, 0.0711, 0.0136, 0.1958, 0.0634, 0.0538],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,335][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0080, 0.0710, 0.0731, 0.0832, 0.0642, 0.0791, 0.0736, 0.0552, 0.0656,
        0.0597, 0.0655, 0.0548, 0.0864, 0.0602, 0.0517, 0.0487],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,339][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1657, 0.0865, 0.0397, 0.0634, 0.0647, 0.0453, 0.0468, 0.0635, 0.0464,
        0.0575, 0.0781, 0.0770, 0.0367, 0.0432, 0.0515, 0.0341],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,341][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.9901e-05, 2.2621e-01, 2.2586e-03, 2.1473e-02, 2.3256e-03, 1.2624e-02,
        7.9422e-03, 4.3222e-02, 1.1752e-01, 4.3051e-02, 5.6702e-02, 2.3484e-02,
        1.8827e-02, 3.9182e-01, 2.2551e-02, 9.8973e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,341][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6165, 0.1800, 0.0097, 0.0834, 0.0054, 0.0052, 0.0042, 0.0083, 0.0059,
        0.0035, 0.0222, 0.0034, 0.0095, 0.0254, 0.0071, 0.0101],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,342][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0046, 0.0008, 0.0004, 0.0017, 0.0013, 0.0038, 0.0116, 0.0078, 0.0175,
        0.0300, 0.0800, 0.1527, 0.0882, 0.2555, 0.3125, 0.0315],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,342][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.4995e-01, 3.3083e-02, 3.1668e-04, 6.4476e-03, 3.1071e-04, 8.9914e-03,
        9.2674e-04, 1.6140e-02, 3.0074e-02, 3.5883e-03, 3.7149e-02, 7.4909e-03,
        1.3942e-02, 2.4031e-01, 2.1949e-02, 4.2933e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,343][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0143, 0.1974, 0.0802, 0.0788, 0.0648, 0.0598, 0.0620, 0.0515, 0.0597,
        0.0618, 0.0578, 0.0508, 0.0405, 0.0403, 0.0398, 0.0406],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,343][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5630, 0.0463, 0.0337, 0.0308, 0.0294, 0.0282, 0.0286, 0.0242, 0.0252,
        0.0225, 0.0255, 0.0264, 0.0273, 0.0309, 0.0297, 0.0283],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,343][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0524, 0.0639, 0.0651, 0.0400, 0.0572, 0.0355, 0.0363, 0.0472, 0.0672,
        0.0789, 0.0826, 0.0883, 0.0793, 0.0593, 0.0573, 0.0894],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,345][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0730, 0.0672, 0.0696, 0.0613, 0.0689, 0.0671, 0.0590, 0.0645, 0.0570,
        0.0518, 0.0576, 0.0593, 0.0616, 0.0644, 0.0589, 0.0586],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,347][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.7395e-08, 9.9490e-01, 4.5305e-04, 2.4315e-03, 4.3198e-04, 3.7851e-04,
        2.1162e-04, 6.7393e-05, 1.9653e-05, 6.8585e-06, 5.3554e-05, 2.5142e-05,
        3.1385e-06, 4.9514e-04, 4.9976e-04, 2.7547e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,350][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0020, 0.0878, 0.0108, 0.0654, 0.0259, 0.0268, 0.0261, 0.0907, 0.0756,
        0.0521, 0.0598, 0.0704, 0.0174, 0.2046, 0.0680, 0.0481, 0.0684],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,354][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0113, 0.0604, 0.0670, 0.0814, 0.0601, 0.0841, 0.0729, 0.0574, 0.0671,
        0.0495, 0.0613, 0.0486, 0.0772, 0.0588, 0.0458, 0.0516, 0.0456],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,354][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1405, 0.0810, 0.0378, 0.0572, 0.0609, 0.0409, 0.0437, 0.0556, 0.0432,
        0.0590, 0.0734, 0.0774, 0.0368, 0.0414, 0.0535, 0.0333, 0.0644],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,355][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([3.2189e-05, 1.7149e-01, 1.6032e-03, 2.4596e-02, 2.4008e-03, 1.2150e-02,
        7.6860e-03, 6.5942e-02, 1.3771e-01, 6.0049e-02, 3.3546e-02, 3.0626e-02,
        1.0142e-02, 3.9398e-01, 2.6965e-02, 1.6848e-02, 4.2386e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,355][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.6242, 0.1706, 0.0084, 0.0761, 0.0044, 0.0050, 0.0042, 0.0081, 0.0058,
        0.0036, 0.0223, 0.0032, 0.0099, 0.0244, 0.0073, 0.0101, 0.0123],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,356][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([1.2403e-02, 3.9578e-04, 1.7730e-04, 1.6256e-03, 4.3716e-04, 1.3153e-03,
        8.9475e-03, 1.1192e-02, 1.6821e-02, 1.8826e-02, 5.3449e-02, 5.6680e-02,
        5.3272e-02, 1.9114e-01, 2.7937e-01, 6.6347e-02, 2.2760e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,356][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([2.1398e-02, 1.2220e-02, 3.8721e-04, 6.5744e-03, 4.4129e-04, 1.1269e-02,
        1.1509e-03, 2.2538e-02, 3.4806e-02, 4.1252e-03, 4.3134e-02, 7.6124e-03,
        1.3832e-02, 2.5924e-01, 3.1491e-02, 5.1533e-01, 1.4451e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,356][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0123, 0.1640, 0.0710, 0.0770, 0.0595, 0.0564, 0.0621, 0.0535, 0.0600,
        0.0627, 0.0613, 0.0511, 0.0415, 0.0414, 0.0407, 0.0405, 0.0452],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,357][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.5505, 0.0447, 0.0322, 0.0296, 0.0283, 0.0271, 0.0274, 0.0232, 0.0243,
        0.0218, 0.0247, 0.0255, 0.0263, 0.0300, 0.0288, 0.0274, 0.0283],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,358][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0464, 0.0662, 0.0547, 0.0421, 0.0494, 0.0331, 0.0369, 0.0458, 0.0665,
        0.0727, 0.0802, 0.0719, 0.0723, 0.0620, 0.0551, 0.0859, 0.0590],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,361][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0623, 0.0593, 0.0647, 0.0576, 0.0653, 0.0634, 0.0568, 0.0605, 0.0545,
        0.0508, 0.0541, 0.0568, 0.0605, 0.0614, 0.0559, 0.0555, 0.0606],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,363][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([7.9933e-08, 9.9138e-01, 6.4550e-04, 3.5307e-03, 7.1406e-04, 7.2111e-04,
        3.7283e-04, 1.5895e-04, 5.4407e-05, 1.7620e-05, 1.1342e-04, 5.2481e-05,
        7.3608e-06, 1.1269e-03, 1.0135e-03, 7.4519e-05, 1.7673e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,366][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0026, 0.0935, 0.0140, 0.0582, 0.0278, 0.0266, 0.0242, 0.0744, 0.0760,
        0.0587, 0.0519, 0.0628, 0.0124, 0.1516, 0.0586, 0.0460, 0.0630, 0.0976],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,368][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0062, 0.0625, 0.0693, 0.0717, 0.0579, 0.0672, 0.0660, 0.0494, 0.0615,
        0.0537, 0.0573, 0.0490, 0.0762, 0.0504, 0.0420, 0.0494, 0.0598, 0.0505],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,368][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1593, 0.0799, 0.0359, 0.0594, 0.0560, 0.0407, 0.0420, 0.0563, 0.0415,
        0.0510, 0.0722, 0.0653, 0.0324, 0.0397, 0.0457, 0.0311, 0.0575, 0.0341],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,369][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([7.1609e-05, 1.8201e-01, 1.7883e-03, 1.3406e-02, 1.4223e-03, 1.0175e-02,
        5.8363e-03, 3.6804e-02, 1.5221e-01, 4.7336e-02, 8.9210e-02, 1.9881e-02,
        1.8090e-02, 3.7132e-01, 2.3769e-02, 1.3607e-02, 2.6023e-03, 1.0462e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,369][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3367, 0.1358, 0.0207, 0.0918, 0.0137, 0.0144, 0.0136, 0.0226, 0.0182,
        0.0132, 0.0484, 0.0160, 0.0312, 0.0651, 0.0227, 0.0305, 0.0358, 0.0695],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,370][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.4326e-03, 7.6172e-04, 2.2498e-04, 2.4399e-03, 4.7328e-04, 2.4563e-03,
        1.4841e-02, 8.3032e-03, 1.8656e-02, 2.1329e-02, 8.7010e-02, 6.8248e-02,
        7.8019e-02, 9.2677e-02, 3.2491e-01, 6.7086e-02, 1.8096e-01, 2.9171e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,370][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.5167e-02, 9.1923e-03, 1.6709e-04, 2.8034e-03, 1.5661e-04, 4.4548e-03,
        4.4005e-04, 8.3127e-03, 1.5603e-02, 1.7451e-03, 1.9407e-02, 3.6577e-03,
        6.5524e-03, 1.1803e-01, 1.1425e-02, 2.5073e-01, 8.2216e-03, 5.1394e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,370][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0160, 0.1895, 0.0725, 0.0735, 0.0592, 0.0556, 0.0566, 0.0471, 0.0553,
        0.0557, 0.0534, 0.0457, 0.0368, 0.0372, 0.0364, 0.0367, 0.0373, 0.0353],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,373][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5321, 0.0436, 0.0317, 0.0291, 0.0278, 0.0266, 0.0269, 0.0227, 0.0237,
        0.0213, 0.0240, 0.0249, 0.0258, 0.0291, 0.0280, 0.0267, 0.0277, 0.0283],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,376][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0504, 0.0534, 0.0586, 0.0347, 0.0522, 0.0332, 0.0326, 0.0430, 0.0596,
        0.0698, 0.0702, 0.0780, 0.0677, 0.0483, 0.0504, 0.0767, 0.0533, 0.0679],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,379][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0625, 0.0588, 0.0623, 0.0546, 0.0604, 0.0595, 0.0531, 0.0571, 0.0520,
        0.0469, 0.0514, 0.0529, 0.0549, 0.0576, 0.0517, 0.0523, 0.0564, 0.0557],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,381][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.9972e-08, 9.9431e-01, 6.7924e-04, 2.3887e-03, 6.5582e-04, 4.3639e-04,
        2.4986e-04, 7.4597e-05, 2.5994e-05, 1.2506e-05, 5.7572e-05, 3.8604e-05,
        4.5410e-06, 4.6730e-04, 5.4831e-04, 3.2421e-05, 1.0879e-05, 6.3745e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,401][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:17,405][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,406][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,406][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,406][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,407][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,407][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,419][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,421][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,423][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,426][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,428][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,428][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,429][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2437, 0.7563], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,429][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1175, 0.8825], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,429][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4694, 0.5306], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,430][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1935, 0.8065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,430][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7255, 0.2745], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,430][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1671, 0.8329], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,431][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1852, 0.8148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,431][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0160, 0.9840], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,431][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4425, 0.5575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,433][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3644, 0.6356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,435][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7830, 0.2170], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,438][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9943e-01, 5.7073e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,442][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.0100, 0.6115, 0.3786], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,442][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.1104, 0.4965, 0.3931], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,442][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.3058, 0.5420, 0.1523], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,443][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.0345, 0.5096, 0.4559], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,443][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.6040, 0.2193, 0.1767], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,443][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.0741, 0.4569, 0.4690], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,444][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.0832, 0.5024, 0.4144], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,444][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.0065, 0.3929, 0.6007], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,444][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.2605, 0.5199, 0.2196], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,446][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.2213, 0.5177, 0.2610], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,448][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.6157, 0.2543, 0.1300], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,450][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([7.4392e-14, 1.0000e+00, 4.9680e-10], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,455][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0173, 0.3611, 0.2778, 0.3438], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,455][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0307, 0.3249, 0.3236, 0.3208], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,455][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2279, 0.3753, 0.1714, 0.2255], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,456][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0219, 0.2043, 0.2870, 0.4868], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,456][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5255, 0.1836, 0.1462, 0.1447], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,456][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0486, 0.3018, 0.3054, 0.3442], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,457][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0442, 0.2958, 0.3614, 0.2987], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,457][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0021, 0.1809, 0.2123, 0.6048], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,457][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2977, 0.3863, 0.1900, 0.1260], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,458][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1795, 0.3601, 0.2028, 0.2575], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,458][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5968, 0.1585, 0.0771, 0.1677], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,459][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.3963e-02, 9.5526e-01, 1.4592e-04, 6.3248e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,460][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.0097, 0.2726, 0.1563, 0.2715, 0.2900], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,462][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0386, 0.2774, 0.2379, 0.2894, 0.1567], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,462][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.2041, 0.3926, 0.1172, 0.1740, 0.1121], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,463][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0133, 0.1551, 0.0736, 0.5278, 0.2302], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,463][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.4588, 0.1609, 0.1288, 0.1266, 0.1249], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,463][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0327, 0.2254, 0.2384, 0.2654, 0.2381], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,466][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0344, 0.2503, 0.2578, 0.2621, 0.1954], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,470][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0011, 0.0654, 0.0997, 0.2405, 0.5935], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,471][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1023, 0.1634, 0.5940, 0.0509, 0.0894], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,471][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.1110, 0.2993, 0.1558, 0.2197, 0.2142], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,471][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.4647, 0.1648, 0.1256, 0.1306, 0.1142], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,472][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([3.6193e-16, 1.4764e-03, 5.2761e-11, 9.9852e-01, 9.8298e-13],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,472][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0083, 0.2000, 0.1460, 0.2872, 0.2664, 0.0921], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,472][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0303, 0.2137, 0.1973, 0.2295, 0.1573, 0.1719], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,473][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1780, 0.3663, 0.1126, 0.1719, 0.1018, 0.0695], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,473][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0022, 0.0655, 0.0578, 0.3634, 0.2673, 0.2438], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,475][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.4016, 0.1429, 0.1144, 0.1128, 0.1112, 0.1172], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,477][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0328, 0.1767, 0.1923, 0.2367, 0.2181, 0.1434], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,481][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0318, 0.1952, 0.2023, 0.2111, 0.1933, 0.1663], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,483][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0007, 0.0507, 0.0535, 0.1549, 0.2836, 0.4566], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,484][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.1568, 0.2392, 0.2555, 0.0726, 0.2254, 0.0505], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,484][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0613, 0.2061, 0.1116, 0.1812, 0.1682, 0.2716], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,484][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.4523, 0.1407, 0.0568, 0.1201, 0.1282, 0.1019], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,485][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([6.4963e-06, 5.5275e-01, 1.1881e-03, 1.5718e-01, 3.4624e-03, 2.8542e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,485][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0040, 0.1633, 0.0986, 0.2466, 0.2405, 0.0972, 0.1498],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,485][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.0340, 0.1779, 0.1655, 0.2053, 0.1358, 0.1551, 0.1264],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,486][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.1718, 0.3770, 0.0974, 0.1518, 0.0836, 0.0542, 0.0642],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,486][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0073, 0.0246, 0.0424, 0.1498, 0.1464, 0.1866, 0.4429],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,486][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.3629, 0.1283, 0.1026, 0.1010, 0.0994, 0.1047, 0.1012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,488][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0309, 0.1537, 0.1601, 0.1950, 0.1808, 0.1183, 0.1612],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,491][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0251, 0.1657, 0.1770, 0.1854, 0.1504, 0.1795, 0.1169],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,495][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0006, 0.0301, 0.0301, 0.0797, 0.1340, 0.2097, 0.5158],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,497][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0917, 0.1312, 0.2581, 0.0647, 0.2184, 0.0633, 0.1725],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,497][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0775, 0.1672, 0.0960, 0.1284, 0.1519, 0.2787, 0.1003],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,498][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.4491, 0.1090, 0.0517, 0.1115, 0.0713, 0.0656, 0.1417],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,498][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([2.8596e-06, 4.8556e-02, 4.9955e-09, 6.1369e-02, 1.2191e-09, 8.5542e-01,
        3.4652e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,498][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0112, 0.1443, 0.1085, 0.1981, 0.2329, 0.0753, 0.1245, 0.1052],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,499][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0175, 0.1624, 0.1598, 0.1655, 0.1114, 0.1390, 0.1338, 0.1106],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,499][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1660, 0.3452, 0.0873, 0.1490, 0.0828, 0.0542, 0.0665, 0.0491],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,499][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0057, 0.0223, 0.0209, 0.0634, 0.0498, 0.0788, 0.4864, 0.2727],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,501][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3294, 0.1161, 0.0927, 0.0914, 0.0899, 0.0944, 0.0911, 0.0950],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,503][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0236, 0.1314, 0.1433, 0.1682, 0.1550, 0.1093, 0.1416, 0.1275],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,506][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0242, 0.1437, 0.1527, 0.1586, 0.1428, 0.1528, 0.1271, 0.0981],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,509][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([2.7670e-04, 1.9236e-02, 2.1812e-02, 5.8709e-02, 1.0938e-01, 1.6349e-01,
        3.9977e-01, 2.2733e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,510][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1354, 0.1865, 0.0950, 0.0483, 0.1142, 0.0633, 0.1610, 0.1962],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,511][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1210, 0.1942, 0.0905, 0.1068, 0.0966, 0.2164, 0.0872, 0.0873],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,511][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.3278, 0.1210, 0.0694, 0.0995, 0.0693, 0.0434, 0.1087, 0.1607],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,511][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.2683e-03, 3.1596e-04, 1.1371e-09, 3.5016e-06, 6.0249e-10, 1.5415e-03,
        4.2538e-02, 9.5333e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,512][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0069, 0.1641, 0.1136, 0.1460, 0.1800, 0.0601, 0.0896, 0.0866, 0.1532],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,512][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0135, 0.1503, 0.1359, 0.1500, 0.0929, 0.1238, 0.1238, 0.1021, 0.1077],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,512][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1430, 0.3280, 0.0883, 0.1518, 0.0798, 0.0555, 0.0659, 0.0504, 0.0373],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,513][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0042, 0.0160, 0.0101, 0.0447, 0.0400, 0.0489, 0.2914, 0.3571, 0.1874],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,513][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3017, 0.1058, 0.0843, 0.0832, 0.0821, 0.0863, 0.0831, 0.0864, 0.0871],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,515][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0141, 0.1133, 0.1189, 0.1388, 0.1356, 0.0950, 0.1258, 0.1196, 0.1388],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,517][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0169, 0.1217, 0.1398, 0.1395, 0.1231, 0.1300, 0.1137, 0.0946, 0.1207],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,519][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.4360e-04, 1.6893e-02, 2.0931e-02, 5.0368e-02, 1.0148e-01, 1.3630e-01,
        3.2368e-01, 1.8601e-01, 1.6409e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,524][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1104, 0.1493, 0.1387, 0.0465, 0.1162, 0.0560, 0.1689, 0.1696, 0.0444],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,524][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0560, 0.1326, 0.0887, 0.0952, 0.1197, 0.2013, 0.0822, 0.1055, 0.1187],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,524][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3494, 0.0955, 0.0424, 0.0911, 0.0637, 0.0584, 0.0876, 0.1216, 0.0901],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,525][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([4.5941e-10, 4.9421e-06, 1.2467e-12, 3.5829e-07, 3.4538e-12, 1.1930e-04,
        3.3470e-04, 9.9954e-01, 7.1431e-11], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,525][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0073, 0.1061, 0.0488, 0.1458, 0.1171, 0.0532, 0.0680, 0.1141, 0.1644,
        0.1751], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,525][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0172, 0.1321, 0.1094, 0.1422, 0.0791, 0.1123, 0.1049, 0.0989, 0.1110,
        0.0927], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,526][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1325, 0.3088, 0.0882, 0.1390, 0.0815, 0.0510, 0.0623, 0.0478, 0.0347,
        0.0543], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,526][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0122, 0.0100, 0.0054, 0.0209, 0.0163, 0.0255, 0.1259, 0.2142, 0.2141,
        0.3554], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,527][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.2786, 0.0977, 0.0776, 0.0766, 0.0753, 0.0792, 0.0763, 0.0798, 0.0801,
        0.0788], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,530][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0173, 0.0966, 0.1077, 0.1233, 0.1229, 0.0732, 0.1102, 0.1125, 0.1246,
        0.1116], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,532][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0153, 0.1152, 0.1207, 0.1274, 0.1089, 0.1175, 0.1009, 0.0797, 0.1118,
        0.1026], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,535][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([2.1176e-04, 1.3539e-02, 1.7423e-02, 4.1273e-02, 8.2947e-02, 1.1658e-01,
        2.6730e-01, 1.5449e-01, 1.2945e-01, 1.7678e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,537][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0988, 0.1763, 0.1271, 0.0568, 0.0956, 0.0368, 0.1863, 0.1271, 0.0509,
        0.0441], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,537][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0585, 0.1037, 0.0650, 0.0770, 0.0908, 0.1980, 0.0831, 0.1015, 0.1381,
        0.0843], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,538][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.2996, 0.0960, 0.0382, 0.0884, 0.0444, 0.0457, 0.0678, 0.0899, 0.0765,
        0.1535], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,538][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([1.0797e-10, 7.0744e-07, 5.3675e-13, 9.4608e-07, 1.5649e-11, 7.5857e-05,
        1.3634e-03, 9.9856e-01, 2.6471e-06, 3.0853e-08], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,538][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0037, 0.1184, 0.0775, 0.1372, 0.1488, 0.0489, 0.0678, 0.0752, 0.1485,
        0.1413, 0.0327], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,539][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0111, 0.1160, 0.1165, 0.1155, 0.0755, 0.0978, 0.0941, 0.0853, 0.0970,
        0.0963, 0.0950], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,539][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1412, 0.2758, 0.0756, 0.1295, 0.0690, 0.0496, 0.0605, 0.0455, 0.0352,
        0.0550, 0.0630], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,539][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0017, 0.0061, 0.0083, 0.0128, 0.0216, 0.0268, 0.1219, 0.1082, 0.1454,
        0.4368, 0.1104], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,540][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2552, 0.0897, 0.0717, 0.0705, 0.0695, 0.0730, 0.0703, 0.0731, 0.0733,
        0.0720, 0.0815], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,542][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0114, 0.0940, 0.0955, 0.1092, 0.1060, 0.0757, 0.0956, 0.0943, 0.1173,
        0.1025, 0.0986], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,544][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0145, 0.0946, 0.1107, 0.1011, 0.0983, 0.1025, 0.0818, 0.0748, 0.0991,
        0.1113, 0.1112], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,548][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0003, 0.0134, 0.0156, 0.0397, 0.0698, 0.1026, 0.2383, 0.1386, 0.1196,
        0.1382, 0.1239], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,550][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1170, 0.1071, 0.1362, 0.0438, 0.1348, 0.0341, 0.1645, 0.1204, 0.0508,
        0.0730, 0.0182], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,551][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0647, 0.1193, 0.0690, 0.0758, 0.0833, 0.1601, 0.0626, 0.0729, 0.1200,
        0.0824, 0.0900], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,551][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.2893, 0.0707, 0.0359, 0.0652, 0.0498, 0.0320, 0.0827, 0.0989, 0.0585,
        0.0961, 0.1209], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,552][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([5.1222e-05, 8.2093e-07, 7.0059e-11, 3.3586e-08, 1.6183e-09, 1.8869e-05,
        3.9633e-03, 9.9594e-01, 4.5206e-08, 2.7182e-05, 2.6421e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,552][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.0065, 0.1017, 0.0495, 0.0979, 0.1003, 0.0395, 0.0616, 0.0651, 0.1092,
        0.1473, 0.0325, 0.1890], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,552][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0148, 0.1115, 0.0958, 0.1166, 0.0605, 0.0993, 0.0929, 0.0862, 0.0932,
        0.0809, 0.0928, 0.0555], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,553][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.1436, 0.3044, 0.0758, 0.1239, 0.0672, 0.0413, 0.0491, 0.0394, 0.0267,
        0.0419, 0.0536, 0.0331], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,553][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0096, 0.0050, 0.0018, 0.0091, 0.0037, 0.0154, 0.0606, 0.1260, 0.0824,
        0.1607, 0.1892, 0.3365], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,555][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.2367, 0.0831, 0.0664, 0.0651, 0.0644, 0.0674, 0.0647, 0.0676, 0.0679,
        0.0664, 0.0755, 0.0749], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,559][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0108, 0.0839, 0.0889, 0.0966, 0.0876, 0.0661, 0.0842, 0.0965, 0.1009,
        0.0952, 0.0982, 0.0912], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,562][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0124, 0.0918, 0.0982, 0.0979, 0.0737, 0.0977, 0.0798, 0.0668, 0.0924,
        0.1021, 0.1144, 0.0730], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,564][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([1.7006e-04, 8.2591e-03, 1.3402e-02, 2.6837e-02, 6.6958e-02, 8.2651e-02,
        2.0151e-01, 1.1837e-01, 9.1788e-02, 1.1057e-01, 9.7235e-02, 1.8225e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,564][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.0712, 0.0910, 0.3270, 0.0273, 0.0559, 0.0468, 0.1359, 0.0766, 0.0388,
        0.0650, 0.0169, 0.0476], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,564][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0434, 0.1113, 0.0576, 0.0775, 0.0836, 0.1397, 0.0503, 0.0711, 0.1102,
        0.0787, 0.1012, 0.0753], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,565][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.2190, 0.0796, 0.0572, 0.0620, 0.0534, 0.0550, 0.0417, 0.0701, 0.0662,
        0.1004, 0.1412, 0.0542], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,565][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([2.4190e-12, 5.0651e-05, 6.2124e-14, 2.1283e-05, 2.5340e-16, 2.7406e-05,
        5.1023e-04, 3.6456e-01, 2.0761e-07, 6.5367e-07, 6.3483e-01, 8.0120e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,565][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0017, 0.0632, 0.0450, 0.1025, 0.1156, 0.0384, 0.0634, 0.0723, 0.1143,
        0.1273, 0.0310, 0.2082, 0.0172], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,566][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0180, 0.0989, 0.0801, 0.1076, 0.0629, 0.0870, 0.0813, 0.0834, 0.0814,
        0.0719, 0.0891, 0.0580, 0.0804], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,566][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1351, 0.2805, 0.0697, 0.1193, 0.0591, 0.0421, 0.0499, 0.0369, 0.0276,
        0.0436, 0.0548, 0.0323, 0.0490], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,567][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0005, 0.0012, 0.0015, 0.0053, 0.0047, 0.0051, 0.0477, 0.0535, 0.0377,
        0.0878, 0.0811, 0.4663, 0.2076], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,568][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.2248, 0.0780, 0.0618, 0.0610, 0.0599, 0.0632, 0.0607, 0.0632, 0.0634,
        0.0622, 0.0705, 0.0698, 0.0617], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,571][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0163, 0.0728, 0.0758, 0.0932, 0.0883, 0.0619, 0.0785, 0.0861, 0.0963,
        0.0820, 0.0875, 0.0920, 0.0693], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,575][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0169, 0.0826, 0.0860, 0.0912, 0.0792, 0.0855, 0.0758, 0.0628, 0.0832,
        0.0913, 0.0958, 0.0781, 0.0716], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,577][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0002, 0.0107, 0.0121, 0.0283, 0.0517, 0.0729, 0.1641, 0.0960, 0.0831,
        0.0899, 0.0841, 0.1344, 0.1726], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,578][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0744, 0.0804, 0.0698, 0.0443, 0.0832, 0.0385, 0.2262, 0.1010, 0.0361,
        0.0488, 0.0165, 0.0600, 0.1207], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,578][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0416, 0.0855, 0.0473, 0.0746, 0.0632, 0.1404, 0.0568, 0.0888, 0.0952,
        0.0671, 0.0842, 0.0600, 0.0953], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,578][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.2210, 0.0691, 0.0275, 0.0769, 0.0372, 0.0466, 0.0581, 0.0830, 0.0630,
        0.0904, 0.1029, 0.0376, 0.0867], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,579][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([1.1451e-09, 1.0241e-05, 4.1046e-11, 1.5303e-06, 1.2983e-10, 1.1515e-05,
        6.5773e-04, 8.6811e-01, 5.5060e-08, 4.2840e-06, 1.1423e-03, 1.0391e-01,
        2.6152e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,579][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0044, 0.0847, 0.0660, 0.1034, 0.1236, 0.0373, 0.0621, 0.0520, 0.1138,
        0.1076, 0.0238, 0.1488, 0.0105, 0.0619], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,580][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0084, 0.0903, 0.0875, 0.0938, 0.0598, 0.0747, 0.0761, 0.0673, 0.0740,
        0.0720, 0.0775, 0.0546, 0.0861, 0.0778], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,580][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1187, 0.2587, 0.0731, 0.1164, 0.0657, 0.0440, 0.0497, 0.0363, 0.0269,
        0.0412, 0.0478, 0.0345, 0.0469, 0.0401], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,582][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0020, 0.0020, 0.0014, 0.0043, 0.0030, 0.0058, 0.0293, 0.0360, 0.0259,
        0.0792, 0.0712, 0.2144, 0.1856, 0.3398], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,584][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2116, 0.0736, 0.0586, 0.0577, 0.0566, 0.0598, 0.0575, 0.0597, 0.0600,
        0.0589, 0.0667, 0.0659, 0.0583, 0.0552], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,588][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0103, 0.0707, 0.0739, 0.0853, 0.0838, 0.0592, 0.0764, 0.0712, 0.0889,
        0.0778, 0.0781, 0.0863, 0.0702, 0.0679], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,591][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0110, 0.0721, 0.0814, 0.0825, 0.0765, 0.0830, 0.0703, 0.0612, 0.0761,
        0.0826, 0.0831, 0.0749, 0.0779, 0.0674], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,591][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0002, 0.0111, 0.0115, 0.0272, 0.0445, 0.0634, 0.1412, 0.0844, 0.0702,
        0.0756, 0.0662, 0.1088, 0.1409, 0.1549], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,591][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0894, 0.0966, 0.0594, 0.0339, 0.0881, 0.0266, 0.1293, 0.1016, 0.0346,
        0.0512, 0.0158, 0.0669, 0.1389, 0.0676], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,592][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0424, 0.0783, 0.0508, 0.0581, 0.0583, 0.1160, 0.0548, 0.0590, 0.0825,
        0.0619, 0.0835, 0.0530, 0.1248, 0.0765], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,592][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1905, 0.0663, 0.0336, 0.0653, 0.0374, 0.0283, 0.0647, 0.0876, 0.0633,
        0.0810, 0.1059, 0.0402, 0.0622, 0.0738], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,592][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.2986e-06, 1.2408e-07, 2.2931e-14, 4.2036e-11, 2.6858e-15, 2.8402e-08,
        3.4385e-06, 1.4429e-04, 1.7300e-13, 5.5209e-10, 5.5733e-07, 7.0267e-07,
        2.8895e-03, 9.9696e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,593][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0034, 0.0641, 0.0326, 0.0890, 0.0874, 0.0337, 0.0492, 0.0671, 0.1032,
        0.1206, 0.0280, 0.1482, 0.0108, 0.0757, 0.0868], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,593][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0098, 0.0869, 0.0760, 0.0950, 0.0567, 0.0717, 0.0650, 0.0687, 0.0717,
        0.0630, 0.0754, 0.0521, 0.0728, 0.0843, 0.0510], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,595][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1166, 0.2451, 0.0615, 0.1118, 0.0602, 0.0406, 0.0501, 0.0334, 0.0271,
        0.0467, 0.0516, 0.0349, 0.0477, 0.0435, 0.0292], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,598][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0005, 0.0006, 0.0006, 0.0021, 0.0019, 0.0026, 0.0108, 0.0195, 0.0105,
        0.0291, 0.0301, 0.1707, 0.0605, 0.2512, 0.4094], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,602][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.1991, 0.0700, 0.0557, 0.0550, 0.0539, 0.0570, 0.0547, 0.0568, 0.0570,
        0.0562, 0.0635, 0.0626, 0.0555, 0.0525, 0.0505], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,604][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0103, 0.0686, 0.0666, 0.0829, 0.0747, 0.0525, 0.0681, 0.0713, 0.0818,
        0.0685, 0.0753, 0.0756, 0.0650, 0.0756, 0.0629], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,604][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0113, 0.0710, 0.0737, 0.0785, 0.0676, 0.0793, 0.0665, 0.0541, 0.0716,
        0.0773, 0.0836, 0.0672, 0.0723, 0.0663, 0.0597], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,605][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0002, 0.0087, 0.0091, 0.0216, 0.0363, 0.0537, 0.1197, 0.0698, 0.0593,
        0.0651, 0.0584, 0.0920, 0.1190, 0.1344, 0.1525], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,605][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0800, 0.0819, 0.0489, 0.0284, 0.0636, 0.0329, 0.0948, 0.1104, 0.0254,
        0.0488, 0.0129, 0.0509, 0.1820, 0.0643, 0.0747], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,606][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0293, 0.0745, 0.0467, 0.0560, 0.0430, 0.1000, 0.0602, 0.0639, 0.0800,
        0.0538, 0.0683, 0.0392, 0.1469, 0.0894, 0.0489], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,606][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.2227, 0.0529, 0.0224, 0.0641, 0.0361, 0.0290, 0.0514, 0.0789, 0.0616,
        0.0664, 0.1035, 0.0360, 0.0542, 0.0668, 0.0539], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,606][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([1.0895e-10, 1.8557e-10, 1.5568e-16, 1.1380e-11, 2.1304e-16, 5.7626e-10,
        1.5884e-09, 1.2381e-05, 1.0013e-14, 9.8960e-13, 6.5269e-08, 5.7767e-08,
        3.3791e-06, 9.9946e-01, 5.2372e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,608][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0021, 0.0788, 0.0546, 0.0900, 0.0936, 0.0294, 0.0512, 0.0485, 0.0939,
        0.1020, 0.0246, 0.1342, 0.0080, 0.0619, 0.0690, 0.0582],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,612][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0087, 0.0836, 0.0728, 0.0865, 0.0520, 0.0694, 0.0669, 0.0607, 0.0634,
        0.0649, 0.0689, 0.0477, 0.0764, 0.0726, 0.0543, 0.0513],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,615][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1240, 0.2746, 0.0612, 0.1127, 0.0564, 0.0380, 0.0443, 0.0299, 0.0230,
        0.0398, 0.0450, 0.0281, 0.0413, 0.0368, 0.0241, 0.0209],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,617][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.5399e-04, 3.9872e-04, 2.5779e-04, 1.7451e-03, 8.2971e-04, 1.4105e-03,
        9.9755e-03, 1.2013e-02, 6.5941e-03, 2.3143e-02, 2.0140e-02, 6.6092e-02,
        7.1684e-02, 2.3815e-01, 5.2494e-01, 2.2470e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,619][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1911, 0.0665, 0.0527, 0.0522, 0.0512, 0.0542, 0.0521, 0.0539, 0.0543,
        0.0533, 0.0603, 0.0596, 0.0528, 0.0499, 0.0479, 0.0481],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,620][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0075, 0.0612, 0.0634, 0.0717, 0.0714, 0.0523, 0.0636, 0.0620, 0.0754,
        0.0723, 0.0700, 0.0747, 0.0605, 0.0651, 0.0599, 0.0690],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,620][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0091, 0.0634, 0.0710, 0.0731, 0.0650, 0.0714, 0.0601, 0.0515, 0.0680,
        0.0737, 0.0783, 0.0649, 0.0747, 0.0628, 0.0636, 0.0496],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,620][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.0944e-04, 6.6267e-03, 8.0079e-03, 1.8626e-02, 3.7318e-02, 4.7838e-02,
        1.1202e-01, 6.4073e-02, 5.2917e-02, 6.0303e-02, 5.3543e-02, 9.3564e-02,
        1.1507e-01, 1.2270e-01, 1.3750e-01, 6.9786e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,621][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0501, 0.0795, 0.0672, 0.0244, 0.0730, 0.0286, 0.0861, 0.0817, 0.0312,
        0.0608, 0.0114, 0.0542, 0.1308, 0.0524, 0.0917, 0.0770],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,621][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0345, 0.0818, 0.0459, 0.0547, 0.0589, 0.1107, 0.0486, 0.0599, 0.0642,
        0.0501, 0.0708, 0.0549, 0.1074, 0.0702, 0.0499, 0.0374],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,622][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1429, 0.0577, 0.0334, 0.0514, 0.0425, 0.0334, 0.0537, 0.0804, 0.0501,
        0.0814, 0.0987, 0.0452, 0.0648, 0.0599, 0.0464, 0.0582],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,622][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.3430e-15, 2.2556e-12, 2.4542e-19, 1.1680e-12, 2.0498e-19, 4.9127e-10,
        1.4574e-10, 3.8622e-06, 7.6955e-17, 3.1243e-13, 5.6779e-09, 1.0142e-10,
        1.2281e-06, 9.7783e-01, 2.2161e-02, 2.9898e-13], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,624][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0039, 0.0482, 0.0270, 0.0844, 0.0722, 0.0286, 0.0457, 0.0580, 0.0865,
        0.0905, 0.0243, 0.1356, 0.0097, 0.0667, 0.0754, 0.0544, 0.0888],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,626][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0116, 0.0731, 0.0626, 0.0819, 0.0459, 0.0694, 0.0636, 0.0618, 0.0657,
        0.0545, 0.0642, 0.0429, 0.0685, 0.0764, 0.0494, 0.0564, 0.0523],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,630][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1274, 0.2691, 0.0615, 0.1059, 0.0540, 0.0353, 0.0420, 0.0297, 0.0217,
        0.0369, 0.0431, 0.0265, 0.0397, 0.0330, 0.0238, 0.0208, 0.0295],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,633][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([5.8711e-04, 3.0210e-04, 1.6577e-04, 1.2803e-03, 4.9566e-04, 1.2613e-03,
        6.2021e-03, 9.5842e-03, 9.0621e-03, 3.9055e-02, 1.4010e-02, 4.9718e-02,
        3.1371e-02, 1.2963e-01, 4.1826e-01, 4.2568e-02, 2.4646e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,633][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1830, 0.0636, 0.0501, 0.0496, 0.0487, 0.0514, 0.0495, 0.0516, 0.0517,
        0.0508, 0.0575, 0.0568, 0.0503, 0.0475, 0.0456, 0.0457, 0.0466],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,634][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0094, 0.0566, 0.0596, 0.0687, 0.0683, 0.0423, 0.0580, 0.0645, 0.0693,
        0.0639, 0.0656, 0.0720, 0.0557, 0.0613, 0.0564, 0.0674, 0.0610],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,634][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0098, 0.0652, 0.0709, 0.0687, 0.0576, 0.0717, 0.0510, 0.0477, 0.0623,
        0.0662, 0.0719, 0.0571, 0.0747, 0.0590, 0.0646, 0.0517, 0.0499],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,634][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0001, 0.0063, 0.0079, 0.0173, 0.0343, 0.0454, 0.1038, 0.0580, 0.0476,
        0.0572, 0.0490, 0.0859, 0.1011, 0.1084, 0.1216, 0.0602, 0.0959],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,635][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0687, 0.0704, 0.0722, 0.0268, 0.0910, 0.0197, 0.0936, 0.0394, 0.0343,
        0.0456, 0.0128, 0.0728, 0.1007, 0.0452, 0.0686, 0.0717, 0.0665],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,635][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0310, 0.0679, 0.0412, 0.0492, 0.0615, 0.1080, 0.0416, 0.0565, 0.0764,
        0.0515, 0.0610, 0.0567, 0.0924, 0.0648, 0.0476, 0.0542, 0.0385],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,636][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.2239, 0.0429, 0.0246, 0.0368, 0.0401, 0.0272, 0.0406, 0.0460, 0.0425,
        0.0810, 0.0718, 0.0440, 0.0554, 0.0490, 0.0417, 0.0471, 0.0852],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,637][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([1.9936e-13, 1.6069e-11, 7.4491e-20, 3.2656e-12, 3.7258e-20, 4.0342e-11,
        5.5474e-10, 7.4587e-07, 9.4499e-13, 1.1690e-13, 6.1999e-07, 5.5117e-11,
        1.4529e-06, 9.8908e-01, 1.0919e-02, 3.5008e-08, 1.6858e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,640][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0030, 0.0737, 0.0510, 0.0760, 0.0899, 0.0275, 0.0469, 0.0386, 0.0873,
        0.1068, 0.0191, 0.1065, 0.0068, 0.0440, 0.0603, 0.0548, 0.0731, 0.0346],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,643][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0051, 0.0716, 0.0705, 0.0752, 0.0460, 0.0585, 0.0593, 0.0537, 0.0590,
        0.0566, 0.0605, 0.0418, 0.0669, 0.0612, 0.0422, 0.0502, 0.0636, 0.0583],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,647][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1046, 0.2019, 0.0621, 0.0980, 0.0593, 0.0416, 0.0467, 0.0339, 0.0266,
        0.0402, 0.0435, 0.0327, 0.0434, 0.0391, 0.0261, 0.0240, 0.0334, 0.0428],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,647][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.0980e-04, 3.0873e-04, 1.8188e-04, 9.9797e-04, 4.1777e-04, 1.2296e-03,
        7.4669e-03, 7.6662e-03, 7.1801e-03, 2.0052e-02, 2.1001e-02, 4.1204e-02,
        5.1170e-02, 1.0844e-01, 4.6754e-01, 3.1916e-02, 1.9330e-01, 3.9821e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,647][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1750, 0.0607, 0.0483, 0.0476, 0.0467, 0.0495, 0.0474, 0.0493, 0.0494,
        0.0487, 0.0550, 0.0543, 0.0482, 0.0456, 0.0438, 0.0438, 0.0446, 0.0421],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,648][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0074, 0.0540, 0.0564, 0.0651, 0.0640, 0.0453, 0.0578, 0.0544, 0.0676,
        0.0601, 0.0594, 0.0657, 0.0540, 0.0516, 0.0554, 0.0663, 0.0635, 0.0519],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,648][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0077, 0.0555, 0.0637, 0.0636, 0.0604, 0.0653, 0.0550, 0.0480, 0.0595,
        0.0655, 0.0646, 0.0589, 0.0618, 0.0522, 0.0609, 0.0475, 0.0623, 0.0477],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,649][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([8.9706e-05, 5.6365e-03, 7.3399e-03, 1.7073e-02, 3.2648e-02, 4.2156e-02,
        9.4352e-02, 5.3860e-02, 4.5527e-02, 5.2243e-02, 4.5796e-02, 8.1767e-02,
        9.7223e-02, 1.0181e-01, 1.1364e-01, 5.8878e-02, 9.1186e-02, 5.8776e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,649][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0656, 0.0718, 0.0436, 0.0239, 0.0689, 0.0187, 0.0903, 0.0705, 0.0273,
        0.0400, 0.0125, 0.0559, 0.0949, 0.0495, 0.0811, 0.0713, 0.0562, 0.0582],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,649][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0317, 0.0637, 0.0416, 0.0473, 0.0476, 0.0934, 0.0437, 0.0468, 0.0671,
        0.0502, 0.0687, 0.0428, 0.0975, 0.0603, 0.0413, 0.0501, 0.0475, 0.0588],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,651][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1571, 0.0515, 0.0263, 0.0532, 0.0297, 0.0225, 0.0524, 0.0725, 0.0518,
        0.0626, 0.0849, 0.0317, 0.0495, 0.0602, 0.0369, 0.0585, 0.0407, 0.0578],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,653][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.7357e-15, 1.0489e-10, 2.7277e-17, 4.4889e-12, 1.1771e-17, 1.0851e-09,
        2.2841e-07, 3.7586e-05, 1.3605e-13, 4.5320e-10, 8.3731e-09, 4.3988e-08,
        1.9734e-04, 2.1207e-01, 7.7637e-01, 1.9568e-09, 1.1319e-02, 1.0376e-07],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,654][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:17,656][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5666],
        [ 8003],
        [11648],
        [10529],
        [ 6631],
        [23491],
        [ 6182],
        [ 8729],
        [21602],
        [11074],
        [ 6331],
        [13112],
        [14588],
        [ 6683],
        [10260],
        [15546],
        [20747],
        [ 6505]], device='cuda:0')
[2024-07-24 10:30:17,658][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5718],
        [ 5712],
        [13149],
        [ 9849],
        [ 8686],
        [22589],
        [ 8816],
        [11880],
        [33247],
        [22973],
        [10661],
        [23505],
        [20267],
        [12636],
        [15726],
        [31515],
        [33255],
        [16527]], device='cuda:0')
[2024-07-24 10:30:17,661][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 4980],
        [22265],
        [22077],
        [16907],
        [16709],
        [16083],
        [15319],
        [13019],
        [12257],
        [11478],
        [11763],
        [11226],
        [11088],
        [10825],
        [10989],
        [11272],
        [11163],
        [11293]], device='cuda:0')
[2024-07-24 10:30:17,663][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15150],
        [17760],
        [21708],
        [25239],
        [23601],
        [23295],
        [23154],
        [22836],
        [22342],
        [23111],
        [23504],
        [23180],
        [25304],
        [25924],
        [26026],
        [26274],
        [26021],
        [26134]], device='cuda:0')
[2024-07-24 10:30:17,664][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[27897],
        [24437],
        [21226],
        [20126],
        [20031],
        [21317],
        [21482],
        [20660],
        [21143],
        [20938],
        [21392],
        [21605],
        [21567],
        [21430],
        [21476],
        [21526],
        [21527],
        [21407]], device='cuda:0')
[2024-07-24 10:30:17,665][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15547],
        [ 4706],
        [ 4801],
        [ 4349],
        [ 4169],
        [ 4518],
        [ 4380],
        [ 4458],
        [ 4776],
        [ 4285],
        [ 4497],
        [ 4898],
        [ 5426],
        [ 5839],
        [ 6086],
        [ 5684],
        [ 5389],
        [ 6194]], device='cuda:0')
[2024-07-24 10:30:17,666][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[3487],
        [2097],
        [1581],
        [1084],
        [1513],
        [1596],
        [1702],
        [1786],
        [1625],
        [1636],
        [1343],
        [1825],
        [1631],
        [1492],
        [1535],
        [1591],
        [1612],
        [1881]], device='cuda:0')
[2024-07-24 10:30:17,668][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 3260],
        [ 1955],
        [20779],
        [ 9938],
        [15368],
        [20769],
        [20467],
        [17729],
        [15627],
        [16933],
        [12898],
        [13953],
        [19509],
        [10132],
        [ 7163],
        [ 7870],
        [ 5452],
        [ 5833]], device='cuda:0')
[2024-07-24 10:30:17,669][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[40198],
        [29549],
        [31156],
        [16566],
        [15114],
        [14405],
        [ 9897],
        [11116],
        [ 9441],
        [ 6243],
        [ 9830],
        [ 8554],
        [ 9347],
        [ 9529],
        [ 8699],
        [ 8640],
        [ 7791],
        [ 8292]], device='cuda:0')
[2024-07-24 10:30:17,671][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40044],
        [14673],
        [14879],
        [15319],
        [15567],
        [15732],
        [15795],
        [15880],
        [16130],
        [15967],
        [16008],
        [16121],
        [16061],
        [15901],
        [15860],
        [15823],
        [15816],
        [15736]], device='cuda:0')
[2024-07-24 10:30:17,672][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38733],
        [38719],
        [38708],
        [38662],
        [38664],
        [38525],
        [38470],
        [38408],
        [38207],
        [38135],
        [37986],
        [37855],
        [37737],
        [37670],
        [37617],
        [37583],
        [37524],
        [37421]], device='cuda:0')
[2024-07-24 10:30:17,675][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10129],
        [ 7920],
        [ 7760],
        [ 7988],
        [ 7936],
        [ 8104],
        [ 8006],
        [ 8060],
        [ 8300],
        [ 8482],
        [ 8095],
        [ 7728],
        [ 8078],
        [ 8153],
        [ 8064],
        [ 8373],
        [ 8333],
        [ 8241]], device='cuda:0')
[2024-07-24 10:30:17,677][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32478],
        [28322],
        [34478],
        [30477],
        [33252],
        [29283],
        [26894],
        [25956],
        [25771],
        [26518],
        [27288],
        [28747],
        [28505],
        [29325],
        [30116],
        [30768],
        [30502],
        [30870]], device='cuda:0')
[2024-07-24 10:30:17,680][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21240],
        [17325],
        [17320],
        [17257],
        [17264],
        [17275],
        [17236],
        [17173],
        [17269],
        [17268],
        [17238],
        [17266],
        [17284],
        [17286],
        [17246],
        [17292],
        [17267],
        [17289]], device='cuda:0')
[2024-07-24 10:30:17,681][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7377],
        [35859],
        [17371],
        [17422],
        [17018],
        [25220],
        [ 9934],
        [18306],
        [10619],
        [ 4150],
        [11840],
        [ 8817],
        [12441],
        [11354],
        [10090],
        [10423],
        [12027],
        [11109]], device='cuda:0')
[2024-07-24 10:30:17,682][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26535],
        [34364],
        [30548],
        [30959],
        [32131],
        [31396],
        [30266],
        [29911],
        [29677],
        [27506],
        [28217],
        [28527],
        [28656],
        [28579],
        [27179],
        [27237],
        [26681],
        [26915]], device='cuda:0')
[2024-07-24 10:30:17,683][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29448],
        [25661],
        [25946],
        [26552],
        [27690],
        [27698],
        [28097],
        [28237],
        [28191],
        [28527],
        [28866],
        [29008],
        [29080],
        [29418],
        [30033],
        [30032],
        [30088],
        [30206]], device='cuda:0')
[2024-07-24 10:30:17,684][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15318],
        [16670],
        [17719],
        [16418],
        [16860],
        [16676],
        [16762],
        [15828],
        [15710],
        [15720],
        [15526],
        [14968],
        [14679],
        [14144],
        [13847],
        [13996],
        [13872],
        [13178]], device='cuda:0')
[2024-07-24 10:30:17,685][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15841],
        [15367],
        [30494],
        [31421],
        [31599],
        [31604],
        [31727],
        [34179],
        [31377],
        [21275],
        [17894],
        [31297],
        [35001],
        [27453],
        [28347],
        [24768],
        [29904],
        [28483]], device='cuda:0')
[2024-07-24 10:30:17,688][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13030],
        [11552],
        [10914],
        [10412],
        [10173],
        [ 9812],
        [ 9772],
        [ 9729],
        [ 9619],
        [ 9733],
        [ 9681],
        [ 9631],
        [ 9598],
        [ 9510],
        [ 9486],
        [ 9431],
        [ 9424],
        [ 9375]], device='cuda:0')
[2024-07-24 10:30:17,689][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14640],
        [ 8172],
        [10115],
        [ 8380],
        [ 9303],
        [ 8279],
        [ 9068],
        [ 9517],
        [ 9645],
        [ 9866],
        [ 9368],
        [ 9633],
        [ 9477],
        [ 9237],
        [ 8927],
        [ 8255],
        [ 7991],
        [ 7789]], device='cuda:0')
[2024-07-24 10:30:17,691][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32387],
        [37464],
        [37680],
        [38380],
        [38099],
        [38696],
        [39033],
        [38927],
        [38729],
        [38480],
        [38539],
        [38487],
        [38614],
        [38624],
        [38286],
        [38257],
        [38072],
        [37917]], device='cuda:0')
[2024-07-24 10:30:17,694][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24806],
        [10959],
        [11016],
        [11866],
        [11007],
        [10426],
        [ 9453],
        [10134],
        [10065],
        [ 9877],
        [ 9573],
        [ 9175],
        [ 8994],
        [ 9098],
        [ 8921],
        [ 8950],
        [ 8948],
        [ 8933]], device='cuda:0')
[2024-07-24 10:30:17,696][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[28449],
        [27598],
        [20922],
        [21516],
        [12831],
        [20885],
        [20877],
        [26883],
        [24963],
        [23195],
        [21911],
        [16722],
        [23971],
        [23344],
        [22195],
        [20569],
        [21243],
        [21938]], device='cuda:0')
[2024-07-24 10:30:17,697][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24152],
        [27653],
        [22947],
        [22286],
        [21795],
        [22111],
        [23354],
        [24089],
        [24198],
        [24318],
        [24215],
        [24005],
        [24636],
        [24835],
        [25567],
        [25272],
        [24715],
        [24725]], device='cuda:0')
[2024-07-24 10:30:17,698][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1538],
        [3137],
        [3640],
        [3539],
        [4650],
        [6069],
        [4231],
        [3680],
        [4053],
        [3694],
        [4036],
        [4923],
        [4651],
        [4427],
        [4241],
        [4235],
        [4531],
        [4276]], device='cuda:0')
[2024-07-24 10:30:17,699][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34094],
        [34096],
        [ 7812],
        [ 8436],
        [40551],
        [20610],
        [26994],
        [18675],
        [18415],
        [18414],
        [18433],
        [23538],
        [15608],
        [22421],
        [22460],
        [22382],
        [22411],
        [16022]], device='cuda:0')
[2024-07-24 10:30:17,701][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[12769],
        [17395],
        [17939],
        [18447],
        [14884],
        [16821],
        [16730],
        [17053],
        [17564],
        [19440],
        [20167],
        [18125],
        [18196],
        [19228],
        [19780],
        [20365],
        [19899],
        [20795]], device='cuda:0')
[2024-07-24 10:30:17,702][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32490],
        [ 5955],
        [16863],
        [21299],
        [27301],
        [20133],
        [24112],
        [14573],
        [21286],
        [26814],
        [22273],
        [23499],
        [17173],
        [15316],
        [18780],
        [16807],
        [17324],
        [16571]], device='cuda:0')
[2024-07-24 10:30:17,704][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821],
        [9821]], device='cuda:0')
[2024-07-24 10:30:17,738][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:17,739][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,741][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,744][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,747][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,748][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,749][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,749][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,749][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,750][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,750][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,750][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,750][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:17,751][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.3914e-05, 9.9991e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,751][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8850, 0.1150], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,753][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9838, 0.0162], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,755][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1575, 0.8425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,759][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9561, 0.0439], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,762][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8010, 0.1990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,762][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1586, 0.8414], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,762][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6973, 0.3027], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,763][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0340, 0.9660], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,763][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4715, 0.5285], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,763][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1006, 0.8994], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,764][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4855, 0.5145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:17,764][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([6.0047e-06, 7.7886e-01, 2.2113e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,764][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.2440, 0.6949, 0.0611], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,765][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.9273, 0.0277, 0.0450], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,766][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.0732, 0.4727, 0.4542], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,769][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.6358, 0.2803, 0.0839], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,773][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.2191, 0.7267, 0.0542], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,775][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.0742, 0.7599, 0.1659], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,775][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.0623, 0.0771, 0.8606], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,776][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.0122, 0.5576, 0.4302], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,776][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.3167, 0.3564, 0.3269], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,776][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.0458, 0.4891, 0.4651], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,777][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.6601, 0.2997, 0.0402], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:17,777][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([5.3396e-06, 6.2782e-01, 1.7912e-01, 1.9305e-01], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,777][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0321, 0.0144, 0.9499, 0.0037], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,778][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9110, 0.0200, 0.0378, 0.0311], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,778][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0485, 0.3244, 0.3332, 0.2939], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,780][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4111, 0.0766, 0.4373, 0.0750], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,782][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0160, 0.0595, 0.9142, 0.0103], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,786][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0638, 0.3162, 0.3613, 0.2588], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,789][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1714, 0.0941, 0.5596, 0.1749], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,789][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0082, 0.3843, 0.2943, 0.3133], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,789][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2459, 0.2776, 0.2533, 0.2232], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,790][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0272, 0.3353, 0.3177, 0.3198], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,790][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5044, 0.2676, 0.0523, 0.1757], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:17,790][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([2.5500e-06, 5.6345e-01, 1.5210e-01, 1.6668e-01, 1.1777e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,791][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0412, 0.1178, 0.8264, 0.0123, 0.0024], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,791][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.7950, 0.0311, 0.0536, 0.0523, 0.0680], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,792][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0368, 0.2465, 0.2509, 0.2333, 0.2325], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,793][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.4493, 0.1531, 0.0842, 0.2602, 0.0532], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,796][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0064, 0.0201, 0.9607, 0.0077, 0.0051], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,799][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0651, 0.3933, 0.0817, 0.2776, 0.1824], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,802][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0250, 0.0241, 0.4055, 0.0427, 0.5027], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,803][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0055, 0.3012, 0.2282, 0.2438, 0.2213], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,803][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.2005, 0.2257, 0.2064, 0.1816, 0.1858], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,803][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0206, 0.2572, 0.2435, 0.2435, 0.2352], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,804][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.6482, 0.2209, 0.0201, 0.0831, 0.0277], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:17,804][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ were] are: tensor([2.2736e-06, 5.1185e-01, 1.3493e-01, 1.4754e-01, 1.0459e-01, 1.0109e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,804][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0363, 0.0182, 0.1163, 0.0103, 0.8070, 0.0119], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,805][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.7977, 0.0257, 0.0446, 0.0399, 0.0567, 0.0354], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,805][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0296, 0.2022, 0.2000, 0.1943, 0.2029, 0.1711], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,807][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.5208, 0.0557, 0.1658, 0.1007, 0.1466, 0.0103], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,809][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0282, 0.2033, 0.2437, 0.1205, 0.3951, 0.0092], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,813][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0195, 0.1588, 0.0974, 0.1409, 0.3810, 0.2024], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,816][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0212, 0.0274, 0.3138, 0.0710, 0.4826, 0.0839], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,816][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0044, 0.2480, 0.1874, 0.1998, 0.1814, 0.1791], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,816][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.1701, 0.1913, 0.1744, 0.1534, 0.1572, 0.1536], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,817][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0158, 0.2060, 0.1952, 0.1948, 0.1890, 0.1992], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,817][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.6573, 0.1966, 0.0182, 0.0747, 0.0231, 0.0301], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:17,817][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ working] are: tensor([1.8231e-06, 4.6840e-01, 1.2139e-01, 1.3224e-01, 9.3859e-02, 9.0913e-02,
        9.3204e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,818][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ working] are: tensor([4.4337e-03, 7.4011e-02, 4.1942e-01, 1.2953e-01, 2.7982e-01, 9.2766e-02,
        1.8488e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,818][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.7932, 0.0188, 0.0320, 0.0305, 0.0404, 0.0298, 0.0553],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,818][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0229, 0.1789, 0.1700, 0.1693, 0.1739, 0.1581, 0.1270],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,820][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.1025, 0.1016, 0.2929, 0.1682, 0.3005, 0.0251, 0.0091],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,823][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0017, 0.0082, 0.6409, 0.0153, 0.3134, 0.0196, 0.0008],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,826][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0180, 0.0906, 0.0414, 0.0667, 0.0842, 0.1808, 0.5183],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,829][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0189, 0.0413, 0.3405, 0.0913, 0.4097, 0.0845, 0.0138],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,829][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0039, 0.2087, 0.1585, 0.1687, 0.1536, 0.1517, 0.1548],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,830][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.1471, 0.1662, 0.1515, 0.1331, 0.1365, 0.1336, 0.1320],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,830][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0131, 0.1716, 0.1635, 0.1631, 0.1585, 0.1661, 0.1641],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,831][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.7109, 0.1793, 0.0127, 0.0525, 0.0147, 0.0187, 0.0113],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:17,831][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([1.7089e-06, 4.2087e-01, 1.1134e-01, 1.2139e-01, 8.6884e-02, 8.3236e-02,
        8.4753e-02, 9.1518e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,831][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.2638e-02, 8.5937e-03, 5.7004e-01, 3.0471e-03, 3.3910e-01, 3.7173e-02,
        2.9329e-02, 7.8323e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,832][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.7751, 0.0171, 0.0307, 0.0270, 0.0378, 0.0258, 0.0519, 0.0346],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,832][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0244, 0.1579, 0.1604, 0.1465, 0.1522, 0.1394, 0.1237, 0.0954],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,834][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1901, 0.0679, 0.3426, 0.1145, 0.2165, 0.0445, 0.0180, 0.0059],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,836][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0207, 0.0493, 0.3246, 0.1033, 0.2333, 0.0269, 0.2409, 0.0009],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,840][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0264, 0.0429, 0.0184, 0.0331, 0.0524, 0.1272, 0.6188, 0.0808],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,843][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0211, 0.0396, 0.3895, 0.1004, 0.2700, 0.1101, 0.0272, 0.0420],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,843][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0032, 0.1819, 0.1375, 0.1470, 0.1335, 0.1319, 0.1344, 0.1305],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,843][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1311, 0.1480, 0.1345, 0.1180, 0.1210, 0.1185, 0.1171, 0.1118],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,844][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0117, 0.1469, 0.1394, 0.1399, 0.1358, 0.1423, 0.1409, 0.1431],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,844][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.6356, 0.1973, 0.0154, 0.0708, 0.0210, 0.0231, 0.0143, 0.0223],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:17,844][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.8777e-06, 3.7909e-01, 1.0158e-01, 1.1107e-01, 7.9786e-02, 7.6286e-02,
        7.7503e-02, 8.4987e-02, 8.9692e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,845][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.5990e-03, 6.6675e-02, 4.9421e-01, 1.0354e-02, 1.2873e-01, 1.5789e-01,
        2.5751e-02, 1.1378e-01, 2.6097e-06], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,845][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.7052, 0.0190, 0.0332, 0.0309, 0.0434, 0.0284, 0.0596, 0.0407, 0.0395],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,846][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0186, 0.1428, 0.1436, 0.1331, 0.1357, 0.1252, 0.1082, 0.0894, 0.1034],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,847][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2283, 0.0990, 0.2366, 0.1153, 0.1914, 0.0487, 0.0436, 0.0229, 0.0142],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,850][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0437, 0.1446, 0.2003, 0.1263, 0.0805, 0.0283, 0.2714, 0.1013, 0.0036],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,854][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0209, 0.0240, 0.0125, 0.0221, 0.0546, 0.0782, 0.4880, 0.2413, 0.0583],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,856][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0544, 0.0399, 0.2807, 0.0795, 0.2992, 0.0961, 0.0212, 0.0521, 0.0770],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,856][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0027, 0.1611, 0.1212, 0.1297, 0.1177, 0.1164, 0.1191, 0.1155, 0.1167],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,857][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1170, 0.1319, 0.1202, 0.1057, 0.1084, 0.1061, 0.1049, 0.1002, 0.1055],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,857][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0100, 0.1289, 0.1221, 0.1227, 0.1186, 0.1248, 0.1233, 0.1255, 0.1241],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,858][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.6803, 0.1830, 0.0113, 0.0554, 0.0142, 0.0174, 0.0096, 0.0161, 0.0126],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:17,858][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ station] are: tensor([1.0791e-06, 3.6502e-01, 9.3967e-02, 1.0246e-01, 7.3100e-02, 6.9763e-02,
        7.1081e-02, 7.7926e-02, 8.2320e-02, 6.4361e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,858][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ station] are: tensor([1.5749e-02, 1.1530e-01, 1.5194e-02, 8.3763e-02, 1.4996e-02, 1.0977e-02,
        2.0946e-04, 7.3764e-01, 6.0687e-03, 1.0368e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,859][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.6915, 0.0180, 0.0291, 0.0264, 0.0364, 0.0264, 0.0520, 0.0356, 0.0377,
        0.0469], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,859][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0205, 0.1255, 0.1247, 0.1205, 0.1192, 0.1130, 0.0978, 0.0781, 0.1013,
        0.0994], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,861][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.2635, 0.0838, 0.1619, 0.1727, 0.1761, 0.0202, 0.0160, 0.0404, 0.0597,
        0.0057], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,863][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0101, 0.3116, 0.0157, 0.1009, 0.0951, 0.0060, 0.0132, 0.2033, 0.2434,
        0.0007], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,868][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0174, 0.0057, 0.0034, 0.0086, 0.0144, 0.0336, 0.2140, 0.1081, 0.0467,
        0.5481], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,870][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0233, 0.0212, 0.2435, 0.0453, 0.4364, 0.0609, 0.0154, 0.0401, 0.0800,
        0.0338], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,870][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0023, 0.1434, 0.1083, 0.1158, 0.1052, 0.1041, 0.1063, 0.1031, 0.1040,
        0.1076], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,870][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1060, 0.1192, 0.1085, 0.0953, 0.0978, 0.0953, 0.0944, 0.0901, 0.0949,
        0.0986], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,871][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0085, 0.1148, 0.1088, 0.1094, 0.1057, 0.1107, 0.1093, 0.1112, 0.1102,
        0.1113], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,871][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.6488, 0.1859, 0.0129, 0.0593, 0.0162, 0.0203, 0.0123, 0.0188, 0.0141,
        0.0114], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:17,872][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.5603e-06, 3.3049e-01, 8.7750e-02, 9.6288e-02, 6.9389e-02, 6.5725e-02,
        6.7103e-02, 7.4076e-02, 7.7742e-02, 6.0956e-02, 7.0482e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,872][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.9758e-02, 4.8976e-03, 7.9257e-01, 5.8813e-04, 2.8601e-02, 1.1775e-01,
        1.8907e-03, 2.2532e-03, 6.8908e-05, 3.1618e-02, 1.2242e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,872][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.6733, 0.0162, 0.0309, 0.0250, 0.0386, 0.0239, 0.0507, 0.0329, 0.0349,
        0.0477, 0.0259], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,874][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0153, 0.1121, 0.1163, 0.1041, 0.1138, 0.0983, 0.0870, 0.0729, 0.0862,
        0.0986, 0.0953], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,877][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1601, 0.0352, 0.2539, 0.0637, 0.2706, 0.0401, 0.0315, 0.0145, 0.0546,
        0.0501, 0.0259], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,879][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([1.1901e-02, 8.1182e-03, 3.6453e-01, 2.2995e-02, 1.7346e-01, 1.2051e-01,
        6.6090e-02, 1.0559e-02, 1.9101e-02, 2.0239e-01, 3.4546e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,883][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0077, 0.0061, 0.0042, 0.0093, 0.0121, 0.0315, 0.1574, 0.0740, 0.0492,
        0.5777, 0.0707], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,883][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0413, 0.0238, 0.2740, 0.0573, 0.2950, 0.0564, 0.0147, 0.0443, 0.0928,
        0.0421, 0.0583], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,884][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0021, 0.1294, 0.0978, 0.1045, 0.0947, 0.0938, 0.0960, 0.0933, 0.0943,
        0.0973, 0.0968], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,884][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0966, 0.1087, 0.0990, 0.0871, 0.0892, 0.0872, 0.0863, 0.0824, 0.0866,
        0.0901, 0.0869], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,885][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0079, 0.1038, 0.0981, 0.0986, 0.0952, 0.1002, 0.0988, 0.1006, 0.0995,
        0.1004, 0.0969], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,885][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.5359, 0.1994, 0.0194, 0.0825, 0.0259, 0.0290, 0.0172, 0.0269, 0.0198,
        0.0160, 0.0280], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:17,885][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([1.1623e-06, 3.1211e-01, 8.2237e-02, 9.0668e-02, 6.4681e-02, 6.1658e-02,
        6.2782e-02, 6.8599e-02, 7.2329e-02, 5.6595e-02, 6.5366e-02, 6.2978e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,886][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([1.8640e-02, 5.7561e-02, 8.6916e-01, 4.0360e-03, 1.3652e-03, 4.2235e-02,
        1.5098e-03, 2.6915e-03, 7.7449e-05, 1.5597e-03, 1.6064e-04, 1.0072e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,887][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.6272, 0.0159, 0.0266, 0.0250, 0.0347, 0.0233, 0.0466, 0.0330, 0.0331,
        0.0439, 0.0261, 0.0646], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,890][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0149, 0.1036, 0.1053, 0.0979, 0.0966, 0.0956, 0.0799, 0.0674, 0.0825,
        0.0833, 0.0916, 0.0815], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,894][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.3763, 0.1012, 0.0729, 0.1902, 0.0471, 0.0248, 0.0224, 0.0239, 0.0442,
        0.0092, 0.0490, 0.0390], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,897][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0045, 0.0141, 0.8673, 0.0066, 0.0039, 0.0182, 0.0318, 0.0037, 0.0035,
        0.0399, 0.0011, 0.0053], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,897][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0572, 0.0219, 0.0021, 0.0063, 0.0037, 0.0121, 0.1137, 0.0364, 0.0363,
        0.3192, 0.2262, 0.1648], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,897][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0154, 0.0140, 0.2604, 0.0248, 0.2999, 0.0431, 0.0067, 0.0132, 0.0442,
        0.0215, 0.0336, 0.2232], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,898][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0020, 0.1188, 0.0888, 0.0952, 0.0862, 0.0856, 0.0876, 0.0851, 0.0858,
        0.0888, 0.0886, 0.0874], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,898][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0885, 0.0994, 0.0906, 0.0798, 0.0816, 0.0799, 0.0790, 0.0754, 0.0793,
        0.0826, 0.0796, 0.0843], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,899][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0082, 0.0945, 0.0895, 0.0895, 0.0867, 0.0909, 0.0898, 0.0912, 0.0905,
        0.0910, 0.0883, 0.0898], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,899][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.7362, 0.1582, 0.0069, 0.0359, 0.0093, 0.0107, 0.0061, 0.0090, 0.0064,
        0.0048, 0.0100, 0.0067], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:17,899][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([1.1612e-06, 2.9701e-01, 7.7607e-02, 8.4624e-02, 6.0747e-02, 5.7913e-02,
        5.9240e-02, 6.4919e-02, 6.8696e-02, 5.3489e-02, 6.1965e-02, 5.9735e-02,
        5.4049e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,900][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([2.2837e-02, 2.0032e-02, 2.6160e-02, 2.1190e-02, 4.0851e-01, 2.2651e-02,
        2.4616e-04, 2.7787e-02, 2.3233e-03, 3.7797e-03, 2.7478e-04, 4.4350e-01,
        7.0932e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,903][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.6219, 0.0158, 0.0257, 0.0232, 0.0317, 0.0209, 0.0421, 0.0299, 0.0299,
        0.0416, 0.0242, 0.0584, 0.0346], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,906][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0169, 0.0932, 0.0916, 0.0912, 0.0912, 0.0836, 0.0737, 0.0619, 0.0744,
        0.0800, 0.0834, 0.0802, 0.0788], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,910][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.2669, 0.0698, 0.0842, 0.2271, 0.0909, 0.0292, 0.0199, 0.0383, 0.0595,
        0.0079, 0.0305, 0.0684, 0.0074], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,910][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0330, 0.0333, 0.0246, 0.0800, 0.3024, 0.0369, 0.0279, 0.0602, 0.0308,
        0.1423, 0.0018, 0.2257, 0.0012], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,911][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0094, 0.0064, 0.0022, 0.0060, 0.0077, 0.0117, 0.0629, 0.0223, 0.0225,
        0.2717, 0.0990, 0.2063, 0.2718], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,911][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0244, 0.0192, 0.2803, 0.0507, 0.2106, 0.0379, 0.0104, 0.0376, 0.0877,
        0.0366, 0.0405, 0.1564, 0.0076], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,912][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0017, 0.1095, 0.0823, 0.0876, 0.0796, 0.0788, 0.0806, 0.0783, 0.0792,
        0.0819, 0.0814, 0.0804, 0.0787], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,912][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0820, 0.0924, 0.0841, 0.0738, 0.0756, 0.0739, 0.0730, 0.0698, 0.0734,
        0.0763, 0.0737, 0.0782, 0.0737], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,913][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0064, 0.0867, 0.0825, 0.0819, 0.0798, 0.0837, 0.0826, 0.0841, 0.0835,
        0.0838, 0.0812, 0.0825, 0.0814], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,913][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.6625, 0.1753, 0.0103, 0.0488, 0.0132, 0.0162, 0.0097, 0.0141, 0.0102,
        0.0080, 0.0138, 0.0088, 0.0090], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:17,914][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.2587e-06, 2.6924e-01, 7.3203e-02, 7.9621e-02, 5.8176e-02, 5.5216e-02,
        5.6263e-02, 6.1173e-02, 6.4751e-02, 5.1070e-02, 5.8215e-02, 5.6880e-02,
        5.1235e-02, 6.4956e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,915][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.0115e-02, 1.3672e-03, 1.4976e-01, 1.0899e-04, 6.6950e-02, 2.7199e-02,
        2.4116e-02, 4.3269e-04, 1.2925e-04, 1.0623e-02, 2.0527e-06, 1.1702e-01,
        5.9217e-01, 6.0234e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,918][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6209, 0.0130, 0.0233, 0.0207, 0.0301, 0.0196, 0.0402, 0.0269, 0.0273,
        0.0391, 0.0208, 0.0539, 0.0323, 0.0319], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,922][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0114, 0.0916, 0.0898, 0.0848, 0.0861, 0.0782, 0.0689, 0.0564, 0.0663,
        0.0757, 0.0775, 0.0736, 0.0749, 0.0648], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,924][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0587, 0.0598, 0.2347, 0.1030, 0.2175, 0.0314, 0.0185, 0.0083, 0.0469,
        0.0154, 0.0324, 0.1451, 0.0235, 0.0047], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,924][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0168, 0.0196, 0.0391, 0.0251, 0.1304, 0.0233, 0.2349, 0.0039, 0.0614,
        0.1793, 0.0017, 0.1220, 0.1422, 0.0003], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,925][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0173, 0.0045, 0.0016, 0.0023, 0.0041, 0.0100, 0.0613, 0.0147, 0.0115,
        0.2167, 0.0452, 0.0983, 0.3038, 0.2086], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,925][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0220, 0.0162, 0.1454, 0.0313, 0.3208, 0.0543, 0.0144, 0.0236, 0.0593,
        0.0294, 0.0370, 0.2135, 0.0120, 0.0209], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,925][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0016, 0.1019, 0.0764, 0.0815, 0.0740, 0.0729, 0.0743, 0.0721, 0.0729,
        0.0754, 0.0751, 0.0742, 0.0725, 0.0753], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,926][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0767, 0.0865, 0.0785, 0.0689, 0.0706, 0.0689, 0.0682, 0.0651, 0.0685,
        0.0713, 0.0687, 0.0729, 0.0687, 0.0666], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,926][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0053, 0.0812, 0.0764, 0.0761, 0.0737, 0.0774, 0.0762, 0.0778, 0.0771,
        0.0777, 0.0751, 0.0766, 0.0751, 0.0741], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,927][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.6247, 0.1737, 0.0111, 0.0552, 0.0143, 0.0175, 0.0104, 0.0168, 0.0117,
        0.0089, 0.0161, 0.0096, 0.0095, 0.0207], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:17,928][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([1.4397e-06, 2.4897e-01, 6.8314e-02, 7.4727e-02, 5.3991e-02, 5.1548e-02,
        5.2472e-02, 5.7513e-02, 6.0517e-02, 4.7745e-02, 5.4780e-02, 5.3064e-02,
        4.7732e-02, 6.1032e-02, 6.7593e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,929][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([9.5931e-03, 1.3145e-02, 2.4399e-01, 2.0599e-02, 3.8656e-01, 5.9561e-03,
        7.7707e-05, 2.1297e-02, 5.4965e-04, 4.3905e-04, 4.6297e-03, 2.9245e-01,
        6.4299e-04, 6.9223e-05, 8.7988e-07], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,932][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.6153, 0.0126, 0.0213, 0.0193, 0.0267, 0.0181, 0.0359, 0.0258, 0.0255,
        0.0363, 0.0196, 0.0478, 0.0293, 0.0310, 0.0354], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,936][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0113, 0.0827, 0.0804, 0.0784, 0.0797, 0.0741, 0.0646, 0.0516, 0.0643,
        0.0696, 0.0719, 0.0685, 0.0699, 0.0634, 0.0695], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,937][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0851, 0.0905, 0.1091, 0.1669, 0.1590, 0.0360, 0.0176, 0.0287, 0.0843,
        0.0134, 0.0580, 0.1125, 0.0157, 0.0181, 0.0050], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,938][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([8.1164e-03, 2.2450e-02, 8.3705e-02, 7.4910e-03, 3.2236e-01, 1.6002e-02,
        2.1884e-02, 5.2479e-02, 2.6031e-02, 5.2853e-02, 2.4201e-02, 2.7148e-01,
        8.5329e-02, 5.4295e-03, 1.8735e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,938][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0028, 0.0018, 0.0010, 0.0015, 0.0034, 0.0063, 0.0241, 0.0162, 0.0053,
        0.1456, 0.0274, 0.0691, 0.1577, 0.3017, 0.2360], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,939][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0117, 0.0258, 0.0979, 0.0565, 0.2411, 0.0583, 0.0171, 0.0443, 0.0919,
        0.0338, 0.0681, 0.1800, 0.0090, 0.0556, 0.0088], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,939][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0015, 0.0952, 0.0711, 0.0759, 0.0689, 0.0679, 0.0693, 0.0673, 0.0680,
        0.0705, 0.0702, 0.0693, 0.0675, 0.0703, 0.0673], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,940][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0714, 0.0806, 0.0735, 0.0644, 0.0660, 0.0644, 0.0637, 0.0608, 0.0639,
        0.0666, 0.0642, 0.0682, 0.0642, 0.0622, 0.0659], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,940][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0052, 0.0755, 0.0712, 0.0708, 0.0687, 0.0720, 0.0708, 0.0724, 0.0718,
        0.0723, 0.0699, 0.0713, 0.0700, 0.0692, 0.0688], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,940][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.5788, 0.1847, 0.0114, 0.0621, 0.0160, 0.0194, 0.0132, 0.0181, 0.0133,
        0.0102, 0.0172, 0.0116, 0.0108, 0.0238, 0.0092], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:17,942][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.2032e-06, 2.3507e-01, 6.4179e-02, 7.0216e-02, 5.0770e-02, 4.8330e-02,
        4.9116e-02, 5.3760e-02, 5.6538e-02, 4.4578e-02, 5.1060e-02, 4.9573e-02,
        4.4816e-02, 5.7136e-02, 6.3256e-02, 6.1604e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,943][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([6.4796e-04, 2.5375e-02, 1.1438e-01, 1.3347e-02, 3.5383e-01, 1.3502e-01,
        4.0795e-03, 2.4317e-02, 2.7264e-05, 3.1735e-03, 7.9887e-04, 3.0164e-01,
        1.7169e-02, 5.1916e-03, 9.8739e-04, 1.6831e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,946][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.5265, 0.0144, 0.0247, 0.0231, 0.0313, 0.0204, 0.0425, 0.0288, 0.0278,
        0.0413, 0.0212, 0.0551, 0.0330, 0.0356, 0.0391, 0.0351],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,949][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0116, 0.0786, 0.0791, 0.0744, 0.0751, 0.0691, 0.0605, 0.0494, 0.0589,
        0.0649, 0.0662, 0.0652, 0.0657, 0.0581, 0.0682, 0.0550],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,951][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1292, 0.0989, 0.1566, 0.1498, 0.1105, 0.0464, 0.0276, 0.0185, 0.0329,
        0.0166, 0.0616, 0.0758, 0.0408, 0.0196, 0.0085, 0.0067],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,952][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0122, 0.1183, 0.0398, 0.1191, 0.0724, 0.0515, 0.0994, 0.0291, 0.0092,
        0.1421, 0.0150, 0.0587, 0.0658, 0.0506, 0.1118, 0.0049],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,952][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0009, 0.0009, 0.0005, 0.0008, 0.0028, 0.0027, 0.0216, 0.0069, 0.0021,
        0.1256, 0.0134, 0.0630, 0.1175, 0.2142, 0.4198, 0.0072],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,953][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0225, 0.0288, 0.1350, 0.0499, 0.2404, 0.0635, 0.0185, 0.0319, 0.0554,
        0.0280, 0.0559, 0.1788, 0.0107, 0.0302, 0.0327, 0.0177],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,953][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0013, 0.0897, 0.0667, 0.0712, 0.0645, 0.0636, 0.0650, 0.0629, 0.0636,
        0.0659, 0.0657, 0.0647, 0.0632, 0.0658, 0.0630, 0.0632],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,953][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0674, 0.0760, 0.0691, 0.0606, 0.0620, 0.0605, 0.0599, 0.0571, 0.0601,
        0.0626, 0.0604, 0.0641, 0.0603, 0.0585, 0.0619, 0.0596],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,954][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0048, 0.0707, 0.0666, 0.0663, 0.0642, 0.0674, 0.0663, 0.0676, 0.0671,
        0.0676, 0.0653, 0.0666, 0.0654, 0.0646, 0.0643, 0.0652],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,954][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.6293, 0.1750, 0.0095, 0.0535, 0.0135, 0.0151, 0.0092, 0.0138, 0.0105,
        0.0082, 0.0133, 0.0092, 0.0076, 0.0173, 0.0061, 0.0090],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:17,956][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([9.7690e-07, 2.2827e-01, 6.0849e-02, 6.6212e-02, 4.7674e-02, 4.5310e-02,
        4.5984e-02, 5.0578e-02, 5.3418e-02, 4.1795e-02, 4.7954e-02, 4.6873e-02,
        4.2171e-02, 5.3776e-02, 5.9669e-02, 5.8319e-02, 5.1149e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,957][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([9.6557e-03, 1.7252e-01, 4.6277e-01, 1.8834e-02, 1.3688e-02, 2.4246e-02,
        5.6476e-05, 2.3614e-01, 5.8901e-04, 2.4783e-03, 8.1242e-04, 5.7243e-03,
        4.2012e-02, 1.6501e-03, 7.6849e-03, 1.1210e-03, 1.7171e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,960][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.5468, 0.0131, 0.0202, 0.0193, 0.0267, 0.0174, 0.0362, 0.0249, 0.0241,
        0.0334, 0.0187, 0.0471, 0.0280, 0.0302, 0.0351, 0.0317, 0.0470],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,965][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0125, 0.0718, 0.0731, 0.0708, 0.0698, 0.0659, 0.0547, 0.0470, 0.0590,
        0.0570, 0.0625, 0.0605, 0.0598, 0.0581, 0.0616, 0.0571, 0.0588],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,965][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0960, 0.0867, 0.0929, 0.1627, 0.1079, 0.0254, 0.0166, 0.0961, 0.0544,
        0.0109, 0.0389, 0.0830, 0.0100, 0.0533, 0.0059, 0.0516, 0.0077],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,966][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([2.7100e-02, 9.7048e-03, 2.5962e-01, 6.9157e-03, 1.9732e-02, 3.7230e-02,
        1.0420e-02, 1.6484e-02, 8.8465e-03, 6.2518e-02, 4.4241e-04, 2.3643e-02,
        6.2343e-02, 1.3105e-02, 4.2084e-01, 2.0764e-02, 2.9438e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,966][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0113, 0.0015, 0.0005, 0.0008, 0.0012, 0.0027, 0.0196, 0.0079, 0.0040,
        0.1050, 0.0173, 0.0363, 0.1157, 0.1309, 0.3456, 0.0252, 0.1745],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,967][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0064, 0.0126, 0.2057, 0.0246, 0.3136, 0.0279, 0.0080, 0.0323, 0.0429,
        0.0149, 0.0294, 0.2061, 0.0028, 0.0228, 0.0067, 0.0244, 0.0189],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,967][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0013, 0.0837, 0.0627, 0.0667, 0.0605, 0.0597, 0.0610, 0.0591, 0.0596,
        0.0618, 0.0617, 0.0608, 0.0594, 0.0620, 0.0593, 0.0595, 0.0613],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,967][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0634, 0.0715, 0.0651, 0.0570, 0.0584, 0.0569, 0.0564, 0.0538, 0.0566,
        0.0589, 0.0569, 0.0604, 0.0569, 0.0551, 0.0585, 0.0562, 0.0581],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,968][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0047, 0.0661, 0.0623, 0.0623, 0.0603, 0.0632, 0.0624, 0.0636, 0.0629,
        0.0637, 0.0614, 0.0625, 0.0612, 0.0606, 0.0604, 0.0612, 0.0614],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,970][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.6509, 0.1638, 0.0085, 0.0469, 0.0111, 0.0140, 0.0088, 0.0128, 0.0098,
        0.0072, 0.0125, 0.0079, 0.0076, 0.0154, 0.0065, 0.0090, 0.0074],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:17,972][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.4215e-06, 2.0273e-01, 5.7624e-02, 6.2188e-02, 4.5767e-02, 4.3329e-02,
        4.3996e-02, 4.7738e-02, 5.0569e-02, 4.0345e-02, 4.5767e-02, 4.4900e-02,
        4.0270e-02, 5.0728e-02, 5.6715e-02, 5.5016e-02, 4.8650e-02, 6.3667e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,974][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.1112e-02, 1.6353e-03, 1.2944e-01, 1.3915e-04, 7.6524e-02, 2.5086e-02,
        2.7346e-02, 4.9914e-04, 1.5878e-04, 1.1265e-02, 2.4665e-06, 1.3920e-01,
        5.5599e-01, 7.9056e-07, 1.5774e-03, 4.4733e-03, 1.5550e-02, 1.1290e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,977][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4867, 0.0136, 0.0225, 0.0209, 0.0287, 0.0191, 0.0397, 0.0258, 0.0258,
        0.0372, 0.0190, 0.0498, 0.0302, 0.0304, 0.0364, 0.0325, 0.0498, 0.0319],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,979][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0094, 0.0705, 0.0698, 0.0659, 0.0672, 0.0610, 0.0537, 0.0439, 0.0521,
        0.0589, 0.0596, 0.0577, 0.0583, 0.0504, 0.0598, 0.0508, 0.0620, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,979][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0259, 0.0662, 0.2389, 0.1066, 0.1933, 0.0330, 0.0169, 0.0081, 0.0415,
        0.0164, 0.0320, 0.1196, 0.0213, 0.0040, 0.0110, 0.0257, 0.0372, 0.0026],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,979][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0119, 0.0145, 0.0249, 0.0171, 0.0889, 0.0189, 0.1638, 0.0030, 0.0450,
        0.1199, 0.0012, 0.0863, 0.1149, 0.0002, 0.0401, 0.1135, 0.1356, 0.0002],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,980][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0023, 0.0010, 0.0004, 0.0006, 0.0013, 0.0032, 0.0270, 0.0060, 0.0038,
        0.1085, 0.0153, 0.0343, 0.1108, 0.0789, 0.3270, 0.0188, 0.2012, 0.0597],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,980][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0152, 0.0164, 0.1223, 0.0333, 0.2879, 0.0466, 0.0125, 0.0266, 0.0629,
        0.0268, 0.0417, 0.1869, 0.0107, 0.0204, 0.0149, 0.0324, 0.0233, 0.0194],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,981][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0012, 0.0793, 0.0593, 0.0632, 0.0573, 0.0564, 0.0575, 0.0557, 0.0563,
        0.0584, 0.0581, 0.0572, 0.0559, 0.0581, 0.0557, 0.0559, 0.0576, 0.0571],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,981][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0602, 0.0679, 0.0617, 0.0541, 0.0554, 0.0540, 0.0534, 0.0509, 0.0536,
        0.0559, 0.0538, 0.0572, 0.0538, 0.0521, 0.0553, 0.0532, 0.0550, 0.0524],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,983][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0040, 0.0629, 0.0590, 0.0588, 0.0567, 0.0597, 0.0588, 0.0601, 0.0594,
        0.0599, 0.0579, 0.0590, 0.0579, 0.0573, 0.0571, 0.0578, 0.0577, 0.0559],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:17,986][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4794, 0.1684, 0.0150, 0.0689, 0.0207, 0.0242, 0.0156, 0.0239, 0.0176,
        0.0137, 0.0228, 0.0152, 0.0139, 0.0299, 0.0115, 0.0159, 0.0134, 0.0299],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,020][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:18,024][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,025][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,025][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,025][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,026][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,026][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,026][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,027][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,027][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,027][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,027][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,029][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,031][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9046, 0.0954], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,035][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9297, 0.0703], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,038][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5100, 0.4900], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,040][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4026, 0.5974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,041][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3808, 0.6192], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,041][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9416, 0.0584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,041][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1586, 0.8414], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,041][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6523, 0.3477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,042][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6855, 0.3145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,042][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9780, 0.0220], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,042][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9819, 0.0181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,043][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9565, 0.0435], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,044][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.7419, 0.0890, 0.1691], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,047][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.9926, 0.0024, 0.0049], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,051][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.2081, 0.5318, 0.2601], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,053][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.0929, 0.5651, 0.3420], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,054][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.0575, 0.5348, 0.4077], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,054][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.9349, 0.0471, 0.0179], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,054][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.0742, 0.7599, 0.1659], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,054][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.4532, 0.2883, 0.2585], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,055][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.5664, 0.2276, 0.2060], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,055][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.9389, 0.0407, 0.0204], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,055][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.9480, 0.0351, 0.0169], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,056][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.9332, 0.0445, 0.0223], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,056][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6991, 0.0451, 0.2391, 0.0168], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,056][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8478, 0.0380, 0.1083, 0.0059], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,058][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1620, 0.2778, 0.3552, 0.2050], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,061][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0864, 0.3832, 0.2358, 0.2946], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,065][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0722, 0.2715, 0.3109, 0.3454], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,067][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8246, 0.0792, 0.0696, 0.0265], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,067][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0638, 0.3162, 0.3613, 0.2588], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,067][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.5776, 0.2408, 0.0535, 0.1281], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,068][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1775, 0.3164, 0.3954, 0.1106], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,068][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9387, 0.0242, 0.0191, 0.0181], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,068][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9731, 0.0174, 0.0029, 0.0066], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,069][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8890, 0.0403, 0.0086, 0.0621], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,069][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.4237, 0.1248, 0.2030, 0.1599, 0.0887], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,069][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.9487, 0.0124, 0.0185, 0.0054, 0.0150], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,071][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.1245, 0.1506, 0.1013, 0.2920, 0.3316], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,074][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0399, 0.2100, 0.1176, 0.3277, 0.3047], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,078][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0167, 0.1021, 0.0830, 0.3868, 0.4114], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,080][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.6833, 0.1246, 0.0595, 0.0927, 0.0400], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,080][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0651, 0.3933, 0.0817, 0.2776, 0.1824], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,080][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.2462, 0.0869, 0.1144, 0.1128, 0.4397], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,081][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1932, 0.1657, 0.1244, 0.3299, 0.1867], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,081][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.7582, 0.0539, 0.0984, 0.0467, 0.0428], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,081][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.8252, 0.0863, 0.0301, 0.0319, 0.0266], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,082][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.7979, 0.0567, 0.0175, 0.0930, 0.0348], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,082][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.4748, 0.1119, 0.1986, 0.0664, 0.0693, 0.0790], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,082][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.5520, 0.0763, 0.1630, 0.0365, 0.0943, 0.0779], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,083][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0307, 0.1322, 0.1070, 0.1138, 0.3565, 0.2598], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,084][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0221, 0.2120, 0.0848, 0.1839, 0.2444, 0.2528], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,087][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0083, 0.0418, 0.0536, 0.0898, 0.3202, 0.4863], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,091][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.4050, 0.1775, 0.0798, 0.2043, 0.0677, 0.0656], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,093][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0195, 0.1588, 0.0974, 0.1409, 0.3810, 0.2024], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,094][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1567, 0.2070, 0.0441, 0.1138, 0.3036, 0.1748], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,094][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.1215, 0.1379, 0.1913, 0.1285, 0.2918, 0.1290], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,094][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.7458, 0.0641, 0.0421, 0.0623, 0.0469, 0.0388], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,095][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.7422, 0.0773, 0.0255, 0.0420, 0.0280, 0.0849], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,095][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.6052, 0.0436, 0.0114, 0.0878, 0.0157, 0.2362], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,095][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.2839, 0.1412, 0.1795, 0.0781, 0.0915, 0.1386, 0.0873],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,096][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.7459, 0.0280, 0.0823, 0.0161, 0.0310, 0.0769, 0.0198],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,097][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.1021, 0.0508, 0.0401, 0.0671, 0.1204, 0.2324, 0.3871],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,099][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0569, 0.1186, 0.0666, 0.1211, 0.1421, 0.2388, 0.2558],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,102][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0234, 0.0273, 0.0297, 0.0599, 0.1039, 0.2683, 0.4875],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,106][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.3498, 0.1857, 0.1317, 0.0946, 0.0906, 0.0893, 0.0583],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,107][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0180, 0.0906, 0.0414, 0.0667, 0.0842, 0.1808, 0.5183],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,107][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.2766, 0.0766, 0.0250, 0.0600, 0.0978, 0.0945, 0.3695],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,107][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.1551, 0.0794, 0.1236, 0.0674, 0.1451, 0.1504, 0.2791],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,108][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.6946, 0.0658, 0.0616, 0.0458, 0.0555, 0.0527, 0.0240],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,108][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.8143, 0.0592, 0.0183, 0.0233, 0.0170, 0.0472, 0.0206],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,108][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.7638, 0.0269, 0.0123, 0.0460, 0.0154, 0.0844, 0.0512],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,109][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.6637, 0.0389, 0.0581, 0.0223, 0.0351, 0.0859, 0.0696, 0.0265],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,109][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.8656, 0.0153, 0.0348, 0.0043, 0.0178, 0.0311, 0.0270, 0.0040],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,109][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1260, 0.0422, 0.0313, 0.0415, 0.0773, 0.1381, 0.3169, 0.2267],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,111][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0672, 0.0797, 0.0442, 0.0868, 0.0948, 0.1498, 0.3219, 0.1556],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,114][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0156, 0.0101, 0.0104, 0.0179, 0.0406, 0.1569, 0.4714, 0.2770],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,118][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.6114, 0.0774, 0.0703, 0.0650, 0.0352, 0.0577, 0.0559, 0.0271],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,120][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0264, 0.0429, 0.0184, 0.0331, 0.0524, 0.1272, 0.6188, 0.0808],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,120][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.2416, 0.0230, 0.0161, 0.0277, 0.0396, 0.0523, 0.4342, 0.1655],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,121][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2786, 0.0582, 0.0500, 0.0652, 0.0463, 0.1230, 0.2684, 0.1103],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,121][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.8270, 0.0329, 0.0240, 0.0224, 0.0238, 0.0201, 0.0277, 0.0221],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,121][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.9077, 0.0244, 0.0062, 0.0110, 0.0074, 0.0207, 0.0093, 0.0133],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,122][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.7824, 0.0207, 0.0064, 0.0332, 0.0104, 0.0509, 0.0214, 0.0746],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,122][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7723, 0.0403, 0.0331, 0.0158, 0.0133, 0.0343, 0.0285, 0.0410, 0.0216],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,122][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.9145, 0.0122, 0.0228, 0.0037, 0.0074, 0.0164, 0.0152, 0.0052, 0.0027],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,124][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1323, 0.0261, 0.0146, 0.0246, 0.0473, 0.0858, 0.2569, 0.2635, 0.1488],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,127][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0595, 0.0628, 0.0375, 0.0637, 0.0868, 0.1028, 0.2682, 0.1389, 0.1799],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,131][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0109, 0.0055, 0.0050, 0.0086, 0.0239, 0.0843, 0.4723, 0.2698, 0.1197],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,133][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.6210, 0.0767, 0.0448, 0.0617, 0.0256, 0.0435, 0.0630, 0.0419, 0.0217],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,133][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0209, 0.0240, 0.0125, 0.0221, 0.0546, 0.0782, 0.4880, 0.2413, 0.0583],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,134][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2128, 0.0368, 0.0089, 0.0217, 0.0427, 0.0495, 0.2851, 0.2165, 0.1258],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,134][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2317, 0.0457, 0.0389, 0.0362, 0.0414, 0.0758, 0.2200, 0.2037, 0.1067],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,134][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.8725, 0.0222, 0.0158, 0.0150, 0.0135, 0.0138, 0.0157, 0.0154, 0.0162],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,135][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9359, 0.0191, 0.0036, 0.0073, 0.0046, 0.0115, 0.0036, 0.0087, 0.0058],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,135][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8170, 0.0201, 0.0039, 0.0223, 0.0056, 0.0329, 0.0142, 0.0287, 0.0552],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,135][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2505, 0.0818, 0.0936, 0.0359, 0.0742, 0.0699, 0.0786, 0.0843, 0.0936,
        0.1376], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,136][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.5210, 0.0426, 0.1022, 0.0188, 0.0557, 0.1261, 0.0617, 0.0212, 0.0312,
        0.0195], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,137][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2249, 0.0171, 0.0074, 0.0109, 0.0259, 0.0621, 0.1502, 0.1592, 0.2111,
        0.1312], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,140][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0628, 0.0338, 0.0242, 0.0391, 0.0740, 0.0874, 0.2101, 0.1078, 0.2163,
        0.1445], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,144][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0304, 0.0044, 0.0027, 0.0077, 0.0168, 0.0539, 0.2180, 0.2473, 0.1543,
        0.2645], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,146][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.3410, 0.1351, 0.0892, 0.1066, 0.0508, 0.0676, 0.0781, 0.0488, 0.0621,
        0.0206], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,147][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0174, 0.0057, 0.0034, 0.0086, 0.0144, 0.0336, 0.2140, 0.1081, 0.0467,
        0.5481], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,147][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.3790, 0.0217, 0.0074, 0.0139, 0.0299, 0.0214, 0.1378, 0.1473, 0.1119,
        0.1298], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,147][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1086, 0.0264, 0.0250, 0.0237, 0.0440, 0.0672, 0.2009, 0.1429, 0.2376,
        0.1239], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,148][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.7273, 0.0318, 0.0388, 0.0304, 0.0490, 0.0201, 0.0227, 0.0263, 0.0357,
        0.0176], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,148][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.9417, 0.0149, 0.0030, 0.0072, 0.0048, 0.0078, 0.0043, 0.0062, 0.0055,
        0.0044], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,148][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.7845, 0.0158, 0.0042, 0.0250, 0.0068, 0.0337, 0.0174, 0.0403, 0.0418,
        0.0306], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,149][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.6267, 0.0398, 0.0628, 0.0238, 0.0384, 0.0438, 0.0345, 0.0506, 0.0315,
        0.0225, 0.0257], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,151][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.5820, 0.0352, 0.1140, 0.0098, 0.0734, 0.0958, 0.0386, 0.0144, 0.0148,
        0.0149, 0.0070], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,153][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0608, 0.0205, 0.0170, 0.0125, 0.0386, 0.0612, 0.1393, 0.1425, 0.1699,
        0.1672, 0.1705], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,157][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0369, 0.0478, 0.0264, 0.0471, 0.0572, 0.0751, 0.1529, 0.0829, 0.1271,
        0.1289, 0.2177], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,159][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0120, 0.0054, 0.0039, 0.0054, 0.0129, 0.0526, 0.2931, 0.1501, 0.1260,
        0.2209, 0.1179], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,160][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.5085, 0.0424, 0.0652, 0.0752, 0.0387, 0.0702, 0.0607, 0.0395, 0.0368,
        0.0312, 0.0317], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,160][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0077, 0.0061, 0.0042, 0.0093, 0.0121, 0.0315, 0.1574, 0.0740, 0.0492,
        0.5777, 0.0707], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,160][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.2309, 0.0379, 0.0134, 0.0163, 0.0627, 0.0238, 0.1760, 0.1311, 0.0976,
        0.0982, 0.1120], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,161][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1391, 0.0285, 0.0233, 0.0251, 0.0322, 0.0539, 0.1707, 0.1486, 0.1623,
        0.1179, 0.0985], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,161][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.8386, 0.0235, 0.0178, 0.0137, 0.0165, 0.0132, 0.0153, 0.0146, 0.0186,
        0.0151, 0.0131], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,162][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.9283, 0.0164, 0.0028, 0.0057, 0.0038, 0.0115, 0.0040, 0.0095, 0.0044,
        0.0048, 0.0089], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,162][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.8012, 0.0183, 0.0053, 0.0200, 0.0052, 0.0249, 0.0091, 0.0280, 0.0196,
        0.0211, 0.0474], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,162][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.3074, 0.0400, 0.0430, 0.0413, 0.0325, 0.0891, 0.0765, 0.0860, 0.0768,
        0.0691, 0.0834, 0.0549], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,164][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.8437, 0.0113, 0.0125, 0.0037, 0.0072, 0.0718, 0.0183, 0.0071, 0.0087,
        0.0059, 0.0061, 0.0036], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,167][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.1648, 0.0054, 0.0025, 0.0038, 0.0067, 0.0143, 0.0735, 0.0474, 0.0310,
        0.0300, 0.0858, 0.5350], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,171][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0526, 0.0174, 0.0075, 0.0136, 0.0184, 0.0286, 0.0900, 0.0489, 0.0626,
        0.0524, 0.1346, 0.4733], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,173][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0196, 0.0017, 0.0010, 0.0029, 0.0031, 0.0180, 0.1463, 0.0915, 0.0577,
        0.1292, 0.1140, 0.4150], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,173][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.3392, 0.0555, 0.0227, 0.0556, 0.0154, 0.1687, 0.1335, 0.0614, 0.0552,
        0.0262, 0.0545, 0.0122], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,174][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0572, 0.0219, 0.0021, 0.0063, 0.0037, 0.0121, 0.1137, 0.0364, 0.0363,
        0.3192, 0.2262, 0.1648], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,174][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.3150, 0.0084, 0.0063, 0.0047, 0.0168, 0.0077, 0.0574, 0.0660, 0.0303,
        0.0472, 0.0662, 0.3740], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,174][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1527, 0.0131, 0.0051, 0.0112, 0.0068, 0.0652, 0.1546, 0.1112, 0.1234,
        0.0882, 0.1075, 0.1610], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,175][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.6692, 0.0346, 0.0536, 0.0266, 0.0239, 0.0243, 0.0214, 0.0222, 0.0305,
        0.0334, 0.0202, 0.0400], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,175][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.8554, 0.0309, 0.0102, 0.0114, 0.0106, 0.0213, 0.0054, 0.0108, 0.0075,
        0.0036, 0.0142, 0.0186], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,177][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.6808, 0.0142, 0.0037, 0.0208, 0.0080, 0.0367, 0.0205, 0.0363, 0.0411,
        0.0344, 0.0717, 0.0317], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,179][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.1140, 0.0654, 0.0447, 0.0274, 0.0330, 0.0451, 0.0524, 0.0915, 0.1035,
        0.1105, 0.1031, 0.0961, 0.1133], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,183][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.2653, 0.0484, 0.0901, 0.0222, 0.0567, 0.1189, 0.0842, 0.0315, 0.0418,
        0.0472, 0.0268, 0.0285, 0.1385], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,186][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0235, 0.0050, 0.0030, 0.0028, 0.0087, 0.0090, 0.0224, 0.0363, 0.0349,
        0.0344, 0.0669, 0.5973, 0.1558], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,186][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0164, 0.0144, 0.0075, 0.0123, 0.0234, 0.0222, 0.0547, 0.0313, 0.0530,
        0.0431, 0.0716, 0.4793, 0.1708], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,187][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0072, 0.0012, 0.0010, 0.0016, 0.0044, 0.0066, 0.0437, 0.0318, 0.0299,
        0.0670, 0.0486, 0.5030, 0.2540], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,187][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.2917, 0.1393, 0.0348, 0.0609, 0.0306, 0.0489, 0.0914, 0.0530, 0.0553,
        0.0410, 0.0623, 0.0607, 0.0301], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,187][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0094, 0.0064, 0.0022, 0.0060, 0.0077, 0.0117, 0.0629, 0.0223, 0.0225,
        0.2717, 0.0990, 0.2063, 0.2718], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,188][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.1382, 0.0099, 0.0031, 0.0051, 0.0155, 0.0072, 0.0301, 0.0507, 0.0315,
        0.0355, 0.0438, 0.3283, 0.3011], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,188][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0933, 0.0151, 0.0082, 0.0075, 0.0103, 0.0186, 0.0913, 0.0737, 0.0895,
        0.0845, 0.0733, 0.2846, 0.1500], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,189][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.5601, 0.0595, 0.0321, 0.0272, 0.0257, 0.0305, 0.0324, 0.0372, 0.0470,
        0.0433, 0.0406, 0.0426, 0.0217], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,189][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.8502, 0.0364, 0.0087, 0.0108, 0.0080, 0.0148, 0.0095, 0.0155, 0.0071,
        0.0032, 0.0182, 0.0120, 0.0056], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,191][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.6257, 0.0190, 0.0036, 0.0262, 0.0056, 0.0663, 0.0240, 0.0549, 0.0449,
        0.0251, 0.0513, 0.0217, 0.0318], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,193][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4952, 0.0216, 0.0387, 0.0107, 0.0334, 0.0393, 0.0346, 0.0219, 0.0449,
        0.0550, 0.0472, 0.0523, 0.0812, 0.0239], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,197][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2989, 0.0331, 0.1187, 0.0110, 0.0838, 0.1341, 0.0660, 0.0118, 0.0324,
        0.0279, 0.0188, 0.0227, 0.1267, 0.0141], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,200][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0818, 0.0038, 0.0031, 0.0024, 0.0068, 0.0096, 0.0298, 0.0298, 0.0275,
        0.0493, 0.0395, 0.3804, 0.2244, 0.1118], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,200][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0502, 0.0152, 0.0078, 0.0098, 0.0135, 0.0203, 0.0443, 0.0214, 0.0365,
        0.0342, 0.0725, 0.2599, 0.1917, 0.2228], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,200][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0134, 0.0010, 0.0006, 0.0014, 0.0024, 0.0109, 0.0529, 0.0271, 0.0241,
        0.0465, 0.0338, 0.1710, 0.3383, 0.2766], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,201][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3876, 0.0745, 0.0408, 0.0454, 0.0334, 0.0576, 0.0572, 0.0295, 0.0584,
        0.0324, 0.0563, 0.0448, 0.0550, 0.0271], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,201][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0173, 0.0045, 0.0016, 0.0023, 0.0041, 0.0100, 0.0613, 0.0147, 0.0115,
        0.2167, 0.0452, 0.0983, 0.3038, 0.2086], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,202][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1520, 0.0084, 0.0023, 0.0038, 0.0079, 0.0058, 0.0384, 0.0228, 0.0199,
        0.0386, 0.0439, 0.1560, 0.2643, 0.2360], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,202][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1296, 0.0096, 0.0077, 0.0070, 0.0117, 0.0222, 0.0611, 0.0477, 0.0802,
        0.0450, 0.0656, 0.2324, 0.1527, 0.1274], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,204][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.8414, 0.0200, 0.0116, 0.0103, 0.0102, 0.0107, 0.0105, 0.0119, 0.0145,
        0.0116, 0.0126, 0.0120, 0.0099, 0.0129], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,206][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9534, 0.0116, 0.0013, 0.0028, 0.0014, 0.0057, 0.0021, 0.0044, 0.0019,
        0.0013, 0.0040, 0.0029, 0.0013, 0.0058], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,210][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7379, 0.0167, 0.0022, 0.0190, 0.0025, 0.0248, 0.0137, 0.0247, 0.0224,
        0.0141, 0.0401, 0.0085, 0.0141, 0.0594], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,212][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.3438, 0.0351, 0.0425, 0.0156, 0.0332, 0.0548, 0.0367, 0.0406, 0.0520,
        0.0631, 0.0644, 0.0529, 0.0726, 0.0555, 0.0372], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,213][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.3702, 0.0615, 0.0882, 0.0131, 0.0490, 0.1164, 0.0415, 0.0210, 0.0292,
        0.0264, 0.0203, 0.0216, 0.1061, 0.0275, 0.0077], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,213][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0261, 0.0022, 0.0014, 0.0016, 0.0042, 0.0052, 0.0103, 0.0201, 0.0166,
        0.0238, 0.0294, 0.3414, 0.0809, 0.1117, 0.3251], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,214][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0309, 0.0059, 0.0028, 0.0053, 0.0075, 0.0138, 0.0287, 0.0148, 0.0379,
        0.0261, 0.0409, 0.1790, 0.1535, 0.2241, 0.2287], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,214][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0124, 0.0005, 0.0004, 0.0009, 0.0016, 0.0050, 0.0257, 0.0191, 0.0182,
        0.0334, 0.0313, 0.1437, 0.1613, 0.2200, 0.3265], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,214][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.3166, 0.0964, 0.0576, 0.0522, 0.0439, 0.0570, 0.0772, 0.0410, 0.0335,
        0.0248, 0.0360, 0.0644, 0.0459, 0.0414, 0.0122], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,215][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0028, 0.0018, 0.0010, 0.0015, 0.0034, 0.0063, 0.0241, 0.0162, 0.0053,
        0.1456, 0.0274, 0.0691, 0.1577, 0.3017, 0.2360], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,215][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1904, 0.0048, 0.0013, 0.0018, 0.0084, 0.0048, 0.0180, 0.0208, 0.0128,
        0.0210, 0.0223, 0.1829, 0.0959, 0.2594, 0.1554], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,217][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1477, 0.0100, 0.0080, 0.0052, 0.0116, 0.0125, 0.0377, 0.0492, 0.0464,
        0.0517, 0.0443, 0.2691, 0.0855, 0.1324, 0.0887], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,219][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.7036, 0.0308, 0.0235, 0.0170, 0.0169, 0.0150, 0.0204, 0.0208, 0.0233,
        0.0261, 0.0234, 0.0239, 0.0150, 0.0282, 0.0123], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,223][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.8874, 0.0208, 0.0040, 0.0058, 0.0043, 0.0115, 0.0031, 0.0098, 0.0053,
        0.0041, 0.0101, 0.0088, 0.0049, 0.0145, 0.0056], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,226][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.5726, 0.0176, 0.0026, 0.0217, 0.0032, 0.0436, 0.0207, 0.0343, 0.0336,
        0.0223, 0.0569, 0.0117, 0.0192, 0.0790, 0.0609], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,226][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3907, 0.0224, 0.0208, 0.0128, 0.0128, 0.0336, 0.0284, 0.0343, 0.0367,
        0.0619, 0.0721, 0.0417, 0.1029, 0.0568, 0.0383, 0.0338],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,227][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7513, 0.0154, 0.0501, 0.0068, 0.0103, 0.0302, 0.0210, 0.0055, 0.0078,
        0.0128, 0.0156, 0.0090, 0.0369, 0.0093, 0.0075, 0.0104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,227][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0086, 0.0010, 0.0008, 0.0015, 0.0028, 0.0037, 0.0146, 0.0183, 0.0109,
        0.0209, 0.0204, 0.2165, 0.0996, 0.1673, 0.3822, 0.0308],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,228][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0087, 0.0057, 0.0036, 0.0059, 0.0086, 0.0111, 0.0277, 0.0146, 0.0216,
        0.0239, 0.0381, 0.1995, 0.1212, 0.1910, 0.2697, 0.0492],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,228][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.0052e-03, 2.0772e-04, 2.5128e-04, 4.3422e-04, 1.0349e-03, 3.3856e-03,
        2.6273e-02, 1.2317e-02, 8.5435e-03, 2.8478e-02, 1.2430e-02, 1.0287e-01,
        1.5170e-01, 2.0001e-01, 4.3756e-01, 1.3497e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,228][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4486, 0.0731, 0.0369, 0.0553, 0.0153, 0.0296, 0.0498, 0.0234, 0.0236,
        0.0161, 0.0530, 0.0335, 0.0349, 0.0361, 0.0492, 0.0216],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,230][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0009, 0.0009, 0.0005, 0.0008, 0.0028, 0.0027, 0.0216, 0.0069, 0.0021,
        0.1256, 0.0134, 0.0630, 0.1175, 0.2142, 0.4198, 0.0072],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,233][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0242, 0.0027, 0.0006, 0.0017, 0.0030, 0.0040, 0.0207, 0.0143, 0.0078,
        0.0204, 0.0200, 0.0625, 0.1213, 0.1829, 0.4974, 0.0164],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,237][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0737, 0.0043, 0.0042, 0.0041, 0.0041, 0.0072, 0.0434, 0.0285, 0.0300,
        0.0350, 0.0485, 0.1474, 0.1116, 0.1374, 0.2716, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,239][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7193, 0.0277, 0.0174, 0.0181, 0.0137, 0.0150, 0.0170, 0.0183, 0.0216,
        0.0186, 0.0213, 0.0173, 0.0174, 0.0201, 0.0199, 0.0172],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,240][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9054, 0.0184, 0.0024, 0.0047, 0.0027, 0.0094, 0.0034, 0.0078, 0.0042,
        0.0027, 0.0080, 0.0049, 0.0026, 0.0115, 0.0051, 0.0067],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,240][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.5855, 0.0155, 0.0027, 0.0192, 0.0043, 0.0315, 0.0141, 0.0292, 0.0334,
        0.0309, 0.0476, 0.0160, 0.0137, 0.0505, 0.0313, 0.0746],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,240][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.2334, 0.0249, 0.0324, 0.0122, 0.0303, 0.0438, 0.0296, 0.0334, 0.0471,
        0.0682, 0.0439, 0.0713, 0.1328, 0.0502, 0.0548, 0.0653, 0.0263],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,241][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.5521, 0.0178, 0.0885, 0.0073, 0.0345, 0.0810, 0.0281, 0.0076, 0.0112,
        0.0083, 0.0093, 0.0202, 0.0667, 0.0132, 0.0225, 0.0234, 0.0083],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,241][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0281, 0.0009, 0.0005, 0.0007, 0.0024, 0.0027, 0.0080, 0.0145, 0.0118,
        0.0132, 0.0189, 0.1862, 0.0466, 0.1226, 0.3718, 0.0493, 0.1219],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,242][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0168, 0.0043, 0.0030, 0.0035, 0.0067, 0.0079, 0.0236, 0.0150, 0.0207,
        0.0187, 0.0298, 0.1668, 0.0780, 0.1567, 0.2612, 0.0581, 0.1292],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,242][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([6.5348e-03, 1.9798e-04, 1.3005e-04, 4.0652e-04, 6.2149e-04, 2.6146e-03,
        1.3212e-02, 1.4900e-02, 8.7285e-03, 2.1415e-02, 1.4293e-02, 6.3485e-02,
        1.0214e-01, 1.9802e-01, 2.9904e-01, 3.8233e-02, 2.1603e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,244][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.4242, 0.0676, 0.0827, 0.0354, 0.0447, 0.0359, 0.0417, 0.0209, 0.0205,
        0.0088, 0.0292, 0.0669, 0.0173, 0.0243, 0.0468, 0.0255, 0.0076],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,246][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0113, 0.0015, 0.0005, 0.0008, 0.0012, 0.0027, 0.0196, 0.0079, 0.0040,
        0.1050, 0.0173, 0.0363, 0.1157, 0.1309, 0.3456, 0.0252, 0.1745],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,250][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.1124, 0.0036, 0.0013, 0.0015, 0.0040, 0.0032, 0.0237, 0.0171, 0.0091,
        0.0181, 0.0206, 0.0777, 0.0813, 0.1552, 0.3552, 0.0192, 0.0969],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,253][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1064, 0.0045, 0.0046, 0.0028, 0.0060, 0.0078, 0.0265, 0.0240, 0.0263,
        0.0186, 0.0288, 0.1744, 0.0593, 0.1135, 0.2466, 0.0758, 0.0739],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,253][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.7246, 0.0201, 0.0266, 0.0170, 0.0265, 0.0118, 0.0081, 0.0131, 0.0204,
        0.0202, 0.0138, 0.0339, 0.0077, 0.0147, 0.0196, 0.0171, 0.0048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,254][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.9186, 0.0173, 0.0024, 0.0054, 0.0053, 0.0057, 0.0026, 0.0050, 0.0038,
        0.0019, 0.0048, 0.0078, 0.0013, 0.0078, 0.0024, 0.0038, 0.0041],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,254][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.6016, 0.0116, 0.0018, 0.0191, 0.0031, 0.0296, 0.0150, 0.0293, 0.0419,
        0.0204, 0.0391, 0.0110, 0.0147, 0.0510, 0.0309, 0.0532, 0.0265],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,254][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4926, 0.0118, 0.0211, 0.0055, 0.0201, 0.0225, 0.0215, 0.0143, 0.0340,
        0.0609, 0.0362, 0.0419, 0.0627, 0.0179, 0.0367, 0.0538, 0.0234, 0.0230],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,255][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3122, 0.0248, 0.1069, 0.0067, 0.0640, 0.0979, 0.0449, 0.0088, 0.0285,
        0.0268, 0.0164, 0.0194, 0.0906, 0.0113, 0.0290, 0.0617, 0.0293, 0.0207],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,255][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0059, 0.0007, 0.0005, 0.0009, 0.0015, 0.0033, 0.0131, 0.0114, 0.0108,
        0.0221, 0.0117, 0.1239, 0.0881, 0.0542, 0.4396, 0.0438, 0.1548, 0.0137],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,257][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0061, 0.0047, 0.0029, 0.0047, 0.0061, 0.0102, 0.0270, 0.0116, 0.0209,
        0.0228, 0.0434, 0.1566, 0.0935, 0.1271, 0.2512, 0.0524, 0.1178, 0.0407],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,259][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.0433e-04, 1.6703e-04, 1.2507e-04, 4.3179e-04, 5.6224e-04, 3.7795e-03,
        2.2669e-02, 9.5487e-03, 1.0637e-02, 2.1338e-02, 1.3175e-02, 5.8072e-02,
        1.2596e-01, 1.2117e-01, 3.8792e-01, 2.5640e-02, 1.6982e-01, 2.8176e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,262][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3547, 0.0642, 0.0312, 0.0352, 0.0219, 0.0434, 0.0477, 0.0228, 0.0465,
        0.0289, 0.0517, 0.0331, 0.0471, 0.0227, 0.0473, 0.0513, 0.0344, 0.0157],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,266][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0023, 0.0010, 0.0004, 0.0006, 0.0013, 0.0032, 0.0270, 0.0060, 0.0038,
        0.1085, 0.0153, 0.0343, 0.1108, 0.0789, 0.3270, 0.0188, 0.2012, 0.0597],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,266][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0188, 0.0022, 0.0005, 0.0016, 0.0022, 0.0030, 0.0167, 0.0091, 0.0089,
        0.0201, 0.0215, 0.0553, 0.1461, 0.1342, 0.4073, 0.0126, 0.0823, 0.0578],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,267][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0269, 0.0034, 0.0024, 0.0029, 0.0039, 0.0082, 0.0301, 0.0226, 0.0427,
        0.0254, 0.0335, 0.1010, 0.0689, 0.0755, 0.2393, 0.1149, 0.1585, 0.0397],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,267][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.8061, 0.0209, 0.0110, 0.0098, 0.0087, 0.0094, 0.0094, 0.0109, 0.0149,
        0.0105, 0.0117, 0.0107, 0.0094, 0.0120, 0.0151, 0.0123, 0.0090, 0.0080],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,267][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.5904e-01, 9.0624e-03, 7.0129e-04, 1.7974e-03, 7.7567e-04, 3.7983e-03,
        1.3275e-03, 3.2068e-03, 1.2939e-03, 7.7971e-04, 2.8969e-03, 1.7440e-03,
        8.2083e-04, 4.3180e-03, 1.9692e-03, 2.1213e-03, 6.1321e-04, 3.7338e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,268][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.6406, 0.0175, 0.0019, 0.0183, 0.0022, 0.0235, 0.0127, 0.0228, 0.0196,
        0.0129, 0.0421, 0.0073, 0.0111, 0.0584, 0.0273, 0.0310, 0.0135, 0.0373],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,269][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:18,270][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5508],
        [13503],
        [34988],
        [ 2325],
        [ 3103],
        [15682],
        [ 2929],
        [ 3860],
        [17063],
        [22290],
        [ 2761],
        [ 9681],
        [12664],
        [ 6509],
        [10116],
        [16469],
        [22296],
        [ 8599]], device='cuda:0')
[2024-07-24 10:30:18,271][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5842],
        [14741],
        [38392],
        [22912],
        [18949],
        [35690],
        [15271],
        [17899],
        [34940],
        [23679],
        [13181],
        [31578],
        [27285],
        [15401],
        [22904],
        [29820],
        [35281],
        [15434]], device='cuda:0')
[2024-07-24 10:30:18,273][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21042],
        [18272],
        [19875],
        [19900],
        [20263],
        [20225],
        [20197],
        [20184],
        [20332],
        [20258],
        [20424],
        [20599],
        [20632],
        [20538],
        [20520],
        [20590],
        [20612],
        [20665]], device='cuda:0')
[2024-07-24 10:30:18,275][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30011],
        [30669],
        [19090],
        [   19],
        [   32],
        [  235],
        [  135],
        [   21],
        [   81],
        [28658],
        [   21],
        [   24],
        [  431],
        [  962],
        [  116],
        [  191],
        [  599],
        [  913]], device='cuda:0')
[2024-07-24 10:30:18,276][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[32480],
        [32373],
        [31495],
        [31721],
        [29993],
        [30271],
        [29499],
        [29309],
        [28874],
        [28345],
        [28253],
        [27720],
        [28083],
        [28064],
        [28097],
        [27978],
        [28130],
        [27837]], device='cuda:0')
[2024-07-24 10:30:18,278][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 5610],
        [ 9999],
        [ 8098],
        [ 9039],
        [10214],
        [10657],
        [10476],
        [ 9739],
        [ 9989],
        [ 9800],
        [ 9560],
        [ 9804],
        [ 9207],
        [ 9268],
        [ 8713],
        [ 8458],
        [ 8559],
        [ 8536]], device='cuda:0')
[2024-07-24 10:30:18,281][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18412],
        [18633],
        [14021],
        [ 2534],
        [11482],
        [ 5410],
        [ 4357],
        [ 3482],
        [ 4482],
        [ 5858],
        [ 3823],
        [ 9907],
        [ 7929],
        [ 4223],
        [ 6889],
        [ 6584],
        [ 6919],
        [ 4088]], device='cuda:0')
[2024-07-24 10:30:18,284][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8791],
        [21916],
        [35198],
        [  246],
        [  199],
        [ 8946],
        [  824],
        [ 3944],
        [ 9372],
        [22674],
        [ 5003],
        [  303],
        [14061],
        [12691],
        [ 9637],
        [16618],
        [ 4212],
        [16520]], device='cuda:0')
[2024-07-24 10:30:18,284][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35917],
        [39641],
        [37796],
        [33484],
        [34185],
        [30950],
        [28187],
        [28543],
        [34138],
        [38273],
        [38893],
        [38846],
        [32028],
        [33057],
        [41708],
        [43834],
        [40630],
        [40088]], device='cuda:0')
[2024-07-24 10:30:18,285][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 2619],
        [20146],
        [14625],
        [22276],
        [25646],
        [29467],
        [29609],
        [29491],
        [32980],
        [32985],
        [33197],
        [30861],
        [32661],
        [34847],
        [38312],
        [36295],
        [33227],
        [36360]], device='cuda:0')
[2024-07-24 10:30:18,287][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 8493],
        [13255],
        [12002],
        [12128],
        [11720],
        [11557],
        [11637],
        [11877],
        [11977],
        [11949],
        [12002],
        [12028],
        [11984],
        [11976],
        [11977],
        [12045],
        [11968],
        [11970]], device='cuda:0')
[2024-07-24 10:30:18,288][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10828],
        [11412],
        [11275],
        [11009],
        [10660],
        [10331],
        [10087],
        [ 9986],
        [ 9918],
        [ 9903],
        [ 9837],
        [ 9790],
        [ 9644],
        [ 9578],
        [ 9563],
        [ 9560],
        [ 9527],
        [ 9500]], device='cuda:0')
[2024-07-24 10:30:18,289][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10366],
        [ 9453],
        [10508],
        [10387],
        [10783],
        [10934],
        [11113],
        [11299],
        [11404],
        [11276],
        [11283],
        [11461],
        [11672],
        [11700],
        [11729],
        [11756],
        [11640],
        [11666]], device='cuda:0')
[2024-07-24 10:30:18,291][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[38840],
        [40119],
        [38881],
        [40818],
        [40533],
        [40992],
        [40848],
        [41619],
        [41719],
        [41962],
        [42621],
        [41365],
        [41951],
        [42648],
        [42974],
        [42889],
        [42975],
        [44265]], device='cuda:0')
[2024-07-24 10:30:18,292][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24484],
        [28422],
        [19304],
        [22387],
        [19684],
        [18902],
        [18836],
        [16860],
        [16653],
        [17700],
        [18341],
        [17356],
        [17483],
        [20415],
        [21462],
        [20192],
        [21916],
        [21468]], device='cuda:0')
[2024-07-24 10:30:18,295][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[31397],
        [31539],
        [32509],
        [32831],
        [43687],
        [42013],
        [43130],
        [34911],
        [33290],
        [42931],
        [37208],
        [42285],
        [43216],
        [39705],
        [41393],
        [39887],
        [41113],
        [38776]], device='cuda:0')
[2024-07-24 10:30:18,297][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[30307],
        [31968],
        [30768],
        [38989],
        [33733],
        [42963],
        [40576],
        [36994],
        [34415],
        [42139],
        [42303],
        [36229],
        [40914],
        [41574],
        [40307],
        [38474],
        [40136],
        [41370]], device='cuda:0')
[2024-07-24 10:30:18,300][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32687],
        [38454],
        [38808],
        [38391],
        [40670],
        [44445],
        [44182],
        [45858],
        [47103],
        [47973],
        [46877],
        [43288],
        [42602],
        [44518],
        [42914],
        [43552],
        [42726],
        [41510]], device='cuda:0')
[2024-07-24 10:30:18,301][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 2617],
        [24287],
        [29401],
        [32061],
        [25339],
        [29134],
        [25387],
        [20786],
        [22014],
        [25236],
        [25299],
        [15059],
        [15473],
        [16648],
        [19278],
        [19938],
        [17707],
        [17978]], device='cuda:0')
[2024-07-24 10:30:18,302][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25452],
        [24035],
        [36738],
        [35450],
        [36332],
        [30962],
        [23985],
        [20334],
        [17561],
        [26007],
        [26834],
        [32062],
        [28184],
        [21944],
        [13600],
        [11287],
        [16540],
        [14430]], device='cuda:0')
[2024-07-24 10:30:18,303][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[41875],
        [42204],
        [42227],
        [42792],
        [43599],
        [44232],
        [44962],
        [43496],
        [43128],
        [44386],
        [43811],
        [43400],
        [44403],
        [44126],
        [44521],
        [43786],
        [44772],
        [43481]], device='cuda:0')
[2024-07-24 10:30:18,304][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24159],
        [27191],
        [27063],
        [23210],
        [23469],
        [26778],
        [36172],
        [35976],
        [33931],
        [21748],
        [21190],
        [24236],
        [26122],
        [28281],
        [27733],
        [26915],
        [26544],
        [26667]], device='cuda:0')
[2024-07-24 10:30:18,305][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[38220],
        [35055],
        [25866],
        [33428],
        [28066],
        [26294],
        [22576],
        [19959],
        [21908],
        [20927],
        [19222],
        [30942],
        [23725],
        [22227],
        [24734],
        [18535],
        [19593],
        [18772]], device='cuda:0')
[2024-07-24 10:30:18,308][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42012],
        [41351],
        [43409],
        [40711],
        [37611],
        [39370],
        [40516],
        [38208],
        [39124],
        [39435],
        [38576],
        [41049],
        [43943],
        [43166],
        [43677],
        [41608],
        [42387],
        [41558]], device='cuda:0')
[2024-07-24 10:30:18,309][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21606],
        [20845],
        [19413],
        [19285],
        [13123],
        [12908],
        [11450],
        [15617],
        [17106],
        [13069],
        [16098],
        [11521],
        [10402],
        [16348],
        [12764],
        [12935],
        [12514],
        [15206]], device='cuda:0')
[2024-07-24 10:30:18,311][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[42368],
        [42856],
        [42847],
        [42732],
        [43231],
        [38931],
        [39948],
        [40929],
        [41946],
        [42035],
        [41680],
        [41224],
        [41348],
        [42130],
        [41934],
        [42038],
        [42219],
        [42263]], device='cuda:0')
[2024-07-24 10:30:18,314][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5356],
        [ 3845],
        [ 5017],
        [ 2758],
        [ 2769],
        [11909],
        [ 7949],
        [ 6001],
        [ 5352],
        [ 7507],
        [ 7403],
        [11961],
        [14793],
        [ 9214],
        [15113],
        [14763],
        [12776],
        [12383]], device='cuda:0')
[2024-07-24 10:30:18,316][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1880],
        [1941],
        [1959],
        [1692],
        [1955],
        [1414],
        [1313],
        [2134],
        [2025],
        [1099],
        [1545],
        [1199],
        [1332],
        [1752],
        [1683],
        [2193],
        [1969],
        [2413]], device='cuda:0')
[2024-07-24 10:30:18,317][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23241],
        [ 3482],
        [ 3278],
        [ 2841],
        [ 2979],
        [ 1574],
        [ 1951],
        [ 3749],
        [ 4863],
        [ 3523],
        [ 4993],
        [ 5044],
        [ 2600],
        [ 3108],
        [ 4687],
        [ 9354],
        [ 6290],
        [ 7189]], device='cuda:0')
[2024-07-24 10:30:18,318][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929],
        [7929]], device='cuda:0')
[2024-07-24 10:30:18,355][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:18,356][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,356][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,357][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,357][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,357][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,358][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,358][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,358][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,359][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,360][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,362][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,365][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,367][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9912e-01, 8.7528e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,369][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1036, 0.8964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,369][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5360, 0.4640], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,370][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4900, 0.5100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,370][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6266, 0.3734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,371][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2396, 0.7604], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,371][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8656, 0.1344], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,371][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8785, 0.1215], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,372][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2824, 0.7176], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,373][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6724, 0.3276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,376][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3760, 0.6240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,380][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9973, 0.0027], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,382][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([9.9895e-01, 5.2611e-04, 5.2546e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,382][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.0357, 0.4550, 0.5093], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,383][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.3048, 0.3999, 0.2952], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,383][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.3270, 0.2774, 0.3955], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,383][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.5915, 0.2807, 0.1277], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,383][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.0974, 0.4378, 0.4647], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,384][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.8656, 0.0793, 0.0552], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,384][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.6051, 0.2168, 0.1781], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,384][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.1624, 0.4587, 0.3788], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,385][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.5438, 0.2419, 0.2144], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,385][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.1856, 0.5397, 0.2746], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,386][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.5658, 0.3604, 0.0737], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,388][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9682e-01, 1.3573e-03, 1.5533e-03, 2.7311e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,391][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0349, 0.3276, 0.3723, 0.2653], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,395][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2410, 0.2948, 0.2277, 0.2364], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,396][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2432, 0.2193, 0.2899, 0.2476], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,396][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5475, 0.2666, 0.1290, 0.0569], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,396][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0754, 0.2906, 0.3206, 0.3133], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,396][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7408, 0.0816, 0.0308, 0.1468], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,397][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5864, 0.1559, 0.1301, 0.1276], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,397][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1082, 0.3065, 0.2890, 0.2963], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,397][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3651, 0.2064, 0.1916, 0.2369], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,398][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2710, 0.4693, 0.1535, 0.1062], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,399][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9153, 0.0237, 0.0562, 0.0048], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,401][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.9909e-01, 3.4638e-04, 2.9665e-04, 6.5606e-05, 1.9830e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,404][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0155, 0.2494, 0.2835, 0.2045, 0.2472], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,408][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.1811, 0.2574, 0.1868, 0.1949, 0.1799], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,409][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.2002, 0.1652, 0.2397, 0.1995, 0.1954], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,409][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.5123, 0.2364, 0.1227, 0.0529, 0.0756], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,409][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0480, 0.2198, 0.2391, 0.2454, 0.2477], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,409][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.5751, 0.1292, 0.0642, 0.0966, 0.1350], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,410][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.4670, 0.1513, 0.1180, 0.1216, 0.1421], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,410][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0952, 0.2536, 0.2051, 0.2607, 0.1854], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,410][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.3840, 0.1570, 0.1374, 0.1499, 0.1717], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,411][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.2057, 0.3543, 0.1565, 0.1194, 0.1641], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,411][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.5468, 0.1967, 0.1175, 0.0656, 0.0733], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,412][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ were] are: tensor([9.9041e-01, 2.4573e-03, 3.3306e-03, 5.4732e-04, 2.1719e-03, 1.0862e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,414][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0176, 0.2055, 0.2221, 0.1733, 0.2120, 0.1695], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,417][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1523, 0.2280, 0.1602, 0.1684, 0.1539, 0.1372], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,421][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.1354, 0.1337, 0.2063, 0.1612, 0.2157, 0.1478], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,422][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.5651, 0.2157, 0.0891, 0.0417, 0.0580, 0.0304], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,422][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0446, 0.1782, 0.1881, 0.1992, 0.2070, 0.1829], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,422][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.5988, 0.0730, 0.0233, 0.0625, 0.0452, 0.1973], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,423][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.3829, 0.1415, 0.1136, 0.1119, 0.1340, 0.1161], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,423][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0642, 0.1965, 0.1674, 0.2001, 0.1659, 0.2058], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,423][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2608, 0.1232, 0.1158, 0.1459, 0.1410, 0.2134], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,424][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2420, 0.3847, 0.1143, 0.0864, 0.1135, 0.0592], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,424][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.4328, 0.0515, 0.0969, 0.0544, 0.2631, 0.1013], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,425][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ working] are: tensor([9.9750e-01, 5.0768e-04, 7.0037e-04, 9.3563e-05, 3.3170e-04, 1.8948e-04,
        6.7693e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,427][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0104, 0.1697, 0.2031, 0.1465, 0.1922, 0.1495, 0.1285],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,430][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.1314, 0.2065, 0.1419, 0.1485, 0.1349, 0.1194, 0.1174],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,434][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.1488, 0.1187, 0.1622, 0.1405, 0.1574, 0.1401, 0.1323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,437][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.4976, 0.2376, 0.0898, 0.0530, 0.0539, 0.0318, 0.0363],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,437][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0350, 0.1513, 0.1591, 0.1688, 0.1749, 0.1545, 0.1564],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,437][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.2981, 0.0834, 0.0244, 0.0847, 0.0474, 0.1641, 0.2978],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,438][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.3442, 0.1257, 0.0986, 0.0989, 0.1166, 0.1025, 0.1136],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,438][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0636, 0.1625, 0.1417, 0.1767, 0.1382, 0.1774, 0.1398],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,438][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.2665, 0.1235, 0.1061, 0.1233, 0.1184, 0.1717, 0.0906],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,439][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.1770, 0.4038, 0.1043, 0.0842, 0.1060, 0.0605, 0.0641],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,439][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.4681, 0.0595, 0.0515, 0.0641, 0.1979, 0.1195, 0.0393],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,439][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.9781e-01, 3.8492e-04, 4.1539e-04, 6.6630e-05, 2.3502e-04, 1.3494e-04,
        7.7787e-04, 1.7267e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,441][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0139, 0.1576, 0.1784, 0.1302, 0.1627, 0.1307, 0.1161, 0.1104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,443][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1193, 0.1832, 0.1281, 0.1327, 0.1209, 0.1068, 0.1052, 0.1038],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,447][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1275, 0.1033, 0.1436, 0.1213, 0.1440, 0.1203, 0.1214, 0.1185],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,450][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.4621, 0.2298, 0.1009, 0.0474, 0.0580, 0.0265, 0.0353, 0.0400],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,450][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0332, 0.1316, 0.1405, 0.1452, 0.1517, 0.1360, 0.1384, 0.1234],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,451][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1253, 0.0622, 0.0160, 0.0617, 0.0336, 0.0956, 0.0773, 0.5282],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,451][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.3295, 0.1061, 0.0888, 0.0871, 0.1020, 0.0876, 0.0986, 0.1002],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,451][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0463, 0.1447, 0.1289, 0.1514, 0.1233, 0.1670, 0.1375, 0.1010],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,452][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.2801, 0.1144, 0.0980, 0.1073, 0.0986, 0.1469, 0.0708, 0.0840],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,452][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1490, 0.3654, 0.1157, 0.0912, 0.1152, 0.0618, 0.0702, 0.0315],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,452][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.5190, 0.0372, 0.1083, 0.0099, 0.0522, 0.0772, 0.1942, 0.0020],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,453][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.9783e-01, 2.9030e-04, 3.2088e-04, 5.3726e-05, 1.9135e-04, 9.7517e-05,
        7.6591e-04, 1.9273e-04, 2.6123e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,454][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0121, 0.1413, 0.1539, 0.1145, 0.1395, 0.1165, 0.1050, 0.1032, 0.1140],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,456][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1059, 0.1715, 0.1167, 0.1224, 0.1108, 0.0974, 0.0954, 0.0945, 0.0853],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,459][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1090, 0.0926, 0.1273, 0.1058, 0.1251, 0.1110, 0.1102, 0.1105, 0.1087],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,463][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.4593, 0.2044, 0.0989, 0.0450, 0.0616, 0.0314, 0.0367, 0.0407, 0.0221],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,464][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0291, 0.1167, 0.1235, 0.1271, 0.1323, 0.1211, 0.1226, 0.1124, 0.1152],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,464][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2499, 0.0555, 0.0119, 0.0412, 0.0183, 0.1190, 0.0574, 0.1028, 0.3440],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,464][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3294, 0.0886, 0.0758, 0.0739, 0.0866, 0.0768, 0.0861, 0.0909, 0.0917],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,465][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0299, 0.1313, 0.1119, 0.1308, 0.1105, 0.1446, 0.1237, 0.0985, 0.1188],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,465][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2525, 0.1019, 0.0856, 0.1041, 0.0910, 0.1464, 0.0712, 0.0752, 0.0722],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,465][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1548, 0.2849, 0.1080, 0.0805, 0.0973, 0.0630, 0.0626, 0.0317, 0.1173],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,466][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.6968, 0.0191, 0.0411, 0.0074, 0.0458, 0.0335, 0.1347, 0.0092, 0.0123],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,466][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ station] are: tensor([9.9718e-01, 2.3442e-04, 2.8395e-04, 5.3974e-05, 1.4347e-04, 9.8174e-05,
        6.2787e-04, 2.3955e-04, 3.5185e-04, 7.9119e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,468][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0119, 0.1201, 0.1359, 0.1035, 0.1264, 0.1032, 0.0938, 0.0960, 0.1039,
        0.1052], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,470][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0970, 0.1568, 0.1071, 0.1123, 0.1015, 0.0892, 0.0877, 0.0869, 0.0783,
        0.0831], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,474][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0951, 0.0789, 0.1140, 0.0922, 0.1151, 0.0989, 0.1014, 0.1020, 0.0965,
        0.1059], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,476][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.4450, 0.2039, 0.0931, 0.0440, 0.0532, 0.0294, 0.0369, 0.0382, 0.0208,
        0.0355], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,477][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0250, 0.1036, 0.1073, 0.1139, 0.1137, 0.1058, 0.1089, 0.0986, 0.1013,
        0.1219], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,477][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2229, 0.0407, 0.0146, 0.0377, 0.0264, 0.1108, 0.0692, 0.1511, 0.1875,
        0.1391], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,477][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.2705, 0.0863, 0.0683, 0.0687, 0.0762, 0.0727, 0.0781, 0.0843, 0.0880,
        0.1069], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,478][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0524, 0.1149, 0.0975, 0.1181, 0.0937, 0.1222, 0.1023, 0.0860, 0.1107,
        0.1021], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,478][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1912, 0.0883, 0.0822, 0.0898, 0.0862, 0.1234, 0.0561, 0.0655, 0.0707,
        0.1466], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,479][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0872, 0.1978, 0.0898, 0.0749, 0.0942, 0.0630, 0.0692, 0.0333, 0.1219,
        0.1687], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,479][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.2938, 0.0840, 0.0400, 0.0659, 0.0881, 0.0889, 0.1184, 0.0633, 0.1507,
        0.0069], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,479][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.9374e-01, 6.5986e-04, 7.2105e-04, 1.2081e-04, 4.2416e-04, 2.1014e-04,
        1.1232e-03, 3.7179e-04, 5.5745e-04, 1.5239e-03, 5.4584e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,481][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0116, 0.1083, 0.1232, 0.0884, 0.1129, 0.0944, 0.0866, 0.0844, 0.0941,
        0.1033, 0.0930], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,483][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0923, 0.1408, 0.0981, 0.1022, 0.0930, 0.0818, 0.0805, 0.0796, 0.0722,
        0.0765, 0.0831], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,487][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0832, 0.0732, 0.1010, 0.0837, 0.0979, 0.0938, 0.0913, 0.0915, 0.0902,
        0.1020, 0.0922], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,490][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.3862, 0.2040, 0.0974, 0.0470, 0.0617, 0.0285, 0.0389, 0.0429, 0.0230,
        0.0406, 0.0298], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,490][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0267, 0.0889, 0.0960, 0.0965, 0.1052, 0.0935, 0.0975, 0.0864, 0.0893,
        0.1118, 0.1084], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,490][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1342, 0.0398, 0.0115, 0.0434, 0.0369, 0.0695, 0.0815, 0.2159, 0.1231,
        0.0772, 0.1671], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,491][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.2515, 0.0761, 0.0637, 0.0616, 0.0729, 0.0652, 0.0722, 0.0760, 0.0774,
        0.0948, 0.0886], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,491][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0278, 0.1027, 0.0907, 0.0965, 0.0903, 0.1149, 0.0985, 0.0764, 0.1026,
        0.1113, 0.0883], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,491][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2315, 0.0858, 0.0695, 0.0733, 0.0759, 0.1055, 0.0509, 0.0545, 0.0568,
        0.1123, 0.0841], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,492][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1053, 0.2311, 0.0915, 0.0707, 0.0808, 0.0525, 0.0480, 0.0250, 0.1013,
        0.1141, 0.0797], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,492][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.4390, 0.0083, 0.0771, 0.0040, 0.0766, 0.0551, 0.1571, 0.0077, 0.1211,
        0.0526, 0.0015], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,493][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.9768e-01, 1.0274e-04, 8.2010e-05, 1.9035e-05, 4.6857e-05, 2.8604e-05,
        1.5563e-04, 4.8332e-05, 6.1574e-05, 2.2979e-04, 9.6228e-05, 1.4475e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,494][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0082, 0.1017, 0.1146, 0.0847, 0.1009, 0.0806, 0.0740, 0.0756, 0.0843,
        0.0882, 0.0875, 0.0996], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,497][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.0860, 0.1321, 0.0911, 0.0951, 0.0865, 0.0755, 0.0745, 0.0732, 0.0664,
        0.0704, 0.0766, 0.0725], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,501][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0850, 0.0663, 0.0956, 0.0785, 0.0763, 0.0881, 0.0848, 0.0796, 0.0772,
        0.0948, 0.0897, 0.0842], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,503][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.3896, 0.1806, 0.0915, 0.0417, 0.0564, 0.0309, 0.0398, 0.0389, 0.0207,
        0.0406, 0.0289, 0.0403], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,503][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0175, 0.0813, 0.0882, 0.0908, 0.0914, 0.0837, 0.0867, 0.0797, 0.0831,
        0.1023, 0.1030, 0.0922], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,504][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.1897, 0.0495, 0.0230, 0.0315, 0.0453, 0.0561, 0.0645, 0.0796, 0.1599,
        0.0647, 0.1371, 0.0992], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,504][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.2399, 0.0694, 0.0526, 0.0542, 0.0619, 0.0570, 0.0627, 0.0667, 0.0690,
        0.0847, 0.0803, 0.1017], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,505][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0403, 0.0982, 0.0785, 0.0992, 0.0717, 0.1040, 0.0887, 0.0717, 0.0909,
        0.0943, 0.0913, 0.0711], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,505][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.1940, 0.0796, 0.0620, 0.0654, 0.0698, 0.1080, 0.0525, 0.0559, 0.0589,
        0.1135, 0.0883, 0.0519], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,505][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.1276, 0.1565, 0.0672, 0.0572, 0.0701, 0.0500, 0.0505, 0.0257, 0.1018,
        0.1237, 0.0834, 0.0864], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,506][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.3967, 0.0765, 0.0462, 0.0333, 0.0293, 0.1232, 0.0311, 0.0419, 0.1459,
        0.0124, 0.0228, 0.0406], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,506][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([9.9093e-01, 3.2631e-04, 4.1136e-04, 6.0489e-05, 2.0335e-04, 7.9647e-05,
        3.8217e-04, 1.3246e-04, 1.5862e-04, 5.9411e-04, 1.9175e-04, 4.9098e-03,
        1.6193e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,508][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0089, 0.0884, 0.0991, 0.0782, 0.0956, 0.0764, 0.0701, 0.0715, 0.0791,
        0.0846, 0.0775, 0.0944, 0.0762], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,510][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0771, 0.1263, 0.0849, 0.0891, 0.0804, 0.0705, 0.0692, 0.0682, 0.0617,
        0.0654, 0.0714, 0.0671, 0.0686], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,514][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0665, 0.0591, 0.0840, 0.0740, 0.0828, 0.0710, 0.0791, 0.0782, 0.0803,
        0.0825, 0.0776, 0.0931, 0.0718], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,516][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.3987, 0.1884, 0.0832, 0.0412, 0.0512, 0.0284, 0.0330, 0.0347, 0.0181,
        0.0310, 0.0237, 0.0337, 0.0348], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,517][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0190, 0.0756, 0.0782, 0.0847, 0.0826, 0.0755, 0.0793, 0.0725, 0.0752,
        0.0920, 0.0897, 0.0831, 0.0928], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,517][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.1796, 0.0199, 0.0079, 0.0170, 0.0167, 0.0600, 0.0643, 0.0969, 0.1347,
        0.0451, 0.0752, 0.0393, 0.2434], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,518][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.1559, 0.0722, 0.0559, 0.0549, 0.0667, 0.0575, 0.0651, 0.0659, 0.0679,
        0.0855, 0.0776, 0.1059, 0.0691], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,518][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0418, 0.0909, 0.0718, 0.0926, 0.0714, 0.0892, 0.0789, 0.0681, 0.0805,
        0.0795, 0.0818, 0.0700, 0.0837], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,518][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.2135, 0.0725, 0.0599, 0.0661, 0.0640, 0.0924, 0.0477, 0.0494, 0.0515,
        0.1023, 0.0791, 0.0450, 0.0565], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,519][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.1490, 0.1903, 0.0621, 0.0524, 0.0627, 0.0407, 0.0462, 0.0211, 0.0837,
        0.0903, 0.0649, 0.0623, 0.0743], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,519][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.1629, 0.0404, 0.0554, 0.0435, 0.0850, 0.1680, 0.0578, 0.0681, 0.1413,
        0.0184, 0.0139, 0.1137, 0.0315], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,520][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9200e-01, 3.8729e-04, 4.2830e-04, 6.8858e-05, 1.8269e-04, 8.7390e-05,
        4.2757e-04, 1.1922e-04, 1.3102e-04, 5.7094e-04, 1.6812e-04, 3.1599e-03,
        1.3617e-03, 9.0429e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,521][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0080, 0.0839, 0.0943, 0.0697, 0.0894, 0.0739, 0.0678, 0.0645, 0.0728,
        0.0802, 0.0715, 0.0883, 0.0736, 0.0621], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,525][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0760, 0.1150, 0.0795, 0.0833, 0.0755, 0.0665, 0.0651, 0.0643, 0.0583,
        0.0616, 0.0670, 0.0634, 0.0647, 0.0597], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,528][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0694, 0.0574, 0.0811, 0.0657, 0.0771, 0.0667, 0.0683, 0.0722, 0.0710,
        0.0767, 0.0710, 0.0847, 0.0710, 0.0676], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,530][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3873, 0.1779, 0.0788, 0.0400, 0.0516, 0.0271, 0.0324, 0.0340, 0.0186,
        0.0325, 0.0234, 0.0350, 0.0340, 0.0276], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,530][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0179, 0.0691, 0.0746, 0.0752, 0.0802, 0.0714, 0.0730, 0.0660, 0.0684,
        0.0856, 0.0819, 0.0795, 0.0893, 0.0680], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,530][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0915, 0.0301, 0.0083, 0.0268, 0.0234, 0.0345, 0.0278, 0.1176, 0.0922,
        0.0452, 0.0873, 0.0487, 0.0544, 0.3121], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,531][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2220, 0.0566, 0.0473, 0.0465, 0.0546, 0.0487, 0.0539, 0.0565, 0.0578,
        0.0707, 0.0671, 0.0869, 0.0603, 0.0712], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,531][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0198, 0.0771, 0.0689, 0.0769, 0.0690, 0.0889, 0.0757, 0.0579, 0.0780,
        0.0864, 0.0679, 0.0694, 0.0953, 0.0689], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,532][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2051, 0.0752, 0.0607, 0.0602, 0.0648, 0.0868, 0.0445, 0.0449, 0.0480,
        0.0943, 0.0758, 0.0453, 0.0531, 0.0412], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,532][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0733, 0.2038, 0.0691, 0.0558, 0.0679, 0.0425, 0.0413, 0.0199, 0.0790,
        0.0877, 0.0663, 0.0666, 0.0687, 0.0581], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,532][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3773, 0.0145, 0.0291, 0.0054, 0.0562, 0.0244, 0.1788, 0.0042, 0.0334,
        0.0441, 0.0014, 0.1066, 0.1184, 0.0062], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,533][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.9346e-01, 2.0333e-04, 2.3171e-04, 3.8717e-05, 9.7949e-05, 5.1299e-05,
        2.3370e-04, 7.7860e-05, 8.8947e-05, 3.2850e-04, 9.6679e-05, 1.9798e-03,
        9.6959e-04, 6.8499e-04, 1.4546e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,536][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0065, 0.0778, 0.0887, 0.0667, 0.0852, 0.0679, 0.0613, 0.0630, 0.0689,
        0.0749, 0.0680, 0.0835, 0.0685, 0.0591, 0.0599], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,538][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0710, 0.1116, 0.0753, 0.0791, 0.0713, 0.0625, 0.0611, 0.0603, 0.0545,
        0.0578, 0.0630, 0.0590, 0.0604, 0.0556, 0.0574], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,542][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0707, 0.0538, 0.0773, 0.0638, 0.0721, 0.0642, 0.0637, 0.0655, 0.0658,
        0.0715, 0.0664, 0.0809, 0.0643, 0.0616, 0.0584], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,543][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.3571, 0.1594, 0.0821, 0.0373, 0.0502, 0.0263, 0.0337, 0.0343, 0.0197,
        0.0349, 0.0255, 0.0361, 0.0381, 0.0301, 0.0353], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,543][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0150, 0.0660, 0.0684, 0.0730, 0.0707, 0.0661, 0.0666, 0.0628, 0.0645,
        0.0787, 0.0791, 0.0704, 0.0806, 0.0662, 0.0720], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,544][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1513, 0.0264, 0.0083, 0.0271, 0.0169, 0.0474, 0.0446, 0.0625, 0.0917,
        0.0506, 0.0691, 0.0376, 0.0808, 0.0959, 0.1899], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,544][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.1797, 0.0569, 0.0452, 0.0443, 0.0517, 0.0461, 0.0510, 0.0543, 0.0560,
        0.0689, 0.0647, 0.0832, 0.0559, 0.0676, 0.0745], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,545][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0208, 0.0748, 0.0623, 0.0775, 0.0619, 0.0777, 0.0670, 0.0585, 0.0728,
        0.0753, 0.0693, 0.0617, 0.0828, 0.0689, 0.0688], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,545][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1660, 0.0697, 0.0600, 0.0649, 0.0643, 0.0891, 0.0471, 0.0452, 0.0491,
        0.0915, 0.0651, 0.0435, 0.0523, 0.0439, 0.0483], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,545][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0733, 0.1771, 0.0595, 0.0545, 0.0589, 0.0412, 0.0406, 0.0194, 0.0756,
        0.0846, 0.0642, 0.0614, 0.0731, 0.0624, 0.0542], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,546][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.4097, 0.0415, 0.0202, 0.0234, 0.0322, 0.0802, 0.0523, 0.0258, 0.1211,
        0.0068, 0.0140, 0.0467, 0.0550, 0.0445, 0.0268], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,547][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9355e-01, 2.2754e-04, 2.5674e-04, 3.9578e-05, 1.0364e-04, 4.5765e-05,
        2.4523e-04, 7.1922e-05, 6.8199e-05, 3.3852e-04, 9.0722e-05, 1.8695e-03,
        7.5926e-04, 5.8645e-04, 1.4020e-03, 3.4884e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,549][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0063, 0.0744, 0.0805, 0.0638, 0.0755, 0.0642, 0.0596, 0.0602, 0.0653,
        0.0687, 0.0656, 0.0744, 0.0659, 0.0583, 0.0563, 0.0611],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,552][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0660, 0.1080, 0.0720, 0.0755, 0.0679, 0.0594, 0.0579, 0.0571, 0.0514,
        0.0546, 0.0595, 0.0557, 0.0572, 0.0524, 0.0542, 0.0511],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,556][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0581, 0.0481, 0.0714, 0.0592, 0.0703, 0.0567, 0.0623, 0.0607, 0.0605,
        0.0696, 0.0622, 0.0772, 0.0664, 0.0609, 0.0619, 0.0544],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,557][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3981, 0.1740, 0.0763, 0.0344, 0.0459, 0.0232, 0.0296, 0.0287, 0.0148,
        0.0258, 0.0196, 0.0302, 0.0283, 0.0229, 0.0284, 0.0197],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,557][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0142, 0.0614, 0.0650, 0.0662, 0.0688, 0.0622, 0.0643, 0.0589, 0.0602,
        0.0750, 0.0723, 0.0685, 0.0787, 0.0607, 0.0672, 0.0563],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,557][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1247, 0.0289, 0.0061, 0.0185, 0.0082, 0.0396, 0.0249, 0.0561, 0.1035,
        0.0263, 0.0547, 0.0162, 0.0275, 0.0895, 0.0523, 0.3230],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,558][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1694, 0.0505, 0.0419, 0.0411, 0.0483, 0.0430, 0.0485, 0.0508, 0.0522,
        0.0648, 0.0607, 0.0785, 0.0538, 0.0633, 0.0711, 0.0621],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,558][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0145, 0.0694, 0.0592, 0.0695, 0.0601, 0.0756, 0.0664, 0.0521, 0.0640,
        0.0741, 0.0613, 0.0611, 0.0830, 0.0634, 0.0739, 0.0525],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,559][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2376, 0.0745, 0.0587, 0.0635, 0.0543, 0.0790, 0.0389, 0.0379, 0.0418,
        0.0789, 0.0583, 0.0350, 0.0423, 0.0349, 0.0387, 0.0256],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,559][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0842, 0.1731, 0.0580, 0.0494, 0.0533, 0.0363, 0.0354, 0.0178, 0.0652,
        0.0829, 0.0609, 0.0589, 0.0630, 0.0562, 0.0508, 0.0545],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,561][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.5274, 0.0263, 0.0116, 0.0081, 0.0183, 0.0231, 0.0885, 0.0105, 0.0208,
        0.0120, 0.0030, 0.0343, 0.0811, 0.0231, 0.1069, 0.0049],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,563][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([9.9717e-01, 7.1893e-05, 7.5631e-05, 1.2396e-05, 3.0025e-05, 1.4331e-05,
        7.8657e-05, 2.5494e-05, 2.4077e-05, 1.1328e-04, 2.8141e-05, 5.6974e-04,
        2.3185e-04, 1.9880e-04, 4.6149e-04, 1.1789e-04, 7.7575e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,565][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0077, 0.0683, 0.0778, 0.0603, 0.0732, 0.0588, 0.0523, 0.0561, 0.0584,
        0.0627, 0.0601, 0.0719, 0.0570, 0.0524, 0.0540, 0.0604, 0.0687],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,569][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0633, 0.1009, 0.0680, 0.0713, 0.0641, 0.0561, 0.0550, 0.0542, 0.0490,
        0.0519, 0.0566, 0.0533, 0.0543, 0.0497, 0.0515, 0.0485, 0.0522],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,570][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0593, 0.0449, 0.0665, 0.0545, 0.0657, 0.0554, 0.0575, 0.0553, 0.0560,
        0.0635, 0.0579, 0.0740, 0.0606, 0.0538, 0.0552, 0.0541, 0.0658],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,570][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.3386, 0.1634, 0.0787, 0.0366, 0.0422, 0.0278, 0.0332, 0.0305, 0.0176,
        0.0308, 0.0212, 0.0283, 0.0269, 0.0281, 0.0289, 0.0246, 0.0427],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,571][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0130, 0.0582, 0.0600, 0.0637, 0.0634, 0.0579, 0.0606, 0.0563, 0.0568,
        0.0688, 0.0692, 0.0631, 0.0725, 0.0573, 0.0638, 0.0528, 0.0626],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,571][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1202, 0.0292, 0.0076, 0.0216, 0.0109, 0.0620, 0.0277, 0.0434, 0.0910,
        0.0568, 0.0998, 0.0204, 0.0548, 0.1173, 0.0502, 0.1012, 0.0860],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,571][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.1591, 0.0484, 0.0372, 0.0380, 0.0431, 0.0406, 0.0447, 0.0468, 0.0488,
        0.0598, 0.0562, 0.0720, 0.0498, 0.0601, 0.0678, 0.0590, 0.0686],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,572][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0295, 0.0664, 0.0546, 0.0702, 0.0560, 0.0699, 0.0583, 0.0512, 0.0641,
        0.0605, 0.0618, 0.0557, 0.0666, 0.0627, 0.0605, 0.0538, 0.0580],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,572][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1708, 0.0727, 0.0633, 0.0632, 0.0627, 0.0816, 0.0437, 0.0413, 0.0427,
        0.0733, 0.0582, 0.0421, 0.0466, 0.0374, 0.0414, 0.0251, 0.0340],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,574][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0982, 0.1891, 0.0501, 0.0466, 0.0500, 0.0364, 0.0370, 0.0184, 0.0672,
        0.0690, 0.0533, 0.0467, 0.0609, 0.0471, 0.0441, 0.0492, 0.0366],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,577][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.4630, 0.0443, 0.0260, 0.0309, 0.0399, 0.0240, 0.0407, 0.0647, 0.0562,
        0.0070, 0.0168, 0.0546, 0.0452, 0.0362, 0.0294, 0.0110, 0.0103],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,579][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.9244e-01, 3.3356e-04, 3.6813e-04, 4.7954e-05, 1.1550e-04, 5.1219e-05,
        2.5009e-04, 5.4891e-05, 5.5486e-05, 2.9222e-04, 7.1506e-05, 1.4703e-03,
        5.8598e-04, 3.7877e-04, 1.0758e-03, 2.5980e-04, 1.7546e-03, 3.9652e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,583][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0059, 0.0657, 0.0732, 0.0545, 0.0691, 0.0577, 0.0519, 0.0508, 0.0568,
        0.0624, 0.0558, 0.0685, 0.0566, 0.0489, 0.0504, 0.0555, 0.0673, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,583][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0631, 0.0891, 0.0627, 0.0660, 0.0597, 0.0535, 0.0522, 0.0518, 0.0473,
        0.0499, 0.0540, 0.0510, 0.0523, 0.0485, 0.0497, 0.0472, 0.0505, 0.0517],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,584][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0537, 0.0441, 0.0626, 0.0512, 0.0600, 0.0523, 0.0541, 0.0564, 0.0551,
        0.0600, 0.0550, 0.0659, 0.0558, 0.0529, 0.0540, 0.0528, 0.0622, 0.0520],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,584][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3456, 0.1588, 0.0691, 0.0346, 0.0438, 0.0237, 0.0286, 0.0290, 0.0159,
        0.0292, 0.0206, 0.0296, 0.0297, 0.0241, 0.0305, 0.0207, 0.0398, 0.0266],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,584][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0126, 0.0541, 0.0581, 0.0585, 0.0623, 0.0555, 0.0563, 0.0512, 0.0527,
        0.0667, 0.0640, 0.0620, 0.0691, 0.0529, 0.0601, 0.0504, 0.0624, 0.0511],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,585][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0563, 0.0237, 0.0059, 0.0186, 0.0152, 0.0236, 0.0181, 0.0716, 0.0572,
        0.0287, 0.0585, 0.0306, 0.0333, 0.2009, 0.0453, 0.1119, 0.0168, 0.1837],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,585][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1794, 0.0409, 0.0353, 0.0349, 0.0401, 0.0372, 0.0412, 0.0428, 0.0442,
        0.0555, 0.0516, 0.0658, 0.0471, 0.0543, 0.0612, 0.0537, 0.0641, 0.0508],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,586][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0117, 0.0585, 0.0532, 0.0589, 0.0542, 0.0683, 0.0582, 0.0442, 0.0593,
        0.0664, 0.0523, 0.0545, 0.0741, 0.0527, 0.0673, 0.0527, 0.0626, 0.0509],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,587][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1647, 0.0675, 0.0551, 0.0573, 0.0537, 0.0746, 0.0381, 0.0414, 0.0476,
        0.0799, 0.0596, 0.0377, 0.0448, 0.0355, 0.0412, 0.0273, 0.0369, 0.0371],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,590][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0511, 0.1819, 0.0597, 0.0477, 0.0533, 0.0342, 0.0343, 0.0171, 0.0685,
        0.0764, 0.0548, 0.0527, 0.0521, 0.0482, 0.0440, 0.0525, 0.0385, 0.0331],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,594][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2660, 0.0135, 0.0268, 0.0049, 0.0500, 0.0212, 0.1437, 0.0042, 0.0258,
        0.0408, 0.0014, 0.0932, 0.0837, 0.0050, 0.1118, 0.0216, 0.0810, 0.0053],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,627][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:18,628][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,630][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,632][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,635][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,637][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,637][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,638][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,638][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,638][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,639][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,639][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,639][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,650][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,650][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9601, 0.0399], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,650][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7526, 0.2474], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,651][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8540, 0.1460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,651][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9607, 0.0393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,651][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7620, 0.2380], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,652][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4378, 0.5622], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,652][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5044, 0.4956], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,652][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6637, 0.3363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,653][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0930, 0.9070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,654][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4072, 0.5928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,657][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3742, 0.6258], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,660][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.9976, 0.0012, 0.0012], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,663][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.8727, 0.0271, 0.1002], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,663][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.3857, 0.2924, 0.3219], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,664][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.5768, 0.1604, 0.2627], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,664][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.9772, 0.0145, 0.0082], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,664][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.4416, 0.4351, 0.1233], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,665][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.3446, 0.1666, 0.4888], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,665][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.3222, 0.3293, 0.3484], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,665][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.3284, 0.4281, 0.2435], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,665][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.0443, 0.4136, 0.5421], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,666][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.1748, 0.2559, 0.5693], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,667][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.0954, 0.5064, 0.3982], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,669][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9709e-01, 1.1002e-03, 1.0334e-03, 7.7208e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,672][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5735, 0.0140, 0.1194, 0.2932], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,676][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3388, 0.1976, 0.2412, 0.2224], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,676][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5350, 0.1441, 0.1822, 0.1387], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,677][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9018, 0.0353, 0.0168, 0.0461], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,677][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3870, 0.2804, 0.1062, 0.2264], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,677][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1637, 0.2595, 0.2298, 0.3470], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,678][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2032, 0.2445, 0.3099, 0.2425], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,678][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3000, 0.1911, 0.1683, 0.3406], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,678][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0199, 0.2536, 0.3506, 0.3758], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,679][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1459, 0.4049, 0.3455, 0.1037], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,679][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0914, 0.3121, 0.3507, 0.2459], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,679][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([9.9622e-01, 1.0443e-03, 9.4206e-04, 7.4952e-04, 1.0449e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,681][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.6597, 0.0113, 0.0464, 0.2510, 0.0316], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,683][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.1892, 0.1856, 0.2299, 0.2103, 0.1850], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,687][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.2410, 0.1384, 0.1618, 0.2614, 0.1976], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,690][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.9470, 0.0119, 0.0076, 0.0265, 0.0070], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,690][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.2198, 0.2638, 0.1103, 0.3044, 0.1018], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,690][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.2385, 0.1231, 0.2896, 0.1080, 0.2408], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,691][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1625, 0.1396, 0.1655, 0.2037, 0.3287], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,691][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1876, 0.0934, 0.0671, 0.3816, 0.2703], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,691][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0190, 0.1921, 0.2557, 0.2779, 0.2554], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,691][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.2099, 0.1769, 0.2949, 0.1144, 0.2038], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,692][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0418, 0.1277, 0.1256, 0.1985, 0.5064], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:18,692][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.9936, 0.0014, 0.0013, 0.0010, 0.0014, 0.0013], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,693][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.5106, 0.0059, 0.0256, 0.1471, 0.0243, 0.2865], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,694][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.2101, 0.1556, 0.1832, 0.1612, 0.1685, 0.1214], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,697][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1310, 0.1063, 0.1628, 0.1218, 0.2440, 0.2340], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,701][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.8472, 0.0363, 0.0124, 0.0458, 0.0089, 0.0495], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,703][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.2853, 0.2264, 0.0674, 0.2500, 0.0887, 0.0822], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,703][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.1146, 0.1682, 0.1497, 0.1334, 0.1367, 0.2974], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,703][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0670, 0.1295, 0.1533, 0.1544, 0.3080, 0.1878], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,704][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0655, 0.1016, 0.0592, 0.1723, 0.2945, 0.3069], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,704][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0118, 0.1538, 0.2074, 0.2243, 0.2066, 0.1961], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,704][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.1179, 0.1955, 0.2392, 0.1118, 0.2535, 0.0822], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,705][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0233, 0.1237, 0.0770, 0.0902, 0.4216, 0.2642], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:18,705][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([9.9304e-01, 1.2082e-03, 1.1282e-03, 8.7250e-04, 1.2148e-03, 1.1499e-03,
        1.3875e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,705][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.8397, 0.0038, 0.0159, 0.0382, 0.0090, 0.0661, 0.0272],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,706][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.1522, 0.1156, 0.1386, 0.1454, 0.1471, 0.1346, 0.1665],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,708][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.3120, 0.0719, 0.0756, 0.0699, 0.1019, 0.1582, 0.2106],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,710][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.6244, 0.0444, 0.0165, 0.0979, 0.0158, 0.1173, 0.0838],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,714][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.1503, 0.2256, 0.0748, 0.2601, 0.1037, 0.0970, 0.0885],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,716][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.1449, 0.1539, 0.1333, 0.1239, 0.1154, 0.1867, 0.1418],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,717][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.1381, 0.0921, 0.0883, 0.0894, 0.1431, 0.1089, 0.3401],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,717][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.2048, 0.0222, 0.0185, 0.0414, 0.0667, 0.1179, 0.5285],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,717][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0105, 0.1320, 0.1749, 0.1873, 0.1727, 0.1659, 0.1568],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,718][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0513, 0.1943, 0.1544, 0.1487, 0.2095, 0.1631, 0.0787],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,718][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0384, 0.0441, 0.0405, 0.0357, 0.1305, 0.1326, 0.5782],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:18,718][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.9490e-01, 8.1372e-04, 7.4459e-04, 5.6696e-04, 7.9899e-04, 7.5405e-04,
        9.2455e-04, 5.0089e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,719][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.8711, 0.0014, 0.0083, 0.0146, 0.0052, 0.0165, 0.0161, 0.0670],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,719][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1541, 0.1078, 0.1259, 0.1267, 0.1183, 0.1102, 0.1243, 0.1326],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,720][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3361, 0.0498, 0.0571, 0.0500, 0.0762, 0.1019, 0.1823, 0.1464],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,723][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.8287, 0.0181, 0.0084, 0.0240, 0.0068, 0.0290, 0.0356, 0.0495],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,727][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1631, 0.1861, 0.0712, 0.2082, 0.0841, 0.0936, 0.0960, 0.0978],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,729][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0685, 0.1229, 0.0960, 0.1212, 0.0951, 0.1156, 0.0556, 0.3250],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,730][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1481, 0.0439, 0.0550, 0.0531, 0.0811, 0.0660, 0.3035, 0.2493],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,730][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.1420, 0.0092, 0.0060, 0.0223, 0.0213, 0.0590, 0.3294, 0.4110],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,731][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0098, 0.1117, 0.1485, 0.1590, 0.1457, 0.1407, 0.1343, 0.1502],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,731][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0842, 0.1316, 0.2270, 0.1030, 0.2366, 0.0727, 0.0545, 0.0904],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,731][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0427, 0.0211, 0.0264, 0.0132, 0.0693, 0.0670, 0.5637, 0.1967],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:18,732][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.9352e-01, 9.0837e-04, 8.4016e-04, 6.4787e-04, 9.0754e-04, 8.4994e-04,
        1.0465e-03, 5.7416e-04, 7.1026e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,732][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.7512, 0.0015, 0.0092, 0.0174, 0.0063, 0.0286, 0.0206, 0.1312, 0.0340],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,732][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1393, 0.1051, 0.1101, 0.1159, 0.1078, 0.0999, 0.1383, 0.1229, 0.0607],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,734][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.3031, 0.0381, 0.0409, 0.0361, 0.0583, 0.0930, 0.1444, 0.1576, 0.1285],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,736][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.8421, 0.0133, 0.0062, 0.0192, 0.0047, 0.0198, 0.0261, 0.0429, 0.0256],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,740][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2267, 0.1741, 0.0571, 0.1588, 0.0622, 0.0699, 0.0720, 0.1090, 0.0704],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,743][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1375, 0.1074, 0.0895, 0.0862, 0.0803, 0.1410, 0.0381, 0.1031, 0.2169],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,743][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1321, 0.0390, 0.0376, 0.0309, 0.0564, 0.0504, 0.2014, 0.2503, 0.2020],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,744][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1578, 0.0075, 0.0042, 0.0128, 0.0222, 0.0344, 0.2306, 0.4120, 0.1186],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,744][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0084, 0.0964, 0.1279, 0.1401, 0.1264, 0.1223, 0.1184, 0.1340, 0.1261],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,744][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1009, 0.1210, 0.1755, 0.0706, 0.1852, 0.0836, 0.0517, 0.1067, 0.1048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,745][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0316, 0.0131, 0.0149, 0.0087, 0.0588, 0.0529, 0.3547, 0.3282, 0.1371],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:18,745][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([9.9168e-01, 1.0073e-03, 9.4237e-04, 7.3872e-04, 1.0237e-03, 9.6579e-04,
        1.2053e-03, 6.8219e-04, 8.4733e-04, 9.0393e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,745][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.5331, 0.0034, 0.0120, 0.0376, 0.0080, 0.0814, 0.0289, 0.2200, 0.0664,
        0.0091], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,746][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0951, 0.0923, 0.1074, 0.1115, 0.1071, 0.0903, 0.1246, 0.1148, 0.0525,
        0.1043], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,747][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.2852, 0.0277, 0.0265, 0.0285, 0.0512, 0.0677, 0.1236, 0.1596, 0.1170,
        0.1131], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,750][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.7919, 0.0114, 0.0058, 0.0208, 0.0059, 0.0311, 0.0343, 0.0490, 0.0409,
        0.0088], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,754][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.2250, 0.1702, 0.0520, 0.1601, 0.0538, 0.0680, 0.0671, 0.1019, 0.0646,
        0.0374], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,756][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0856, 0.0960, 0.0890, 0.0803, 0.0782, 0.1154, 0.0361, 0.1148, 0.1157,
        0.1887], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,756][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1420, 0.0293, 0.0234, 0.0209, 0.0305, 0.0325, 0.0994, 0.1560, 0.1395,
        0.3265], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,757][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1554, 0.0026, 0.0014, 0.0048, 0.0057, 0.0147, 0.0992, 0.1561, 0.1181,
        0.4420], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,757][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0070, 0.0870, 0.1148, 0.1214, 0.1140, 0.1081, 0.1031, 0.1155, 0.1120,
        0.1171], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,757][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0578, 0.1380, 0.1098, 0.0845, 0.1221, 0.0940, 0.0464, 0.0895, 0.1926,
        0.0653], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,758][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0323, 0.0080, 0.0054, 0.0040, 0.0175, 0.0222, 0.1335, 0.1809, 0.0974,
        0.4988], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:18,758][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.9033e-01, 1.0996e-03, 1.0351e-03, 7.8653e-04, 1.1085e-03, 1.0252e-03,
        1.2503e-03, 7.0821e-04, 8.7384e-04, 9.6391e-04, 8.1625e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,759][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.6320, 0.0013, 0.0084, 0.0146, 0.0061, 0.0366, 0.0224, 0.1543, 0.0439,
        0.0062, 0.0742], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,759][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1334, 0.0861, 0.0838, 0.0984, 0.0874, 0.0742, 0.1114, 0.1051, 0.0423,
        0.0957, 0.0822], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,761][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1614, 0.0331, 0.0266, 0.0259, 0.0338, 0.0774, 0.1104, 0.1353, 0.1225,
        0.1122, 0.1615], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,763][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.7846, 0.0201, 0.0076, 0.0228, 0.0046, 0.0211, 0.0243, 0.0579, 0.0284,
        0.0089, 0.0196], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,767][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.2695, 0.1335, 0.0443, 0.1123, 0.0551, 0.0526, 0.0613, 0.0884, 0.0497,
        0.0393, 0.0940], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,769][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0735, 0.0807, 0.0863, 0.0797, 0.0957, 0.0688, 0.0343, 0.1230, 0.0762,
        0.1365, 0.1453], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,770][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0436, 0.0250, 0.0243, 0.0153, 0.0346, 0.0298, 0.1206, 0.1411, 0.1317,
        0.3021, 0.1320], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,770][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0582, 0.0047, 0.0024, 0.0054, 0.0104, 0.0183, 0.0781, 0.1474, 0.0955,
        0.4213, 0.1584], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,770][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0070, 0.0768, 0.1018, 0.1092, 0.1016, 0.0969, 0.0931, 0.1042, 0.0997,
        0.1062, 0.1036], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,771][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0887, 0.0900, 0.1527, 0.0610, 0.1191, 0.0418, 0.0396, 0.0963, 0.1505,
        0.0665, 0.0938], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,771][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0263, 0.0107, 0.0109, 0.0043, 0.0333, 0.0240, 0.1378, 0.1238, 0.0813,
        0.4146, 0.1328], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:18,772][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([9.9085e-01, 9.1142e-04, 8.1346e-04, 6.4697e-04, 8.7483e-04, 8.2660e-04,
        1.0236e-03, 5.7562e-04, 7.2053e-04, 7.9956e-04, 7.0150e-04, 1.2545e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,772][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.5505, 0.0012, 0.0032, 0.0151, 0.0031, 0.0453, 0.0191, 0.1809, 0.0442,
        0.0050, 0.0868, 0.0455], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,772][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0809, 0.0778, 0.0968, 0.0899, 0.0783, 0.0762, 0.1032, 0.0914, 0.0457,
        0.1010, 0.0836, 0.0753], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,774][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.1904, 0.0207, 0.0147, 0.0245, 0.0151, 0.0555, 0.0830, 0.1049, 0.0760,
        0.0740, 0.1582, 0.1830], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,776][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.9240, 0.0042, 0.0027, 0.0062, 0.0027, 0.0118, 0.0092, 0.0148, 0.0113,
        0.0029, 0.0063, 0.0039], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,780][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.1045, 0.1298, 0.0605, 0.1548, 0.0513, 0.0526, 0.0577, 0.0895, 0.0660,
        0.0431, 0.1482, 0.0420], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,783][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.1145, 0.0558, 0.1272, 0.0492, 0.1060, 0.0621, 0.0257, 0.0616, 0.0817,
        0.0889, 0.1024, 0.1249], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,783][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1070, 0.0165, 0.0096, 0.0114, 0.0144, 0.0170, 0.0633, 0.0817, 0.0806,
        0.1728, 0.1219, 0.3039], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,783][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.1426, 0.0017, 0.0007, 0.0023, 0.0018, 0.0052, 0.0469, 0.0553, 0.0282,
        0.2013, 0.1371, 0.3769], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,784][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0073, 0.0718, 0.0909, 0.0978, 0.0902, 0.0899, 0.0850, 0.0931, 0.0912,
        0.0955, 0.0952, 0.0921], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,784][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.1270, 0.0878, 0.1339, 0.0590, 0.0899, 0.0569, 0.0231, 0.0602, 0.0770,
        0.0492, 0.1422, 0.0937], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,785][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0284, 0.0023, 0.0016, 0.0012, 0.0043, 0.0074, 0.0449, 0.0498, 0.0222,
        0.1558, 0.0629, 0.6192], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:18,785][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([9.8791e-01, 1.0497e-03, 9.8275e-04, 7.5710e-04, 1.0539e-03, 9.7458e-04,
        1.1990e-03, 6.9281e-04, 8.5556e-04, 9.4248e-04, 8.0885e-04, 1.4906e-03,
        1.2868e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,785][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.6416, 0.0007, 0.0016, 0.0097, 0.0018, 0.0153, 0.0089, 0.0997, 0.0311,
        0.0031, 0.0688, 0.0387, 0.0790], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,787][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.1140, 0.0673, 0.0763, 0.0850, 0.0696, 0.0698, 0.1077, 0.0851, 0.0370,
        0.0712, 0.0697, 0.0679, 0.0793], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,789][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.1344, 0.0167, 0.0186, 0.0178, 0.0254, 0.0308, 0.0773, 0.0778, 0.0716,
        0.0723, 0.0844, 0.2213, 0.1517], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,793][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.7393, 0.0142, 0.0056, 0.0228, 0.0042, 0.0286, 0.0222, 0.0590, 0.0341,
        0.0078, 0.0218, 0.0067, 0.0337], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,796][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0957, 0.1505, 0.0436, 0.1843, 0.0487, 0.0438, 0.0528, 0.0829, 0.0637,
        0.0381, 0.1077, 0.0381, 0.0500], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,796][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0416, 0.0627, 0.0593, 0.0438, 0.0563, 0.0930, 0.0461, 0.0858, 0.0868,
        0.0721, 0.0802, 0.0655, 0.2067], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,797][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0309, 0.0132, 0.0095, 0.0093, 0.0180, 0.0136, 0.0524, 0.0780, 0.0604,
        0.1307, 0.0874, 0.3022, 0.1943], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,797][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0308, 0.0009, 0.0006, 0.0016, 0.0024, 0.0039, 0.0228, 0.0394, 0.0204,
        0.1337, 0.0858, 0.4232, 0.2346], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,797][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0054, 0.0651, 0.0832, 0.0899, 0.0835, 0.0801, 0.0773, 0.0868, 0.0844,
        0.0897, 0.0886, 0.0869, 0.0790], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,798][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0394, 0.0917, 0.0834, 0.0697, 0.0915, 0.0584, 0.0315, 0.0617, 0.1375,
        0.0815, 0.1234, 0.0980, 0.0323], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,798][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0084, 0.0016, 0.0016, 0.0008, 0.0055, 0.0034, 0.0271, 0.0222, 0.0141,
        0.1222, 0.0251, 0.5585, 0.2096], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:18,799][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8845e-01, 9.5568e-04, 8.7240e-04, 6.7194e-04, 9.2623e-04, 8.7109e-04,
        1.0748e-03, 6.0181e-04, 7.3754e-04, 8.3581e-04, 7.1611e-04, 1.2781e-03,
        1.1355e-03, 8.7472e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,800][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([8.2581e-01, 2.4765e-04, 1.2744e-03, 3.3929e-03, 1.0756e-03, 5.9925e-03,
        5.0063e-03, 2.7041e-02, 8.1870e-03, 1.5287e-03, 1.8623e-02, 2.1458e-02,
        3.0841e-02, 4.9524e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,802][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0971, 0.0663, 0.0703, 0.0785, 0.0760, 0.0611, 0.0809, 0.0869, 0.0361,
        0.0720, 0.0661, 0.0747, 0.0792, 0.0548], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,805][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2957, 0.0153, 0.0146, 0.0141, 0.0176, 0.0295, 0.0464, 0.0579, 0.0509,
        0.0484, 0.0556, 0.1201, 0.1196, 0.1144], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,809][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8535, 0.0147, 0.0046, 0.0126, 0.0039, 0.0101, 0.0121, 0.0310, 0.0151,
        0.0047, 0.0089, 0.0056, 0.0149, 0.0082], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,810][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1945, 0.1203, 0.0373, 0.1225, 0.0435, 0.0462, 0.0486, 0.0714, 0.0465,
        0.0348, 0.0811, 0.0343, 0.0721, 0.0470], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,810][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0701, 0.0573, 0.0557, 0.0586, 0.0745, 0.0584, 0.0209, 0.0903, 0.0689,
        0.0977, 0.0914, 0.0841, 0.0661, 0.1059], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,810][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0948, 0.0129, 0.0078, 0.0071, 0.0100, 0.0130, 0.0484, 0.0604, 0.0474,
        0.1045, 0.0638, 0.1497, 0.1574, 0.2225], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,811][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1052, 0.0009, 0.0005, 0.0011, 0.0014, 0.0032, 0.0188, 0.0336, 0.0145,
        0.1427, 0.0565, 0.1672, 0.1839, 0.2703], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,811][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0055, 0.0605, 0.0794, 0.0845, 0.0783, 0.0748, 0.0714, 0.0797, 0.0774,
        0.0807, 0.0812, 0.0790, 0.0729, 0.0748], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,812][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0533, 0.0599, 0.1259, 0.0350, 0.1531, 0.0532, 0.0312, 0.0585, 0.0801,
        0.0529, 0.0562, 0.1528, 0.0416, 0.0465], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,812][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0300, 0.0018, 0.0018, 0.0008, 0.0053, 0.0045, 0.0309, 0.0184, 0.0112,
        0.1007, 0.0234, 0.3326, 0.1906, 0.2479], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:18,813][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([9.8695e-01, 9.5755e-04, 8.7210e-04, 6.7749e-04, 9.3679e-04, 8.8015e-04,
        1.0895e-03, 6.1405e-04, 7.5848e-04, 8.5112e-04, 7.3845e-04, 1.3268e-03,
        1.1859e-03, 9.2034e-04, 1.2362e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,814][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([8.2269e-01, 1.8024e-04, 8.4459e-04, 1.9192e-03, 5.7195e-04, 3.3117e-03,
        2.4671e-03, 1.7740e-02, 5.6770e-03, 9.2188e-04, 1.3963e-02, 1.0540e-02,
        1.7115e-02, 3.6226e-02, 6.5827e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,818][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0886, 0.0566, 0.0766, 0.0670, 0.0781, 0.0548, 0.0777, 0.0756, 0.0366,
        0.0756, 0.0647, 0.0760, 0.0812, 0.0461, 0.0448], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,820][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.3149, 0.0102, 0.0107, 0.0103, 0.0127, 0.0202, 0.0330, 0.0468, 0.0414,
        0.0387, 0.0447, 0.1185, 0.0949, 0.0969, 0.1061], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,824][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.8431, 0.0099, 0.0044, 0.0111, 0.0037, 0.0137, 0.0133, 0.0252, 0.0186,
        0.0063, 0.0085, 0.0060, 0.0166, 0.0044, 0.0151], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,825][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1468, 0.1254, 0.0361, 0.1432, 0.0336, 0.0431, 0.0368, 0.0730, 0.0489,
        0.0296, 0.1135, 0.0274, 0.0517, 0.0586, 0.0321], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,825][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0593, 0.0579, 0.0554, 0.0500, 0.0570, 0.0611, 0.0302, 0.0562, 0.0666,
        0.0844, 0.0710, 0.0680, 0.0952, 0.0522, 0.1355], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,826][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0697, 0.0094, 0.0074, 0.0052, 0.0087, 0.0084, 0.0257, 0.0419, 0.0322,
        0.0676, 0.0505, 0.1463, 0.1021, 0.1730, 0.2519], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,826][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([4.7851e-02, 6.1149e-04, 1.9832e-04, 5.9725e-04, 6.9905e-04, 1.7249e-03,
        8.6369e-03, 2.2805e-02, 1.1068e-02, 6.7786e-02, 3.8162e-02, 1.0534e-01,
        9.7850e-02, 2.5812e-01, 3.3855e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,826][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0046, 0.0556, 0.0732, 0.0781, 0.0726, 0.0696, 0.0661, 0.0740, 0.0719,
        0.0758, 0.0745, 0.0737, 0.0677, 0.0700, 0.0726], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,827][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0805, 0.0632, 0.0859, 0.0537, 0.0818, 0.0803, 0.0390, 0.0576, 0.1063,
        0.0411, 0.0694, 0.0950, 0.0405, 0.0691, 0.0364], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,828][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0131, 0.0009, 0.0007, 0.0004, 0.0027, 0.0024, 0.0152, 0.0126, 0.0096,
        0.0537, 0.0147, 0.2073, 0.0922, 0.2494, 0.3250], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:18,830][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.8625e-01, 9.5224e-04, 8.7125e-04, 6.7469e-04, 9.4272e-04, 8.7859e-04,
        1.0907e-03, 6.0576e-04, 7.3858e-04, 8.4175e-04, 7.2270e-04, 1.3105e-03,
        1.1518e-03, 8.9556e-04, 1.2210e-03, 8.5267e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,832][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.2449e-01, 1.6059e-04, 9.7633e-04, 2.2170e-03, 7.6702e-04, 2.9808e-03,
        4.2599e-03, 2.6685e-02, 8.2578e-03, 1.5416e-03, 2.1163e-02, 2.3118e-02,
        3.4209e-02, 8.2745e-02, 1.3953e-01, 2.6898e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,836][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0871, 0.0637, 0.0700, 0.0667, 0.0704, 0.0565, 0.0791, 0.0701, 0.0357,
        0.0717, 0.0617, 0.0692, 0.0778, 0.0484, 0.0453, 0.0265],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,837][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1216, 0.0085, 0.0103, 0.0127, 0.0161, 0.0223, 0.0499, 0.0531, 0.0419,
        0.0419, 0.0498, 0.1298, 0.1111, 0.1227, 0.1453, 0.0630],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,838][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6602, 0.0230, 0.0077, 0.0237, 0.0053, 0.0180, 0.0195, 0.0533, 0.0245,
        0.0087, 0.0176, 0.0085, 0.0272, 0.0130, 0.0396, 0.0503],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,838][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1201, 0.1212, 0.0412, 0.1054, 0.0423, 0.0450, 0.0507, 0.0767, 0.0481,
        0.0354, 0.0872, 0.0342, 0.0744, 0.0516, 0.0318, 0.0346],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,839][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0655, 0.0541, 0.0438, 0.0436, 0.0437, 0.0636, 0.0215, 0.0696, 0.0981,
        0.0817, 0.0888, 0.0519, 0.0599, 0.0479, 0.0674, 0.0987],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,839][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0297, 0.0056, 0.0039, 0.0038, 0.0052, 0.0062, 0.0246, 0.0336, 0.0264,
        0.0679, 0.0386, 0.0959, 0.1033, 0.1640, 0.3119, 0.0794],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,839][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.1810e-02, 3.2998e-04, 1.5822e-04, 5.9631e-04, 8.1990e-04, 1.1086e-03,
        8.8943e-03, 1.6327e-02, 5.4872e-03, 5.9969e-02, 3.0208e-02, 1.2072e-01,
        8.1102e-02, 2.2456e-01, 4.0412e-01, 3.3786e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,840][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0047, 0.0523, 0.0686, 0.0738, 0.0667, 0.0644, 0.0613, 0.0683, 0.0664,
        0.0697, 0.0703, 0.0685, 0.0632, 0.0648, 0.0689, 0.0680],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,840][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0385, 0.0628, 0.0966, 0.0368, 0.1302, 0.0441, 0.0323, 0.0612, 0.0742,
        0.0672, 0.0623, 0.1299, 0.0384, 0.0558, 0.0388, 0.0309],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,841][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.0788e-03, 4.1820e-04, 4.0074e-04, 3.2106e-04, 1.4709e-03, 1.8129e-03,
        1.4158e-02, 1.0986e-02, 4.7325e-03, 5.7383e-02, 9.9009e-03, 1.3695e-01,
        1.0014e-01, 1.8852e-01, 4.4407e-01, 2.5653e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:18,842][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.8639e-01, 8.5351e-04, 7.7355e-04, 6.0564e-04, 8.3609e-04, 7.8693e-04,
        9.8718e-04, 5.5689e-04, 6.8382e-04, 7.6802e-04, 6.6444e-04, 1.1955e-03,
        1.0611e-03, 8.3479e-04, 1.1297e-03, 7.9483e-04, 1.0743e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,846][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.2675, 0.0010, 0.0022, 0.0108, 0.0020, 0.0171, 0.0074, 0.0873, 0.0183,
        0.0029, 0.0328, 0.0238, 0.0436, 0.1651, 0.2394, 0.0755, 0.0034],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,849][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0672, 0.0523, 0.0703, 0.0636, 0.0767, 0.0516, 0.0853, 0.0723, 0.0342,
        0.0643, 0.0562, 0.0722, 0.0704, 0.0444, 0.0464, 0.0236, 0.0491],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,851][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1917, 0.0068, 0.0067, 0.0090, 0.0122, 0.0159, 0.0389, 0.0405, 0.0275,
        0.0303, 0.0312, 0.1068, 0.0767, 0.0966, 0.1333, 0.0565, 0.1193],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,851][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.8687, 0.0042, 0.0025, 0.0065, 0.0028, 0.0101, 0.0123, 0.0132, 0.0120,
        0.0048, 0.0047, 0.0036, 0.0105, 0.0024, 0.0103, 0.0257, 0.0056],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,851][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.1029, 0.1128, 0.0360, 0.1232, 0.0400, 0.0408, 0.0496, 0.0738, 0.0461,
        0.0278, 0.0919, 0.0318, 0.0654, 0.0544, 0.0390, 0.0356, 0.0288],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,852][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0916, 0.0517, 0.0440, 0.0449, 0.0410, 0.0576, 0.0170, 0.0430, 0.0663,
        0.0879, 0.0871, 0.0534, 0.0708, 0.0492, 0.0527, 0.0385, 0.1034],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,852][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0741, 0.0063, 0.0031, 0.0029, 0.0038, 0.0060, 0.0193, 0.0272, 0.0203,
        0.0471, 0.0252, 0.0678, 0.0633, 0.1175, 0.2494, 0.0702, 0.1965],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,853][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([7.8505e-02, 2.0047e-04, 8.6271e-05, 2.4755e-04, 3.2410e-04, 7.0421e-04,
        5.3352e-03, 1.0193e-02, 3.3950e-03, 3.3732e-02, 1.6262e-02, 6.1888e-02,
        4.4687e-02, 1.4357e-01, 3.4985e-01, 3.0552e-02, 2.2048e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,853][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0042, 0.0491, 0.0651, 0.0683, 0.0641, 0.0602, 0.0577, 0.0640, 0.0617,
        0.0636, 0.0650, 0.0650, 0.0584, 0.0611, 0.0653, 0.0638, 0.0634],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,855][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0561, 0.1265, 0.0692, 0.0488, 0.0801, 0.0451, 0.0216, 0.0524, 0.0801,
        0.0432, 0.0867, 0.0911, 0.0376, 0.0551, 0.0399, 0.0368, 0.0299],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,857][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([1.4923e-02, 3.9891e-04, 3.4857e-04, 1.8414e-04, 9.6447e-04, 9.1493e-04,
        9.3501e-03, 7.7530e-03, 4.2801e-03, 3.8816e-02, 8.4389e-03, 1.0086e-01,
        5.0529e-02, 1.5474e-01, 2.9620e-01, 2.5372e-02, 2.8593e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:18,859][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8372e-01, 9.6523e-04, 8.9799e-04, 6.8395e-04, 9.6097e-04, 9.1062e-04,
        1.1375e-03, 6.3211e-04, 7.6693e-04, 8.7587e-04, 7.4569e-04, 1.3452e-03,
        1.1977e-03, 9.2313e-04, 1.2672e-03, 8.8275e-04, 1.1989e-03, 8.8397e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,861][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9580e-01, 2.0700e-04, 1.2352e-03, 3.7981e-03, 1.0583e-03, 6.7264e-03,
        5.1332e-03, 3.2297e-02, 1.0092e-02, 1.4149e-03, 2.4727e-02, 2.0218e-02,
        3.3719e-02, 6.1855e-02, 1.2835e-01, 4.0040e-02, 2.7443e-03, 3.0590e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,863][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0854, 0.0561, 0.0600, 0.0682, 0.0624, 0.0536, 0.0647, 0.0734, 0.0307,
        0.0583, 0.0565, 0.0618, 0.0647, 0.0470, 0.0426, 0.0243, 0.0449, 0.0452],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,864][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1249, 0.0090, 0.0100, 0.0110, 0.0128, 0.0219, 0.0380, 0.0470, 0.0396,
        0.0401, 0.0416, 0.0958, 0.0813, 0.0931, 0.1229, 0.0632, 0.1099, 0.0379],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,864][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8740, 0.0098, 0.0026, 0.0080, 0.0024, 0.0056, 0.0067, 0.0186, 0.0091,
        0.0027, 0.0048, 0.0031, 0.0080, 0.0046, 0.0117, 0.0218, 0.0027, 0.0038],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,865][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1445, 0.1075, 0.0326, 0.1123, 0.0377, 0.0417, 0.0416, 0.0611, 0.0411,
        0.0303, 0.0791, 0.0300, 0.0639, 0.0414, 0.0331, 0.0357, 0.0320, 0.0339],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,865][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0585, 0.0433, 0.0446, 0.0465, 0.0596, 0.0413, 0.0144, 0.0678, 0.0517,
        0.0773, 0.0721, 0.0674, 0.0473, 0.0813, 0.0618, 0.0421, 0.0495, 0.0733],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,866][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0259, 0.0047, 0.0026, 0.0032, 0.0035, 0.0059, 0.0223, 0.0311, 0.0242,
        0.0550, 0.0320, 0.0634, 0.0729, 0.1157, 0.2562, 0.0717, 0.1707, 0.0391],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,866][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1249e-02, 2.3400e-04, 1.0508e-04, 4.0309e-04, 4.0235e-04, 1.0077e-03,
        6.9894e-03, 1.0980e-02, 5.7822e-03, 5.9763e-02, 2.1885e-02, 5.9266e-02,
        6.3246e-02, 1.1311e-01, 3.5933e-01, 3.2789e-02, 2.1989e-01, 3.3566e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,867][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0042, 0.0459, 0.0602, 0.0638, 0.0590, 0.0567, 0.0537, 0.0601, 0.0587,
        0.0613, 0.0616, 0.0596, 0.0551, 0.0566, 0.0610, 0.0602, 0.0609, 0.0615],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,869][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0459, 0.0524, 0.0992, 0.0312, 0.1344, 0.0422, 0.0271, 0.0548, 0.0708,
        0.0475, 0.0449, 0.1348, 0.0366, 0.0402, 0.0267, 0.0303, 0.0420, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,871][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.4421e-03, 4.0761e-04, 4.9906e-04, 2.8342e-04, 1.5078e-03, 1.6647e-03,
        1.3220e-02, 6.8012e-03, 5.3917e-03, 4.8574e-02, 1.1699e-02, 1.1431e-01,
        8.0020e-02, 1.1308e-01, 3.2804e-01, 2.6085e-02, 2.1137e-01, 3.3605e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:18,872][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:18,874][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5684],
        [18328],
        [35919],
        [12099],
        [ 9708],
        [ 9628],
        [ 3835],
        [ 3564],
        [ 8643],
        [13382],
        [ 5145],
        [12007],
        [ 5791],
        [ 3705],
        [ 5956],
        [ 7081],
        [13865],
        [ 3305]], device='cuda:0')
[2024-07-24 10:30:18,877][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5835],
        [15334],
        [48795],
        [ 8878],
        [16608],
        [18275],
        [ 6817],
        [ 5642],
        [15274],
        [23754],
        [ 4290],
        [23547],
        [14273],
        [ 7434],
        [11187],
        [16186],
        [29537],
        [ 8855]], device='cuda:0')
[2024-07-24 10:30:18,879][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38032],
        [38069],
        [38075],
        [38165],
        [38068],
        [38378],
        [38140],
        [38131],
        [38132],
        [38162],
        [38327],
        [38154],
        [38471],
        [38423],
        [38381],
        [38384],
        [38193],
        [38402]], device='cuda:0')
[2024-07-24 10:30:18,880][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20871],
        [28813],
        [24080],
        [25796],
        [24792],
        [27724],
        [26715],
        [27118],
        [26886],
        [26588],
        [26852],
        [26500],
        [26386],
        [26984],
        [27267],
        [27868],
        [28359],
        [28693]], device='cuda:0')
[2024-07-24 10:30:18,881][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[4081],
        [3208],
        [2764],
        [2735],
        [2876],
        [2751],
        [2633],
        [2520],
        [2473],
        [2424],
        [2356],
        [2425],
        [2359],
        [2330],
        [2274],
        [2225],
        [2189],
        [2163]], device='cuda:0')
[2024-07-24 10:30:18,882][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7767],
        [14638],
        [13789],
        [15123],
        [16810],
        [16417],
        [16947],
        [17638],
        [16344],
        [15568],
        [14591],
        [15230],
        [15022],
        [13689],
        [13664],
        [12689],
        [13178],
        [12399]], device='cuda:0')
[2024-07-24 10:30:18,883][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[2328],
        [1928],
        [ 706],
        [ 733],
        [ 504],
        [ 597],
        [ 617],
        [ 547],
        [ 556],
        [ 657],
        [ 651],
        [ 570],
        [ 625],
        [ 696],
        [ 666],
        [ 683],
        [ 836],
        [ 901]], device='cuda:0')
[2024-07-24 10:30:18,885][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 6848],
        [19185],
        [22010],
        [20844],
        [19014],
        [18825],
        [18213],
        [17819],
        [17548],
        [16879],
        [17283],
        [16952],
        [17278],
        [17094],
        [17014],
        [16911],
        [16858],
        [16727]], device='cuda:0')
[2024-07-24 10:30:18,887][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17343],
        [ 6913],
        [10412],
        [ 6111],
        [ 9128],
        [ 5491],
        [ 3505],
        [ 2855],
        [ 2873],
        [ 2240],
        [ 2091],
        [ 3088],
        [ 1792],
        [ 1511],
        [ 1717],
        [ 2004],
        [ 1718],
        [ 1296]], device='cuda:0')
[2024-07-24 10:30:18,888][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7349],
        [ 9129],
        [16741],
        [16102],
        [18363],
        [20162],
        [21300],
        [21857],
        [22240],
        [22639],
        [22666],
        [23354],
        [24486],
        [23918],
        [24389],
        [24743],
        [24387],
        [24174]], device='cuda:0')
[2024-07-24 10:30:18,890][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[26894],
        [27190],
        [25515],
        [23887],
        [23899],
        [23626],
        [24411],
        [24751],
        [24907],
        [26122],
        [25986],
        [25716],
        [26150],
        [26550],
        [26056],
        [25818],
        [25968],
        [26247]], device='cuda:0')
[2024-07-24 10:30:18,893][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20490],
        [13124],
        [19889],
        [18562],
        [19813],
        [19696],
        [18678],
        [17718],
        [16950],
        [16268],
        [16056],
        [16279],
        [16338],
        [16514],
        [16744],
        [16854],
        [17053],
        [16934]], device='cuda:0')
[2024-07-24 10:30:18,895][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[46847],
        [39186],
        [40876],
        [40195],
        [41195],
        [40696],
        [39988],
        [40040],
        [40098],
        [39779],
        [39824],
        [40026],
        [39395],
        [39180],
        [38780],
        [38830],
        [38708],
        [38829]], device='cuda:0')
[2024-07-24 10:30:18,896][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15934],
        [15930],
        [19889],
        [17129],
        [22538],
        [20818],
        [19515],
        [17529],
        [17638],
        [19214],
        [16767],
        [17111],
        [18029],
        [18485],
        [16135],
        [13825],
        [18251],
        [15474]], device='cuda:0')
[2024-07-24 10:30:18,897][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7216],
        [30334],
        [15391],
        [32200],
        [19543],
        [20353],
        [20414],
        [20480],
        [16410],
        [17513],
        [30844],
        [16803],
        [13524],
        [20056],
        [21054],
        [17676],
        [17718],
        [14989]], device='cuda:0')
[2024-07-24 10:30:18,898][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21222],
        [21202],
        [21123],
        [21082],
        [21044],
        [20932],
        [20926],
        [20985],
        [20932],
        [20831],
        [20758],
        [20762],
        [20615],
        [20633],
        [20587],
        [20557],
        [20572],
        [20450]], device='cuda:0')
[2024-07-24 10:30:18,900][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[46207],
        [46911],
        [44490],
        [38706],
        [40146],
        [38903],
        [46428],
        [47341],
        [45065],
        [41429],
        [42661],
        [41293],
        [42412],
        [46585],
        [46833],
        [43527],
        [40546],
        [43100]], device='cuda:0')
[2024-07-24 10:30:18,901][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[19449],
        [25965],
        [25978],
        [25411],
        [25801],
        [25364],
        [26918],
        [27552],
        [28188],
        [28885],
        [28588],
        [28727],
        [28669],
        [28711],
        [28649],
        [28581],
        [29157],
        [28956]], device='cuda:0')
[2024-07-24 10:30:18,903][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[28184],
        [39378],
        [23118],
        [30394],
        [29739],
        [29786],
        [31363],
        [29448],
        [28059],
        [25257],
        [27072],
        [22330],
        [19556],
        [22896],
        [21201],
        [21415],
        [22903],
        [23401]], device='cuda:0')
[2024-07-24 10:30:18,904][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20752],
        [22958],
        [21285],
        [29234],
        [25496],
        [30281],
        [19562],
        [28907],
        [29523],
        [25593],
        [26819],
        [25916],
        [21681],
        [30164],
        [29524],
        [22056],
        [29980],
        [30063]], device='cuda:0')
[2024-07-24 10:30:18,906][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14458],
        [ 6361],
        [ 3195],
        [ 3331],
        [ 3016],
        [ 4090],
        [ 4685],
        [ 5907],
        [ 5940],
        [ 5986],
        [ 5728],
        [ 5035],
        [ 4927],
        [ 5780],
        [ 5373],
        [ 5750],
        [ 5621],
        [ 5854]], device='cuda:0')
[2024-07-24 10:30:18,909][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34214],
        [22642],
        [24461],
        [23722],
        [21618],
        [20611],
        [22256],
        [21468],
        [21973],
        [20727],
        [20621],
        [19860],
        [15932],
        [18550],
        [18070],
        [19310],
        [19570],
        [19307]], device='cuda:0')
[2024-07-24 10:30:18,911][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[45662],
        [37321],
        [20607],
        [30312],
        [29113],
        [22174],
        [23391],
        [16983],
        [13782],
        [18155],
        [16988],
        [16178],
        [15681],
        [18141],
        [14563],
        [15040],
        [19304],
        [18990]], device='cuda:0')
[2024-07-24 10:30:18,912][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[11400],
        [17647],
        [24930],
        [29508],
        [32324],
        [32302],
        [33763],
        [40168],
        [38977],
        [33708],
        [34960],
        [31133],
        [30593],
        [29980],
        [33756],
        [34082],
        [34854],
        [35252]], device='cuda:0')
[2024-07-24 10:30:18,913][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34594],
        [24434],
        [26481],
        [25269],
        [25855],
        [24984],
        [24395],
        [24033],
        [23981],
        [24045],
        [24076],
        [24336],
        [24298],
        [24251],
        [24222],
        [24154],
        [24277],
        [24291]], device='cuda:0')
[2024-07-24 10:30:18,915][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44008],
        [45910],
        [36533],
        [44092],
        [40191],
        [41429],
        [44043],
        [42981],
        [44192],
        [44716],
        [44383],
        [44331],
        [44708],
        [43807],
        [45133],
        [44494],
        [45080],
        [44181]], device='cuda:0')
[2024-07-24 10:30:18,916][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34449],
        [40298],
        [16065],
        [19756],
        [26872],
        [16789],
        [10442],
        [10625],
        [ 9164],
        [18310],
        [20394],
        [35606],
        [34768],
        [28378],
        [18954],
        [15019],
        [14752],
        [14603]], device='cuda:0')
[2024-07-24 10:30:18,917][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1099],
        [1291],
        [7323],
        [3983],
        [4242],
        [6095],
        [5769],
        [4383],
        [5960],
        [6299],
        [5798],
        [5757],
        [7166],
        [4794],
        [5835],
        [7836],
        [6461],
        [6075]], device='cuda:0')
[2024-07-24 10:30:18,919][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25136],
        [ 3840],
        [14260],
        [ 6159],
        [ 9565],
        [ 8047],
        [ 6380],
        [10381],
        [11330],
        [ 9530],
        [ 5602],
        [11964],
        [14227],
        [10311],
        [11631],
        [ 8865],
        [ 8058],
        [ 8917]], device='cuda:0')
[2024-07-24 10:30:18,920][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962],
        [10962]], device='cuda:0')
[2024-07-24 10:30:18,959][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:18,963][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,963][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,964][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,964][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,964][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,965][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,965][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,965][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,966][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,966][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,967][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,969][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:18,970][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9934e-01, 6.6350e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,974][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2074, 0.7926], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,976][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,977][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6121, 0.3879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,977][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3300, 0.6700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,977][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9823, 0.0177], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,978][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,978][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0742, 0.9258], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,978][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3092, 0.6908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,979][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4117, 0.5883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,980][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0117, 0.9883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,983][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0861, 0.9139], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:18,986][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.9761, 0.0175, 0.0064], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,989][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.1645, 0.3677, 0.4678], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,989][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.0632, 0.8126, 0.1242], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,990][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.7474, 0.0906, 0.1620], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,990][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.0470, 0.6426, 0.3104], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,990][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.7881, 0.0970, 0.1149], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,990][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.9904, 0.0042, 0.0054], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,991][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.1062, 0.2491, 0.6447], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,991][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.0500, 0.4441, 0.5059], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,991][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.7756, 0.0231, 0.2013], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,992][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.0297, 0.3997, 0.5706], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,992][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.0152, 0.2015, 0.7833], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:18,993][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9224e-01, 1.5789e-03, 5.9921e-03, 1.9353e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,995][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0445, 0.2578, 0.2951, 0.4025], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:18,998][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0049, 0.6836, 0.1454, 0.1661], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,002][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4254, 0.0878, 0.2019, 0.2848], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,002][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0876, 0.3557, 0.1237, 0.4330], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,003][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9530, 0.0189, 0.0184, 0.0097], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,003][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9927, 0.0023, 0.0030, 0.0020], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,003][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0213, 0.0711, 0.4832, 0.4243], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,004][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0404, 0.2509, 0.2657, 0.4430], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,004][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2402, 0.0082, 0.1752, 0.5763], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,004][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0022, 0.1538, 0.5220, 0.3221], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,005][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0088, 0.1741, 0.7022, 0.1149], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,006][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.9314, 0.0261, 0.0216, 0.0101, 0.0108], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,009][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0833, 0.1513, 0.2025, 0.3005, 0.2624], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,012][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.0048, 0.6438, 0.0980, 0.1095, 0.1440], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,015][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.4004, 0.0555, 0.1280, 0.2153, 0.2008], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,015][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0196, 0.2276, 0.0579, 0.4807, 0.2141], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,016][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.6321, 0.0876, 0.0868, 0.0937, 0.0998], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,016][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.9887, 0.0024, 0.0037, 0.0022, 0.0029], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,016][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0923, 0.1339, 0.2514, 0.2853, 0.2370], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,017][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0074, 0.0460, 0.0999, 0.2486, 0.5982], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,017][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.1436, 0.0108, 0.0974, 0.7142, 0.0340], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,017][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0051, 0.1952, 0.4120, 0.2438, 0.1440], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,018][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0038, 0.3430, 0.4590, 0.1621, 0.0322], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,018][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.9338, 0.0077, 0.0287, 0.0065, 0.0224, 0.0010], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,019][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0143, 0.1305, 0.1467, 0.2088, 0.1983, 0.3013], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,022][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0007, 0.6010, 0.0376, 0.1528, 0.1030, 0.1049], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,026][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.1074, 0.0513, 0.2009, 0.1875, 0.2652, 0.1877], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,028][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0331, 0.1398, 0.0286, 0.1971, 0.1221, 0.4792], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,029][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.8481, 0.0418, 0.0288, 0.0176, 0.0317, 0.0320], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,029][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.9886, 0.0016, 0.0022, 0.0015, 0.0019, 0.0042], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,029][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1155, 0.1470, 0.1804, 0.2230, 0.1467, 0.1875], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,030][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0056, 0.0390, 0.0562, 0.1107, 0.4257, 0.3628], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,030][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0201, 0.0032, 0.1068, 0.2799, 0.0306, 0.5595], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,030][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ were] are: tensor([2.9025e-04, 1.3858e-01, 9.7022e-02, 4.4199e-01, 1.9731e-01, 1.2481e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,030][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0089, 0.1350, 0.3066, 0.1651, 0.0650, 0.3193], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,031][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ working] are: tensor([9.6740e-01, 1.1944e-02, 2.1929e-03, 1.2533e-02, 4.9905e-03, 6.1538e-04,
        3.2021e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,034][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0401, 0.0850, 0.1156, 0.1705, 0.1454, 0.2498, 0.1935],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,037][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0020, 0.3511, 0.0722, 0.1272, 0.0841, 0.2025, 0.1609],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,040][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.1560, 0.0441, 0.1074, 0.1501, 0.1642, 0.1489, 0.2292],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,041][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0403, 0.0453, 0.0059, 0.0438, 0.0218, 0.1367, 0.7061],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,041][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.7501, 0.0476, 0.0437, 0.0379, 0.0353, 0.0616, 0.0238],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,042][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.9322, 0.0071, 0.0091, 0.0063, 0.0088, 0.0181, 0.0184],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,042][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.1877, 0.1794, 0.1302, 0.1699, 0.1020, 0.1198, 0.1109],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,042][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0110, 0.0046, 0.0046, 0.0119, 0.0439, 0.0433, 0.8807],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,043][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0389, 0.0040, 0.0419, 0.1849, 0.0193, 0.4409, 0.2701],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,043][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0004, 0.1549, 0.2505, 0.2118, 0.1809, 0.1655, 0.0360],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,043][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0010, 0.0631, 0.2581, 0.0977, 0.0980, 0.4051, 0.0771],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,044][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.1627e-01, 7.3124e-03, 3.3724e-02, 5.2172e-03, 2.2313e-02, 3.3549e-03,
        1.1010e-02, 8.0098e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,045][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0163, 0.0965, 0.0930, 0.1392, 0.1208, 0.2022, 0.1915, 0.1406],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,048][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0007, 0.2765, 0.0811, 0.1058, 0.1015, 0.0869, 0.2752, 0.0724],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,051][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1176, 0.0365, 0.0893, 0.1162, 0.1297, 0.1263, 0.2138, 0.1706],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,054][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0740, 0.0131, 0.0016, 0.0113, 0.0057, 0.0492, 0.2102, 0.6351],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,054][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.9664, 0.0078, 0.0055, 0.0025, 0.0044, 0.0075, 0.0025, 0.0034],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,055][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.9698, 0.0028, 0.0040, 0.0025, 0.0029, 0.0060, 0.0072, 0.0047],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,055][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2182, 0.1752, 0.1059, 0.1481, 0.0784, 0.0910, 0.0878, 0.0953],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,055][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0407, 0.0034, 0.0025, 0.0040, 0.0119, 0.0282, 0.6055, 0.3038],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,056][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0873, 0.0012, 0.0286, 0.0645, 0.0117, 0.1772, 0.1696, 0.4598],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,056][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0010, 0.1151, 0.1577, 0.3246, 0.1227, 0.1275, 0.0502, 0.1012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,056][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0099, 0.1451, 0.2622, 0.1411, 0.0527, 0.2158, 0.1196, 0.0536],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,058][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.8647, 0.0211, 0.0399, 0.0069, 0.0171, 0.0040, 0.0182, 0.0201, 0.0080],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,061][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0134, 0.0742, 0.0840, 0.1235, 0.1101, 0.1784, 0.1623, 0.1461, 0.1080],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,065][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0015, 0.1398, 0.0483, 0.0719, 0.0616, 0.1254, 0.2013, 0.1382, 0.2118],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,067][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1324, 0.0285, 0.0731, 0.0897, 0.0979, 0.0978, 0.1818, 0.1702, 0.1285],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,067][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0573, 0.0081, 0.0007, 0.0073, 0.0027, 0.0250, 0.1430, 0.4935, 0.2624],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,067][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.9732, 0.0052, 0.0035, 0.0020, 0.0034, 0.0051, 0.0017, 0.0043, 0.0017],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,068][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.9786, 0.0017, 0.0022, 0.0015, 0.0019, 0.0039, 0.0050, 0.0030, 0.0023],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,068][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2575, 0.1991, 0.0956, 0.1301, 0.0637, 0.0719, 0.0606, 0.0725, 0.0490],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,069][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0129, 0.0020, 0.0016, 0.0027, 0.0124, 0.0125, 0.3162, 0.4883, 0.1514],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,069][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0369, 0.0010, 0.0187, 0.0553, 0.0060, 0.1114, 0.1062, 0.4796, 0.1849],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,069][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0005, 0.0481, 0.0684, 0.1677, 0.0846, 0.1164, 0.0550, 0.1885, 0.2709],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,070][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0015, 0.1800, 0.2402, 0.1009, 0.0499, 0.1737, 0.0920, 0.1198, 0.0420],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,071][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ station] are: tensor([9.9473e-01, 8.1973e-04, 6.2285e-04, 4.9836e-04, 9.8577e-04, 3.8622e-05,
        3.6716e-04, 6.7009e-04, 1.0929e-03, 1.7659e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,073][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0643, 0.0732, 0.0729, 0.1186, 0.0837, 0.1637, 0.1196, 0.1268, 0.1038,
        0.0734], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,076][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0041, 0.1746, 0.0514, 0.0549, 0.0513, 0.1221, 0.1266, 0.1409, 0.2550,
        0.0192], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,080][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1712, 0.0296, 0.0495, 0.0850, 0.0768, 0.0943, 0.1392, 0.1491, 0.1014,
        0.1039], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,080][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ station] are: tensor([2.6994e-02, 2.8171e-03, 3.1391e-04, 2.5413e-03, 1.2333e-03, 1.2326e-02,
        6.6990e-02, 2.4831e-01, 2.5896e-01, 3.7951e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,081][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.9736, 0.0042, 0.0029, 0.0023, 0.0027, 0.0038, 0.0012, 0.0034, 0.0015,
        0.0043], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,081][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.9505, 0.0037, 0.0044, 0.0031, 0.0035, 0.0072, 0.0087, 0.0065, 0.0052,
        0.0073], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,081][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.2727, 0.1899, 0.0827, 0.1116, 0.0600, 0.0663, 0.0521, 0.0643, 0.0477,
        0.0527], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,082][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ station] are: tensor([2.3204e-02, 1.3229e-03, 3.4565e-04, 1.1585e-03, 2.1426e-03, 4.2418e-03,
        5.0503e-02, 1.8238e-01, 1.5232e-01, 5.8238e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,082][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0357, 0.0019, 0.0115, 0.0635, 0.0057, 0.1352, 0.0953, 0.4352, 0.1970,
        0.0190], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,082][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ station] are: tensor([2.5107e-04, 6.2206e-02, 1.0402e-01, 1.1839e-01, 1.0840e-01, 9.3936e-02,
        4.1010e-02, 1.4579e-01, 2.6963e-01, 5.6358e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,084][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0093, 0.1298, 0.2642, 0.0837, 0.0758, 0.1049, 0.0898, 0.1314, 0.0573,
        0.0538], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,087][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.8794, 0.0033, 0.0184, 0.0009, 0.0167, 0.0016, 0.0162, 0.0050, 0.0222,
        0.0278, 0.0085], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,091][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0118, 0.0657, 0.0694, 0.1038, 0.0918, 0.1481, 0.1444, 0.1132, 0.0926,
        0.0749, 0.0843], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,093][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0004, 0.1597, 0.0403, 0.0592, 0.0584, 0.1164, 0.1584, 0.0967, 0.2495,
        0.0328, 0.0282], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,093][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.2819, 0.0190, 0.0413, 0.0483, 0.0613, 0.0608, 0.0988, 0.1005, 0.0824,
        0.0883, 0.1176], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,094][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0126, 0.0045, 0.0005, 0.0029, 0.0017, 0.0110, 0.0328, 0.1638, 0.1607,
        0.2535, 0.3561], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,094][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.9711, 0.0059, 0.0028, 0.0014, 0.0026, 0.0036, 0.0012, 0.0025, 0.0014,
        0.0047, 0.0028], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,094][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.9579, 0.0026, 0.0033, 0.0022, 0.0025, 0.0059, 0.0065, 0.0053, 0.0042,
        0.0060, 0.0036], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,095][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1334, 0.1319, 0.0956, 0.1163, 0.0729, 0.0794, 0.0781, 0.0788, 0.0675,
        0.0718, 0.0744], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,095][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0048, 0.0013, 0.0008, 0.0011, 0.0078, 0.0063, 0.0843, 0.2168, 0.1045,
        0.4868, 0.0856], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,096][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1127, 0.0006, 0.0081, 0.0163, 0.0028, 0.0476, 0.0426, 0.1610, 0.0806,
        0.0125, 0.5154], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,096][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.1678e-04, 3.6511e-02, 1.2597e-01, 1.0117e-01, 9.9774e-02, 7.1491e-02,
        3.1797e-02, 8.4283e-02, 2.3520e-01, 8.6913e-02, 1.2668e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,098][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0034, 0.0443, 0.1498, 0.0369, 0.0588, 0.1225, 0.2469, 0.0978, 0.0766,
        0.1050, 0.0581], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,099][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.4442e-01, 6.0886e-03, 4.4905e-03, 2.6505e-03, 2.3987e-03, 4.4161e-04,
        3.3391e-03, 5.3253e-03, 8.1464e-03, 4.3614e-03, 7.4812e-03, 1.0854e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,100][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0267, 0.0537, 0.0698, 0.0907, 0.0812, 0.1387, 0.1136, 0.1111, 0.0862,
        0.0662, 0.0746, 0.0875], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,100][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.0008, 0.2098, 0.0322, 0.0308, 0.0442, 0.0877, 0.1168, 0.0889, 0.2517,
        0.0270, 0.0426, 0.0675], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,101][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.2469, 0.0182, 0.0295, 0.0595, 0.0463, 0.0554, 0.0985, 0.0887, 0.0695,
        0.0849, 0.0891, 0.1134], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,103][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([2.3089e-02, 2.0492e-03, 2.8930e-04, 1.1800e-03, 7.1636e-04, 3.4949e-03,
        2.5666e-02, 1.0268e-01, 8.7719e-02, 1.4828e-01, 1.8645e-01, 4.1838e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,106][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.8679, 0.0119, 0.0051, 0.0050, 0.0044, 0.0150, 0.0066, 0.0093, 0.0046,
        0.0265, 0.0142, 0.0296], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,108][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.9474, 0.0028, 0.0039, 0.0025, 0.0029, 0.0070, 0.0081, 0.0044, 0.0044,
        0.0076, 0.0050, 0.0040], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,108][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.2479, 0.1742, 0.0790, 0.1064, 0.0537, 0.0630, 0.0500, 0.0596, 0.0402,
        0.0434, 0.0462, 0.0363], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,108][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([1.5260e-02, 4.6941e-04, 2.7581e-04, 5.5129e-04, 1.2238e-03, 1.0716e-03,
        1.8096e-02, 5.0645e-02, 3.3586e-02, 1.8238e-01, 3.4798e-02, 6.6164e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,109][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.1038, 0.0007, 0.0057, 0.0251, 0.0023, 0.0597, 0.0414, 0.2954, 0.0781,
        0.0108, 0.3495, 0.0272], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,109][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0005, 0.0789, 0.0699, 0.0827, 0.0370, 0.1197, 0.0629, 0.0948, 0.2602,
        0.0347, 0.1239, 0.0348], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,110][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0031, 0.2219, 0.2102, 0.0994, 0.0148, 0.1049, 0.0727, 0.0720, 0.0251,
        0.0703, 0.0941, 0.0115], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,110][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([9.8168e-01, 2.5217e-03, 5.5654e-04, 1.7415e-03, 1.1047e-03, 2.6312e-04,
        3.3904e-04, 3.0165e-03, 3.0905e-03, 3.1145e-04, 1.6587e-03, 3.6421e-03,
        7.3504e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,112][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0207, 0.0547, 0.0559, 0.0847, 0.0725, 0.1195, 0.1035, 0.0987, 0.0784,
        0.0546, 0.0749, 0.0699, 0.1120], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,114][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0009, 0.0751, 0.0253, 0.0391, 0.0421, 0.1086, 0.0986, 0.1254, 0.2218,
        0.0214, 0.0590, 0.0475, 0.1353], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,118][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.1219, 0.0164, 0.0364, 0.0553, 0.0629, 0.0535, 0.0889, 0.1009, 0.0639,
        0.0708, 0.0979, 0.1460, 0.0852], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,120][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([1.4058e-02, 1.5106e-03, 2.2053e-04, 1.4541e-03, 7.4790e-04, 4.4178e-03,
        2.7554e-02, 7.8364e-02, 6.4777e-02, 1.0692e-01, 1.2370e-01, 2.6381e-01,
        3.1246e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,121][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.9326, 0.0089, 0.0025, 0.0030, 0.0021, 0.0045, 0.0018, 0.0047, 0.0035,
        0.0077, 0.0069, 0.0111, 0.0109], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,121][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.9409, 0.0025, 0.0035, 0.0024, 0.0030, 0.0071, 0.0078, 0.0055, 0.0045,
        0.0076, 0.0043, 0.0041, 0.0069], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,122][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.2124, 0.1593, 0.0776, 0.1035, 0.0500, 0.0608, 0.0507, 0.0569, 0.0437,
        0.0515, 0.0530, 0.0384, 0.0422], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,122][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([1.5446e-03, 1.7441e-04, 7.8716e-05, 2.4475e-04, 9.2317e-04, 9.0542e-04,
        9.4398e-03, 2.9199e-02, 1.6690e-02, 1.0604e-01, 2.3181e-02, 6.3806e-01,
        1.7352e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,122][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0308, 0.0005, 0.0062, 0.0233, 0.0030, 0.0384, 0.0433, 0.1730, 0.0775,
        0.0120, 0.4243, 0.0474, 0.1203], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,123][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([1.6894e-04, 3.0108e-02, 2.7157e-02, 6.7128e-02, 4.1719e-02, 4.5614e-02,
        3.6835e-02, 1.3421e-01, 2.3807e-01, 9.7027e-02, 1.9173e-01, 4.2297e-02,
        4.7942e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,123][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0048, 0.1050, 0.1420, 0.0629, 0.0809, 0.1378, 0.0955, 0.0983, 0.0687,
        0.0310, 0.1105, 0.0580, 0.0047], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,123][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.6904e-01, 1.2391e-03, 4.7140e-03, 5.2908e-04, 3.7984e-03, 3.3406e-04,
        1.7219e-03, 3.1156e-04, 2.3523e-03, 2.5082e-03, 5.7153e-04, 1.0222e-02,
        2.3573e-03, 2.9942e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,125][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0129, 0.0474, 0.0486, 0.0768, 0.0687, 0.1145, 0.1077, 0.0828, 0.0743,
        0.0547, 0.0629, 0.0598, 0.1143, 0.0748], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,128][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0008, 0.0938, 0.0492, 0.0422, 0.0516, 0.0694, 0.1238, 0.0511, 0.1935,
        0.0226, 0.0370, 0.0540, 0.1394, 0.0717], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,132][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0641, 0.0152, 0.0408, 0.0591, 0.0643, 0.0528, 0.1009, 0.0839, 0.0614,
        0.0771, 0.0912, 0.1363, 0.0819, 0.0710], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,134][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.9344e-02, 1.4609e-03, 1.7228e-04, 8.4973e-04, 4.2024e-04, 4.0607e-03,
        1.4284e-02, 5.4675e-02, 3.3591e-02, 1.1767e-01, 7.7480e-02, 1.0732e-01,
        1.7140e-01, 3.1726e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,134][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.8404e-01, 2.0218e-03, 1.0221e-03, 6.0501e-04, 7.7703e-04, 1.2998e-03,
        4.2007e-04, 6.9422e-04, 3.6992e-04, 1.8321e-03, 9.3791e-04, 2.4823e-03,
        1.4078e-03, 2.0924e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,135][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.9465, 0.0024, 0.0033, 0.0023, 0.0028, 0.0054, 0.0070, 0.0043, 0.0036,
        0.0060, 0.0037, 0.0033, 0.0058, 0.0037], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,135][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1408, 0.1061, 0.0748, 0.0895, 0.0568, 0.0619, 0.0620, 0.0702, 0.0571,
        0.0611, 0.0598, 0.0493, 0.0481, 0.0626], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,135][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.2785e-02, 3.0753e-04, 1.1934e-04, 2.0233e-04, 8.5644e-04, 8.2230e-04,
        1.7410e-02, 2.9829e-02, 1.2094e-02, 1.0465e-01, 1.4485e-02, 2.6749e-01,
        1.9145e-01, 3.3749e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,136][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0470, 0.0004, 0.0049, 0.0233, 0.0026, 0.0424, 0.0439, 0.1487, 0.0648,
        0.0089, 0.3280, 0.0313, 0.1222, 0.1317], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,136][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.2527e-04, 2.8814e-02, 5.0607e-02, 7.7721e-02, 3.6506e-02, 6.1101e-02,
        1.4480e-02, 4.1046e-02, 2.6567e-01, 6.3810e-02, 2.0471e-01, 4.5786e-02,
        6.5671e-02, 4.3944e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,138][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0025, 0.0693, 0.1137, 0.0607, 0.0313, 0.1625, 0.1373, 0.0834, 0.0914,
        0.0628, 0.0428, 0.0438, 0.0156, 0.0828], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,140][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.3465e-01, 4.6540e-03, 3.6034e-03, 4.8713e-03, 3.6892e-03, 4.5475e-04,
        1.2119e-03, 4.3450e-03, 1.1107e-02, 2.8486e-03, 6.9295e-03, 1.2420e-02,
        1.5616e-03, 7.2219e-03, 4.3578e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,143][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0129, 0.0386, 0.0519, 0.0701, 0.0682, 0.1091, 0.0933, 0.0835, 0.0643,
        0.0453, 0.0578, 0.0600, 0.0961, 0.0699, 0.0787], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,147][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0006, 0.1122, 0.0400, 0.0519, 0.0392, 0.0897, 0.0874, 0.0727, 0.1808,
        0.0157, 0.0414, 0.0300, 0.0857, 0.0974, 0.0554], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,147][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0834, 0.0140, 0.0346, 0.0491, 0.0539, 0.0394, 0.0796, 0.0728, 0.0514,
        0.0700, 0.0777, 0.1263, 0.0741, 0.0702, 0.1036], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,147][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([1.9214e-02, 6.2920e-04, 6.9497e-05, 4.5952e-04, 2.3053e-04, 2.2829e-03,
        1.0996e-02, 3.2271e-02, 2.7477e-02, 4.4787e-02, 4.3630e-02, 8.8466e-02,
        1.0720e-01, 2.6422e-01, 3.5807e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,148][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([9.5392e-01, 3.9231e-03, 2.2496e-03, 1.6301e-03, 1.8585e-03, 2.1402e-03,
        8.4660e-04, 1.5866e-03, 8.7381e-04, 5.1378e-03, 2.2310e-03, 8.6102e-03,
        3.1342e-03, 6.3747e-03, 5.4849e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,148][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.9320, 0.0025, 0.0034, 0.0025, 0.0031, 0.0068, 0.0068, 0.0055, 0.0041,
        0.0062, 0.0042, 0.0037, 0.0059, 0.0048, 0.0086], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,149][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.2385, 0.1559, 0.0655, 0.0847, 0.0454, 0.0498, 0.0407, 0.0479, 0.0372,
        0.0431, 0.0395, 0.0320, 0.0339, 0.0472, 0.0387], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,149][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([8.3352e-03, 1.0494e-04, 6.6798e-05, 1.1865e-04, 3.7769e-04, 4.3391e-04,
        4.4715e-03, 1.1938e-02, 7.3922e-03, 5.9596e-02, 9.8778e-03, 1.6826e-01,
        6.9164e-02, 1.6518e-01, 4.9468e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,149][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([2.4365e-02, 1.8456e-04, 3.1750e-03, 1.4381e-02, 1.8116e-03, 2.2728e-02,
        3.5335e-02, 1.1419e-01, 5.2154e-02, 8.3741e-03, 2.3158e-01, 2.8165e-02,
        8.0017e-02, 1.4326e-01, 2.4028e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,151][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([4.5937e-05, 2.1418e-02, 4.5991e-02, 8.2213e-02, 4.5844e-02, 6.3107e-02,
        2.8868e-02, 9.2532e-02, 2.4489e-01, 6.3219e-02, 1.0816e-01, 5.0225e-02,
        4.7781e-02, 8.3141e-02, 2.2567e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,153][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0005, 0.0788, 0.1703, 0.0638, 0.0520, 0.1483, 0.0973, 0.0830, 0.0540,
        0.0568, 0.0449, 0.0521, 0.0084, 0.0716, 0.0182], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,156][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.9085, 0.0092, 0.0062, 0.0040, 0.0062, 0.0015, 0.0040, 0.0044, 0.0043,
        0.0065, 0.0040, 0.0198, 0.0035, 0.0058, 0.0037, 0.0083],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,160][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0076, 0.0444, 0.0452, 0.0665, 0.0609, 0.0987, 0.0932, 0.0680, 0.0589,
        0.0486, 0.0520, 0.0515, 0.0920, 0.0624, 0.0726, 0.0774],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,160][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.1244, 0.0322, 0.0583, 0.0331, 0.0655, 0.0889, 0.0651, 0.1352,
        0.0184, 0.0480, 0.0282, 0.0838, 0.0866, 0.0838, 0.0481],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,161][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0189, 0.0099, 0.0300, 0.0506, 0.0532, 0.0393, 0.0784, 0.0680, 0.0559,
        0.0659, 0.0918, 0.1236, 0.0783, 0.0692, 0.1082, 0.0588],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,161][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.3068e-02, 5.0679e-04, 6.2398e-05, 6.2462e-04, 1.8625e-04, 1.4967e-03,
        9.8173e-03, 3.6958e-02, 2.0540e-02, 3.1847e-02, 3.8420e-02, 6.3998e-02,
        7.2867e-02, 3.4504e-01, 3.1272e-01, 5.1851e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,162][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9197, 0.0055, 0.0025, 0.0023, 0.0018, 0.0044, 0.0013, 0.0031, 0.0019,
        0.0079, 0.0054, 0.0086, 0.0061, 0.0133, 0.0138, 0.0023],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,162][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.7032e-01, 1.2808e-03, 1.3498e-03, 9.3029e-04, 1.1871e-03, 2.3626e-03,
        2.9433e-03, 2.0907e-03, 1.4415e-03, 2.3151e-03, 1.6807e-03, 1.4979e-03,
        2.4829e-03, 1.8156e-03, 4.0925e-03, 2.2068e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,163][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2394, 0.1483, 0.0663, 0.0859, 0.0423, 0.0464, 0.0403, 0.0439, 0.0328,
        0.0398, 0.0374, 0.0284, 0.0307, 0.0462, 0.0380, 0.0338],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,164][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([6.4294e-04, 2.3399e-05, 1.3740e-05, 2.7712e-05, 8.5987e-05, 1.3489e-04,
        3.1451e-03, 6.0607e-03, 2.0920e-03, 3.0433e-02, 2.6704e-03, 5.8905e-02,
        6.3326e-02, 1.0232e-01, 6.9974e-01, 3.0377e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,165][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.7021e-03, 1.3387e-04, 2.2554e-03, 1.4015e-02, 1.2705e-03, 1.6998e-02,
        2.2686e-02, 9.6687e-02, 3.9832e-02, 5.7940e-03, 2.3624e-01, 2.2648e-02,
        9.0404e-02, 1.1762e-01, 2.8346e-01, 4.5256e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,167][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.0806e-04, 3.2482e-02, 3.4960e-02, 1.0315e-01, 2.4890e-02, 4.5626e-02,
        1.8139e-02, 5.7652e-02, 1.5278e-01, 4.0403e-02, 1.9589e-01, 4.7972e-02,
        5.9422e-02, 6.3079e-02, 6.3214e-02, 6.0232e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,170][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0005, 0.1238, 0.0989, 0.0911, 0.0341, 0.1652, 0.0683, 0.0760, 0.0466,
        0.0510, 0.0410, 0.0424, 0.0183, 0.1079, 0.0170, 0.0181],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,173][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([9.7771e-01, 1.5421e-03, 6.7668e-04, 1.4993e-03, 6.0039e-04, 1.8261e-04,
        2.4325e-04, 3.4625e-03, 1.5257e-03, 4.1851e-04, 4.7507e-04, 1.7415e-03,
        1.0513e-04, 2.1806e-03, 1.8841e-04, 6.0479e-03, 1.4028e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,173][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0460, 0.0374, 0.0394, 0.0612, 0.0399, 0.0843, 0.0592, 0.0684, 0.0517,
        0.0361, 0.0517, 0.0424, 0.0749, 0.0599, 0.0711, 0.0897, 0.0867],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,174][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0007, 0.1080, 0.0271, 0.0362, 0.0228, 0.0618, 0.0763, 0.0809, 0.1303,
        0.0103, 0.0333, 0.0277, 0.1083, 0.0870, 0.1080, 0.0492, 0.0323],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,174][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0832, 0.0127, 0.0257, 0.0509, 0.0425, 0.0362, 0.0697, 0.0734, 0.0447,
        0.0597, 0.0625, 0.0885, 0.0576, 0.0674, 0.0987, 0.0500, 0.0766],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,174][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([2.1991e-02, 2.7636e-04, 3.0305e-05, 2.4538e-04, 1.0243e-04, 7.7065e-04,
        5.6455e-03, 2.3321e-02, 1.3024e-02, 3.8373e-02, 2.0514e-02, 4.3165e-02,
        4.3773e-02, 2.4143e-01, 3.4603e-01, 3.6587e-02, 1.6472e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,175][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([9.5523e-01, 1.8847e-03, 1.9205e-03, 1.0474e-03, 1.7821e-03, 1.9044e-03,
        8.9575e-04, 1.8285e-03, 8.6859e-04, 3.3050e-03, 1.3140e-03, 7.2584e-03,
        2.5305e-03, 5.9073e-03, 5.7771e-03, 1.7681e-03, 4.7824e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,175][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.9041, 0.0021, 0.0031, 0.0023, 0.0024, 0.0077, 0.0085, 0.0053, 0.0055,
        0.0086, 0.0047, 0.0034, 0.0089, 0.0056, 0.0128, 0.0081, 0.0071],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,176][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.2443, 0.1498, 0.0633, 0.0796, 0.0424, 0.0448, 0.0369, 0.0417, 0.0300,
        0.0329, 0.0350, 0.0288, 0.0294, 0.0416, 0.0342, 0.0322, 0.0330],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,176][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([3.7340e-03, 9.8762e-06, 6.0352e-06, 8.8132e-06, 4.3196e-05, 5.1882e-05,
        1.0793e-03, 3.1302e-03, 1.1814e-03, 1.3121e-02, 9.3770e-04, 2.3544e-02,
        1.6549e-02, 4.8616e-02, 3.7491e-01, 2.3900e-02, 4.8918e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,177][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([9.8431e-03, 2.1429e-04, 3.8895e-03, 1.8346e-02, 2.2158e-03, 2.4944e-02,
        4.2720e-02, 1.3904e-01, 5.1272e-02, 7.7183e-03, 1.3584e-01, 2.0264e-02,
        5.6677e-02, 1.2757e-01, 2.5660e-01, 7.1657e-02, 3.1188e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,180][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0003, 0.0258, 0.1081, 0.0565, 0.0902, 0.0581, 0.0277, 0.0694, 0.0888,
        0.0158, 0.0903, 0.1044, 0.0413, 0.0581, 0.0981, 0.0506, 0.0167],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,182][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0012, 0.0405, 0.1367, 0.0279, 0.0645, 0.1074, 0.0986, 0.1063, 0.0343,
        0.0505, 0.0696, 0.0750, 0.0256, 0.0646, 0.0275, 0.0414, 0.0284],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,185][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.5638e-01, 2.3745e-03, 1.0243e-02, 9.8546e-04, 7.0972e-03, 6.5265e-04,
        3.1907e-03, 5.2411e-04, 5.2454e-03, 4.7515e-03, 9.4798e-04, 2.0396e-02,
        4.5545e-03, 5.3084e-04, 2.8370e-03, 1.7522e-02, 6.1364e-02, 3.9973e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,186][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0095, 0.0364, 0.0375, 0.0566, 0.0505, 0.0834, 0.0773, 0.0569, 0.0500,
        0.0393, 0.0422, 0.0421, 0.0775, 0.0511, 0.0618, 0.0709, 0.0833, 0.0738],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,187][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0006, 0.0713, 0.0328, 0.0299, 0.0391, 0.0425, 0.1044, 0.0408, 0.1459,
        0.0196, 0.0286, 0.0310, 0.0926, 0.0533, 0.0904, 0.0583, 0.0830, 0.0359],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,187][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0259, 0.0087, 0.0286, 0.0490, 0.0484, 0.0395, 0.0755, 0.0651, 0.0479,
        0.0576, 0.0774, 0.1070, 0.0616, 0.0579, 0.0844, 0.0414, 0.0648, 0.0593],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,188][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.2698e-02, 4.1735e-04, 6.9499e-05, 3.8821e-04, 1.6923e-04, 1.6984e-03,
        9.1718e-03, 2.7552e-02, 1.7518e-02, 6.5239e-02, 3.8257e-02, 5.2807e-02,
        7.3645e-02, 1.7045e-01, 3.2742e-01, 4.3547e-02, 1.2855e-01, 3.0406e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,188][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.5930e-01, 2.6216e-03, 1.8335e-03, 1.1457e-03, 1.4495e-03, 2.3222e-03,
        7.0717e-04, 1.4852e-03, 8.1135e-04, 3.5872e-03, 1.8081e-03, 5.1674e-03,
        2.2333e-03, 4.2118e-03, 4.6643e-03, 1.0881e-03, 3.3075e-03, 2.2545e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,189][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.9352, 0.0019, 0.0027, 0.0019, 0.0023, 0.0045, 0.0062, 0.0037, 0.0030,
        0.0048, 0.0030, 0.0027, 0.0052, 0.0030, 0.0081, 0.0039, 0.0049, 0.0031],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,189][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0410, 0.0463, 0.0564, 0.0605, 0.0484, 0.0513, 0.0584, 0.0646, 0.0574,
        0.0619, 0.0563, 0.0533, 0.0467, 0.0621, 0.0606, 0.0629, 0.0641, 0.0477],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,190][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.7928e-04, 2.0672e-05, 1.2628e-05, 2.3571e-05, 9.6613e-05, 1.2299e-04,
        2.1518e-03, 4.5994e-03, 2.1126e-03, 2.3878e-02, 2.9461e-03, 4.7808e-02,
        2.7816e-02, 5.7599e-02, 3.9261e-01, 3.3290e-02, 3.7786e-01, 2.6074e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,191][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.9591e-03, 1.0012e-04, 2.1546e-03, 1.4337e-02, 1.3964e-03, 2.1637e-02,
        2.7742e-02, 9.4714e-02, 4.2389e-02, 4.8858e-03, 2.5232e-01, 2.1221e-02,
        8.1248e-02, 8.9319e-02, 2.1970e-01, 4.3886e-02, 1.8008e-02, 5.6981e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,193][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.3060e-04, 2.8367e-02, 5.2186e-02, 6.0792e-02, 2.8961e-02, 4.9040e-02,
        9.8680e-03, 3.1723e-02, 2.1198e-01, 3.6841e-02, 1.4913e-01, 3.3848e-02,
        3.6681e-02, 3.4536e-02, 7.4502e-02, 9.0464e-02, 3.7372e-02, 3.3570e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,197][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0009, 0.0481, 0.0722, 0.0418, 0.0219, 0.1203, 0.1146, 0.0639, 0.0752,
        0.0491, 0.0318, 0.0366, 0.0191, 0.0684, 0.0430, 0.1172, 0.0151, 0.0607],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,236][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:19,239][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,242][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,242][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,243][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,243][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,243][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,244][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,244][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,244][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,245][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,245][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,246][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,249][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3978, 0.6022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,252][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9828, 0.0172], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,256][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0156, 0.9844], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,256][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5790, 0.4210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,256][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3300, 0.6700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,256][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9823, 0.0177], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,257][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9679, 0.0321], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,257][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6220, 0.3780], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,257][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2780, 0.7220], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,258][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1238, 0.8762], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,258][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0117, 0.9883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,258][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8475, 0.1525], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,258][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.0330, 0.7132, 0.2538], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,260][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.8588, 0.0311, 0.1101], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,263][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.0312, 0.4383, 0.5305], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,267][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.2440, 0.4259, 0.3301], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,269][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.0470, 0.6426, 0.3104], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,269][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.7881, 0.0970, 0.1149], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,269][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.8761, 0.0420, 0.0819], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,270][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.3206, 0.2896, 0.3898], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,270][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.0875, 0.3783, 0.5342], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,270][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.0598, 0.3589, 0.5813], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,271][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.0297, 0.3997, 0.5706], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,271][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.7281, 0.1068, 0.1650], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,271][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0918, 0.2341, 0.2039, 0.4701], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,272][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9133, 0.0177, 0.0490, 0.0200], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,273][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0026, 0.1824, 0.5072, 0.3078], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,275][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2436, 0.1857, 0.1686, 0.4022], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,278][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0876, 0.3557, 0.1237, 0.4330], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,282][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9530, 0.0189, 0.0184, 0.0097], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,282][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9344, 0.0217, 0.0281, 0.0159], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,283][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3653, 0.1919, 0.2354, 0.2074], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,283][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1323, 0.2737, 0.3202, 0.2738], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,283][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0375, 0.1507, 0.4060, 0.4058], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,284][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0022, 0.1538, 0.5220, 0.3221], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,284][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.6417, 0.0786, 0.2438, 0.0359], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,284][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.0042, 0.0672, 0.0239, 0.6167, 0.2880], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,284][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.5466, 0.0295, 0.1427, 0.0578, 0.2234], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,285][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0031, 0.1861, 0.2609, 0.2801, 0.2699], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,286][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.1530, 0.0852, 0.0679, 0.2968, 0.3972], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,289][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0196, 0.2276, 0.0579, 0.4807, 0.2141], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,291][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.6321, 0.0876, 0.0868, 0.0937, 0.0998], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,295][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.7580, 0.0328, 0.0668, 0.0469, 0.0955], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,296][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1787, 0.1679, 0.1404, 0.3571, 0.1559], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,296][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.0191, 0.0442, 0.1209, 0.1886, 0.6273], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,296][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0291, 0.0834, 0.1098, 0.3841, 0.3935], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,297][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0051, 0.1952, 0.4120, 0.2438, 0.1440], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,297][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.5292, 0.1233, 0.0986, 0.0857, 0.1632], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,297][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0164, 0.0295, 0.0157, 0.0624, 0.1955, 0.6804], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,298][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.3840, 0.0722, 0.0999, 0.0890, 0.1471, 0.2078], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,298][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([3.2851e-04, 2.0213e-01, 1.0106e-01, 3.9729e-01, 1.7116e-01, 1.2804e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,298][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0410, 0.0270, 0.0422, 0.0605, 0.2486, 0.5807], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,300][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0331, 0.1398, 0.0286, 0.1971, 0.1221, 0.4792], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,302][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.8481, 0.0418, 0.0288, 0.0176, 0.0317, 0.0320], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,306][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.7196, 0.0619, 0.0660, 0.0417, 0.0650, 0.0458], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,309][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1166, 0.1807, 0.1534, 0.2672, 0.1289, 0.1531], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,309][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0157, 0.0379, 0.0595, 0.0761, 0.4162, 0.3946], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,309][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0059, 0.0421, 0.0865, 0.0955, 0.3002, 0.4698], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,310][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([2.9025e-04, 1.3858e-01, 9.7022e-02, 4.4199e-01, 1.9731e-01, 1.2481e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,310][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.5474, 0.1075, 0.0852, 0.0492, 0.1596, 0.0511], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,310][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0077, 0.0025, 0.0009, 0.0056, 0.0079, 0.1032, 0.8721],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,311][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.1749, 0.0559, 0.1626, 0.0714, 0.2620, 0.1608, 0.1125],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,311][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([6.2164e-05, 1.0414e-01, 1.4563e-01, 3.6046e-01, 1.6769e-01, 1.3860e-01,
        8.3406e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,311][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0328, 0.0083, 0.0092, 0.0181, 0.0575, 0.1827, 0.6914],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,312][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0403, 0.0453, 0.0059, 0.0438, 0.0218, 0.1367, 0.7061],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,313][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.7501, 0.0476, 0.0437, 0.0379, 0.0353, 0.0616, 0.0238],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,316][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.6391, 0.0489, 0.0778, 0.0437, 0.0740, 0.0598, 0.0566],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,320][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.1149, 0.1585, 0.1316, 0.1927, 0.1238, 0.1301, 0.1485],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,322][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0142, 0.0039, 0.0037, 0.0058, 0.0299, 0.0325, 0.9101],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,322][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0063, 0.0099, 0.0089, 0.0234, 0.0503, 0.1034, 0.7978],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,323][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0004, 0.1549, 0.2505, 0.2118, 0.1809, 0.1655, 0.0360],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,323][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.4545, 0.1749, 0.0805, 0.0581, 0.0999, 0.0734, 0.0587],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,323][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([2.6515e-02, 8.4344e-04, 2.3078e-04, 9.6099e-04, 2.7516e-03, 1.9972e-02,
        5.8501e-01, 3.6372e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,324][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.7399, 0.0275, 0.0282, 0.0275, 0.0316, 0.0721, 0.0537, 0.0196],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,324][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.7952e-04, 6.8976e-02, 1.5570e-01, 3.3080e-01, 1.2170e-01, 9.4424e-02,
        8.6945e-02, 1.4127e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,324][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1362, 0.0068, 0.0044, 0.0075, 0.0181, 0.0888, 0.3693, 0.3689],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,325][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0740, 0.0131, 0.0016, 0.0113, 0.0057, 0.0492, 0.2102, 0.6351],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,325][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.9664, 0.0078, 0.0055, 0.0025, 0.0044, 0.0075, 0.0025, 0.0034],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,327][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.9014, 0.0123, 0.0197, 0.0092, 0.0226, 0.0117, 0.0150, 0.0081],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,329][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.4932, 0.0797, 0.0631, 0.1058, 0.0609, 0.0480, 0.0817, 0.0675],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,333][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0513, 0.0029, 0.0018, 0.0021, 0.0084, 0.0217, 0.6308, 0.2810],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,335][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0278, 0.0042, 0.0050, 0.0052, 0.0241, 0.0406, 0.3608, 0.5324],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,336][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0010, 0.1151, 0.1577, 0.3246, 0.1227, 0.1275, 0.0502, 0.1012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,336][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.8440, 0.0143, 0.0203, 0.0098, 0.0567, 0.0197, 0.0268, 0.0085],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,336][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([8.5638e-03, 4.9008e-04, 1.1531e-04, 4.6377e-04, 1.1313e-03, 1.2759e-02,
        3.7163e-01, 5.0683e-01, 9.8014e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,337][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.7562, 0.0187, 0.0318, 0.0228, 0.0362, 0.0497, 0.0390, 0.0312, 0.0146],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,337][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0006, 0.0455, 0.1221, 0.1946, 0.0898, 0.1424, 0.0970, 0.1430, 0.1649],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,337][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0830, 0.0043, 0.0021, 0.0038, 0.0106, 0.0547, 0.2247, 0.3673, 0.2494],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,338][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0573, 0.0081, 0.0007, 0.0073, 0.0027, 0.0250, 0.1430, 0.4935, 0.2624],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,338][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.9732, 0.0052, 0.0035, 0.0020, 0.0034, 0.0051, 0.0017, 0.0043, 0.0017],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,340][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.9324, 0.0086, 0.0127, 0.0053, 0.0105, 0.0088, 0.0100, 0.0056, 0.0060],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,342][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5000, 0.0911, 0.0685, 0.0772, 0.0474, 0.0426, 0.0607, 0.0790, 0.0336],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,346][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0241, 0.0019, 0.0013, 0.0014, 0.0092, 0.0094, 0.3359, 0.4789, 0.1379],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,349][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0088, 0.0024, 0.0021, 0.0036, 0.0081, 0.0194, 0.1851, 0.5378, 0.2327],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,349][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0005, 0.0481, 0.0684, 0.1677, 0.0846, 0.1164, 0.0550, 0.1885, 0.2709],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,349][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8907, 0.0167, 0.0216, 0.0076, 0.0223, 0.0103, 0.0131, 0.0055, 0.0121],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,350][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([5.6195e-03, 1.4988e-04, 2.9430e-05, 9.1251e-05, 3.0510e-04, 3.0522e-03,
        7.9942e-02, 2.2813e-01, 9.4630e-02, 5.8805e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,350][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.5686, 0.0432, 0.0502, 0.0307, 0.0749, 0.0713, 0.0593, 0.0360, 0.0258,
        0.0399], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,350][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([1.9934e-04, 6.0706e-02, 8.6492e-02, 1.4720e-01, 1.0322e-01, 1.1302e-01,
        7.0999e-02, 1.1369e-01, 2.6352e-01, 4.0957e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,351][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0760, 0.0024, 0.0008, 0.0022, 0.0041, 0.0371, 0.1196, 0.1824, 0.1601,
        0.4153], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,351][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([2.6994e-02, 2.8171e-03, 3.1391e-04, 2.5413e-03, 1.2333e-03, 1.2326e-02,
        6.6990e-02, 2.4831e-01, 2.5896e-01, 3.7951e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,351][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.9736, 0.0042, 0.0029, 0.0023, 0.0027, 0.0038, 0.0012, 0.0034, 0.0015,
        0.0043], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,353][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.8488, 0.0151, 0.0204, 0.0112, 0.0234, 0.0151, 0.0181, 0.0138, 0.0165,
        0.0175], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,356][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.3929, 0.0921, 0.0662, 0.0599, 0.0651, 0.0498, 0.0443, 0.0844, 0.0784,
        0.0670], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,358][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([4.8104e-02, 1.2819e-03, 3.2761e-04, 8.0907e-04, 2.0007e-03, 3.9960e-03,
        6.1860e-02, 1.9694e-01, 1.5468e-01, 5.2999e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,362][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0115, 0.0012, 0.0008, 0.0018, 0.0036, 0.0097, 0.0880, 0.2241, 0.2359,
        0.4233], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,362][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([2.5107e-04, 6.2206e-02, 1.0402e-01, 1.1839e-01, 1.0840e-01, 9.3936e-02,
        4.1010e-02, 1.4579e-01, 2.6963e-01, 5.6358e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,363][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.4384, 0.0828, 0.0761, 0.0289, 0.0961, 0.0499, 0.0453, 0.0355, 0.0730,
        0.0740], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,363][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([8.2866e-03, 2.4272e-04, 4.9851e-05, 1.8283e-04, 4.3413e-04, 5.0299e-03,
        7.7809e-02, 1.8117e-01, 6.8477e-02, 6.2035e-01, 3.7975e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,363][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.7797, 0.0139, 0.0184, 0.0151, 0.0228, 0.0407, 0.0393, 0.0197, 0.0176,
        0.0193, 0.0135], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,364][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0003, 0.0287, 0.1226, 0.1350, 0.0972, 0.1068, 0.0627, 0.0873, 0.2303,
        0.0605, 0.0686], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,364][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0734, 0.0031, 0.0014, 0.0015, 0.0057, 0.0310, 0.0853, 0.1549, 0.1603,
        0.3357, 0.1478], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,364][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0126, 0.0045, 0.0005, 0.0029, 0.0017, 0.0110, 0.0328, 0.1638, 0.1607,
        0.2535, 0.3561], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,365][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.9711, 0.0059, 0.0028, 0.0014, 0.0026, 0.0036, 0.0012, 0.0025, 0.0014,
        0.0047, 0.0028], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,366][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.9004, 0.0110, 0.0116, 0.0062, 0.0127, 0.0090, 0.0092, 0.0061, 0.0070,
        0.0120, 0.0149], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,369][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1864, 0.1239, 0.0645, 0.0853, 0.0668, 0.0666, 0.0865, 0.0829, 0.0779,
        0.0595, 0.0996], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,373][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0132, 0.0014, 0.0007, 0.0007, 0.0070, 0.0058, 0.1003, 0.2290, 0.1050,
        0.4826, 0.0543], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,375][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0113, 0.0017, 0.0022, 0.0011, 0.0071, 0.0122, 0.0714, 0.1791, 0.1291,
        0.3455, 0.2394], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,376][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.1678e-04, 3.6511e-02, 1.2597e-01, 1.0117e-01, 9.9774e-02, 7.1491e-02,
        3.1797e-02, 8.4283e-02, 2.3520e-01, 8.6913e-02, 1.2668e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,376][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.6672, 0.0197, 0.0414, 0.0129, 0.0833, 0.0235, 0.0328, 0.0138, 0.0269,
        0.0356, 0.0428], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,376][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([5.5389e-03, 1.0253e-04, 1.0426e-05, 8.8353e-05, 8.1395e-05, 8.7344e-04,
        4.5162e-02, 7.3503e-02, 2.2452e-02, 2.6068e-01, 5.4566e-02, 5.3694e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,377][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.3261, 0.0212, 0.0703, 0.0379, 0.0916, 0.0832, 0.0680, 0.0591, 0.0244,
        0.0648, 0.0276, 0.1257], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,377][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0003, 0.0610, 0.0731, 0.0862, 0.0744, 0.0863, 0.0482, 0.0797, 0.2163,
        0.0401, 0.1300, 0.1044], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,377][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([6.7567e-02, 9.8412e-04, 3.2065e-04, 8.4964e-04, 1.2616e-03, 8.8410e-03,
        4.0850e-02, 5.4688e-02, 5.5406e-02, 1.5845e-01, 6.6672e-02, 5.4411e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,378][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([2.3089e-02, 2.0492e-03, 2.8930e-04, 1.1800e-03, 7.1636e-04, 3.4949e-03,
        2.5666e-02, 1.0268e-01, 8.7719e-02, 1.4828e-01, 1.8645e-01, 4.1838e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,378][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.8679, 0.0119, 0.0051, 0.0050, 0.0044, 0.0150, 0.0066, 0.0093, 0.0046,
        0.0265, 0.0142, 0.0296], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,380][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.7788, 0.0140, 0.0214, 0.0115, 0.0227, 0.0216, 0.0175, 0.0160, 0.0186,
        0.0278, 0.0246, 0.0256], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,382][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.1428, 0.1127, 0.0510, 0.1253, 0.0447, 0.0606, 0.0652, 0.1087, 0.0682,
        0.0483, 0.1036, 0.0689], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,385][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([4.0311e-02, 4.4527e-04, 2.6534e-04, 3.8220e-04, 1.1384e-03, 1.0697e-03,
        2.0594e-02, 4.9978e-02, 3.4836e-02, 1.8449e-01, 2.4731e-02, 6.4175e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,387][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([1.6543e-02, 4.2595e-04, 2.9511e-04, 4.3895e-04, 9.4179e-04, 2.6709e-03,
        2.9197e-02, 8.6931e-02, 4.6099e-02, 1.5831e-01, 7.9428e-02, 5.7872e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,389][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0005, 0.0789, 0.0699, 0.0827, 0.0370, 0.1197, 0.0629, 0.0948, 0.2602,
        0.0347, 0.1239, 0.0348], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,389][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.6089, 0.0250, 0.0244, 0.0126, 0.0374, 0.0250, 0.0291, 0.0186, 0.0409,
        0.0265, 0.0890, 0.0628], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,389][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([1.8237e-03, 2.8252e-05, 8.7704e-06, 2.0529e-05, 1.0113e-04, 3.9443e-04,
        1.3041e-02, 2.1137e-02, 7.6679e-03, 9.5678e-02, 1.9876e-02, 6.3309e-01,
        2.0713e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,390][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.2313, 0.0432, 0.0400, 0.0397, 0.0600, 0.0723, 0.0703, 0.0696, 0.0591,
        0.0776, 0.0586, 0.0809, 0.0974], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,390][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([5.3455e-05, 2.5396e-02, 4.1172e-02, 7.7752e-02, 4.7878e-02, 7.9971e-02,
        5.3444e-02, 9.3448e-02, 2.0102e-01, 7.1771e-02, 1.7969e-01, 5.6330e-02,
        7.2080e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,390][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([7.3748e-03, 3.0870e-04, 2.0653e-04, 3.6940e-04, 1.5245e-03, 5.2191e-03,
        1.8918e-02, 5.2503e-02, 2.3172e-02, 6.3945e-02, 4.0729e-02, 6.6921e-01,
        1.1653e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,391][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([1.4058e-02, 1.5106e-03, 2.2053e-04, 1.4541e-03, 7.4790e-04, 4.4178e-03,
        2.7554e-02, 7.8364e-02, 6.4777e-02, 1.0692e-01, 1.2370e-01, 2.6381e-01,
        3.1246e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,391][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.9326, 0.0089, 0.0025, 0.0030, 0.0021, 0.0045, 0.0018, 0.0047, 0.0035,
        0.0077, 0.0069, 0.0111, 0.0109], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,393][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.6483, 0.0294, 0.0263, 0.0191, 0.0318, 0.0226, 0.0275, 0.0202, 0.0300,
        0.0312, 0.0478, 0.0353, 0.0305], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,395][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0330, 0.0676, 0.0551, 0.0936, 0.0510, 0.0849, 0.0641, 0.0855, 0.0938,
        0.0923, 0.1417, 0.0731, 0.0641], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,397][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([3.9892e-03, 2.2568e-04, 9.5627e-05, 1.9453e-04, 9.9371e-04, 8.8966e-04,
        1.3526e-02, 3.9699e-02, 1.9868e-02, 1.0948e-01, 1.7265e-02, 6.1364e-01,
        1.8014e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,400][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([1.1067e-03, 1.4721e-04, 1.8869e-04, 1.8096e-04, 8.0812e-04, 9.3041e-04,
        9.3315e-03, 2.3470e-02, 1.8128e-02, 6.8519e-02, 3.8251e-02, 7.0131e-01,
        1.3763e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,402][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([1.6894e-04, 3.0108e-02, 2.7157e-02, 6.7128e-02, 4.1719e-02, 4.5614e-02,
        3.6835e-02, 1.3421e-01, 2.3807e-01, 9.7027e-02, 1.9173e-01, 4.2297e-02,
        4.7942e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,402][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.3964, 0.0448, 0.0480, 0.0256, 0.0493, 0.0290, 0.0396, 0.0214, 0.0636,
        0.0350, 0.1379, 0.0660, 0.0433], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,403][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.4193e-02, 2.8707e-05, 5.0189e-06, 1.9678e-05, 4.4006e-05, 3.0527e-04,
        1.0497e-02, 1.2306e-02, 3.2481e-03, 8.3211e-02, 6.9881e-03, 1.3550e-01,
        1.1961e-01, 6.0405e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,403][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.8130, 0.0094, 0.0106, 0.0087, 0.0129, 0.0234, 0.0236, 0.0096, 0.0128,
        0.0117, 0.0069, 0.0133, 0.0358, 0.0083], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,403][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.8593e-05, 1.7867e-02, 8.6717e-02, 7.8802e-02, 6.4625e-02, 5.3959e-02,
        3.9784e-02, 4.5756e-02, 2.0621e-01, 3.8364e-02, 1.2759e-01, 6.5650e-02,
        6.4343e-02, 1.1026e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,404][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0850, 0.0006, 0.0003, 0.0005, 0.0014, 0.0055, 0.0228, 0.0314, 0.0208,
        0.0729, 0.0361, 0.3128, 0.1255, 0.2845], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,404][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9344e-02, 1.4609e-03, 1.7228e-04, 8.4973e-04, 4.2024e-04, 4.0607e-03,
        1.4284e-02, 5.4675e-02, 3.3591e-02, 1.1767e-01, 7.7480e-02, 1.0732e-01,
        1.7140e-01, 3.1726e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,404][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.8404e-01, 2.0218e-03, 1.0221e-03, 6.0501e-04, 7.7703e-04, 1.2998e-03,
        4.2007e-04, 6.9422e-04, 3.6992e-04, 1.8321e-03, 9.3791e-04, 2.4823e-03,
        1.4078e-03, 2.0924e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,406][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9217, 0.0060, 0.0090, 0.0034, 0.0080, 0.0051, 0.0065, 0.0031, 0.0037,
        0.0070, 0.0058, 0.0072, 0.0073, 0.0062], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,408][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3888, 0.0490, 0.0589, 0.0396, 0.0588, 0.0299, 0.0410, 0.0474, 0.0584,
        0.0495, 0.0542, 0.0650, 0.0342, 0.0253], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,409][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.7865e-02, 2.8820e-04, 1.0250e-04, 1.2043e-04, 6.9172e-04, 6.7551e-04,
        1.8078e-02, 3.0526e-02, 1.2153e-02, 1.0826e-01, 9.8054e-03, 2.4302e-01,
        1.9658e-01, 3.4184e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,411][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.2682e-02, 1.6769e-04, 1.7273e-04, 1.7298e-04, 5.9050e-04, 1.1720e-03,
        1.0391e-02, 2.0740e-02, 1.1626e-02, 4.1696e-02, 2.7203e-02, 2.8528e-01,
        1.3791e-01, 4.5020e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,414][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.2527e-04, 2.8814e-02, 5.0607e-02, 7.7721e-02, 3.6506e-02, 6.1101e-02,
        1.4480e-02, 4.1046e-02, 2.6567e-01, 6.3810e-02, 2.0471e-01, 4.5786e-02,
        6.5671e-02, 4.3944e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,415][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7576, 0.0080, 0.0216, 0.0034, 0.0414, 0.0082, 0.0110, 0.0039, 0.0205,
        0.0163, 0.0435, 0.0307, 0.0227, 0.0112], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,416][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([3.6327e-03, 8.5846e-06, 1.6452e-06, 7.2033e-06, 1.6475e-05, 1.2232e-04,
        3.1311e-03, 7.0677e-03, 1.8629e-03, 3.1669e-02, 5.0521e-03, 6.8459e-02,
        3.8093e-02, 3.4825e-01, 4.9262e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,416][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.3724, 0.0279, 0.0536, 0.0275, 0.0643, 0.0696, 0.0689, 0.0477, 0.0261,
        0.0323, 0.0233, 0.0602, 0.0610, 0.0310, 0.0343], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,417][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([2.0569e-05, 2.4160e-02, 5.3512e-02, 9.9518e-02, 4.7052e-02, 7.6713e-02,
        3.8437e-02, 7.1492e-02, 1.8647e-01, 3.6125e-02, 1.2521e-01, 2.9784e-02,
        4.0830e-02, 1.3571e-01, 3.4961e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,417][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([3.4269e-02, 3.8964e-04, 2.4403e-04, 2.8509e-04, 9.5784e-04, 2.8039e-03,
        1.2192e-02, 2.0815e-02, 1.6126e-02, 5.0264e-02, 2.4915e-02, 2.8471e-01,
        6.1988e-02, 2.5003e-01, 2.4002e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,417][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([1.9214e-02, 6.2920e-04, 6.9497e-05, 4.5952e-04, 2.3053e-04, 2.2829e-03,
        1.0996e-02, 3.2271e-02, 2.7477e-02, 4.4787e-02, 4.3630e-02, 8.8466e-02,
        1.0720e-01, 2.6422e-01, 3.5807e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,418][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([9.5392e-01, 3.9231e-03, 2.2496e-03, 1.6301e-03, 1.8585e-03, 2.1402e-03,
        8.4660e-04, 1.5866e-03, 8.7381e-04, 5.1378e-03, 2.2310e-03, 8.6102e-03,
        3.1342e-03, 6.3747e-03, 5.4849e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,418][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.7572, 0.0148, 0.0243, 0.0102, 0.0232, 0.0124, 0.0164, 0.0093, 0.0111,
        0.0204, 0.0165, 0.0234, 0.0171, 0.0193, 0.0242], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,420][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1771, 0.0676, 0.0465, 0.0484, 0.0547, 0.0486, 0.0267, 0.0546, 0.0730,
        0.0622, 0.0714, 0.0893, 0.0500, 0.0537, 0.0762], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,422][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([1.2888e-02, 1.0743e-04, 5.9051e-05, 6.6287e-05, 2.8250e-04, 3.2391e-04,
        4.6850e-03, 1.2581e-02, 7.0452e-03, 5.3076e-02, 6.2029e-03, 1.3363e-01,
        6.1793e-02, 1.6682e-01, 5.4044e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,424][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([2.7374e-03, 8.8659e-05, 1.0719e-04, 1.0487e-04, 4.4919e-04, 5.3916e-04,
        5.8924e-03, 1.2811e-02, 8.7596e-03, 2.8900e-02, 1.5827e-02, 2.5916e-01,
        4.7329e-02, 3.6009e-01, 2.5721e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,426][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([4.5937e-05, 2.1418e-02, 4.5991e-02, 8.2213e-02, 4.5844e-02, 6.3107e-02,
        2.8868e-02, 9.2532e-02, 2.4489e-01, 6.3219e-02, 1.0816e-01, 5.0225e-02,
        4.7781e-02, 8.3141e-02, 2.2567e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,429][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.5282, 0.0261, 0.0398, 0.0133, 0.0518, 0.0174, 0.0250, 0.0116, 0.0420,
        0.0336, 0.0730, 0.0507, 0.0377, 0.0310, 0.0188], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,429][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.4216e-04, 2.8673e-06, 5.0630e-07, 4.9263e-06, 5.9859e-06, 5.7109e-05,
        3.0600e-03, 3.0657e-03, 4.6032e-04, 1.6277e-02, 1.2298e-03, 2.8864e-02,
        2.4581e-02, 2.3794e-01, 6.7323e-01, 1.0986e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,429][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5258, 0.0178, 0.0238, 0.0204, 0.0273, 0.0512, 0.0481, 0.0179, 0.0237,
        0.0406, 0.0147, 0.0313, 0.0682, 0.0248, 0.0394, 0.0250],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,430][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([8.2233e-05, 1.8912e-02, 5.2181e-02, 1.0180e-01, 3.0805e-02, 7.3269e-02,
        2.7060e-02, 4.5251e-02, 1.1078e-01, 2.4611e-02, 1.7446e-01, 3.6890e-02,
        4.2501e-02, 1.1530e-01, 6.3383e-02, 8.2708e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,430][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.4550e-02, 1.9741e-04, 1.3065e-04, 2.4536e-04, 6.7732e-04, 2.5723e-03,
        1.4211e-02, 1.9174e-02, 1.1925e-02, 4.7374e-02, 2.1726e-02, 2.1390e-01,
        7.3849e-02, 2.3567e-01, 2.6570e-01, 7.8096e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,431][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.3068e-02, 5.0679e-04, 6.2398e-05, 6.2462e-04, 1.8625e-04, 1.4967e-03,
        9.8173e-03, 3.6958e-02, 2.0540e-02, 3.1847e-02, 3.8420e-02, 6.3998e-02,
        7.2867e-02, 3.4504e-01, 3.1272e-01, 5.1851e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,431][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9197, 0.0055, 0.0025, 0.0023, 0.0018, 0.0044, 0.0013, 0.0031, 0.0019,
        0.0079, 0.0054, 0.0086, 0.0061, 0.0133, 0.0138, 0.0023],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,431][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8011, 0.0126, 0.0207, 0.0076, 0.0137, 0.0104, 0.0131, 0.0069, 0.0075,
        0.0187, 0.0117, 0.0152, 0.0133, 0.0143, 0.0231, 0.0100],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,433][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1503, 0.0579, 0.0587, 0.0548, 0.0363, 0.0320, 0.0375, 0.0481, 0.0459,
        0.0648, 0.0747, 0.0646, 0.0376, 0.0673, 0.1161, 0.0533],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,435][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.7786e-03, 2.4207e-05, 1.2819e-05, 1.6722e-05, 7.2702e-05, 1.1887e-04,
        3.8542e-03, 6.7422e-03, 2.1316e-03, 2.5232e-02, 1.5502e-03, 4.5728e-02,
        5.1635e-02, 1.1292e-01, 7.1707e-01, 3.1116e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,437][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.8523e-04, 6.7901e-05, 6.1394e-05, 9.0103e-05, 2.4116e-04, 4.3217e-04,
        4.2299e-03, 1.1918e-02, 6.2497e-03, 2.3986e-02, 1.5693e-02, 1.5123e-01,
        5.4349e-02, 3.2491e-01, 3.5426e-01, 5.1304e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,439][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.0806e-04, 3.2482e-02, 3.4960e-02, 1.0315e-01, 2.4890e-02, 4.5626e-02,
        1.8139e-02, 5.7652e-02, 1.5278e-01, 4.0403e-02, 1.9589e-01, 4.7972e-02,
        5.9422e-02, 6.3079e-02, 6.3214e-02, 6.0232e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,442][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6538, 0.0135, 0.0202, 0.0061, 0.0156, 0.0108, 0.0139, 0.0047, 0.0246,
        0.0184, 0.0878, 0.0298, 0.0401, 0.0240, 0.0190, 0.0177],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,442][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([3.1353e-03, 2.4233e-06, 4.9281e-07, 1.3547e-06, 4.5695e-06, 2.6073e-05,
        1.2207e-03, 2.1388e-03, 3.5939e-04, 1.0591e-02, 6.8300e-04, 2.0840e-02,
        7.7312e-03, 1.4254e-01, 3.3103e-01, 1.2083e-02, 4.6761e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,443][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.5263, 0.0273, 0.0378, 0.0282, 0.0354, 0.0394, 0.0463, 0.0323, 0.0134,
        0.0269, 0.0137, 0.0377, 0.0368, 0.0182, 0.0319, 0.0216, 0.0270],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,443][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([2.9818e-05, 2.3887e-02, 4.6251e-02, 8.1827e-02, 4.0715e-02, 5.0751e-02,
        4.2770e-02, 5.6883e-02, 1.1074e-01, 1.7460e-02, 8.3276e-02, 5.1522e-02,
        5.3661e-02, 1.4209e-01, 9.9025e-02, 6.7268e-02, 3.1845e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,444][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([3.2269e-02, 1.6111e-04, 7.5870e-05, 1.7524e-04, 3.7199e-04, 1.6931e-03,
        8.7290e-03, 1.7266e-02, 8.6143e-03, 3.4552e-02, 1.4201e-02, 1.2950e-01,
        4.3277e-02, 1.9933e-01, 2.1607e-01, 6.1720e-02, 2.3200e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,444][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([2.1991e-02, 2.7636e-04, 3.0305e-05, 2.4538e-04, 1.0243e-04, 7.7065e-04,
        5.6455e-03, 2.3321e-02, 1.3024e-02, 3.8373e-02, 2.0514e-02, 4.3165e-02,
        4.3773e-02, 2.4143e-01, 3.4603e-01, 3.6587e-02, 1.6472e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,444][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([9.5523e-01, 1.8847e-03, 1.9205e-03, 1.0474e-03, 1.7821e-03, 1.9044e-03,
        8.9575e-04, 1.8285e-03, 8.6859e-04, 3.3050e-03, 1.3140e-03, 7.2584e-03,
        2.5305e-03, 5.9073e-03, 5.7771e-03, 1.7681e-03, 4.7824e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,445][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.8864, 0.0065, 0.0111, 0.0047, 0.0086, 0.0054, 0.0070, 0.0045, 0.0042,
        0.0096, 0.0060, 0.0078, 0.0046, 0.0065, 0.0105, 0.0055, 0.0111],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,446][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.1247, 0.0586, 0.0590, 0.0471, 0.0500, 0.0365, 0.0340, 0.0513, 0.0478,
        0.0351, 0.0700, 0.0797, 0.0425, 0.0536, 0.0746, 0.0725, 0.0629],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,448][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([1.5889e-02, 1.5818e-05, 8.5034e-06, 7.0566e-06, 5.0720e-05, 6.4395e-05,
        1.9140e-03, 4.6307e-03, 1.6056e-03, 1.3675e-02, 7.5542e-04, 2.6183e-02,
        1.8342e-02, 6.7543e-02, 4.8159e-01, 3.1104e-02, 3.3662e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,449][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([5.4347e-03, 3.3483e-05, 5.0654e-05, 5.0756e-05, 1.9884e-04, 3.0544e-04,
        4.5675e-03, 8.3826e-03, 4.2653e-03, 1.6736e-02, 7.8413e-03, 1.3407e-01,
        2.3689e-02, 2.1071e-01, 2.5818e-01, 4.3845e-02, 2.8164e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,453][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0003, 0.0258, 0.1081, 0.0565, 0.0902, 0.0581, 0.0277, 0.0694, 0.0888,
        0.0158, 0.0903, 0.1044, 0.0413, 0.0581, 0.0981, 0.0506, 0.0167],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,455][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.4946, 0.0261, 0.0422, 0.0085, 0.0590, 0.0183, 0.0151, 0.0084, 0.0329,
        0.0249, 0.0606, 0.0625, 0.0478, 0.0277, 0.0257, 0.0279, 0.0180],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,456][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.3059e-03, 2.7395e-06, 5.4540e-07, 3.3776e-06, 4.8337e-06, 4.0305e-05,
        2.3502e-03, 2.1408e-03, 5.3662e-04, 1.6348e-02, 1.2063e-03, 1.6679e-02,
        1.1767e-02, 9.8835e-02, 3.6034e-01, 1.0749e-02, 4.4628e-01, 3.1411e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,456][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7286, 0.0115, 0.0156, 0.0100, 0.0154, 0.0283, 0.0273, 0.0097, 0.0137,
        0.0148, 0.0069, 0.0165, 0.0370, 0.0093, 0.0169, 0.0167, 0.0116, 0.0102],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,457][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.2489e-04, 1.1593e-02, 6.6800e-02, 5.2284e-02, 4.1667e-02, 3.7238e-02,
        2.6047e-02, 2.8045e-02, 1.3648e-01, 2.6590e-02, 9.4962e-02, 3.2098e-02,
        3.9101e-02, 6.7274e-02, 7.2919e-02, 1.1197e-01, 6.2925e-02, 9.1880e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,457][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.7040e-02, 1.8407e-04, 1.3150e-04, 2.5886e-04, 6.4184e-04, 2.7142e-03,
        1.3326e-02, 1.6662e-02, 1.1050e-02, 4.5038e-02, 1.9358e-02, 1.5063e-01,
        5.6708e-02, 1.6450e-01, 2.1622e-01, 5.7507e-02, 1.8602e-01, 4.2011e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,458][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2698e-02, 4.1735e-04, 6.9499e-05, 3.8821e-04, 1.6923e-04, 1.6984e-03,
        9.1718e-03, 2.7552e-02, 1.7518e-02, 6.5239e-02, 3.8257e-02, 5.2807e-02,
        7.3645e-02, 1.7045e-01, 3.2742e-01, 4.3547e-02, 1.2855e-01, 3.0406e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,458][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.5930e-01, 2.6216e-03, 1.8335e-03, 1.1457e-03, 1.4495e-03, 2.3222e-03,
        7.0717e-04, 1.4852e-03, 8.1135e-04, 3.5872e-03, 1.8081e-03, 5.1674e-03,
        2.2333e-03, 4.2118e-03, 4.6643e-03, 1.0881e-03, 3.3075e-03, 2.2545e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,458][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9078, 0.0047, 0.0093, 0.0031, 0.0074, 0.0045, 0.0054, 0.0028, 0.0032,
        0.0061, 0.0042, 0.0062, 0.0042, 0.0048, 0.0086, 0.0037, 0.0089, 0.0051],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,460][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2938, 0.0341, 0.0478, 0.0302, 0.0472, 0.0226, 0.0351, 0.0438, 0.0464,
        0.0450, 0.0460, 0.0527, 0.0244, 0.0275, 0.0611, 0.0671, 0.0606, 0.0147],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,462][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.1902e-03, 2.6350e-05, 1.4294e-05, 1.8434e-05, 1.0430e-04, 1.4184e-04,
        3.3156e-03, 6.3338e-03, 2.6671e-03, 2.4604e-02, 2.0528e-03, 4.5505e-02,
        2.7909e-02, 7.7504e-02, 4.8306e-01, 4.1085e-02, 2.5369e-01, 2.8772e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,464][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.0839e-03, 3.4231e-05, 4.8281e-05, 6.3315e-05, 2.0309e-04, 4.1654e-04,
        4.8005e-03, 8.0468e-03, 4.8246e-03, 2.0036e-02, 1.2449e-02, 1.2823e-01,
        4.4837e-02, 1.8941e-01, 2.3316e-01, 3.5670e-02, 2.6324e-01, 5.3451e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,466][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.3060e-04, 2.8367e-02, 5.2186e-02, 6.0792e-02, 2.8961e-02, 4.9040e-02,
        9.8680e-03, 3.1723e-02, 2.1198e-01, 3.6841e-02, 1.4913e-01, 3.3848e-02,
        3.6681e-02, 3.4536e-02, 7.4502e-02, 9.0464e-02, 3.7372e-02, 3.3570e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,469][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.6615, 0.0079, 0.0214, 0.0034, 0.0372, 0.0096, 0.0124, 0.0045, 0.0227,
        0.0221, 0.0528, 0.0348, 0.0239, 0.0140, 0.0178, 0.0203, 0.0211, 0.0124],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,470][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:19,471][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 5523],
        [10307],
        [42018],
        [ 8852],
        [11973],
        [ 2635],
        [ 2007],
        [ 1043],
        [ 1814],
        [ 2670],
        [ 1027],
        [ 4992],
        [ 1098],
        [  516],
        [  933],
        [ 1207],
        [ 3798],
        [  389]], device='cuda:0')
[2024-07-24 10:30:19,472][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5472],
        [16841],
        [44277],
        [15701],
        [15753],
        [ 8897],
        [ 3980],
        [ 3603],
        [ 7083],
        [ 9392],
        [ 4910],
        [15596],
        [ 4934],
        [ 2954],
        [ 4599],
        [ 5649],
        [12953],
        [ 2326]], device='cuda:0')
[2024-07-24 10:30:19,473][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[42648],
        [42630],
        [41831],
        [42350],
        [39939],
        [40128],
        [41575],
        [39951],
        [38209],
        [42564],
        [41410],
        [41811],
        [42370],
        [42291],
        [41516],
        [40908],
        [42230],
        [40605]], device='cuda:0')
[2024-07-24 10:30:19,474][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 9517],
        [ 9697],
        [20079],
        [14720],
        [16507],
        [15018],
        [14131],
        [13586],
        [13650],
        [12531],
        [12550],
        [13149],
        [13426],
        [12990],
        [12631],
        [12068],
        [10780],
        [10808]], device='cuda:0')
[2024-07-24 10:30:19,477][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17388],
        [ 9718],
        [16438],
        [15837],
        [15283],
        [11365],
        [12519],
        [12699],
        [ 8017],
        [ 7893],
        [ 7280],
        [ 7165],
        [ 7347],
        [ 8258],
        [ 7327],
        [ 6589],
        [ 6046],
        [ 5781]], device='cuda:0')
[2024-07-24 10:30:19,478][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[6520],
        [1022],
        [ 566],
        [ 662],
        [ 932],
        [1138],
        [1621],
        [1847],
        [1940],
        [2037],
        [2266],
        [2293],
        [2364],
        [2402],
        [2807],
        [3136],
        [3261],
        [3179]], device='cuda:0')
[2024-07-24 10:30:19,480][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6586],
        [ 2992],
        [ 3595],
        [14188],
        [18191],
        [20004],
        [13282],
        [ 8710],
        [10636],
        [11483],
        [ 9931],
        [ 8039],
        [ 7552],
        [ 9180],
        [12301],
        [13251],
        [15582],
        [14931]], device='cuda:0')
[2024-07-24 10:30:19,483][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45722],
        [45740],
        [49083],
        [46935],
        [48709],
        [48412],
        [48980],
        [46647],
        [46459],
        [46342],
        [46345],
        [47778],
        [47047],
        [46132],
        [46765],
        [47216],
        [46601],
        [46546]], device='cuda:0')
[2024-07-24 10:30:19,485][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[28484],
        [28692],
        [30281],
        [29835],
        [30479],
        [30472],
        [37745],
        [33448],
        [32209],
        [35977],
        [34952],
        [36091],
        [36896],
        [36318],
        [37140],
        [33170],
        [38286],
        [36748]], device='cuda:0')
[2024-07-24 10:30:19,486][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25354],
        [31377],
        [35557],
        [29648],
        [31499],
        [27545],
        [26035],
        [24527],
        [24143],
        [22723],
        [20024],
        [22716],
        [21844],
        [19424],
        [20181],
        [19028],
        [17620],
        [12245]], device='cuda:0')
[2024-07-24 10:30:19,487][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11980],
        [18300],
        [36119],
        [22679],
        [24925],
        [25520],
        [30099],
        [35684],
        [38996],
        [23024],
        [25480],
        [22101],
        [25810],
        [34333],
        [21841],
        [18381],
        [16121],
        [17901]], device='cuda:0')
[2024-07-24 10:30:19,488][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38858],
        [26398],
        [10432],
        [14826],
        [17118],
        [15627],
        [19598],
        [17636],
        [17367],
        [17662],
        [20410],
        [19090],
        [20891],
        [20567],
        [19537],
        [19543],
        [18727],
        [19268]], device='cuda:0')
[2024-07-24 10:30:19,489][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 8783],
        [21271],
        [50257],
        [50255],
        [50254],
        [46022],
        [50186],
        [49156],
        [43522],
        [47439],
        [48146],
        [43106],
        [35362],
        [38753],
        [40807],
        [37402],
        [48608],
        [41877]], device='cuda:0')
[2024-07-24 10:30:19,491][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18864],
        [18960],
        [ 1153],
        [ 1608],
        [ 4033],
        [ 4066],
        [ 2940],
        [ 3823],
        [ 4261],
        [ 3403],
        [ 3521],
        [ 7178],
        [ 4622],
        [ 4236],
        [ 3852],
        [ 5892],
        [ 3743],
        [ 4393]], device='cuda:0')
[2024-07-24 10:30:19,493][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[20599],
        [21039],
        [14899],
        [ 6049],
        [ 8295],
        [ 9702],
        [16705],
        [13597],
        [13172],
        [12316],
        [12546],
        [ 5893],
        [14426],
        [11916],
        [12392],
        [10855],
        [ 8530],
        [12778]], device='cuda:0')
[2024-07-24 10:30:19,494][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23677],
        [23805],
        [28177],
        [33287],
        [37589],
        [16901],
        [43474],
        [38244],
        [31135],
        [26383],
        [26801],
        [21443],
        [22021],
        [32353],
        [19599],
        [16608],
        [29587],
        [29084]], device='cuda:0')
[2024-07-24 10:30:19,496][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26669],
        [27031],
        [17987],
        [22919],
        [39675],
        [47292],
        [46483],
        [31960],
        [29662],
        [40070],
        [29125],
        [44025],
        [44643],
        [23775],
        [42676],
        [38089],
        [38115],
        [28493]], device='cuda:0')
[2024-07-24 10:30:19,499][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[26223],
        [44562],
        [48265],
        [47121],
        [47973],
        [44456],
        [43438],
        [41779],
        [44367],
        [45603],
        [46031],
        [47150],
        [46587],
        [47487],
        [45371],
        [44197],
        [44492],
        [44696]], device='cuda:0')
[2024-07-24 10:30:19,501][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9811],
        [28131],
        [42506],
        [42125],
        [35355],
        [32603],
        [43781],
        [38455],
        [37358],
        [22082],
        [22826],
        [23381],
        [26861],
        [33000],
        [35155],
        [37104],
        [36065],
        [36829]], device='cuda:0')
[2024-07-24 10:30:19,502][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31677],
        [45234],
        [44987],
        [45466],
        [45973],
        [44605],
        [45884],
        [41213],
        [41516],
        [38528],
        [35935],
        [34323],
        [31022],
        [33027],
        [32678],
        [33335],
        [32570],
        [32080]], device='cuda:0')
[2024-07-24 10:30:19,503][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[30754],
        [31280],
        [27364],
        [30593],
        [36290],
        [30950],
        [32077],
        [31360],
        [31389],
        [31819],
        [31957],
        [35956],
        [34067],
        [31651],
        [33065],
        [34140],
        [32955],
        [32689]], device='cuda:0')
[2024-07-24 10:30:19,504][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22909],
        [22541],
        [21095],
        [22347],
        [ 9629],
        [ 9937],
        [ 7248],
        [17877],
        [20300],
        [15988],
        [17745],
        [10792],
        [10957],
        [19017],
        [15180],
        [17177],
        [18034],
        [19081]], device='cuda:0')
[2024-07-24 10:30:19,506][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31698],
        [26231],
        [20680],
        [15037],
        [12880],
        [13932],
        [13953],
        [15249],
        [16316],
        [17565],
        [16373],
        [15945],
        [15735],
        [16395],
        [16366],
        [16086],
        [16335],
        [17130]], device='cuda:0')
[2024-07-24 10:30:19,507][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44253],
        [41571],
        [38423],
        [47182],
        [47588],
        [49193],
        [44537],
        [45741],
        [47279],
        [46713],
        [46646],
        [47376],
        [46973],
        [46957],
        [47942],
        [47397],
        [48600],
        [48468]], device='cuda:0')
[2024-07-24 10:30:19,509][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[40365],
        [33338],
        [23194],
        [27462],
        [23584],
        [20687],
        [31228],
        [31599],
        [35634],
        [42165],
        [43279],
        [35966],
        [35215],
        [38690],
        [38096],
        [38397],
        [38687],
        [38961]], device='cuda:0')
[2024-07-24 10:30:19,510][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[26969],
        [38919],
        [39953],
        [39092],
        [39823],
        [31500],
        [40565],
        [35052],
        [30666],
        [32987],
        [34108],
        [31946],
        [28903],
        [31105],
        [29322],
        [28783],
        [33483],
        [29950]], device='cuda:0')
[2024-07-24 10:30:19,512][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25636],
        [20566],
        [21336],
        [22632],
        [20617],
        [19650],
        [18237],
        [24178],
        [23276],
        [19071],
        [22556],
        [20479],
        [17400],
        [20495],
        [17679],
        [16585],
        [16361],
        [16919]], device='cuda:0')
[2024-07-24 10:30:19,515][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1831],
        [ 536],
        [ 568],
        [ 243],
        [ 321],
        [ 573],
        [ 176],
        [ 432],
        [ 489],
        [ 707],
        [ 824],
        [ 737],
        [1107],
        [ 797],
        [ 799],
        [1204],
        [ 592],
        [ 933]], device='cuda:0')
[2024-07-24 10:30:19,517][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5408],
        [ 2962],
        [12551],
        [13892],
        [10577],
        [12831],
        [ 6440],
        [ 6840],
        [ 5404],
        [ 4601],
        [ 5676],
        [10816],
        [ 9317],
        [ 6652],
        [ 5686],
        [ 5634],
        [ 6031],
        [ 4324]], device='cuda:0')
[2024-07-24 10:30:19,518][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998],
        [6998]], device='cuda:0')
[2024-07-24 10:30:19,559][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:19,559][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,560][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,560][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,560][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,561][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,561][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,562][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,564][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,566][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,569][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,571][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,572][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,584][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9970, 0.0030], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,584][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4606, 0.5394], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,585][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9921e-01, 7.8985e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,585][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9911, 0.0089], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,585][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1140, 0.8860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,585][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9576, 0.0424], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,586][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,586][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8980, 0.1020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,586][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9981, 0.0019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,587][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9957, 0.0043], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,587][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9455, 0.0545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,589][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7095, 0.2905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,591][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.9809, 0.0177, 0.0014], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,595][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.1170, 0.4146, 0.4684], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,597][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.9430, 0.0169, 0.0401], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,598][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.8907, 0.0322, 0.0771], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,598][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.0065, 0.7714, 0.2221], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,598][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.4211, 0.5421, 0.0368], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,598][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.9616, 0.0125, 0.0259], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,599][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.0391, 0.9289, 0.0321], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,599][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.9785, 0.0134, 0.0081], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,599][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.9423, 0.0325, 0.0252], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,600][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.9089, 0.0511, 0.0400], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,600][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.1424, 0.4871, 0.3706], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,600][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9573e-01, 3.3672e-03, 1.9450e-04, 7.0941e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,602][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3063, 0.2096, 0.3938, 0.0903], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,604][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9926, 0.0019, 0.0043, 0.0013], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,608][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9666, 0.0066, 0.0191, 0.0076], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,610][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0077, 0.4110, 0.0797, 0.5016], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,611][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8277, 0.1230, 0.0064, 0.0429], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,611][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.9149e-01, 7.8741e-04, 4.4713e-03, 3.2499e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,611][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4459, 0.3549, 0.0093, 0.1899], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,612][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9856, 0.0064, 0.0040, 0.0040], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,612][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9959, 0.0020, 0.0011, 0.0011], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,612][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8989, 0.0385, 0.0280, 0.0346], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,613][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6464, 0.0815, 0.1843, 0.0878], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,613][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([9.7219e-01, 9.7570e-03, 7.9353e-04, 3.2548e-03, 1.4001e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,613][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0507, 0.2290, 0.4056, 0.1122, 0.2025], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,614][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.8740, 0.0146, 0.0391, 0.0207, 0.0516], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,616][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.7589, 0.0236, 0.0624, 0.0272, 0.1279], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,619][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0010, 0.1576, 0.0616, 0.6729, 0.1069], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,622][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.2699, 0.3345, 0.0216, 0.3152, 0.0588], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,626][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.9243, 0.0037, 0.0142, 0.0185, 0.0393], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,626][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0055, 0.1917, 0.0117, 0.7398, 0.0513], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,626][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.8499, 0.0356, 0.0294, 0.0421, 0.0430], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,627][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.9365, 0.0186, 0.0154, 0.0128, 0.0167], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,627][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.8411, 0.0430, 0.0346, 0.0425, 0.0389], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,627][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0588, 0.1726, 0.2346, 0.2878, 0.2463], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,628][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ were] are: tensor([9.8753e-01, 5.1289e-03, 1.5619e-04, 1.9153e-03, 4.9709e-03, 3.0276e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,628][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0192, 0.2224, 0.2356, 0.2175, 0.1737, 0.1316], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,628][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.9456, 0.0035, 0.0079, 0.0043, 0.0155, 0.0232], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,630][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.4696, 0.0593, 0.0799, 0.0394, 0.1070, 0.2448], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,632][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0020, 0.1347, 0.0097, 0.2277, 0.0266, 0.5993], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,636][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.3683, 0.1505, 0.0091, 0.0648, 0.0231, 0.3843], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,638][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.9549, 0.0011, 0.0039, 0.0031, 0.0173, 0.0196], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,639][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0507, 0.1504, 0.0072, 0.0731, 0.0325, 0.6861], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,639][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.9500, 0.0145, 0.0049, 0.0067, 0.0079, 0.0160], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,639][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.9308, 0.0157, 0.0131, 0.0090, 0.0120, 0.0194], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,640][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.8134, 0.0441, 0.0338, 0.0389, 0.0348, 0.0349], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,640][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.2341, 0.1404, 0.1732, 0.1335, 0.1312, 0.1876], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,640][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ working] are: tensor([9.9344e-01, 3.2008e-03, 8.9861e-05, 7.3871e-04, 2.0848e-03, 1.4358e-04,
        2.9753e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,641][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0108, 0.1985, 0.2727, 0.1587, 0.0958, 0.1511, 0.1123],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,641][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.8832, 0.0072, 0.0120, 0.0080, 0.0196, 0.0321, 0.0380],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,641][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.5411, 0.0404, 0.0640, 0.0210, 0.0830, 0.1455, 0.1050],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,642][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ working] are: tensor([1.9512e-03, 7.0030e-03, 8.9241e-04, 7.2916e-03, 1.0640e-03, 3.4745e-02,
        9.4705e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,645][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.5037, 0.0313, 0.0011, 0.0076, 0.0025, 0.0619, 0.3918],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,646][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ working] are: tensor([9.5475e-01, 8.8080e-04, 4.0206e-03, 2.4753e-03, 1.8000e-02, 1.0768e-02,
        9.1092e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,648][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ working] are: tensor([2.1332e-02, 6.9648e-03, 2.1058e-04, 2.1714e-03, 3.4300e-04, 3.2303e-02,
        9.3668e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,652][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.9332, 0.0071, 0.0037, 0.0039, 0.0055, 0.0077, 0.0388],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,652][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.9737, 0.0046, 0.0028, 0.0021, 0.0023, 0.0039, 0.0106],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,652][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.8190, 0.0356, 0.0264, 0.0308, 0.0274, 0.0273, 0.0335],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,653][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.1519, 0.1139, 0.0930, 0.0597, 0.0607, 0.1548, 0.3660],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,653][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.9565e-01, 1.4139e-03, 6.2839e-05, 3.7417e-04, 1.7160e-03, 6.4594e-05,
        1.2194e-04, 5.9468e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,653][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1188, 0.1204, 0.1798, 0.0838, 0.0801, 0.1083, 0.2507, 0.0581],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,654][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.9283, 0.0022, 0.0053, 0.0025, 0.0094, 0.0145, 0.0154, 0.0223],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,654][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.9384, 0.0047, 0.0069, 0.0029, 0.0088, 0.0143, 0.0120, 0.0120],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,655][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([5.6609e-03, 1.6523e-03, 2.4050e-04, 1.9046e-03, 5.1229e-04, 1.3502e-02,
        3.3779e-01, 6.3874e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,656][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([8.3609e-01, 3.3839e-03, 1.3674e-04, 5.3177e-04, 3.6983e-04, 7.1413e-03,
        5.5970e-02, 9.6378e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,657][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([9.9459e-01, 6.7330e-05, 4.0937e-04, 1.5296e-04, 2.0189e-03, 9.3468e-04,
        7.9518e-04, 1.0336e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,658][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.1123e-01, 1.2616e-03, 2.2083e-05, 3.3441e-04, 8.4963e-05, 3.4909e-03,
        1.9187e-01, 6.9170e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,661][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([9.8102e-01, 1.0107e-03, 5.6878e-04, 4.0012e-04, 1.0867e-03, 1.1645e-03,
        7.7109e-03, 7.0367e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,663][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([9.9084e-01, 9.1339e-04, 7.0448e-04, 4.3834e-04, 5.6482e-04, 1.1781e-03,
        2.1297e-03, 3.2325e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,665][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.8315, 0.0285, 0.0203, 0.0236, 0.0208, 0.0202, 0.0247, 0.0303],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,665][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3105, 0.0261, 0.0562, 0.0245, 0.0372, 0.0320, 0.1073, 0.4062],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,665][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([4.5368e-01, 2.4871e-04, 9.0504e-06, 5.8272e-05, 3.0947e-04, 1.0445e-05,
        1.7108e-05, 8.6797e-05, 5.4558e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,666][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1108, 0.1023, 0.1953, 0.1099, 0.0624, 0.0825, 0.1098, 0.1257, 0.1014],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,666][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([9.5790e-01, 9.6287e-04, 2.4806e-03, 9.0414e-04, 4.0256e-03, 5.4420e-03,
        7.0693e-03, 9.8604e-03, 1.1358e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,666][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.8083, 0.0095, 0.0111, 0.0053, 0.0231, 0.0371, 0.0250, 0.0413, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,667][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.4469e-03, 8.2875e-04, 6.9136e-05, 8.2094e-04, 1.2258e-04, 3.4523e-03,
        1.0547e-01, 4.8094e-01, 4.0686e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,667][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([6.4440e-01, 3.8394e-03, 1.0811e-04, 5.1067e-04, 3.0642e-04, 8.6218e-03,
        6.2564e-02, 2.2966e-01, 4.9988e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,667][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.9848e-01, 3.1349e-05, 1.0782e-04, 6.7188e-05, 4.5714e-04, 3.2515e-04,
        1.8191e-04, 2.5853e-04, 9.5114e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,668][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([2.7832e-02, 7.5558e-04, 9.0252e-06, 1.7002e-04, 3.8661e-05, 1.5962e-03,
        2.3689e-01, 6.0895e-01, 1.2376e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,669][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.7976e-01, 1.0457e-03, 5.1650e-04, 2.8281e-04, 6.3025e-04, 9.2321e-04,
        4.0484e-03, 8.2661e-03, 4.5249e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,671][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.8770e-01, 9.1490e-04, 5.9350e-04, 4.1520e-04, 4.7194e-04, 8.5772e-04,
        2.2026e-03, 3.5550e-03, 3.2896e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,674][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.7946, 0.0288, 0.0201, 0.0246, 0.0211, 0.0212, 0.0256, 0.0309, 0.0332],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,678][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2281, 0.0184, 0.0289, 0.0148, 0.0210, 0.0230, 0.0897, 0.3201, 0.2558],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,678][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ station] are: tensor([4.7802e-01, 3.3112e-04, 1.4716e-05, 7.7633e-05, 2.3994e-04, 1.5292e-05,
        2.5602e-05, 1.0174e-04, 5.2108e-01, 9.5816e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,678][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0357, 0.1106, 0.1453, 0.0441, 0.1090, 0.0490, 0.1033, 0.0590, 0.2051,
        0.1390], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,679][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.8648, 0.0026, 0.0053, 0.0032, 0.0084, 0.0171, 0.0183, 0.0254, 0.0260,
        0.0291], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,679][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.7735, 0.0100, 0.0068, 0.0072, 0.0142, 0.0234, 0.0276, 0.0373, 0.0367,
        0.0632], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,679][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ station] are: tensor([6.7213e-03, 3.4222e-04, 1.8514e-05, 2.1267e-04, 4.4898e-05, 1.0741e-03,
        2.1054e-02, 1.0362e-01, 1.6599e-01, 7.0092e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,680][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ station] are: tensor([6.6811e-01, 2.0427e-03, 3.4206e-05, 2.9102e-04, 7.8221e-05, 3.1543e-03,
        2.7197e-02, 8.4226e-02, 4.2094e-02, 1.7277e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,680][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ station] are: tensor([9.8405e-01, 3.5398e-04, 6.9971e-04, 4.7263e-04, 3.4277e-03, 3.2652e-03,
        1.6052e-03, 2.2431e-03, 1.3848e-03, 2.4949e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,681][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ station] are: tensor([2.6956e-02, 2.9187e-04, 1.3431e-06, 5.3348e-05, 7.7917e-06, 5.5356e-04,
        3.5505e-02, 1.6852e-01, 1.0525e-01, 6.6286e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,682][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ station] are: tensor([9.7368e-01, 8.6525e-04, 3.6425e-04, 4.1894e-04, 4.9850e-04, 1.1254e-03,
        4.3291e-03, 7.3641e-03, 4.8338e-03, 6.5224e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,684][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ station] are: tensor([9.8559e-01, 5.9525e-04, 4.7703e-04, 2.6288e-04, 4.4092e-04, 6.7460e-04,
        1.4433e-03, 2.5838e-03, 2.2085e-03, 5.7201e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,688][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.7612, 0.0300, 0.0204, 0.0249, 0.0209, 0.0210, 0.0251, 0.0302, 0.0325,
        0.0338], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,690][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0835, 0.0112, 0.0097, 0.0057, 0.0056, 0.0098, 0.0330, 0.1250, 0.1749,
        0.5417], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,691][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([5.0936e-01, 2.6142e-04, 5.8952e-06, 6.0466e-05, 2.9308e-04, 9.7148e-06,
        1.3912e-05, 6.3148e-05, 4.8928e-01, 2.9512e-05, 6.2671e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,691][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0564, 0.0916, 0.1320, 0.0344, 0.0632, 0.0560, 0.0922, 0.0629, 0.1253,
        0.1226, 0.1633], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,691][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([9.4221e-01, 8.5047e-04, 2.5296e-03, 9.6529e-04, 4.3264e-03, 7.0003e-03,
        7.2637e-03, 9.3931e-03, 1.1003e-02, 1.3206e-02, 1.2523e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,692][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.8716, 0.0052, 0.0060, 0.0026, 0.0134, 0.0158, 0.0127, 0.0212, 0.0165,
        0.0176, 0.0175], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,692][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([1.4889e-03, 5.7225e-04, 3.9130e-05, 2.5622e-04, 9.3442e-05, 1.4582e-03,
        1.7432e-02, 1.0110e-01, 1.4749e-01, 5.3348e-01, 1.9659e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,692][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([6.1497e-01, 2.7058e-03, 5.9586e-05, 2.5415e-04, 1.6814e-04, 4.1891e-03,
        1.8335e-02, 7.3023e-02, 3.0932e-02, 1.4444e-01, 1.1092e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,693][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([9.8735e-01, 2.0085e-04, 6.6651e-04, 3.8332e-04, 2.8471e-03, 1.5026e-03,
        1.5884e-03, 2.1928e-03, 1.0302e-03, 1.5021e-03, 7.3859e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,693][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([3.5033e-02, 3.9379e-04, 3.6978e-06, 6.5225e-05, 1.2570e-05, 6.2846e-04,
        3.2574e-02, 1.0977e-01, 5.4576e-02, 6.4646e-01, 1.2048e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,694][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([9.8808e-01, 5.2439e-04, 2.4681e-04, 9.9888e-05, 3.3603e-04, 3.8150e-04,
        1.5072e-03, 3.2715e-03, 1.9376e-03, 2.6303e-03, 9.8111e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,695][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([9.8589e-01, 9.5302e-04, 3.7611e-04, 2.7060e-04, 4.2014e-04, 7.0766e-04,
        1.1708e-03, 2.1596e-03, 1.9899e-03, 4.0855e-03, 1.9813e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,698][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.7450, 0.0281, 0.0197, 0.0232, 0.0207, 0.0197, 0.0234, 0.0286, 0.0310,
        0.0320, 0.0286], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,702][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1972, 0.0107, 0.0079, 0.0049, 0.0056, 0.0099, 0.0368, 0.1166, 0.1407,
        0.2957, 0.1741], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,704][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([3.0075e-01, 3.6283e-04, 1.6501e-05, 9.6436e-05, 4.2332e-04, 1.7723e-05,
        4.2528e-05, 1.7056e-04, 6.9215e-01, 1.6326e-04, 1.5379e-03, 4.2780e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,704][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0066, 0.0275, 0.0422, 0.0130, 0.0264, 0.0450, 0.0489, 0.0580, 0.1054,
        0.1073, 0.0997, 0.4200], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,704][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.8751, 0.0015, 0.0040, 0.0019, 0.0070, 0.0085, 0.0119, 0.0181, 0.0206,
        0.0295, 0.0024, 0.0193], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,705][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.5995, 0.0057, 0.0053, 0.0048, 0.0155, 0.0308, 0.0302, 0.0379, 0.0409,
        0.0887, 0.0352, 0.1056], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,705][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([9.8263e-04, 8.5178e-05, 6.2525e-06, 6.1182e-05, 1.0848e-05, 3.7288e-04,
        7.4864e-03, 3.0495e-02, 3.1188e-02, 4.7031e-01, 5.3088e-02, 4.0591e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,705][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([5.7121e-01, 1.0941e-03, 1.7119e-05, 1.1593e-04, 3.3211e-05, 1.1483e-03,
        1.0713e-02, 3.9865e-02, 9.0794e-03, 1.3671e-01, 6.5165e-02, 1.6485e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,706][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([9.6601e-01, 5.6356e-04, 1.2260e-03, 7.1139e-04, 2.9151e-03, 3.4817e-03,
        2.3106e-03, 3.7779e-03, 2.0848e-03, 1.8436e-03, 1.8298e-03, 1.3248e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,707][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([4.4211e-03, 4.8814e-05, 4.0505e-07, 1.6945e-05, 1.8897e-06, 8.7233e-05,
        1.1069e-02, 5.8961e-02, 1.4197e-02, 4.9169e-01, 8.8642e-02, 3.3086e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,708][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([8.7114e-01, 1.9323e-03, 6.8389e-04, 7.9348e-04, 1.0699e-03, 2.0444e-03,
        1.2905e-02, 2.6006e-02, 1.8388e-02, 2.5898e-02, 1.2362e-02, 2.6779e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,709][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([9.2740e-01, 1.8762e-03, 9.7660e-04, 6.9380e-04, 1.0267e-03, 1.5539e-03,
        2.7100e-03, 6.5949e-03, 6.8600e-03, 1.5029e-02, 7.2812e-03, 2.8000e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,712][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.7308, 0.0238, 0.0163, 0.0213, 0.0182, 0.0194, 0.0229, 0.0265, 0.0283,
        0.0324, 0.0270, 0.0331], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,716][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0389, 0.0036, 0.0014, 0.0024, 0.0013, 0.0040, 0.0205, 0.0618, 0.0964,
        0.2185, 0.1702, 0.3809], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,717][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([4.8577e-01, 3.7303e-04, 9.3071e-06, 1.4575e-04, 3.1108e-04, 1.8615e-05,
        4.6361e-05, 1.7222e-04, 4.9575e-01, 1.3899e-04, 1.7390e-03, 2.3367e-03,
        1.3184e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,717][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0037, 0.0423, 0.0477, 0.0246, 0.0220, 0.0300, 0.0625, 0.0330, 0.1136,
        0.0585, 0.1879, 0.3071, 0.0671], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,717][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.8848, 0.0018, 0.0034, 0.0019, 0.0057, 0.0140, 0.0131, 0.0154, 0.0150,
        0.0189, 0.0021, 0.0107, 0.0131], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,718][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.4251, 0.0128, 0.0100, 0.0070, 0.0211, 0.0335, 0.0414, 0.0687, 0.0534,
        0.0543, 0.0533, 0.1035, 0.1160], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,718][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([6.3746e-04, 4.9375e-05, 3.9283e-06, 7.5436e-05, 9.2800e-06, 1.5539e-04,
        7.1016e-03, 2.5330e-02, 2.9170e-02, 2.2391e-01, 2.9546e-02, 2.2015e-01,
        4.6386e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,718][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.9371e-01, 1.1504e-03, 3.0913e-05, 2.4197e-04, 6.9901e-05, 1.7032e-03,
        1.5914e-02, 4.1155e-02, 1.0329e-02, 1.1693e-01, 6.6743e-02, 3.0421e-01,
        2.4781e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,719][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.8839, 0.0013, 0.0021, 0.0014, 0.0078, 0.0124, 0.0070, 0.0092, 0.0069,
        0.0106, 0.0073, 0.0339, 0.0162], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,719][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([6.0098e-03, 4.0334e-05, 6.0172e-07, 7.3452e-06, 2.8692e-06, 7.3337e-05,
        6.7135e-03, 2.3986e-02, 7.8595e-03, 1.8024e-01, 2.5157e-02, 4.5498e-01,
        2.9494e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,720][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([9.2081e-01, 1.6180e-03, 6.0261e-04, 4.3126e-04, 6.6964e-04, 1.1985e-03,
        5.4398e-03, 1.2593e-02, 7.5320e-03, 1.3975e-02, 6.2090e-03, 1.8413e-02,
        1.0506e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,722][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.8947, 0.0024, 0.0017, 0.0010, 0.0014, 0.0019, 0.0070, 0.0120, 0.0084,
        0.0171, 0.0108, 0.0293, 0.0123], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,725][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.7240, 0.0249, 0.0173, 0.0203, 0.0173, 0.0171, 0.0213, 0.0252, 0.0272,
        0.0280, 0.0246, 0.0304, 0.0223], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,729][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0665, 0.0066, 0.0028, 0.0043, 0.0017, 0.0044, 0.0165, 0.0806, 0.0893,
        0.2296, 0.1395, 0.2864, 0.0717], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:19,730][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.4388e-01, 2.0567e-04, 5.6652e-06, 4.0202e-05, 2.2163e-04, 6.6748e-06,
        1.4571e-05, 5.4797e-05, 2.4723e-01, 3.1542e-05, 6.3928e-04, 1.2566e-03,
        5.6155e-03, 8.0198e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,730][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0355, 0.0388, 0.0720, 0.0210, 0.0395, 0.0225, 0.0438, 0.0158, 0.0961,
        0.0501, 0.1183, 0.3251, 0.0652, 0.0564], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,730][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.5855e-01, 4.6772e-04, 1.5518e-03, 5.0808e-04, 2.6235e-03, 3.1401e-03,
        4.1788e-03, 4.2932e-03, 5.0341e-03, 6.3391e-03, 5.8822e-04, 5.1861e-03,
        3.7245e-03, 3.8109e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,731][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.2685e-01, 2.4815e-03, 1.6295e-03, 6.9826e-04, 2.9943e-03, 4.0661e-03,
        5.5602e-03, 6.2614e-03, 4.8486e-03, 6.2416e-03, 5.2610e-03, 9.4862e-03,
        1.2560e-02, 1.1062e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,731][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.1633e-03, 2.6485e-05, 2.6684e-06, 2.0318e-05, 6.2752e-06, 1.0924e-04,
        3.1081e-03, 8.4648e-03, 7.0414e-03, 5.9658e-02, 1.0155e-02, 7.2199e-02,
        1.9218e-01, 6.4487e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,732][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.1231e-01, 2.3924e-04, 5.7937e-06, 2.1653e-05, 1.0839e-05, 2.7828e-04,
        1.8819e-03, 4.1954e-03, 9.4264e-04, 1.6080e-02, 8.2043e-03, 1.7818e-02,
        2.5415e-02, 1.1260e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,732][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.8820e-01, 6.2327e-05, 2.4492e-04, 1.7562e-04, 1.4038e-03, 1.0034e-03,
        6.5525e-04, 8.5518e-04, 4.4975e-04, 6.0889e-04, 2.8318e-04, 4.5432e-03,
        1.1163e-03, 3.9403e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,733][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.7396e-02, 1.8775e-05, 2.2085e-07, 2.8312e-06, 6.7738e-07, 1.6629e-05,
        1.2981e-03, 4.3229e-03, 7.8002e-04, 3.1552e-02, 4.4152e-03, 2.2491e-02,
        2.7764e-02, 8.2994e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,734][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9399e-01, 1.3105e-04, 8.3371e-05, 2.6589e-05, 1.1500e-04, 1.2210e-04,
        5.4436e-04, 7.8703e-04, 3.8138e-04, 8.2209e-04, 2.3364e-04, 1.0742e-03,
        5.0983e-04, 1.1790e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,736][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9344e-01, 2.2027e-04, 1.4404e-04, 6.1918e-05, 1.2116e-04, 1.5405e-04,
        3.1813e-04, 4.6277e-04, 4.8561e-04, 8.7393e-04, 4.3914e-04, 1.5604e-03,
        6.6584e-04, 1.0541e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,739][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7299, 0.0251, 0.0164, 0.0192, 0.0157, 0.0149, 0.0181, 0.0222, 0.0251,
        0.0247, 0.0226, 0.0258, 0.0187, 0.0214], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,742][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1638, 0.0081, 0.0064, 0.0036, 0.0025, 0.0056, 0.0139, 0.0371, 0.0528,
        0.1180, 0.0752, 0.1445, 0.0695, 0.2991], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:19,743][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([7.3458e-01, 3.3907e-04, 1.3018e-05, 6.5623e-05, 3.3676e-04, 1.0932e-05,
        3.8395e-05, 1.1143e-04, 2.5346e-01, 8.4839e-05, 8.4370e-04, 2.2220e-03,
        5.8233e-03, 1.1387e-03, 9.2393e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,743][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0087, 0.0286, 0.0575, 0.0192, 0.0337, 0.0168, 0.0263, 0.0270, 0.0702,
        0.0444, 0.0908, 0.4054, 0.0523, 0.0900, 0.0291], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,744][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.8935, 0.0010, 0.0031, 0.0012, 0.0050, 0.0066, 0.0086, 0.0098, 0.0100,
        0.0116, 0.0010, 0.0101, 0.0083, 0.0077, 0.0224], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,744][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.7544, 0.0077, 0.0071, 0.0037, 0.0137, 0.0119, 0.0134, 0.0200, 0.0158,
        0.0139, 0.0130, 0.0467, 0.0184, 0.0311, 0.0291], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,744][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([5.0560e-04, 1.6594e-05, 8.0694e-07, 1.0097e-05, 1.7133e-06, 4.4689e-05,
        7.4383e-04, 3.8900e-03, 3.5260e-03, 3.0071e-02, 5.5343e-03, 2.8196e-02,
        4.7484e-02, 4.2397e-01, 4.5601e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,745][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([3.3534e-01, 3.0540e-04, 7.1544e-06, 3.2557e-05, 1.0815e-05, 3.6216e-04,
        2.9416e-03, 7.7245e-03, 2.5458e-03, 2.9434e-02, 1.4012e-02, 3.3361e-02,
        4.6468e-02, 3.0115e-01, 2.2631e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,745][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([9.5313e-01, 3.4093e-04, 1.1273e-03, 5.5944e-04, 4.5981e-03, 2.9814e-03,
        1.5879e-03, 2.7460e-03, 2.2764e-03, 1.6362e-03, 1.2977e-03, 1.8517e-02,
        3.6119e-03, 1.9851e-03, 3.6084e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,746][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([1.5021e-02, 8.3875e-06, 8.0592e-08, 1.0939e-06, 2.4095e-07, 6.9362e-06,
        5.3284e-04, 2.9038e-03, 6.8825e-04, 2.2645e-02, 4.1407e-03, 1.8845e-02,
        2.1107e-02, 4.4697e-01, 4.6713e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,747][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([9.4811e-01, 5.2406e-04, 3.1396e-04, 2.4107e-04, 4.1844e-04, 4.1805e-04,
        2.1955e-03, 4.9220e-03, 3.2501e-03, 4.1975e-03, 2.3126e-03, 6.6084e-03,
        2.7136e-03, 1.0991e-02, 1.2789e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,749][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([9.6305e-01, 5.7945e-04, 4.2079e-04, 2.2512e-04, 3.8035e-04, 5.3958e-04,
        1.1650e-03, 1.7728e-03, 1.8924e-03, 4.1703e-03, 1.9873e-03, 6.8919e-03,
        2.2749e-03, 4.0509e-03, 1.0602e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,752][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.6779, 0.0252, 0.0174, 0.0202, 0.0175, 0.0170, 0.0205, 0.0247, 0.0270,
        0.0275, 0.0245, 0.0299, 0.0212, 0.0238, 0.0258], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,756][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0705, 0.0027, 0.0027, 0.0018, 0.0020, 0.0027, 0.0090, 0.0398, 0.0367,
        0.1029, 0.0782, 0.2039, 0.0356, 0.3455, 0.0661], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:19,756][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([5.9180e-01, 2.1580e-04, 8.4419e-06, 4.9753e-05, 2.2723e-04, 9.3241e-06,
        1.5460e-05, 7.7803e-05, 2.7993e-01, 7.5580e-05, 7.6568e-04, 1.5175e-03,
        5.7037e-03, 7.4379e-04, 5.7297e-04, 1.1829e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,756][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0110, 0.0161, 0.0545, 0.0196, 0.0166, 0.0127, 0.0280, 0.0202, 0.0531,
        0.0651, 0.1045, 0.3463, 0.0582, 0.0856, 0.0853, 0.0233],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,757][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.8602, 0.0010, 0.0026, 0.0012, 0.0044, 0.0059, 0.0078, 0.0097, 0.0101,
        0.0130, 0.0012, 0.0093, 0.0074, 0.0089, 0.0186, 0.0389],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,757][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6461, 0.0055, 0.0041, 0.0021, 0.0098, 0.0154, 0.0201, 0.0221, 0.0181,
        0.0223, 0.0175, 0.0419, 0.0511, 0.0468, 0.0620, 0.0150],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,758][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.7541e-04, 1.1300e-05, 7.0684e-07, 1.3156e-05, 9.4744e-07, 3.2868e-05,
        1.1159e-03, 2.0696e-03, 2.0916e-03, 2.9276e-02, 2.6976e-03, 2.1299e-02,
        6.8107e-02, 2.7472e-01, 5.8743e-01, 1.0962e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,758][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.1745e-01, 1.7565e-04, 4.9811e-06, 3.5417e-05, 1.1404e-05, 3.2908e-04,
        2.9669e-03, 9.9038e-03, 1.6557e-03, 3.1862e-02, 1.1050e-02, 4.1734e-02,
        5.2494e-02, 2.9720e-01, 4.1070e-01, 2.2430e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,759][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.7585e-01, 1.7880e-04, 4.5719e-04, 3.0920e-04, 1.6569e-03, 1.8754e-03,
        1.1953e-03, 1.8434e-03, 7.7546e-04, 8.7271e-04, 8.0758e-04, 7.7197e-03,
        2.1520e-03, 1.4215e-03, 1.7671e-03, 1.1214e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,760][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.9063e-04, 2.3773e-06, 3.2632e-08, 1.1321e-06, 1.3067e-07, 3.2764e-06,
        5.1567e-04, 1.5596e-03, 2.6587e-04, 2.0259e-02, 9.8286e-04, 1.1134e-02,
        1.2137e-02, 3.0428e-01, 6.4036e-01, 8.1132e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,762][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.6674e-01, 3.0763e-04, 1.7323e-04, 1.1208e-04, 2.6851e-04, 3.6506e-04,
        1.8087e-03, 3.1906e-03, 1.6884e-03, 3.0625e-03, 1.1523e-03, 3.8366e-03,
        1.8882e-03, 5.3743e-03, 8.5525e-03, 1.4830e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,764][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.5949e-01, 6.1649e-04, 3.5568e-04, 2.0613e-04, 2.8901e-04, 4.1754e-04,
        1.0965e-03, 1.9502e-03, 1.5021e-03, 3.9846e-03, 1.5941e-03, 5.1684e-03,
        2.7456e-03, 4.1069e-03, 1.3331e-02, 3.1487e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,767][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6508, 0.0260, 0.0176, 0.0209, 0.0178, 0.0169, 0.0207, 0.0247, 0.0274,
        0.0279, 0.0251, 0.0297, 0.0213, 0.0241, 0.0262, 0.0229],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,769][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0800, 0.0047, 0.0033, 0.0028, 0.0017, 0.0039, 0.0115, 0.0327, 0.0447,
        0.1075, 0.0711, 0.1567, 0.0402, 0.3560, 0.0615, 0.0215],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:19,769][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([5.8129e-01, 2.1430e-04, 1.0846e-05, 7.1655e-05, 2.7342e-04, 9.0992e-06,
        2.3274e-05, 9.3189e-05, 2.9506e-01, 7.3696e-05, 7.6077e-04, 1.5328e-03,
        5.1290e-03, 8.5292e-04, 6.3196e-04, 1.1344e-01, 5.3109e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,769][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0084, 0.0235, 0.0407, 0.0135, 0.0184, 0.0244, 0.0276, 0.0221, 0.0488,
        0.0205, 0.0725, 0.3634, 0.0699, 0.0824, 0.0611, 0.0305, 0.0723],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,770][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.8506, 0.0012, 0.0020, 0.0009, 0.0031, 0.0062, 0.0060, 0.0083, 0.0111,
        0.0125, 0.0012, 0.0072, 0.0076, 0.0079, 0.0190, 0.0362, 0.0189],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,770][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([8.8930e-01, 1.8292e-03, 1.2898e-03, 8.4056e-04, 3.8054e-03, 3.7112e-03,
        5.1647e-03, 7.2443e-03, 4.7318e-03, 7.9170e-03, 4.3416e-03, 1.5023e-02,
        8.4502e-03, 1.1909e-02, 1.1023e-02, 3.4829e-03, 1.9939e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,771][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([7.3340e-04, 3.6013e-06, 2.8326e-07, 2.3520e-06, 4.4108e-07, 1.0767e-05,
        2.8843e-04, 1.7882e-03, 6.7127e-04, 1.3256e-02, 1.5595e-03, 1.1995e-02,
        1.6851e-02, 2.2373e-01, 3.3324e-01, 7.8366e-03, 3.8804e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,771][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([3.2425e-01, 7.5365e-05, 1.6110e-06, 9.2826e-06, 2.8440e-06, 9.1939e-05,
        1.2752e-03, 3.3600e-03, 6.6736e-04, 1.4612e-02, 3.6251e-03, 1.2010e-02,
        1.4272e-02, 1.4601e-01, 2.5585e-01, 1.2663e-02, 2.1122e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,771][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([9.4201e-01, 3.5239e-04, 1.2677e-03, 8.1316e-04, 4.8363e-03, 4.8359e-03,
        3.2655e-03, 3.0206e-03, 1.3789e-03, 2.2517e-03, 1.3651e-03, 1.3644e-02,
        3.1979e-03, 3.3460e-03, 3.3820e-03, 2.4030e-03, 8.6273e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,772][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([7.2580e-03, 9.5942e-07, 9.3278e-09, 1.5791e-07, 3.4143e-08, 1.2331e-06,
        2.1970e-04, 6.9598e-04, 9.2661e-05, 6.4139e-03, 5.9206e-04, 3.7622e-03,
        3.1228e-03, 2.0418e-01, 2.4866e-01, 4.6849e-03, 5.2031e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,774][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([9.5350e-01, 3.3026e-04, 1.6231e-04, 1.2199e-04, 2.0709e-04, 2.5056e-04,
        1.8925e-03, 3.0651e-03, 1.1134e-03, 3.4665e-03, 9.1779e-04, 3.3356e-03,
        1.2106e-03, 6.4111e-03, 7.6325e-03, 1.3788e-03, 1.4999e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,775][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([9.8079e-01, 2.3458e-04, 1.4942e-04, 9.0440e-05, 1.5100e-04, 2.2921e-04,
        4.8495e-04, 9.9068e-04, 6.4865e-04, 1.7568e-03, 5.3323e-04, 2.7558e-03,
        9.5997e-04, 1.4445e-03, 4.8323e-03, 9.9794e-04, 2.9478e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,779][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.6682, 0.0220, 0.0144, 0.0178, 0.0150, 0.0148, 0.0181, 0.0214, 0.0233,
        0.0249, 0.0218, 0.0259, 0.0189, 0.0215, 0.0236, 0.0202, 0.0281],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,782][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0763, 0.0027, 0.0018, 0.0015, 0.0011, 0.0015, 0.0035, 0.0223, 0.0292,
        0.0758, 0.0437, 0.0973, 0.0259, 0.2973, 0.0321, 0.0172, 0.2707],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:19,782][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.0389e-01, 2.0879e-04, 6.6415e-06, 4.3097e-05, 2.5675e-04, 8.1193e-06,
        1.7481e-05, 6.8193e-05, 2.8028e-01, 4.3329e-05, 7.9874e-04, 1.6652e-03,
        5.1765e-03, 7.8426e-04, 5.3549e-04, 1.0559e-01, 2.9001e-04, 3.3465e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,783][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0195, 0.0221, 0.0461, 0.0135, 0.0277, 0.0147, 0.0356, 0.0114, 0.0604,
        0.0313, 0.1019, 0.2664, 0.0403, 0.0484, 0.0450, 0.0436, 0.1326, 0.0395],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,783][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([8.8881e-01, 5.3001e-04, 1.9669e-03, 6.2890e-04, 3.8306e-03, 3.4766e-03,
        5.0469e-03, 5.3482e-03, 6.9916e-03, 8.2024e-03, 7.4120e-04, 7.5962e-03,
        4.5689e-03, 4.6339e-03, 1.2988e-02, 2.5352e-02, 1.3504e-02, 5.7839e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,783][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.8491e-01, 2.6445e-03, 1.7569e-03, 8.4112e-04, 3.2878e-03, 4.0380e-03,
        5.9429e-03, 5.9643e-03, 4.4678e-03, 6.6573e-03, 5.4165e-03, 1.2105e-02,
        1.1473e-02, 1.2541e-02, 1.2530e-02, 4.2787e-03, 1.3981e-02, 7.1612e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,784][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.0959e-04, 3.9223e-06, 5.6960e-07, 6.5117e-06, 1.4953e-06, 2.5712e-05,
        8.5801e-04, 2.5290e-03, 1.8856e-03, 3.2432e-02, 3.4224e-03, 2.2390e-02,
        4.6057e-02, 1.8461e-01, 3.0878e-01, 9.8253e-03, 3.5655e-01, 3.0417e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,784][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.3849e-01, 1.1417e-04, 4.0063e-06, 2.1215e-05, 8.1704e-06, 2.6405e-04,
        2.2747e-03, 5.6519e-03, 1.2217e-03, 3.3102e-02, 1.2076e-02, 2.2477e-02,
        2.9913e-02, 1.4264e-01, 2.8970e-01, 1.7467e-02, 2.7726e-01, 2.7317e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,785][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.6211e-01, 9.1756e-05, 4.5282e-04, 2.4567e-04, 2.9472e-03, 1.9344e-03,
        1.4671e-03, 1.9231e-03, 8.7468e-04, 8.5370e-04, 5.5077e-04, 1.2580e-02,
        2.1429e-03, 1.0914e-03, 2.5351e-03, 1.9631e-03, 4.7462e-03, 1.4940e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,787][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.8513e-03, 2.0135e-06, 3.9408e-08, 6.5304e-07, 1.2338e-07, 2.7626e-06,
        3.4325e-04, 1.0817e-03, 2.1062e-04, 1.4900e-02, 1.2741e-03, 6.4944e-03,
        4.8261e-03, 1.8082e-01, 2.7390e-01, 4.2216e-03, 4.8491e-01, 2.3165e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,788][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.6613e-01, 1.9337e-04, 1.9679e-04, 6.1148e-05, 2.7945e-04, 2.8587e-04,
        1.6162e-03, 1.8103e-03, 9.3341e-04, 2.4867e-03, 5.3812e-04, 3.2070e-03,
        1.1188e-03, 3.1345e-03, 6.5251e-03, 1.1373e-03, 8.9336e-03, 1.4092e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,790][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.8530e-01, 1.8528e-04, 1.4268e-04, 6.4801e-05, 1.2958e-04, 1.4268e-04,
        3.6374e-04, 5.0278e-04, 4.7238e-04, 1.1258e-03, 4.0073e-04, 1.8119e-03,
        7.1234e-04, 1.0764e-03, 4.2489e-03, 9.7662e-04, 1.8935e-03, 4.5157e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,794][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.6623, 0.0233, 0.0159, 0.0180, 0.0154, 0.0139, 0.0171, 0.0207, 0.0234,
        0.0233, 0.0210, 0.0247, 0.0173, 0.0197, 0.0213, 0.0190, 0.0251, 0.0187],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,795][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0793, 0.0044, 0.0039, 0.0023, 0.0020, 0.0037, 0.0068, 0.0198, 0.0352,
        0.0609, 0.0411, 0.1158, 0.0292, 0.2035, 0.0383, 0.0204, 0.2808, 0.0525],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:19,847][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:19,848][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,848][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,848][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,849][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,849][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,850][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,852][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,854][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,857][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,859][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,860][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,860][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:19,860][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9970, 0.0030], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,861][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4606, 0.5394], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,861][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9977, 0.0023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,861][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9911, 0.0089], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,862][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1140, 0.8860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,863][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9576, 0.0424], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,866][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,869][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8980, 0.1020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,872][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9981, 0.0019], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,872][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9957, 0.0043], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,873][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9655, 0.0345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,873][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4306, 0.5694], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:19,873][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.9809, 0.0177, 0.0014], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,873][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.1170, 0.4146, 0.4684], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,874][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.9002, 0.0144, 0.0854], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,874][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.8907, 0.0322, 0.0771], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,874][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.0065, 0.7714, 0.2221], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,875][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.4211, 0.5421, 0.0368], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,875][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.9508, 0.0171, 0.0321], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,876][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.0391, 0.9289, 0.0321], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,879][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.9785, 0.0134, 0.0081], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,883][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.9423, 0.0325, 0.0252], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,885][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.6842, 0.1228, 0.1931], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,885][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.0356, 0.7028, 0.2616], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:19,886][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9573e-01, 3.3672e-03, 1.9450e-04, 7.0941e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,886][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3063, 0.2096, 0.3938, 0.0903], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,886][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9121e-01, 1.4278e-03, 6.7757e-03, 5.8585e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,887][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9666, 0.0066, 0.0191, 0.0076], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,887][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0077, 0.4110, 0.0797, 0.5016], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,887][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8277, 0.1230, 0.0064, 0.0429], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,888][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9890, 0.0012, 0.0061, 0.0037], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,889][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4459, 0.3549, 0.0093, 0.1899], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,892][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9856, 0.0064, 0.0040, 0.0040], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,895][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9959, 0.0020, 0.0011, 0.0011], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,898][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8353, 0.0313, 0.0394, 0.0940], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,898][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2106, 0.2897, 0.1902, 0.3095], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:19,899][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([9.7219e-01, 9.7570e-03, 7.9353e-04, 3.2548e-03, 1.4001e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,899][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0507, 0.2290, 0.4056, 0.1122, 0.2025], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,899][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.7703, 0.0159, 0.1122, 0.0264, 0.0752], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,899][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.7589, 0.0236, 0.0624, 0.0272, 0.1279], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,900][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0010, 0.1576, 0.0616, 0.6729, 0.1069], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,900][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.2699, 0.3345, 0.0216, 0.3152, 0.0588], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,900][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.9145, 0.0054, 0.0169, 0.0249, 0.0383], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,901][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0055, 0.1917, 0.0117, 0.7398, 0.0513], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,902][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.8499, 0.0356, 0.0294, 0.0421, 0.0430], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,905][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.9365, 0.0186, 0.0154, 0.0128, 0.0167], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,908][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.3899, 0.0473, 0.1041, 0.1802, 0.2786], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,911][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0118, 0.2477, 0.1433, 0.4057, 0.1914], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:19,911][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([9.8753e-01, 5.1289e-03, 1.5619e-04, 1.9153e-03, 4.9709e-03, 3.0276e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,912][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0192, 0.2224, 0.2356, 0.2175, 0.1737, 0.1316], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,912][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.9589, 0.0024, 0.0124, 0.0025, 0.0132, 0.0107], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,912][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.4696, 0.0593, 0.0799, 0.0394, 0.1070, 0.2448], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,913][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0020, 0.1347, 0.0097, 0.2277, 0.0266, 0.5993], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,913][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.3683, 0.1505, 0.0091, 0.0648, 0.0231, 0.3843], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,913][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.9542, 0.0018, 0.0049, 0.0040, 0.0168, 0.0183], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,915][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0507, 0.1504, 0.0072, 0.0731, 0.0325, 0.6861], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,917][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.9500, 0.0145, 0.0049, 0.0067, 0.0079, 0.0160], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,920][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.9308, 0.0157, 0.0131, 0.0090, 0.0120, 0.0194], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,924][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.3365, 0.0354, 0.0666, 0.0740, 0.1201, 0.3674], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,924][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0382, 0.2489, 0.0865, 0.2223, 0.0961, 0.3080], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:19,925][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([9.9344e-01, 3.2008e-03, 8.9861e-05, 7.3871e-04, 2.0848e-03, 1.4358e-04,
        2.9753e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,925][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.0108, 0.1985, 0.2727, 0.1587, 0.0958, 0.1511, 0.1123],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,925][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.9114, 0.0059, 0.0213, 0.0058, 0.0182, 0.0173, 0.0200],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,926][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.5411, 0.0404, 0.0640, 0.0210, 0.0830, 0.1455, 0.1050],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,926][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([1.9512e-03, 7.0030e-03, 8.9241e-04, 7.2916e-03, 1.0640e-03, 3.4745e-02,
        9.4705e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,926][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.5037, 0.0313, 0.0011, 0.0076, 0.0025, 0.0619, 0.3918],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,927][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.9528, 0.0012, 0.0048, 0.0032, 0.0166, 0.0111, 0.0104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,928][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([2.1332e-02, 6.9648e-03, 2.1058e-04, 2.1714e-03, 3.4300e-04, 3.2303e-02,
        9.3668e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,930][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.9332, 0.0071, 0.0037, 0.0039, 0.0055, 0.0077, 0.0388],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,933][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.9737, 0.0046, 0.0028, 0.0021, 0.0023, 0.0039, 0.0106],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,937][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.3163, 0.0164, 0.0245, 0.0336, 0.0504, 0.1484, 0.4104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,937][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0288, 0.1768, 0.0559, 0.1020, 0.0539, 0.2234, 0.3592],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:19,938][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.9565e-01, 1.4139e-03, 6.2839e-05, 3.7417e-04, 1.7160e-03, 6.4594e-05,
        1.2194e-04, 5.9468e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,938][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1188, 0.1204, 0.1798, 0.0838, 0.0801, 0.1083, 0.2507, 0.0581],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,938][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([9.8781e-01, 4.7783e-04, 2.7542e-03, 3.5213e-04, 2.6451e-03, 2.1123e-03,
        2.0535e-03, 1.7963e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,939][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.9384, 0.0047, 0.0069, 0.0029, 0.0088, 0.0143, 0.0120, 0.0120],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,939][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([5.6609e-03, 1.6523e-03, 2.4050e-04, 1.9046e-03, 5.1229e-04, 1.3502e-02,
        3.3779e-01, 6.3874e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,939][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([8.3609e-01, 3.3839e-03, 1.3674e-04, 5.3177e-04, 3.6983e-04, 7.1413e-03,
        5.5970e-02, 9.6378e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,940][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([9.9383e-01, 1.0530e-04, 5.2557e-04, 2.0194e-04, 2.0495e-03, 1.1032e-03,
        1.0256e-03, 1.1622e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,941][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([1.1123e-01, 1.2616e-03, 2.2083e-05, 3.3441e-04, 8.4963e-05, 3.4909e-03,
        1.9187e-01, 6.9170e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,942][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.8102e-01, 1.0107e-03, 5.6878e-04, 4.0012e-04, 1.0867e-03, 1.1645e-03,
        7.7109e-03, 7.0367e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,944][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([9.9084e-01, 9.1339e-04, 7.0448e-04, 4.3834e-04, 5.6482e-04, 1.1781e-03,
        2.1297e-03, 3.2325e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,947][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.6048, 0.0050, 0.0083, 0.0083, 0.0166, 0.0338, 0.1112, 0.2120],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,950][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0474, 0.0366, 0.0222, 0.0322, 0.0242, 0.0485, 0.1043, 0.6845],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:19,950][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([4.5368e-01, 2.4871e-04, 9.0504e-06, 5.8272e-05, 3.0947e-04, 1.0445e-05,
        1.7108e-05, 8.6797e-05, 5.4558e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,950][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1108, 0.1023, 0.1953, 0.1099, 0.0624, 0.0825, 0.1098, 0.1257, 0.1014],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,951][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([9.9177e-01, 2.9432e-04, 1.7544e-03, 1.5591e-04, 1.4346e-03, 9.0354e-04,
        1.1967e-03, 9.2071e-04, 1.5664e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,951][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.8083, 0.0095, 0.0111, 0.0053, 0.0231, 0.0371, 0.0250, 0.0413, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,951][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.4469e-03, 8.2875e-04, 6.9136e-05, 8.2094e-04, 1.2258e-04, 3.4523e-03,
        1.0547e-01, 4.8094e-01, 4.0686e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,952][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([6.4440e-01, 3.8394e-03, 1.0811e-04, 5.1067e-04, 3.0642e-04, 8.6218e-03,
        6.2564e-02, 2.2966e-01, 4.9988e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,952][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.9837e-01, 4.2790e-05, 1.3437e-04, 8.5284e-05, 4.2986e-04, 3.3308e-04,
        2.1162e-04, 2.9436e-04, 1.0127e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,952][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.7832e-02, 7.5558e-04, 9.0252e-06, 1.7002e-04, 3.8661e-05, 1.5962e-03,
        2.3689e-01, 6.0895e-01, 1.2376e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,953][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([9.7976e-01, 1.0457e-03, 5.1650e-04, 2.8281e-04, 6.3025e-04, 9.2321e-04,
        4.0484e-03, 8.2661e-03, 4.5249e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,955][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([9.8770e-01, 9.1490e-04, 5.9350e-04, 4.1520e-04, 4.7194e-04, 8.5772e-04,
        2.2026e-03, 3.5550e-03, 3.2896e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,958][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.5414, 0.0048, 0.0046, 0.0086, 0.0099, 0.0309, 0.1061, 0.1762, 0.1176],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,961][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0291, 0.0233, 0.0103, 0.0165, 0.0119, 0.0287, 0.0663, 0.4134, 0.4005],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:19,963][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([4.7802e-01, 3.3112e-04, 1.4716e-05, 7.7633e-05, 2.3994e-04, 1.5292e-05,
        2.5602e-05, 1.0174e-04, 5.2108e-01, 9.5816e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,963][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0357, 0.1106, 0.1453, 0.0441, 0.1090, 0.0490, 0.1033, 0.0590, 0.2051,
        0.1390], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,963][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([9.5760e-01, 9.7660e-04, 4.4829e-03, 9.0747e-04, 3.7252e-03, 4.8804e-03,
        4.6706e-03, 4.0634e-03, 5.5237e-03, 1.3168e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,964][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.7735, 0.0100, 0.0068, 0.0072, 0.0142, 0.0234, 0.0276, 0.0373, 0.0367,
        0.0632], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,964][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([6.7213e-03, 3.4222e-04, 1.8514e-05, 2.1267e-04, 4.4898e-05, 1.0741e-03,
        2.1054e-02, 1.0362e-01, 1.6599e-01, 7.0092e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,964][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([6.6811e-01, 2.0427e-03, 3.4206e-05, 2.9102e-04, 7.8221e-05, 3.1543e-03,
        2.7197e-02, 8.4226e-02, 4.2094e-02, 1.7277e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,965][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([9.8342e-01, 4.4855e-04, 8.0208e-04, 5.8117e-04, 3.1395e-03, 3.1324e-03,
        1.8736e-03, 2.3208e-03, 1.5116e-03, 2.7732e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,965][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([2.6956e-02, 2.9187e-04, 1.3431e-06, 5.3348e-05, 7.7917e-06, 5.5356e-04,
        3.5505e-02, 1.6852e-01, 1.0525e-01, 6.6286e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,966][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([9.7368e-01, 8.6525e-04, 3.6425e-04, 4.1894e-04, 4.9850e-04, 1.1254e-03,
        4.3291e-03, 7.3641e-03, 4.8338e-03, 6.5224e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,967][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([9.8559e-01, 5.9525e-04, 4.7703e-04, 2.6288e-04, 4.4092e-04, 6.7460e-04,
        1.4433e-03, 2.5838e-03, 2.2085e-03, 5.7201e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,969][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.3833, 0.0036, 0.0025, 0.0050, 0.0053, 0.0199, 0.0595, 0.1097, 0.0668,
        0.3445], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,973][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0135, 0.0143, 0.0040, 0.0070, 0.0040, 0.0124, 0.0282, 0.1654, 0.2733,
        0.4779], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:19,976][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([5.0936e-01, 2.6142e-04, 5.8952e-06, 6.0466e-05, 2.9308e-04, 9.7148e-06,
        1.3912e-05, 6.3148e-05, 4.8928e-01, 2.9512e-05, 6.2671e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,976][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0564, 0.0916, 0.1320, 0.0344, 0.0632, 0.0560, 0.0922, 0.0629, 0.1253,
        0.1226, 0.1633], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,976][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([9.8824e-01, 2.2966e-04, 1.6078e-03, 1.5014e-04, 1.4229e-03, 1.2170e-03,
        1.1315e-03, 7.5147e-04, 1.3364e-03, 3.6032e-03, 3.1126e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,977][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.8716, 0.0052, 0.0060, 0.0026, 0.0134, 0.0158, 0.0127, 0.0212, 0.0165,
        0.0176, 0.0175], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,977][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.4889e-03, 5.7225e-04, 3.9130e-05, 2.5622e-04, 9.3442e-05, 1.4582e-03,
        1.7432e-02, 1.0110e-01, 1.4749e-01, 5.3348e-01, 1.9659e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,977][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([6.1497e-01, 2.7058e-03, 5.9586e-05, 2.5415e-04, 1.6814e-04, 4.1891e-03,
        1.8335e-02, 7.3023e-02, 3.0932e-02, 1.4444e-01, 1.1092e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,978][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.8689e-01, 2.5167e-04, 7.8213e-04, 4.5051e-04, 2.4959e-03, 1.5407e-03,
        1.8229e-03, 2.3112e-03, 1.0778e-03, 1.5677e-03, 8.0808e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,978][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([3.5033e-02, 3.9379e-04, 3.6978e-06, 6.5225e-05, 1.2570e-05, 6.2846e-04,
        3.2574e-02, 1.0977e-01, 5.4576e-02, 6.4646e-01, 1.2048e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,979][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([9.8808e-01, 5.2439e-04, 2.4681e-04, 9.9888e-05, 3.3603e-04, 3.8150e-04,
        1.5072e-03, 3.2715e-03, 1.9376e-03, 2.6303e-03, 9.8111e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,980][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([9.8589e-01, 9.5302e-04, 3.7611e-04, 2.7060e-04, 4.2014e-04, 7.0766e-04,
        1.1708e-03, 2.1596e-03, 1.9899e-03, 4.0855e-03, 1.9813e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,982][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.4906, 0.0023, 0.0027, 0.0028, 0.0075, 0.0125, 0.0395, 0.0687, 0.0469,
        0.2410, 0.0854], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,986][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0285, 0.0117, 0.0029, 0.0050, 0.0034, 0.0106, 0.0239, 0.1264, 0.1722,
        0.2607, 0.3549], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:19,988][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([3.0075e-01, 3.6283e-04, 1.6501e-05, 9.6436e-05, 4.2332e-04, 1.7723e-05,
        4.2528e-05, 1.7056e-04, 6.9215e-01, 1.6326e-04, 1.5379e-03, 4.2780e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,989][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0066, 0.0275, 0.0422, 0.0130, 0.0264, 0.0450, 0.0489, 0.0580, 0.1054,
        0.1073, 0.0997, 0.4200], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,989][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([9.3242e-01, 8.2838e-04, 4.9934e-03, 7.8118e-04, 4.7335e-03, 2.8003e-03,
        4.0338e-03, 4.1449e-03, 6.4097e-03, 2.2076e-02, 1.5694e-03, 1.5211e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,989][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.5995, 0.0057, 0.0053, 0.0048, 0.0155, 0.0308, 0.0302, 0.0379, 0.0409,
        0.0887, 0.0352, 0.1056], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,990][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([9.8263e-04, 8.5178e-05, 6.2525e-06, 6.1182e-05, 1.0848e-05, 3.7288e-04,
        7.4864e-03, 3.0495e-02, 3.1188e-02, 4.7031e-01, 5.3088e-02, 4.0591e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,990][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([5.7121e-01, 1.0941e-03, 1.7119e-05, 1.1593e-04, 3.3211e-05, 1.1483e-03,
        1.0713e-02, 3.9865e-02, 9.0794e-03, 1.3671e-01, 6.5165e-02, 1.6485e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,991][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([9.5898e-01, 7.8495e-04, 1.4964e-03, 9.8646e-04, 2.9946e-03, 4.0886e-03,
        3.0805e-03, 4.9593e-03, 2.5833e-03, 2.7530e-03, 2.6583e-03, 1.4638e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,991][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([4.4211e-03, 4.8814e-05, 4.0505e-07, 1.6945e-05, 1.8897e-06, 8.7233e-05,
        1.1069e-02, 5.8961e-02, 1.4197e-02, 4.9169e-01, 8.8642e-02, 3.3086e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,992][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([8.7114e-01, 1.9323e-03, 6.8389e-04, 7.9348e-04, 1.0699e-03, 2.0444e-03,
        1.2905e-02, 2.6006e-02, 1.8388e-02, 2.5898e-02, 1.2362e-02, 2.6779e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,993][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([9.2740e-01, 1.8762e-03, 9.7660e-04, 6.9380e-04, 1.0267e-03, 1.5539e-03,
        2.7100e-03, 6.5949e-03, 6.8600e-03, 1.5029e-02, 7.2812e-03, 2.8000e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,997][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.1441, 0.0014, 0.0011, 0.0022, 0.0031, 0.0124, 0.0355, 0.0648, 0.0369,
        0.3613, 0.0677, 0.2694], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:19,999][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0042, 0.0049, 0.0007, 0.0031, 0.0009, 0.0052, 0.0161, 0.0767, 0.1343,
        0.1957, 0.3626, 0.1959], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,002][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([4.8577e-01, 3.7303e-04, 9.3071e-06, 1.4575e-04, 3.1108e-04, 1.8615e-05,
        4.6361e-05, 1.7222e-04, 4.9575e-01, 1.3899e-04, 1.7390e-03, 2.3367e-03,
        1.3184e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,003][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0037, 0.0423, 0.0477, 0.0246, 0.0220, 0.0300, 0.0625, 0.0330, 0.1136,
        0.0585, 0.1879, 0.3071, 0.0671], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,004][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([9.4263e-01, 1.2350e-03, 4.4409e-03, 8.7053e-04, 3.7875e-03, 6.3140e-03,
        5.0160e-03, 3.2533e-03, 4.0153e-03, 1.0938e-02, 1.3495e-03, 6.4851e-03,
        9.6684e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,004][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.4251, 0.0128, 0.0100, 0.0070, 0.0211, 0.0335, 0.0414, 0.0687, 0.0534,
        0.0543, 0.0533, 0.1035, 0.1160], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,004][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([6.3746e-04, 4.9375e-05, 3.9283e-06, 7.5436e-05, 9.2800e-06, 1.5539e-04,
        7.1016e-03, 2.5330e-02, 2.9170e-02, 2.2391e-01, 2.9546e-02, 2.2015e-01,
        4.6386e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,005][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.9371e-01, 1.1504e-03, 3.0913e-05, 2.4197e-04, 6.9901e-05, 1.7032e-03,
        1.5914e-02, 4.1155e-02, 1.0329e-02, 1.1693e-01, 6.6743e-02, 3.0421e-01,
        2.4781e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,005][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.8706, 0.0017, 0.0026, 0.0018, 0.0080, 0.0136, 0.0088, 0.0102, 0.0077,
        0.0126, 0.0099, 0.0354, 0.0171], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,006][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([6.0098e-03, 4.0334e-05, 6.0172e-07, 7.3452e-06, 2.8692e-06, 7.3337e-05,
        6.7135e-03, 2.3986e-02, 7.8595e-03, 1.8024e-01, 2.5157e-02, 4.5498e-01,
        2.9494e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,007][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([9.2081e-01, 1.6180e-03, 6.0261e-04, 4.3126e-04, 6.6964e-04, 1.1985e-03,
        5.4398e-03, 1.2593e-02, 7.5320e-03, 1.3975e-02, 6.2090e-03, 1.8413e-02,
        1.0506e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,009][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.8947, 0.0024, 0.0017, 0.0010, 0.0014, 0.0019, 0.0070, 0.0120, 0.0084,
        0.0171, 0.0108, 0.0293, 0.0123], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,012][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.1146, 0.0016, 0.0018, 0.0026, 0.0043, 0.0105, 0.0393, 0.0804, 0.0420,
        0.2275, 0.0717, 0.3296, 0.0741], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,016][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0109, 0.0095, 0.0012, 0.0049, 0.0011, 0.0054, 0.0125, 0.0950, 0.1128,
        0.1910, 0.2825, 0.1580, 0.1152], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,016][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.4388e-01, 2.0567e-04, 5.6652e-06, 4.0202e-05, 2.2163e-04, 6.6748e-06,
        1.4571e-05, 5.4797e-05, 2.4723e-01, 3.1542e-05, 6.3928e-04, 1.2566e-03,
        5.6155e-03, 8.0198e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,016][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0355, 0.0388, 0.0720, 0.0210, 0.0395, 0.0225, 0.0438, 0.0158, 0.0961,
        0.0501, 0.1183, 0.3251, 0.0652, 0.0564], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,017][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9387e-01, 9.2648e-05, 7.6935e-04, 5.2209e-05, 6.5636e-04, 3.2774e-04,
        4.5364e-04, 1.8213e-04, 3.4336e-04, 1.0175e-03, 8.5383e-05, 1.1526e-03,
        7.6000e-04, 2.3983e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,017][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.2685e-01, 2.4815e-03, 1.6295e-03, 6.9826e-04, 2.9943e-03, 4.0661e-03,
        5.5602e-03, 6.2614e-03, 4.8486e-03, 6.2416e-03, 5.2610e-03, 9.4862e-03,
        1.2560e-02, 1.1062e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,018][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.1633e-03, 2.6485e-05, 2.6684e-06, 2.0318e-05, 6.2752e-06, 1.0924e-04,
        3.1081e-03, 8.4648e-03, 7.0414e-03, 5.9658e-02, 1.0155e-02, 7.2199e-02,
        1.9218e-01, 6.4487e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,018][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.1231e-01, 2.3924e-04, 5.7937e-06, 2.1653e-05, 1.0839e-05, 2.7828e-04,
        1.8819e-03, 4.1954e-03, 9.4264e-04, 1.6080e-02, 8.2043e-03, 1.7818e-02,
        2.5415e-02, 1.1260e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,018][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9015e-01, 6.6465e-05, 2.3358e-04, 1.6471e-04, 1.0489e-03, 8.2825e-04,
        6.2455e-04, 7.9168e-04, 4.1549e-04, 6.1163e-04, 2.8693e-04, 3.4863e-03,
        9.3860e-04, 3.5541e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,019][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([7.7396e-02, 1.8775e-05, 2.2085e-07, 2.8312e-06, 6.7738e-07, 1.6629e-05,
        1.2981e-03, 4.3229e-03, 7.8002e-04, 3.1552e-02, 4.4152e-03, 2.2491e-02,
        2.7764e-02, 8.2994e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,019][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.9399e-01, 1.3105e-04, 8.3371e-05, 2.6589e-05, 1.1500e-04, 1.2210e-04,
        5.4436e-04, 7.8703e-04, 3.8138e-04, 8.2209e-04, 2.3364e-04, 1.0742e-03,
        5.0983e-04, 1.1790e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,020][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.9344e-01, 2.2027e-04, 1.4404e-04, 6.1918e-05, 1.2116e-04, 1.5405e-04,
        3.1813e-04, 4.6277e-04, 4.8561e-04, 8.7393e-04, 4.3914e-04, 1.5604e-03,
        6.6584e-04, 1.0541e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,023][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6451, 0.0009, 0.0009, 0.0011, 0.0022, 0.0049, 0.0169, 0.0216, 0.0152,
        0.0828, 0.0262, 0.0935, 0.0226, 0.0660], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,025][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0540, 0.0096, 0.0023, 0.0036, 0.0015, 0.0068, 0.0143, 0.0517, 0.0724,
        0.1312, 0.1568, 0.0962, 0.1093, 0.2904], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,028][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([7.3458e-01, 3.3907e-04, 1.3018e-05, 6.5623e-05, 3.3676e-04, 1.0932e-05,
        3.8395e-05, 1.1143e-04, 2.5346e-01, 8.4839e-05, 8.4370e-04, 2.2220e-03,
        5.8233e-03, 1.1387e-03, 9.2393e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,030][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0087, 0.0286, 0.0575, 0.0192, 0.0337, 0.0168, 0.0263, 0.0270, 0.0702,
        0.0444, 0.0908, 0.4054, 0.0523, 0.0900, 0.0291], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,030][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([9.6914e-01, 3.8229e-04, 2.8578e-03, 2.8174e-04, 2.3684e-03, 1.4815e-03,
        1.9755e-03, 1.1013e-03, 1.5354e-03, 3.8366e-03, 2.9614e-04, 4.6191e-03,
        3.7883e-03, 1.1654e-03, 5.1733e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,031][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.7544, 0.0077, 0.0071, 0.0037, 0.0137, 0.0119, 0.0134, 0.0200, 0.0158,
        0.0139, 0.0130, 0.0467, 0.0184, 0.0311, 0.0291], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,031][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([5.0560e-04, 1.6594e-05, 8.0694e-07, 1.0097e-05, 1.7133e-06, 4.4689e-05,
        7.4383e-04, 3.8900e-03, 3.5260e-03, 3.0071e-02, 5.5343e-03, 2.8196e-02,
        4.7484e-02, 4.2397e-01, 4.5601e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,031][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.3534e-01, 3.0540e-04, 7.1544e-06, 3.2557e-05, 1.0815e-05, 3.6216e-04,
        2.9416e-03, 7.7245e-03, 2.5458e-03, 2.9434e-02, 1.4012e-02, 3.3361e-02,
        4.6468e-02, 3.0115e-01, 2.2631e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,032][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([9.6149e-01, 3.3205e-04, 1.0460e-03, 5.1728e-04, 3.5286e-03, 2.4785e-03,
        1.4678e-03, 2.4036e-03, 1.8988e-03, 1.5956e-03, 1.2539e-03, 1.4343e-02,
        2.8899e-03, 1.6753e-03, 3.0830e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,032][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([1.5021e-02, 8.3875e-06, 8.0592e-08, 1.0939e-06, 2.4095e-07, 6.9362e-06,
        5.3284e-04, 2.9038e-03, 6.8825e-04, 2.2645e-02, 4.1407e-03, 1.8845e-02,
        2.1107e-02, 4.4697e-01, 4.6713e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,033][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([9.4811e-01, 5.2406e-04, 3.1396e-04, 2.4107e-04, 4.1844e-04, 4.1805e-04,
        2.1955e-03, 4.9220e-03, 3.2501e-03, 4.1975e-03, 2.3126e-03, 6.6084e-03,
        2.7136e-03, 1.0991e-02, 1.2789e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,034][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([9.6305e-01, 5.7945e-04, 4.2079e-04, 2.2512e-04, 3.8035e-04, 5.3958e-04,
        1.1650e-03, 1.7728e-03, 1.8924e-03, 4.1703e-03, 1.9873e-03, 6.8919e-03,
        2.2749e-03, 4.0509e-03, 1.0602e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,036][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.2274, 0.0012, 0.0015, 0.0017, 0.0033, 0.0079, 0.0251, 0.0418, 0.0244,
        0.1297, 0.0397, 0.1806, 0.0314, 0.1234, 0.1609], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,039][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0136, 0.0045, 0.0012, 0.0025, 0.0012, 0.0035, 0.0077, 0.0534, 0.0536,
        0.1043, 0.1806, 0.1182, 0.0634, 0.3167, 0.0756], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,041][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.9180e-01, 2.1580e-04, 8.4419e-06, 4.9753e-05, 2.2723e-04, 9.3241e-06,
        1.5460e-05, 7.7803e-05, 2.7993e-01, 7.5580e-05, 7.6568e-04, 1.5175e-03,
        5.7037e-03, 7.4379e-04, 5.7297e-04, 1.1829e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,043][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0110, 0.0161, 0.0545, 0.0196, 0.0166, 0.0127, 0.0280, 0.0202, 0.0531,
        0.0651, 0.1045, 0.3463, 0.0582, 0.0856, 0.0853, 0.0233],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,043][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.7089e-01, 3.3002e-04, 2.0274e-03, 2.4256e-04, 1.7481e-03, 1.0763e-03,
        1.4957e-03, 9.3330e-04, 1.3405e-03, 4.1068e-03, 3.2398e-04, 3.5350e-03,
        2.7389e-03, 1.2695e-03, 3.2630e-03, 4.6827e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,044][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.6461, 0.0055, 0.0041, 0.0021, 0.0098, 0.0154, 0.0201, 0.0221, 0.0181,
        0.0223, 0.0175, 0.0419, 0.0511, 0.0468, 0.0620, 0.0150],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,044][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.7541e-04, 1.1300e-05, 7.0684e-07, 1.3156e-05, 9.4744e-07, 3.2868e-05,
        1.1159e-03, 2.0696e-03, 2.0916e-03, 2.9276e-02, 2.6976e-03, 2.1299e-02,
        6.8107e-02, 2.7472e-01, 5.8743e-01, 1.0962e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,045][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.1745e-01, 1.7565e-04, 4.9811e-06, 3.5417e-05, 1.1404e-05, 3.2908e-04,
        2.9669e-03, 9.9038e-03, 1.6557e-03, 3.1862e-02, 1.1050e-02, 4.1734e-02,
        5.2494e-02, 2.9720e-01, 4.1070e-01, 2.2430e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,045][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.8012e-01, 1.8867e-04, 4.4293e-04, 2.8373e-04, 1.2061e-03, 1.5718e-03,
        1.1362e-03, 1.6730e-03, 6.4496e-04, 9.2983e-04, 8.0964e-04, 5.4889e-03,
        1.8243e-03, 1.2851e-03, 1.5319e-03, 8.6701e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,045][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.9063e-04, 2.3773e-06, 3.2632e-08, 1.1321e-06, 1.3067e-07, 3.2764e-06,
        5.1567e-04, 1.5596e-03, 2.6587e-04, 2.0259e-02, 9.8286e-04, 1.1134e-02,
        1.2137e-02, 3.0428e-01, 6.4036e-01, 8.1132e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,046][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.6674e-01, 3.0763e-04, 1.7323e-04, 1.1208e-04, 2.6851e-04, 3.6506e-04,
        1.8087e-03, 3.1906e-03, 1.6884e-03, 3.0625e-03, 1.1523e-03, 3.8366e-03,
        1.8882e-03, 5.3743e-03, 8.5525e-03, 1.4830e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,047][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.5949e-01, 6.1649e-04, 3.5568e-04, 2.0613e-04, 2.8901e-04, 4.1754e-04,
        1.0965e-03, 1.9502e-03, 1.5021e-03, 3.9846e-03, 1.5941e-03, 5.1684e-03,
        2.7456e-03, 4.1069e-03, 1.3331e-02, 3.1487e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,049][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1754, 0.0012, 0.0012, 0.0019, 0.0030, 0.0067, 0.0281, 0.0370, 0.0266,
        0.1428, 0.0455, 0.1607, 0.0302, 0.1313, 0.1666, 0.0418],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,052][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0184, 0.0062, 0.0013, 0.0036, 0.0011, 0.0052, 0.0102, 0.0495, 0.0674,
        0.1130, 0.1636, 0.0905, 0.0750, 0.2752, 0.0771, 0.0428],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,054][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([5.8129e-01, 2.1430e-04, 1.0846e-05, 7.1655e-05, 2.7342e-04, 9.0992e-06,
        2.3274e-05, 9.3189e-05, 2.9506e-01, 7.3696e-05, 7.6077e-04, 1.5328e-03,
        5.1290e-03, 8.5292e-04, 6.3196e-04, 1.1344e-01, 5.3109e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,056][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0084, 0.0235, 0.0407, 0.0135, 0.0184, 0.0244, 0.0276, 0.0221, 0.0488,
        0.0205, 0.0725, 0.3634, 0.0699, 0.0824, 0.0611, 0.0305, 0.0723],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,057][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([9.6613e-01, 5.0665e-04, 1.4722e-03, 1.9106e-04, 1.1740e-03, 1.3054e-03,
        1.1338e-03, 8.3108e-04, 1.7439e-03, 4.0288e-03, 3.8965e-04, 2.5259e-03,
        3.0167e-03, 1.1262e-03, 3.6292e-03, 4.5022e-03, 6.2890e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,057][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([8.8930e-01, 1.8292e-03, 1.2898e-03, 8.4056e-04, 3.8054e-03, 3.7112e-03,
        5.1647e-03, 7.2443e-03, 4.7318e-03, 7.9170e-03, 4.3416e-03, 1.5023e-02,
        8.4502e-03, 1.1909e-02, 1.1023e-02, 3.4829e-03, 1.9939e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,057][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([7.3340e-04, 3.6013e-06, 2.8326e-07, 2.3520e-06, 4.4108e-07, 1.0767e-05,
        2.8843e-04, 1.7882e-03, 6.7127e-04, 1.3256e-02, 1.5595e-03, 1.1995e-02,
        1.6851e-02, 2.2373e-01, 3.3324e-01, 7.8366e-03, 3.8804e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,058][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([3.2425e-01, 7.5365e-05, 1.6110e-06, 9.2826e-06, 2.8440e-06, 9.1939e-05,
        1.2752e-03, 3.3600e-03, 6.6736e-04, 1.4612e-02, 3.6251e-03, 1.2010e-02,
        1.4272e-02, 1.4601e-01, 2.5585e-01, 1.2663e-02, 2.1122e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,058][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([9.4825e-01, 3.9724e-04, 1.2707e-03, 7.6281e-04, 3.8008e-03, 4.2268e-03,
        3.1497e-03, 2.7458e-03, 1.2658e-03, 2.3879e-03, 1.3972e-03, 1.0883e-02,
        2.6930e-03, 3.3093e-03, 3.0942e-03, 2.2251e-03, 8.1374e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,059][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([7.2580e-03, 9.5942e-07, 9.3278e-09, 1.5791e-07, 3.4143e-08, 1.2331e-06,
        2.1970e-04, 6.9598e-04, 9.2661e-05, 6.4139e-03, 5.9206e-04, 3.7622e-03,
        3.1228e-03, 2.0418e-01, 2.4866e-01, 4.6849e-03, 5.2031e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,059][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([9.5350e-01, 3.3026e-04, 1.6231e-04, 1.2199e-04, 2.0709e-04, 2.5056e-04,
        1.8925e-03, 3.0651e-03, 1.1134e-03, 3.4665e-03, 9.1779e-04, 3.3356e-03,
        1.2106e-03, 6.4111e-03, 7.6325e-03, 1.3788e-03, 1.4999e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,060][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([9.8079e-01, 2.3458e-04, 1.4942e-04, 9.0440e-05, 1.5100e-04, 2.2921e-04,
        4.8495e-04, 9.9068e-04, 6.4865e-04, 1.7568e-03, 5.3323e-04, 2.7558e-03,
        9.5997e-04, 1.4445e-03, 4.8323e-03, 9.9794e-04, 2.9478e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,062][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.2293, 0.0009, 0.0005, 0.0013, 0.0015, 0.0045, 0.0160, 0.0249, 0.0132,
        0.0989, 0.0238, 0.0763, 0.0175, 0.0859, 0.1200, 0.0227, 0.2629],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,065][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0142, 0.0032, 0.0009, 0.0020, 0.0009, 0.0025, 0.0041, 0.0388, 0.0495,
        0.0983, 0.1089, 0.0722, 0.0487, 0.2609, 0.0470, 0.0371, 0.2106],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,067][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.0389e-01, 2.0879e-04, 6.6415e-06, 4.3097e-05, 2.5675e-04, 8.1193e-06,
        1.7481e-05, 6.8193e-05, 2.8028e-01, 4.3329e-05, 7.9874e-04, 1.6652e-03,
        5.1765e-03, 7.8426e-04, 5.3549e-04, 1.0559e-01, 2.9001e-04, 3.3465e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,069][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0195, 0.0221, 0.0461, 0.0135, 0.0277, 0.0147, 0.0356, 0.0114, 0.0604,
        0.0313, 0.1019, 0.2664, 0.0403, 0.0484, 0.0450, 0.0436, 0.1326, 0.0395],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,070][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.7643e-01, 1.5133e-04, 1.5373e-03, 1.0966e-04, 1.6490e-03, 5.5692e-04,
        8.8514e-04, 4.0741e-04, 8.8848e-04, 2.3486e-03, 1.9504e-04, 3.1566e-03,
        1.5511e-03, 5.1255e-04, 2.2036e-03, 2.7495e-03, 4.2865e-03, 3.7944e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,070][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.8491e-01, 2.6445e-03, 1.7569e-03, 8.4112e-04, 3.2878e-03, 4.0380e-03,
        5.9429e-03, 5.9643e-03, 4.4678e-03, 6.6573e-03, 5.4165e-03, 1.2105e-02,
        1.1473e-02, 1.2541e-02, 1.2530e-02, 4.2787e-03, 1.3981e-02, 7.1612e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,071][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.0959e-04, 3.9223e-06, 5.6960e-07, 6.5117e-06, 1.4953e-06, 2.5712e-05,
        8.5801e-04, 2.5290e-03, 1.8856e-03, 3.2432e-02, 3.4224e-03, 2.2390e-02,
        4.6057e-02, 1.8461e-01, 3.0878e-01, 9.8253e-03, 3.5655e-01, 3.0417e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,071][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.3849e-01, 1.1417e-04, 4.0063e-06, 2.1215e-05, 8.1704e-06, 2.6405e-04,
        2.2747e-03, 5.6519e-03, 1.2217e-03, 3.3102e-02, 1.2076e-02, 2.2477e-02,
        2.9913e-02, 1.4264e-01, 2.8970e-01, 1.7467e-02, 2.7726e-01, 2.7317e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,071][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.7006e-01, 9.2901e-05, 4.0945e-04, 2.0983e-04, 2.0159e-03, 1.5102e-03,
        1.2923e-03, 1.6210e-03, 7.3959e-04, 8.6113e-04, 5.1510e-04, 8.7023e-03,
        1.6832e-03, 9.1612e-04, 2.1757e-03, 1.6310e-03, 4.4272e-03, 1.1400e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,072][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.8513e-03, 2.0135e-06, 3.9408e-08, 6.5304e-07, 1.2338e-07, 2.7626e-06,
        3.4325e-04, 1.0817e-03, 2.1062e-04, 1.4900e-02, 1.2741e-03, 6.4944e-03,
        4.8261e-03, 1.8082e-01, 2.7390e-01, 4.2216e-03, 4.8491e-01, 2.3165e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,073][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.6613e-01, 1.9337e-04, 1.9679e-04, 6.1148e-05, 2.7945e-04, 2.8587e-04,
        1.6162e-03, 1.8103e-03, 9.3341e-04, 2.4867e-03, 5.3812e-04, 3.2070e-03,
        1.1188e-03, 3.1345e-03, 6.5251e-03, 1.1373e-03, 8.9336e-03, 1.4092e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,074][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.8530e-01, 1.8528e-04, 1.4268e-04, 6.4801e-05, 1.2958e-04, 1.4268e-04,
        3.6374e-04, 5.0278e-04, 4.7238e-04, 1.1258e-03, 4.0073e-04, 1.8119e-03,
        7.1234e-04, 1.0764e-03, 4.2489e-03, 9.7662e-04, 1.8935e-03, 4.5157e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,076][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3180, 0.0007, 0.0009, 0.0011, 0.0023, 0.0042, 0.0176, 0.0203, 0.0156,
        0.0909, 0.0250, 0.1049, 0.0164, 0.0640, 0.0971, 0.0244, 0.1688, 0.0275],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,080][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0184, 0.0046, 0.0015, 0.0026, 0.0012, 0.0054, 0.0089, 0.0346, 0.0574,
        0.0779, 0.0975, 0.0800, 0.0489, 0.1814, 0.0730, 0.0394, 0.2360, 0.0313],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,081][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:20,082][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1549],
        [   6],
        [7157],
        [  20],
        [ 466],
        [  81],
        [   7],
        [   5],
        [   4],
        [   2],
        [   7],
        [ 178],
        [   3],
        [   3],
        [   3],
        [   2],
        [  12],
        [   2]], device='cuda:0')
[2024-07-24 10:30:20,085][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[915],
        [  7],
        [655],
        [  8],
        [ 53],
        [ 14],
        [  4],
        [  4],
        [  2],
        [  7],
        [  7],
        [ 46],
        [  5],
        [  3],
        [  3],
        [  2],
        [  9],
        [  2]], device='cuda:0')
[2024-07-24 10:30:20,085][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6232],
        [ 6318],
        [ 6947],
        [ 6368],
        [ 7723],
        [ 6828],
        [ 6515],
        [ 6435],
        [31313],
        [30814],
        [30097],
        [33586],
        [30460],
        [21211],
        [21717],
        [25960],
        [26462],
        [25767]], device='cuda:0')
[2024-07-24 10:30:20,086][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18760],
        [24648],
        [50249],
        [50250],
        [50244],
        [50126],
        [50175],
        [49691],
        [50074],
        [50076],
        [50066],
        [49874],
        [49803],
        [50021],
        [49970],
        [49859],
        [49727],
        [49740]], device='cuda:0')
[2024-07-24 10:30:20,087][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14021],
        [13849],
        [10038],
        [13211],
        [ 6385],
        [ 9977],
        [ 5252],
        [ 7229],
        [ 9300],
        [ 4995],
        [ 8441],
        [ 5953],
        [ 6219],
        [ 9951],
        [ 6855],
        [ 5981],
        [ 5651],
        [ 6547]], device='cuda:0')
[2024-07-24 10:30:20,089][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26523],
        [27382],
        [35435],
        [28996],
        [33391],
        [43094],
        [42443],
        [31497],
        [38657],
        [39884],
        [36578],
        [38844],
        [42223],
        [33225],
        [39011],
        [42638],
        [35333],
        [36296]], device='cuda:0')
[2024-07-24 10:30:20,090][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18794],
        [ 9278],
        [14791],
        [16024],
        [17520],
        [30632],
        [23412],
        [40452],
        [38759],
        [34080],
        [34175],
        [25284],
        [27118],
        [25099],
        [26588],
        [27293],
        [22546],
        [22701]], device='cuda:0')
[2024-07-24 10:30:20,092][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 7981],
        [ 8383],
        [16206],
        [11326],
        [22728],
        [26918],
        [21792],
        [16038],
        [25377],
        [23024],
        [24611],
        [28356],
        [34562],
        [15204],
        [25558],
        [27453],
        [25302],
        [27053]], device='cuda:0')
[2024-07-24 10:30:20,093][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 5134],
        [ 5088],
        [ 8821],
        [ 5757],
        [16895],
        [ 9265],
        [ 9416],
        [ 5578],
        [ 5255],
        [ 6051],
        [ 5923],
        [ 8646],
        [17882],
        [ 6189],
        [10173],
        [ 7023],
        [ 9536],
        [ 8294]], device='cuda:0')
[2024-07-24 10:30:20,096][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39286],
        [41781],
        [40772],
        [44158],
        [41799],
        [39453],
        [46102],
        [43327],
        [43542],
        [46253],
        [46719],
        [45404],
        [45304],
        [45191],
        [41853],
        [40108],
        [41422],
        [41534]], device='cuda:0')
[2024-07-24 10:30:20,098][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14391],
        [14515],
        [17486],
        [16129],
        [36221],
        [20353],
        [18629],
        [15753],
        [16258],
        [17063],
        [15652],
        [31786],
        [26309],
        [15199],
        [22481],
        [19399],
        [19953],
        [18590]], device='cuda:0')
[2024-07-24 10:30:20,100][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43149],
        [43411],
        [44041],
        [43275],
        [43281],
        [42898],
        [43548],
        [43253],
        [43274],
        [43304],
        [43327],
        [43079],
        [42942],
        [43264],
        [43535],
        [43664],
        [43412],
        [43374]], device='cuda:0')
[2024-07-24 10:30:20,101][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33627],
        [34970],
        [30837],
        [32630],
        [30205],
        [29398],
        [28980],
        [30245],
        [30102],
        [29836],
        [29371],
        [28161],
        [27543],
        [27984],
        [27158],
        [26962],
        [27729],
        [27552]], device='cuda:0')
[2024-07-24 10:30:20,102][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39154],
        [19243],
        [50113],
        [50189],
        [47507],
        [46961],
        [27975],
        [14554],
        [ 6529],
        [ 4585],
        [ 3876],
        [11988],
        [ 9775],
        [17159],
        [17258],
        [16074],
        [11806],
        [11897]], device='cuda:0')
[2024-07-24 10:30:20,103][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[42848],
        [39068],
        [47843],
        [29567],
        [45941],
        [32096],
        [17247],
        [40858],
        [31266],
        [17908],
        [22997],
        [45795],
        [10621],
        [25773],
        [22147],
        [26176],
        [19925],
        [31153]], device='cuda:0')
[2024-07-24 10:30:20,105][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14321],
        [14376],
        [14675],
        [14442],
        [13399],
        [14057],
        [14192],
        [14154],
        [25182],
        [25300],
        [25423],
        [24372],
        [24850],
        [24280],
        [24389],
        [26579],
        [26558],
        [26441]], device='cuda:0')
[2024-07-24 10:30:20,106][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9519],
        [11992],
        [13997],
        [12559],
        [15125],
        [17362],
        [15739],
        [14883],
        [14737],
        [14649],
        [14483],
        [14965],
        [16404],
        [14885],
        [14722],
        [13722],
        [13169],
        [11562]], device='cuda:0')
[2024-07-24 10:30:20,108][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[20091],
        [20310],
        [24444],
        [20343],
        [21362],
        [20724],
        [23501],
        [20490],
        [20387],
        [21068],
        [20433],
        [21377],
        [21755],
        [20309],
        [20258],
        [20182],
        [20178],
        [20220]], device='cuda:0')
[2024-07-24 10:30:20,109][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[44044],
        [43775],
        [39626],
        [43400],
        [37313],
        [34040],
        [37914],
        [41200],
        [31646],
        [28687],
        [35509],
        [28182],
        [27120],
        [39482],
        [27874],
        [25845],
        [36455],
        [36077]], device='cuda:0')
[2024-07-24 10:30:20,111][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19015],
        [ 6345],
        [ 6297],
        [ 9742],
        [11234],
        [23229],
        [31497],
        [26359],
        [22091],
        [21821],
        [22403],
        [22360],
        [22970],
        [25263],
        [24943],
        [22867],
        [22443],
        [22650]], device='cuda:0')
[2024-07-24 10:30:20,114][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38026],
        [36626],
        [17319],
        [28933],
        [18873],
        [ 9482],
        [15378],
        [29497],
        [21502],
        [26399],
        [20816],
        [19202],
        [12978],
        [28897],
        [17013],
        [16401],
        [17141],
        [16372]], device='cuda:0')
[2024-07-24 10:30:20,116][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15681],
        [15660],
        [13606],
        [15459],
        [15407],
        [15108],
        [15327],
        [15507],
        [15650],
        [15468],
        [15442],
        [14835],
        [17696],
        [15330],
        [14634],
        [15086],
        [15039],
        [14887]], device='cuda:0')
[2024-07-24 10:30:20,117][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3914],
        [ 2655],
        [12429],
        [ 4687],
        [25868],
        [33088],
        [ 8328],
        [18923],
        [21465],
        [25354],
        [24892],
        [33033],
        [28891],
        [37804],
        [28269],
        [25741],
        [35866],
        [35231]], device='cuda:0')
[2024-07-24 10:30:20,118][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8673],
        [ 8662],
        [ 8891],
        [ 8740],
        [24296],
        [ 9760],
        [11328],
        [ 9002],
        [ 8882],
        [ 8157],
        [ 8340],
        [13295],
        [ 9529],
        [ 8584],
        [ 8461],
        [ 8202],
        [ 7929],
        [ 8063]], device='cuda:0')
[2024-07-24 10:30:20,119][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33882],
        [34086],
        [38047],
        [34176],
        [40580],
        [40519],
        [36692],
        [34625],
        [34906],
        [35064],
        [35088],
        [40847],
        [43009],
        [34454],
        [37520],
        [37565],
        [35484],
        [35082]], device='cuda:0')
[2024-07-24 10:30:20,120][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 3066],
        [ 1336],
        [18370],
        [ 2372],
        [29151],
        [21698],
        [36322],
        [22129],
        [23911],
        [17391],
        [16127],
        [23748],
        [25739],
        [11293],
        [26075],
        [26667],
        [22769],
        [22543]], device='cuda:0')
[2024-07-24 10:30:20,122][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5674],
        [13229],
        [19012],
        [25609],
        [26438],
        [29238],
        [26812],
        [36250],
        [36479],
        [41577],
        [39168],
        [34436],
        [38315],
        [38823],
        [37667],
        [38194],
        [39318],
        [38956]], device='cuda:0')
[2024-07-24 10:30:20,123][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24459],
        [28713],
        [20168],
        [24181],
        [ 8527],
        [ 9461],
        [ 9589],
        [ 6708],
        [ 8451],
        [ 7181],
        [ 7879],
        [ 6529],
        [ 6587],
        [ 4682],
        [ 8650],
        [ 9499],
        [ 7220],
        [ 7722]], device='cuda:0')
[2024-07-24 10:30:20,125][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 2793],
        [ 8498],
        [11417],
        [18076],
        [ 6330],
        [15925],
        [25356],
        [ 3662],
        [16898],
        [29876],
        [24728],
        [ 5773],
        [32158],
        [11552],
        [17757],
        [20488],
        [27975],
        [11019]], device='cuda:0')
[2024-07-24 10:30:20,126][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673],
        [13673]], device='cuda:0')
[2024-07-24 10:30:20,170][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:20,173][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,173][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,173][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,174][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,174][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,174][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,175][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,175][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,175][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,177][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,178][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,181][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,193][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9795, 0.0205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,195][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9749, 0.0251], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,198][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9946e-01, 5.3600e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,198][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0539, 0.9461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,198][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7881, 0.2119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,199][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.0000e+00, 3.7928e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,199][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0569, 0.9431], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,199][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8025, 0.1975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,200][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9915, 0.0085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,200][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0089, 0.9911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,200][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4592, 0.5408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,200][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4922, 0.5078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,201][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.8253, 0.0839, 0.0908], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,202][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.1609, 0.1722, 0.6669], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,205][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.9920, 0.0061, 0.0019], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,208][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.0312, 0.5781, 0.3907], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,211][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.0063, 0.9407, 0.0530], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,211][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([9.9793e-01, 9.9750e-05, 1.9668e-03], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,211][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.0154, 0.1870, 0.7976], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,212][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.2136, 0.7112, 0.0752], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,212][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.7191, 0.2169, 0.0640], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,212][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.0049, 0.2611, 0.7339], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,213][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.0088, 0.6574, 0.3338], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,213][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.1404, 0.3136, 0.5461], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,213][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8162, 0.0606, 0.0483, 0.0749], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,214][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6273, 0.0333, 0.2606, 0.0788], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,215][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9315e-01, 4.5260e-03, 8.2843e-04, 1.4919e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,217][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0185, 0.3712, 0.5016, 0.1086], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,220][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2629, 0.3840, 0.2423, 0.1108], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,222][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9943e-01, 2.8348e-05, 3.4189e-04, 1.9928e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,224][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0149, 0.0579, 0.5417, 0.3855], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,224][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4200, 0.3492, 0.0506, 0.1802], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,224][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9380, 0.0338, 0.0131, 0.0151], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,225][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0012, 0.1007, 0.2571, 0.6410], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,225][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0170, 0.4346, 0.4926, 0.0559], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,225][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1457, 0.2112, 0.4137, 0.2294], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,226][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.4763, 0.1215, 0.1325, 0.1768, 0.0929], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,226][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0690, 0.0926, 0.3192, 0.1040, 0.4152], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,226][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.9647, 0.0142, 0.0097, 0.0087, 0.0027], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,227][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0148, 0.4402, 0.3917, 0.1128, 0.0405], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,228][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([7.7438e-04, 8.9563e-01, 1.8674e-02, 7.5314e-02, 9.6117e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,229][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([9.8888e-01, 2.1708e-04, 5.1198e-03, 1.6029e-03, 4.1776e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,231][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0060, 0.0502, 0.3371, 0.2321, 0.3747], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,235][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0729, 0.3681, 0.0789, 0.4308, 0.0493], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,237][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.3590, 0.2311, 0.1651, 0.1566, 0.0882], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,237][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0012, 0.0856, 0.1574, 0.4231, 0.3327], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,238][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0019, 0.5428, 0.3639, 0.0408, 0.0507], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,238][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0405, 0.1495, 0.2946, 0.2571, 0.2583], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,238][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.4321, 0.1481, 0.0720, 0.1104, 0.0538, 0.1836], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,238][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1529, 0.0226, 0.2642, 0.0473, 0.2911, 0.2219], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,239][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.9139, 0.0460, 0.0044, 0.0085, 0.0013, 0.0259], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,239][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0141, 0.3814, 0.4144, 0.1005, 0.0462, 0.0433], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,239][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0010, 0.8480, 0.0201, 0.0965, 0.0074, 0.0270], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,240][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ were] are: tensor([9.9600e-01, 8.7354e-05, 1.1849e-03, 3.8451e-04, 1.1025e-03, 1.2421e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,241][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0026, 0.0188, 0.2313, 0.1221, 0.2574, 0.3678], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,244][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1794, 0.3450, 0.0308, 0.1618, 0.0219, 0.2610], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,247][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.8342, 0.0627, 0.0259, 0.0220, 0.0175, 0.0376], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,249][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ were] are: tensor([2.4044e-04, 4.8234e-02, 1.4966e-01, 2.6366e-01, 2.5621e-01, 2.8200e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,250][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0027, 0.4088, 0.4483, 0.0405, 0.0680, 0.0317], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,250][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0482, 0.0826, 0.1892, 0.1206, 0.2552, 0.3042], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,251][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.2875, 0.1047, 0.0778, 0.0910, 0.0612, 0.1529, 0.2249],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,251][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.1041, 0.0227, 0.2170, 0.0519, 0.2959, 0.1827, 0.1257],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,251][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.9328, 0.0156, 0.0039, 0.0075, 0.0015, 0.0124, 0.0263],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,252][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0117, 0.4422, 0.3189, 0.1079, 0.0422, 0.0491, 0.0280],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,252][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0084, 0.7463, 0.0591, 0.1013, 0.0125, 0.0268, 0.0455],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,252][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ working] are: tensor([9.9627e-01, 2.8506e-05, 4.7170e-04, 1.7813e-04, 4.7530e-04, 3.8126e-04,
        2.1988e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,253][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0012, 0.0156, 0.1881, 0.0959, 0.2317, 0.1974, 0.2700],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,254][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.1435, 0.1676, 0.0129, 0.0586, 0.0087, 0.1318, 0.4769],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,256][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.7210, 0.0836, 0.0499, 0.0368, 0.0224, 0.0639, 0.0224],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,258][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ working] are: tensor([2.2085e-04, 3.5414e-02, 9.7783e-02, 2.7911e-01, 2.3081e-01, 2.5323e-01,
        1.0344e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,262][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0024, 0.5761, 0.2289, 0.0433, 0.0574, 0.0385, 0.0535],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,263][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0611, 0.0898, 0.1017, 0.1660, 0.2010, 0.1785, 0.2018],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,263][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2643, 0.0803, 0.0672, 0.0741, 0.0501, 0.1015, 0.1726, 0.1899],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,263][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.2065, 0.0103, 0.1358, 0.0204, 0.1678, 0.0957, 0.0448, 0.3187],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,264][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([9.8335e-01, 1.8107e-03, 6.2326e-04, 5.6061e-04, 2.3549e-04, 1.6731e-03,
        4.2420e-03, 7.5092e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,264][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0135, 0.3571, 0.3926, 0.1045, 0.0374, 0.0501, 0.0390, 0.0059],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,264][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0361, 0.5759, 0.1429, 0.0754, 0.0396, 0.0610, 0.0320, 0.0372],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,265][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([9.9723e-01, 1.9390e-05, 2.8640e-04, 1.0471e-04, 3.0035e-04, 2.3439e-04,
        9.2712e-04, 8.9856e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,265][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0024, 0.0130, 0.1338, 0.0685, 0.1405, 0.1395, 0.2432, 0.2591],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,265][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2311, 0.1291, 0.0073, 0.0260, 0.0046, 0.0522, 0.1796, 0.3702],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,267][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.7671, 0.0492, 0.0435, 0.0161, 0.0197, 0.0452, 0.0135, 0.0457],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,269][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0003, 0.0362, 0.1102, 0.2105, 0.1924, 0.1691, 0.0914, 0.1899],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,273][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0050, 0.5400, 0.2180, 0.0500, 0.0597, 0.0453, 0.0693, 0.0127],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,276][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0326, 0.0840, 0.1493, 0.1023, 0.2072, 0.1771, 0.1644, 0.0832],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,276][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3847, 0.0686, 0.0423, 0.0578, 0.0294, 0.0739, 0.1180, 0.1429, 0.0823],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,276][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.3831, 0.0045, 0.0698, 0.0131, 0.1120, 0.0521, 0.0293, 0.2545, 0.0816],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,277][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([9.8079e-01, 2.6458e-03, 4.7469e-04, 5.8261e-04, 1.4713e-04, 9.1806e-04,
        2.7124e-03, 8.8568e-03, 2.8678e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,277][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0138, 0.3708, 0.3472, 0.1045, 0.0400, 0.0499, 0.0383, 0.0148, 0.0208],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,277][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0369, 0.5153, 0.1393, 0.1090, 0.0196, 0.0644, 0.0436, 0.0613, 0.0107],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,278][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.9926e-01, 5.1525e-06, 6.2928e-05, 2.8758e-05, 5.8714e-05, 4.7914e-05,
        2.4126e-04, 1.9934e-04, 9.7622e-05], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,278][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0019, 0.0107, 0.0902, 0.0638, 0.1075, 0.1230, 0.2164, 0.2439, 0.1427],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,278][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2143, 0.1084, 0.0045, 0.0263, 0.0028, 0.0397, 0.1071, 0.2648, 0.2322],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,280][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8821, 0.0255, 0.0164, 0.0091, 0.0072, 0.0126, 0.0049, 0.0341, 0.0081],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,282][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.2840e-04, 2.2639e-02, 4.6751e-02, 1.4860e-01, 9.2336e-02, 1.3376e-01,
        6.6411e-02, 1.7340e-01, 3.1587e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,284][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0042, 0.4952, 0.2306, 0.0546, 0.0557, 0.0509, 0.0690, 0.0190, 0.0208],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,288][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0377, 0.0993, 0.1258, 0.0946, 0.1509, 0.1374, 0.1710, 0.0833, 0.1000],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,289][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.4829, 0.0319, 0.0237, 0.0417, 0.0191, 0.0478, 0.0929, 0.0921, 0.0639,
        0.1040], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,289][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0633, 0.0087, 0.1029, 0.0116, 0.1488, 0.0489, 0.0459, 0.3199, 0.0812,
        0.1689], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,289][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ station] are: tensor([9.7259e-01, 2.0595e-03, 5.8037e-04, 6.5614e-04, 2.4314e-04, 1.2672e-03,
        2.8939e-03, 1.0217e-02, 3.5817e-03, 5.9093e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,290][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0232, 0.3275, 0.2575, 0.0864, 0.0447, 0.0410, 0.0423, 0.0176, 0.0355,
        0.1242], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,290][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0073, 0.6656, 0.0544, 0.0891, 0.0218, 0.0241, 0.0390, 0.0762, 0.0172,
        0.0052], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,290][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ station] are: tensor([9.9642e-01, 1.5768e-05, 1.6029e-04, 6.7475e-05, 1.4159e-04, 1.4795e-04,
        5.7439e-04, 6.5104e-04, 2.5040e-04, 1.5663e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,291][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0029, 0.0102, 0.0457, 0.0531, 0.0813, 0.1020, 0.1729, 0.1864, 0.1524,
        0.1930], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,291][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1181, 0.0391, 0.0011, 0.0049, 0.0008, 0.0131, 0.0452, 0.1101, 0.1249,
        0.5427], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,292][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.8860, 0.0209, 0.0069, 0.0110, 0.0050, 0.0104, 0.0069, 0.0367, 0.0034,
        0.0128], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,293][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ station] are: tensor([2.3890e-04, 2.1055e-02, 3.5688e-02, 1.4120e-01, 7.1249e-02, 1.1025e-01,
        6.4877e-02, 1.6185e-01, 2.6107e-01, 1.3254e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,296][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0098, 0.3326, 0.2750, 0.0407, 0.0737, 0.0342, 0.0816, 0.0200, 0.0254,
        0.1071], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,299][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0665, 0.0572, 0.1096, 0.0491, 0.1588, 0.0770, 0.1110, 0.0585, 0.0736,
        0.2387], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,302][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4975, 0.0371, 0.0260, 0.0290, 0.0205, 0.0525, 0.0619, 0.0756, 0.0549,
        0.0871, 0.0578], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,302][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.2700, 0.0064, 0.0773, 0.0107, 0.1404, 0.0574, 0.0379, 0.2054, 0.0768,
        0.1014, 0.0163], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,302][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([9.8728e-01, 1.8344e-03, 2.8172e-04, 2.7593e-04, 1.2431e-04, 7.6202e-04,
        1.4416e-03, 3.5989e-03, 1.4957e-03, 2.3762e-03, 5.3058e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,303][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0176, 0.3063, 0.2543, 0.0827, 0.0361, 0.0409, 0.0400, 0.0107, 0.0252,
        0.1470, 0.0393], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,303][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0344, 0.4530, 0.1330, 0.0746, 0.0271, 0.0785, 0.0670, 0.0473, 0.0237,
        0.0094, 0.0521], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,303][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([9.9844e-01, 6.0672e-06, 1.3663e-04, 3.3303e-05, 1.1578e-04, 7.5834e-05,
        2.5041e-04, 2.2431e-04, 1.1243e-04, 5.7237e-04, 3.0094e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,304][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0037, 0.0082, 0.1212, 0.0396, 0.1102, 0.0834, 0.1522, 0.1174, 0.1063,
        0.1804, 0.0773], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,304][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1198, 0.0454, 0.0028, 0.0057, 0.0016, 0.0144, 0.0454, 0.0795, 0.0989,
        0.5011, 0.0854], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,304][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.9378, 0.0161, 0.0099, 0.0045, 0.0052, 0.0050, 0.0017, 0.0076, 0.0023,
        0.0048, 0.0050], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,305][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.7514e-04, 1.6624e-02, 4.1336e-02, 8.9607e-02, 6.1088e-02, 6.8762e-02,
        3.2461e-02, 9.4797e-02, 1.9772e-01, 1.1060e-01, 2.8682e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,308][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0151, 0.4080, 0.1215, 0.0337, 0.0445, 0.0396, 0.0730, 0.0205, 0.0329,
        0.1059, 0.1053], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,310][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0268, 0.0621, 0.0935, 0.0480, 0.1847, 0.0912, 0.1314, 0.0444, 0.0984,
        0.1517, 0.0679], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,314][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.2925, 0.0364, 0.0294, 0.0401, 0.0214, 0.0600, 0.1012, 0.1046, 0.0679,
        0.1067, 0.0696, 0.0702], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,315][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0295, 0.0056, 0.0323, 0.0061, 0.0527, 0.0377, 0.0277, 0.1549, 0.0781,
        0.2063, 0.0132, 0.3559], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,315][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([9.5610e-01, 2.1031e-03, 4.5100e-04, 5.2337e-04, 1.8075e-04, 1.7876e-03,
        7.3757e-03, 1.5495e-02, 4.1807e-03, 8.8137e-03, 1.4780e-03, 1.5114e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,315][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0163, 0.3450, 0.2016, 0.0776, 0.0265, 0.0340, 0.0296, 0.0142, 0.0238,
        0.1255, 0.0445, 0.0613], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,316][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0033, 0.6789, 0.0404, 0.0454, 0.0069, 0.0245, 0.0304, 0.0703, 0.0224,
        0.0088, 0.0639, 0.0048], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,316][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([9.9110e-01, 1.8896e-05, 3.1217e-04, 1.2444e-04, 2.7212e-04, 2.3668e-04,
        1.4366e-03, 1.0537e-03, 4.3489e-04, 3.0593e-03, 1.6079e-04, 1.7925e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,316][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0028, 0.0085, 0.0532, 0.0332, 0.0576, 0.0872, 0.1050, 0.1135, 0.1076,
        0.1824, 0.0879, 0.1611], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,317][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([2.0414e-02, 1.5339e-02, 6.3250e-04, 3.8572e-03, 3.5647e-04, 6.4329e-03,
        2.5708e-02, 6.1917e-02, 5.6899e-02, 6.8010e-01, 7.0247e-02, 5.8092e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,317][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.5257, 0.0654, 0.0525, 0.0235, 0.0262, 0.0379, 0.0241, 0.0682, 0.0253,
        0.0448, 0.0433, 0.0632], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,318][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([1.3360e-04, 1.2124e-02, 1.5642e-02, 6.2808e-02, 3.1806e-02, 5.7800e-02,
        2.8148e-02, 6.1737e-02, 1.5470e-01, 8.3418e-02, 1.7168e-01, 3.2001e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,320][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0080, 0.2931, 0.2251, 0.0349, 0.0439, 0.0313, 0.0494, 0.0148, 0.0228,
        0.0832, 0.0931, 0.1006], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,323][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0129, 0.0452, 0.0850, 0.0591, 0.0837, 0.0728, 0.0903, 0.0559, 0.0600,
        0.2246, 0.0872, 0.1234], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,327][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.3576, 0.0365, 0.0223, 0.0304, 0.0201, 0.0522, 0.0666, 0.0724, 0.0597,
        0.0841, 0.0675, 0.0553, 0.0753], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,328][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.1143, 0.0039, 0.0738, 0.0058, 0.0924, 0.0504, 0.0366, 0.1531, 0.0456,
        0.0546, 0.0126, 0.3035, 0.0534], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,328][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([9.4352e-01, 5.2045e-03, 5.8756e-04, 8.5150e-04, 2.3233e-04, 2.3206e-03,
        3.5596e-03, 1.9016e-02, 9.0939e-03, 7.1896e-03, 2.4765e-03, 1.9109e-03,
        4.0387e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,328][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0213, 0.3473, 0.0900, 0.0862, 0.0292, 0.0454, 0.0247, 0.0214, 0.0318,
        0.0965, 0.0466, 0.0695, 0.0901], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,329][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([4.8441e-04, 9.0072e-01, 7.8937e-03, 3.3488e-02, 1.0776e-03, 6.1279e-03,
        1.0621e-02, 1.5434e-02, 9.9541e-03, 1.2873e-03, 1.1001e-02, 8.6371e-04,
        1.0464e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,329][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([9.9688e-01, 8.1305e-06, 7.4902e-05, 3.9010e-05, 1.0651e-04, 8.2694e-05,
        3.5738e-04, 2.7004e-04, 1.4215e-04, 9.2072e-04, 4.2603e-05, 5.8562e-04,
        4.9363e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,329][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0031, 0.0063, 0.0590, 0.0303, 0.0701, 0.0692, 0.1217, 0.1034, 0.0765,
        0.1144, 0.0602, 0.1607, 0.1252], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,330][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0285, 0.0144, 0.0009, 0.0035, 0.0007, 0.0084, 0.0457, 0.0995, 0.0746,
        0.4740, 0.0723, 0.1071, 0.0704], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,330][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.8897, 0.0221, 0.0096, 0.0038, 0.0057, 0.0089, 0.0032, 0.0151, 0.0035,
        0.0076, 0.0108, 0.0048, 0.0153], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,331][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([9.6544e-05, 1.0034e-02, 1.5943e-02, 5.2185e-02, 3.1347e-02, 3.7648e-02,
        1.9465e-02, 7.1923e-02, 1.1008e-01, 5.3322e-02, 1.9411e-01, 3.2616e-01,
        7.7685e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,333][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0143, 0.3022, 0.1251, 0.0320, 0.0457, 0.0280, 0.0419, 0.0163, 0.0235,
        0.0637, 0.0826, 0.0921, 0.1325], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,336][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0278, 0.0264, 0.0373, 0.0418, 0.1131, 0.0645, 0.0750, 0.0420, 0.0504,
        0.1317, 0.0486, 0.1662, 0.1753], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,340][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4085, 0.0326, 0.0237, 0.0274, 0.0174, 0.0422, 0.0589, 0.0668, 0.0432,
        0.0757, 0.0464, 0.0432, 0.0567, 0.0574], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,341][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3124, 0.0040, 0.0502, 0.0084, 0.0766, 0.0348, 0.0272, 0.0753, 0.0362,
        0.0469, 0.0081, 0.1985, 0.0511, 0.0704], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,341][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.8751e-01, 1.3336e-03, 2.2863e-04, 2.5083e-04, 7.2600e-05, 5.5506e-04,
        9.9704e-04, 2.7371e-03, 1.2426e-03, 1.8559e-03, 3.4115e-04, 3.2372e-04,
        7.0339e-04, 1.8519e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,341][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0197, 0.2812, 0.1976, 0.0769, 0.0251, 0.0307, 0.0261, 0.0078, 0.0180,
        0.1023, 0.0292, 0.0599, 0.1151, 0.0104], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,342][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0301, 0.5514, 0.0593, 0.0723, 0.0193, 0.0258, 0.0320, 0.0607, 0.0302,
        0.0134, 0.0475, 0.0131, 0.0097, 0.0352], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,342][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9799e-01, 4.8838e-06, 8.7818e-05, 2.5244e-05, 8.2488e-05, 3.7340e-05,
        1.7861e-04, 1.7045e-04, 8.5545e-05, 5.6524e-04, 1.8949e-05, 3.5553e-04,
        2.0637e-04, 1.9648e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,342][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0027, 0.0067, 0.0465, 0.0292, 0.0573, 0.0597, 0.1205, 0.0689, 0.0708,
        0.0885, 0.0558, 0.1250, 0.1447, 0.1237], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,343][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1937, 0.0288, 0.0013, 0.0037, 0.0009, 0.0098, 0.0320, 0.0590, 0.0631,
        0.3000, 0.0714, 0.0605, 0.0588, 0.1172], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,343][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.9381, 0.0108, 0.0064, 0.0031, 0.0033, 0.0049, 0.0017, 0.0054, 0.0017,
        0.0042, 0.0041, 0.0028, 0.0045, 0.0090], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,344][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.4624e-04, 1.1911e-02, 1.6337e-02, 5.6253e-02, 2.7759e-02, 3.8353e-02,
        2.4480e-02, 4.3195e-02, 1.0827e-01, 3.6195e-02, 1.8067e-01, 2.0821e-01,
        7.2355e-02, 1.7587e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,346][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0054, 0.2863, 0.1444, 0.0373, 0.0524, 0.0385, 0.0565, 0.0122, 0.0202,
        0.0812, 0.0518, 0.0731, 0.1176, 0.0233], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,349][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0223, 0.0392, 0.0461, 0.0380, 0.0831, 0.0646, 0.0719, 0.0364, 0.0721,
        0.1272, 0.0471, 0.1377, 0.1475, 0.0668], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,353][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2730, 0.0330, 0.0288, 0.0292, 0.0194, 0.0489, 0.0588, 0.0748, 0.0479,
        0.0821, 0.0465, 0.0497, 0.0604, 0.0668, 0.0807], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,353][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.1850, 0.0032, 0.0799, 0.0086, 0.0857, 0.0377, 0.0205, 0.1288, 0.0371,
        0.0434, 0.0100, 0.2000, 0.0320, 0.0683, 0.0597], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,354][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([9.8455e-01, 1.3074e-03, 1.8682e-04, 1.7685e-04, 5.0468e-05, 3.7289e-04,
        9.4301e-04, 2.8606e-03, 1.2166e-03, 2.3186e-03, 3.2890e-04, 3.0702e-04,
        6.9277e-04, 2.0835e-03, 2.6036e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,354][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0164, 0.3421, 0.1458, 0.0833, 0.0234, 0.0344, 0.0234, 0.0110, 0.0206,
        0.0889, 0.0364, 0.0558, 0.0933, 0.0119, 0.0131], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,355][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0029, 0.8504, 0.0149, 0.0463, 0.0021, 0.0077, 0.0170, 0.0164, 0.0100,
        0.0022, 0.0164, 0.0020, 0.0019, 0.0089, 0.0009], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,355][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([9.9322e-01, 1.0631e-05, 1.6319e-04, 6.4327e-05, 1.8122e-04, 1.3543e-04,
        5.9631e-04, 5.7802e-04, 2.8283e-04, 1.5528e-03, 8.0410e-05, 8.8132e-04,
        6.3521e-04, 4.5312e-04, 1.1696e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,355][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0014, 0.0069, 0.0613, 0.0262, 0.0746, 0.0552, 0.0705, 0.0732, 0.0675,
        0.0785, 0.0526, 0.1532, 0.0889, 0.0940, 0.0962], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,356][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0847, 0.0203, 0.0011, 0.0032, 0.0006, 0.0076, 0.0273, 0.0664, 0.0479,
        0.3512, 0.0544, 0.0586, 0.0522, 0.1155, 0.1090], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,356][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.7500, 0.0319, 0.0237, 0.0074, 0.0126, 0.0198, 0.0032, 0.0223, 0.0125,
        0.0124, 0.0186, 0.0116, 0.0130, 0.0380, 0.0231], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,357][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.9715e-04, 1.1665e-02, 2.0023e-02, 5.1129e-02, 3.8516e-02, 4.3523e-02,
        1.9328e-02, 5.4202e-02, 8.5408e-02, 3.7202e-02, 1.3887e-01, 2.6918e-01,
        5.5094e-02, 1.3819e-01, 3.7477e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,359][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0062, 0.3579, 0.1063, 0.0296, 0.0403, 0.0243, 0.0382, 0.0097, 0.0166,
        0.0615, 0.0612, 0.0745, 0.1019, 0.0292, 0.0425], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,362][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0151, 0.0266, 0.0422, 0.0327, 0.0801, 0.0544, 0.0817, 0.0336, 0.0480,
        0.1465, 0.0472, 0.1337, 0.1169, 0.0447, 0.0965], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,366][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3659, 0.0294, 0.0174, 0.0216, 0.0131, 0.0342, 0.0540, 0.0589, 0.0380,
        0.0739, 0.0394, 0.0386, 0.0547, 0.0538, 0.0673, 0.0398],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,366][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1127, 0.0025, 0.0350, 0.0041, 0.0890, 0.0277, 0.0182, 0.0734, 0.0222,
        0.0337, 0.0065, 0.3867, 0.0300, 0.0561, 0.0615, 0.0406],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,367][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.7076e-01, 1.6400e-03, 2.8825e-04, 3.2043e-04, 1.0926e-04, 8.0689e-04,
        1.6912e-03, 5.9733e-03, 1.9380e-03, 3.7203e-03, 4.7770e-04, 7.8849e-04,
        1.6200e-03, 3.5051e-03, 4.7613e-03, 1.5973e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,367][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0210, 0.3254, 0.1843, 0.0879, 0.0197, 0.0264, 0.0198, 0.0085, 0.0143,
        0.0815, 0.0307, 0.0532, 0.0920, 0.0122, 0.0177, 0.0053],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,368][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0069, 0.6549, 0.0381, 0.0882, 0.0047, 0.0200, 0.0467, 0.0386, 0.0295,
        0.0065, 0.0278, 0.0035, 0.0049, 0.0232, 0.0037, 0.0026],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,368][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9371e-01, 1.0321e-05, 1.7436e-04, 6.3503e-05, 1.7509e-04, 9.5659e-05,
        4.5639e-04, 5.4774e-04, 2.3065e-04, 1.3670e-03, 5.8137e-05, 7.9555e-04,
        6.0268e-04, 4.1691e-04, 8.5218e-04, 4.4758e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,368][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0010, 0.0052, 0.0467, 0.0289, 0.0556, 0.0517, 0.0537, 0.0565, 0.0586,
        0.0868, 0.0552, 0.1469, 0.0830, 0.0942, 0.0986, 0.0773],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,369][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0560, 0.0214, 0.0013, 0.0044, 0.0009, 0.0095, 0.0280, 0.0485, 0.0532,
        0.3848, 0.0554, 0.0626, 0.0510, 0.0996, 0.0932, 0.0303],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,369][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8215, 0.0208, 0.0112, 0.0091, 0.0062, 0.0130, 0.0035, 0.0233, 0.0038,
        0.0104, 0.0108, 0.0062, 0.0137, 0.0258, 0.0189, 0.0016],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,370][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.1056e-04, 7.2963e-03, 1.8370e-02, 5.0813e-02, 2.7489e-02, 3.1102e-02,
        1.8275e-02, 3.5863e-02, 6.2541e-02, 3.8406e-02, 1.1525e-01, 2.2777e-01,
        5.1323e-02, 1.1114e-01, 3.8410e-02, 1.6584e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,372][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0038, 0.2782, 0.1714, 0.0402, 0.0447, 0.0316, 0.0419, 0.0139, 0.0150,
        0.0660, 0.0554, 0.0675, 0.0961, 0.0242, 0.0364, 0.0137],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,375][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0124, 0.0368, 0.0410, 0.0271, 0.0595, 0.0461, 0.0710, 0.0347, 0.0382,
        0.1555, 0.0517, 0.1112, 0.1555, 0.0473, 0.0724, 0.0396],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,379][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.3831, 0.0198, 0.0173, 0.0213, 0.0123, 0.0244, 0.0505, 0.0554, 0.0283,
        0.0605, 0.0297, 0.0366, 0.0414, 0.0472, 0.0677, 0.0354, 0.0692],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,379][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0646, 0.0018, 0.0348, 0.0040, 0.0649, 0.0257, 0.0179, 0.0689, 0.0178,
        0.0474, 0.0048, 0.3296, 0.0435, 0.0630, 0.0779, 0.0533, 0.0803],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,380][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([9.7257e-01, 1.4340e-03, 2.7883e-04, 2.4508e-04, 1.0672e-04, 6.1387e-04,
        1.5924e-03, 4.2166e-03, 1.2938e-03, 3.2282e-03, 3.1427e-04, 6.6762e-04,
        1.1819e-03, 2.9146e-03, 3.3072e-03, 1.2315e-03, 4.8057e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,380][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0219, 0.3007, 0.1624, 0.0799, 0.0256, 0.0324, 0.0167, 0.0124, 0.0210,
        0.0841, 0.0290, 0.0589, 0.0841, 0.0142, 0.0169, 0.0082, 0.0315],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,381][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0069, 0.6700, 0.0208, 0.0574, 0.0069, 0.0200, 0.0433, 0.0638, 0.0192,
        0.0057, 0.0414, 0.0056, 0.0050, 0.0233, 0.0032, 0.0023, 0.0053],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,381][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([9.9458e-01, 5.0516e-06, 7.2024e-05, 3.6767e-05, 6.9903e-05, 4.7196e-05,
        2.2137e-04, 2.4065e-04, 1.0193e-04, 6.7111e-04, 2.7479e-05, 3.2335e-04,
        2.4693e-04, 2.1467e-04, 5.0451e-04, 2.1982e-04, 2.4165e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,381][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0018, 0.0036, 0.0337, 0.0187, 0.0438, 0.0416, 0.0543, 0.0377, 0.0367,
        0.0624, 0.0429, 0.1231, 0.0833, 0.0828, 0.1140, 0.0579, 0.1616],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,382][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0653, 0.0106, 0.0005, 0.0019, 0.0003, 0.0047, 0.0251, 0.0519, 0.0352,
        0.2865, 0.0416, 0.0414, 0.0354, 0.0931, 0.1151, 0.0319, 0.1596],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,382][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.8764, 0.0138, 0.0071, 0.0046, 0.0032, 0.0071, 0.0026, 0.0102, 0.0032,
        0.0093, 0.0074, 0.0041, 0.0064, 0.0192, 0.0132, 0.0018, 0.0104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,384][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0002, 0.0065, 0.0094, 0.0291, 0.0169, 0.0260, 0.0155, 0.0293, 0.0511,
        0.0295, 0.0672, 0.1672, 0.0450, 0.0972, 0.0441, 0.1641, 0.2018],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,387][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0050, 0.3138, 0.1254, 0.0345, 0.0407, 0.0202, 0.0349, 0.0141, 0.0192,
        0.0465, 0.0564, 0.0649, 0.0806, 0.0252, 0.0407, 0.0198, 0.0580],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,390][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0096, 0.0207, 0.0296, 0.0218, 0.0640, 0.0423, 0.0671, 0.0252, 0.0384,
        0.0815, 0.0368, 0.0924, 0.1441, 0.0290, 0.0762, 0.0484, 0.1727],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,394][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4232, 0.0182, 0.0164, 0.0177, 0.0126, 0.0281, 0.0457, 0.0429, 0.0290,
        0.0580, 0.0291, 0.0322, 0.0379, 0.0402, 0.0533, 0.0321, 0.0514, 0.0319],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,394][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1179, 0.0024, 0.0408, 0.0050, 0.0628, 0.0247, 0.0197, 0.0641, 0.0240,
        0.0333, 0.0065, 0.2455, 0.0303, 0.0615, 0.0601, 0.0604, 0.0600, 0.0809],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,395][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.7921e-01, 9.0149e-04, 1.9816e-04, 1.9790e-04, 7.2490e-05, 4.6074e-04,
        1.0922e-03, 2.6059e-03, 1.0941e-03, 2.4096e-03, 2.2783e-04, 3.9396e-04,
        7.9649e-04, 2.1717e-03, 3.0194e-03, 1.0127e-03, 3.1300e-03, 1.0043e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,395][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0161, 0.3232, 0.2031, 0.0840, 0.0177, 0.0245, 0.0193, 0.0054, 0.0124,
        0.0824, 0.0236, 0.0397, 0.0800, 0.0063, 0.0110, 0.0040, 0.0433, 0.0039],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,396][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0149, 0.6265, 0.0440, 0.0673, 0.0106, 0.0243, 0.0448, 0.0439, 0.0184,
        0.0082, 0.0336, 0.0056, 0.0062, 0.0225, 0.0049, 0.0041, 0.0069, 0.0131],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,396][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9246e-01, 5.4667e-06, 1.1724e-04, 3.3642e-05, 1.0047e-04, 5.5655e-05,
        2.7350e-04, 2.5420e-04, 1.1288e-04, 7.9296e-04, 2.1795e-05, 4.5901e-04,
        2.8919e-04, 2.8908e-04, 5.9294e-04, 2.2301e-04, 3.6164e-03, 2.9896e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,396][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0015, 0.0050, 0.0349, 0.0227, 0.0455, 0.0448, 0.0612, 0.0364, 0.0478,
        0.0494, 0.0407, 0.0932, 0.0794, 0.0753, 0.0875, 0.0672, 0.1402, 0.0673],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,398][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0769, 0.0116, 0.0009, 0.0025, 0.0007, 0.0067, 0.0247, 0.0389, 0.0406,
        0.2806, 0.0463, 0.0536, 0.0438, 0.0828, 0.0802, 0.0275, 0.1365, 0.0452],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,400][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.8479, 0.0169, 0.0085, 0.0061, 0.0055, 0.0093, 0.0036, 0.0113, 0.0031,
        0.0090, 0.0075, 0.0048, 0.0104, 0.0211, 0.0152, 0.0016, 0.0120, 0.0060],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,402][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.1072e-04, 7.0743e-03, 1.0862e-02, 3.0053e-02, 1.7216e-02, 2.3539e-02,
        1.3424e-02, 2.2298e-02, 5.7847e-02, 1.7953e-02, 7.3615e-02, 1.3334e-01,
        3.5810e-02, 8.2021e-02, 3.0769e-02, 1.6083e-01, 1.8172e-01, 1.0151e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,405][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0049, 0.2364, 0.1385, 0.0346, 0.0445, 0.0356, 0.0536, 0.0107, 0.0177,
        0.0684, 0.0479, 0.0611, 0.0934, 0.0181, 0.0327, 0.0144, 0.0612, 0.0263],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,407][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0128, 0.0262, 0.0263, 0.0244, 0.0510, 0.0411, 0.0402, 0.0224, 0.0474,
        0.0736, 0.0356, 0.0870, 0.0918, 0.0424, 0.0864, 0.0544, 0.1873, 0.0498],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,451][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:20,453][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,455][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,458][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,459][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,460][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,460][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,460][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,461][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,461][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,461][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,462][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,463][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,465][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9981e-01, 1.8698e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,467][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9749, 0.0251], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,469][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9946e-01, 5.3600e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,471][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.9998e-01, 1.6167e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,472][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9979, 0.0021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,472][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9997e-01, 3.3610e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,473][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0461, 0.9539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,473][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9330, 0.0670], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,473][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9915, 0.0085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,474][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0342, 0.9658], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,474][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7858, 0.2142], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,474][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5260, 0.4740], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,474][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.9967, 0.0015, 0.0018], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,476][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.1609, 0.1722, 0.6669], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,478][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.9920, 0.0061, 0.0019], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,480][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([9.4588e-01, 5.3477e-02, 6.4497e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,483][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.8335, 0.0448, 0.1217], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,485][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.9948, 0.0010, 0.0042], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,485][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.0071, 0.6270, 0.3658], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,485][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.0686, 0.9068, 0.0246], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,486][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.7191, 0.2169, 0.0640], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,486][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.0014, 0.1227, 0.8759], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,486][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.0048, 0.9886, 0.0067], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,487][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.0688, 0.7708, 0.1604], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,487][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9869e-01, 6.0239e-04, 3.3279e-04, 3.7548e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,488][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6273, 0.0333, 0.2606, 0.0788], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,490][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9315e-01, 4.5260e-03, 8.2843e-04, 1.4919e-03], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,491][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.9908e-01, 8.0278e-04, 5.0226e-06, 1.1069e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,494][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9892, 0.0022, 0.0062, 0.0024], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,497][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9911e-01, 1.5987e-04, 4.3228e-04, 2.9502e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,497][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0104, 0.1427, 0.2719, 0.5751], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,497][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4514, 0.4216, 0.0190, 0.1079], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,498][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9380, 0.0338, 0.0131, 0.0151], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,498][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0018, 0.0550, 0.4366, 0.5066], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,498][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1071, 0.7436, 0.0027, 0.1467], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,499][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2051, 0.4706, 0.1571, 0.1672], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,499][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.9752, 0.0061, 0.0090, 0.0073, 0.0024], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,499][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0690, 0.0926, 0.3192, 0.1040, 0.4152], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,500][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.9647, 0.0142, 0.0097, 0.0087, 0.0027], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,500][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.6295, 0.1445, 0.0015, 0.2212, 0.0033], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,501][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.5843, 0.0520, 0.1638, 0.0427, 0.1573], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,504][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.9657, 0.0027, 0.0109, 0.0064, 0.0142], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,507][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0013, 0.2007, 0.2251, 0.4887, 0.0842], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,510][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0188, 0.4751, 0.0349, 0.4544, 0.0168], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,510][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.3590, 0.2311, 0.1651, 0.1566, 0.0882], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,511][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([2.3094e-04, 6.2375e-02, 2.6868e-01, 4.8140e-01, 1.8732e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,511][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0011, 0.4941, 0.0024, 0.5001, 0.0022], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,511][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0180, 0.5843, 0.0942, 0.1117, 0.1918], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,512][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([9.7745e-01, 1.0310e-02, 2.0904e-03, 2.3093e-03, 6.5873e-04, 7.1796e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,512][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.1529, 0.0226, 0.2642, 0.0473, 0.2911, 0.2219], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,512][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.9139, 0.0460, 0.0044, 0.0085, 0.0013, 0.0259], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,513][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([9.9015e-01, 5.4432e-03, 1.7506e-05, 4.6596e-04, 5.0730e-05, 3.8699e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,513][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.7349, 0.0355, 0.0816, 0.0337, 0.0568, 0.0575], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,514][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([9.9100e-01, 7.1717e-04, 1.2896e-03, 8.3871e-04, 1.8554e-03, 4.2951e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,514][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0006, 0.0938, 0.1241, 0.2938, 0.0421, 0.4455], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,516][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1454, 0.4494, 0.0118, 0.1144, 0.0068, 0.2722], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,518][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.8342, 0.0627, 0.0259, 0.0220, 0.0175, 0.0376], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,520][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([1.2461e-04, 4.5851e-02, 1.9349e-01, 2.7500e-01, 1.1552e-01, 3.7001e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,524][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0228, 0.4559, 0.0013, 0.0728, 0.0013, 0.4460], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,524][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.2048, 0.3146, 0.1203, 0.0849, 0.1413, 0.1340], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,524][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.9573, 0.0066, 0.0037, 0.0022, 0.0013, 0.0066, 0.0224],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,525][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.1041, 0.0227, 0.2170, 0.0519, 0.2959, 0.1827, 0.1257],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,525][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.9328, 0.0156, 0.0039, 0.0075, 0.0015, 0.0124, 0.0263],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,525][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([9.8688e-01, 8.2327e-04, 8.6165e-07, 5.3797e-05, 2.0529e-06, 5.5641e-04,
        1.1687e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,526][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.6491, 0.0437, 0.1189, 0.0391, 0.0702, 0.0419, 0.0372],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,526][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([9.8507e-01, 5.3589e-04, 1.2799e-03, 8.5954e-04, 1.9298e-03, 3.3797e-03,
        6.9417e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,526][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0004, 0.0780, 0.1564, 0.2662, 0.0854, 0.3152, 0.0984],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,528][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0785, 0.1571, 0.0043, 0.0323, 0.0023, 0.1118, 0.6138],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,530][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.7210, 0.0836, 0.0499, 0.0368, 0.0224, 0.0639, 0.0224],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,532][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([3.3733e-05, 3.2279e-02, 1.6079e-01, 2.6946e-01, 1.2719e-01, 3.3742e-01,
        7.2819e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,534][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([7.9206e-02, 8.9032e-02, 1.0815e-04, 8.9591e-03, 1.1217e-04, 8.1035e-02,
        7.4155e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,537][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0399, 0.3334, 0.0961, 0.1314, 0.1359, 0.1027, 0.1606],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,537][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.7219e-01, 2.5571e-03, 1.7879e-03, 8.2732e-04, 5.2101e-04, 1.7692e-03,
        9.2094e-03, 1.1139e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,537][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.2065, 0.0103, 0.1358, 0.0204, 0.1678, 0.0957, 0.0448, 0.3187],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,538][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([9.8335e-01, 1.8107e-03, 6.2326e-04, 5.6061e-04, 2.3549e-04, 1.6731e-03,
        4.2420e-03, 7.5092e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,538][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([9.9704e-01, 1.5931e-05, 2.6429e-08, 1.0764e-06, 9.3706e-08, 1.0617e-05,
        4.4829e-04, 2.4827e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,538][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.9626, 0.0056, 0.0126, 0.0023, 0.0057, 0.0051, 0.0039, 0.0022],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,539][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([9.9426e-01, 1.9382e-04, 4.5790e-04, 2.6141e-04, 7.7540e-04, 1.2825e-03,
        1.7760e-03, 9.9321e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,539][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0007, 0.0279, 0.0757, 0.1256, 0.0404, 0.2073, 0.0840, 0.4383],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,541][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1677, 0.0943, 0.0017, 0.0083, 0.0009, 0.0276, 0.1487, 0.5508],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,543][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.7671, 0.0492, 0.0435, 0.0161, 0.0197, 0.0452, 0.0135, 0.0457],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,545][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([8.4467e-05, 2.3500e-02, 2.2506e-01, 1.7415e-01, 1.0302e-01, 2.0389e-01,
        5.1900e-02, 2.1840e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,547][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([4.9355e-02, 4.1434e-03, 5.6828e-06, 3.6489e-04, 5.0075e-06, 4.4223e-03,
        3.2556e-02, 9.0915e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,549][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2444, 0.1924, 0.0872, 0.0854, 0.1627, 0.0445, 0.1096, 0.0737],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,549][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.8620e-01, 2.0092e-03, 5.9560e-04, 4.9046e-04, 1.5394e-04, 8.5103e-04,
        3.6969e-03, 5.1453e-03, 8.6239e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,550][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.3831, 0.0045, 0.0698, 0.0131, 0.1120, 0.0521, 0.0293, 0.2545, 0.0816],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,550][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([9.8079e-01, 2.6458e-03, 4.7469e-04, 5.8261e-04, 1.4713e-04, 9.1806e-04,
        2.7124e-03, 8.8568e-03, 2.8678e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,550][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.5682e-01, 1.6216e-04, 1.1816e-07, 6.2443e-06, 3.3078e-07, 5.5375e-05,
        3.8658e-03, 3.8743e-02, 3.4414e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,551][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.6037e-01, 3.3304e-03, 1.3889e-02, 4.0049e-03, 5.2984e-03, 5.5899e-03,
        3.3829e-03, 3.3831e-03, 7.5092e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,551][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.9739e-01, 9.2447e-05, 1.6629e-04, 1.3028e-04, 2.6443e-04, 4.7298e-04,
        8.4137e-04, 3.5919e-04, 2.8243e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,551][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0007, 0.0394, 0.0519, 0.1431, 0.0202, 0.1177, 0.0479, 0.4257, 0.1533],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,552][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.5780e-01, 6.2877e-02, 6.8421e-04, 7.2587e-03, 3.4633e-04, 1.7871e-02,
        7.0311e-02, 3.8479e-01, 2.9806e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,553][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8821, 0.0255, 0.0164, 0.0091, 0.0072, 0.0126, 0.0049, 0.0341, 0.0081],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,555][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.2010e-04, 1.3763e-02, 6.3522e-02, 1.2235e-01, 4.1750e-02, 1.7319e-01,
        3.3555e-02, 2.4933e-01, 3.0241e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,556][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.3171e-03, 1.3507e-03, 1.2608e-06, 1.0506e-04, 1.5221e-06, 1.1186e-03,
        1.0402e-02, 9.5345e-01, 3.1259e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,560][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.3797, 0.1014, 0.0340, 0.0329, 0.0679, 0.0308, 0.0754, 0.0903, 0.1876],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,562][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([9.9181e-01, 4.9275e-04, 1.7950e-04, 2.9653e-04, 7.4994e-05, 4.0367e-04,
        2.6674e-03, 2.0442e-03, 6.4312e-04, 1.3852e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,562][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0633, 0.0087, 0.1029, 0.0116, 0.1488, 0.0489, 0.0459, 0.3199, 0.0812,
        0.1689], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,563][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([9.7259e-01, 2.0595e-03, 5.8037e-04, 6.5614e-04, 2.4314e-04, 1.2672e-03,
        2.8939e-03, 1.0217e-02, 3.5817e-03, 5.9093e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,563][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([9.8453e-01, 5.3499e-05, 1.0194e-08, 1.6668e-06, 2.9094e-08, 9.6063e-06,
        2.8688e-04, 5.1716e-03, 1.6334e-04, 9.7882e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,563][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.7913, 0.0181, 0.0489, 0.0161, 0.0534, 0.0171, 0.0161, 0.0218, 0.0111,
        0.0061], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,564][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([9.9482e-01, 1.6101e-04, 2.1663e-04, 1.7973e-04, 3.0622e-04, 6.6133e-04,
        1.0164e-03, 6.4749e-04, 3.7781e-04, 1.6163e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,564][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0004, 0.0383, 0.0263, 0.1345, 0.0302, 0.0963, 0.0519, 0.3295, 0.2038,
        0.0890], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,565][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([5.9152e-02, 2.0209e-02, 1.7392e-04, 1.2431e-03, 1.0995e-04, 6.3186e-03,
        3.2309e-02, 1.5127e-01, 1.7401e-01, 5.5520e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,567][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.8860, 0.0209, 0.0069, 0.0110, 0.0050, 0.0104, 0.0069, 0.0367, 0.0034,
        0.0128], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,568][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([3.4825e-05, 1.4402e-02, 5.8431e-02, 1.2637e-01, 4.8560e-02, 1.0765e-01,
        2.8034e-02, 2.2598e-01, 2.4194e-01, 1.4860e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,570][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([2.0341e-02, 2.6508e-03, 6.9470e-07, 1.1170e-04, 6.4828e-07, 1.1082e-03,
        6.0130e-03, 5.9610e-01, 6.6210e-02, 3.0747e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,574][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0344, 0.1030, 0.0206, 0.0349, 0.0346, 0.0364, 0.0543, 0.0922, 0.3583,
        0.2313], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,575][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.9571e-01, 5.9146e-04, 1.7994e-04, 8.1451e-05, 6.7115e-05, 4.1179e-04,
        7.6680e-04, 9.1621e-04, 3.2607e-04, 6.4979e-04, 2.9741e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,575][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.2700, 0.0064, 0.0773, 0.0107, 0.1404, 0.0574, 0.0379, 0.2054, 0.0768,
        0.1014, 0.0163], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,575][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([9.8728e-01, 1.8344e-03, 2.8172e-04, 2.7593e-04, 1.2431e-04, 7.6202e-04,
        1.4416e-03, 3.5989e-03, 1.4957e-03, 2.3762e-03, 5.3058e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,576][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.9409e-01, 4.8730e-05, 3.5662e-08, 1.1924e-06, 9.7597e-08, 1.1566e-05,
        3.1459e-04, 2.0249e-03, 7.6227e-05, 2.5659e-03, 8.6380e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,576][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([9.6823e-01, 2.1845e-03, 1.0678e-02, 1.7295e-03, 4.5312e-03, 3.7882e-03,
        3.2542e-03, 1.6623e-03, 1.1668e-03, 9.4197e-04, 1.8328e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,576][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.9770e-01, 5.0615e-05, 1.8921e-04, 7.2450e-05, 2.6703e-04, 3.4891e-04,
        4.5049e-04, 2.0674e-04, 1.6458e-04, 5.0056e-04, 5.1569e-05],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,577][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0007, 0.0326, 0.0861, 0.0839, 0.0383, 0.1203, 0.0451, 0.2123, 0.1860,
        0.0871, 0.1076], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,577][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.1657e-01, 2.8476e-02, 6.2874e-04, 1.2929e-03, 2.7948e-04, 6.4028e-03,
        3.2288e-02, 9.7118e-02, 1.2650e-01, 4.6831e-01, 1.2213e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,578][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.9378, 0.0161, 0.0099, 0.0045, 0.0052, 0.0050, 0.0017, 0.0076, 0.0023,
        0.0048, 0.0050], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,579][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([6.3205e-05, 8.7537e-03, 4.6710e-02, 4.5673e-02, 2.9032e-02, 9.4614e-02,
        1.6628e-02, 1.3665e-01, 2.0163e-01, 1.5415e-01, 2.6610e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,581][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([3.3240e-02, 5.4273e-03, 3.5902e-06, 2.2324e-04, 3.4566e-06, 2.5653e-03,
        7.9485e-03, 4.5694e-01, 7.2716e-02, 1.9676e-01, 2.2417e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,584][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2238, 0.0410, 0.0189, 0.0270, 0.0878, 0.0239, 0.0448, 0.0833, 0.1872,
        0.2129, 0.0495], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,586][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([9.7594e-01, 1.2040e-03, 6.1970e-04, 5.0809e-04, 1.9655e-04, 1.4812e-03,
        6.7622e-03, 6.0850e-03, 1.5665e-03, 3.1758e-03, 1.3644e-03, 1.0942e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,588][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0295, 0.0056, 0.0323, 0.0061, 0.0527, 0.0377, 0.0277, 0.1549, 0.0781,
        0.2063, 0.0132, 0.3559], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,588][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([9.5610e-01, 2.1031e-03, 4.5100e-04, 5.2337e-04, 1.8075e-04, 1.7876e-03,
        7.3757e-03, 1.5495e-02, 4.1807e-03, 8.8137e-03, 1.4780e-03, 1.5114e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,588][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([7.9065e-01, 7.4800e-05, 5.4490e-08, 8.6299e-06, 9.7920e-08, 4.3302e-05,
        3.0075e-03, 3.4362e-02, 3.5643e-04, 1.4086e-01, 1.9639e-02, 1.1002e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,589][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.7182, 0.0179, 0.0569, 0.0118, 0.0372, 0.0229, 0.0171, 0.0322, 0.0180,
        0.0148, 0.0340, 0.0190], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,589][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([9.8040e-01, 2.8125e-04, 6.0065e-04, 4.9149e-04, 8.9206e-04, 1.6876e-03,
        4.0366e-03, 1.5439e-03, 1.0146e-03, 4.7237e-03, 4.6020e-04, 3.8696e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,589][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0002, 0.0280, 0.0276, 0.0741, 0.0111, 0.1230, 0.0365, 0.1751, 0.1701,
        0.1235, 0.0967, 0.1341], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,590][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([3.9407e-03, 6.7994e-03, 7.6478e-05, 1.0824e-03, 3.5489e-05, 2.4201e-03,
        1.6386e-02, 7.8898e-02, 7.0365e-02, 6.8205e-01, 9.8951e-02, 3.8992e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,591][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.5257, 0.0654, 0.0525, 0.0235, 0.0262, 0.0379, 0.0241, 0.0682, 0.0253,
        0.0448, 0.0433, 0.0632], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,593][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([1.1177e-05, 4.5390e-03, 9.3185e-03, 2.9057e-02, 8.0652e-03, 5.8521e-02,
        1.3794e-02, 4.2707e-02, 1.1990e-01, 7.5227e-02, 7.5672e-02, 5.6319e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,594][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([2.1047e-03, 6.6396e-04, 1.2780e-07, 4.1065e-05, 1.4876e-07, 3.8454e-04,
        2.5456e-03, 2.3580e-01, 9.7388e-03, 4.9121e-01, 1.8754e-01, 6.9961e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,598][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0275, 0.1309, 0.0105, 0.0223, 0.0495, 0.0264, 0.0487, 0.0680, 0.2889,
        0.1329, 0.1187, 0.0758], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,600][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([9.8313e-01, 1.6663e-03, 3.8522e-04, 3.0378e-04, 2.1452e-04, 1.2413e-03,
        2.9263e-03, 2.7608e-03, 1.4026e-03, 1.9825e-03, 1.5761e-03, 7.2779e-04,
        1.6792e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,600][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.1143, 0.0039, 0.0738, 0.0058, 0.0924, 0.0504, 0.0366, 0.1531, 0.0456,
        0.0546, 0.0126, 0.3035, 0.0534], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,601][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([9.4352e-01, 5.2045e-03, 5.8756e-04, 8.5150e-04, 2.3233e-04, 2.3206e-03,
        3.5596e-03, 1.9016e-02, 9.0939e-03, 7.1896e-03, 2.4765e-03, 1.9109e-03,
        4.0387e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,601][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([9.4287e-01, 2.8719e-05, 2.3935e-08, 1.6406e-06, 8.4085e-08, 1.2939e-05,
        6.6851e-04, 7.9665e-03, 8.6331e-05, 2.9075e-02, 3.0363e-03, 6.6589e-03,
        9.5907e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,601][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.7497, 0.0281, 0.0601, 0.0143, 0.0290, 0.0190, 0.0214, 0.0163, 0.0229,
        0.0051, 0.0154, 0.0118, 0.0068], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,602][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([9.9220e-01, 1.2224e-04, 1.3708e-04, 1.5983e-04, 3.4631e-04, 6.3902e-04,
        1.1064e-03, 4.0013e-04, 3.5453e-04, 1.5516e-03, 1.3665e-04, 1.2417e-03,
        1.6024e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,602][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0004, 0.0252, 0.0473, 0.0828, 0.0279, 0.0943, 0.0500, 0.1909, 0.1265,
        0.0505, 0.0715, 0.1761, 0.0567], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,603][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([9.9749e-03, 7.5960e-03, 1.6472e-04, 9.2091e-04, 9.6049e-05, 3.5458e-03,
        3.4779e-02, 1.4282e-01, 9.7833e-02, 4.5397e-01, 1.0604e-01, 8.6499e-02,
        5.5757e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,604][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.8897, 0.0221, 0.0096, 0.0038, 0.0057, 0.0089, 0.0032, 0.0151, 0.0035,
        0.0076, 0.0108, 0.0048, 0.0153], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,606][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([1.0203e-05, 3.9597e-03, 1.2079e-02, 1.7303e-02, 1.0237e-02, 2.6912e-02,
        6.0875e-03, 6.5580e-02, 9.7789e-02, 6.1984e-02, 1.5605e-01, 5.0842e-01,
        3.3592e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,607][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([4.8317e-03, 5.6096e-04, 2.6369e-07, 4.6483e-05, 3.3360e-07, 4.5919e-04,
        4.4235e-03, 2.4815e-01, 1.0688e-02, 2.5396e-01, 1.1265e-01, 6.9357e-02,
        2.9487e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,611][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0432, 0.0816, 0.0182, 0.0235, 0.0370, 0.0336, 0.0494, 0.0680, 0.2393,
        0.1494, 0.1398, 0.0572, 0.0599], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,613][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9596e-01, 4.0748e-04, 1.5627e-04, 7.3332e-05, 4.9429e-05, 2.4174e-04,
        7.2832e-04, 7.1872e-04, 1.6994e-04, 4.5792e-04, 1.5445e-04, 1.0702e-04,
        2.3887e-04, 5.3261e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,613][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3124, 0.0040, 0.0502, 0.0084, 0.0766, 0.0348, 0.0272, 0.0753, 0.0362,
        0.0469, 0.0081, 0.1985, 0.0511, 0.0704], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,614][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.8751e-01, 1.3336e-03, 2.2863e-04, 2.5083e-04, 7.2600e-05, 5.5506e-04,
        9.9704e-04, 2.7371e-03, 1.2426e-03, 1.8559e-03, 3.4115e-04, 3.2372e-04,
        7.0339e-04, 1.8519e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,614][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.9471e-01, 2.4290e-06, 3.6931e-09, 1.2786e-07, 6.1133e-09, 9.6123e-07,
        3.5243e-05, 2.8080e-04, 2.2610e-06, 9.8959e-04, 1.8613e-04, 8.6712e-05,
        2.1723e-04, 3.4877e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,614][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8814e-01, 1.0447e-03, 3.0388e-03, 6.1105e-04, 1.7531e-03, 8.1111e-04,
        7.3230e-04, 7.1466e-04, 5.6755e-04, 4.1655e-04, 5.6749e-04, 7.5175e-04,
        3.9311e-04, 4.6091e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,615][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9843e-01, 2.5609e-05, 6.9511e-05, 3.0310e-05, 1.0580e-04, 1.0549e-04,
        1.8376e-04, 8.5294e-05, 6.3923e-05, 2.8431e-04, 1.8502e-05, 2.5324e-04,
        1.9507e-04, 1.4527e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,615][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0008, 0.0211, 0.0381, 0.0469, 0.0217, 0.0694, 0.0442, 0.0776, 0.0846,
        0.0416, 0.0417, 0.1240, 0.0563, 0.3318], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,616][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.0766e-01, 1.2399e-02, 1.9049e-04, 5.8622e-04, 9.7742e-05, 3.2078e-03,
        1.9340e-02, 6.4990e-02, 6.2793e-02, 2.4207e-01, 9.2011e-02, 4.0804e-02,
        4.0698e-02, 2.1316e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,618][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.9381, 0.0108, 0.0064, 0.0031, 0.0033, 0.0049, 0.0017, 0.0054, 0.0017,
        0.0042, 0.0041, 0.0028, 0.0045, 0.0090], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,619][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.6311e-05, 5.5967e-03, 2.0775e-02, 2.6185e-02, 1.5553e-02, 3.6487e-02,
        1.3310e-02, 3.5440e-02, 1.0100e-01, 4.1789e-02, 1.5081e-01, 4.0744e-01,
        3.3693e-02, 1.1186e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,621][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.5311e-02, 3.2898e-04, 3.4010e-07, 1.5991e-05, 3.3613e-07, 1.9310e-04,
        1.1070e-03, 6.2740e-02, 1.8879e-03, 5.6515e-02, 3.1263e-02, 1.2940e-02,
        5.6680e-02, 6.9102e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,625][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3657, 0.0531, 0.0131, 0.0158, 0.0397, 0.0190, 0.0380, 0.0287, 0.1281,
        0.1210, 0.0541, 0.0390, 0.0342, 0.0504], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,626][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([9.8622e-01, 9.9303e-04, 5.8468e-04, 1.9548e-04, 1.3705e-04, 7.9294e-04,
        1.5545e-03, 2.3155e-03, 5.1853e-04, 1.3433e-03, 3.5983e-04, 3.5937e-04,
        6.3886e-04, 1.9565e-03, 2.0272e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,626][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1850, 0.0032, 0.0799, 0.0086, 0.0857, 0.0377, 0.0205, 0.1288, 0.0371,
        0.0434, 0.0100, 0.2000, 0.0320, 0.0683, 0.0597], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,626][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([9.8455e-01, 1.3074e-03, 1.8682e-04, 1.7685e-04, 5.0468e-05, 3.7289e-04,
        9.4301e-04, 2.8606e-03, 1.2166e-03, 2.3186e-03, 3.2890e-04, 3.0702e-04,
        6.9277e-04, 2.0835e-03, 2.6036e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,627][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([9.6249e-01, 6.3034e-06, 5.6820e-09, 2.2406e-07, 1.1925e-08, 1.8985e-06,
        4.9974e-05, 8.2454e-04, 6.7559e-06, 3.7058e-03, 8.6875e-04, 3.5740e-04,
        8.3731e-04, 2.0268e-02, 1.0587e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,627][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.9275, 0.0090, 0.0209, 0.0042, 0.0083, 0.0048, 0.0038, 0.0031, 0.0038,
        0.0013, 0.0032, 0.0038, 0.0018, 0.0024, 0.0020], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,628][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([9.9208e-01, 8.0500e-05, 1.7850e-04, 1.2050e-04, 3.1618e-04, 5.1812e-04,
        9.0579e-04, 4.5692e-04, 3.4104e-04, 1.2968e-03, 1.3384e-04, 9.6359e-04,
        9.9755e-04, 5.2177e-04, 1.0886e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,628][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0002, 0.0193, 0.0500, 0.0513, 0.0314, 0.0534, 0.0246, 0.1084, 0.0894,
        0.0354, 0.0476, 0.1512, 0.0332, 0.2204, 0.0842], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,629][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([5.0279e-02, 7.9548e-03, 1.5511e-04, 5.8668e-04, 5.7995e-05, 2.4939e-03,
        1.6179e-02, 8.1026e-02, 4.7416e-02, 2.6935e-01, 7.0466e-02, 3.7836e-02,
        3.4898e-02, 2.2692e-01, 1.5438e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,631][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.7500, 0.0319, 0.0237, 0.0074, 0.0126, 0.0198, 0.0032, 0.0223, 0.0125,
        0.0124, 0.0186, 0.0116, 0.0130, 0.0380, 0.0231], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,632][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([2.4683e-05, 3.1742e-03, 1.7859e-02, 1.9610e-02, 1.7676e-02, 3.3072e-02,
        8.7277e-03, 4.9999e-02, 6.8712e-02, 4.3577e-02, 1.1353e-01, 5.3145e-01,
        2.2022e-02, 5.6923e-02, 1.3640e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,634][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([1.0210e-02, 1.1777e-04, 1.0465e-07, 6.8345e-06, 6.9445e-08, 7.7370e-05,
        4.0986e-04, 2.7898e-02, 1.1638e-03, 4.9506e-02, 1.7724e-02, 6.3888e-03,
        3.3339e-02, 4.6715e-01, 3.8601e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,638][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0420, 0.0487, 0.0123, 0.0288, 0.0360, 0.0260, 0.0450, 0.0456, 0.2699,
        0.1229, 0.0870, 0.0368, 0.0387, 0.1043, 0.0560], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,639][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.8824e-01, 9.6902e-04, 2.0168e-04, 1.1765e-04, 7.0599e-05, 4.0871e-04,
        1.6900e-03, 1.6006e-03, 3.9956e-04, 1.3930e-03, 3.3515e-04, 2.5920e-04,
        6.9210e-04, 1.4795e-03, 1.6464e-03, 4.9447e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,639][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1127, 0.0025, 0.0350, 0.0041, 0.0890, 0.0277, 0.0182, 0.0734, 0.0222,
        0.0337, 0.0065, 0.3867, 0.0300, 0.0561, 0.0615, 0.0406],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,639][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.7076e-01, 1.6400e-03, 2.8825e-04, 3.2043e-04, 1.0926e-04, 8.0689e-04,
        1.6912e-03, 5.9733e-03, 1.9380e-03, 3.7203e-03, 4.7770e-04, 7.8849e-04,
        1.6200e-03, 3.5051e-03, 4.7613e-03, 1.5973e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,640][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.5049e-01, 1.4307e-05, 1.8789e-08, 1.3541e-06, 4.2943e-08, 6.3238e-06,
        4.6681e-04, 5.1597e-03, 2.7384e-05, 2.6271e-02, 2.0393e-03, 3.4064e-03,
        4.7668e-03, 1.0673e-01, 1.9879e-01, 1.8409e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,640][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9554, 0.0031, 0.0103, 0.0029, 0.0042, 0.0033, 0.0042, 0.0028, 0.0031,
        0.0011, 0.0017, 0.0014, 0.0012, 0.0019, 0.0021, 0.0013],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,641][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.9216e-01, 8.2445e-05, 2.1895e-04, 1.3438e-04, 3.5384e-04, 4.2523e-04,
        7.8087e-04, 5.2031e-04, 3.1101e-04, 1.2679e-03, 1.0131e-04, 9.8029e-04,
        1.0302e-03, 4.9434e-04, 7.9367e-04, 3.4199e-04], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,642][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0003, 0.0182, 0.0374, 0.0500, 0.0194, 0.0503, 0.0166, 0.0957, 0.0873,
        0.0321, 0.0371, 0.1643, 0.0247, 0.1974, 0.0761, 0.0929],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,644][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.9480e-02, 8.9426e-03, 1.7816e-04, 8.0176e-04, 9.6568e-05, 3.2975e-03,
        1.6530e-02, 5.4203e-02, 5.6415e-02, 3.5170e-01, 6.4121e-02, 4.7628e-02,
        3.4667e-02, 1.7843e-01, 1.2917e-01, 2.4344e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,647][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8215, 0.0208, 0.0112, 0.0091, 0.0062, 0.0130, 0.0035, 0.0233, 0.0038,
        0.0104, 0.0108, 0.0062, 0.0137, 0.0258, 0.0189, 0.0016],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,649][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.2440e-05, 3.4725e-03, 1.6137e-02, 2.4914e-02, 1.4132e-02, 3.0192e-02,
        1.0685e-02, 3.8883e-02, 6.2506e-02, 2.7774e-02, 8.8340e-02, 5.2582e-01,
        2.1654e-02, 6.6310e-02, 2.0368e-02, 4.8790e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,651][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.9013e-04, 3.7247e-05, 2.8740e-08, 4.5436e-06, 2.7882e-08, 2.7450e-05,
        2.5381e-04, 1.9812e-02, 4.4738e-04, 2.9042e-02, 6.1557e-03, 5.8536e-03,
        1.6336e-02, 3.9734e-01, 5.2019e-01, 4.3077e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,651][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1046, 0.0470, 0.0176, 0.0199, 0.0424, 0.0299, 0.0308, 0.0457, 0.1369,
        0.1191, 0.0843, 0.0506, 0.0396, 0.0780, 0.0436, 0.1102],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,651][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([9.8396e-01, 5.6569e-04, 3.2628e-04, 2.0594e-04, 1.0800e-04, 2.8075e-04,
        2.0298e-03, 1.8602e-03, 2.7052e-04, 1.1217e-03, 2.3820e-04, 3.5077e-04,
        4.9273e-04, 1.3971e-03, 2.3410e-03, 5.4387e-04, 3.9103e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,652][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0646, 0.0018, 0.0348, 0.0040, 0.0649, 0.0257, 0.0179, 0.0689, 0.0178,
        0.0474, 0.0048, 0.3296, 0.0435, 0.0630, 0.0779, 0.0533, 0.0803],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,652][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([9.7257e-01, 1.4340e-03, 2.7883e-04, 2.4508e-04, 1.0672e-04, 6.1387e-04,
        1.5924e-03, 4.2166e-03, 1.2938e-03, 3.2282e-03, 3.1427e-04, 6.6762e-04,
        1.1819e-03, 2.9146e-03, 3.3072e-03, 1.2315e-03, 4.8057e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,653][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([8.0967e-01, 3.1884e-06, 1.8102e-09, 1.5360e-07, 4.3958e-09, 7.3420e-07,
        4.5961e-05, 1.0669e-03, 3.6569e-06, 5.1458e-03, 3.8402e-04, 4.8590e-04,
        5.6637e-04, 3.7357e-02, 3.3257e-02, 4.8741e-04, 1.1153e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,653][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.8930, 0.0066, 0.0168, 0.0054, 0.0153, 0.0075, 0.0064, 0.0092, 0.0053,
        0.0028, 0.0073, 0.0061, 0.0029, 0.0046, 0.0042, 0.0030, 0.0037],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,653][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([9.9154e-01, 7.2001e-05, 1.3215e-04, 1.2367e-04, 2.1434e-04, 3.3750e-04,
        6.2308e-04, 3.5154e-04, 2.2669e-04, 9.8959e-04, 7.6672e-05, 5.7693e-04,
        6.1040e-04, 4.5461e-04, 7.8805e-04, 2.6602e-04, 2.6200e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,654][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.5294e-04, 9.7576e-03, 2.0655e-02, 2.9262e-02, 1.2511e-02, 3.5825e-02,
        1.6532e-02, 5.6615e-02, 4.3775e-02, 3.6706e-02, 3.5927e-02, 1.3178e-01,
        2.5040e-02, 1.8363e-01, 1.2624e-01, 9.3976e-02, 1.4161e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,656][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([2.8460e-02, 3.6171e-03, 5.2361e-05, 3.2332e-04, 2.7491e-05, 1.4119e-03,
        1.5883e-02, 6.7240e-02, 3.0713e-02, 2.2949e-01, 4.8854e-02, 2.6951e-02,
        2.1026e-02, 1.7335e-01, 1.6861e-01, 2.5741e-02, 1.5825e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,658][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.8764, 0.0138, 0.0071, 0.0046, 0.0032, 0.0071, 0.0026, 0.0102, 0.0032,
        0.0093, 0.0074, 0.0041, 0.0064, 0.0192, 0.0132, 0.0018, 0.0104],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,660][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([1.7076e-05, 2.5779e-03, 1.1681e-02, 1.5694e-02, 8.1453e-03, 2.3829e-02,
        8.8231e-03, 3.2472e-02, 5.2610e-02, 4.4453e-02, 6.5093e-02, 3.5654e-01,
        2.1825e-02, 6.7005e-02, 3.5971e-02, 8.2665e-02, 1.7060e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,662][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([4.0736e-03, 2.8385e-05, 1.1831e-08, 1.3097e-06, 1.1927e-08, 1.3973e-05,
        1.5303e-04, 1.2292e-02, 2.1835e-04, 1.6843e-02, 4.7777e-03, 2.4705e-03,
        7.3354e-03, 3.0645e-01, 3.1826e-01, 2.6755e-03, 3.2441e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,664][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0294, 0.0376, 0.0102, 0.0131, 0.0242, 0.0191, 0.0247, 0.0502, 0.1276,
        0.1266, 0.0717, 0.0463, 0.0452, 0.0825, 0.0591, 0.1253, 0.1072],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,664][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.9162e-01, 3.5578e-04, 2.0682e-04, 8.8553e-05, 8.0287e-05, 2.9212e-04,
        1.2499e-03, 7.3029e-04, 2.1861e-04, 7.6462e-04, 1.6642e-04, 1.7998e-04,
        2.8803e-04, 7.2647e-04, 9.4086e-04, 3.1460e-04, 1.4407e-03, 3.3518e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,664][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1179, 0.0024, 0.0408, 0.0050, 0.0628, 0.0247, 0.0197, 0.0641, 0.0240,
        0.0333, 0.0065, 0.2455, 0.0303, 0.0615, 0.0601, 0.0604, 0.0600, 0.0809],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,665][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.7921e-01, 9.0149e-04, 1.9816e-04, 1.9790e-04, 7.2490e-05, 4.6074e-04,
        1.0922e-03, 2.6059e-03, 1.0941e-03, 2.4096e-03, 2.2783e-04, 3.9396e-04,
        7.9649e-04, 2.1717e-03, 3.0194e-03, 1.0127e-03, 3.1300e-03, 1.0043e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,665][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.1964e-01, 5.8910e-06, 1.6690e-08, 8.2303e-07, 2.5125e-08, 4.4773e-06,
        2.6245e-04, 2.6614e-03, 1.8144e-05, 2.1738e-02, 2.0421e-03, 1.1014e-03,
        1.5452e-03, 3.7581e-02, 6.9007e-02, 8.9805e-04, 1.3895e-01, 4.5482e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,666][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.7811e-01, 1.5580e-03, 4.8998e-03, 1.0776e-03, 2.8395e-03, 1.3309e-03,
        1.4738e-03, 1.1459e-03, 7.8305e-04, 6.1792e-04, 8.7637e-04, 1.0005e-03,
        4.9174e-04, 7.1500e-04, 9.0129e-04, 6.8890e-04, 5.8311e-04, 9.0334e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,667][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9312e-01, 3.7543e-05, 1.3130e-04, 5.7190e-05, 1.7148e-04, 2.3194e-04,
        4.3953e-04, 2.1239e-04, 1.3012e-04, 6.4672e-04, 3.1040e-05, 4.8096e-04,
        4.1135e-04, 3.5139e-04, 5.5191e-04, 1.4737e-04, 2.6093e-03, 2.4151e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,669][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0005, 0.0109, 0.0196, 0.0302, 0.0144, 0.0436, 0.0228, 0.0408, 0.0520,
        0.0182, 0.0258, 0.0925, 0.0247, 0.1769, 0.0823, 0.1157, 0.1070, 0.1222],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,670][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.1465e-02, 3.7751e-03, 1.1777e-04, 3.9809e-04, 6.5842e-05, 2.1262e-03,
        1.4583e-02, 4.3308e-02, 4.2033e-02, 2.5761e-01, 5.7848e-02, 4.4687e-02,
        3.0610e-02, 1.5472e-01, 1.1464e-01, 2.2838e-02, 1.3140e-01, 3.7775e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,674][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.8479, 0.0169, 0.0085, 0.0061, 0.0055, 0.0093, 0.0036, 0.0113, 0.0031,
        0.0090, 0.0075, 0.0048, 0.0104, 0.0211, 0.0152, 0.0016, 0.0120, 0.0060],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,676][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.1146e-05, 2.9474e-03, 1.1284e-02, 1.4995e-02, 1.1201e-02, 2.3494e-02,
        8.9985e-03, 2.0118e-02, 5.7104e-02, 1.9987e-02, 6.9684e-02, 3.7769e-01,
        1.7659e-02, 6.2682e-02, 2.1795e-02, 7.4869e-02, 1.4102e-01, 6.4420e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,676][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.3152e-03, 2.7907e-05, 3.8781e-08, 3.5175e-06, 4.0335e-08, 3.6363e-05,
        3.1259e-04, 1.6245e-02, 4.4706e-04, 3.2928e-02, 1.0223e-02, 4.0513e-03,
        1.3135e-02, 2.5016e-01, 3.2854e-01, 2.8539e-03, 3.2573e-01, 1.1992e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,677][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2074, 0.0318, 0.0080, 0.0101, 0.0374, 0.0143, 0.0239, 0.0258, 0.1020,
        0.0836, 0.0376, 0.0466, 0.0281, 0.0524, 0.0331, 0.1032, 0.0902, 0.0646],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,678][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:20,679][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 483],
        [  59],
        [3353],
        [  22],
        [ 126],
        [  27],
        [  21],
        [  27],
        [   8],
        [   1],
        [   3],
        [  22],
        [   3],
        [   1],
        [   3],
        [  13],
        [   4],
        [   1]], device='cuda:0')
[2024-07-24 10:30:20,680][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 239],
        [  87],
        [1031],
        [  29],
        [ 293],
        [ 111],
        [  54],
        [  97],
        [  26],
        [   8],
        [  78],
        [ 172],
        [  32],
        [  15],
        [  24],
        [  39],
        [  19],
        [  15]], device='cuda:0')
[2024-07-24 10:30:20,681][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[29359],
        [28291],
        [26605],
        [18689],
        [ 9433],
        [ 7041],
        [ 4483],
        [ 3497],
        [ 3838],
        [ 3489],
        [ 3567],
        [ 2231],
        [ 2819],
        [ 3111],
        [ 3157],
        [ 3661],
        [ 3368],
        [ 3627]], device='cuda:0')
[2024-07-24 10:30:20,683][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[45452],
        [43997],
        [40250],
        [40858],
        [40679],
        [36162],
        [34289],
        [27136],
        [25523],
        [23595],
        [25766],
        [30418],
        [33807],
        [34446],
        [33038],
        [36165],
        [33260],
        [32527]], device='cuda:0')
[2024-07-24 10:30:20,685][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[28564],
        [28594],
        [29214],
        [28921],
        [31209],
        [32558],
        [32979],
        [30168],
        [30324],
        [30659],
        [29601],
        [32006],
        [33770],
        [29911],
        [30166],
        [31625],
        [31053],
        [30532]], device='cuda:0')
[2024-07-24 10:30:20,687][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[21133],
        [ 5554],
        [ 3117],
        [ 2843],
        [ 3304],
        [ 3331],
        [ 3981],
        [ 3865],
        [ 4290],
        [ 5713],
        [ 5862],
        [ 6212],
        [ 8465],
        [ 7381],
        [ 7579],
        [ 7008],
        [ 7532],
        [ 6685]], device='cuda:0')
[2024-07-24 10:30:20,689][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[5789],
        [3462],
        [7495],
        [2319],
        [7515],
        [7265],
        [5634],
        [3576],
        [3689],
        [5313],
        [3575],
        [6194],
        [7949],
        [4777],
        [7439],
        [5718],
        [6142],
        [5441]], device='cuda:0')
[2024-07-24 10:30:20,692][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19385],
        [19384],
        [18755],
        [19236],
        [16810],
        [18555],
        [18512],
        [18710],
        [19184],
        [18594],
        [19010],
        [17294],
        [18551],
        [18848],
        [17607],
        [17719],
        [18357],
        [18003]], device='cuda:0')
[2024-07-24 10:30:20,693][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[40927],
        [15991],
        [50228],
        [49973],
        [48601],
        [45289],
        [42109],
        [33522],
        [27122],
        [19921],
        [29279],
        [23461],
        [26374],
        [25192],
        [26681],
        [23702],
        [22423],
        [22153]], device='cuda:0')
[2024-07-24 10:30:20,694][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25057],
        [34798],
        [34712],
        [27517],
        [23138],
        [20861],
        [35261],
        [35403],
        [32954],
        [16300],
        [16029],
        [13293],
        [15960],
        [17763],
        [17816],
        [16718],
        [18108],
        [17702]], device='cuda:0')
[2024-07-24 10:30:20,695][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[2978],
        [2657],
        [5025],
        [2609],
        [9494],
        [3103],
        [4050],
        [4741],
        [2720],
        [2008],
        [2863],
        [5118],
        [2376],
        [2757],
        [3861],
        [2795],
        [2549],
        [2683]], device='cuda:0')
[2024-07-24 10:30:20,696][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36336],
        [34756],
        [50257],
        [50162],
        [49840],
        [49949],
        [49420],
        [49393],
        [45222],
        [45793],
        [44689],
        [44117],
        [43830],
        [44052],
        [44795],
        [45316],
        [44635],
        [44587]], device='cuda:0')
[2024-07-24 10:30:20,697][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15299],
        [ 6481],
        [ 3862],
        [ 3105],
        [ 3430],
        [ 3039],
        [ 3837],
        [ 3797],
        [ 3680],
        [ 3798],
        [ 4748],
        [ 3854],
        [ 4001],
        [ 3999],
        [ 4112],
        [ 3778],
        [ 4103],
        [ 4091]], device='cuda:0')
[2024-07-24 10:30:20,699][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27323],
        [32113],
        [ 6281],
        [ 8701],
        [ 6081],
        [ 9688],
        [10704],
        [ 9887],
        [10993],
        [10054],
        [10005],
        [ 9338],
        [ 8294],
        [ 9668],
        [ 9375],
        [10833],
        [10812],
        [12050]], device='cuda:0')
[2024-07-24 10:30:20,700][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[40906],
        [12157],
        [18257],
        [ 5640],
        [ 3633],
        [ 3234],
        [ 5829],
        [ 6972],
        [ 7564],
        [ 7917],
        [ 1951],
        [ 4362],
        [ 2814],
        [ 1983],
        [ 2676],
        [ 6742],
        [ 4038],
        [ 1761]], device='cuda:0')
[2024-07-24 10:30:20,703][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[5958],
        [5971],
        [6011],
        [6010],
        [6874],
        [6922],
        [6308],
        [6295],
        [6193],
        [6033],
        [6035],
        [6466],
        [6346],
        [6002],
        [6161],
        [6095],
        [6121],
        [6004]], device='cuda:0')
[2024-07-24 10:30:20,705][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8854],
        [ 9621],
        [11291],
        [ 9820],
        [32556],
        [28981],
        [27626],
        [23309],
        [19766],
        [19373],
        [19934],
        [23406],
        [25250],
        [22541],
        [24252],
        [28136],
        [24255],
        [22806]], device='cuda:0')
[2024-07-24 10:30:20,707][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[31669],
        [31694],
        [32023],
        [32108],
        [33066],
        [32323],
        [31198],
        [31911],
        [31847],
        [32751],
        [32255],
        [32995],
        [33339],
        [32374],
        [32576],
        [33218],
        [33211],
        [32964]], device='cuda:0')
[2024-07-24 10:30:20,708][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3375],
        [ 3376],
        [ 3796],
        [ 3379],
        [12317],
        [ 3391],
        [ 3367],
        [ 3352],
        [ 3247],
        [ 3229],
        [ 3320],
        [ 3354],
        [ 2999],
        [ 3328],
        [ 3332],
        [ 7696],
        [ 5483],
        [ 6385]], device='cuda:0')
[2024-07-24 10:30:20,709][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 5230],
        [ 5422],
        [11752],
        [ 5841],
        [21743],
        [22011],
        [22974],
        [ 8579],
        [ 8728],
        [26158],
        [ 8202],
        [34240],
        [30548],
        [ 6321],
        [13628],
        [10409],
        [21483],
        [ 7534]], device='cuda:0')
[2024-07-24 10:30:20,710][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6424],
        [6423],
        [6622],
        [6396],
        [6529],
        [6012],
        [6257],
        [6350],
        [6366],
        [6281],
        [6356],
        [6122],
        [6268],
        [6371],
        [6284],
        [6295],
        [6192],
        [6202]], device='cuda:0')
[2024-07-24 10:30:20,712][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[13040],
        [42530],
        [46186],
        [46302],
        [46560],
        [46813],
        [46132],
        [45520],
        [45310],
        [44993],
        [45246],
        [44647],
        [45465],
        [45559],
        [45897],
        [45695],
        [45246],
        [45515]], device='cuda:0')
[2024-07-24 10:30:20,713][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17066],
        [15610],
        [22785],
        [25510],
        [29462],
        [28651],
        [39238],
        [33062],
        [35013],
        [29457],
        [29332],
        [28154],
        [30369],
        [32323],
        [33875],
        [33351],
        [35237],
        [35265]], device='cuda:0')
[2024-07-24 10:30:20,715][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23757],
        [23387],
        [28709],
        [23753],
        [31722],
        [30145],
        [32938],
        [32822],
        [30780],
        [30642],
        [25612],
        [31261],
        [29067],
        [26370],
        [29528],
        [29937],
        [28260],
        [28879]], device='cuda:0')
[2024-07-24 10:30:20,716][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 7339],
        [42371],
        [44880],
        [45319],
        [44072],
        [46300],
        [46020],
        [45415],
        [42828],
        [45870],
        [45797],
        [40299],
        [40869],
        [42098],
        [41193],
        [41439],
        [44618],
        [43635]], device='cuda:0')
[2024-07-24 10:30:20,718][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13368],
        [ 4026],
        [11298],
        [11099],
        [15566],
        [15522],
        [20574],
        [ 5285],
        [ 5419],
        [10417],
        [12989],
        [18648],
        [17920],
        [13686],
        [11166],
        [10423],
        [11143],
        [11379]], device='cuda:0')
[2024-07-24 10:30:20,721][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[2852],
        [4820],
        [3870],
        [4681],
        [2674],
        [3950],
        [7490],
        [3889],
        [6789],
        [8744],
        [7428],
        [9062],
        [8512],
        [6993],
        [9682],
        [8428],
        [9335],
        [8854]], device='cuda:0')
[2024-07-24 10:30:20,723][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43931],
        [37660],
        [27642],
        [30654],
        [15477],
        [17342],
        [12036],
        [24773],
        [26819],
        [20406],
        [26265],
        [15263],
        [15609],
        [26535],
        [21670],
        [20045],
        [17866],
        [22044]], device='cuda:0')
[2024-07-24 10:30:20,724][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5542],
        [23599],
        [19808],
        [29451],
        [14222],
        [26105],
        [25174],
        [23130],
        [24267],
        [20465],
        [28755],
        [18513],
        [27898],
        [32869],
        [31467],
        [19678],
        [32468],
        [35638]], device='cuda:0')
[2024-07-24 10:30:20,725][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457],
        [4457]], device='cuda:0')
[2024-07-24 10:30:20,771][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:20,771][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,772][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,772][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,772][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,773][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,773][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,773][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,774][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,774][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,774][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,775][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,775][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:20,775][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2463, 0.7537], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,776][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0202, 0.9798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,777][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4750, 0.5250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,777][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9724, 0.0276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,778][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,778][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9855, 0.0145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,778][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5777, 0.4223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,779][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9804, 0.0196], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,779][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3257, 0.6743], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,780][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8287, 0.1713], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,780][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9908, 0.0092], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,781][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9988e-01, 1.1646e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:20,781][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.0056, 0.9138, 0.0806], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,781][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([4.4069e-05, 6.2602e-01, 3.7394e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,782][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([0.0212, 0.6833, 0.2955], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,782][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.0780, 0.8055, 0.1166], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,782][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.4033, 0.5925, 0.0041], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,783][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.0156, 0.9826, 0.0019], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,783][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.0091, 0.8720, 0.1188], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,783][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.5704, 0.2785, 0.1511], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,784][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.0218, 0.7538, 0.2244], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,785][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([1.4626e-04, 9.9932e-01, 5.3619e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,787][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.0554, 0.0765, 0.8682], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,789][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.0572, 0.7632, 0.1797], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:20,793][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0342, 0.4335, 0.0349, 0.4974], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,795][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0008, 0.2662, 0.2445, 0.4885], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,796][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0255, 0.4302, 0.3469, 0.1975], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,796][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5796, 0.1743, 0.0810, 0.1651], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,796][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([8.5528e-01, 1.0994e-01, 4.4291e-04, 3.4337e-02], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,796][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.9057e-01, 7.5669e-01, 1.4958e-04, 5.2588e-02], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,797][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0211, 0.5615, 0.0816, 0.3358], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,797][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6992, 0.1855, 0.0661, 0.0492], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,797][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0467, 0.5689, 0.2512, 0.1331], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,798][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.2483e-03, 9.7550e-01, 4.1308e-05, 1.9214e-02], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,799][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2863, 0.0329, 0.6768, 0.0041], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,801][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3896, 0.3006, 0.1082, 0.2016], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:20,803][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([4.3588e-04, 6.0483e-01, 4.6330e-02, 3.3494e-01, 1.3456e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,805][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([8.8174e-06, 5.1408e-01, 1.9648e-01, 1.9727e-01, 9.2165e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,808][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.0019, 0.5956, 0.1581, 0.2065, 0.0378], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,808][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0050, 0.5276, 0.0818, 0.3081, 0.0776], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,808][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.1343, 0.5881, 0.0035, 0.2693, 0.0048], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,808][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([4.9128e-04, 3.1515e-01, 7.0787e-04, 6.8344e-01, 2.1180e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,809][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([8.7971e-05, 7.1950e-01, 3.5795e-02, 2.1237e-01, 3.2247e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,809][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.3018, 0.2918, 0.2130, 0.1377, 0.0557], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,809][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0066, 0.5311, 0.0923, 0.0622, 0.3078], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,810][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([1.8820e-06, 2.8279e-01, 1.9134e-04, 7.1701e-01, 5.4476e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,810][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0136, 0.0811, 0.8789, 0.0081, 0.0183], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,810][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([6.2063e-04, 7.0525e-01, 9.4076e-02, 1.4188e-01, 5.8167e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:20,811][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0025, 0.6562, 0.0249, 0.0834, 0.0068, 0.2263], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,811][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ were] are: tensor([1.1910e-04, 3.6632e-01, 1.8159e-01, 2.1926e-01, 1.0317e-01, 1.2953e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,812][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0044, 0.6017, 0.1445, 0.1486, 0.0203, 0.0804], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,815][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.1003, 0.4936, 0.0512, 0.1354, 0.0365, 0.1830], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,816][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ were] are: tensor([8.1989e-01, 1.4661e-01, 3.7067e-04, 2.1775e-02, 3.3276e-04, 1.1021e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,818][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ were] are: tensor([4.0256e-02, 8.1751e-01, 4.7048e-05, 4.3238e-02, 8.0275e-06, 9.8936e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,821][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0016, 0.6624, 0.0295, 0.1180, 0.0316, 0.1569], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,821][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.6848, 0.1661, 0.0612, 0.0423, 0.0238, 0.0218], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,822][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0252, 0.4281, 0.0805, 0.0711, 0.1542, 0.2408], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,822][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ were] are: tensor([6.6528e-05, 9.8393e-01, 9.2456e-06, 9.6505e-03, 8.8523e-08, 6.3455e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,822][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.1125, 0.0867, 0.7275, 0.0039, 0.0226, 0.0468], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,823][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0071, 0.5866, 0.0424, 0.0878, 0.0316, 0.2444], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:20,823][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0019, 0.4017, 0.0412, 0.1260, 0.0114, 0.1463, 0.2716],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,824][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ working] are: tensor([9.6677e-05, 2.1133e-01, 1.4684e-01, 2.2923e-01, 2.3803e-01, 1.1616e-01,
        5.8320e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,825][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0033, 0.4519, 0.1672, 0.2042, 0.0433, 0.0814, 0.0488],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,827][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ working] are: tensor([0.0928, 0.3194, 0.0620, 0.1583, 0.0680, 0.1679, 0.1317],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,829][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ working] are: tensor([6.4850e-01, 2.4711e-01, 6.0778e-04, 5.9224e-02, 1.0005e-03, 3.1279e-02,
        1.2282e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,831][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ working] are: tensor([1.1543e-01, 4.2028e-01, 1.3732e-05, 1.7684e-02, 1.5520e-06, 4.8729e-02,
        3.9786e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,834][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0013, 0.5298, 0.0297, 0.1431, 0.0656, 0.1390, 0.0914],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,834][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.7586, 0.1135, 0.0360, 0.0303, 0.0182, 0.0131, 0.0303],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,834][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0184, 0.2735, 0.0880, 0.0996, 0.2240, 0.2623, 0.0343],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,835][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ working] are: tensor([7.8573e-04, 8.7334e-01, 3.5915e-06, 6.9741e-03, 3.3552e-08, 8.4077e-03,
        1.1048e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,835][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.0237, 0.0550, 0.7382, 0.0048, 0.0427, 0.0518, 0.0838],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,835][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0110, 0.3001, 0.0779, 0.1415, 0.0547, 0.2475, 0.1672],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:20,836][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0012, 0.2645, 0.0313, 0.0766, 0.0138, 0.1078, 0.1241, 0.3808],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,836][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([5.3075e-05, 9.5546e-02, 1.9354e-01, 1.2984e-01, 2.7404e-01, 7.6998e-02,
        6.5964e-02, 1.6402e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,838][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0040, 0.1949, 0.2296, 0.1620, 0.0943, 0.0685, 0.0407, 0.2060],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,840][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0638, 0.1568, 0.0496, 0.1051, 0.0707, 0.1327, 0.1201, 0.3012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,842][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([8.7132e-01, 4.6908e-02, 5.4445e-04, 2.4962e-02, 1.1261e-03, 1.5050e-02,
        4.4333e-03, 3.5657e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,844][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([4.6139e-01, 6.9765e-02, 1.1411e-05, 3.7397e-03, 2.6685e-06, 1.1042e-02,
        5.0767e-02, 4.0328e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,846][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0011, 0.3273, 0.0538, 0.0967, 0.0779, 0.1290, 0.0476, 0.2666],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,847][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.4738, 0.1921, 0.0828, 0.0455, 0.0552, 0.0278, 0.0363, 0.0866],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,847][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0151, 0.1347, 0.0997, 0.0751, 0.1545, 0.2395, 0.0257, 0.2557],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,847][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([7.6375e-02, 4.5812e-01, 1.6939e-05, 4.4471e-03, 3.4696e-07, 5.8315e-03,
        3.9078e-02, 4.1613e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,848][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0282, 0.0143, 0.8173, 0.0020, 0.0346, 0.0252, 0.0639, 0.0144],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,848][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0288, 0.1108, 0.0643, 0.0699, 0.0348, 0.1659, 0.0865, 0.4390],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:20,849][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0017, 0.2433, 0.0150, 0.0542, 0.0055, 0.0463, 0.0585, 0.3135, 0.2618],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,849][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.7454e-04, 1.1685e-01, 9.1550e-02, 1.0557e-01, 1.3812e-01, 4.4363e-02,
        4.2540e-02, 1.5187e-01, 3.0896e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,850][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0107, 0.2737, 0.1658, 0.1339, 0.0565, 0.0565, 0.0294, 0.1829, 0.0906],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,853][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0858, 0.2130, 0.0532, 0.0901, 0.0480, 0.0777, 0.0511, 0.1912, 0.1897],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,855][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([7.7883e-01, 1.4252e-01, 3.6503e-04, 2.3209e-02, 4.3873e-04, 1.4414e-02,
        2.5840e-03, 3.2044e-02, 5.5960e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,857][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.1176e-01, 2.1263e-01, 2.2428e-06, 4.1799e-03, 3.4093e-07, 9.4691e-03,
        4.3820e-02, 5.5407e-01, 6.4066e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,859][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0015, 0.2684, 0.0289, 0.1114, 0.0433, 0.0578, 0.0307, 0.1869, 0.2712],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,860][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.6058, 0.2084, 0.0373, 0.0243, 0.0167, 0.0113, 0.0189, 0.0377, 0.0395],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,860][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0116, 0.2917, 0.0710, 0.0409, 0.1435, 0.1303, 0.0202, 0.1950, 0.0958],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,861][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.3299e-03, 6.6312e-01, 8.6766e-07, 2.3220e-03, 1.8018e-08, 1.1756e-03,
        1.7427e-02, 2.7497e-01, 3.8652e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,861][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0731, 0.0316, 0.7733, 0.0023, 0.0284, 0.0194, 0.0454, 0.0169, 0.0097],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,861][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0357, 0.2281, 0.0684, 0.1120, 0.0875, 0.1030, 0.0551, 0.2235, 0.0867],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:20,862][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0007, 0.2029, 0.0104, 0.0471, 0.0049, 0.0363, 0.0560, 0.1848, 0.2302,
        0.2269], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,862][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ station] are: tensor([2.1900e-05, 1.4595e-01, 7.6245e-02, 9.7109e-02, 1.2503e-01, 3.9447e-02,
        4.0922e-02, 1.3343e-01, 2.1171e-01, 1.3013e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,863][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0040, 0.3804, 0.0637, 0.1010, 0.0476, 0.0437, 0.0274, 0.1800, 0.1043,
        0.0478], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,866][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0372, 0.2094, 0.0381, 0.0980, 0.0308, 0.0508, 0.0405, 0.1592, 0.1416,
        0.1944], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,867][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ station] are: tensor([6.8285e-01, 2.1080e-01, 6.6297e-04, 2.9707e-02, 5.7671e-04, 1.6415e-02,
        5.0817e-03, 4.2478e-02, 6.0717e-03, 5.3565e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,869][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ station] are: tensor([9.3529e-02, 1.9528e-01, 9.8587e-07, 2.2533e-03, 7.6145e-08, 2.2086e-03,
        1.9313e-02, 3.2592e-01, 4.1653e-02, 3.1984e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,873][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0007, 0.2908, 0.0166, 0.0853, 0.0320, 0.0483, 0.0345, 0.1425, 0.2369,
        0.1123], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,873][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.4472, 0.1937, 0.0437, 0.0336, 0.0315, 0.0143, 0.0324, 0.0640, 0.0658,
        0.0737], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,874][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0037, 0.1102, 0.0487, 0.0478, 0.1845, 0.1390, 0.0189, 0.2089, 0.1033,
        0.1351], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,874][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ station] are: tensor([2.0621e-03, 6.0504e-01, 2.9311e-07, 1.4622e-03, 2.5129e-09, 7.3850e-04,
        6.1311e-03, 2.1111e-01, 3.5615e-02, 1.3785e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,874][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0382, 0.0361, 0.7972, 0.0024, 0.0263, 0.0191, 0.0434, 0.0183, 0.0098,
        0.0092], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,875][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0005, 0.4578, 0.0335, 0.0773, 0.0284, 0.0507, 0.0505, 0.1213, 0.1105,
        0.0696], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:20,875][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0031, 0.1446, 0.0166, 0.0317, 0.0067, 0.0309, 0.0298, 0.1665, 0.1455,
        0.2030, 0.2217], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,876][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.2436e-04, 6.8774e-02, 1.0704e-01, 5.6993e-02, 1.4211e-01, 3.3092e-02,
        2.6457e-02, 9.5113e-02, 2.2780e-01, 2.0519e-01, 3.7203e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,877][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0212, 0.1958, 0.1056, 0.0701, 0.0465, 0.0385, 0.0242, 0.1329, 0.0807,
        0.0413, 0.2432], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,880][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0987, 0.0666, 0.0291, 0.0396, 0.0375, 0.0411, 0.0263, 0.0933, 0.0973,
        0.1136, 0.3568], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,882][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([8.0862e-01, 1.0746e-01, 7.5835e-04, 2.2193e-02, 6.2573e-04, 1.2922e-02,
        2.6538e-03, 2.3384e-02, 5.2857e-03, 5.7302e-03, 1.0366e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,884][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([3.5554e-01, 1.2057e-01, 3.0401e-06, 1.1288e-03, 4.8606e-07, 2.3884e-03,
        9.8289e-03, 1.0750e-01, 2.1964e-02, 1.0629e-01, 2.7478e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,886][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0033, 0.1435, 0.0222, 0.0588, 0.0319, 0.0459, 0.0173, 0.1136, 0.1951,
        0.1147, 0.2538], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,887][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.6191, 0.1036, 0.0394, 0.0214, 0.0260, 0.0102, 0.0196, 0.0321, 0.0341,
        0.0400, 0.0547], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,887][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0128, 0.1245, 0.0493, 0.0314, 0.1724, 0.1507, 0.0166, 0.1609, 0.0852,
        0.1631, 0.0332], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,888][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([7.7786e-03, 6.6966e-01, 1.5945e-06, 1.2171e-03, 3.0809e-08, 8.5625e-04,
        3.0884e-03, 8.0762e-02, 1.8832e-02, 2.3843e-02, 1.9396e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,888][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1223, 0.0211, 0.7599, 0.0013, 0.0250, 0.0168, 0.0275, 0.0112, 0.0059,
        0.0062, 0.0029], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,888][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0085, 0.2253, 0.0462, 0.0570, 0.0514, 0.0785, 0.0402, 0.1519, 0.0841,
        0.0685, 0.1884], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:20,889][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([1.6780e-04, 8.7150e-02, 6.1561e-03, 1.8959e-02, 1.7487e-03, 2.6113e-02,
        2.6542e-02, 1.8507e-01, 1.7288e-01, 1.7872e-01, 1.3146e-01, 1.6504e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,889][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([1.2540e-05, 8.2202e-02, 7.2903e-02, 4.1565e-02, 6.5331e-02, 3.2674e-02,
        2.9493e-02, 8.1479e-02, 2.1474e-01, 1.6349e-01, 2.3368e-02, 1.9274e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,891][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.0018, 0.2363, 0.0592, 0.0833, 0.0237, 0.0445, 0.0323, 0.1575, 0.0779,
        0.0492, 0.1900, 0.0442], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,893][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.0018, 0.0826, 0.0214, 0.0438, 0.0156, 0.0402, 0.0316, 0.0987, 0.1133,
        0.1294, 0.2275, 0.1943], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,897][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.2741, 0.3290, 0.0017, 0.1121, 0.0022, 0.0404, 0.0178, 0.1063, 0.0230,
        0.0293, 0.0493, 0.0149], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,899][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([3.0380e-04, 4.6764e-03, 4.3103e-07, 7.8559e-04, 9.9993e-08, 1.3495e-03,
        1.9343e-02, 9.4036e-02, 1.6222e-02, 6.3778e-01, 2.2449e-01, 1.0145e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,900][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([9.4807e-05, 1.7641e-01, 9.5819e-03, 4.6381e-02, 1.1191e-02, 3.5454e-02,
        1.9040e-02, 1.3689e-01, 1.9331e-01, 8.9104e-02, 1.7866e-01, 1.0388e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,900][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0761, 0.1746, 0.0621, 0.0434, 0.0239, 0.0359, 0.0585, 0.1406, 0.1073,
        0.1183, 0.1115, 0.0479], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,901][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0017, 0.1033, 0.0493, 0.0254, 0.1487, 0.1064, 0.0159, 0.1439, 0.0851,
        0.1509, 0.0364, 0.1330], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,901][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([5.6602e-06, 2.2055e-02, 3.1552e-07, 1.4294e-03, 6.2596e-09, 7.8205e-04,
        1.5105e-02, 1.4477e-01, 2.3018e-02, 3.8019e-01, 4.1237e-01, 2.7731e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,901][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0267, 0.0377, 0.6900, 0.0036, 0.0197, 0.0444, 0.0982, 0.0242, 0.0137,
        0.0177, 0.0050, 0.0191], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,902][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([1.7426e-04, 3.5517e-01, 3.0684e-02, 5.7792e-02, 2.1842e-02, 6.6619e-02,
        3.9204e-02, 1.5967e-01, 6.7596e-02, 4.4678e-02, 1.0329e-01, 5.3284e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:20,902][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0003, 0.1093, 0.0112, 0.0154, 0.0028, 0.0209, 0.0241, 0.1067, 0.1377,
        0.1170, 0.1270, 0.1444, 0.1833], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,903][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([6.1038e-05, 7.5714e-02, 7.1473e-02, 4.5895e-02, 8.1914e-02, 3.5429e-02,
        3.4514e-02, 1.0285e-01, 1.7208e-01, 7.5461e-02, 3.6240e-02, 2.2965e-01,
        3.8726e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,904][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0031, 0.2244, 0.0507, 0.0835, 0.0216, 0.0378, 0.0323, 0.1324, 0.0824,
        0.0376, 0.2181, 0.0385, 0.0378], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,907][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([0.0096, 0.1461, 0.0233, 0.0473, 0.0130, 0.0452, 0.0360, 0.0871, 0.1071,
        0.0796, 0.2714, 0.0944, 0.0399], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,909][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([6.4191e-01, 1.6331e-01, 8.0079e-04, 3.6603e-02, 6.0907e-04, 2.4671e-02,
        7.3958e-03, 4.7329e-02, 1.1406e-02, 1.6819e-02, 2.7124e-02, 6.8422e-03,
        1.5178e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,911][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([1.8295e-02, 4.7966e-02, 4.8518e-07, 1.3664e-03, 8.5251e-08, 2.1657e-03,
        1.9369e-02, 1.7649e-01, 2.0108e-02, 3.8692e-01, 2.7529e-01, 1.1868e-03,
        5.0841e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,913][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0004, 0.1798, 0.0139, 0.0581, 0.0146, 0.0417, 0.0299, 0.1213, 0.1924,
        0.0744, 0.1596, 0.0784, 0.0354], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,914][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.3450, 0.1796, 0.0282, 0.0254, 0.0210, 0.0122, 0.0391, 0.0490, 0.0676,
        0.0644, 0.0866, 0.0369, 0.0448], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,914][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0031, 0.0862, 0.0356, 0.0280, 0.1179, 0.0922, 0.0220, 0.1891, 0.1042,
        0.1045, 0.0590, 0.0958, 0.0622], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,914][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([6.4683e-05, 3.6432e-01, 2.4449e-07, 9.3397e-04, 2.4188e-09, 4.6734e-04,
        5.3843e-03, 1.2869e-01, 3.0055e-02, 1.1212e-01, 3.4782e-01, 1.5084e-04,
        9.9979e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,915][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.0639, 0.0684, 0.6151, 0.0032, 0.0253, 0.0321, 0.0682, 0.0265, 0.0190,
        0.0131, 0.0082, 0.0193, 0.0377], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,915][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([0.0015, 0.2412, 0.0281, 0.0653, 0.0211, 0.0688, 0.0467, 0.1028, 0.0725,
        0.0510, 0.2048, 0.0380, 0.0583], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:20,916][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0019, 0.0782, 0.0091, 0.0155, 0.0044, 0.0164, 0.0177, 0.0676, 0.1018,
        0.1260, 0.1093, 0.1196, 0.1199, 0.2126], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,916][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.2566e-04, 2.8329e-02, 7.3408e-02, 3.4072e-02, 1.0937e-01, 1.7903e-02,
        1.7523e-02, 4.7001e-02, 1.0750e-01, 8.8141e-02, 1.7508e-02, 2.3892e-01,
        2.4770e-02, 1.9544e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,918][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0283, 0.1200, 0.1400, 0.0757, 0.0573, 0.0365, 0.0243, 0.1055, 0.0501,
        0.0246, 0.1403, 0.0534, 0.0231, 0.1210], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,920][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1214, 0.0353, 0.0190, 0.0227, 0.0206, 0.0231, 0.0231, 0.0433, 0.0608,
        0.0609, 0.1810, 0.1341, 0.0346, 0.2200], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,923][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.0757e-01, 3.7407e-02, 2.9666e-04, 1.0474e-02, 2.6569e-04, 4.9525e-03,
        1.1644e-03, 1.1897e-02, 2.1351e-03, 3.2547e-03, 6.4504e-03, 2.4144e-03,
        2.7822e-03, 8.9314e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,925][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.0149e-01, 9.5499e-03, 3.4309e-07, 1.7069e-04, 4.6457e-08, 3.4240e-04,
        1.6227e-03, 2.2364e-02, 2.0522e-03, 3.0705e-02, 7.1774e-02, 1.2475e-04,
        4.1372e-03, 3.5567e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,927][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0030, 0.1526, 0.0171, 0.0508, 0.0260, 0.0298, 0.0150, 0.0725, 0.1285,
        0.0735, 0.1542, 0.0946, 0.0222, 0.1604], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,927][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5858, 0.0913, 0.0239, 0.0156, 0.0194, 0.0069, 0.0236, 0.0211, 0.0247,
        0.0382, 0.0283, 0.0203, 0.0146, 0.0862], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,927][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0086, 0.0819, 0.0491, 0.0258, 0.1220, 0.1066, 0.0139, 0.1141, 0.0694,
        0.0857, 0.0345, 0.0675, 0.0442, 0.1767], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,928][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.4745e-02, 1.4002e-01, 4.8098e-07, 2.6979e-04, 4.8012e-09, 2.0667e-04,
        1.0110e-03, 2.4937e-02, 2.9310e-03, 1.4397e-02, 1.3467e-01, 2.3167e-05,
        1.5130e-03, 6.6527e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,928][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1725, 0.0207, 0.6664, 0.0017, 0.0213, 0.0110, 0.0283, 0.0076, 0.0047,
        0.0042, 0.0022, 0.0077, 0.0101, 0.0416], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,929][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0067, 0.0915, 0.0183, 0.0410, 0.0224, 0.0616, 0.0370, 0.1037, 0.0450,
        0.0470, 0.1365, 0.0461, 0.0609, 0.2823], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:20,929][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0003, 0.0519, 0.0071, 0.0123, 0.0022, 0.0151, 0.0194, 0.0593, 0.0795,
        0.0712, 0.0857, 0.0781, 0.1075, 0.1941, 0.2164], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,930][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([5.7768e-05, 3.6628e-02, 7.2432e-02, 3.2829e-02, 9.3798e-02, 2.2328e-02,
        1.8814e-02, 5.5109e-02, 9.8461e-02, 8.4338e-02, 1.8609e-02, 2.0503e-01,
        2.4393e-02, 1.8852e-01, 4.8654e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,931][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0049, 0.1056, 0.0848, 0.0673, 0.0423, 0.0295, 0.0199, 0.0816, 0.0470,
        0.0252, 0.1476, 0.0611, 0.0285, 0.1244, 0.1303], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,934][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0132, 0.0242, 0.0162, 0.0195, 0.0154, 0.0149, 0.0168, 0.0598, 0.0589,
        0.0592, 0.1402, 0.1252, 0.0236, 0.2458, 0.1671], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,938][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.5622, 0.0791, 0.0016, 0.0480, 0.0014, 0.0249, 0.0062, 0.0485, 0.0110,
        0.0147, 0.0346, 0.0150, 0.0130, 0.0523, 0.0874], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,940][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([2.1991e-02, 5.1712e-03, 9.9052e-08, 1.6039e-04, 1.3845e-08, 3.3798e-04,
        2.3219e-03, 2.3442e-02, 3.7302e-03, 7.8582e-02, 9.4400e-02, 1.6223e-04,
        6.7131e-03, 7.0482e-01, 5.8167e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,940][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0008, 0.1263, 0.0274, 0.0482, 0.0277, 0.0308, 0.0192, 0.0669, 0.1226,
        0.0641, 0.1015, 0.0896, 0.0216, 0.1715, 0.0817], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,941][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.1220, 0.1461, 0.0705, 0.0294, 0.0319, 0.0131, 0.0342, 0.0608, 0.0673,
        0.0833, 0.0630, 0.0403, 0.0264, 0.1895, 0.0222], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,941][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0029, 0.0504, 0.0448, 0.0267, 0.1247, 0.0733, 0.0207, 0.1331, 0.0537,
        0.0764, 0.0304, 0.0929, 0.0411, 0.1292, 0.0997], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,942][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.2427e-04, 2.6280e-02, 5.2039e-08, 1.1055e-04, 3.9524e-10, 7.4989e-05,
        6.9392e-04, 1.5973e-02, 3.0707e-03, 1.9983e-02, 1.0187e-01, 1.1570e-05,
        1.4106e-03, 8.1196e-01, 1.8437e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,942][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0393, 0.0260, 0.6317, 0.0030, 0.0269, 0.0201, 0.0466, 0.0156, 0.0094,
        0.0094, 0.0040, 0.0148, 0.0251, 0.0855, 0.0426], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,942][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0019, 0.0963, 0.0181, 0.0392, 0.0114, 0.0509, 0.0476, 0.0880, 0.0525,
        0.0573, 0.1526, 0.0276, 0.0443, 0.2272, 0.0850], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:20,943][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0006, 0.0599, 0.0052, 0.0091, 0.0023, 0.0148, 0.0199, 0.0714, 0.0669,
        0.0833, 0.0617, 0.0805, 0.1113, 0.1692, 0.2122, 0.0318],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,944][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.9181e-05, 4.4272e-02, 7.4200e-02, 3.0167e-02, 9.8271e-02, 2.1469e-02,
        2.3930e-02, 5.4300e-02, 9.1252e-02, 8.4233e-02, 1.3151e-02, 2.1027e-01,
        2.1310e-02, 1.2169e-01, 5.5646e-02, 5.5738e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,946][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0068, 0.1320, 0.1010, 0.0748, 0.0477, 0.0302, 0.0214, 0.0949, 0.0484,
        0.0254, 0.1286, 0.0608, 0.0212, 0.0920, 0.0874, 0.0274],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,949][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0142, 0.0651, 0.0128, 0.0341, 0.0126, 0.0263, 0.0233, 0.0675, 0.0557,
        0.0550, 0.1547, 0.0916, 0.0293, 0.1816, 0.1023, 0.0738],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,953][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6708, 0.0940, 0.0008, 0.0330, 0.0010, 0.0230, 0.0033, 0.0355, 0.0063,
        0.0088, 0.0185, 0.0107, 0.0096, 0.0270, 0.0530, 0.0048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,954][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.4339e-03, 5.1008e-03, 6.6823e-08, 2.6206e-04, 1.0041e-08, 3.3811e-04,
        3.2210e-03, 3.1497e-02, 2.7686e-03, 6.8858e-02, 5.2219e-02, 1.3763e-04,
        6.3566e-03, 7.4260e-01, 8.0090e-02, 2.1177e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,954][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0015, 0.1312, 0.0158, 0.0450, 0.0306, 0.0314, 0.0211, 0.0890, 0.1172,
        0.0665, 0.0997, 0.1031, 0.0198, 0.1208, 0.0627, 0.0446],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,954][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4156, 0.1811, 0.0308, 0.0209, 0.0208, 0.0099, 0.0305, 0.0242, 0.0339,
        0.0489, 0.0368, 0.0203, 0.0134, 0.0734, 0.0087, 0.0310],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,955][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0074, 0.0613, 0.0585, 0.0270, 0.1158, 0.0821, 0.0121, 0.1121, 0.0668,
        0.0991, 0.0250, 0.0833, 0.0249, 0.1103, 0.0690, 0.0454],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,955][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.5058e-05, 2.0057e-02, 2.7317e-08, 1.3604e-04, 4.5543e-10, 7.6284e-05,
        9.7993e-04, 1.8939e-02, 1.7694e-03, 2.2918e-02, 4.0526e-02, 1.8743e-05,
        1.6464e-03, 8.5779e-01, 3.4008e-02, 1.0885e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,956][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0597, 0.0260, 0.5577, 0.0024, 0.0319, 0.0213, 0.0471, 0.0147, 0.0092,
        0.0086, 0.0037, 0.0163, 0.0164, 0.0587, 0.0402, 0.0861],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,956][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0091, 0.1049, 0.0125, 0.0258, 0.0143, 0.0753, 0.0569, 0.1003, 0.0318,
        0.0465, 0.1042, 0.0373, 0.0411, 0.1881, 0.0822, 0.0698],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:20,958][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0003, 0.0409, 0.0039, 0.0105, 0.0015, 0.0057, 0.0094, 0.0611, 0.0548,
        0.0694, 0.0611, 0.0675, 0.0528, 0.1567, 0.1517, 0.0263, 0.2266],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,960][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([1.2418e-05, 4.7621e-02, 5.6076e-02, 3.1185e-02, 7.2939e-02, 1.5361e-02,
        2.2820e-02, 4.9174e-02, 9.5988e-02, 5.0540e-02, 1.3387e-02, 1.3133e-01,
        1.2488e-02, 1.0962e-01, 5.1859e-02, 8.7349e-02, 1.5226e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,962][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0032, 0.1468, 0.0507, 0.0625, 0.0310, 0.0253, 0.0173, 0.0771, 0.0459,
        0.0328, 0.1453, 0.0394, 0.0207, 0.0992, 0.0959, 0.0488, 0.0582],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,966][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0121, 0.0339, 0.0131, 0.0220, 0.0103, 0.0131, 0.0167, 0.0481, 0.0373,
        0.0684, 0.1155, 0.0790, 0.0191, 0.1810, 0.1517, 0.1046, 0.0741],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,967][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([7.2192e-01, 5.8835e-02, 2.7531e-04, 2.3791e-02, 3.7890e-04, 1.4543e-02,
        3.5789e-03, 3.1937e-02, 3.3812e-03, 7.8089e-03, 1.0807e-02, 5.1504e-03,
        6.7924e-03, 2.5016e-02, 5.9033e-02, 3.9630e-03, 2.2792e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,967][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([2.0323e-03, 3.3067e-03, 1.4024e-08, 7.5463e-05, 1.5740e-09, 9.5440e-05,
        1.1674e-03, 1.8457e-02, 7.6763e-04, 3.0084e-02, 2.4411e-02, 4.3588e-05,
        2.0771e-03, 8.6619e-01, 3.9842e-02, 8.4451e-04, 1.0602e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,968][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0002, 0.1471, 0.0119, 0.0431, 0.0146, 0.0151, 0.0164, 0.0678, 0.0846,
        0.0469, 0.0789, 0.0619, 0.0114, 0.1334, 0.0476, 0.0495, 0.1694],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,968][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.4418, 0.1199, 0.0202, 0.0198, 0.0109, 0.0088, 0.0261, 0.0266, 0.0345,
        0.0421, 0.0452, 0.0179, 0.0123, 0.1036, 0.0142, 0.0287, 0.0274],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,969][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0037, 0.0429, 0.0243, 0.0206, 0.1078, 0.0727, 0.0125, 0.0893, 0.0619,
        0.0664, 0.0351, 0.0870, 0.0463, 0.1085, 0.0933, 0.0826, 0.0452],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,969][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([9.7834e-06, 1.1182e-02, 3.2600e-09, 3.4238e-05, 3.0432e-11, 1.4957e-05,
        2.5070e-04, 1.0803e-02, 3.6305e-04, 6.5631e-03, 1.6935e-02, 3.2485e-06,
        1.9875e-04, 9.3784e-01, 1.3046e-02, 3.9277e-04, 2.3617e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,970][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0357, 0.0338, 0.5355, 0.0023, 0.0220, 0.0179, 0.0448, 0.0163, 0.0094,
        0.0093, 0.0032, 0.0106, 0.0106, 0.0665, 0.0381, 0.1390, 0.0048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,971][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0005, 0.1418, 0.0203, 0.0580, 0.0173, 0.0309, 0.0275, 0.0810, 0.0440,
        0.0329, 0.1404, 0.0293, 0.0151, 0.1642, 0.0449, 0.0798, 0.0723],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:20,974][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0004, 0.0322, 0.0027, 0.0075, 0.0018, 0.0091, 0.0110, 0.0384, 0.0495,
        0.0775, 0.0525, 0.0691, 0.0648, 0.1290, 0.1584, 0.0259, 0.2310, 0.0394],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,976][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.6528e-05, 2.2911e-02, 4.0912e-02, 2.3744e-02, 7.2117e-02, 1.4122e-02,
        1.6477e-02, 2.9790e-02, 6.7168e-02, 6.8461e-02, 1.0034e-02, 1.5288e-01,
        1.4626e-02, 1.3575e-01, 4.8224e-02, 7.0777e-02, 1.0731e-01, 1.0464e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,980][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0171, 0.1042, 0.0738, 0.0814, 0.0502, 0.0292, 0.0220, 0.0836, 0.0336,
        0.0163, 0.1163, 0.0513, 0.0172, 0.0952, 0.0923, 0.0336, 0.0284, 0.0542],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,980][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0456, 0.0325, 0.0083, 0.0235, 0.0110, 0.0166, 0.0172, 0.0364, 0.0404,
        0.0395, 0.1410, 0.0843, 0.0219, 0.1815, 0.0885, 0.0822, 0.0419, 0.0876],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,981][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.5437e-01, 4.4139e-02, 4.2943e-04, 2.1952e-02, 4.7525e-04, 1.1056e-02,
        2.1496e-03, 2.2960e-02, 3.5410e-03, 6.4089e-03, 1.2401e-02, 5.9733e-03,
        4.8709e-03, 2.2454e-02, 4.7354e-02, 5.2123e-03, 2.6064e-02, 8.1881e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,981][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.9675e-02, 2.2520e-03, 5.4430e-08, 1.3166e-04, 8.4339e-09, 2.1055e-04,
        2.1497e-03, 2.3637e-02, 1.9421e-03, 7.6216e-02, 7.3197e-02, 9.8876e-05,
        5.4815e-03, 7.1349e-01, 5.8730e-02, 1.8504e-03, 1.2611e-02, 8.3307e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,982][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0022, 0.1158, 0.0116, 0.0421, 0.0218, 0.0223, 0.0142, 0.0511, 0.0781,
        0.0509, 0.0914, 0.0660, 0.0120, 0.1111, 0.0454, 0.0539, 0.1686, 0.0415],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,982][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5091, 0.1022, 0.0185, 0.0135, 0.0131, 0.0067, 0.0232, 0.0188, 0.0225,
        0.0383, 0.0294, 0.0159, 0.0117, 0.0782, 0.0069, 0.0245, 0.0124, 0.0551],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,983][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0083, 0.0555, 0.0297, 0.0185, 0.0936, 0.0806, 0.0083, 0.0646, 0.0486,
        0.0575, 0.0226, 0.0499, 0.0294, 0.1411, 0.0659, 0.0722, 0.0318, 0.1220],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,983][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.8710e-04, 1.1724e-02, 1.6256e-08, 5.7763e-05, 2.2855e-10, 5.1647e-05,
        5.5571e-04, 1.2574e-02, 1.5674e-03, 2.4398e-02, 7.1356e-02, 1.0348e-05,
        1.0332e-03, 8.4019e-01, 2.6421e-02, 7.1624e-04, 2.7942e-03, 6.3636e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,985][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1729, 0.0188, 0.5048, 0.0017, 0.0216, 0.0146, 0.0372, 0.0082, 0.0045,
        0.0055, 0.0020, 0.0099, 0.0112, 0.0493, 0.0326, 0.0815, 0.0031, 0.0205],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:20,987][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0052, 0.0617, 0.0077, 0.0271, 0.0062, 0.0377, 0.0285, 0.0614, 0.0197,
        0.0268, 0.0893, 0.0190, 0.0249, 0.2316, 0.0448, 0.0489, 0.0522, 0.2073],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,023][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:21,025][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,027][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,030][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,032][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,033][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,033][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,033][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,034][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,034][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,034][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,035][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,035][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,037][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2463, 0.7537], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,039][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0202, 0.9798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,043][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4750, 0.5250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,046][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9724, 0.0276], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,046][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,046][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9855, 0.0145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,047][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5777, 0.4223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,047][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9804, 0.0196], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,047][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3257, 0.6743], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,047][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8287, 0.1713], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,048][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9908, 0.0092], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,048][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9988e-01, 1.1646e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,048][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.0056, 0.9138, 0.0806], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,049][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([4.4069e-05, 6.2602e-01, 3.7394e-01], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,052][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([0.0212, 0.6833, 0.2955], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,054][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.0780, 0.8055, 0.1166], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,058][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.4033, 0.5925, 0.0041], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,059][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.0156, 0.9826, 0.0019], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,059][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.0091, 0.8720, 0.1188], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,060][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.5704, 0.2785, 0.1511], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,060][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.0218, 0.7538, 0.2244], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,060][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([1.4626e-04, 9.9932e-01, 5.3619e-04], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,060][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.0554, 0.0765, 0.8682], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,061][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.0572, 0.7632, 0.1797], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,061][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0342, 0.4335, 0.0349, 0.4974], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,061][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0008, 0.2662, 0.2445, 0.4885], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,062][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0255, 0.4302, 0.3469, 0.1975], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,063][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5796, 0.1743, 0.0810, 0.1651], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,064][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([8.5528e-01, 1.0994e-01, 4.4291e-04, 3.4337e-02], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,066][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.9057e-01, 7.5669e-01, 1.4958e-04, 5.2588e-02], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,070][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0211, 0.5615, 0.0816, 0.3358], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,072][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6992, 0.1855, 0.0661, 0.0492], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,073][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0467, 0.5689, 0.2512, 0.1331], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,073][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.2483e-03, 9.7550e-01, 4.1308e-05, 1.9214e-02], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,073][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2863, 0.0329, 0.6768, 0.0041], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,074][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3896, 0.3006, 0.1082, 0.2016], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,074][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([4.3588e-04, 6.0483e-01, 4.6330e-02, 3.3494e-01, 1.3456e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,074][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([8.8174e-06, 5.1408e-01, 1.9648e-01, 1.9727e-01, 9.2165e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,075][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0019, 0.5956, 0.1581, 0.2065, 0.0378], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,075][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0050, 0.5276, 0.0818, 0.3081, 0.0776], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,075][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.1343, 0.5881, 0.0035, 0.2693, 0.0048], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,076][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([4.9128e-04, 3.1515e-01, 7.0787e-04, 6.8344e-01, 2.1180e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,078][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([8.7971e-05, 7.1950e-01, 3.5795e-02, 2.1237e-01, 3.2247e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,081][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.3018, 0.2918, 0.2130, 0.1377, 0.0557], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,084][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.0066, 0.5311, 0.0923, 0.0622, 0.3078], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,086][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([1.8820e-06, 2.8279e-01, 1.9134e-04, 7.1701e-01, 5.4476e-06],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,086][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0136, 0.0811, 0.8789, 0.0081, 0.0183], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,087][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([6.2063e-04, 7.0525e-01, 9.4076e-02, 1.4188e-01, 5.8167e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,087][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0025, 0.6562, 0.0249, 0.0834, 0.0068, 0.2263], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,087][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([1.1910e-04, 3.6632e-01, 1.8159e-01, 2.1926e-01, 1.0317e-01, 1.2953e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,087][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0044, 0.6017, 0.1445, 0.1486, 0.0203, 0.0804], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,088][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1003, 0.4936, 0.0512, 0.1354, 0.0365, 0.1830], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,088][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([8.1989e-01, 1.4661e-01, 3.7067e-04, 2.1775e-02, 3.3276e-04, 1.1021e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,088][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([4.0256e-02, 8.1751e-01, 4.7048e-05, 4.3238e-02, 8.0275e-06, 9.8936e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,089][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0016, 0.6624, 0.0295, 0.1180, 0.0316, 0.1569], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,090][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.6848, 0.1661, 0.0612, 0.0423, 0.0238, 0.0218], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,093][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0252, 0.4281, 0.0805, 0.0711, 0.1542, 0.2408], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,095][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([6.6528e-05, 9.8393e-01, 9.2456e-06, 9.6505e-03, 8.8523e-08, 6.3455e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,099][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.1125, 0.0867, 0.7275, 0.0039, 0.0226, 0.0468], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,100][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0071, 0.5866, 0.0424, 0.0878, 0.0316, 0.2444], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,100][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0019, 0.4017, 0.0412, 0.1260, 0.0114, 0.1463, 0.2716],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,100][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([9.6677e-05, 2.1133e-01, 1.4684e-01, 2.2923e-01, 2.3803e-01, 1.1616e-01,
        5.8320e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,101][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0033, 0.4519, 0.1672, 0.2042, 0.0433, 0.0814, 0.0488],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,101][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([0.0928, 0.3194, 0.0620, 0.1583, 0.0680, 0.1679, 0.1317],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,101][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([6.4850e-01, 2.4711e-01, 6.0778e-04, 5.9224e-02, 1.0005e-03, 3.1279e-02,
        1.2282e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,102][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([1.1543e-01, 4.2028e-01, 1.3732e-05, 1.7684e-02, 1.5520e-06, 4.8729e-02,
        3.9786e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,102][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0013, 0.5298, 0.0297, 0.1431, 0.0656, 0.1390, 0.0914],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,102][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.7586, 0.1135, 0.0360, 0.0303, 0.0182, 0.0131, 0.0303],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,104][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0184, 0.2735, 0.0880, 0.0996, 0.2240, 0.2623, 0.0343],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,106][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([7.8573e-04, 8.7334e-01, 3.5915e-06, 6.9741e-03, 3.3552e-08, 8.4077e-03,
        1.1048e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,109][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.0237, 0.0550, 0.7382, 0.0048, 0.0427, 0.0518, 0.0838],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,113][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0110, 0.3001, 0.0779, 0.1415, 0.0547, 0.2475, 0.1672],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,113][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0012, 0.2645, 0.0313, 0.0766, 0.0138, 0.1078, 0.1241, 0.3808],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,113][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([5.3075e-05, 9.5546e-02, 1.9354e-01, 1.2984e-01, 2.7404e-01, 7.6998e-02,
        6.5964e-02, 1.6402e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,114][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0040, 0.1949, 0.2296, 0.1620, 0.0943, 0.0685, 0.0407, 0.2060],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,114][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0638, 0.1568, 0.0496, 0.1051, 0.0707, 0.1327, 0.1201, 0.3012],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,114][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([8.7132e-01, 4.6908e-02, 5.4445e-04, 2.4962e-02, 1.1261e-03, 1.5050e-02,
        4.4333e-03, 3.5657e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,115][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([4.6139e-01, 6.9765e-02, 1.1411e-05, 3.7397e-03, 2.6685e-06, 1.1042e-02,
        5.0767e-02, 4.0328e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,115][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0011, 0.3273, 0.0538, 0.0967, 0.0779, 0.1290, 0.0476, 0.2666],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,115][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.4738, 0.1921, 0.0828, 0.0455, 0.0552, 0.0278, 0.0363, 0.0866],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,117][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0151, 0.1347, 0.0997, 0.0751, 0.1545, 0.2395, 0.0257, 0.2557],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,119][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([7.6375e-02, 4.5812e-01, 1.6939e-05, 4.4471e-03, 3.4696e-07, 5.8315e-03,
        3.9078e-02, 4.1613e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,122][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0282, 0.0143, 0.8173, 0.0020, 0.0346, 0.0252, 0.0639, 0.0144],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,126][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0288, 0.1108, 0.0643, 0.0699, 0.0348, 0.1659, 0.0865, 0.4390],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,126][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0017, 0.2433, 0.0150, 0.0542, 0.0055, 0.0463, 0.0585, 0.3135, 0.2618],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,126][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.7454e-04, 1.1685e-01, 9.1550e-02, 1.0557e-01, 1.3812e-01, 4.4363e-02,
        4.2540e-02, 1.5187e-01, 3.0896e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,127][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0107, 0.2737, 0.1658, 0.1339, 0.0565, 0.0565, 0.0294, 0.1829, 0.0906],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,127][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0858, 0.2130, 0.0532, 0.0901, 0.0480, 0.0777, 0.0511, 0.1912, 0.1897],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,128][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([7.7883e-01, 1.4252e-01, 3.6503e-04, 2.3209e-02, 4.3873e-04, 1.4414e-02,
        2.5840e-03, 3.2044e-02, 5.5960e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,128][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.1176e-01, 2.1263e-01, 2.2428e-06, 4.1799e-03, 3.4093e-07, 9.4691e-03,
        4.3820e-02, 5.5407e-01, 6.4066e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,128][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0015, 0.2684, 0.0289, 0.1114, 0.0433, 0.0578, 0.0307, 0.1869, 0.2712],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,129][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.6058, 0.2084, 0.0373, 0.0243, 0.0167, 0.0113, 0.0189, 0.0377, 0.0395],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,129][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0116, 0.2917, 0.0710, 0.0409, 0.1435, 0.1303, 0.0202, 0.1950, 0.0958],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,130][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.3299e-03, 6.6312e-01, 8.6766e-07, 2.3220e-03, 1.8018e-08, 1.1756e-03,
        1.7427e-02, 2.7497e-01, 3.8652e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,133][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0731, 0.0316, 0.7733, 0.0023, 0.0284, 0.0194, 0.0454, 0.0169, 0.0097],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,135][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0357, 0.2281, 0.0684, 0.1120, 0.0875, 0.1030, 0.0551, 0.2235, 0.0867],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,139][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0007, 0.2029, 0.0104, 0.0471, 0.0049, 0.0363, 0.0560, 0.1848, 0.2302,
        0.2269], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,140][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([2.1900e-05, 1.4595e-01, 7.6245e-02, 9.7109e-02, 1.2503e-01, 3.9447e-02,
        4.0922e-02, 1.3343e-01, 2.1171e-01, 1.3013e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,140][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0040, 0.3804, 0.0637, 0.1010, 0.0476, 0.0437, 0.0274, 0.1800, 0.1043,
        0.0478], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,140][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0372, 0.2094, 0.0381, 0.0980, 0.0308, 0.0508, 0.0405, 0.1592, 0.1416,
        0.1944], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,141][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([6.8285e-01, 2.1080e-01, 6.6297e-04, 2.9707e-02, 5.7671e-04, 1.6415e-02,
        5.0817e-03, 4.2478e-02, 6.0717e-03, 5.3565e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,141][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([9.3529e-02, 1.9528e-01, 9.8587e-07, 2.2533e-03, 7.6145e-08, 2.2086e-03,
        1.9313e-02, 3.2592e-01, 4.1653e-02, 3.1984e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,142][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0007, 0.2908, 0.0166, 0.0853, 0.0320, 0.0483, 0.0345, 0.1425, 0.2369,
        0.1123], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,142][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.4472, 0.1937, 0.0437, 0.0336, 0.0315, 0.0143, 0.0324, 0.0640, 0.0658,
        0.0737], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,142][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0037, 0.1102, 0.0487, 0.0478, 0.1845, 0.1390, 0.0189, 0.2089, 0.1033,
        0.1351], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,143][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([2.0621e-03, 6.0504e-01, 2.9311e-07, 1.4622e-03, 2.5129e-09, 7.3850e-04,
        6.1311e-03, 2.1111e-01, 3.5615e-02, 1.3785e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,146][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0382, 0.0361, 0.7972, 0.0024, 0.0263, 0.0191, 0.0434, 0.0183, 0.0098,
        0.0092], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,149][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0005, 0.4578, 0.0335, 0.0773, 0.0284, 0.0507, 0.0505, 0.1213, 0.1105,
        0.0696], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,153][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0031, 0.1446, 0.0166, 0.0317, 0.0067, 0.0309, 0.0298, 0.1665, 0.1455,
        0.2030, 0.2217], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,153][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.2436e-04, 6.8774e-02, 1.0704e-01, 5.6993e-02, 1.4211e-01, 3.3092e-02,
        2.6457e-02, 9.5113e-02, 2.2780e-01, 2.0519e-01, 3.7203e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,154][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0212, 0.1958, 0.1056, 0.0701, 0.0465, 0.0385, 0.0242, 0.1329, 0.0807,
        0.0413, 0.2432], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,154][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0987, 0.0666, 0.0291, 0.0396, 0.0375, 0.0411, 0.0263, 0.0933, 0.0973,
        0.1136, 0.3568], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,154][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([8.0862e-01, 1.0746e-01, 7.5835e-04, 2.2193e-02, 6.2573e-04, 1.2922e-02,
        2.6538e-03, 2.3384e-02, 5.2857e-03, 5.7302e-03, 1.0366e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,155][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([3.5554e-01, 1.2057e-01, 3.0401e-06, 1.1288e-03, 4.8606e-07, 2.3884e-03,
        9.8289e-03, 1.0750e-01, 2.1964e-02, 1.0629e-01, 2.7478e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,155][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0033, 0.1435, 0.0222, 0.0588, 0.0319, 0.0459, 0.0173, 0.1136, 0.1951,
        0.1147, 0.2538], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,155][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.6191, 0.1036, 0.0394, 0.0214, 0.0260, 0.0102, 0.0196, 0.0321, 0.0341,
        0.0400, 0.0547], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,156][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0128, 0.1245, 0.0493, 0.0314, 0.1724, 0.1507, 0.0166, 0.1609, 0.0852,
        0.1631, 0.0332], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,157][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([7.7786e-03, 6.6966e-01, 1.5945e-06, 1.2171e-03, 3.0809e-08, 8.5625e-04,
        3.0884e-03, 8.0762e-02, 1.8832e-02, 2.3843e-02, 1.9396e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,159][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1223, 0.0211, 0.7599, 0.0013, 0.0250, 0.0168, 0.0275, 0.0112, 0.0059,
        0.0062, 0.0029], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,162][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0085, 0.2253, 0.0462, 0.0570, 0.0514, 0.0785, 0.0402, 0.1519, 0.0841,
        0.0685, 0.1884], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,164][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([1.6780e-04, 8.7150e-02, 6.1561e-03, 1.8959e-02, 1.7487e-03, 2.6113e-02,
        2.6542e-02, 1.8507e-01, 1.7288e-01, 1.7872e-01, 1.3146e-01, 1.6504e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,166][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([1.2540e-05, 8.2202e-02, 7.2903e-02, 4.1565e-02, 6.5331e-02, 3.2674e-02,
        2.9493e-02, 8.1479e-02, 2.1474e-01, 1.6349e-01, 2.3368e-02, 1.9274e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,167][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0018, 0.2363, 0.0592, 0.0833, 0.0237, 0.0445, 0.0323, 0.1575, 0.0779,
        0.0492, 0.1900, 0.0442], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,167][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.0018, 0.0826, 0.0214, 0.0438, 0.0156, 0.0402, 0.0316, 0.0987, 0.1133,
        0.1294, 0.2275, 0.1943], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,167][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.2741, 0.3290, 0.0017, 0.1121, 0.0022, 0.0404, 0.0178, 0.1063, 0.0230,
        0.0293, 0.0493, 0.0149], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,168][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([3.0380e-04, 4.6764e-03, 4.3103e-07, 7.8559e-04, 9.9993e-08, 1.3495e-03,
        1.9343e-02, 9.4036e-02, 1.6222e-02, 6.3778e-01, 2.2449e-01, 1.0145e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,168][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([9.4807e-05, 1.7641e-01, 9.5819e-03, 4.6381e-02, 1.1191e-02, 3.5454e-02,
        1.9040e-02, 1.3689e-01, 1.9331e-01, 8.9104e-02, 1.7866e-01, 1.0388e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,168][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0761, 0.1746, 0.0621, 0.0434, 0.0239, 0.0359, 0.0585, 0.1406, 0.1073,
        0.1183, 0.1115, 0.0479], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,169][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.0017, 0.1033, 0.0493, 0.0254, 0.1487, 0.1064, 0.0159, 0.1439, 0.0851,
        0.1509, 0.0364, 0.1330], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,169][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([5.6602e-06, 2.2055e-02, 3.1552e-07, 1.4294e-03, 6.2596e-09, 7.8205e-04,
        1.5105e-02, 1.4477e-01, 2.3018e-02, 3.8019e-01, 4.1237e-01, 2.7731e-04],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,171][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0267, 0.0377, 0.6900, 0.0036, 0.0197, 0.0444, 0.0982, 0.0242, 0.0137,
        0.0177, 0.0050, 0.0191], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,173][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([1.7426e-04, 3.5517e-01, 3.0684e-02, 5.7792e-02, 2.1842e-02, 6.6619e-02,
        3.9204e-02, 1.5967e-01, 6.7596e-02, 4.4678e-02, 1.0329e-01, 5.3284e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,176][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0003, 0.1093, 0.0112, 0.0154, 0.0028, 0.0209, 0.0241, 0.1067, 0.1377,
        0.1170, 0.1270, 0.1444, 0.1833], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,178][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([6.1038e-05, 7.5714e-02, 7.1473e-02, 4.5895e-02, 8.1914e-02, 3.5429e-02,
        3.4514e-02, 1.0285e-01, 1.7208e-01, 7.5461e-02, 3.6240e-02, 2.2965e-01,
        3.8726e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,180][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0031, 0.2244, 0.0507, 0.0835, 0.0216, 0.0378, 0.0323, 0.1324, 0.0824,
        0.0376, 0.2181, 0.0385, 0.0378], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,180][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([0.0096, 0.1461, 0.0233, 0.0473, 0.0130, 0.0452, 0.0360, 0.0871, 0.1071,
        0.0796, 0.2714, 0.0944, 0.0399], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,181][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([6.4191e-01, 1.6331e-01, 8.0079e-04, 3.6603e-02, 6.0907e-04, 2.4671e-02,
        7.3958e-03, 4.7329e-02, 1.1406e-02, 1.6819e-02, 2.7124e-02, 6.8422e-03,
        1.5178e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,181][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([1.8295e-02, 4.7966e-02, 4.8518e-07, 1.3664e-03, 8.5251e-08, 2.1657e-03,
        1.9369e-02, 1.7649e-01, 2.0108e-02, 3.8692e-01, 2.7529e-01, 1.1868e-03,
        5.0841e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,181][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0004, 0.1798, 0.0139, 0.0581, 0.0146, 0.0417, 0.0299, 0.1213, 0.1924,
        0.0744, 0.1596, 0.0784, 0.0354], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,182][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.3450, 0.1796, 0.0282, 0.0254, 0.0210, 0.0122, 0.0391, 0.0490, 0.0676,
        0.0644, 0.0866, 0.0369, 0.0448], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,182][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0031, 0.0862, 0.0356, 0.0280, 0.1179, 0.0922, 0.0220, 0.1891, 0.1042,
        0.1045, 0.0590, 0.0958, 0.0622], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,182][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([6.4683e-05, 3.6432e-01, 2.4449e-07, 9.3397e-04, 2.4188e-09, 4.6734e-04,
        5.3843e-03, 1.2869e-01, 3.0055e-02, 1.1212e-01, 3.4782e-01, 1.5084e-04,
        9.9979e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,183][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.0639, 0.0684, 0.6151, 0.0032, 0.0253, 0.0321, 0.0682, 0.0265, 0.0190,
        0.0131, 0.0082, 0.0193, 0.0377], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,184][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([0.0015, 0.2412, 0.0281, 0.0653, 0.0211, 0.0688, 0.0467, 0.1028, 0.0725,
        0.0510, 0.2048, 0.0380, 0.0583], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,188][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0019, 0.0782, 0.0091, 0.0155, 0.0044, 0.0164, 0.0177, 0.0676, 0.1018,
        0.1260, 0.1093, 0.1196, 0.1199, 0.2126], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,189][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.2566e-04, 2.8329e-02, 7.3408e-02, 3.4072e-02, 1.0937e-01, 1.7903e-02,
        1.7523e-02, 4.7001e-02, 1.0750e-01, 8.8141e-02, 1.7508e-02, 2.3892e-01,
        2.4770e-02, 1.9544e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,193][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0283, 0.1200, 0.1400, 0.0757, 0.0573, 0.0365, 0.0243, 0.1055, 0.0501,
        0.0246, 0.1403, 0.0534, 0.0231, 0.1210], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,195][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1214, 0.0353, 0.0190, 0.0227, 0.0206, 0.0231, 0.0231, 0.0433, 0.0608,
        0.0609, 0.1810, 0.1341, 0.0346, 0.2200], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,196][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.0757e-01, 3.7407e-02, 2.9666e-04, 1.0474e-02, 2.6569e-04, 4.9525e-03,
        1.1644e-03, 1.1897e-02, 2.1351e-03, 3.2547e-03, 6.4504e-03, 2.4144e-03,
        2.7822e-03, 8.9314e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,196][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.0149e-01, 9.5499e-03, 3.4309e-07, 1.7069e-04, 4.6457e-08, 3.4240e-04,
        1.6227e-03, 2.2364e-02, 2.0522e-03, 3.0705e-02, 7.1774e-02, 1.2475e-04,
        4.1372e-03, 3.5567e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,197][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0030, 0.1526, 0.0171, 0.0508, 0.0260, 0.0298, 0.0150, 0.0725, 0.1285,
        0.0735, 0.1542, 0.0946, 0.0222, 0.1604], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,197][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.5858, 0.0913, 0.0239, 0.0156, 0.0194, 0.0069, 0.0236, 0.0211, 0.0247,
        0.0382, 0.0283, 0.0203, 0.0146, 0.0862], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,197][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0086, 0.0819, 0.0491, 0.0258, 0.1220, 0.1066, 0.0139, 0.1141, 0.0694,
        0.0857, 0.0345, 0.0675, 0.0442, 0.1767], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,198][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.4745e-02, 1.4002e-01, 4.8098e-07, 2.6979e-04, 4.8012e-09, 2.0667e-04,
        1.0110e-03, 2.4937e-02, 2.9310e-03, 1.4397e-02, 1.3467e-01, 2.3167e-05,
        1.5130e-03, 6.6527e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,199][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1725, 0.0207, 0.6664, 0.0017, 0.0213, 0.0110, 0.0283, 0.0076, 0.0047,
        0.0042, 0.0022, 0.0077, 0.0101, 0.0416], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,202][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0067, 0.0915, 0.0183, 0.0410, 0.0224, 0.0616, 0.0370, 0.1037, 0.0450,
        0.0470, 0.1365, 0.0461, 0.0609, 0.2823], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,206][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0003, 0.0519, 0.0071, 0.0123, 0.0022, 0.0151, 0.0194, 0.0593, 0.0795,
        0.0712, 0.0857, 0.0781, 0.1075, 0.1941, 0.2164], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,208][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([5.7768e-05, 3.6628e-02, 7.2432e-02, 3.2829e-02, 9.3798e-02, 2.2328e-02,
        1.8814e-02, 5.5109e-02, 9.8461e-02, 8.4338e-02, 1.8609e-02, 2.0503e-01,
        2.4393e-02, 1.8852e-01, 4.8654e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,209][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0049, 0.1056, 0.0848, 0.0673, 0.0423, 0.0295, 0.0199, 0.0816, 0.0470,
        0.0252, 0.1476, 0.0611, 0.0285, 0.1244, 0.1303], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,209][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0132, 0.0242, 0.0162, 0.0195, 0.0154, 0.0149, 0.0168, 0.0598, 0.0589,
        0.0592, 0.1402, 0.1252, 0.0236, 0.2458, 0.1671], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,209][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.5622, 0.0791, 0.0016, 0.0480, 0.0014, 0.0249, 0.0062, 0.0485, 0.0110,
        0.0147, 0.0346, 0.0150, 0.0130, 0.0523, 0.0874], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,210][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([2.1991e-02, 5.1712e-03, 9.9052e-08, 1.6039e-04, 1.3845e-08, 3.3798e-04,
        2.3219e-03, 2.3442e-02, 3.7302e-03, 7.8582e-02, 9.4400e-02, 1.6223e-04,
        6.7131e-03, 7.0482e-01, 5.8167e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,210][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0008, 0.1263, 0.0274, 0.0482, 0.0277, 0.0308, 0.0192, 0.0669, 0.1226,
        0.0641, 0.1015, 0.0896, 0.0216, 0.1715, 0.0817], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,211][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1220, 0.1461, 0.0705, 0.0294, 0.0319, 0.0131, 0.0342, 0.0608, 0.0673,
        0.0833, 0.0630, 0.0403, 0.0264, 0.1895, 0.0222], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,211][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0029, 0.0504, 0.0448, 0.0267, 0.1247, 0.0733, 0.0207, 0.1331, 0.0537,
        0.0764, 0.0304, 0.0929, 0.0411, 0.1292, 0.0997], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,212][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.2427e-04, 2.6280e-02, 5.2039e-08, 1.1055e-04, 3.9524e-10, 7.4989e-05,
        6.9392e-04, 1.5973e-02, 3.0707e-03, 1.9983e-02, 1.0187e-01, 1.1570e-05,
        1.4106e-03, 8.1196e-01, 1.8437e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,215][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0393, 0.0260, 0.6317, 0.0030, 0.0269, 0.0201, 0.0466, 0.0156, 0.0094,
        0.0094, 0.0040, 0.0148, 0.0251, 0.0855, 0.0426], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,218][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0019, 0.0963, 0.0181, 0.0392, 0.0114, 0.0509, 0.0476, 0.0880, 0.0525,
        0.0573, 0.1526, 0.0276, 0.0443, 0.2272, 0.0850], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,222][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0006, 0.0599, 0.0052, 0.0091, 0.0023, 0.0148, 0.0199, 0.0714, 0.0669,
        0.0833, 0.0617, 0.0805, 0.1113, 0.1692, 0.2122, 0.0318],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,222][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9181e-05, 4.4272e-02, 7.4200e-02, 3.0167e-02, 9.8271e-02, 2.1469e-02,
        2.3930e-02, 5.4300e-02, 9.1252e-02, 8.4233e-02, 1.3151e-02, 2.1027e-01,
        2.1310e-02, 1.2169e-01, 5.5646e-02, 5.5738e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,222][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0068, 0.1320, 0.1010, 0.0748, 0.0477, 0.0302, 0.0214, 0.0949, 0.0484,
        0.0254, 0.1286, 0.0608, 0.0212, 0.0920, 0.0874, 0.0274],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,223][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0142, 0.0651, 0.0128, 0.0341, 0.0126, 0.0263, 0.0233, 0.0675, 0.0557,
        0.0550, 0.1547, 0.0916, 0.0293, 0.1816, 0.1023, 0.0738],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,223][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6708, 0.0940, 0.0008, 0.0330, 0.0010, 0.0230, 0.0033, 0.0355, 0.0063,
        0.0088, 0.0185, 0.0107, 0.0096, 0.0270, 0.0530, 0.0048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,224][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.4339e-03, 5.1008e-03, 6.6823e-08, 2.6206e-04, 1.0041e-08, 3.3811e-04,
        3.2210e-03, 3.1497e-02, 2.7686e-03, 6.8858e-02, 5.2219e-02, 1.3763e-04,
        6.3566e-03, 7.4260e-01, 8.0090e-02, 2.1177e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,224][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0015, 0.1312, 0.0158, 0.0450, 0.0306, 0.0314, 0.0211, 0.0890, 0.1172,
        0.0665, 0.0997, 0.1031, 0.0198, 0.1208, 0.0627, 0.0446],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,226][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4156, 0.1811, 0.0308, 0.0209, 0.0208, 0.0099, 0.0305, 0.0242, 0.0339,
        0.0489, 0.0368, 0.0203, 0.0134, 0.0734, 0.0087, 0.0310],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,228][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0074, 0.0613, 0.0585, 0.0270, 0.1158, 0.0821, 0.0121, 0.1121, 0.0668,
        0.0991, 0.0250, 0.0833, 0.0249, 0.1103, 0.0690, 0.0454],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,231][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.5058e-05, 2.0057e-02, 2.7317e-08, 1.3604e-04, 4.5543e-10, 7.6284e-05,
        9.7993e-04, 1.8939e-02, 1.7694e-03, 2.2918e-02, 4.0526e-02, 1.8743e-05,
        1.6464e-03, 8.5779e-01, 3.4008e-02, 1.0885e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,235][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0597, 0.0260, 0.5577, 0.0024, 0.0319, 0.0213, 0.0471, 0.0147, 0.0092,
        0.0086, 0.0037, 0.0163, 0.0164, 0.0587, 0.0402, 0.0861],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,235][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0091, 0.1049, 0.0125, 0.0258, 0.0143, 0.0753, 0.0569, 0.1003, 0.0318,
        0.0465, 0.1042, 0.0373, 0.0411, 0.1881, 0.0822, 0.0698],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,235][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0003, 0.0409, 0.0039, 0.0105, 0.0015, 0.0057, 0.0094, 0.0611, 0.0548,
        0.0694, 0.0611, 0.0675, 0.0528, 0.1567, 0.1517, 0.0263, 0.2266],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,236][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([1.2418e-05, 4.7621e-02, 5.6076e-02, 3.1185e-02, 7.2939e-02, 1.5361e-02,
        2.2820e-02, 4.9174e-02, 9.5988e-02, 5.0540e-02, 1.3387e-02, 1.3133e-01,
        1.2488e-02, 1.0962e-01, 5.1859e-02, 8.7349e-02, 1.5226e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,236][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0032, 0.1468, 0.0507, 0.0625, 0.0310, 0.0253, 0.0173, 0.0771, 0.0459,
        0.0328, 0.1453, 0.0394, 0.0207, 0.0992, 0.0959, 0.0488, 0.0582],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,237][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0121, 0.0339, 0.0131, 0.0220, 0.0103, 0.0131, 0.0167, 0.0481, 0.0373,
        0.0684, 0.1155, 0.0790, 0.0191, 0.1810, 0.1517, 0.1046, 0.0741],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,237][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([7.2192e-01, 5.8835e-02, 2.7531e-04, 2.3791e-02, 3.7890e-04, 1.4543e-02,
        3.5789e-03, 3.1937e-02, 3.3812e-03, 7.8089e-03, 1.0807e-02, 5.1504e-03,
        6.7924e-03, 2.5016e-02, 5.9033e-02, 3.9630e-03, 2.2792e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,237][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.0323e-03, 3.3067e-03, 1.4024e-08, 7.5463e-05, 1.5740e-09, 9.5440e-05,
        1.1674e-03, 1.8457e-02, 7.6763e-04, 3.0084e-02, 2.4411e-02, 4.3588e-05,
        2.0771e-03, 8.6619e-01, 3.9842e-02, 8.4451e-04, 1.0602e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,239][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0002, 0.1471, 0.0119, 0.0431, 0.0146, 0.0151, 0.0164, 0.0678, 0.0846,
        0.0469, 0.0789, 0.0619, 0.0114, 0.1334, 0.0476, 0.0495, 0.1694],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,242][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.4418, 0.1199, 0.0202, 0.0198, 0.0109, 0.0088, 0.0261, 0.0266, 0.0345,
        0.0421, 0.0452, 0.0179, 0.0123, 0.1036, 0.0142, 0.0287, 0.0274],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,246][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0037, 0.0429, 0.0243, 0.0206, 0.1078, 0.0727, 0.0125, 0.0893, 0.0619,
        0.0664, 0.0351, 0.0870, 0.0463, 0.1085, 0.0933, 0.0826, 0.0452],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,248][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([9.7834e-06, 1.1182e-02, 3.2600e-09, 3.4238e-05, 3.0432e-11, 1.4957e-05,
        2.5070e-04, 1.0803e-02, 3.6305e-04, 6.5631e-03, 1.6935e-02, 3.2485e-06,
        1.9875e-04, 9.3784e-01, 1.3046e-02, 3.9277e-04, 2.3617e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,248][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0357, 0.0338, 0.5355, 0.0023, 0.0220, 0.0179, 0.0448, 0.0163, 0.0094,
        0.0093, 0.0032, 0.0106, 0.0106, 0.0665, 0.0381, 0.1390, 0.0048],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,249][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0005, 0.1418, 0.0203, 0.0580, 0.0173, 0.0309, 0.0275, 0.0810, 0.0440,
        0.0329, 0.1404, 0.0293, 0.0151, 0.1642, 0.0449, 0.0798, 0.0723],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,249][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0004, 0.0322, 0.0027, 0.0075, 0.0018, 0.0091, 0.0110, 0.0384, 0.0495,
        0.0775, 0.0525, 0.0691, 0.0648, 0.1290, 0.1584, 0.0259, 0.2310, 0.0394],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,250][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.6528e-05, 2.2911e-02, 4.0912e-02, 2.3744e-02, 7.2117e-02, 1.4122e-02,
        1.6477e-02, 2.9790e-02, 6.7168e-02, 6.8461e-02, 1.0034e-02, 1.5288e-01,
        1.4626e-02, 1.3575e-01, 4.8224e-02, 7.0777e-02, 1.0731e-01, 1.0464e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,250][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0171, 0.1042, 0.0738, 0.0814, 0.0502, 0.0292, 0.0220, 0.0836, 0.0336,
        0.0163, 0.1163, 0.0513, 0.0172, 0.0952, 0.0923, 0.0336, 0.0284, 0.0542],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,250][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0456, 0.0325, 0.0083, 0.0235, 0.0110, 0.0166, 0.0172, 0.0364, 0.0404,
        0.0395, 0.1410, 0.0843, 0.0219, 0.1815, 0.0885, 0.0822, 0.0419, 0.0876],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,252][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.5437e-01, 4.4139e-02, 4.2943e-04, 2.1952e-02, 4.7525e-04, 1.1056e-02,
        2.1496e-03, 2.2960e-02, 3.5410e-03, 6.4089e-03, 1.2401e-02, 5.9733e-03,
        4.8709e-03, 2.2454e-02, 4.7354e-02, 5.2123e-03, 2.6064e-02, 8.1881e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,253][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.9675e-02, 2.2520e-03, 5.4430e-08, 1.3166e-04, 8.4339e-09, 2.1055e-04,
        2.1497e-03, 2.3637e-02, 1.9421e-03, 7.6216e-02, 7.3197e-02, 9.8876e-05,
        5.4815e-03, 7.1349e-01, 5.8730e-02, 1.8504e-03, 1.2611e-02, 8.3307e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,256][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0022, 0.1158, 0.0116, 0.0421, 0.0218, 0.0223, 0.0142, 0.0511, 0.0781,
        0.0509, 0.0914, 0.0660, 0.0120, 0.1111, 0.0454, 0.0539, 0.1686, 0.0415],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,260][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.5091, 0.1022, 0.0185, 0.0135, 0.0131, 0.0067, 0.0232, 0.0188, 0.0225,
        0.0383, 0.0294, 0.0159, 0.0117, 0.0782, 0.0069, 0.0245, 0.0124, 0.0551],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,261][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0083, 0.0555, 0.0297, 0.0185, 0.0936, 0.0806, 0.0083, 0.0646, 0.0486,
        0.0575, 0.0226, 0.0499, 0.0294, 0.1411, 0.0659, 0.0722, 0.0318, 0.1220],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,261][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.8710e-04, 1.1724e-02, 1.6256e-08, 5.7763e-05, 2.2855e-10, 5.1647e-05,
        5.5571e-04, 1.2574e-02, 1.5674e-03, 2.4398e-02, 7.1356e-02, 1.0348e-05,
        1.0332e-03, 8.4019e-01, 2.6421e-02, 7.1624e-04, 2.7942e-03, 6.3636e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,262][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1729, 0.0188, 0.5048, 0.0017, 0.0216, 0.0146, 0.0372, 0.0082, 0.0045,
        0.0055, 0.0020, 0.0099, 0.0112, 0.0493, 0.0326, 0.0815, 0.0031, 0.0205],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,262][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0052, 0.0617, 0.0077, 0.0271, 0.0062, 0.0377, 0.0285, 0.0614, 0.0197,
        0.0268, 0.0893, 0.0190, 0.0249, 0.2316, 0.0448, 0.0489, 0.0522, 0.2073],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,263][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:21,264][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2134],
        [  98],
        [1266],
        [ 136],
        [ 375],
        [  45],
        [ 268],
        [  63],
        [  22],
        [  19],
        [  26],
        [  96],
        [  11],
        [   4],
        [   4],
        [   6],
        [   1],
        [   2]], device='cuda:0')
[2024-07-24 10:30:21,266][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1798],
        [  86],
        [ 432],
        [  24],
        [  91],
        [   5],
        [  62],
        [  14],
        [   2],
        [   4],
        [   3],
        [  34],
        [   2],
        [   1],
        [   1],
        [   3],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:30:21,267][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20351],
        [ 4584],
        [ 6760],
        [ 5096],
        [ 5398],
        [ 5005],
        [ 7562],
        [ 6133],
        [ 3771],
        [ 3129],
        [ 3364],
        [ 4008],
        [ 4474],
        [ 4488],
        [ 4021],
        [ 4009],
        [ 4490],
        [ 4585]], device='cuda:0')
[2024-07-24 10:30:21,269][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[10940],
        [17706],
        [36574],
        [30996],
        [28944],
        [27382],
        [24374],
        [27466],
        [20512],
        [19307],
        [21475],
        [21295],
        [21404],
        [23021],
        [22490],
        [22415],
        [22214],
        [21675]], device='cuda:0')
[2024-07-24 10:30:21,270][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16407],
        [ 8531],
        [43759],
        [46286],
        [25808],
        [25057],
        [28485],
        [44582],
        [35769],
        [18331],
        [26097],
        [17929],
        [16372],
        [38301],
        [26946],
        [29786],
        [18743],
        [24787]], device='cuda:0')
[2024-07-24 10:30:21,272][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26654],
        [21912],
        [ 6059],
        [ 3983],
        [ 2953],
        [ 3112],
        [ 2775],
        [ 2038],
        [ 2079],
        [ 1932],
        [ 2684],
        [ 2702],
        [ 2608],
        [ 3508],
        [ 4140],
        [ 3411],
        [ 3794],
        [ 4131]], device='cuda:0')
[2024-07-24 10:30:21,275][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[41276],
        [41334],
        [36216],
        [42576],
        [35717],
        [42164],
        [40326],
        [42896],
        [42052],
        [40919],
        [42519],
        [37384],
        [40684],
        [42572],
        [39369],
        [40931],
        [41281],
        [41605]], device='cuda:0')
[2024-07-24 10:30:21,278][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15790],
        [14090],
        [ 5967],
        [ 6225],
        [ 9819],
        [ 6581],
        [ 9586],
        [11380],
        [10201],
        [ 8239],
        [ 9262],
        [ 8918],
        [ 9409],
        [ 9003],
        [ 8716],
        [ 8635],
        [ 8563],
        [ 8590]], device='cuda:0')
[2024-07-24 10:30:21,278][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11055],
        [41108],
        [46718],
        [43632],
        [42914],
        [44610],
        [44894],
        [44693],
        [46277],
        [47018],
        [47488],
        [47184],
        [47419],
        [47390],
        [47565],
        [47447],
        [47275],
        [47467]], device='cuda:0')
[2024-07-24 10:30:21,279][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[41786],
        [41285],
        [  291],
        [ 3170],
        [  182],
        [ 3407],
        [ 8962],
        [ 2213],
        [ 8166],
        [ 6300],
        [ 6817],
        [ 4467],
        [ 7416],
        [ 6642],
        [ 1964],
        [ 6080],
        [ 6427],
        [ 6217]], device='cuda:0')
[2024-07-24 10:30:21,281][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[37009],
        [40446],
        [42130],
        [42875],
        [43538],
        [42764],
        [43735],
        [44721],
        [44482],
        [45206],
        [45136],
        [45888],
        [45990],
        [46047],
        [46682],
        [46316],
        [46495],
        [46320]], device='cuda:0')
[2024-07-24 10:30:21,282][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30080],
        [38144],
        [42864],
        [42919],
        [43457],
        [42893],
        [43511],
        [45795],
        [44980],
        [43630],
        [43594],
        [39813],
        [43035],
        [39573],
        [38281],
        [37934],
        [37630],
        [37938]], device='cuda:0')
[2024-07-24 10:30:21,283][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29989],
        [30614],
        [50231],
        [50230],
        [50231],
        [50229],
        [50220],
        [50231],
        [50232],
        [50231],
        [50231],
        [50221],
        [50214],
        [50232],
        [50221],
        [50207],
        [50202],
        [50211]], device='cuda:0')
[2024-07-24 10:30:21,285][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12589],
        [12594],
        [41625],
        [37864],
        [38999],
        [35957],
        [31918],
        [14885],
        [23556],
        [29048],
        [22473],
        [25296],
        [23221],
        [17087],
        [18602],
        [18462],
        [19720],
        [15085]], device='cuda:0')
[2024-07-24 10:30:21,286][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22111],
        [17067],
        [15358],
        [27909],
        [28733],
        [30408],
        [29329],
        [18652],
        [26297],
        [22756],
        [25314],
        [25328],
        [24210],
        [23856],
        [24055],
        [25404],
        [34569],
        [23265]], device='cuda:0')
[2024-07-24 10:30:21,289][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11650],
        [30726],
        [30103],
        [31303],
        [30740],
        [30220],
        [28103],
        [30441],
        [32016],
        [33108],
        [32540],
        [31319],
        [30375],
        [31433],
        [33537],
        [33880],
        [32857],
        [32426]], device='cuda:0')
[2024-07-24 10:30:21,291][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[36121],
        [44085],
        [46550],
        [43953],
        [45457],
        [44681],
        [42584],
        [41838],
        [41426],
        [42932],
        [42650],
        [40981],
        [39648],
        [39762],
        [40634],
        [41042],
        [41450],
        [41810]], device='cuda:0')
[2024-07-24 10:30:21,294][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[47958],
        [38260],
        [20808],
        [16644],
        [27752],
        [28790],
        [25570],
        [15343],
        [23152],
        [32249],
        [30610],
        [33056],
        [34645],
        [25395],
        [31680],
        [30658],
        [36867],
        [33114]], device='cuda:0')
[2024-07-24 10:30:21,295][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24982],
        [21938],
        [22489],
        [22197],
        [23430],
        [22423],
        [21830],
        [19102],
        [18211],
        [18569],
        [17091],
        [17714],
        [17739],
        [15659],
        [15360],
        [15698],
        [15210],
        [14957]], device='cuda:0')
[2024-07-24 10:30:21,296][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8056],
        [ 8130],
        [18783],
        [13943],
        [20754],
        [14987],
        [18093],
        [13956],
        [16172],
        [17285],
        [15472],
        [16128],
        [16336],
        [11906],
        [11511],
        [13263],
        [13038],
        [12715]], device='cuda:0')
[2024-07-24 10:30:21,297][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 2655],
        [ 3183],
        [22697],
        [21446],
        [20699],
        [20786],
        [19553],
        [15418],
        [18086],
        [13605],
        [13237],
        [11580],
        [13486],
        [14675],
        [20099],
        [20257],
        [20842],
        [20182]], device='cuda:0')
[2024-07-24 10:30:21,298][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29434],
        [15627],
        [15374],
        [15008],
        [14629],
        [17550],
        [18606],
        [22399],
        [21904],
        [20517],
        [21281],
        [20550],
        [20482],
        [21214],
        [22343],
        [21644],
        [21499],
        [21454]], device='cuda:0')
[2024-07-24 10:30:21,299][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13059],
        [13292],
        [22945],
        [21688],
        [25018],
        [24336],
        [24213],
        [28076],
        [22503],
        [22266],
        [22659],
        [23985],
        [23205],
        [24014],
        [25339],
        [22470],
        [22546],
        [23039]], device='cuda:0')
[2024-07-24 10:30:21,301][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4734],
        [13116],
        [12182],
        [12004],
        [12873],
        [12482],
        [11804],
        [10654],
        [10002],
        [ 9720],
        [ 9946],
        [ 9964],
        [ 9163],
        [ 8959],
        [ 8417],
        [ 8728],
        [ 8023],
        [ 7982]], device='cuda:0')
[2024-07-24 10:30:21,303][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18973],
        [15891],
        [23722],
        [23776],
        [24704],
        [23753],
        [21919],
        [14870],
        [18592],
        [19274],
        [21737],
        [16319],
        [18886],
        [24005],
        [24485],
        [24607],
        [25385],
        [24553]], device='cuda:0')
[2024-07-24 10:30:21,305][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[29553],
        [31134],
        [28003],
        [28855],
        [27742],
        [27384],
        [26227],
        [27305],
        [27380],
        [27269],
        [27896],
        [25630],
        [25469],
        [27587],
        [25658],
        [24552],
        [23578],
        [24888]], device='cuda:0')
[2024-07-24 10:30:21,307][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13052],
        [13041],
        [29716],
        [22118],
        [30034],
        [32151],
        [30314],
        [31098],
        [32020],
        [31510],
        [31496],
        [31568],
        [30988],
        [26688],
        [26725],
        [27393],
        [26623],
        [25073]], device='cuda:0')
[2024-07-24 10:30:21,310][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[5200],
        [5295],
        [2407],
        [3528],
        [2543],
        [2086],
        [2901],
        [4076],
        [3275],
        [3325],
        [3167],
        [4453],
        [4233],
        [4177],
        [4284],
        [3907],
        [3646],
        [3888]], device='cuda:0')
[2024-07-24 10:30:21,311][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12966],
        [22097],
        [21139],
        [12020],
        [11916],
        [11400],
        [ 9240],
        [15228],
        [10935],
        [11112],
        [10407],
        [ 8563],
        [ 8010],
        [10392],
        [ 7284],
        [ 6971],
        [ 7163],
        [10279]], device='cuda:0')
[2024-07-24 10:30:21,312][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246],
        [17246]], device='cuda:0')
[2024-07-24 10:30:21,360][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:21,360][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,361][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,361][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,361][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,362][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,364][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,367][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,370][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,372][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,372][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,372][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,373][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,373][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6146, 0.3854], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,373][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7770, 0.2230], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,374][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0822, 0.9178], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,374][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,374][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0272, 0.9728], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,376][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1188, 0.8812], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,378][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4595, 0.5405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,382][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8385, 0.1615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,384][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8875, 0.1125], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,385][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7202, 0.2798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,385][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8017, 0.1983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,385][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1973, 0.8027], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,386][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Samuel] are: tensor([0.0999, 0.4819, 0.4182], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,386][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Samuel] are: tensor([0.0447, 0.3478, 0.6075], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,386][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Samuel] are: tensor([8.0051e-04, 9.6171e-01, 3.7486e-02], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,386][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Samuel] are: tensor([0.9656, 0.0266, 0.0078], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,387][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Samuel] are: tensor([0.0081, 0.8208, 0.1712], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,387][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Samuel] are: tensor([0.0176, 0.4348, 0.5477], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,387][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Samuel] are: tensor([0.0077, 0.9442, 0.0482], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,389][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Samuel] are: tensor([0.0304, 0.2970, 0.6726], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,391][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Samuel] are: tensor([0.2384, 0.0894, 0.6722], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,395][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Samuel] are: tensor([0.0016, 0.6584, 0.3399], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,398][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Samuel] are: tensor([0.5088, 0.2487, 0.2424], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,398][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Samuel] are: tensor([0.0114, 0.4035, 0.5851], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,398][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2456, 0.5571, 0.0994, 0.0980], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,399][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0698, 0.3174, 0.2192, 0.3937], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,399][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0043, 0.4001, 0.0277, 0.5679], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,399][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9238e-01, 6.8899e-03, 1.2512e-04, 6.0670e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,399][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0031, 0.4481, 0.0778, 0.4710], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,400][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0238, 0.1543, 0.4198, 0.4020], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,400][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0502, 0.4235, 0.0282, 0.4981], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,401][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1703, 0.0591, 0.4435, 0.3271], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,404][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0069, 0.4891, 0.2128, 0.2911], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,407][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0103, 0.2647, 0.3009, 0.4240], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,411][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5342, 0.2216, 0.1172, 0.1270], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,411][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1869, 0.5451, 0.1014, 0.1666], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,411][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.0334, 0.3305, 0.2317, 0.3146, 0.0899], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,411][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0064, 0.4117, 0.1235, 0.3900, 0.0685], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,412][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([3.7919e-04, 4.8780e-01, 1.0973e-02, 4.9277e-01, 8.0787e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,412][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([0.4434, 0.2471, 0.0337, 0.2576, 0.0181], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,412][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0017, 0.4782, 0.0635, 0.4219, 0.0346], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,413][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0026, 0.3213, 0.1662, 0.4821, 0.0278], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,413][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0034, 0.5892, 0.0142, 0.3880, 0.0053], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,413][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0119, 0.1304, 0.3085, 0.4064, 0.1428], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,415][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.2112, 0.1222, 0.1433, 0.3116, 0.2116], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,417][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([1.7241e-04, 5.6373e-01, 8.5738e-02, 3.4111e-01, 9.2499e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,419][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.1990, 0.0832, 0.1661, 0.2190, 0.3328], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,423][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0115, 0.4162, 0.1211, 0.4381, 0.0131], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,424][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0926, 0.5379, 0.0938, 0.1153, 0.0247, 0.1357], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,424][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0464, 0.2489, 0.1401, 0.1731, 0.1034, 0.2881], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,425][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0039, 0.5937, 0.0156, 0.3152, 0.0136, 0.0581], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,425][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ were] are: tensor([7.7954e-01, 1.8693e-01, 3.3157e-04, 4.2055e-03, 1.1024e-04, 2.8890e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,425][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0042, 0.4412, 0.0433, 0.2086, 0.0173, 0.2854], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,425][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0388, 0.2439, 0.2130, 0.3496, 0.0307, 0.1240], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,426][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0366, 0.5678, 0.0118, 0.2943, 0.0054, 0.0841], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,426][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1185, 0.0824, 0.1178, 0.1431, 0.0655, 0.4727], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,426][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0023, 0.6862, 0.0615, 0.1429, 0.0338, 0.0734], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,428][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0016, 0.6523, 0.0967, 0.1808, 0.0135, 0.0550], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,430][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.7044, 0.0739, 0.0759, 0.0314, 0.0814, 0.0330], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,433][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.2603, 0.5525, 0.0276, 0.1336, 0.0036, 0.0224], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,437][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ working] are: tensor([0.0434, 0.3997, 0.0273, 0.0537, 0.0135, 0.0557, 0.4068],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,437][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ working] are: tensor([0.0246, 0.4600, 0.0558, 0.1871, 0.0363, 0.1254, 0.1109],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,438][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ working] are: tensor([0.0016, 0.7432, 0.0055, 0.1680, 0.0029, 0.0319, 0.0469],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,438][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ working] are: tensor([6.1330e-01, 2.4322e-01, 7.1013e-05, 5.8355e-03, 2.2653e-05, 2.6404e-02,
        1.1114e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,438][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ working] are: tensor([0.0053, 0.4857, 0.0324, 0.1463, 0.0142, 0.1163, 0.1999],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,439][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ working] are: tensor([0.0153, 0.4834, 0.0884, 0.2284, 0.0220, 0.0626, 0.0999],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,439][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ working] are: tensor([0.0491, 0.7387, 0.0079, 0.1443, 0.0016, 0.0306, 0.0278],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,439][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ working] are: tensor([0.0507, 0.1022, 0.1215, 0.1601, 0.0693, 0.2143, 0.2819],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,440][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ working] are: tensor([0.0299, 0.6406, 0.0412, 0.1733, 0.0294, 0.0162, 0.0694],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,441][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ working] are: tensor([0.0164, 0.5608, 0.0786, 0.2331, 0.0101, 0.0690, 0.0320],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,443][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ working] are: tensor([0.8804, 0.0537, 0.0045, 0.0136, 0.0076, 0.0081, 0.0322],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,446][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ working] are: tensor([0.0681, 0.7627, 0.0141, 0.0476, 0.0010, 0.0282, 0.0782],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,450][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0711, 0.2860, 0.0326, 0.0435, 0.0121, 0.0465, 0.3611, 0.1470],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,450][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0502, 0.1895, 0.0855, 0.1656, 0.0688, 0.1682, 0.1055, 0.1667],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,451][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0036, 0.5857, 0.0085, 0.1729, 0.0083, 0.0356, 0.0563, 0.1291],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,451][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([8.0424e-01, 3.1099e-02, 3.0696e-05, 1.2405e-03, 8.2781e-06, 4.8230e-03,
        1.4854e-02, 1.4371e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,451][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0076, 0.2655, 0.0257, 0.1094, 0.0135, 0.1017, 0.1387, 0.3378],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,452][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0043, 0.3563, 0.1335, 0.1876, 0.0283, 0.0422, 0.0324, 0.2153],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,452][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0598, 0.4988, 0.0136, 0.1706, 0.0048, 0.0467, 0.0336, 0.1722],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,452][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0576, 0.0991, 0.1084, 0.1606, 0.0680, 0.1505, 0.0925, 0.2632],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,453][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0045, 0.6186, 0.0430, 0.1287, 0.0270, 0.0258, 0.0674, 0.0850],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,455][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0120, 0.3793, 0.1410, 0.2010, 0.0320, 0.0745, 0.0461, 0.1141],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,457][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.9655, 0.0131, 0.0012, 0.0025, 0.0021, 0.0016, 0.0111, 0.0029],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,461][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3932, 0.1585, 0.0129, 0.0408, 0.0017, 0.0291, 0.0464, 0.3176],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,463][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1585, 0.2334, 0.0191, 0.0340, 0.0069, 0.0263, 0.2399, 0.0929, 0.1889],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,463][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0215, 0.2190, 0.0922, 0.1315, 0.0685, 0.0765, 0.0526, 0.0867, 0.2515],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,464][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0033, 0.5084, 0.0083, 0.1321, 0.0072, 0.0193, 0.0261, 0.0775, 0.2178],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,464][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([8.6725e-01, 3.4682e-02, 8.9214e-06, 5.8799e-04, 1.5312e-06, 1.0938e-03,
        4.0003e-03, 4.5405e-02, 4.6971e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,464][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0015, 0.1643, 0.0133, 0.0775, 0.0091, 0.0530, 0.0808, 0.3161, 0.2844],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,465][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0028, 0.3164, 0.0791, 0.1692, 0.0159, 0.0198, 0.0186, 0.1323, 0.2459],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,465][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0416, 0.5164, 0.0104, 0.1081, 0.0029, 0.0196, 0.0139, 0.0909, 0.1963],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,465][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0212, 0.1110, 0.1126, 0.1663, 0.0722, 0.0967, 0.0654, 0.1388, 0.2160],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,466][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0472, 0.4861, 0.0204, 0.1414, 0.0179, 0.0246, 0.0391, 0.0655, 0.1578],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,467][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0096, 0.4244, 0.1090, 0.1191, 0.0119, 0.0377, 0.0191, 0.0509, 0.2183],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,470][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.9607, 0.0220, 0.0011, 0.0018, 0.0013, 0.0011, 0.0050, 0.0016, 0.0054],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,472][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1467, 0.3571, 0.0095, 0.0301, 0.0007, 0.0102, 0.0153, 0.1602, 0.2702],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,476][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0525, 0.1073, 0.0144, 0.0233, 0.0075, 0.0399, 0.3010, 0.1086, 0.1754,
        0.1702], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,477][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0066, 0.3501, 0.0543, 0.1275, 0.0296, 0.0559, 0.0238, 0.0500, 0.1616,
        0.1404], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,477][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0018, 0.4695, 0.0042, 0.1268, 0.0046, 0.0167, 0.0233, 0.0586, 0.1825,
        0.1120], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,477][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ station] are: tensor([6.0945e-01, 2.9357e-02, 3.7406e-06, 3.6900e-04, 8.9624e-07, 1.4266e-03,
        4.2251e-03, 6.8355e-02, 6.7745e-02, 2.1907e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,478][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0019, 0.2630, 0.0119, 0.0694, 0.0045, 0.0467, 0.0721, 0.1677, 0.2613,
        0.1016], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,478][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0009, 0.2911, 0.0590, 0.1742, 0.0127, 0.0169, 0.0365, 0.1176, 0.2272,
        0.0640], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,479][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0061, 0.6394, 0.0048, 0.0681, 0.0012, 0.0086, 0.0083, 0.0539, 0.1362,
        0.0733], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,479][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0087, 0.2392, 0.0666, 0.1326, 0.0271, 0.0512, 0.0556, 0.1464, 0.1815,
        0.0910], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,481][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0007, 0.3467, 0.0154, 0.0426, 0.0114, 0.0198, 0.1174, 0.1270, 0.2687,
        0.0502], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,482][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ station] are: tensor([3.5626e-04, 5.2942e-01, 5.1300e-02, 1.1385e-01, 6.8951e-03, 1.6609e-02,
        1.6917e-02, 3.6696e-02, 1.7989e-01, 4.8070e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,485][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.8883, 0.0450, 0.0033, 0.0068, 0.0050, 0.0024, 0.0126, 0.0040, 0.0105,
        0.0221], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,489][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1441, 0.1901, 0.0044, 0.0228, 0.0004, 0.0091, 0.0259, 0.1676, 0.2545,
        0.1811], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,490][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1054, 0.2452, 0.0350, 0.0274, 0.0105, 0.0202, 0.1871, 0.0731, 0.1251,
        0.0725, 0.0985], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,490][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0362, 0.1089, 0.0680, 0.0587, 0.0488, 0.0340, 0.0189, 0.0317, 0.0991,
        0.0944, 0.4014], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,490][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0048, 0.2347, 0.0094, 0.1238, 0.0084, 0.0113, 0.0124, 0.0314, 0.1263,
        0.0554, 0.3820], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,491][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([8.8416e-01, 6.8068e-03, 4.8825e-06, 9.6790e-05, 1.2470e-06, 3.9807e-04,
        1.1729e-03, 1.3040e-02, 1.2073e-02, 4.3747e-02, 3.8502e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,491][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0040, 0.0866, 0.0155, 0.0510, 0.0105, 0.0350, 0.0567, 0.1695, 0.1872,
        0.1197, 0.2642], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,491][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0094, 0.1109, 0.1133, 0.1199, 0.0217, 0.0184, 0.0322, 0.1077, 0.1626,
        0.0841, 0.2199], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,492][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0567, 0.2847, 0.0083, 0.0654, 0.0021, 0.0093, 0.0068, 0.0371, 0.0952,
        0.0571, 0.3773], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,492][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0510, 0.0423, 0.0999, 0.0833, 0.0475, 0.0591, 0.0393, 0.0768, 0.1036,
        0.0638, 0.3333], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,494][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0042, 0.3984, 0.0258, 0.0651, 0.0164, 0.0230, 0.0757, 0.0959, 0.1884,
        0.0236, 0.0834], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,496][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0079, 0.2798, 0.1217, 0.1214, 0.0118, 0.0200, 0.0175, 0.0327, 0.1325,
        0.0515, 0.2031], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,500][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.9048, 0.0211, 0.0052, 0.0024, 0.0056, 0.0011, 0.0038, 0.0013, 0.0026,
        0.0100, 0.0419], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,503][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.3247, 0.1338, 0.0054, 0.0135, 0.0006, 0.0028, 0.0086, 0.0680, 0.0835,
        0.0521, 0.3071], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,503][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Matthew] are: tensor([0.0063, 0.0847, 0.0156, 0.0274, 0.0081, 0.0296, 0.2785, 0.0899, 0.1646,
        0.1464, 0.1150, 0.0341], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,503][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Matthew] are: tensor([0.0031, 0.0770, 0.0233, 0.0461, 0.0154, 0.0477, 0.0336, 0.0662, 0.1286,
        0.2411, 0.2328, 0.0851], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,504][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Matthew] are: tensor([0.0010, 0.0909, 0.0056, 0.0735, 0.0066, 0.0146, 0.0314, 0.0760, 0.1607,
        0.1638, 0.2991, 0.0768], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,504][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Matthew] are: tensor([1.0973e-02, 2.7300e-03, 1.8563e-05, 3.1360e-04, 6.0502e-06, 3.6560e-03,
        1.8802e-02, 9.3263e-02, 9.0202e-02, 4.6231e-01, 3.0717e-01, 1.0554e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,504][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Matthew] are: tensor([0.0007, 0.0797, 0.0175, 0.0419, 0.0063, 0.0552, 0.0893, 0.2020, 0.2261,
        0.0802, 0.1762, 0.0249], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,505][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Matthew] are: tensor([0.0006, 0.1397, 0.0579, 0.0815, 0.0118, 0.0219, 0.0519, 0.1797, 0.1672,
        0.0688, 0.1678, 0.0511], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,506][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Matthew] are: tensor([0.0034, 0.2264, 0.0095, 0.0496, 0.0031, 0.0118, 0.0196, 0.0882, 0.1488,
        0.1071, 0.2929, 0.0396], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,509][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Matthew] are: tensor([0.0084, 0.0311, 0.0452, 0.0326, 0.0180, 0.0413, 0.0914, 0.1528, 0.1439,
        0.1140, 0.1919, 0.1294], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,513][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Matthew] are: tensor([0.0256, 0.0443, 0.0147, 0.0506, 0.0237, 0.0583, 0.1063, 0.1415, 0.2418,
        0.0815, 0.1412, 0.0705], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,515][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Matthew] are: tensor([0.0005, 0.2939, 0.1038, 0.0798, 0.0118, 0.0293, 0.0417, 0.0585, 0.1329,
        0.0657, 0.1302, 0.0519], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,516][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Matthew] are: tensor([0.0629, 0.0480, 0.0071, 0.0138, 0.0102, 0.0142, 0.0794, 0.0314, 0.0682,
        0.1757, 0.3309, 0.1583], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,516][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Matthew] are: tensor([0.0041, 0.0241, 0.0031, 0.0116, 0.0005, 0.0055, 0.0316, 0.1482, 0.1666,
        0.1954, 0.3739, 0.0354], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,516][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ decided] are: tensor([0.0264, 0.1629, 0.0166, 0.0303, 0.0077, 0.0237, 0.1785, 0.0698, 0.1153,
        0.0803, 0.1180, 0.0204, 0.1501], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,517][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ decided] are: tensor([0.0085, 0.1143, 0.0158, 0.0457, 0.0122, 0.0262, 0.0172, 0.0409, 0.1033,
        0.1252, 0.3388, 0.0498, 0.1020], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,517][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ decided] are: tensor([0.0006, 0.2378, 0.0027, 0.0491, 0.0019, 0.0077, 0.0144, 0.0429, 0.1240,
        0.0752, 0.3073, 0.0260, 0.1105], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,518][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ decided] are: tensor([1.9928e-01, 3.2833e-02, 5.5357e-06, 3.5935e-04, 1.0562e-06, 1.3309e-03,
        4.3381e-03, 5.2278e-02, 6.0405e-02, 2.8882e-01, 2.9311e-01, 7.7284e-03,
        5.9510e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,518][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ decided] are: tensor([0.0005, 0.1280, 0.0061, 0.0299, 0.0018, 0.0265, 0.0534, 0.1369, 0.1909,
        0.0765, 0.2230, 0.0111, 0.1155], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,518][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ decided] are: tensor([0.0015, 0.1575, 0.0506, 0.0812, 0.0087, 0.0152, 0.0278, 0.0997, 0.1499,
        0.0509, 0.1362, 0.0430, 0.1777], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,520][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ decided] are: tensor([0.0059, 0.3647, 0.0034, 0.0398, 0.0007, 0.0063, 0.0075, 0.0512, 0.1102,
        0.0565, 0.2774, 0.0139, 0.0624], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,522][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ decided] are: tensor([0.0274, 0.0394, 0.0246, 0.0355, 0.0072, 0.0279, 0.0269, 0.0849, 0.1070,
        0.0438, 0.1866, 0.0881, 0.3007], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,526][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ decided] are: tensor([0.0333, 0.1999, 0.0077, 0.0726, 0.0065, 0.0354, 0.0405, 0.0733, 0.2054,
        0.0403, 0.1526, 0.0208, 0.1117], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,529][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ decided] are: tensor([0.0018, 0.3303, 0.0434, 0.0710, 0.0041, 0.0160, 0.0177, 0.0288, 0.1246,
        0.0404, 0.1632, 0.0319, 0.1267], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,529][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ decided] are: tensor([0.5598, 0.0550, 0.0035, 0.0057, 0.0041, 0.0038, 0.0124, 0.0068, 0.0144,
        0.0451, 0.1861, 0.0440, 0.0593], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,529][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ decided] are: tensor([8.5347e-02, 1.8744e-01, 8.9500e-04, 1.3418e-02, 9.1937e-05, 2.0882e-03,
        8.4901e-03, 8.2942e-02, 1.1059e-01, 8.4345e-02, 3.3549e-01, 1.4612e-02,
        7.4242e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,530][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0666, 0.1789, 0.0153, 0.0217, 0.0048, 0.0138, 0.0952, 0.0393, 0.0605,
        0.0273, 0.0500, 0.0083, 0.0483, 0.3700], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,530][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0359, 0.0690, 0.0253, 0.0281, 0.0235, 0.0145, 0.0101, 0.0167, 0.0514,
        0.0550, 0.2129, 0.0549, 0.0703, 0.3324], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,531][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0024, 0.0936, 0.0018, 0.0203, 0.0015, 0.0020, 0.0033, 0.0099, 0.0307,
        0.0181, 0.1064, 0.0160, 0.0256, 0.6684], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,531][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.3090e-01, 3.9278e-03, 5.2242e-07, 1.3097e-05, 7.0204e-08, 5.0533e-05,
        1.3191e-04, 2.4811e-03, 2.2516e-03, 1.1622e-02, 1.4203e-02, 4.1683e-04,
        1.8198e-03, 3.2179e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,533][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0009, 0.0546, 0.0046, 0.0232, 0.0019, 0.0113, 0.0201, 0.0749, 0.0688,
        0.0455, 0.1000, 0.0080, 0.0430, 0.5432], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,535][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0028, 0.0971, 0.0648, 0.0776, 0.0085, 0.0056, 0.0087, 0.0458, 0.0845,
        0.0301, 0.0738, 0.0277, 0.0599, 0.4130], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,537][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.8891e-02, 5.2963e-02, 9.8844e-04, 9.8407e-03, 2.2892e-04, 8.8558e-04,
        9.5902e-04, 6.6954e-03, 1.5915e-02, 1.0687e-02, 5.3251e-02, 4.1729e-03,
        9.0225e-03, 8.1550e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,541][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0849, 0.0081, 0.0173, 0.0147, 0.0099, 0.0125, 0.0062, 0.0186, 0.0230,
        0.0147, 0.0641, 0.0857, 0.1083, 0.5321], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,542][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0293, 0.2025, 0.0095, 0.0521, 0.0093, 0.0141, 0.0384, 0.0495, 0.1292,
        0.0138, 0.0766, 0.0111, 0.0500, 0.3146], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,542][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0056, 0.0962, 0.0269, 0.0270, 0.0016, 0.0036, 0.0034, 0.0052, 0.0254,
        0.0086, 0.0314, 0.0103, 0.0304, 0.7244], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,543][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.6914e-01, 4.6349e-02, 1.6895e-03, 1.5503e-03, 1.2309e-03, 4.5675e-04,
        1.5397e-03, 7.8838e-04, 1.4622e-03, 4.4499e-03, 3.1806e-02, 8.9465e-03,
        7.1350e-03, 2.3459e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,543][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.7596e-01, 6.6693e-02, 7.8872e-04, 2.0940e-03, 4.5587e-05, 4.9595e-04,
        1.4139e-03, 1.7136e-02, 1.7655e-02, 1.2615e-02, 5.3611e-02, 7.0178e-03,
        1.7579e-02, 5.2690e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,543][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0080, 0.0927, 0.0116, 0.0138, 0.0031, 0.0094, 0.0748, 0.0297, 0.0535,
        0.0289, 0.0483, 0.0061, 0.0455, 0.3428, 0.2318], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,544][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0093, 0.0280, 0.0080, 0.0143, 0.0062, 0.0131, 0.0077, 0.0154, 0.0559,
        0.0592, 0.1777, 0.0481, 0.0892, 0.3630, 0.1048], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,544][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([3.3766e-04, 2.9721e-02, 8.7124e-04, 9.4701e-03, 5.7540e-04, 1.7297e-03,
        4.3078e-03, 1.0312e-02, 3.3421e-02, 2.0736e-02, 8.4296e-02, 1.0130e-02,
        3.4100e-02, 6.9924e-01, 6.0750e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,545][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([2.1345e-01, 1.2471e-02, 1.3386e-06, 7.5159e-05, 2.1411e-07, 3.5275e-04,
        1.0658e-03, 2.0738e-02, 2.4281e-02, 1.1230e-01, 1.3559e-01, 2.4974e-03,
        2.0325e-02, 4.1653e-01, 4.0326e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,547][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0009, 0.0357, 0.0026, 0.0136, 0.0009, 0.0101, 0.0176, 0.0635, 0.0687,
        0.0416, 0.1092, 0.0062, 0.0498, 0.4680, 0.1116], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,550][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0014, 0.0519, 0.0191, 0.0335, 0.0026, 0.0042, 0.0099, 0.0369, 0.0667,
        0.0326, 0.0645, 0.0218, 0.0945, 0.4535, 0.1068], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,552][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([2.6344e-03, 2.0905e-02, 3.3326e-04, 5.7803e-03, 7.2122e-05, 7.4053e-04,
        1.1992e-03, 6.5305e-03, 1.4727e-02, 1.0227e-02, 4.7110e-02, 2.4840e-03,
        9.5557e-03, 8.1152e-01, 6.6183e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,555][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0112, 0.0123, 0.0103, 0.0111, 0.0031, 0.0087, 0.0069, 0.0206, 0.0313,
        0.0146, 0.0626, 0.0349, 0.1106, 0.5024, 0.1594], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,555][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0386, 0.1415, 0.0040, 0.0357, 0.0034, 0.0166, 0.0327, 0.0656, 0.1176,
        0.0253, 0.0965, 0.0105, 0.0563, 0.3013, 0.0543], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,555][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([9.3200e-04, 4.3034e-02, 7.8730e-03, 1.1533e-02, 3.2377e-04, 2.1789e-03,
        2.3442e-03, 3.6126e-03, 1.4175e-02, 7.8770e-03, 2.3958e-02, 5.1357e-03,
        2.3771e-02, 7.5736e-01, 9.5894e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,556][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.4456, 0.0799, 0.0030, 0.0039, 0.0030, 0.0019, 0.0072, 0.0038, 0.0085,
        0.0243, 0.1599, 0.0379, 0.0436, 0.1524, 0.0250], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,556][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([6.5148e-02, 4.1472e-02, 3.5273e-04, 1.6328e-03, 2.9275e-05, 3.6364e-04,
        1.5100e-03, 2.3312e-02, 2.9337e-02, 2.1921e-02, 4.5208e-02, 5.7457e-03,
        1.3308e-02, 6.6353e-01, 8.7132e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,557][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0228, 0.1132, 0.0158, 0.0144, 0.0046, 0.0146, 0.0757, 0.0311, 0.0460,
        0.0316, 0.0407, 0.0072, 0.0422, 0.2407, 0.1620, 0.1375],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,557][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0078, 0.0368, 0.0199, 0.0214, 0.0160, 0.0266, 0.0114, 0.0205, 0.0516,
        0.0686, 0.1783, 0.0485, 0.0708, 0.2808, 0.0825, 0.0584],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,558][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.3497e-04, 3.8496e-02, 6.9344e-04, 1.3519e-02, 9.3154e-04, 2.3413e-03,
        3.4997e-03, 1.0032e-02, 3.9697e-02, 2.1714e-02, 1.0273e-01, 1.0130e-02,
        2.7338e-02, 6.4192e-01, 5.0505e-02, 3.6220e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,559][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.1297e-01, 4.3442e-03, 1.4906e-06, 3.0151e-05, 2.9398e-07, 2.2569e-04,
        7.5129e-04, 1.0192e-02, 7.0868e-03, 3.1788e-02, 3.8708e-02, 1.6369e-03,
        8.0773e-03, 6.8967e-02, 1.0193e-02, 5.0247e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,563][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0008, 0.0250, 0.0027, 0.0146, 0.0012, 0.0150, 0.0177, 0.0842, 0.0634,
        0.0537, 0.0903, 0.0061, 0.0485, 0.3183, 0.1068, 0.1517],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,566][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0016, 0.0788, 0.0442, 0.0609, 0.0075, 0.0080, 0.0144, 0.0480, 0.0714,
        0.0395, 0.0630, 0.0270, 0.0776, 0.2727, 0.0889, 0.0965],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,568][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.9002e-03, 4.1167e-02, 9.7302e-04, 1.3093e-02, 2.2509e-04, 1.5940e-03,
        1.4053e-03, 9.2095e-03, 1.8772e-02, 1.3366e-02, 5.7705e-02, 2.9882e-03,
        8.9708e-03, 6.9784e-01, 6.8933e-02, 6.0855e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,568][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0158, 0.0096, 0.0140, 0.0143, 0.0057, 0.0201, 0.0112, 0.0240, 0.0399,
        0.0140, 0.0783, 0.0342, 0.1123, 0.3527, 0.1351, 0.1188],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,568][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1755, 0.1595, 0.0067, 0.0504, 0.0082, 0.0186, 0.0258, 0.0471, 0.0910,
        0.0174, 0.0768, 0.0088, 0.0445, 0.1737, 0.0292, 0.0669],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,569][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0006, 0.0836, 0.0191, 0.0238, 0.0013, 0.0049, 0.0049, 0.0050, 0.0178,
        0.0094, 0.0321, 0.0064, 0.0257, 0.5260, 0.1001, 0.1392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,569][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6140, 0.0613, 0.0059, 0.0038, 0.0058, 0.0021, 0.0087, 0.0033, 0.0080,
        0.0178, 0.0881, 0.0343, 0.0308, 0.0790, 0.0131, 0.0238],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,570][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.2462e-02, 2.9853e-02, 9.8930e-04, 2.6575e-03, 6.4409e-05, 1.0435e-03,
        1.6262e-03, 1.8791e-02, 2.9377e-02, 2.0541e-02, 7.9733e-02, 6.7308e-03,
        2.5138e-02, 5.2131e-01, 9.9802e-02, 1.0988e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,570][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0194, 0.0774, 0.0060, 0.0080, 0.0023, 0.0121, 0.0826, 0.0229, 0.0429,
        0.0289, 0.0397, 0.0071, 0.0542, 0.2442, 0.1686, 0.1445, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,572][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0118, 0.0730, 0.0130, 0.0249, 0.0074, 0.0172, 0.0098, 0.0265, 0.0724,
        0.0768, 0.1878, 0.0373, 0.0639, 0.2162, 0.0702, 0.0526, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,574][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([1.1046e-04, 4.8424e-02, 5.5466e-04, 1.5242e-02, 4.4771e-04, 1.4566e-03,
        3.4459e-03, 7.7576e-03, 3.1272e-02, 2.1653e-02, 7.5268e-02, 7.1538e-03,
        2.8368e-02, 5.8541e-01, 5.4465e-02, 4.3334e-02, 7.5638e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,576][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([4.6179e-01, 2.0575e-02, 9.2641e-07, 8.1942e-05, 1.4783e-07, 3.6855e-04,
        9.4285e-04, 1.5082e-02, 1.2883e-02, 4.9740e-02, 7.8994e-02, 1.2779e-03,
        1.1543e-02, 2.6031e-01, 2.3739e-02, 1.6495e-02, 4.6176e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,579][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0005, 0.0520, 0.0035, 0.0165, 0.0011, 0.0109, 0.0182, 0.0556, 0.0673,
        0.0408, 0.0891, 0.0052, 0.0400, 0.2122, 0.0740, 0.1294, 0.1838],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,580][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0008, 0.0727, 0.0250, 0.0409, 0.0029, 0.0031, 0.0150, 0.0390, 0.0585,
        0.0216, 0.0526, 0.0167, 0.0712, 0.2525, 0.1176, 0.1073, 0.1025],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,581][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([1.0003e-03, 9.6113e-02, 1.0025e-03, 9.6396e-03, 9.9648e-05, 1.0350e-03,
        1.2542e-03, 9.2595e-03, 2.1613e-02, 1.3208e-02, 5.4984e-02, 2.0775e-03,
        8.7476e-03, 5.6892e-01, 5.5367e-02, 1.2277e-01, 3.2914e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,581][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0101, 0.0075, 0.0089, 0.0085, 0.0034, 0.0086, 0.0101, 0.0214, 0.0280,
        0.0169, 0.0676, 0.0376, 0.1380, 0.2535, 0.1920, 0.1611, 0.0269],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,582][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0122, 0.0544, 0.0029, 0.0379, 0.0030, 0.0138, 0.0417, 0.0461, 0.1233,
        0.0208, 0.0831, 0.0080, 0.0475, 0.2857, 0.0522, 0.1269, 0.0405],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,582][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([3.2736e-04, 8.0723e-02, 1.4899e-02, 1.2478e-02, 6.4808e-04, 2.6017e-03,
        3.1780e-03, 3.7123e-03, 1.7644e-02, 6.2691e-03, 2.2606e-02, 4.2384e-03,
        2.1333e-02, 4.4691e-01, 9.6221e-02, 2.2161e-01, 4.4598e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,582][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.6665, 0.0701, 0.0018, 0.0046, 0.0017, 0.0017, 0.0061, 0.0024, 0.0045,
        0.0135, 0.0847, 0.0149, 0.0166, 0.0499, 0.0131, 0.0216, 0.0263],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,583][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([9.4256e-03, 6.2026e-02, 4.7053e-04, 3.3451e-03, 3.3450e-05, 8.4975e-04,
        1.0097e-03, 1.3372e-02, 1.9672e-02, 1.2096e-02, 8.5514e-02, 2.7173e-03,
        1.9653e-02, 4.9719e-01, 7.2608e-02, 1.3227e-01, 6.7754e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,583][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0322, 0.0656, 0.0095, 0.0088, 0.0030, 0.0082, 0.0678, 0.0207, 0.0376,
        0.0171, 0.0297, 0.0046, 0.0334, 0.2107, 0.1369, 0.1455, 0.0164, 0.1522],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,585][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0300, 0.0287, 0.0149, 0.0169, 0.0153, 0.0154, 0.0062, 0.0115, 0.0338,
        0.0487, 0.1367, 0.0528, 0.0509, 0.2016, 0.0542, 0.0386, 0.0220, 0.2217],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,588][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0011, 0.0488, 0.0008, 0.0130, 0.0009, 0.0018, 0.0027, 0.0061, 0.0222,
        0.0147, 0.0672, 0.0102, 0.0181, 0.4330, 0.0332, 0.0315, 0.0367, 0.2580],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,590][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.3650e-01, 1.0762e-03, 2.9915e-07, 4.8968e-06, 5.1923e-08, 3.5423e-05,
        8.5398e-05, 1.5264e-03, 1.1521e-03, 7.7210e-03, 9.5602e-03, 3.6559e-04,
        1.4586e-03, 2.0780e-02, 2.4350e-03, 1.6408e-03, 2.7652e-03, 1.2897e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,594][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0009, 0.0296, 0.0023, 0.0115, 0.0008, 0.0077, 0.0106, 0.0377, 0.0330,
        0.0285, 0.0532, 0.0042, 0.0244, 0.2067, 0.0456, 0.0801, 0.1236, 0.2997],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,596][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0028, 0.0627, 0.0347, 0.0546, 0.0046, 0.0041, 0.0091, 0.0315, 0.0463,
        0.0220, 0.0430, 0.0214, 0.0557, 0.2304, 0.0702, 0.0884, 0.0628, 0.1557],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,596][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([6.7195e-03, 5.0094e-02, 8.6877e-04, 8.6200e-03, 1.5899e-04, 8.9014e-04,
        8.5856e-04, 4.7360e-03, 1.0477e-02, 7.3208e-03, 3.4151e-02, 2.2777e-03,
        4.8084e-03, 4.9141e-01, 3.7964e-02, 6.0056e-02, 1.4981e-02, 2.6361e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,597][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0493, 0.0051, 0.0132, 0.0111, 0.0064, 0.0129, 0.0052, 0.0131, 0.0181,
        0.0104, 0.0533, 0.0522, 0.1012, 0.2730, 0.1158, 0.1149, 0.0196, 0.1252],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,597][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0534, 0.0979, 0.0092, 0.0365, 0.0115, 0.0141, 0.0356, 0.0339, 0.0823,
        0.0130, 0.0588, 0.0094, 0.0479, 0.2114, 0.0349, 0.1025, 0.0174, 0.1303],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,597][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0018, 0.0480, 0.0091, 0.0131, 0.0005, 0.0019, 0.0020, 0.0016, 0.0076,
        0.0040, 0.0149, 0.0041, 0.0119, 0.3320, 0.0560, 0.1165, 0.0257, 0.3493],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,598][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.4346e-01, 1.0656e-02, 9.2221e-04, 5.2838e-04, 8.0184e-04, 2.3837e-04,
        6.6812e-04, 2.1440e-04, 4.7474e-04, 1.6594e-03, 1.0923e-02, 4.1374e-03,
        2.5913e-03, 6.4937e-03, 1.3308e-03, 2.5426e-03, 1.8616e-03, 1.0498e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,598][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.7889e-01, 2.4013e-02, 5.8468e-04, 1.3058e-03, 3.6227e-05, 3.9590e-04,
        5.7845e-04, 7.2759e-03, 8.9899e-03, 7.1956e-03, 3.5063e-02, 3.3177e-03,
        8.6784e-03, 2.1175e-01, 4.1147e-02, 5.6457e-02, 2.5830e-02, 3.8849e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,636][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:21,638][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,639][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,639][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,640][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,640][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,640][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,641][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,641][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,641][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,642][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,642][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,642][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:30:21,643][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6146, 0.3854], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,643][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7770, 0.2230], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,643][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0822, 0.9178], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,644][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,644][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0272, 0.9728], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,644][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1188, 0.8812], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,645][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4595, 0.5405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,645][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8385, 0.1615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,645][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8875, 0.1125], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,646][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7202, 0.2798], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,646][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8017, 0.1983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,647][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1973, 0.8027], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:30:21,647][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Samuel] are: tensor([0.0999, 0.4819, 0.4182], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,647][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Samuel] are: tensor([0.0447, 0.3478, 0.6075], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,648][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Samuel] are: tensor([8.0051e-04, 9.6171e-01, 3.7486e-02], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,651][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Samuel] are: tensor([0.9656, 0.0266, 0.0078], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,658][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Samuel] are: tensor([0.0081, 0.8208, 0.1712], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,659][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Samuel] are: tensor([0.0176, 0.4348, 0.5477], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,661][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Samuel] are: tensor([0.0077, 0.9442, 0.0482], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,664][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Samuel] are: tensor([0.0304, 0.2970, 0.6726], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,668][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Samuel] are: tensor([0.2384, 0.0894, 0.6722], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,669][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Samuel] are: tensor([0.0016, 0.6584, 0.3399], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,670][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Samuel] are: tensor([0.5088, 0.2487, 0.2424], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,670][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Samuel] are: tensor([0.0114, 0.4035, 0.5851], device='cuda:0') for source tokens [Then, Samuel]
[2024-07-24 10:30:21,670][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2456, 0.5571, 0.0994, 0.0980], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,671][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0698, 0.3174, 0.2192, 0.3937], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,671][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0043, 0.4001, 0.0277, 0.5679], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,671][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.9238e-01, 6.8899e-03, 1.2512e-04, 6.0670e-04], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,671][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0031, 0.4481, 0.0778, 0.4710], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,672][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0238, 0.1543, 0.4198, 0.4020], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,672][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0502, 0.4235, 0.0282, 0.4981], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,672][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1703, 0.0591, 0.4435, 0.3271], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,674][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0069, 0.4891, 0.2128, 0.2911], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,677][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0103, 0.2647, 0.3009, 0.4240], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,681][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5342, 0.2216, 0.1172, 0.1270], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,683][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1869, 0.5451, 0.1014, 0.1666], device='cuda:0') for source tokens [Then, Samuel and]
[2024-07-24 10:30:21,683][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.0334, 0.3305, 0.2317, 0.3146, 0.0899], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,684][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0064, 0.4117, 0.1235, 0.3900, 0.0685], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,684][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([3.7919e-04, 4.8780e-01, 1.0973e-02, 4.9277e-01, 8.0787e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,684][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([0.4434, 0.2471, 0.0337, 0.2576, 0.0181], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,685][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0017, 0.4782, 0.0635, 0.4219, 0.0346], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,685][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0026, 0.3213, 0.1662, 0.4821, 0.0278], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,685][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0034, 0.5892, 0.0142, 0.3880, 0.0053], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,685][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0119, 0.1304, 0.3085, 0.4064, 0.1428], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,686][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.2112, 0.1222, 0.1433, 0.3116, 0.2116], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,687][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([1.7241e-04, 5.6373e-01, 8.5738e-02, 3.4111e-01, 9.2499e-03],
       device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,689][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.1990, 0.0832, 0.1661, 0.2190, 0.3328], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,692][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0115, 0.4162, 0.1211, 0.4381, 0.0131], device='cuda:0') for source tokens [Then, Samuel and Matthew]
[2024-07-24 10:30:21,696][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0926, 0.5379, 0.0938, 0.1153, 0.0247, 0.1357], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,697][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0464, 0.2489, 0.1401, 0.1731, 0.1034, 0.2881], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,697][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0039, 0.5937, 0.0156, 0.3152, 0.0136, 0.0581], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,697][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([7.7954e-01, 1.8693e-01, 3.3157e-04, 4.2055e-03, 1.1024e-04, 2.8890e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,698][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0042, 0.4412, 0.0433, 0.2086, 0.0173, 0.2854], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,698][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0388, 0.2439, 0.2130, 0.3496, 0.0307, 0.1240], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,698][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0366, 0.5678, 0.0118, 0.2943, 0.0054, 0.0841], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,699][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1185, 0.0824, 0.1178, 0.1431, 0.0655, 0.4727], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,699][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0023, 0.6862, 0.0615, 0.1429, 0.0338, 0.0734], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,699][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0016, 0.6523, 0.0967, 0.1808, 0.0135, 0.0550], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,700][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.7044, 0.0739, 0.0759, 0.0314, 0.0814, 0.0330], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,701][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.2603, 0.5525, 0.0276, 0.1336, 0.0036, 0.0224], device='cuda:0') for source tokens [Then, Samuel and Matthew were]
[2024-07-24 10:30:21,704][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ working] are: tensor([0.0434, 0.3997, 0.0273, 0.0537, 0.0135, 0.0557, 0.4068],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,708][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ working] are: tensor([0.0246, 0.4600, 0.0558, 0.1871, 0.0363, 0.1254, 0.1109],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,710][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ working] are: tensor([0.0016, 0.7432, 0.0055, 0.1680, 0.0029, 0.0319, 0.0469],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,710][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ working] are: tensor([6.1330e-01, 2.4322e-01, 7.1013e-05, 5.8355e-03, 2.2653e-05, 2.6404e-02,
        1.1114e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,711][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ working] are: tensor([0.0053, 0.4857, 0.0324, 0.1463, 0.0142, 0.1163, 0.1999],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,711][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ working] are: tensor([0.0153, 0.4834, 0.0884, 0.2284, 0.0220, 0.0626, 0.0999],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,711][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ working] are: tensor([0.0491, 0.7387, 0.0079, 0.1443, 0.0016, 0.0306, 0.0278],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,712][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ working] are: tensor([0.0507, 0.1022, 0.1215, 0.1601, 0.0693, 0.2143, 0.2819],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,712][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ working] are: tensor([0.0299, 0.6406, 0.0412, 0.1733, 0.0294, 0.0162, 0.0694],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,712][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ working] are: tensor([0.0164, 0.5608, 0.0786, 0.2331, 0.0101, 0.0690, 0.0320],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,713][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ working] are: tensor([0.8804, 0.0537, 0.0045, 0.0136, 0.0076, 0.0081, 0.0322],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,713][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ working] are: tensor([0.0681, 0.7627, 0.0141, 0.0476, 0.0010, 0.0282, 0.0782],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working]
[2024-07-24 10:30:21,715][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0711, 0.2860, 0.0326, 0.0435, 0.0121, 0.0465, 0.3611, 0.1470],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,717][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0502, 0.1895, 0.0855, 0.1656, 0.0688, 0.1682, 0.1055, 0.1667],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,721][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0036, 0.5857, 0.0085, 0.1729, 0.0083, 0.0356, 0.0563, 0.1291],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,724][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([8.0424e-01, 3.1099e-02, 3.0696e-05, 1.2405e-03, 8.2781e-06, 4.8230e-03,
        1.4854e-02, 1.4371e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,724][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0076, 0.2655, 0.0257, 0.1094, 0.0135, 0.1017, 0.1387, 0.3378],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,724][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0043, 0.3563, 0.1335, 0.1876, 0.0283, 0.0422, 0.0324, 0.2153],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,725][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0598, 0.4988, 0.0136, 0.1706, 0.0048, 0.0467, 0.0336, 0.1722],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,725][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0576, 0.0991, 0.1084, 0.1606, 0.0680, 0.1505, 0.0925, 0.2632],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,725][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0045, 0.6186, 0.0430, 0.1287, 0.0270, 0.0258, 0.0674, 0.0850],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,726][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0120, 0.3793, 0.1410, 0.2010, 0.0320, 0.0745, 0.0461, 0.1141],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,726][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.9655, 0.0131, 0.0012, 0.0025, 0.0021, 0.0016, 0.0111, 0.0029],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,726][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.3932, 0.1585, 0.0129, 0.0408, 0.0017, 0.0291, 0.0464, 0.3176],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at]
[2024-07-24 10:30:21,727][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1585, 0.2334, 0.0191, 0.0340, 0.0069, 0.0263, 0.2399, 0.0929, 0.1889],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,728][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0215, 0.2190, 0.0922, 0.1315, 0.0685, 0.0765, 0.0526, 0.0867, 0.2515],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,731][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0033, 0.5084, 0.0083, 0.1321, 0.0072, 0.0193, 0.0261, 0.0775, 0.2178],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,733][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.6725e-01, 3.4682e-02, 8.9214e-06, 5.8799e-04, 1.5312e-06, 1.0938e-03,
        4.0003e-03, 4.5405e-02, 4.6971e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,737][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0015, 0.1643, 0.0133, 0.0775, 0.0091, 0.0530, 0.0808, 0.3161, 0.2844],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,738][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0028, 0.3164, 0.0791, 0.1692, 0.0159, 0.0198, 0.0186, 0.1323, 0.2459],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,738][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0416, 0.5164, 0.0104, 0.1081, 0.0029, 0.0196, 0.0139, 0.0909, 0.1963],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,738][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0212, 0.1110, 0.1126, 0.1663, 0.0722, 0.0967, 0.0654, 0.1388, 0.2160],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,739][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0472, 0.4861, 0.0204, 0.1414, 0.0179, 0.0246, 0.0391, 0.0655, 0.1578],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,739][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0096, 0.4244, 0.1090, 0.1191, 0.0119, 0.0377, 0.0191, 0.0509, 0.2183],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,739][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9607, 0.0220, 0.0011, 0.0018, 0.0013, 0.0011, 0.0050, 0.0016, 0.0054],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,740][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1467, 0.3571, 0.0095, 0.0301, 0.0007, 0.0102, 0.0153, 0.1602, 0.2702],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the]
[2024-07-24 10:30:21,740][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0525, 0.1073, 0.0144, 0.0233, 0.0075, 0.0399, 0.3010, 0.1086, 0.1754,
        0.1702], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,742][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0066, 0.3501, 0.0543, 0.1275, 0.0296, 0.0559, 0.0238, 0.0500, 0.1616,
        0.1404], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,744][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0018, 0.4695, 0.0042, 0.1268, 0.0046, 0.0167, 0.0233, 0.0586, 0.1825,
        0.1120], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,747][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([6.0945e-01, 2.9357e-02, 3.7406e-06, 3.6900e-04, 8.9624e-07, 1.4266e-03,
        4.2251e-03, 6.8355e-02, 6.7745e-02, 2.1907e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,751][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0019, 0.2630, 0.0119, 0.0694, 0.0045, 0.0467, 0.0721, 0.1677, 0.2613,
        0.1016], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,751][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0009, 0.2911, 0.0590, 0.1742, 0.0127, 0.0169, 0.0365, 0.1176, 0.2272,
        0.0640], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,752][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0061, 0.6394, 0.0048, 0.0681, 0.0012, 0.0086, 0.0083, 0.0539, 0.1362,
        0.0733], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,752][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0087, 0.2392, 0.0666, 0.1326, 0.0271, 0.0512, 0.0556, 0.1464, 0.1815,
        0.0910], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,752][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0007, 0.3467, 0.0154, 0.0426, 0.0114, 0.0198, 0.1174, 0.1270, 0.2687,
        0.0502], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,753][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([3.5626e-04, 5.2942e-01, 5.1300e-02, 1.1385e-01, 6.8951e-03, 1.6609e-02,
        1.6917e-02, 3.6696e-02, 1.7989e-01, 4.8070e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,753][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.8883, 0.0450, 0.0033, 0.0068, 0.0050, 0.0024, 0.0126, 0.0040, 0.0105,
        0.0221], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,753][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1441, 0.1901, 0.0044, 0.0228, 0.0004, 0.0091, 0.0259, 0.1676, 0.2545,
        0.1811], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station]
[2024-07-24 10:30:21,754][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1054, 0.2452, 0.0350, 0.0274, 0.0105, 0.0202, 0.1871, 0.0731, 0.1251,
        0.0725, 0.0985], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,754][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0362, 0.1089, 0.0680, 0.0587, 0.0488, 0.0340, 0.0189, 0.0317, 0.0991,
        0.0944, 0.4014], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,756][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0048, 0.2347, 0.0094, 0.1238, 0.0084, 0.0113, 0.0124, 0.0314, 0.1263,
        0.0554, 0.3820], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,758][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([8.8416e-01, 6.8068e-03, 4.8825e-06, 9.6790e-05, 1.2470e-06, 3.9807e-04,
        1.1729e-03, 1.3040e-02, 1.2073e-02, 4.3747e-02, 3.8502e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,761][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0040, 0.0866, 0.0155, 0.0510, 0.0105, 0.0350, 0.0567, 0.1695, 0.1872,
        0.1197, 0.2642], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,765][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0094, 0.1109, 0.1133, 0.1199, 0.0217, 0.0184, 0.0322, 0.1077, 0.1626,
        0.0841, 0.2199], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,765][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0567, 0.2847, 0.0083, 0.0654, 0.0021, 0.0093, 0.0068, 0.0371, 0.0952,
        0.0571, 0.3773], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,765][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0510, 0.0423, 0.0999, 0.0833, 0.0475, 0.0591, 0.0393, 0.0768, 0.1036,
        0.0638, 0.3333], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,766][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0042, 0.3984, 0.0258, 0.0651, 0.0164, 0.0230, 0.0757, 0.0959, 0.1884,
        0.0236, 0.0834], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,766][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0079, 0.2798, 0.1217, 0.1214, 0.0118, 0.0200, 0.0175, 0.0327, 0.1325,
        0.0515, 0.2031], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,767][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.9048, 0.0211, 0.0052, 0.0024, 0.0056, 0.0011, 0.0038, 0.0013, 0.0026,
        0.0100, 0.0419], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,767][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.3247, 0.1338, 0.0054, 0.0135, 0.0006, 0.0028, 0.0086, 0.0680, 0.0835,
        0.0521, 0.3071], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station.]
[2024-07-24 10:30:21,767][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Matthew] are: tensor([0.0063, 0.0847, 0.0156, 0.0274, 0.0081, 0.0296, 0.2785, 0.0899, 0.1646,
        0.1464, 0.1150, 0.0341], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,768][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Matthew] are: tensor([0.0031, 0.0770, 0.0233, 0.0461, 0.0154, 0.0477, 0.0336, 0.0662, 0.1286,
        0.2411, 0.2328, 0.0851], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,769][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Matthew] are: tensor([0.0010, 0.0909, 0.0056, 0.0735, 0.0066, 0.0146, 0.0314, 0.0760, 0.1607,
        0.1638, 0.2991, 0.0768], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,771][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Matthew] are: tensor([1.0973e-02, 2.7300e-03, 1.8563e-05, 3.1360e-04, 6.0502e-06, 3.6560e-03,
        1.8802e-02, 9.3263e-02, 9.0202e-02, 4.6231e-01, 3.0717e-01, 1.0554e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,774][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Matthew] are: tensor([0.0007, 0.0797, 0.0175, 0.0419, 0.0063, 0.0552, 0.0893, 0.2020, 0.2261,
        0.0802, 0.1762, 0.0249], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,778][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Matthew] are: tensor([0.0006, 0.1397, 0.0579, 0.0815, 0.0118, 0.0219, 0.0519, 0.1797, 0.1672,
        0.0688, 0.1678, 0.0511], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,779][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Matthew] are: tensor([0.0034, 0.2264, 0.0095, 0.0496, 0.0031, 0.0118, 0.0196, 0.0882, 0.1488,
        0.1071, 0.2929, 0.0396], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,779][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Matthew] are: tensor([0.0084, 0.0311, 0.0452, 0.0326, 0.0180, 0.0413, 0.0914, 0.1528, 0.1439,
        0.1140, 0.1919, 0.1294], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,779][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Matthew] are: tensor([0.0256, 0.0443, 0.0147, 0.0506, 0.0237, 0.0583, 0.1063, 0.1415, 0.2418,
        0.0815, 0.1412, 0.0705], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,780][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Matthew] are: tensor([0.0005, 0.2939, 0.1038, 0.0798, 0.0118, 0.0293, 0.0417, 0.0585, 0.1329,
        0.0657, 0.1302, 0.0519], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,780][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Matthew] are: tensor([0.0629, 0.0480, 0.0071, 0.0138, 0.0102, 0.0142, 0.0794, 0.0314, 0.0682,
        0.1757, 0.3309, 0.1583], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,780][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Matthew] are: tensor([0.0041, 0.0241, 0.0031, 0.0116, 0.0005, 0.0055, 0.0316, 0.1482, 0.1666,
        0.1954, 0.3739, 0.0354], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew]
[2024-07-24 10:30:21,781][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ decided] are: tensor([0.0264, 0.1629, 0.0166, 0.0303, 0.0077, 0.0237, 0.1785, 0.0698, 0.1153,
        0.0803, 0.1180, 0.0204, 0.1501], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,781][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ decided] are: tensor([0.0085, 0.1143, 0.0158, 0.0457, 0.0122, 0.0262, 0.0172, 0.0409, 0.1033,
        0.1252, 0.3388, 0.0498, 0.1020], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,783][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ decided] are: tensor([0.0006, 0.2378, 0.0027, 0.0491, 0.0019, 0.0077, 0.0144, 0.0429, 0.1240,
        0.0752, 0.3073, 0.0260, 0.1105], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,785][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ decided] are: tensor([1.9928e-01, 3.2833e-02, 5.5357e-06, 3.5935e-04, 1.0562e-06, 1.3309e-03,
        4.3381e-03, 5.2278e-02, 6.0405e-02, 2.8882e-01, 2.9311e-01, 7.7284e-03,
        5.9510e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,788][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ decided] are: tensor([0.0005, 0.1280, 0.0061, 0.0299, 0.0018, 0.0265, 0.0534, 0.1369, 0.1909,
        0.0765, 0.2230, 0.0111, 0.1155], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,792][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ decided] are: tensor([0.0015, 0.1575, 0.0506, 0.0812, 0.0087, 0.0152, 0.0278, 0.0997, 0.1499,
        0.0509, 0.1362, 0.0430, 0.1777], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,792][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ decided] are: tensor([0.0059, 0.3647, 0.0034, 0.0398, 0.0007, 0.0063, 0.0075, 0.0512, 0.1102,
        0.0565, 0.2774, 0.0139, 0.0624], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,793][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ decided] are: tensor([0.0274, 0.0394, 0.0246, 0.0355, 0.0072, 0.0279, 0.0269, 0.0849, 0.1070,
        0.0438, 0.1866, 0.0881, 0.3007], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,793][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ decided] are: tensor([0.0333, 0.1999, 0.0077, 0.0726, 0.0065, 0.0354, 0.0405, 0.0733, 0.2054,
        0.0403, 0.1526, 0.0208, 0.1117], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,793][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ decided] are: tensor([0.0018, 0.3303, 0.0434, 0.0710, 0.0041, 0.0160, 0.0177, 0.0288, 0.1246,
        0.0404, 0.1632, 0.0319, 0.1267], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,794][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ decided] are: tensor([0.5598, 0.0550, 0.0035, 0.0057, 0.0041, 0.0038, 0.0124, 0.0068, 0.0144,
        0.0451, 0.1861, 0.0440, 0.0593], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,794][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ decided] are: tensor([8.5347e-02, 1.8744e-01, 8.9500e-04, 1.3418e-02, 9.1937e-05, 2.0882e-03,
        8.4901e-03, 8.2942e-02, 1.1059e-01, 8.4345e-02, 3.3549e-01, 1.4612e-02,
        7.4242e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided]
[2024-07-24 10:30:21,795][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0666, 0.1789, 0.0153, 0.0217, 0.0048, 0.0138, 0.0952, 0.0393, 0.0605,
        0.0273, 0.0500, 0.0083, 0.0483, 0.3700], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,795][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0359, 0.0690, 0.0253, 0.0281, 0.0235, 0.0145, 0.0101, 0.0167, 0.0514,
        0.0550, 0.2129, 0.0549, 0.0703, 0.3324], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,797][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0024, 0.0936, 0.0018, 0.0203, 0.0015, 0.0020, 0.0033, 0.0099, 0.0307,
        0.0181, 0.1064, 0.0160, 0.0256, 0.6684], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,799][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.3090e-01, 3.9278e-03, 5.2242e-07, 1.3097e-05, 7.0204e-08, 5.0533e-05,
        1.3191e-04, 2.4811e-03, 2.2516e-03, 1.1622e-02, 1.4203e-02, 4.1683e-04,
        1.8198e-03, 3.2179e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,802][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0009, 0.0546, 0.0046, 0.0232, 0.0019, 0.0113, 0.0201, 0.0749, 0.0688,
        0.0455, 0.1000, 0.0080, 0.0430, 0.5432], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,806][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0028, 0.0971, 0.0648, 0.0776, 0.0085, 0.0056, 0.0087, 0.0458, 0.0845,
        0.0301, 0.0738, 0.0277, 0.0599, 0.4130], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,806][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.8891e-02, 5.2963e-02, 9.8844e-04, 9.8407e-03, 2.2892e-04, 8.8558e-04,
        9.5902e-04, 6.6954e-03, 1.5915e-02, 1.0687e-02, 5.3251e-02, 4.1729e-03,
        9.0225e-03, 8.1550e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,806][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0849, 0.0081, 0.0173, 0.0147, 0.0099, 0.0125, 0.0062, 0.0186, 0.0230,
        0.0147, 0.0641, 0.0857, 0.1083, 0.5321], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,807][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0293, 0.2025, 0.0095, 0.0521, 0.0093, 0.0141, 0.0384, 0.0495, 0.1292,
        0.0138, 0.0766, 0.0111, 0.0500, 0.3146], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,807][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0056, 0.0962, 0.0269, 0.0270, 0.0016, 0.0036, 0.0034, 0.0052, 0.0254,
        0.0086, 0.0314, 0.0103, 0.0304, 0.7244], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,807][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.6914e-01, 4.6349e-02, 1.6895e-03, 1.5503e-03, 1.2309e-03, 4.5675e-04,
        1.5397e-03, 7.8838e-04, 1.4622e-03, 4.4499e-03, 3.1806e-02, 8.9465e-03,
        7.1350e-03, 2.3459e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,808][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.7596e-01, 6.6693e-02, 7.8872e-04, 2.0940e-03, 4.5587e-05, 4.9595e-04,
        1.4139e-03, 1.7136e-02, 1.7655e-02, 1.2615e-02, 5.3611e-02, 7.0178e-03,
        1.7579e-02, 5.2690e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to]
[2024-07-24 10:30:21,808][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0080, 0.0927, 0.0116, 0.0138, 0.0031, 0.0094, 0.0748, 0.0297, 0.0535,
        0.0289, 0.0483, 0.0061, 0.0455, 0.3428, 0.2318], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,809][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0093, 0.0280, 0.0080, 0.0143, 0.0062, 0.0131, 0.0077, 0.0154, 0.0559,
        0.0592, 0.1777, 0.0481, 0.0892, 0.3630, 0.1048], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,810][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([3.3766e-04, 2.9721e-02, 8.7124e-04, 9.4701e-03, 5.7540e-04, 1.7297e-03,
        4.3078e-03, 1.0312e-02, 3.3421e-02, 2.0736e-02, 8.4296e-02, 1.0130e-02,
        3.4100e-02, 6.9924e-01, 6.0750e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,811][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([2.1345e-01, 1.2471e-02, 1.3386e-06, 7.5159e-05, 2.1411e-07, 3.5275e-04,
        1.0658e-03, 2.0738e-02, 2.4281e-02, 1.1230e-01, 1.3559e-01, 2.4974e-03,
        2.0325e-02, 4.1653e-01, 4.0326e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,814][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0009, 0.0357, 0.0026, 0.0136, 0.0009, 0.0101, 0.0176, 0.0635, 0.0687,
        0.0416, 0.1092, 0.0062, 0.0498, 0.4680, 0.1116], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,817][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0014, 0.0519, 0.0191, 0.0335, 0.0026, 0.0042, 0.0099, 0.0369, 0.0667,
        0.0326, 0.0645, 0.0218, 0.0945, 0.4535, 0.1068], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,819][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([2.6344e-03, 2.0905e-02, 3.3326e-04, 5.7803e-03, 7.2122e-05, 7.4053e-04,
        1.1992e-03, 6.5305e-03, 1.4727e-02, 1.0227e-02, 4.7110e-02, 2.4840e-03,
        9.5557e-03, 8.1152e-01, 6.6183e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,820][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0112, 0.0123, 0.0103, 0.0111, 0.0031, 0.0087, 0.0069, 0.0206, 0.0313,
        0.0146, 0.0626, 0.0349, 0.1106, 0.5024, 0.1594], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,820][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0386, 0.1415, 0.0040, 0.0357, 0.0034, 0.0166, 0.0327, 0.0656, 0.1176,
        0.0253, 0.0965, 0.0105, 0.0563, 0.3013, 0.0543], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,820][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([9.3200e-04, 4.3034e-02, 7.8730e-03, 1.1533e-02, 3.2377e-04, 2.1789e-03,
        2.3442e-03, 3.6126e-03, 1.4175e-02, 7.8770e-03, 2.3958e-02, 5.1357e-03,
        2.3771e-02, 7.5736e-01, 9.5894e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,821][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.4456, 0.0799, 0.0030, 0.0039, 0.0030, 0.0019, 0.0072, 0.0038, 0.0085,
        0.0243, 0.1599, 0.0379, 0.0436, 0.1524, 0.0250], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,821][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([6.5148e-02, 4.1472e-02, 3.5273e-04, 1.6328e-03, 2.9275e-05, 3.6364e-04,
        1.5100e-03, 2.3312e-02, 2.9337e-02, 2.1921e-02, 4.5208e-02, 5.7457e-03,
        1.3308e-02, 6.6353e-01, 8.7132e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give]
[2024-07-24 10:30:21,822][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0228, 0.1132, 0.0158, 0.0144, 0.0046, 0.0146, 0.0757, 0.0311, 0.0460,
        0.0316, 0.0407, 0.0072, 0.0422, 0.2407, 0.1620, 0.1375],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,823][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0078, 0.0368, 0.0199, 0.0214, 0.0160, 0.0266, 0.0114, 0.0205, 0.0516,
        0.0686, 0.1783, 0.0485, 0.0708, 0.2808, 0.0825, 0.0584],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,825][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.3497e-04, 3.8496e-02, 6.9344e-04, 1.3519e-02, 9.3154e-04, 2.3413e-03,
        3.4997e-03, 1.0032e-02, 3.9697e-02, 2.1714e-02, 1.0273e-01, 1.0130e-02,
        2.7338e-02, 6.4192e-01, 5.0505e-02, 3.6220e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,827][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.1297e-01, 4.3442e-03, 1.4906e-06, 3.0151e-05, 2.9398e-07, 2.2569e-04,
        7.5129e-04, 1.0192e-02, 7.0868e-03, 3.1788e-02, 3.8708e-02, 1.6369e-03,
        8.0773e-03, 6.8967e-02, 1.0193e-02, 5.0247e-03], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,831][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0008, 0.0250, 0.0027, 0.0146, 0.0012, 0.0150, 0.0177, 0.0842, 0.0634,
        0.0537, 0.0903, 0.0061, 0.0485, 0.3183, 0.1068, 0.1517],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,833][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0016, 0.0788, 0.0442, 0.0609, 0.0075, 0.0080, 0.0144, 0.0480, 0.0714,
        0.0395, 0.0630, 0.0270, 0.0776, 0.2727, 0.0889, 0.0965],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,833][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.9002e-03, 4.1167e-02, 9.7302e-04, 1.3093e-02, 2.2509e-04, 1.5940e-03,
        1.4053e-03, 9.2095e-03, 1.8772e-02, 1.3366e-02, 5.7705e-02, 2.9882e-03,
        8.9708e-03, 6.9784e-01, 6.8933e-02, 6.0855e-02], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,833][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0158, 0.0096, 0.0140, 0.0143, 0.0057, 0.0201, 0.0112, 0.0240, 0.0399,
        0.0140, 0.0783, 0.0342, 0.1123, 0.3527, 0.1351, 0.1188],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,834][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1755, 0.1595, 0.0067, 0.0504, 0.0082, 0.0186, 0.0258, 0.0471, 0.0910,
        0.0174, 0.0768, 0.0088, 0.0445, 0.1737, 0.0292, 0.0669],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,834][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0006, 0.0836, 0.0191, 0.0238, 0.0013, 0.0049, 0.0049, 0.0050, 0.0178,
        0.0094, 0.0321, 0.0064, 0.0257, 0.5260, 0.1001, 0.1392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,835][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6140, 0.0613, 0.0059, 0.0038, 0.0058, 0.0021, 0.0087, 0.0033, 0.0080,
        0.0178, 0.0881, 0.0343, 0.0308, 0.0790, 0.0131, 0.0238],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,835][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.2462e-02, 2.9853e-02, 9.8930e-04, 2.6575e-03, 6.4409e-05, 1.0435e-03,
        1.6262e-03, 1.8791e-02, 2.9377e-02, 2.0541e-02, 7.9733e-02, 6.7308e-03,
        2.5138e-02, 5.2131e-01, 9.9802e-02, 1.0988e-01], device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a]
[2024-07-24 10:30:21,835][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0194, 0.0774, 0.0060, 0.0080, 0.0023, 0.0121, 0.0826, 0.0229, 0.0429,
        0.0289, 0.0397, 0.0071, 0.0542, 0.2442, 0.1686, 0.1445, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,837][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0118, 0.0730, 0.0130, 0.0249, 0.0074, 0.0172, 0.0098, 0.0265, 0.0724,
        0.0768, 0.1878, 0.0373, 0.0639, 0.2162, 0.0702, 0.0526, 0.0392],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,839][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.1046e-04, 4.8424e-02, 5.5466e-04, 1.5242e-02, 4.4771e-04, 1.4566e-03,
        3.4459e-03, 7.7576e-03, 3.1272e-02, 2.1653e-02, 7.5268e-02, 7.1538e-03,
        2.8368e-02, 5.8541e-01, 5.4465e-02, 4.3334e-02, 7.5638e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,841][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([4.6179e-01, 2.0575e-02, 9.2641e-07, 8.1942e-05, 1.4783e-07, 3.6855e-04,
        9.4285e-04, 1.5082e-02, 1.2883e-02, 4.9740e-02, 7.8994e-02, 1.2779e-03,
        1.1543e-02, 2.6031e-01, 2.3739e-02, 1.6495e-02, 4.6176e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,844][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0005, 0.0520, 0.0035, 0.0165, 0.0011, 0.0109, 0.0182, 0.0556, 0.0673,
        0.0408, 0.0891, 0.0052, 0.0400, 0.2122, 0.0740, 0.1294, 0.1838],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,846][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0008, 0.0727, 0.0250, 0.0409, 0.0029, 0.0031, 0.0150, 0.0390, 0.0585,
        0.0216, 0.0526, 0.0167, 0.0712, 0.2525, 0.1176, 0.1073, 0.1025],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,847][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.0003e-03, 9.6113e-02, 1.0025e-03, 9.6396e-03, 9.9648e-05, 1.0350e-03,
        1.2542e-03, 9.2595e-03, 2.1613e-02, 1.3208e-02, 5.4984e-02, 2.0775e-03,
        8.7476e-03, 5.6892e-01, 5.5367e-02, 1.2277e-01, 3.2914e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,847][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0101, 0.0075, 0.0089, 0.0085, 0.0034, 0.0086, 0.0101, 0.0214, 0.0280,
        0.0169, 0.0676, 0.0376, 0.1380, 0.2535, 0.1920, 0.1611, 0.0269],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,848][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0122, 0.0544, 0.0029, 0.0379, 0.0030, 0.0138, 0.0417, 0.0461, 0.1233,
        0.0208, 0.0831, 0.0080, 0.0475, 0.2857, 0.0522, 0.1269, 0.0405],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,848][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([3.2736e-04, 8.0723e-02, 1.4899e-02, 1.2478e-02, 6.4808e-04, 2.6017e-03,
        3.1780e-03, 3.7123e-03, 1.7644e-02, 6.2691e-03, 2.2606e-02, 4.2384e-03,
        2.1333e-02, 4.4691e-01, 9.6221e-02, 2.2161e-01, 4.4598e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,848][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.6665, 0.0701, 0.0018, 0.0046, 0.0017, 0.0017, 0.0061, 0.0024, 0.0045,
        0.0135, 0.0847, 0.0149, 0.0166, 0.0499, 0.0131, 0.0216, 0.0263],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,849][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([9.4256e-03, 6.2026e-02, 4.7053e-04, 3.3451e-03, 3.3450e-05, 8.4975e-04,
        1.0097e-03, 1.3372e-02, 1.9672e-02, 1.2096e-02, 8.5514e-02, 2.7173e-03,
        1.9653e-02, 4.9719e-01, 7.2608e-02, 1.3227e-01, 6.7754e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer]
[2024-07-24 10:30:21,851][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0322, 0.0656, 0.0095, 0.0088, 0.0030, 0.0082, 0.0678, 0.0207, 0.0376,
        0.0171, 0.0297, 0.0046, 0.0334, 0.2107, 0.1369, 0.1455, 0.0164, 0.1522],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,853][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0300, 0.0287, 0.0149, 0.0169, 0.0153, 0.0154, 0.0062, 0.0115, 0.0338,
        0.0487, 0.1367, 0.0528, 0.0509, 0.2016, 0.0542, 0.0386, 0.0220, 0.2217],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,857][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0011, 0.0488, 0.0008, 0.0130, 0.0009, 0.0018, 0.0027, 0.0061, 0.0222,
        0.0147, 0.0672, 0.0102, 0.0181, 0.4330, 0.0332, 0.0315, 0.0367, 0.2580],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,860][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.3650e-01, 1.0762e-03, 2.9915e-07, 4.8968e-06, 5.1923e-08, 3.5423e-05,
        8.5398e-05, 1.5264e-03, 1.1521e-03, 7.7210e-03, 9.5602e-03, 3.6559e-04,
        1.4586e-03, 2.0780e-02, 2.4350e-03, 1.6408e-03, 2.7652e-03, 1.2897e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,860][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0009, 0.0296, 0.0023, 0.0115, 0.0008, 0.0077, 0.0106, 0.0377, 0.0330,
        0.0285, 0.0532, 0.0042, 0.0244, 0.2067, 0.0456, 0.0801, 0.1236, 0.2997],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,861][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0028, 0.0627, 0.0347, 0.0546, 0.0046, 0.0041, 0.0091, 0.0315, 0.0463,
        0.0220, 0.0430, 0.0214, 0.0557, 0.2304, 0.0702, 0.0884, 0.0628, 0.1557],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,861][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([6.7195e-03, 5.0094e-02, 8.6877e-04, 8.6200e-03, 1.5899e-04, 8.9014e-04,
        8.5856e-04, 4.7360e-03, 1.0477e-02, 7.3208e-03, 3.4151e-02, 2.2777e-03,
        4.8084e-03, 4.9141e-01, 3.7964e-02, 6.0056e-02, 1.4981e-02, 2.6361e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,861][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0493, 0.0051, 0.0132, 0.0111, 0.0064, 0.0129, 0.0052, 0.0131, 0.0181,
        0.0104, 0.0533, 0.0522, 0.1012, 0.2730, 0.1158, 0.1149, 0.0196, 0.1252],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,862][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0534, 0.0979, 0.0092, 0.0365, 0.0115, 0.0141, 0.0356, 0.0339, 0.0823,
        0.0130, 0.0588, 0.0094, 0.0479, 0.2114, 0.0349, 0.1025, 0.0174, 0.1303],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,862][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0018, 0.0480, 0.0091, 0.0131, 0.0005, 0.0019, 0.0020, 0.0016, 0.0076,
        0.0040, 0.0149, 0.0041, 0.0119, 0.3320, 0.0560, 0.1165, 0.0257, 0.3493],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,863][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.4346e-01, 1.0656e-02, 9.2221e-04, 5.2838e-04, 8.0184e-04, 2.3837e-04,
        6.6812e-04, 2.1440e-04, 4.7474e-04, 1.6594e-03, 1.0923e-02, 4.1374e-03,
        2.5913e-03, 6.4937e-03, 1.3308e-03, 2.5426e-03, 1.8616e-03, 1.0498e-02],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,864][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.7889e-01, 2.4013e-02, 5.8468e-04, 1.3058e-03, 3.6227e-05, 3.9590e-04,
        5.7845e-04, 7.2759e-03, 8.9899e-03, 7.1956e-03, 3.5063e-02, 3.3177e-03,
        8.6784e-03, 2.1175e-01, 4.1147e-02, 5.6457e-02, 2.5830e-02, 3.8849e-01],
       device='cuda:0') for source tokens [Then, Samuel and Matthew were working at the station. Matthew decided to give a computer to]
[2024-07-24 10:30:21,865][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:21,866][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[579],
        [ 97],
        [ 11],
        [  9],
        [ 14],
        [  2],
        [ 90],
        [ 14],
        [  2],
        [  4],
        [  2],
        [ 35],
        [  9],
        [  1],
        [  2],
        [  2],
        [  2],
        [  1]], device='cuda:0')
[2024-07-24 10:30:21,869][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[766],
        [ 20],
        [ 50],
        [ 19],
        [ 66],
        [ 10],
        [144],
        [ 66],
        [ 21],
        [  7],
        [ 15],
        [ 72],
        [ 22],
        [  7],
        [  9],
        [ 11],
        [  4],
        [  4]], device='cuda:0')
[2024-07-24 10:30:21,870][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 9196],
        [10663],
        [12651],
        [12002],
        [12904],
        [11637],
        [ 9966],
        [ 9419],
        [ 9366],
        [ 8911],
        [ 9630],
        [ 9154],
        [10181],
        [11235],
        [11311],
        [10920],
        [10872],
        [10609]], device='cuda:0')
[2024-07-24 10:30:21,872][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[  309],
        [  829],
        [15771],
        [ 9073],
        [ 8317],
        [11157],
        [ 6967],
        [12267],
        [16370],
        [14544],
        [30749],
        [34941],
        [35211],
        [32520],
        [33043],
        [32588],
        [31103],
        [30864]], device='cuda:0')
[2024-07-24 10:30:21,875][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6762],
        [33647],
        [35617],
        [25494],
        [26189],
        [29763],
        [31373],
        [32212],
        [30883],
        [30527],
        [22992],
        [24245],
        [25374],
        [29356],
        [28956],
        [28758],
        [29795],
        [32518]], device='cuda:0')
[2024-07-24 10:30:21,877][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36560],
        [36710],
        [38884],
        [37306],
        [41296],
        [40338],
        [41401],
        [43880],
        [44085],
        [46873],
        [45578],
        [47600],
        [47619],
        [44750],
        [47885],
        [47155],
        [47900],
        [45022]], device='cuda:0')
[2024-07-24 10:30:21,878][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17599],
        [40187],
        [39386],
        [43371],
        [43114],
        [39771],
        [41078],
        [39748],
        [39678],
        [39850],
        [38599],
        [38524],
        [38520],
        [36285],
        [36033],
        [37128],
        [39488],
        [39360]], device='cuda:0')
[2024-07-24 10:30:21,879][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43767],
        [33542],
        [21969],
        [22225],
        [27340],
        [26876],
        [30406],
        [30134],
        [32854],
        [33084],
        [30500],
        [31844],
        [31484],
        [29909],
        [30229],
        [30099],
        [30622],
        [31122]], device='cuda:0')
[2024-07-24 10:30:21,880][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[4795],
        [2278],
        [3082],
        [1982],
        [1978],
        [2190],
        [2205],
        [2378],
        [2463],
        [2435],
        [2322],
        [2884],
        [2568],
        [4406],
        [4752],
        [4456],
        [3990],
        [5178]], device='cuda:0')
[2024-07-24 10:30:21,881][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48045],
        [46294],
        [25833],
        [33723],
        [36395],
        [37614],
        [41173],
        [42317],
        [41502],
        [42129],
        [45106],
        [46231],
        [46547],
        [48062],
        [47874],
        [47228],
        [47029],
        [47435]], device='cuda:0')
[2024-07-24 10:30:21,883][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6369],
        [ 6391],
        [ 8271],
        [ 5637],
        [ 8391],
        [ 5596],
        [ 5840],
        [ 5418],
        [ 6051],
        [ 5156],
        [ 5348],
        [ 5924],
        [ 6246],
        [ 5812],
        [ 6216],
        [16541],
        [ 5678],
        [ 6639]], device='cuda:0')
[2024-07-24 10:30:21,884][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20725],
        [ 8207],
        [12943],
        [16630],
        [10044],
        [ 9956],
        [10852],
        [14716],
        [15355],
        [13414],
        [17242],
        [18802],
        [16726],
        [19498],
        [20356],
        [20384],
        [20975],
        [18738]], device='cuda:0')
[2024-07-24 10:30:21,886][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29856],
        [44293],
        [ 9093],
        [27603],
        [ 9244],
        [14807],
        [37416],
        [32695],
        [33682],
        [35151],
        [32218],
        [28017],
        [31764],
        [36429],
        [36676],
        [35074],
        [37211],
        [32331]], device='cuda:0')
[2024-07-24 10:30:21,887][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25144],
        [13197],
        [13731],
        [13744],
        [14399],
        [13964],
        [14102],
        [21629],
        [19893],
        [24743],
        [23169],
        [27220],
        [23674],
        [35538],
        [36756],
        [35208],
        [33617],
        [30822]], device='cuda:0')
[2024-07-24 10:30:21,890][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10011],
        [ 9732],
        [ 4642],
        [ 5358],
        [ 3778],
        [ 5560],
        [ 7992],
        [ 7127],
        [ 8073],
        [ 8069],
        [ 8243],
        [ 6993],
        [ 6098],
        [ 8576],
        [10470],
        [ 9464],
        [ 6748],
        [ 7909]], device='cuda:0')
[2024-07-24 10:30:21,892][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16525],
        [15607],
        [17488],
        [17551],
        [20695],
        [18983],
        [14198],
        [14771],
        [15808],
        [16704],
        [17250],
        [17395],
        [18690],
        [19314],
        [20418],
        [21054],
        [21268],
        [21462]], device='cuda:0')
[2024-07-24 10:30:21,895][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10653],
        [19896],
        [23811],
        [27097],
        [27206],
        [26221],
        [26273],
        [26524],
        [25956],
        [25910],
        [23509],
        [23905],
        [21957],
        [21957],
        [22209],
        [22341],
        [22517],
        [22859]], device='cuda:0')
[2024-07-24 10:30:21,896][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33901],
        [ 2491],
        [ 2746],
        [10834],
        [ 8626],
        [ 6170],
        [ 4164],
        [ 6369],
        [ 5219],
        [ 5469],
        [ 7123],
        [ 8970],
        [ 6618],
        [ 8667],
        [10373],
        [ 9450],
        [ 9065],
        [ 7124]], device='cuda:0')
[2024-07-24 10:30:21,897][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[5263],
        [5225],
        [4836],
        [5121],
        [4735],
        [4161],
        [4290],
        [5189],
        [4543],
        [4701],
        [4111],
        [5000],
        [4727],
        [4088],
        [4290],
        [3796],
        [4191],
        [4063]], device='cuda:0')
[2024-07-24 10:30:21,898][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13159],
        [ 4363],
        [ 4348],
        [ 4324],
        [ 4350],
        [ 3883],
        [ 3433],
        [ 3861],
        [ 3517],
        [ 3559],
        [ 3027],
        [ 3154],
        [ 3031],
        [ 3263],
        [ 3086],
        [ 2984],
        [ 3045],
        [ 2908]], device='cuda:0')
[2024-07-24 10:30:21,899][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11274],
        [ 6739],
        [ 5264],
        [ 4924],
        [ 5443],
        [ 6017],
        [ 6307],
        [ 5547],
        [ 4766],
        [ 4615],
        [ 4276],
        [ 4213],
        [ 4132],
        [ 4133],
        [ 3748],
        [ 3937],
        [ 3716],
        [ 3845]], device='cuda:0')
[2024-07-24 10:30:21,900][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 2765],
        [12533],
        [12913],
        [ 9153],
        [10629],
        [11093],
        [12240],
        [10207],
        [ 9981],
        [10999],
        [12650],
        [11548],
        [12154],
        [10202],
        [10178],
        [10918],
        [12195],
        [ 9936]], device='cuda:0')
[2024-07-24 10:30:21,903][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26069],
        [15306],
        [ 8019],
        [ 7578],
        [ 7134],
        [ 6989],
        [ 8387],
        [ 8227],
        [ 8907],
        [ 7944],
        [ 9504],
        [10852],
        [11934],
        [13597],
        [13262],
        [13632],
        [13951],
        [14249]], device='cuda:0')
[2024-07-24 10:30:21,904][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15400],
        [15375],
        [12108],
        [10021],
        [12412],
        [10275],
        [10218],
        [10180],
        [ 9821],
        [ 9824],
        [ 9857],
        [ 9088],
        [ 9384],
        [ 9753],
        [ 9545],
        [ 8854],
        [ 9620],
        [ 9339]], device='cuda:0')
[2024-07-24 10:30:21,906][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8027],
        [16898],
        [14854],
        [13720],
        [14748],
        [15370],
        [15137],
        [14697],
        [13984],
        [14328],
        [12812],
        [12654],
        [13636],
        [11161],
        [11098],
        [11715],
        [11927],
        [11776]], device='cuda:0')
[2024-07-24 10:30:21,909][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[4578],
        [9661],
        [7999],
        [7496],
        [3351],
        [3560],
        [4999],
        [4753],
        [4965],
        [4763],
        [4099],
        [3243],
        [3295],
        [4131],
        [3349],
        [3110],
        [3497],
        [4172]], device='cuda:0')
[2024-07-24 10:30:21,911][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6931],
        [15879],
        [ 6697],
        [12000],
        [ 9892],
        [13871],
        [15364],
        [11192],
        [13788],
        [12462],
        [10939],
        [10621],
        [11295],
        [ 8229],
        [ 8561],
        [ 9603],
        [ 9468],
        [ 8802]], device='cuda:0')
[2024-07-24 10:30:21,912][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26943],
        [28470],
        [32706],
        [28665],
        [31790],
        [32110],
        [31788],
        [31819],
        [32761],
        [32809],
        [33933],
        [32222],
        [32874],
        [35062],
        [34474],
        [34648],
        [33381],
        [35110]], device='cuda:0')
[2024-07-24 10:30:21,913][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33858],
        [33226],
        [38706],
        [37481],
        [39587],
        [37620],
        [35584],
        [36793],
        [35890],
        [34780],
        [35978],
        [35576],
        [36102],
        [35313],
        [32571],
        [32155],
        [36013],
        [36328]], device='cuda:0')
[2024-07-24 10:30:21,914][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316],
        [10316]], device='cuda:0')
