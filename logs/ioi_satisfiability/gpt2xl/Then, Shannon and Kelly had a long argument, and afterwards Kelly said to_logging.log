[2024-07-24 10:20:33,804][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Shannon and Kelly had a long argument, and afterwards Kelly said to
[2024-07-24 10:20:33,804][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Shannon
[2024-07-24 10:20:33,804][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:20:33,804][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:20:33,804][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:20:33,805][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,806][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:20:33,807][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit26']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:20:33,808][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:33,809][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit22', 'circuit27']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit12', 'circuit27']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:20:33,810][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit12', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,811][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:20:33,812][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,813][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,814][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit20', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit4', 'circuit9', 'circuit12', 'circuit14', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:20:33,815][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:33,816][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit9', 'circuit15', 'circuit16', 'circuit18', 'circuit26']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit12']
[2024-07-24 10:20:33,817][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit13']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit20']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit22']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,818][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit27']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,819][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit14', 'circuit15']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,820][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit19']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,821][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,822][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,823][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,824][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,825][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit10', 'circuit11']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit3']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:20:33,826][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,827][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,828][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit26']
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,829][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit12']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit11', 'circuit26']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,830][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit22']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit23']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,831][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,832][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit21', 'circuit26']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:20:33,833][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit17', 'circuit24']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12']
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,834][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit2']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit12', 'circuit13']
[2024-07-24 10:20:33,835][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:20:33,836][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,837][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,838][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:20:33,839][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,840][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit28']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit20', 'circuit24']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit23']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18']
[2024-07-24 10:20:33,841][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:20:33,842][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit6', 'circuit13']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:20:33,843][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit26']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,844][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,845][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,846][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,847][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:20:33,848][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,849][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25', 'circuit27']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit18']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit15', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit23']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,850][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15']
[2024-07-24 10:20:33,851][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,852][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,853][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit19']
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,854][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,855][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,856][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:20:33,857][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,858][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,859][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit13', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit11', 'circuit13', 'circuit17', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,860][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,861][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,862][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit4', 'circuit11', 'circuit13', 'circuit15', 'circuit17', 'circuit22']
[2024-07-24 10:20:33,863][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,864][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit19', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,865][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,866][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,867][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,868][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,869][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,870][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,871][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,872][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:20:33,873][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,874][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,875][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,876][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,877][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,878][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,879][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,880][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,881][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,882][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit20', 'circuit24']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit7']
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,883][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit26']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,884][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,885][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit22']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-24 10:20:33,886][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit11', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit22']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit25']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,887][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,888][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,889][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,890][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,891][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,892][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,893][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:33,894][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,895][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:33,896][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:35,586][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:35,587][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,587][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,588][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,590][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,590][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,590][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,591][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,594][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,594][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,594][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,595][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,595][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,595][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,595][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,599][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,603][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,607][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,607][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,608][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,608][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,608][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,609][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,609][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,609][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,610][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.4719, 0.3600, 0.1681], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,610][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([4.4981e-05, 1.3373e-04, 9.9982e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,611][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.5569, 0.3262, 0.1169], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,613][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([3.3031e-03, 2.4033e-04, 9.9646e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,616][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.0622, 0.0061, 0.9317], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,619][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([2.9020e-03, 4.5683e-07, 9.9710e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,623][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.3486, 0.3378, 0.3135], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,626][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.5010, 0.3833, 0.1157], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,630][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.4841, 0.3293, 0.1866], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,634][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.5959, 0.3859, 0.0182], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,637][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.4334, 0.2670, 0.2996], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,637][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.3301, 0.4367, 0.2332], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,637][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6876, 0.0779, 0.1737, 0.0607], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,638][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3016e-03, 3.9232e-02, 8.6980e-04, 9.5760e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,638][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2323, 0.1740, 0.0585, 0.5352], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,638][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1149, 0.3927, 0.0120, 0.4804], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,639][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3693, 0.1673, 0.1604, 0.3030], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,639][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1224, 0.1960, 0.0121, 0.6695], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,639][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6034, 0.0289, 0.3458, 0.0219], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,640][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2281, 0.1735, 0.3372, 0.2612], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,641][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0669, 0.4682, 0.0260, 0.4390], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,644][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4195, 0.2343, 0.1285, 0.2176], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,648][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4208, 0.3135, 0.0589, 0.2068], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,652][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4353, 0.1901, 0.1261, 0.2484], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,655][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.2324, 0.2292, 0.2298, 0.1647, 0.1439], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,658][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([1.0017e-03, 2.5621e-04, 9.4703e-03, 2.0967e-04, 9.8906e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,662][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.3273, 0.1624, 0.1924, 0.0795, 0.2385], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,664][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([1.3735e-02, 1.2368e-04, 1.8027e-02, 3.3693e-04, 9.6778e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,666][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0295, 0.0044, 0.2776, 0.0036, 0.6848], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,666][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([5.4377e-03, 1.0666e-06, 1.7056e-04, 1.6720e-07, 9.9439e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,667][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.2482, 0.1734, 0.2988, 0.0770, 0.2026], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,667][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.2167, 0.2103, 0.1301, 0.3604, 0.0825], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,668][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.2672, 0.2153, 0.2582, 0.1412, 0.1181], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,668][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.4019, 0.2869, 0.0700, 0.2276, 0.0135], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,668][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.2832, 0.2171, 0.0783, 0.1219, 0.2996], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,669][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.2817, 0.1910, 0.1669, 0.2205, 0.1398], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:35,669][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3574, 0.0314, 0.1565, 0.0313, 0.1482, 0.2753], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,670][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2175e-04, 1.6732e-03, 7.7487e-04, 2.8580e-03, 9.7964e-04, 9.9339e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,673][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4660, 0.1188, 0.0608, 0.1406, 0.0745, 0.1392], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,676][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0013, 0.0113, 0.0136, 0.9635], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,680][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2187, 0.0622, 0.0402, 0.1126, 0.1021, 0.4643], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,684][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0396, 0.0018, 0.0024, 0.0013, 0.0035, 0.9514], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,687][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2871, 0.0214, 0.3413, 0.0201, 0.3013, 0.0288], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,691][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1124, 0.0875, 0.0856, 0.2032, 0.2585, 0.2527], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,695][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0910, 0.2557, 0.0437, 0.3359, 0.0659, 0.2078], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,696][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3016, 0.1818, 0.1167, 0.1874, 0.0858, 0.1266], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,696][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2504, 0.1931, 0.0564, 0.1414, 0.0515, 0.3071], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,697][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4257, 0.1422, 0.0995, 0.1773, 0.0658, 0.0896], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:35,697][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4602, 0.0530, 0.1362, 0.0401, 0.2089, 0.0661, 0.0355],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,697][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5568e-04, 4.3003e-03, 1.5684e-03, 4.2983e-03, 2.8960e-04, 4.6834e-04,
        9.8822e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,698][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2897, 0.1796, 0.0786, 0.2118, 0.0756, 0.1199, 0.0448],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,698][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0295, 0.0181, 0.0078, 0.0333, 0.0101, 0.1800, 0.7213],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,698][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1426, 0.0314, 0.0447, 0.0442, 0.0754, 0.4460, 0.2158],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,699][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0554, 0.1285, 0.0054, 0.0962, 0.0094, 0.0444, 0.6607],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,700][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3175, 0.0105, 0.3248, 0.0090, 0.2812, 0.0467, 0.0103],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,703][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0974, 0.0586, 0.1004, 0.1309, 0.0908, 0.2196, 0.3023],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,707][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0237, 0.1289, 0.0164, 0.1914, 0.0163, 0.1399, 0.4835],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,711][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2604, 0.1667, 0.0903, 0.1692, 0.0750, 0.1049, 0.1335],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,714][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2260, 0.1927, 0.0633, 0.1634, 0.0451, 0.0837, 0.2259],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,719][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3350, 0.1343, 0.1105, 0.1442, 0.0784, 0.0866, 0.1111],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:35,723][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2072, 0.0496, 0.2658, 0.0459, 0.2207, 0.0853, 0.0651, 0.0604],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,725][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8483e-04, 9.9001e-04, 2.5644e-04, 1.4123e-03, 7.0154e-05, 3.2549e-03,
        9.3924e-04, 9.9279e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,726][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3090, 0.1592, 0.0563, 0.1611, 0.0816, 0.1124, 0.0804, 0.0400],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,726][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5022e-03, 4.5884e-04, 8.0650e-04, 8.0146e-04, 2.3095e-03, 9.0830e-03,
        7.2358e-03, 9.7280e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,726][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0976, 0.0223, 0.0463, 0.0292, 0.0537, 0.1458, 0.0772, 0.5279],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,727][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4042e-03, 1.8790e-04, 1.0466e-04, 1.0305e-04, 4.4107e-05, 1.9184e-04,
        8.2372e-05, 9.9388e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,727][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2983, 0.0321, 0.2972, 0.0223, 0.1913, 0.0494, 0.0231, 0.0864],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,728][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1056, 0.0459, 0.0368, 0.0963, 0.0496, 0.1935, 0.3574, 0.1148],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,728][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1021, 0.1022, 0.1353, 0.1299, 0.1115, 0.1257, 0.2555, 0.0378],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,728][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2433, 0.1591, 0.0903, 0.1540, 0.0581, 0.0940, 0.1350, 0.0662],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,730][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2261, 0.1602, 0.0443, 0.1122, 0.0313, 0.0778, 0.0879, 0.2602],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,734][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3931, 0.1058, 0.0682, 0.1316, 0.0551, 0.0652, 0.0667, 0.1143],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:35,737][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.2700, 0.0646, 0.2599, 0.0509, 0.1567, 0.0551, 0.0433, 0.0550, 0.0444],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,739][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8598e-03, 3.0818e-04, 3.9288e-04, 2.0946e-04, 9.3152e-05, 3.4936e-04,
        1.9551e-04, 3.4393e-05, 9.9656e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,743][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2942, 0.1000, 0.0993, 0.0733, 0.0762, 0.0963, 0.1128, 0.0933, 0.0546],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,745][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3890e-03, 4.0930e-05, 1.1468e-04, 9.1372e-05, 1.2259e-04, 2.4721e-04,
        6.3029e-04, 4.3104e-03, 9.9105e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,748][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1302, 0.0059, 0.0144, 0.0050, 0.0250, 0.0158, 0.0133, 0.1744, 0.6160],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,751][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2029e-02, 1.5135e-05, 4.5281e-06, 4.1252e-06, 1.0487e-05, 2.0255e-06,
        1.5990e-06, 6.3681e-07, 9.8793e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,755][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1843, 0.0479, 0.1954, 0.0418, 0.2051, 0.0316, 0.0339, 0.0760, 0.1839],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,757][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0899, 0.0516, 0.0178, 0.0960, 0.0434, 0.1324, 0.2112, 0.2543, 0.1034],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,757][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2446, 0.0945, 0.0635, 0.1106, 0.0670, 0.2306, 0.1181, 0.0637, 0.0074],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,758][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2349, 0.1368, 0.0807, 0.1282, 0.0688, 0.1114, 0.1146, 0.0827, 0.0420],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,758][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2178, 0.1357, 0.0484, 0.1146, 0.0327, 0.0783, 0.0756, 0.0396, 0.2572],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,759][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3213, 0.1425, 0.0868, 0.1031, 0.0658, 0.0408, 0.0394, 0.0870, 0.1133],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:35,759][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4483, 0.0154, 0.0910, 0.0179, 0.1148, 0.0794, 0.0344, 0.0637, 0.1221,
        0.0130], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,759][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8437e-03, 4.4339e-01, 4.2011e-04, 1.1167e-02, 1.7301e-04, 3.9656e-04,
        1.7954e-04, 5.1685e-05, 7.8219e-06, 5.4237e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,760][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1938, 0.3051, 0.0288, 0.0746, 0.0350, 0.0355, 0.0073, 0.0099, 0.0098,
        0.3001], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,762][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0332, 0.0077, 0.0011, 0.0078, 0.0036, 0.0607, 0.0498, 0.0552, 0.0865,
        0.6945], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,764][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2792, 0.0271, 0.0329, 0.0233, 0.0259, 0.1349, 0.0329, 0.1153, 0.0484,
        0.2801], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,768][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0959, 0.3388, 0.0212, 0.1222, 0.0127, 0.0680, 0.1006, 0.0296, 0.0100,
        0.2012], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,772][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2785, 0.0082, 0.2686, 0.0079, 0.1978, 0.0261, 0.0102, 0.0672, 0.1299,
        0.0055], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,776][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0379, 0.0143, 0.0304, 0.0388, 0.0401, 0.0709, 0.1131, 0.1483, 0.1417,
        0.3646], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,780][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0191, 0.1642, 0.0097, 0.1843, 0.0067, 0.0640, 0.1653, 0.0291, 0.0075,
        0.3502], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,784][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2117, 0.1211, 0.0706, 0.1258, 0.0655, 0.0849, 0.0925, 0.0691, 0.0558,
        0.1030], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,786][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1743, 0.1604, 0.0623, 0.1473, 0.0554, 0.0954, 0.0923, 0.0592, 0.0423,
        0.1111], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,787][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2454, 0.0949, 0.0875, 0.1077, 0.0643, 0.0685, 0.0652, 0.0796, 0.0741,
        0.1128], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:35,787][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3366, 0.0274, 0.0989, 0.0236, 0.1416, 0.0661, 0.0399, 0.0879, 0.1222,
        0.0269, 0.0287], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,788][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0613e-03, 1.2474e-02, 2.4221e-04, 5.1179e-01, 7.6290e-05, 6.9034e-04,
        2.3417e-04, 1.8324e-04, 8.4958e-06, 7.4668e-03, 4.6577e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,788][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0805, 0.0602, 0.0290, 0.3014, 0.0413, 0.0419, 0.0168, 0.0144, 0.0225,
        0.0535, 0.3385], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,788][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0825e-02, 6.0666e-03, 7.8769e-05, 3.9895e-03, 3.2314e-04, 7.8493e-03,
        1.3929e-02, 1.5643e-02, 7.4117e-03, 4.9319e-01, 4.4070e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,789][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0355, 0.0130, 0.0057, 0.0247, 0.0171, 0.1623, 0.0659, 0.1201, 0.1781,
        0.1219, 0.2556], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,789][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0325, 0.0869, 0.0062, 0.3865, 0.0039, 0.0541, 0.1207, 0.0253, 0.0037,
        0.0305, 0.2497], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,791][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2461, 0.0100, 0.2199, 0.0095, 0.2004, 0.0312, 0.0115, 0.0870, 0.1665,
        0.0076, 0.0105], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,794][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0333, 0.0121, 0.0183, 0.0201, 0.0278, 0.0426, 0.0640, 0.0801, 0.0986,
        0.2465, 0.3566], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,798][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.0999, 0.0062, 0.1172, 0.0064, 0.0608, 0.1994, 0.0255, 0.0108,
        0.2619, 0.2004], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,802][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1737, 0.1083, 0.0667, 0.1093, 0.0568, 0.0757, 0.0869, 0.0584, 0.0571,
        0.0958, 0.1114], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,805][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1452, 0.1315, 0.0486, 0.1398, 0.0421, 0.0983, 0.0992, 0.0528, 0.0355,
        0.0954, 0.1117], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,809][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2158, 0.0880, 0.0791, 0.1013, 0.0533, 0.0526, 0.0467, 0.0605, 0.0772,
        0.1112, 0.1142], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:35,813][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2395, 0.0436, 0.0425, 0.0483, 0.1477, 0.1272, 0.0496, 0.0348, 0.1529,
        0.0378, 0.0577, 0.0184], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,816][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7411e-03, 4.1758e-04, 1.9475e-03, 1.5599e-04, 1.9418e-04, 1.7377e-04,
        9.0199e-05, 1.4344e-04, 6.0605e-04, 9.2362e-05, 7.0774e-05, 9.9437e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,816][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2534, 0.0828, 0.0920, 0.0786, 0.0417, 0.1599, 0.0656, 0.0579, 0.0334,
        0.0525, 0.0632, 0.0190], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,817][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2695e-02, 5.1814e-05, 6.7520e-05, 7.2031e-05, 1.4467e-04, 1.1422e-03,
        2.1229e-04, 3.4372e-03, 1.4253e-03, 2.2502e-03, 4.8175e-03, 9.7368e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,817][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0417, 0.0033, 0.0152, 0.0070, 0.0018, 0.0113, 0.0108, 0.0292, 0.0152,
        0.0126, 0.0435, 0.8084], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,818][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2455e-02, 4.3741e-06, 1.7832e-04, 1.6933e-06, 3.6362e-05, 4.4307e-06,
        4.7551e-07, 4.6484e-06, 5.0049e-06, 9.8436e-08, 2.7243e-07, 9.0731e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,818][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1449, 0.0606, 0.1186, 0.0451, 0.1415, 0.0378, 0.0643, 0.0564, 0.1302,
        0.0535, 0.0496, 0.0975], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,818][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0530, 0.0190, 0.0083, 0.0293, 0.0137, 0.0337, 0.0716, 0.0491, 0.0277,
        0.1931, 0.3931, 0.1084], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,820][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0985, 0.1113, 0.0170, 0.1409, 0.0183, 0.0398, 0.1231, 0.0369, 0.1009,
        0.1312, 0.1691, 0.0130], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,824][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1773, 0.1002, 0.0677, 0.0920, 0.0569, 0.0763, 0.0672, 0.0575, 0.0870,
        0.0849, 0.0924, 0.0407], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,827][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1946, 0.0946, 0.0424, 0.0905, 0.0338, 0.0848, 0.0563, 0.0526, 0.0394,
        0.0674, 0.0701, 0.1736], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,831][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1693, 0.1342, 0.0981, 0.0890, 0.0692, 0.0306, 0.0391, 0.0394, 0.0360,
        0.1534, 0.0955, 0.0461], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:35,835][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1269, 0.0968, 0.1341, 0.0736, 0.0851, 0.0125, 0.0440, 0.0320, 0.0669,
        0.0864, 0.0806, 0.0573, 0.1037], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,838][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([5.3284e-04, 6.4581e-05, 3.6088e-03, 6.2502e-05, 5.1728e-01, 3.8919e-05,
        4.3350e-05, 1.5836e-05, 2.1180e-05, 1.2287e-05, 2.7829e-05, 4.4147e-05,
        4.7825e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,841][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.1617, 0.0697, 0.1193, 0.0435, 0.1558, 0.0502, 0.0615, 0.0264, 0.0335,
        0.0501, 0.0398, 0.0230, 0.1656], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,843][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([1.3101e-03, 1.2819e-06, 1.6875e-04, 1.5232e-06, 7.3745e-03, 2.1697e-05,
        6.1087e-06, 6.8420e-05, 5.4428e-04, 4.2921e-05, 9.4156e-05, 4.0600e-04,
        9.8996e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,845][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([5.5828e-03, 5.1238e-04, 2.4797e-02, 3.4265e-04, 5.8538e-02, 3.0837e-04,
        3.5872e-04, 7.1149e-04, 2.8433e-03, 3.0063e-03, 3.3172e-03, 3.5184e-03,
        8.9616e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,845][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([1.1336e-03, 1.7545e-07, 4.9160e-05, 2.8494e-08, 5.8376e-01, 4.7566e-07,
        1.8979e-08, 5.4870e-08, 4.1129e-08, 5.6352e-09, 4.5218e-09, 4.5114e-08,
        4.1506e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,846][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1334, 0.0834, 0.2148, 0.0417, 0.1609, 0.0142, 0.0250, 0.0230, 0.0319,
        0.0536, 0.0344, 0.0226, 0.1611], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,846][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0731, 0.0265, 0.0142, 0.0369, 0.0076, 0.0480, 0.0746, 0.0243, 0.0235,
        0.1759, 0.2951, 0.1098, 0.0904], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,847][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.1286, 0.0946, 0.1530, 0.0714, 0.0714, 0.0244, 0.0550, 0.0314, 0.1301,
        0.0676, 0.0626, 0.0369, 0.0729], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,847][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.1839, 0.1362, 0.0362, 0.1137, 0.0075, 0.0689, 0.0874, 0.0470, 0.0473,
        0.1116, 0.1083, 0.0451, 0.0069], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,847][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.1004, 0.0803, 0.0529, 0.0645, 0.2647, 0.0435, 0.0403, 0.0166, 0.0144,
        0.0470, 0.0451, 0.0139, 0.2163], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,848][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.1024, 0.0678, 0.0711, 0.0675, 0.0580, 0.0629, 0.0525, 0.0798, 0.1089,
        0.0805, 0.0872, 0.0845, 0.0768], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:35,850][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3369, 0.0292, 0.0614, 0.0169, 0.0696, 0.0614, 0.0180, 0.0445, 0.0429,
        0.0287, 0.0179, 0.0976, 0.1000, 0.0750], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,852][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4417e-03, 3.5439e-03, 2.8040e-03, 1.1984e-03, 7.7793e-04, 8.4728e-03,
        1.4017e-03, 4.5687e-05, 1.5886e-03, 1.5475e-03, 7.2071e-04, 1.1215e-04,
        5.4196e-04, 9.7580e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,855][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2244, 0.0501, 0.0238, 0.0433, 0.0299, 0.1032, 0.0341, 0.0250, 0.0491,
        0.0414, 0.0404, 0.0406, 0.0302, 0.2644], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,857][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([1.9847e-03, 7.3407e-05, 8.8150e-05, 5.4645e-05, 1.0390e-04, 3.0762e-04,
        4.2738e-04, 4.8582e-04, 1.2524e-03, 2.5361e-03, 3.5451e-03, 1.3155e-03,
        1.1180e-02, 9.7665e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,861][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0831, 0.0127, 0.0042, 0.0181, 0.0079, 0.0258, 0.0210, 0.0244, 0.0413,
        0.0545, 0.1158, 0.0234, 0.0639, 0.5039], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,863][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2016e-02, 2.4224e-03, 1.7874e-03, 8.8620e-04, 2.5003e-03, 8.6550e-03,
        2.0660e-04, 2.9333e-05, 6.6919e-04, 2.4762e-04, 2.7983e-04, 6.1711e-06,
        1.0438e-03, 9.6925e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,867][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.2121, 0.0104, 0.1761, 0.0105, 0.1082, 0.0139, 0.0085, 0.0379, 0.1001,
        0.0078, 0.0103, 0.1453, 0.1383, 0.0205], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,871][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0318, 0.0060, 0.0065, 0.0101, 0.0113, 0.0137, 0.0289, 0.0125, 0.0198,
        0.1051, 0.1643, 0.1693, 0.2544, 0.1662], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,875][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0516, 0.1067, 0.0289, 0.1047, 0.0138, 0.1020, 0.1380, 0.0314, 0.0279,
        0.1766, 0.1382, 0.0250, 0.0177, 0.0374], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,875][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1479, 0.0795, 0.0572, 0.0816, 0.0465, 0.0654, 0.0622, 0.0462, 0.0543,
        0.0739, 0.0846, 0.0549, 0.0512, 0.0946], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,875][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0996, 0.0719, 0.0486, 0.0757, 0.0431, 0.0780, 0.0585, 0.0245, 0.0469,
        0.0608, 0.0654, 0.0279, 0.0369, 0.2622], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,876][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2493, 0.0593, 0.0663, 0.0792, 0.0416, 0.0379, 0.0318, 0.0572, 0.0680,
        0.0629, 0.0805, 0.0834, 0.0428, 0.0399], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:35,876][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2485, 0.0241, 0.0766, 0.0202, 0.0781, 0.0648, 0.0216, 0.0350, 0.0692,
        0.0241, 0.0246, 0.0801, 0.1141, 0.1032, 0.0159], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,877][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1203e-03, 1.1776e-02, 4.2678e-04, 3.4308e-02, 8.1684e-05, 3.0527e-04,
        1.4489e-03, 1.7843e-04, 5.7919e-05, 8.2826e-03, 3.0200e-02, 2.4499e-04,
        5.2725e-05, 1.4512e-04, 9.0837e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,878][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1560, 0.0686, 0.0349, 0.0942, 0.0331, 0.0573, 0.0246, 0.0368, 0.0299,
        0.0586, 0.0927, 0.0381, 0.0338, 0.0729, 0.1685], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,880][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9473e-03, 2.6607e-04, 3.7534e-05, 1.8233e-04, 2.8260e-05, 7.2979e-04,
        1.2070e-03, 2.4273e-04, 1.1491e-03, 7.2066e-03, 1.1950e-02, 1.6589e-02,
        2.8428e-03, 2.9365e-01, 6.6097e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,883][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0358, 0.0023, 0.0011, 0.0038, 0.0016, 0.0338, 0.0104, 0.0262, 0.0572,
        0.0123, 0.0316, 0.0731, 0.0178, 0.4155, 0.2774], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,887][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0430, 0.0608, 0.0091, 0.0778, 0.0018, 0.0310, 0.2249, 0.0341, 0.0047,
        0.0210, 0.0410, 0.0007, 0.0008, 0.0324, 0.4168], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,890][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1243, 0.0060, 0.0924, 0.0052, 0.0661, 0.0174, 0.0049, 0.0322, 0.0555,
        0.0044, 0.0065, 0.1131, 0.1088, 0.0334, 0.3299], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,894][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0230, 0.0043, 0.0060, 0.0071, 0.0051, 0.0093, 0.0124, 0.0191, 0.0280,
        0.0512, 0.0830, 0.0973, 0.1002, 0.2690, 0.2848], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,898][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0080, 0.0594, 0.0054, 0.1034, 0.0043, 0.0465, 0.1309, 0.0197, 0.0089,
        0.1506, 0.1812, 0.0048, 0.0065, 0.0337, 0.2365], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,901][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1176, 0.0729, 0.0497, 0.0801, 0.0436, 0.0535, 0.0682, 0.0468, 0.0421,
        0.0688, 0.0841, 0.0452, 0.0488, 0.0817, 0.0969], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,903][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1019, 0.0837, 0.0336, 0.1003, 0.0336, 0.0743, 0.0854, 0.0502, 0.0333,
        0.0760, 0.0926, 0.0275, 0.0301, 0.0641, 0.1133], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,903][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1799, 0.0711, 0.0573, 0.0730, 0.0430, 0.0507, 0.0460, 0.0540, 0.0542,
        0.0731, 0.0694, 0.0747, 0.0431, 0.0371, 0.0734], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:35,926][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:35,930][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,932][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,936][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,938][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,939][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,939][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,939][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,940][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,940][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,940][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,941][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,941][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:35,941][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,943][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,945][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,949][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,952][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,956][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,960][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,963][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,967][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,968][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,968][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,968][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:35,969][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.4719, 0.3600, 0.1681], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,969][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([4.4981e-05, 1.3373e-04, 9.9982e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,969][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.5569, 0.3262, 0.1169], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,970][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([3.3031e-03, 2.4033e-04, 9.9646e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,970][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.0622, 0.0061, 0.9317], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,970][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([2.9020e-03, 4.5683e-07, 9.9710e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,972][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.3486, 0.3378, 0.3135], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,974][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.5010, 0.3833, 0.1157], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,978][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.4841, 0.3293, 0.1866], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,982][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.5959, 0.3859, 0.0182], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,985][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.4334, 0.2670, 0.2996], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,989][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.3301, 0.4367, 0.2332], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:35,993][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6876, 0.0779, 0.1737, 0.0607], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,996][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3016e-03, 3.9232e-02, 8.6980e-04, 9.5760e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,996][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2323, 0.1740, 0.0585, 0.5352], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,997][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1149, 0.3927, 0.0120, 0.4804], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,997][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3693, 0.1673, 0.1604, 0.3030], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,997][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1224, 0.1960, 0.0121, 0.6695], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,998][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6034, 0.0289, 0.3458, 0.0219], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,998][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2281, 0.1735, 0.3372, 0.2612], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,998][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0669, 0.4682, 0.0260, 0.4390], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:35,999][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4195, 0.2343, 0.1285, 0.2176], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,000][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4208, 0.3135, 0.0589, 0.2068], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,003][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4353, 0.1901, 0.1261, 0.2484], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,007][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.2324, 0.2292, 0.2298, 0.1647, 0.1439], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,009][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([1.0017e-03, 2.5621e-04, 9.4703e-03, 2.0967e-04, 9.8906e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,013][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.3273, 0.1624, 0.1924, 0.0795, 0.2385], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,015][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([1.3735e-02, 1.2368e-04, 1.8027e-02, 3.3693e-04, 9.6778e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,018][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0295, 0.0044, 0.2776, 0.0036, 0.6848], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,021][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([5.4377e-03, 1.0666e-06, 1.7056e-04, 1.6720e-07, 9.9439e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,025][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.2482, 0.1734, 0.2988, 0.0770, 0.2026], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,025][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.2167, 0.2103, 0.1301, 0.3604, 0.0825], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,025][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.2672, 0.2153, 0.2582, 0.1412, 0.1181], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,026][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.4019, 0.2869, 0.0700, 0.2276, 0.0135], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,026][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.2832, 0.2171, 0.0783, 0.1219, 0.2996], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,026][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.2817, 0.1910, 0.1669, 0.2205, 0.1398], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,027][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3574, 0.0314, 0.1565, 0.0313, 0.1482, 0.2753], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,027][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2175e-04, 1.6732e-03, 7.7487e-04, 2.8580e-03, 9.7964e-04, 9.9339e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,027][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4660, 0.1188, 0.0608, 0.1406, 0.0745, 0.1392], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,029][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0013, 0.0113, 0.0136, 0.9635], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,032][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2187, 0.0622, 0.0402, 0.1126, 0.1021, 0.4643], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,036][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0396, 0.0018, 0.0024, 0.0013, 0.0035, 0.9514], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,040][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2871, 0.0214, 0.3413, 0.0201, 0.3013, 0.0288], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,043][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1124, 0.0875, 0.0856, 0.2032, 0.2585, 0.2527], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,047][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0910, 0.2557, 0.0437, 0.3359, 0.0659, 0.2078], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,051][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3016, 0.1818, 0.1167, 0.1874, 0.0858, 0.1266], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,053][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2504, 0.1931, 0.0564, 0.1414, 0.0515, 0.3071], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,054][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4257, 0.1422, 0.0995, 0.1773, 0.0658, 0.0896], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,054][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4602, 0.0530, 0.1362, 0.0401, 0.2089, 0.0661, 0.0355],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,054][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5568e-04, 4.3003e-03, 1.5684e-03, 4.2983e-03, 2.8960e-04, 4.6834e-04,
        9.8822e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,055][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2897, 0.1796, 0.0786, 0.2118, 0.0756, 0.1199, 0.0448],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,055][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0295, 0.0181, 0.0078, 0.0333, 0.0101, 0.1800, 0.7213],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,056][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1426, 0.0314, 0.0447, 0.0442, 0.0754, 0.4460, 0.2158],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,057][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0554, 0.1285, 0.0054, 0.0962, 0.0094, 0.0444, 0.6607],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,059][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3175, 0.0105, 0.3248, 0.0090, 0.2812, 0.0467, 0.0103],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,062][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0974, 0.0586, 0.1004, 0.1309, 0.0908, 0.2196, 0.3023],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,066][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0237, 0.1289, 0.0164, 0.1914, 0.0163, 0.1399, 0.4835],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,070][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2604, 0.1667, 0.0903, 0.1692, 0.0750, 0.1049, 0.1335],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,073][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2260, 0.1927, 0.0633, 0.1634, 0.0451, 0.0837, 0.2259],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,077][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3350, 0.1343, 0.1105, 0.1442, 0.0784, 0.0866, 0.1111],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,081][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2072, 0.0496, 0.2658, 0.0459, 0.2207, 0.0853, 0.0651, 0.0604],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,082][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8483e-04, 9.9001e-04, 2.5644e-04, 1.4123e-03, 7.0154e-05, 3.2549e-03,
        9.3924e-04, 9.9279e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,082][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3090, 0.1592, 0.0563, 0.1611, 0.0816, 0.1124, 0.0804, 0.0400],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,083][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5022e-03, 4.5884e-04, 8.0650e-04, 8.0146e-04, 2.3095e-03, 9.0830e-03,
        7.2358e-03, 9.7280e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,083][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0976, 0.0223, 0.0463, 0.0292, 0.0537, 0.1458, 0.0772, 0.5279],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,083][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4042e-03, 1.8790e-04, 1.0466e-04, 1.0305e-04, 4.4107e-05, 1.9184e-04,
        8.2372e-05, 9.9388e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,084][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2983, 0.0321, 0.2972, 0.0223, 0.1913, 0.0494, 0.0231, 0.0864],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,084][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1056, 0.0459, 0.0368, 0.0963, 0.0496, 0.1935, 0.3574, 0.1148],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,084][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1021, 0.1022, 0.1353, 0.1299, 0.1115, 0.1257, 0.2555, 0.0378],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,086][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2433, 0.1591, 0.0903, 0.1540, 0.0581, 0.0940, 0.1350, 0.0662],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,089][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2261, 0.1602, 0.0443, 0.1122, 0.0313, 0.0778, 0.0879, 0.2602],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,092][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3931, 0.1058, 0.0682, 0.1316, 0.0551, 0.0652, 0.0667, 0.1143],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,096][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.2700, 0.0646, 0.2599, 0.0509, 0.1567, 0.0551, 0.0433, 0.0550, 0.0444],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,098][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8598e-03, 3.0818e-04, 3.9288e-04, 2.0946e-04, 9.3152e-05, 3.4936e-04,
        1.9551e-04, 3.4393e-05, 9.9656e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,102][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2942, 0.1000, 0.0993, 0.0733, 0.0762, 0.0963, 0.1128, 0.0933, 0.0546],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,104][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3890e-03, 4.0930e-05, 1.1468e-04, 9.1372e-05, 1.2259e-04, 2.4721e-04,
        6.3029e-04, 4.3104e-03, 9.9105e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,108][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1302, 0.0059, 0.0144, 0.0050, 0.0250, 0.0158, 0.0133, 0.1744, 0.6160],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,111][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2029e-02, 1.5135e-05, 4.5281e-06, 4.1252e-06, 1.0487e-05, 2.0255e-06,
        1.5990e-06, 6.3681e-07, 9.8793e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,111][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1843, 0.0479, 0.1954, 0.0418, 0.2051, 0.0316, 0.0339, 0.0760, 0.1839],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,111][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0899, 0.0516, 0.0178, 0.0960, 0.0434, 0.1324, 0.2112, 0.2543, 0.1034],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,112][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2446, 0.0945, 0.0635, 0.1106, 0.0670, 0.2306, 0.1181, 0.0637, 0.0074],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,112][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2349, 0.1368, 0.0807, 0.1282, 0.0688, 0.1114, 0.1146, 0.0827, 0.0420],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,113][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2178, 0.1357, 0.0484, 0.1146, 0.0327, 0.0783, 0.0756, 0.0396, 0.2572],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,113][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3213, 0.1425, 0.0868, 0.1031, 0.0658, 0.0408, 0.0394, 0.0870, 0.1133],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,113][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4483, 0.0154, 0.0910, 0.0179, 0.1148, 0.0794, 0.0344, 0.0637, 0.1221,
        0.0130], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,114][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8437e-03, 4.4339e-01, 4.2011e-04, 1.1167e-02, 1.7301e-04, 3.9656e-04,
        1.7954e-04, 5.1685e-05, 7.8219e-06, 5.4237e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,117][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1938, 0.3051, 0.0288, 0.0746, 0.0350, 0.0355, 0.0073, 0.0099, 0.0098,
        0.3001], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,121][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0332, 0.0077, 0.0011, 0.0078, 0.0036, 0.0607, 0.0498, 0.0552, 0.0865,
        0.6945], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,124][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2792, 0.0271, 0.0329, 0.0233, 0.0259, 0.1349, 0.0329, 0.1153, 0.0484,
        0.2801], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,128][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0959, 0.3388, 0.0212, 0.1222, 0.0127, 0.0680, 0.1006, 0.0296, 0.0100,
        0.2012], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,132][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2785, 0.0082, 0.2686, 0.0079, 0.1978, 0.0261, 0.0102, 0.0672, 0.1299,
        0.0055], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,135][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0379, 0.0143, 0.0304, 0.0388, 0.0401, 0.0709, 0.1131, 0.1483, 0.1417,
        0.3646], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,139][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0191, 0.1642, 0.0097, 0.1843, 0.0067, 0.0640, 0.1653, 0.0291, 0.0075,
        0.3502], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,140][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2117, 0.1211, 0.0706, 0.1258, 0.0655, 0.0849, 0.0925, 0.0691, 0.0558,
        0.1030], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,140][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1743, 0.1604, 0.0623, 0.1473, 0.0554, 0.0954, 0.0923, 0.0592, 0.0423,
        0.1111], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,141][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2454, 0.0949, 0.0875, 0.1077, 0.0643, 0.0685, 0.0652, 0.0796, 0.0741,
        0.1128], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,141][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3366, 0.0274, 0.0989, 0.0236, 0.1416, 0.0661, 0.0399, 0.0879, 0.1222,
        0.0269, 0.0287], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,141][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0613e-03, 1.2474e-02, 2.4221e-04, 5.1179e-01, 7.6290e-05, 6.9034e-04,
        2.3417e-04, 1.8324e-04, 8.4958e-06, 7.4668e-03, 4.6577e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,142][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0805, 0.0602, 0.0290, 0.3014, 0.0413, 0.0419, 0.0168, 0.0144, 0.0225,
        0.0535, 0.3385], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,143][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0825e-02, 6.0666e-03, 7.8769e-05, 3.9895e-03, 3.2314e-04, 7.8493e-03,
        1.3929e-02, 1.5643e-02, 7.4117e-03, 4.9319e-01, 4.4070e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,146][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0355, 0.0130, 0.0057, 0.0247, 0.0171, 0.1623, 0.0659, 0.1201, 0.1781,
        0.1219, 0.2556], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,148][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0325, 0.0869, 0.0062, 0.3865, 0.0039, 0.0541, 0.1207, 0.0253, 0.0037,
        0.0305, 0.2497], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,152][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2461, 0.0100, 0.2199, 0.0095, 0.2004, 0.0312, 0.0115, 0.0870, 0.1665,
        0.0076, 0.0105], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,157][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0333, 0.0121, 0.0183, 0.0201, 0.0278, 0.0426, 0.0640, 0.0801, 0.0986,
        0.2465, 0.3566], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,160][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.0999, 0.0062, 0.1172, 0.0064, 0.0608, 0.1994, 0.0255, 0.0108,
        0.2619, 0.2004], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,164][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1737, 0.1083, 0.0667, 0.1093, 0.0568, 0.0757, 0.0869, 0.0584, 0.0571,
        0.0958, 0.1114], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,168][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1452, 0.1315, 0.0486, 0.1398, 0.0421, 0.0983, 0.0992, 0.0528, 0.0355,
        0.0954, 0.1117], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,168][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2158, 0.0880, 0.0791, 0.1013, 0.0533, 0.0526, 0.0467, 0.0605, 0.0772,
        0.1112, 0.1142], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,169][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2395, 0.0436, 0.0425, 0.0483, 0.1477, 0.1272, 0.0496, 0.0348, 0.1529,
        0.0378, 0.0577, 0.0184], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,169][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7411e-03, 4.1758e-04, 1.9475e-03, 1.5599e-04, 1.9418e-04, 1.7377e-04,
        9.0199e-05, 1.4344e-04, 6.0605e-04, 9.2362e-05, 7.0774e-05, 9.9437e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,170][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2534, 0.0828, 0.0920, 0.0786, 0.0417, 0.1599, 0.0656, 0.0579, 0.0334,
        0.0525, 0.0632, 0.0190], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,170][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2695e-02, 5.1814e-05, 6.7520e-05, 7.2031e-05, 1.4467e-04, 1.1422e-03,
        2.1229e-04, 3.4372e-03, 1.4253e-03, 2.2502e-03, 4.8175e-03, 9.7368e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,170][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0417, 0.0033, 0.0152, 0.0070, 0.0018, 0.0113, 0.0108, 0.0292, 0.0152,
        0.0126, 0.0435, 0.8084], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,171][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2455e-02, 4.3741e-06, 1.7832e-04, 1.6933e-06, 3.6362e-05, 4.4307e-06,
        4.7551e-07, 4.6484e-06, 5.0049e-06, 9.8436e-08, 2.7243e-07, 9.0731e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,173][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1449, 0.0606, 0.1186, 0.0451, 0.1415, 0.0378, 0.0643, 0.0564, 0.1302,
        0.0535, 0.0496, 0.0975], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,176][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0530, 0.0190, 0.0083, 0.0293, 0.0137, 0.0337, 0.0716, 0.0491, 0.0277,
        0.1931, 0.3931, 0.1084], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,179][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0985, 0.1113, 0.0170, 0.1409, 0.0183, 0.0398, 0.1231, 0.0369, 0.1009,
        0.1312, 0.1691, 0.0130], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,183][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1773, 0.1002, 0.0677, 0.0920, 0.0569, 0.0763, 0.0672, 0.0575, 0.0870,
        0.0849, 0.0924, 0.0407], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,187][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1946, 0.0946, 0.0424, 0.0905, 0.0338, 0.0848, 0.0563, 0.0526, 0.0394,
        0.0674, 0.0701, 0.1736], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,191][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1693, 0.1342, 0.0981, 0.0890, 0.0692, 0.0306, 0.0391, 0.0394, 0.0360,
        0.1534, 0.0955, 0.0461], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,195][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.1269, 0.0968, 0.1341, 0.0736, 0.0851, 0.0125, 0.0440, 0.0320, 0.0669,
        0.0864, 0.0806, 0.0573, 0.1037], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,197][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([5.3284e-04, 6.4581e-05, 3.6088e-03, 6.2502e-05, 5.1728e-01, 3.8919e-05,
        4.3350e-05, 1.5836e-05, 2.1180e-05, 1.2287e-05, 2.7829e-05, 4.4147e-05,
        4.7825e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,197][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.1617, 0.0697, 0.1193, 0.0435, 0.1558, 0.0502, 0.0615, 0.0264, 0.0335,
        0.0501, 0.0398, 0.0230, 0.1656], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,198][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([1.3101e-03, 1.2819e-06, 1.6875e-04, 1.5232e-06, 7.3745e-03, 2.1697e-05,
        6.1087e-06, 6.8420e-05, 5.4428e-04, 4.2921e-05, 9.4156e-05, 4.0600e-04,
        9.8996e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,198][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([5.5828e-03, 5.1238e-04, 2.4797e-02, 3.4265e-04, 5.8538e-02, 3.0837e-04,
        3.5872e-04, 7.1149e-04, 2.8433e-03, 3.0063e-03, 3.3172e-03, 3.5184e-03,
        8.9616e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,199][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([1.1336e-03, 1.7545e-07, 4.9160e-05, 2.8494e-08, 5.8376e-01, 4.7566e-07,
        1.8979e-08, 5.4870e-08, 4.1129e-08, 5.6352e-09, 4.5218e-09, 4.5114e-08,
        4.1506e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,199][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.1334, 0.0834, 0.2148, 0.0417, 0.1609, 0.0142, 0.0250, 0.0230, 0.0319,
        0.0536, 0.0344, 0.0226, 0.1611], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,199][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0731, 0.0265, 0.0142, 0.0369, 0.0076, 0.0480, 0.0746, 0.0243, 0.0235,
        0.1759, 0.2951, 0.1098, 0.0904], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,200][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1286, 0.0946, 0.1530, 0.0714, 0.0714, 0.0244, 0.0550, 0.0314, 0.1301,
        0.0676, 0.0626, 0.0369, 0.0729], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,202][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1839, 0.1362, 0.0362, 0.1137, 0.0075, 0.0689, 0.0874, 0.0470, 0.0473,
        0.1116, 0.1083, 0.0451, 0.0069], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,204][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.1004, 0.0803, 0.0529, 0.0645, 0.2647, 0.0435, 0.0403, 0.0166, 0.0144,
        0.0470, 0.0451, 0.0139, 0.2163], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,208][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.1024, 0.0678, 0.0711, 0.0675, 0.0580, 0.0629, 0.0525, 0.0798, 0.1089,
        0.0805, 0.0872, 0.0845, 0.0768], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,212][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3369, 0.0292, 0.0614, 0.0169, 0.0696, 0.0614, 0.0180, 0.0445, 0.0429,
        0.0287, 0.0179, 0.0976, 0.1000, 0.0750], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,214][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4417e-03, 3.5439e-03, 2.8040e-03, 1.1984e-03, 7.7793e-04, 8.4728e-03,
        1.4017e-03, 4.5687e-05, 1.5886e-03, 1.5475e-03, 7.2071e-04, 1.1215e-04,
        5.4196e-04, 9.7580e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,218][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2244, 0.0501, 0.0238, 0.0433, 0.0299, 0.1032, 0.0341, 0.0250, 0.0491,
        0.0414, 0.0404, 0.0406, 0.0302, 0.2644], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,220][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.9847e-03, 7.3407e-05, 8.8150e-05, 5.4645e-05, 1.0390e-04, 3.0762e-04,
        4.2738e-04, 4.8582e-04, 1.2524e-03, 2.5361e-03, 3.5451e-03, 1.3155e-03,
        1.1180e-02, 9.7665e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,224][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0831, 0.0127, 0.0042, 0.0181, 0.0079, 0.0258, 0.0210, 0.0244, 0.0413,
        0.0545, 0.1158, 0.0234, 0.0639, 0.5039], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,226][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2016e-02, 2.4224e-03, 1.7874e-03, 8.8620e-04, 2.5003e-03, 8.6550e-03,
        2.0660e-04, 2.9333e-05, 6.6919e-04, 2.4762e-04, 2.7983e-04, 6.1711e-06,
        1.0438e-03, 9.6925e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,227][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2121, 0.0104, 0.1761, 0.0105, 0.1082, 0.0139, 0.0085, 0.0379, 0.1001,
        0.0078, 0.0103, 0.1453, 0.1383, 0.0205], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,227][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0318, 0.0060, 0.0065, 0.0101, 0.0113, 0.0137, 0.0289, 0.0125, 0.0198,
        0.1051, 0.1643, 0.1693, 0.2544, 0.1662], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,227][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0516, 0.1067, 0.0289, 0.1047, 0.0138, 0.1020, 0.1380, 0.0314, 0.0279,
        0.1766, 0.1382, 0.0250, 0.0177, 0.0374], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,228][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1479, 0.0795, 0.0572, 0.0816, 0.0465, 0.0654, 0.0622, 0.0462, 0.0543,
        0.0739, 0.0846, 0.0549, 0.0512, 0.0946], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,228][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0996, 0.0719, 0.0486, 0.0757, 0.0431, 0.0780, 0.0585, 0.0245, 0.0469,
        0.0608, 0.0654, 0.0279, 0.0369, 0.2622], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,230][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2493, 0.0593, 0.0663, 0.0792, 0.0416, 0.0379, 0.0318, 0.0572, 0.0680,
        0.0629, 0.0805, 0.0834, 0.0428, 0.0399], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,233][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2485, 0.0241, 0.0766, 0.0202, 0.0781, 0.0648, 0.0216, 0.0350, 0.0692,
        0.0241, 0.0246, 0.0801, 0.1141, 0.1032, 0.0159], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,235][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1203e-03, 1.1776e-02, 4.2678e-04, 3.4308e-02, 8.1684e-05, 3.0527e-04,
        1.4489e-03, 1.7843e-04, 5.7919e-05, 8.2826e-03, 3.0200e-02, 2.4499e-04,
        5.2725e-05, 1.4512e-04, 9.0837e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,239][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1560, 0.0686, 0.0349, 0.0942, 0.0331, 0.0573, 0.0246, 0.0368, 0.0299,
        0.0586, 0.0927, 0.0381, 0.0338, 0.0729, 0.1685], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,241][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9473e-03, 2.6607e-04, 3.7534e-05, 1.8233e-04, 2.8260e-05, 7.2979e-04,
        1.2070e-03, 2.4273e-04, 1.1491e-03, 7.2066e-03, 1.1950e-02, 1.6589e-02,
        2.8428e-03, 2.9365e-01, 6.6097e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,244][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0358, 0.0023, 0.0011, 0.0038, 0.0016, 0.0338, 0.0104, 0.0262, 0.0572,
        0.0123, 0.0316, 0.0731, 0.0178, 0.4155, 0.2774], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,248][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0430, 0.0608, 0.0091, 0.0778, 0.0018, 0.0310, 0.2249, 0.0341, 0.0047,
        0.0210, 0.0410, 0.0007, 0.0008, 0.0324, 0.4168], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,252][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1243, 0.0060, 0.0924, 0.0052, 0.0661, 0.0174, 0.0049, 0.0322, 0.0555,
        0.0044, 0.0065, 0.1131, 0.1088, 0.0334, 0.3299], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,255][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0230, 0.0043, 0.0060, 0.0071, 0.0051, 0.0093, 0.0124, 0.0191, 0.0280,
        0.0512, 0.0830, 0.0973, 0.1002, 0.2690, 0.2848], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,255][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0594, 0.0054, 0.1034, 0.0043, 0.0465, 0.1309, 0.0197, 0.0089,
        0.1506, 0.1812, 0.0048, 0.0065, 0.0337, 0.2365], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,256][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1176, 0.0729, 0.0497, 0.0801, 0.0436, 0.0535, 0.0682, 0.0468, 0.0421,
        0.0688, 0.0841, 0.0452, 0.0488, 0.0817, 0.0969], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,256][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1019, 0.0837, 0.0336, 0.1003, 0.0336, 0.0743, 0.0854, 0.0502, 0.0333,
        0.0760, 0.0926, 0.0275, 0.0301, 0.0641, 0.1133], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,257][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1799, 0.0711, 0.0573, 0.0730, 0.0430, 0.0507, 0.0460, 0.0540, 0.0542,
        0.0731, 0.0694, 0.0747, 0.0431, 0.0371, 0.0734], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,258][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:36,259][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4882],
        [30536],
        [    1],
        [33651],
        [  868],
        [29769],
        [45342],
        [41504],
        [44518],
        [23390],
        [32765],
        [25603],
        [ 1367],
        [25563],
        [32598]], device='cuda:0')
[2024-07-24 10:20:36,261][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[34440],
        [38946],
        [    1],
        [45940],
        [  271],
        [47462],
        [43570],
        [45801],
        [44451],
        [44289],
        [42471],
        [46786],
        [  180],
        [28210],
        [41024]], device='cuda:0')
[2024-07-24 10:20:36,263][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11192],
        [10484],
        [ 3426],
        [ 4624],
        [ 2206],
        [ 1974],
        [ 3090],
        [ 1696],
        [ 1819],
        [ 3789],
        [ 3260],
        [ 2910],
        [ 3210],
        [ 5490],
        [ 5090]], device='cuda:0')
[2024-07-24 10:20:36,264][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 7288],
        [12996],
        [26317],
        [24747],
        [ 1707],
        [33302],
        [49185],
        [26519],
        [40616],
        [11915],
        [25361],
        [28493],
        [ 1826],
        [26924],
        [35855]], device='cuda:0')
[2024-07-24 10:20:36,266][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7229],
        [ 5777],
        [ 5234],
        [ 8755],
        [ 8757],
        [10299],
        [ 8862],
        [ 8017],
        [ 6364],
        [ 7674],
        [11978],
        [ 8611],
        [11831],
        [15712],
        [11299]], device='cuda:0')
[2024-07-24 10:20:36,269][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[35596],
        [32752],
        [ 2113],
        [18620],
        [24422],
        [ 7037],
        [20695],
        [13919],
        [ 8611],
        [25743],
        [24219],
        [39199],
        [26598],
        [ 7572],
        [13514]], device='cuda:0')
[2024-07-24 10:20:36,271][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[27445],
        [27303],
        [ 1466],
        [10685],
        [ 2782],
        [14746],
        [ 8927],
        [ 7386],
        [20517],
        [15058],
        [10927],
        [36166],
        [ 5280],
        [12316],
        [11786]], device='cuda:0')
[2024-07-24 10:20:36,274][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28842],
        [28665],
        [33885],
        [34686],
        [20798],
        [42165],
        [29374],
        [40747],
        [30435],
        [29704],
        [34393],
        [43047],
        [19157],
        [35333],
        [25252]], device='cuda:0')
[2024-07-24 10:20:36,276][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41658],
        [41821],
        [24330],
        [18880],
        [19733],
        [11367],
        [12663],
        [17787],
        [16897],
        [12378],
        [15271],
        [28398],
        [20885],
        [21083],
        [10241]], device='cuda:0')
[2024-07-24 10:20:36,279][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23751],
        [22712],
        [19926],
        [33502],
        [32302],
        [36710],
        [38043],
        [36425],
        [34664],
        [23981],
        [33909],
        [35532],
        [34687],
        [29333],
        [35669]], device='cuda:0')
[2024-07-24 10:20:36,281][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[23369],
        [31474],
        [19817],
        [24201],
        [13598],
        [29888],
        [40402],
        [35900],
        [36656],
        [33555],
        [31466],
        [30033],
        [22191],
        [32539],
        [29049]], device='cuda:0')
[2024-07-24 10:20:36,284][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[44892],
        [45812],
        [45910],
        [46014],
        [45940],
        [46587],
        [46258],
        [45949],
        [45989],
        [45694],
        [45472],
        [45288],
        [44933],
        [45306],
        [44718]], device='cuda:0')
[2024-07-24 10:20:36,286][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5736],
        [11149],
        [32299],
        [16190],
        [37021],
        [11058],
        [29824],
        [31211],
        [23487],
        [24857],
        [21685],
        [19899],
        [43416],
        [16770],
        [20881]], device='cuda:0')
[2024-07-24 10:20:36,289][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[17702],
        [28634],
        [38848],
        [36310],
        [41701],
        [37629],
        [43732],
        [44168],
        [44922],
        [45807],
        [44802],
        [44447],
        [46557],
        [44129],
        [45610]], device='cuda:0')
[2024-07-24 10:20:36,290][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14422],
        [12178],
        [    1],
        [32386],
        [  354],
        [ 7057],
        [43342],
        [30898],
        [42069],
        [11796],
        [31493],
        [17289],
        [  338],
        [19641],
        [30019]], device='cuda:0')
[2024-07-24 10:20:36,291][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[14313],
        [14800],
        [14938],
        [10789],
        [10762],
        [15304],
        [ 9278],
        [ 8943],
        [ 8110],
        [11135],
        [11580],
        [14716],
        [14386],
        [14411],
        [14040]], device='cuda:0')
[2024-07-24 10:20:36,292][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14426],
        [35960],
        [26022],
        [31062],
        [38622],
        [16197],
        [14385],
        [25833],
        [20714],
        [33201],
        [27132],
        [17240],
        [33060],
        [21682],
        [14938]], device='cuda:0')
[2024-07-24 10:20:36,293][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[21343],
        [21034],
        [20230],
        [17793],
        [19392],
        [18103],
        [17230],
        [18017],
        [20117],
        [27654],
        [19183],
        [18906],
        [20345],
        [14811],
        [14115]], device='cuda:0')
[2024-07-24 10:20:36,294][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16795],
        [19555],
        [33920],
        [20888],
        [30829],
        [27196],
        [17680],
        [29847],
        [41910],
        [29617],
        [29938],
        [23801],
        [36439],
        [42415],
        [25648]], device='cuda:0')
[2024-07-24 10:20:36,296][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25588],
        [25329],
        [23268],
        [28192],
        [18327],
        [30132],
        [27286],
        [34187],
        [37306],
        [25715],
        [27604],
        [29652],
        [18987],
        [33088],
        [31979]], device='cuda:0')
[2024-07-24 10:20:36,297][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19989],
        [32556],
        [27489],
        [32684],
        [28822],
        [23269],
        [34674],
        [25151],
        [27409],
        [33080],
        [33033],
        [21051],
        [29090],
        [34224],
        [34444]], device='cuda:0')
[2024-07-24 10:20:36,300][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40737],
        [40286],
        [ 3737],
        [12483],
        [ 4324],
        [ 7185],
        [ 7762],
        [ 5573],
        [ 4564],
        [ 8761],
        [ 8383],
        [ 6867],
        [ 4493],
        [18894],
        [20087]], device='cuda:0')
[2024-07-24 10:20:36,302][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[16405],
        [15714],
        [ 9122],
        [ 4497],
        [ 4765],
        [ 6611],
        [ 6878],
        [ 7173],
        [ 5639],
        [ 4624],
        [ 6512],
        [ 8193],
        [ 5648],
        [ 6238],
        [10584]], device='cuda:0')
[2024-07-24 10:20:36,305][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34353],
        [34333],
        [33259],
        [35118],
        [30455],
        [33629],
        [21770],
        [25132],
        [30803],
        [29515],
        [29407],
        [29891],
        [28197],
        [28443],
        [31672]], device='cuda:0')
[2024-07-24 10:20:36,307][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32989],
        [33307],
        [33272],
        [34109],
        [34402],
        [34017],
        [36675],
        [38105],
        [37927],
        [36287],
        [36628],
        [36170],
        [36923],
        [35764],
        [36883]], device='cuda:0')
[2024-07-24 10:20:36,310][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44789],
        [44355],
        [40119],
        [41619],
        [38717],
        [36860],
        [36414],
        [39536],
        [37563],
        [37059],
        [35655],
        [40799],
        [35687],
        [36874],
        [36416]], device='cuda:0')
[2024-07-24 10:20:36,312][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[27239],
        [34527],
        [46077],
        [40918],
        [38881],
        [38692],
        [40942],
        [39146],
        [40232],
        [43289],
        [42125],
        [44233],
        [39967],
        [40170],
        [41268]], device='cuda:0')
[2024-07-24 10:20:36,315][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6845],
        [ 5335],
        [11363],
        [12653],
        [13979],
        [15727],
        [19391],
        [14925],
        [13996],
        [12842],
        [14096],
        [11859],
        [15123],
        [11973],
        [12419]], device='cuda:0')
[2024-07-24 10:20:36,317][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[25289],
        [30358],
        [50254],
        [11985],
        [49249],
        [37456],
        [ 4089],
        [14221],
        [ 5600],
        [31082],
        [12521],
        [25550],
        [49278],
        [23895],
        [13949]], device='cuda:0')
[2024-07-24 10:20:36,320][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914],
        [23914]], device='cuda:0')
[2024-07-24 10:20:36,345][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:36,349][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,351][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,354][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,358][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,358][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,358][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,359][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,359][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,359][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,360][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,360][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,360][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,361][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,364][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9917, 0.0083], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,366][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9887, 0.0113], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,370][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4140, 0.5860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,373][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5982, 0.4018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,377][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8312, 0.1688], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,381][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5958, 0.4042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,384][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9731, 0.0269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,386][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8721, 0.1279], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,387][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,387][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2299, 0.7701], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,387][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0102, 0.9898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,387][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.6638, 0.1134, 0.2228], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,388][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.8267, 0.1469, 0.0264], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,388][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.8434, 0.0610, 0.0956], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,388][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.3673, 0.3732, 0.2596], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,389][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.7057, 0.2457, 0.0486], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,390][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.6475, 0.3188, 0.0337], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,392][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.5311, 0.3640, 0.1049], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,395][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.6962, 0.1956, 0.1082], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,399][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.7926, 0.1615, 0.0459], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,402][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.0010, 0.6828, 0.3162], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,406][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.1220, 0.3856, 0.4924], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,410][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.0010, 0.2226, 0.7764], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,413][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4369, 0.1466, 0.0772, 0.3393], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,415][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7718, 0.0990, 0.0464, 0.0829], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,415][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3622, 0.0441, 0.0946, 0.4991], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,416][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3307, 0.2713, 0.1920, 0.2060], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,416][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3557, 0.2460, 0.0591, 0.3392], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,416][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3996, 0.3910, 0.0079, 0.2016], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,417][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2685, 0.1985, 0.0917, 0.4413], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,417][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6016, 0.0739, 0.1464, 0.1781], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,417][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5709, 0.1128, 0.0774, 0.2389], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,418][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.9565e-04, 3.7539e-01, 1.9822e-01, 4.2609e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,421][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0920, 0.2783, 0.3891, 0.2407], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,423][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0015, 0.1467, 0.4372, 0.4145], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,427][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1916, 0.1413, 0.3773, 0.2332, 0.0565], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,430][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.5767, 0.0870, 0.0297, 0.2725, 0.0342], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,434][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.3409, 0.0478, 0.0694, 0.4643, 0.0777], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,438][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.2796, 0.2451, 0.1696, 0.1677, 0.1380], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,441][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.4320, 0.1537, 0.0374, 0.2975, 0.0795], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,443][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.3572, 0.2921, 0.0927, 0.2007, 0.0573], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,443][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.3055, 0.2089, 0.0572, 0.3549, 0.0735], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,444][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.4906, 0.1195, 0.1131, 0.1834, 0.0934], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,444][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.5668, 0.1701, 0.0567, 0.1535, 0.0530], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,445][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0006, 0.4209, 0.1825, 0.3165, 0.0795], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,445][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0737, 0.2156, 0.2733, 0.1826, 0.2548], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,445][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([1.1921e-04, 5.2587e-02, 1.5166e-01, 3.8890e-01, 4.0674e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,446][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2944, 0.2037, 0.0122, 0.4293, 0.0134, 0.0471], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,446][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.5365, 0.1358, 0.0247, 0.1930, 0.0499, 0.0601], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,448][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2207, 0.0432, 0.0819, 0.2890, 0.0915, 0.2737], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,450][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2232, 0.1681, 0.1218, 0.1273, 0.1110, 0.2487], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,454][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2775, 0.1964, 0.0343, 0.2501, 0.0824, 0.1593], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,457][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3946, 0.3718, 0.0424, 0.0636, 0.0568, 0.0708], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,461][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1455, 0.1329, 0.0672, 0.3043, 0.1097, 0.2404], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,465][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4398, 0.0470, 0.1587, 0.0726, 0.1518, 0.1301], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,468][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4487, 0.1357, 0.0814, 0.1251, 0.0757, 0.1333], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,470][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([3.1026e-04, 4.1268e-01, 1.8101e-01, 3.0618e-01, 9.2949e-02, 6.8610e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,472][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0538, 0.1758, 0.2316, 0.1475, 0.2229, 0.1684], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,472][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([9.5524e-05, 2.8464e-02, 9.0855e-02, 8.6690e-02, 1.4861e-01, 6.4528e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,473][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0998, 0.0450, 0.0094, 0.1285, 0.0081, 0.6137, 0.0956],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,473][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3908, 0.0801, 0.0384, 0.1970, 0.0719, 0.1488, 0.0731],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,473][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1766, 0.0345, 0.0625, 0.2108, 0.0653, 0.1772, 0.2730],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,474][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2059, 0.1457, 0.1049, 0.1081, 0.0896, 0.2041, 0.1417],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,474][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2200, 0.1762, 0.0343, 0.2173, 0.0798, 0.1228, 0.1496],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,475][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3049, 0.3224, 0.0336, 0.0923, 0.0720, 0.0413, 0.1335],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,478][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1453, 0.1133, 0.0549, 0.2586, 0.0819, 0.1851, 0.1609],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,482][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3509, 0.0490, 0.1410, 0.0767, 0.1573, 0.1143, 0.1108],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,485][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3828, 0.0821, 0.0586, 0.1168, 0.0535, 0.0937, 0.2126],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,487][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.7907e-04, 2.8855e-01, 1.9501e-01, 3.5758e-01, 1.2212e-01, 5.8556e-03,
        3.0709e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,491][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0494, 0.1496, 0.2069, 0.1281, 0.1927, 0.1445, 0.1288],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,494][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.6494e-04, 3.1106e-02, 1.1609e-01, 8.3931e-02, 1.8339e-01, 3.1622e-01,
        2.6910e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,498][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0203, 0.0074, 0.0035, 0.0402, 0.0047, 0.4593, 0.4550, 0.0095],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,500][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.3229, 0.0854, 0.0430, 0.1332, 0.0739, 0.1117, 0.1851, 0.0447],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,501][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1403, 0.0350, 0.0554, 0.2060, 0.0635, 0.1604, 0.2283, 0.1110],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,501][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2073, 0.1260, 0.0961, 0.1078, 0.0887, 0.1772, 0.1292, 0.0676],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,501][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2221, 0.1751, 0.0454, 0.1790, 0.1129, 0.1045, 0.1069, 0.0542],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,502][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.2180, 0.3634, 0.0043, 0.0874, 0.0124, 0.0282, 0.1467, 0.1395],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,502][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1446, 0.1157, 0.0410, 0.2330, 0.0582, 0.1644, 0.1326, 0.1105],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,503][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.3792, 0.0619, 0.0526, 0.0788, 0.0927, 0.1791, 0.1278, 0.0279],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,503][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.3132, 0.0576, 0.0536, 0.1268, 0.0639, 0.1129, 0.1833, 0.0887],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,503][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.7552e-04, 3.7820e-01, 1.7080e-01, 2.9898e-01, 9.5857e-02, 6.3953e-03,
        4.4342e-02, 5.2510e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,505][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0430, 0.1326, 0.1794, 0.1112, 0.1693, 0.1251, 0.1124, 0.1271],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,507][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.1801e-05, 9.9944e-03, 2.3634e-02, 3.9358e-02, 4.2141e-02, 2.4991e-01,
        1.8034e-01, 4.5460e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,510][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0285, 0.0359, 0.0194, 0.0836, 0.0299, 0.3000, 0.2285, 0.2150, 0.0591],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,514][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.3652, 0.0490, 0.0247, 0.1130, 0.0330, 0.1177, 0.1209, 0.0780, 0.0984],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,518][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1099, 0.0308, 0.0516, 0.1826, 0.0573, 0.1466, 0.2008, 0.0891, 0.1313],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,521][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1737, 0.1107, 0.0834, 0.0949, 0.0767, 0.1557, 0.1120, 0.0639, 0.1290],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,525][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2294, 0.1212, 0.0394, 0.1683, 0.0902, 0.1238, 0.1230, 0.0597, 0.0450],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,529][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.2494, 0.1634, 0.1105, 0.0613, 0.1152, 0.0414, 0.1690, 0.0286, 0.0612],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,530][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1162, 0.0949, 0.0302, 0.1679, 0.0423, 0.1325, 0.1023, 0.0960, 0.2176],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,530][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.2534, 0.0226, 0.1403, 0.0707, 0.1659, 0.1525, 0.0554, 0.0681, 0.0712],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,530][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.3223, 0.0809, 0.0564, 0.1033, 0.0440, 0.1210, 0.1618, 0.0628, 0.0476],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,531][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([1.3820e-04, 4.5657e-01, 1.3842e-01, 2.7907e-01, 7.7772e-02, 4.7663e-03,
        3.5187e-02, 3.9989e-03, 4.0751e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,531][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0382, 0.1138, 0.1558, 0.0947, 0.1462, 0.1063, 0.0959, 0.1089, 0.1402],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,532][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([6.6506e-06, 6.3458e-03, 1.5352e-02, 4.1947e-02, 3.6249e-02, 2.8355e-01,
        1.9485e-01, 3.1781e-01, 1.0390e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,532][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0957, 0.0119, 0.0240, 0.1110, 0.0264, 0.1810, 0.1440, 0.1049, 0.2648,
        0.0363], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,534][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4146, 0.0116, 0.0317, 0.0991, 0.0515, 0.0835, 0.0943, 0.0481, 0.0570,
        0.1087], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,536][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0654, 0.0191, 0.0388, 0.1019, 0.0398, 0.0990, 0.1177, 0.0589, 0.0946,
        0.3649], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,540][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1613, 0.1052, 0.0751, 0.0805, 0.0634, 0.1515, 0.0992, 0.0554, 0.1333,
        0.0752], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,544][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1656, 0.1280, 0.0194, 0.1567, 0.0377, 0.0997, 0.1168, 0.0472, 0.0422,
        0.1869], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,547][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0495, 0.1644, 0.0039, 0.0144, 0.0120, 0.0104, 0.0594, 0.0079, 0.0092,
        0.6689], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,551][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0756, 0.0618, 0.0287, 0.1164, 0.0424, 0.0858, 0.0748, 0.0639, 0.1710,
        0.2794], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,555][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2790, 0.0363, 0.1210, 0.0606, 0.1514, 0.0484, 0.0640, 0.0231, 0.1169,
        0.0993], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,558][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3095, 0.0771, 0.0426, 0.1340, 0.0466, 0.0555, 0.1549, 0.0521, 0.0502,
        0.0776], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,558][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.7346e-04, 4.6815e-01, 1.2988e-01, 2.9771e-01, 6.2565e-02, 4.2118e-03,
        2.0640e-02, 3.0320e-03, 3.2063e-03, 1.0437e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,559][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0338, 0.1017, 0.1409, 0.0867, 0.1348, 0.0987, 0.0861, 0.1020, 0.1300,
        0.0853], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,559][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([7.1865e-05, 1.5942e-02, 5.6645e-02, 4.8194e-02, 9.3061e-02, 1.8997e-01,
        1.2479e-01, 1.9333e-01, 1.1754e-01, 1.6046e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,560][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0331, 0.0168, 0.0108, 0.0332, 0.0109, 0.1070, 0.2042, 0.1320, 0.1652,
        0.1769, 0.1099], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,560][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2153, 0.0270, 0.0226, 0.0234, 0.0453, 0.0896, 0.0915, 0.0372, 0.0562,
        0.3086, 0.0831], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,560][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0529, 0.0162, 0.0334, 0.0842, 0.0345, 0.0770, 0.0919, 0.0450, 0.0755,
        0.2630, 0.2265], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,561][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1642, 0.0974, 0.0682, 0.0763, 0.0583, 0.1355, 0.0905, 0.0505, 0.1152,
        0.0721, 0.0718], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,563][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1487, 0.1170, 0.0278, 0.1365, 0.0509, 0.0814, 0.0930, 0.0405, 0.0355,
        0.1548, 0.1138], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,565][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0645, 0.0941, 0.0044, 0.0546, 0.0191, 0.0053, 0.0680, 0.0118, 0.0121,
        0.5691, 0.0969], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,569][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0583, 0.0453, 0.0225, 0.0945, 0.0335, 0.0711, 0.0641, 0.0490, 0.1360,
        0.2294, 0.1962], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,573][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2207, 0.0352, 0.0765, 0.0599, 0.1208, 0.0866, 0.0722, 0.0269, 0.1139,
        0.0999, 0.0875], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,576][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2831, 0.0680, 0.0395, 0.1152, 0.0379, 0.0472, 0.1358, 0.0493, 0.0462,
        0.0629, 0.1148], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,579][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([3.3269e-04, 3.7322e-01, 1.6494e-01, 2.6587e-01, 8.6442e-02, 7.8409e-03,
        5.1844e-02, 7.4155e-03, 9.5617e-03, 2.0115e-02, 1.2414e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,583][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0318, 0.0921, 0.1309, 0.0802, 0.1246, 0.0909, 0.0788, 0.0943, 0.1206,
        0.0783, 0.0775], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,587][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0002, 0.0256, 0.0933, 0.0463, 0.1325, 0.1408, 0.0746, 0.1368, 0.1356,
        0.1226, 0.0917], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,587][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0164, 0.0071, 0.0023, 0.0324, 0.0023, 0.1776, 0.0317, 0.3431, 0.0534,
        0.1253, 0.1457, 0.0627], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,588][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.1020, 0.0218, 0.0099, 0.0595, 0.0305, 0.0221, 0.0346, 0.0270, 0.0404,
        0.3438, 0.2919, 0.0166], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,588][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0588, 0.0183, 0.0307, 0.0789, 0.0312, 0.0665, 0.0840, 0.0442, 0.0681,
        0.2541, 0.1888, 0.0765], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,588][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1520, 0.0866, 0.0592, 0.0757, 0.0533, 0.1386, 0.1025, 0.0468, 0.1221,
        0.0744, 0.0784, 0.0103], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,589][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1437, 0.0646, 0.0072, 0.1085, 0.0087, 0.1371, 0.1739, 0.0689, 0.0353,
        0.1359, 0.1114, 0.0048], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,589][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.3052, 0.0944, 0.0032, 0.0501, 0.0055, 0.0444, 0.0760, 0.0707, 0.0164,
        0.1709, 0.0586, 0.1046], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,590][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0600, 0.0465, 0.0168, 0.0895, 0.0229, 0.0649, 0.0538, 0.0479, 0.1219,
        0.2270, 0.1858, 0.0631], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,591][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.2116, 0.0319, 0.0765, 0.0394, 0.1076, 0.1477, 0.0783, 0.0361, 0.1010,
        0.0673, 0.0562, 0.0463], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,595][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.2364, 0.0677, 0.0348, 0.0669, 0.0368, 0.0821, 0.1585, 0.0565, 0.0391,
        0.0891, 0.0867, 0.0456], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,598][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0004, 0.3743, 0.1614, 0.2329, 0.0909, 0.0104, 0.0638, 0.0102, 0.0135,
        0.0247, 0.0144, 0.0030], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,602][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0299, 0.0872, 0.1170, 0.0734, 0.1104, 0.0814, 0.0737, 0.0826, 0.1056,
        0.0719, 0.0704, 0.0965], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,604][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([8.2889e-05, 1.2293e-02, 3.4265e-02, 4.7492e-02, 5.5847e-02, 1.6788e-01,
        1.2157e-01, 1.5211e-01, 7.3694e-02, 1.2416e-01, 1.7410e-01, 3.6523e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,607][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0827, 0.0641, 0.1236, 0.0702, 0.0157, 0.0698, 0.0590, 0.0074, 0.0566,
        0.2745, 0.1144, 0.0424, 0.0196], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,611][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.1058, 0.0171, 0.0075, 0.0423, 0.0072, 0.0411, 0.0436, 0.0297, 0.0273,
        0.3457, 0.2224, 0.0844, 0.0259], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,614][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0465, 0.0152, 0.0227, 0.0723, 0.0251, 0.0695, 0.0824, 0.0345, 0.0592,
        0.2493, 0.1955, 0.0723, 0.0556], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,618][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.1431, 0.0985, 0.0662, 0.0716, 0.0561, 0.1348, 0.0845, 0.0450, 0.1161,
        0.0672, 0.0669, 0.0115, 0.0384], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,619][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1478, 0.0678, 0.0119, 0.1174, 0.0212, 0.1358, 0.1194, 0.0432, 0.0266,
        0.1496, 0.1185, 0.0190, 0.0219], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,619][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0582, 0.0836, 0.0278, 0.0804, 0.0281, 0.0073, 0.0582, 0.0126, 0.0122,
        0.3513, 0.2137, 0.0210, 0.0454], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,619][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0597, 0.0446, 0.0144, 0.0888, 0.0195, 0.0621, 0.0518, 0.0379, 0.0991,
        0.2509, 0.2006, 0.0549, 0.0156], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,620][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1791, 0.0574, 0.0628, 0.0575, 0.0423, 0.0893, 0.0449, 0.0368, 0.0971,
        0.1387, 0.0869, 0.0635, 0.0437], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,620][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.2197, 0.0953, 0.0211, 0.0450, 0.0198, 0.1122, 0.2186, 0.0287, 0.0303,
        0.0976, 0.0459, 0.0366, 0.0293], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,621][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([3.1676e-04, 3.8418e-01, 1.8075e-01, 2.4745e-01, 8.2901e-02, 6.7128e-03,
        4.1445e-02, 7.1615e-03, 8.7435e-03, 1.7568e-02, 1.1953e-02, 3.0818e-03,
        7.7363e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,621][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0281, 0.0799, 0.1030, 0.0678, 0.0961, 0.0748, 0.0645, 0.0738, 0.0931,
        0.0650, 0.0647, 0.0881, 0.1012], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,622][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([2.0838e-06, 2.4018e-03, 6.6173e-03, 2.3291e-02, 2.7644e-02, 1.5724e-01,
        1.4131e-01, 1.7779e-01, 3.2686e-02, 1.2644e-01, 2.4317e-01, 1.2903e-02,
        4.8509e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,623][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0246, 0.0180, 0.0097, 0.0565, 0.0083, 0.1112, 0.0440, 0.0749, 0.0376,
        0.2295, 0.1588, 0.1823, 0.0171, 0.0277], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,626][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0761, 0.0280, 0.0055, 0.0257, 0.0117, 0.0265, 0.0268, 0.0154, 0.0071,
        0.3433, 0.1548, 0.2199, 0.0448, 0.0144], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,630][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0389, 0.0155, 0.0314, 0.0537, 0.0356, 0.0540, 0.0673, 0.0362, 0.0579,
        0.1783, 0.1424, 0.0708, 0.0764, 0.1416], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,634][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1408, 0.0821, 0.0534, 0.0674, 0.0510, 0.1246, 0.0839, 0.0411, 0.1040,
        0.0673, 0.0667, 0.0114, 0.0360, 0.0703], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,637][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1135, 0.0857, 0.0113, 0.1190, 0.0215, 0.0762, 0.0965, 0.0336, 0.0240,
        0.1584, 0.1029, 0.0362, 0.0231, 0.0980], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,641][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0941, 0.0982, 0.0158, 0.0378, 0.0338, 0.0421, 0.0783, 0.0236, 0.0383,
        0.2225, 0.0543, 0.0277, 0.0439, 0.1895], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,645][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0321, 0.0328, 0.0159, 0.0704, 0.0255, 0.0611, 0.0504, 0.0455, 0.1267,
        0.2005, 0.1638, 0.0582, 0.0201, 0.0970], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,648][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.2022, 0.0228, 0.1522, 0.0444, 0.1085, 0.0372, 0.0292, 0.0418, 0.1000,
        0.0443, 0.0664, 0.0611, 0.0769, 0.0131], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,648][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2507, 0.0510, 0.0382, 0.0529, 0.0400, 0.0623, 0.1222, 0.0387, 0.0342,
        0.0638, 0.0665, 0.0406, 0.0628, 0.0762], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,649][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.6796e-04, 3.8709e-01, 1.6154e-01, 3.0075e-01, 7.5103e-02, 3.9474e-03,
        1.4800e-02, 3.2448e-03, 4.1048e-03, 1.0844e-02, 7.8660e-03, 1.7092e-03,
        4.5124e-03, 2.4321e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,649][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0228, 0.0692, 0.0964, 0.0591, 0.0930, 0.0676, 0.0590, 0.0696, 0.0891,
        0.0583, 0.0572, 0.0839, 0.0986, 0.0762], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,649][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([1.2258e-05, 5.9716e-03, 1.7837e-02, 1.9715e-02, 3.6504e-02, 1.2669e-01,
        6.1392e-02, 1.2865e-01, 6.5694e-02, 9.1930e-02, 9.1698e-02, 1.4628e-02,
        4.9788e-02, 2.8949e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,650][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0179, 0.0069, 0.0015, 0.0210, 0.0013, 0.1364, 0.0933, 0.0357, 0.1107,
        0.1957, 0.0967, 0.0378, 0.0036, 0.1805, 0.0612], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,650][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1183, 0.0198, 0.0100, 0.0463, 0.0152, 0.0362, 0.0511, 0.0155, 0.0269,
        0.1855, 0.1651, 0.0795, 0.0412, 0.1159, 0.0736], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,651][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0282, 0.0137, 0.0306, 0.0408, 0.0279, 0.0490, 0.0558, 0.0309, 0.0522,
        0.1358, 0.1068, 0.0664, 0.0598, 0.1276, 0.1744], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,652][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1421, 0.0828, 0.0529, 0.0643, 0.0450, 0.1234, 0.0814, 0.0398, 0.1004,
        0.0618, 0.0612, 0.0103, 0.0311, 0.0653, 0.0383], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,655][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1223, 0.0790, 0.0085, 0.1016, 0.0136, 0.0852, 0.1025, 0.0360, 0.0232,
        0.1354, 0.0829, 0.0241, 0.0141, 0.0844, 0.0870], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,659][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0491, 0.0186, 0.0065, 0.0138, 0.0208, 0.0075, 0.0680, 0.0116, 0.0142,
        0.0784, 0.0210, 0.0135, 0.0280, 0.0218, 0.6272], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,663][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0366, 0.0324, 0.0148, 0.0610, 0.0210, 0.0501, 0.0434, 0.0372, 0.0966,
        0.1522, 0.1227, 0.0443, 0.0166, 0.0748, 0.1964], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,666][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1723, 0.0429, 0.0581, 0.0572, 0.0859, 0.0384, 0.0585, 0.0201, 0.0960,
        0.0848, 0.0619, 0.0375, 0.0583, 0.0284, 0.0996], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,670][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2299, 0.0504, 0.0397, 0.0734, 0.0338, 0.0420, 0.1098, 0.0443, 0.0375,
        0.0428, 0.0788, 0.0509, 0.0442, 0.0719, 0.0506], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,672][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.0650e-04, 3.5054e-01, 1.7274e-01, 2.9040e-01, 7.8563e-02, 4.4933e-03,
        2.0538e-02, 4.0272e-03, 6.0348e-03, 1.5274e-02, 9.7171e-03, 2.1590e-03,
        5.3664e-03, 3.8131e-02, 1.9127e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,676][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0220, 0.0659, 0.0915, 0.0558, 0.0870, 0.0636, 0.0561, 0.0657, 0.0848,
        0.0554, 0.0538, 0.0784, 0.0924, 0.0724, 0.0553], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,677][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.3289e-05, 1.3769e-02, 4.7877e-02, 2.6858e-02, 7.7076e-02, 9.0609e-02,
        5.3479e-02, 1.0201e-01, 8.3378e-02, 8.2712e-02, 6.2993e-02, 2.5236e-02,
        9.1600e-02, 1.8562e-01, 5.6688e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,703][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:36,704][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,704][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,705][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,705][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,705][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,706][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,706][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,706][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,707][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,708][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,709][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,709][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:36,709][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5006, 0.4994], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,709][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6423, 0.3577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,710][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8054, 0.1946], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,710][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3691, 0.6309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,710][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2811, 0.7189], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,711][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8408, 0.1592], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,711][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4086, 0.5914], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,711][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3816, 0.6184], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,712][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3904, 0.6096], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,712][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.6044e-04, 9.9974e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,712][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6022, 0.3978], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,713][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1977, 0.8023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:36,713][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.3338, 0.3330, 0.3332], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,713][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.1842, 0.5875, 0.2283], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,714][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.5686, 0.2504, 0.1811], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,714][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.3386, 0.5013, 0.1601], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,714][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.1367, 0.4230, 0.4403], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,715][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([6.9774e-04, 2.0557e-02, 9.7874e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,715][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.2837, 0.3624, 0.3539], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,715][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.1441, 0.4296, 0.4263], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,716][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.3213, 0.5065, 0.1722], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,716][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.0011, 0.9922, 0.0068], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,716][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.3795, 0.2398, 0.3807], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,717][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.0961, 0.5229, 0.3810], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:36,717][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2504, 0.2498, 0.2500, 0.2498], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,717][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0789, 0.1666, 0.6261, 0.1283], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,718][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4162, 0.1568, 0.1627, 0.2643], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,718][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2159, 0.2814, 0.1374, 0.3653], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,718][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1078, 0.2769, 0.3610, 0.2543], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,719][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6511, 0.0012, 0.2285, 0.1191], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,719][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1135, 0.1652, 0.2462, 0.4751], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,721][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1414, 0.2451, 0.3991, 0.2144], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,722][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1240, 0.2368, 0.0457, 0.5935], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,722][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.4382e-05, 9.9789e-01, 1.7327e-03, 3.3008e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,722][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3015, 0.1959, 0.3182, 0.1844], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,725][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0189, 0.0907, 0.0839, 0.8066], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:36,728][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.2003, 0.1998, 0.2000, 0.1998, 0.2001], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,732][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0540, 0.0758, 0.1322, 0.6337, 0.1044], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,736][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.3186, 0.1793, 0.1239, 0.2522, 0.1260], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,739][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.1768, 0.2553, 0.0971, 0.3152, 0.1556], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,743][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0750, 0.2332, 0.2508, 0.2000, 0.2410], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,745][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([6.2496e-05, 8.8423e-04, 8.4747e-01, 6.9155e-04, 1.5089e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,745][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.1235, 0.1662, 0.1503, 0.3630, 0.1970], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,746][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0763, 0.2494, 0.3065, 0.2008, 0.1670], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,746][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1353, 0.2309, 0.0692, 0.5269, 0.0377], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,746][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([2.6013e-04, 9.9058e-01, 3.6894e-03, 9.1085e-04, 4.5620e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,747][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.2379, 0.1510, 0.2363, 0.1379, 0.2369], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,747][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0064, 0.0461, 0.0356, 0.8037, 0.1083], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:36,747][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1669, 0.1665, 0.1666, 0.1665, 0.1667, 0.1668], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,748][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0252, 0.0661, 0.0891, 0.2272, 0.3683, 0.2241], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,749][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2415, 0.1595, 0.1190, 0.1834, 0.1382, 0.1584], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,751][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1315, 0.1961, 0.0879, 0.2342, 0.1475, 0.2028], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,752][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0648, 0.1782, 0.2140, 0.1525, 0.2082, 0.1823], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,752][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0319, 0.0101, 0.2219, 0.0007, 0.3610, 0.3743], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,752][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0535, 0.0918, 0.1527, 0.2711, 0.2498, 0.1810], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,753][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0872, 0.1562, 0.2312, 0.1457, 0.1748, 0.2049], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,753][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1013, 0.2028, 0.0509, 0.3912, 0.0304, 0.2233], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,753][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([3.2139e-05, 9.8804e-01, 3.9844e-03, 8.0503e-05, 3.6039e-03, 4.2545e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,754][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1985, 0.1277, 0.2094, 0.1208, 0.2089, 0.1347], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,754][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0034, 0.0175, 0.0195, 0.1621, 0.0542, 0.7433], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:36,755][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1431, 0.1427, 0.1428, 0.1427, 0.1429, 0.1430, 0.1427],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,758][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0239, 0.0343, 0.0706, 0.1068, 0.1996, 0.4079, 0.1569],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,761][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2473, 0.1186, 0.1064, 0.1645, 0.1145, 0.1075, 0.1412],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,765][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1113, 0.1473, 0.0727, 0.1793, 0.1114, 0.1514, 0.2266],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,768][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0596, 0.1530, 0.1823, 0.1363, 0.1758, 0.1550, 0.1380],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,771][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.1687e-02, 4.3694e-04, 7.1571e-01, 1.7958e-03, 2.4873e-01, 1.2257e-03,
        4.1785e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,775][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0547, 0.0876, 0.1375, 0.2589, 0.2022, 0.1562, 0.1029],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,777][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0746, 0.1087, 0.2155, 0.0994, 0.1478, 0.1542, 0.1997],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,777][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0873, 0.1354, 0.0293, 0.3180, 0.0202, 0.1523, 0.2575],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,777][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.4019e-05, 9.9432e-01, 1.7685e-03, 1.1547e-04, 1.1945e-03, 1.3429e-03,
        1.2181e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,778][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1783, 0.1143, 0.1855, 0.1065, 0.1846, 0.1192, 0.1115],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,778][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0038, 0.0160, 0.0180, 0.1280, 0.0434, 0.4036, 0.3873],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:36,779][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1252, 0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249, 0.1249],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,779][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0073, 0.0130, 0.0291, 0.0595, 0.1405, 0.1820, 0.4867, 0.0819],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,779][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2148, 0.1140, 0.1026, 0.1360, 0.1154, 0.1018, 0.1065, 0.1089],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,780][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0977, 0.1314, 0.0627, 0.1584, 0.1057, 0.1382, 0.1749, 0.1309],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,781][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0465, 0.1391, 0.1555, 0.1185, 0.1520, 0.1372, 0.1180, 0.1334],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,783][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([6.9711e-05, 2.0736e-05, 6.3141e-06, 7.2354e-06, 1.0796e-05, 3.8360e-05,
        8.7273e-06, 9.9984e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,786][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0562, 0.0919, 0.1084, 0.2401, 0.1576, 0.1454, 0.0914, 0.1090],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,790][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0533, 0.0868, 0.1731, 0.0795, 0.1054, 0.1824, 0.2066, 0.1129],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,794][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0571, 0.1261, 0.0355, 0.2881, 0.0249, 0.1293, 0.2471, 0.0918],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,796][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([8.7955e-06, 9.9580e-01, 2.2485e-03, 2.2556e-04, 1.1220e-03, 2.4713e-04,
        3.4207e-04, 3.9043e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,799][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1524, 0.0974, 0.1612, 0.0917, 0.1634, 0.1036, 0.0967, 0.1336],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,803][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0007, 0.0050, 0.0036, 0.0582, 0.0101, 0.2484, 0.2486, 0.4254],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:36,805][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1113, 0.1110, 0.1111, 0.1110, 0.1112, 0.1112, 0.1110, 0.1110, 0.1112],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,806][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0114, 0.0150, 0.0363, 0.0568, 0.0713, 0.2148, 0.2541, 0.2938, 0.0465],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,806][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1814, 0.1043, 0.0856, 0.1261, 0.1010, 0.0929, 0.0963, 0.0887, 0.1238],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,806][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0883, 0.1235, 0.0578, 0.1523, 0.0883, 0.1240, 0.1671, 0.1252, 0.0736],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,807][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0385, 0.1163, 0.1362, 0.0958, 0.1314, 0.1168, 0.0959, 0.1109, 0.1582],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,807][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.9544e-04, 4.3881e-04, 1.0973e-02, 4.5649e-05, 3.5284e-03, 9.7050e-03,
        1.5676e-03, 4.4606e-03, 9.6909e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,808][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0487, 0.0733, 0.0772, 0.1693, 0.1115, 0.1133, 0.0695, 0.0918, 0.2454],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,808][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0407, 0.0742, 0.1735, 0.0588, 0.0959, 0.1542, 0.1148, 0.1456, 0.1422],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,810][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0775, 0.1084, 0.0339, 0.2335, 0.0181, 0.1501, 0.2301, 0.1100, 0.0385],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,811][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.0717e-05, 9.9413e-01, 1.6388e-03, 1.1229e-04, 2.1234e-03, 7.0402e-04,
        1.2611e-03, 9.5694e-06, 1.3467e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,814][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1321, 0.0840, 0.1415, 0.0783, 0.1439, 0.0888, 0.0833, 0.1162, 0.1319],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,818][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0004, 0.0039, 0.0028, 0.0659, 0.0086, 0.2542, 0.2624, 0.3639, 0.0378],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:36,821][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1001, 0.0999, 0.1000, 0.0999, 0.1000, 0.1001, 0.0999, 0.0999, 0.1000,
        0.1002], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,825][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0068, 0.0050, 0.0357, 0.0441, 0.1010, 0.2359, 0.1219, 0.3492, 0.0869,
        0.0137], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,829][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1548, 0.0717, 0.0770, 0.0991, 0.0882, 0.0831, 0.0846, 0.0888, 0.1296,
        0.1230], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,832][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0824, 0.1014, 0.0470, 0.1358, 0.0807, 0.1092, 0.1475, 0.1203, 0.0722,
        0.1035], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,834][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0381, 0.0978, 0.1231, 0.0878, 0.1228, 0.1033, 0.0869, 0.1023, 0.1378,
        0.1001], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,834][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([3.9699e-04, 1.1224e-05, 2.0990e-03, 2.9884e-05, 1.2137e-03, 1.1087e-06,
        9.9024e-07, 1.0514e-03, 9.9520e-01, 5.2511e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,835][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0364, 0.0545, 0.0804, 0.1334, 0.1183, 0.0838, 0.0557, 0.0658, 0.2210,
        0.1507], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,835][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0371, 0.0671, 0.1322, 0.0646, 0.0927, 0.0938, 0.1304, 0.1106, 0.1516,
        0.1199], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,835][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0477, 0.0816, 0.0188, 0.1589, 0.0130, 0.0957, 0.1559, 0.0513, 0.0247,
        0.3523], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,836][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.6224e-05, 9.9504e-01, 3.5503e-04, 1.3127e-04, 3.2578e-04, 2.4181e-04,
        6.2196e-04, 7.2837e-06, 2.7518e-06, 3.2540e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,836][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1198, 0.0772, 0.1299, 0.0725, 0.1308, 0.0814, 0.0764, 0.1061, 0.1207,
        0.0854], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,837][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0016, 0.0075, 0.0078, 0.0649, 0.0194, 0.2140, 0.1977, 0.2349, 0.0467,
        0.2055], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:36,838][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0910, 0.0908, 0.0909, 0.0908, 0.0909, 0.0910, 0.0908, 0.0908, 0.0909,
        0.0910, 0.0910], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,841][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0056, 0.0112, 0.0453, 0.0077, 0.1727, 0.2032, 0.1676, 0.2869, 0.0588,
        0.0270, 0.0140], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,844][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1345, 0.0608, 0.0692, 0.1000, 0.0770, 0.0720, 0.0734, 0.0715, 0.1192,
        0.1059, 0.1165], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,847][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0726, 0.0853, 0.0431, 0.1210, 0.0740, 0.0910, 0.1205, 0.1039, 0.0643,
        0.0888, 0.1353], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,851][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0352, 0.0879, 0.1154, 0.0806, 0.1130, 0.0928, 0.0791, 0.0930, 0.1284,
        0.0910, 0.0836], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,854][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([5.0764e-03, 5.3847e-06, 1.3302e-03, 6.3183e-04, 7.6545e-04, 2.5840e-07,
        7.3595e-07, 1.1907e-03, 9.9060e-01, 1.6230e-07, 3.9832e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,857][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0279, 0.0410, 0.0641, 0.1110, 0.0954, 0.0713, 0.0486, 0.0519, 0.1806,
        0.1263, 0.1819], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,860][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0418, 0.0677, 0.0957, 0.0610, 0.0773, 0.0931, 0.1313, 0.0977, 0.1316,
        0.1304, 0.0724], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,862][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0304, 0.0595, 0.0118, 0.1389, 0.0085, 0.0688, 0.1080, 0.0340, 0.0163,
        0.2889, 0.2349], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,863][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.4510e-05, 9.9419e-01, 1.4751e-03, 2.5973e-04, 8.3881e-04, 3.8185e-04,
        5.0074e-04, 9.2731e-06, 1.3857e-05, 2.2685e-03, 3.5561e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,863][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1117, 0.0715, 0.1191, 0.0667, 0.1199, 0.0748, 0.0703, 0.0974, 0.1108,
        0.0787, 0.0790], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,863][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0019, 0.0070, 0.0090, 0.0487, 0.0212, 0.1494, 0.1311, 0.1422, 0.0417,
        0.1391, 0.3085], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:36,864][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0834, 0.0832, 0.0833, 0.0832, 0.0834, 0.0834, 0.0832, 0.0832, 0.0833,
        0.0834, 0.0834, 0.0834], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,864][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0053, 0.0127, 0.0085, 0.0926, 0.0553, 0.1163, 0.0942, 0.2632, 0.0858,
        0.0462, 0.2133, 0.0067], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,865][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1478, 0.0752, 0.0608, 0.0876, 0.0717, 0.0627, 0.0691, 0.0681, 0.0948,
        0.1015, 0.0940, 0.0668], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,866][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0700, 0.0915, 0.0343, 0.1157, 0.0617, 0.0928, 0.1273, 0.0952, 0.0581,
        0.0989, 0.1288, 0.0256], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,868][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0302, 0.0902, 0.0952, 0.0763, 0.0930, 0.0864, 0.0755, 0.0820, 0.1144,
        0.0907, 0.0796, 0.0864], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,869][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([3.6721e-03, 4.0271e-04, 4.4943e-03, 6.2393e-05, 1.5575e-03, 7.3503e-04,
        6.1953e-05, 3.7563e-01, 4.2801e-01, 4.8194e-05, 5.4257e-05, 1.8527e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,873][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0277, 0.0412, 0.0479, 0.1015, 0.0664, 0.0620, 0.0409, 0.0508, 0.1578,
        0.1219, 0.1676, 0.1145], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,876][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0286, 0.0553, 0.1263, 0.0448, 0.0733, 0.1152, 0.1080, 0.0916, 0.1603,
        0.0937, 0.0476, 0.0553], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,880][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0341, 0.0577, 0.0234, 0.1132, 0.0131, 0.0683, 0.1195, 0.0730, 0.0287,
        0.2271, 0.1917, 0.0502], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,883][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([9.2803e-05, 9.7059e-01, 2.8583e-03, 4.1946e-04, 1.4388e-03, 1.1960e-02,
        3.4265e-03, 3.6454e-05, 3.1916e-05, 8.3527e-03, 7.9506e-05, 7.1112e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,887][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1036, 0.0663, 0.1073, 0.0610, 0.1083, 0.0684, 0.0644, 0.0880, 0.0995,
        0.0721, 0.0721, 0.0890], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,890][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0009, 0.0043, 0.0035, 0.0452, 0.0085, 0.1316, 0.1302, 0.1381, 0.0229,
        0.1344, 0.3624, 0.0180], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:36,892][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0770, 0.0768, 0.0769, 0.0768, 0.0769, 0.0770, 0.0768, 0.0768, 0.0769,
        0.0770, 0.0770, 0.0770, 0.0769], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,892][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0066, 0.0085, 0.0162, 0.0707, 0.0128, 0.1506, 0.2118, 0.1649, 0.0752,
        0.0313, 0.1481, 0.0827, 0.0207], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,893][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.1137, 0.0699, 0.0499, 0.0960, 0.0512, 0.0676, 0.0620, 0.0613, 0.0942,
        0.1033, 0.1059, 0.0701, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,893][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0655, 0.0881, 0.0343, 0.1143, 0.0554, 0.0911, 0.1132, 0.0801, 0.0545,
        0.0934, 0.1283, 0.0264, 0.0553], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,893][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0255, 0.0810, 0.0882, 0.0691, 0.0842, 0.0814, 0.0642, 0.0722, 0.1030,
        0.0791, 0.0711, 0.0785, 0.1025], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,894][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([6.5874e-05, 3.4909e-04, 5.9384e-01, 2.8909e-04, 8.1625e-02, 1.8210e-05,
        6.1846e-04, 1.8225e-03, 2.8227e-01, 5.9228e-05, 1.9297e-04, 5.4124e-03,
        3.3444e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,894][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0265, 0.0389, 0.0423, 0.1010, 0.0583, 0.0602, 0.0395, 0.0411, 0.1342,
        0.1353, 0.1817, 0.1008, 0.0402], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,896][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0224, 0.0774, 0.0903, 0.0639, 0.0477, 0.1076, 0.1077, 0.0747, 0.1414,
        0.1032, 0.0627, 0.0575, 0.0435], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,899][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0317, 0.0524, 0.0166, 0.1116, 0.0087, 0.0740, 0.1135, 0.0676, 0.0210,
        0.2329, 0.2001, 0.0552, 0.0146], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,901][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([1.3836e-04, 9.6853e-01, 2.8993e-03, 7.1642e-04, 4.0529e-03, 3.8167e-03,
        6.5468e-03, 8.4801e-05, 2.4661e-04, 1.0143e-02, 1.4539e-04, 4.4521e-04,
        2.2355e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,905][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0921, 0.0580, 0.0945, 0.0536, 0.0965, 0.0607, 0.0575, 0.0782, 0.0888,
        0.0643, 0.0645, 0.0802, 0.1112], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,909][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0006, 0.0026, 0.0023, 0.0382, 0.0068, 0.1154, 0.1204, 0.1188, 0.0163,
        0.1317, 0.4107, 0.0131, 0.0230], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:36,912][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0715, 0.0714, 0.0714, 0.0713, 0.0714, 0.0715, 0.0713, 0.0713, 0.0714,
        0.0715, 0.0715, 0.0715, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,916][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0086, 0.0207, 0.0088, 0.0453, 0.0682, 0.0747, 0.0843, 0.3407, 0.0275,
        0.0624, 0.0981, 0.0518, 0.1034, 0.0054], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,921][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.1040, 0.0584, 0.0553, 0.0662, 0.0721, 0.0570, 0.0584, 0.0526, 0.0860,
        0.0872, 0.0736, 0.0590, 0.0781, 0.0919], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,921][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0612, 0.0767, 0.0353, 0.0983, 0.0589, 0.0831, 0.1034, 0.0814, 0.0520,
        0.0811, 0.1113, 0.0270, 0.0590, 0.0713], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,922][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0232, 0.0685, 0.0807, 0.0578, 0.0820, 0.0690, 0.0589, 0.0657, 0.0925,
        0.0698, 0.0600, 0.0749, 0.0990, 0.0980], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,922][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([4.1430e-05, 2.4820e-06, 1.9776e-03, 1.8542e-06, 6.9290e-04, 1.9850e-05,
        3.8789e-06, 4.5649e-04, 7.1646e-01, 1.7460e-07, 1.3650e-06, 3.4867e-04,
        2.9941e-04, 2.7970e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,922][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0150, 0.0258, 0.0422, 0.0730, 0.0681, 0.0544, 0.0342, 0.0433, 0.1493,
        0.0967, 0.1341, 0.0965, 0.0466, 0.1208], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,923][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0281, 0.0497, 0.1171, 0.0424, 0.0667, 0.0789, 0.0752, 0.0905, 0.0975,
        0.0771, 0.0454, 0.0576, 0.0611, 0.1127], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,923][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0423, 0.0598, 0.0158, 0.1136, 0.0088, 0.0753, 0.1209, 0.0393, 0.0200,
        0.2348, 0.1816, 0.0408, 0.0136, 0.0334], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,924][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([7.0570e-05, 9.2525e-01, 2.9634e-03, 8.8160e-05, 5.3878e-03, 3.2612e-03,
        1.3905e-03, 3.2851e-05, 1.7493e-04, 2.3914e-03, 1.0497e-05, 2.6810e-04,
        2.1989e-03, 5.6512e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,926][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0834, 0.0539, 0.0894, 0.0508, 0.0903, 0.0566, 0.0534, 0.0735, 0.0828,
        0.0597, 0.0597, 0.0736, 0.1022, 0.0707], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,928][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0005, 0.0028, 0.0028, 0.0282, 0.0077, 0.1155, 0.0956, 0.1275, 0.0221,
        0.1046, 0.2673, 0.0135, 0.0224, 0.1894], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:36,932][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0668, 0.0666, 0.0666, 0.0666, 0.0667, 0.0667, 0.0666, 0.0666, 0.0667,
        0.0668, 0.0668, 0.0667, 0.0667, 0.0667, 0.0666], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,936][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0061, 0.0063, 0.0118, 0.0364, 0.0349, 0.1554, 0.1588, 0.2324, 0.0436,
        0.0197, 0.0841, 0.0513, 0.0556, 0.0316, 0.0720], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,940][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0932, 0.0481, 0.0550, 0.0597, 0.0588, 0.0536, 0.0578, 0.0626, 0.0876,
        0.0787, 0.0675, 0.0693, 0.0642, 0.0808, 0.0631], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,944][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0548, 0.0651, 0.0317, 0.0827, 0.0550, 0.0751, 0.0961, 0.0727, 0.0508,
        0.0711, 0.0930, 0.0235, 0.0551, 0.0627, 0.1105], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,948][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0254, 0.0624, 0.0775, 0.0556, 0.0753, 0.0650, 0.0578, 0.0651, 0.0863,
        0.0650, 0.0579, 0.0715, 0.0899, 0.0862, 0.0591], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,950][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.2073e-06, 1.4124e-08, 4.1016e-05, 3.0441e-07, 1.3195e-04, 2.6918e-08,
        6.3030e-09, 6.1469e-04, 9.9772e-01, 1.8808e-10, 1.5643e-07, 1.3410e-03,
        2.2066e-05, 8.2268e-05, 3.7650e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,951][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0173, 0.0274, 0.0404, 0.0668, 0.0585, 0.0470, 0.0311, 0.0370, 0.1209,
        0.0785, 0.1065, 0.0780, 0.0401, 0.0989, 0.1516], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,951][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0281, 0.0483, 0.0884, 0.0437, 0.0609, 0.0642, 0.0867, 0.0666, 0.1129,
        0.0876, 0.0487, 0.0494, 0.0539, 0.1009, 0.0595], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,952][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0262, 0.0479, 0.0123, 0.0928, 0.0076, 0.0574, 0.0921, 0.0328, 0.0154,
        0.2022, 0.1512, 0.0359, 0.0121, 0.0259, 0.1883], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,952][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.9544e-05, 9.8393e-01, 1.0798e-03, 1.6607e-04, 6.6116e-04, 6.4471e-04,
        1.2955e-03, 2.0507e-05, 6.8409e-06, 3.1982e-03, 2.1623e-05, 3.8021e-04,
        2.8194e-04, 7.8838e-03, 4.0741e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,953][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0797, 0.0508, 0.0838, 0.0475, 0.0846, 0.0533, 0.0502, 0.0695, 0.0785,
        0.0562, 0.0563, 0.0701, 0.0976, 0.0666, 0.0552], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,953][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0013, 0.0043, 0.0051, 0.0285, 0.0117, 0.0898, 0.0786, 0.0937, 0.0251,
        0.0855, 0.1899, 0.0180, 0.0325, 0.1451, 0.1909], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:36,954][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:36,956][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11057],
        [34480],
        [ 3346],
        [38961],
        [23375],
        [35969],
        [46596],
        [45697],
        [46124],
        [39353],
        [42015],
        [36096],
        [37593],
        [35917],
        [44723]], device='cuda:0')
[2024-07-24 10:20:36,957][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 2473],
        [18209],
        [    1],
        [25684],
        [  688],
        [15406],
        [36483],
        [38307],
        [43251],
        [14678],
        [21740],
        [ 7495],
        [ 1230],
        [18729],
        [25668]], device='cuda:0')
[2024-07-24 10:20:36,959][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[27248],
        [27253],
        [24908],
        [31067],
        [23891],
        [32377],
        [26591],
        [26495],
        [25248],
        [25748],
        [27653],
        [28998],
        [28956],
        [34756],
        [25371]], device='cuda:0')
[2024-07-24 10:20:36,960][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[40922],
        [40846],
        [39264],
        [40611],
        [41810],
        [44561],
        [48531],
        [48828],
        [48380],
        [47692],
        [46748],
        [41498],
        [44986],
        [45412],
        [47566]], device='cuda:0')
[2024-07-24 10:20:36,963][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8688],
        [ 8672],
        [ 7658],
        [ 9580],
        [10262],
        [11356],
        [13026],
        [12947],
        [15213],
        [30965],
        [30611],
        [27287],
        [28026],
        [22591],
        [24975]], device='cuda:0')
[2024-07-24 10:20:36,965][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 9034],
        [11006],
        [ 8208],
        [10332],
        [ 8908],
        [ 8532],
        [10028],
        [10024],
        [ 8144],
        [ 8939],
        [ 9654],
        [ 9831],
        [ 9355],
        [ 9501],
        [ 9875]], device='cuda:0')
[2024-07-24 10:20:36,968][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14837],
        [15362],
        [14453],
        [11358],
        [12423],
        [11554],
        [10889],
        [11640],
        [11216],
        [12171],
        [12174],
        [10990],
        [11678],
        [12970],
        [12836]], device='cuda:0')
[2024-07-24 10:20:36,971][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43414],
        [39700],
        [36515],
        [30955],
        [39595],
        [34696],
        [35725],
        [24917],
        [40195],
        [18616],
        [21652],
        [32552],
        [28764],
        [27635],
        [31386]], device='cuda:0')
[2024-07-24 10:20:36,973][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18446],
        [21269],
        [20577],
        [22074],
        [21712],
        [21800],
        [21554],
        [21074],
        [19592],
        [21168],
        [22237],
        [22276],
        [22700],
        [21766],
        [22891]], device='cuda:0')
[2024-07-24 10:20:36,976][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38470],
        [38401],
        [10751],
        [11871],
        [ 7329],
        [ 1317],
        [ 1575],
        [17387],
        [  923],
        [  934],
        [ 7122],
        [ 7338],
        [14850],
        [  486],
        [ 8579]], device='cuda:0')
[2024-07-24 10:20:36,978][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3146],
        [ 6857],
        [13189],
        [27517],
        [30498],
        [35160],
        [31830],
        [31543],
        [33593],
        [34386],
        [34157],
        [32505],
        [31811],
        [32848],
        [33426]], device='cuda:0')
[2024-07-24 10:20:36,981][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[33043],
        [33841],
        [35092],
        [26018],
        [27706],
        [27784],
        [26186],
        [27567],
        [28161],
        [27759],
        [27668],
        [28108],
        [28198],
        [27190],
        [27013]], device='cuda:0')
[2024-07-24 10:20:36,984][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3077],
        [2989],
        [2770],
        [2331],
        [2685],
        [2865],
        [2855],
        [2736],
        [2653],
        [2611],
        [2477],
        [2456],
        [2616],
        [2671],
        [2701]], device='cuda:0')
[2024-07-24 10:20:36,986][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30576],
        [39489],
        [35699],
        [40851],
        [41219],
        [46455],
        [46036],
        [47653],
        [47539],
        [46797],
        [46263],
        [47540],
        [47979],
        [47470],
        [46721]], device='cuda:0')
[2024-07-24 10:20:36,987][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6906],
        [ 3899],
        [10422],
        [ 6989],
        [13706],
        [ 4387],
        [ 5368],
        [ 1668],
        [ 1220],
        [ 6504],
        [10221],
        [12315],
        [20905],
        [ 5664],
        [11339]], device='cuda:0')
[2024-07-24 10:20:36,988][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22338],
        [22340],
        [22327],
        [22357],
        [22368],
        [22378],
        [22356],
        [22361],
        [22359],
        [22353],
        [22355],
        [22362],
        [22363],
        [22369],
        [22369]], device='cuda:0')
[2024-07-24 10:20:36,989][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[17040],
        [16649],
        [16797],
        [34149],
        [ 8769],
        [22871],
        [35686],
        [38524],
        [40645],
        [41805],
        [41963],
        [21093],
        [28098],
        [31343],
        [33362]], device='cuda:0')
[2024-07-24 10:20:36,990][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[45661],
        [44651],
        [42162],
        [39889],
        [39318],
        [37597],
        [37491],
        [37261],
        [36716],
        [35946],
        [35458],
        [35864],
        [35429],
        [35279],
        [35255]], device='cuda:0')
[2024-07-24 10:20:36,992][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21525],
        [21842],
        [20329],
        [28072],
        [27941],
        [26076],
        [27239],
        [26167],
        [25114],
        [25735],
        [27795],
        [27238],
        [27144],
        [25979],
        [27681]], device='cuda:0')
[2024-07-24 10:20:36,994][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[38336],
        [35701],
        [38276],
        [38229],
        [37579],
        [38793],
        [38929],
        [38763],
        [38928],
        [38655],
        [38503],
        [38298],
        [38119],
        [38421],
        [38481]], device='cuda:0')
[2024-07-24 10:20:36,995][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9528],
        [ 7530],
        [35595],
        [ 7886],
        [38762],
        [40000],
        [40046],
        [25425],
        [38353],
        [38585],
        [38605],
        [33769],
        [38522],
        [39726],
        [38616]], device='cuda:0')
[2024-07-24 10:20:36,997][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[36893],
        [39155],
        [31656],
        [32195],
        [29381],
        [26271],
        [27319],
        [28017],
        [23240],
        [22484],
        [22938],
        [23640],
        [23512],
        [22442],
        [22578]], device='cuda:0')
[2024-07-24 10:20:37,000][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[15652],
        [10208],
        [33133],
        [27330],
        [29643],
        [29420],
        [30169],
        [25738],
        [26039],
        [21565],
        [17127],
        [20421],
        [18227],
        [22442],
        [19284]], device='cuda:0')
[2024-07-24 10:20:37,003][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13998],
        [10998],
        [ 9934],
        [12215],
        [11482],
        [11480],
        [12407],
        [11712],
        [11169],
        [12715],
        [13549],
        [12331],
        [12423],
        [12410],
        [12610]], device='cuda:0')
[2024-07-24 10:20:37,005][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9722],
        [35772],
        [35757],
        [35766],
        [35782],
        [35774],
        [35782],
        [35776],
        [35788],
        [35791],
        [35787],
        [35793],
        [35842],
        [36145],
        [35838]], device='cuda:0')
[2024-07-24 10:20:37,008][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18186],
        [19141],
        [20510],
        [20716],
        [21263],
        [21477],
        [21376],
        [21613],
        [21860],
        [21844],
        [21840],
        [21989],
        [22366],
        [22317],
        [22275]], device='cuda:0')
[2024-07-24 10:20:37,010][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25220],
        [41140],
        [39109],
        [48214],
        [48291],
        [49171],
        [49567],
        [49931],
        [49897],
        [49838],
        [49933],
        [49989],
        [49982],
        [49956],
        [49958]], device='cuda:0')
[2024-07-24 10:20:37,013][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11688],
        [ 9121],
        [ 4967],
        [ 5282],
        [ 6100],
        [ 4712],
        [ 3484],
        [ 4555],
        [ 3464],
        [ 3666],
        [ 3568],
        [ 6036],
        [ 4318],
        [ 4004],
        [ 3952]], device='cuda:0')
[2024-07-24 10:20:37,015][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37689],
        [39552],
        [31309],
        [31089],
        [18497],
        [33567],
        [30400],
        [35792],
        [40020],
        [35733],
        [26530],
        [22389],
        [13936],
        [32525],
        [25595]], device='cuda:0')
[2024-07-24 10:20:37,018][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857],
        [23857]], device='cuda:0')
[2024-07-24 10:20:37,048][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:37,052][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,055][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,057][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,061][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,064][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,064][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,064][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,065][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,065][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,065][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,065][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,066][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,066][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5384, 0.4616], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,066][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9947, 0.0053], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,067][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,069][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9813, 0.0187], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,072][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4604, 0.5396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,076][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8933, 0.1067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,080][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6854, 0.3146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,084][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3785, 0.6215], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,087][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4563, 0.5437], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,091][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2101, 0.7899], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,093][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2425, 0.7575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,093][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6162, 0.3838], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,094][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.3116, 0.4390, 0.2494], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,094][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.7787, 0.0907, 0.1305], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,094][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([6.3813e-06, 7.6263e-02, 9.2373e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,095][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.1014, 0.0722, 0.8264], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,095][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.0795, 0.6383, 0.2823], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,095][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.0031, 0.9563, 0.0406], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,096][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.4680, 0.2535, 0.2785], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,096][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.3026, 0.4637, 0.2337], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,098][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.2353, 0.5728, 0.1919], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,100][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.0576, 0.2734, 0.6690], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,105][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.0857, 0.4359, 0.4784], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,109][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.4876, 0.2021, 0.3103], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,112][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2190, 0.2836, 0.3103, 0.1870], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,116][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8404, 0.0281, 0.0797, 0.0518], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,118][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([6.3549e-07, 4.9635e-03, 5.4858e-01, 4.4645e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,123][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0496, 0.0079, 0.9311, 0.0113], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,123][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0909, 0.4800, 0.1530, 0.2761], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,123][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3291, 0.0898, 0.1828, 0.3983], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,124][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3830, 0.2008, 0.2249, 0.1913], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,124][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1820, 0.2868, 0.1714, 0.3597], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,124][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1317, 0.2928, 0.2776, 0.2979], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,125][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0331, 0.1682, 0.6384, 0.1603], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,125][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0475, 0.2541, 0.2979, 0.4005], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,125][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2662, 0.2583, 0.2051, 0.2704], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,126][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1128, 0.2158, 0.2280, 0.2509, 0.1924], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,127][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.5664, 0.1095, 0.2001, 0.0853, 0.0387], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,129][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([1.6378e-07, 1.3647e-03, 9.1003e-02, 4.5290e-01, 4.5473e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,132][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0139, 0.0041, 0.8039, 0.0457, 0.1324], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,136][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0870, 0.2711, 0.1933, 0.4243, 0.0242], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,141][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0012, 0.3400, 0.0269, 0.6045, 0.0273], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,144][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.2916, 0.1661, 0.1761, 0.1661, 0.2002], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,148][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1542, 0.2452, 0.1217, 0.3416, 0.1372], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,152][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.1140, 0.2332, 0.1747, 0.4001, 0.0779], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,153][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0242, 0.1237, 0.3670, 0.1272, 0.3579], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,153][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0278, 0.1474, 0.1826, 0.3369, 0.3053], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,153][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.2440, 0.1657, 0.1654, 0.2547, 0.1703], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,154][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1074, 0.1876, 0.1402, 0.1516, 0.3477, 0.0655], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,154][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.6829, 0.0404, 0.1058, 0.0620, 0.0303, 0.0786], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,154][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([1.4205e-08, 1.4010e-04, 1.3685e-02, 9.9644e-02, 7.1506e-01, 1.7147e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,155][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0289, 0.0018, 0.2692, 0.0220, 0.6767, 0.0014], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,155][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1671, 0.2339, 0.0429, 0.3872, 0.0255, 0.1434], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,155][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0231, 0.0983, 0.0384, 0.4750, 0.0893, 0.2758], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,157][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2043, 0.1588, 0.1509, 0.1480, 0.1392, 0.1988], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,160][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1256, 0.2303, 0.1023, 0.2742, 0.1185, 0.1490], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,164][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1008, 0.2289, 0.1081, 0.1985, 0.1509, 0.2128], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,168][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0148, 0.0868, 0.2614, 0.0850, 0.4027, 0.1493], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,171][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0194, 0.1117, 0.1332, 0.2218, 0.2216, 0.2922], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,175][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1857, 0.1706, 0.2080, 0.1376, 0.2067, 0.0914], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,179][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1148, 0.1409, 0.1466, 0.1671, 0.2621, 0.0901, 0.0784],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,182][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6659, 0.0354, 0.0798, 0.0582, 0.0264, 0.0577, 0.0766],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,182][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.1822e-08, 2.9597e-05, 1.8380e-03, 3.3037e-02, 8.3414e-02, 6.5222e-01,
        2.2946e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,183][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0063, 0.0014, 0.2292, 0.0289, 0.7239, 0.0050, 0.0053],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,183][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1312, 0.1976, 0.0495, 0.3505, 0.0256, 0.1574, 0.0881],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,183][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1514, 0.0195, 0.0690, 0.1302, 0.1710, 0.2451, 0.2137],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,184][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2416, 0.1283, 0.1271, 0.1150, 0.1245, 0.1595, 0.1040],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,184][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1014, 0.1802, 0.0955, 0.2376, 0.1035, 0.1181, 0.1637],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,185][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0429, 0.0956, 0.1086, 0.1698, 0.1145, 0.3991, 0.0696],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,185][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0112, 0.0663, 0.2129, 0.0611, 0.3443, 0.1280, 0.1762],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,185][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0182, 0.0864, 0.1045, 0.1684, 0.1504, 0.1872, 0.2849],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,187][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1780, 0.1439, 0.1234, 0.2153, 0.1164, 0.1354, 0.0876],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,189][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0932, 0.1261, 0.1403, 0.1171, 0.2607, 0.0620, 0.0904, 0.1102],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,193][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.6856, 0.0295, 0.0715, 0.0556, 0.0106, 0.0614, 0.0701, 0.0156],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,196][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([9.6988e-10, 8.8071e-07, 2.3045e-04, 5.0607e-04, 2.2770e-02, 3.3647e-02,
        1.4091e-01, 8.0194e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,199][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0075, 0.0011, 0.3381, 0.0173, 0.5136, 0.0295, 0.0490, 0.0439],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,203][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0894, 0.1624, 0.0680, 0.2579, 0.0100, 0.1344, 0.1967, 0.0813],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,207][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0029, 0.0573, 0.0266, 0.2240, 0.0531, 0.1422, 0.4176, 0.0763],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,210][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2684, 0.1176, 0.1093, 0.0982, 0.1124, 0.1392, 0.0845, 0.0704],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,212][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0947, 0.1793, 0.0818, 0.2212, 0.0892, 0.1014, 0.1333, 0.0991],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,212][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0352, 0.0980, 0.0658, 0.1194, 0.1171, 0.3669, 0.1203, 0.0773],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,213][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0112, 0.0590, 0.1645, 0.0552, 0.2345, 0.1131, 0.1665, 0.1960],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,213][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0088, 0.0531, 0.0588, 0.1074, 0.0901, 0.1154, 0.1736, 0.3929],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,214][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1657, 0.1527, 0.1091, 0.1683, 0.1268, 0.1221, 0.0805, 0.0747],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,214][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0797, 0.1216, 0.1164, 0.0988, 0.2204, 0.0785, 0.0620, 0.1647, 0.0580],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,214][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.4198, 0.0370, 0.0998, 0.0431, 0.0247, 0.1426, 0.0882, 0.0203, 0.1244],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,215][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([1.0307e-10, 1.3917e-07, 2.0239e-05, 8.0950e-05, 2.2264e-03, 2.2521e-03,
        1.3276e-02, 5.4710e-01, 4.3505e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,217][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0041, 0.0008, 0.2684, 0.0134, 0.2063, 0.0571, 0.0200, 0.4050, 0.0248],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,219][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0385, 0.1400, 0.0511, 0.2148, 0.0391, 0.1903, 0.1563, 0.1239, 0.0460],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,223][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0058, 0.0612, 0.0437, 0.1779, 0.1050, 0.0929, 0.2520, 0.1109, 0.1507],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,227][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.2639, 0.0977, 0.1075, 0.0900, 0.1170, 0.1198, 0.0761, 0.0709, 0.0572],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,231][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0966, 0.1506, 0.0725, 0.1885, 0.0810, 0.0965, 0.1245, 0.0915, 0.0983],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,235][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0351, 0.0791, 0.1095, 0.1093, 0.0516, 0.3452, 0.1279, 0.0922, 0.0502],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,239][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0088, 0.0490, 0.1403, 0.0493, 0.1870, 0.0985, 0.1474, 0.1845, 0.1352],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,241][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0080, 0.0394, 0.0368, 0.0909, 0.0573, 0.0832, 0.1554, 0.2533, 0.2758],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,242][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1430, 0.0982, 0.1106, 0.1224, 0.0972, 0.1049, 0.0875, 0.1321, 0.1040],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,242][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0888, 0.0834, 0.1022, 0.0904, 0.1528, 0.0722, 0.0687, 0.1448, 0.0908,
        0.1061], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,243][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5496, 0.0239, 0.0644, 0.0411, 0.0171, 0.0474, 0.0882, 0.0225, 0.0816,
        0.0641], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,243][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.3708e-11, 4.6804e-09, 4.4550e-06, 3.2516e-05, 2.5894e-04, 5.4393e-04,
        2.2514e-03, 1.1396e-01, 1.9556e-01, 6.8739e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,243][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([4.5093e-03, 5.5580e-05, 4.3767e-02, 3.6452e-03, 5.4218e-02, 3.5318e-02,
        3.4831e-02, 6.8940e-01, 1.3366e-01, 5.9405e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,244][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0768, 0.0906, 0.1323, 0.1472, 0.0309, 0.0688, 0.2037, 0.0801, 0.0594,
        0.1103], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,244][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3995, 0.0006, 0.0294, 0.0044, 0.0456, 0.0180, 0.0170, 0.0455, 0.2186,
        0.2212], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,246][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2599, 0.0912, 0.1112, 0.0833, 0.1165, 0.1160, 0.0711, 0.0622, 0.0494,
        0.0394], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,249][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0704, 0.1187, 0.0655, 0.1555, 0.0688, 0.0803, 0.1080, 0.0747, 0.0898,
        0.1683], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,253][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0402, 0.0536, 0.0645, 0.0990, 0.0620, 0.2785, 0.1119, 0.1085, 0.1132,
        0.0687], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,257][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0040, 0.0223, 0.1110, 0.0299, 0.2137, 0.0760, 0.1059, 0.1532, 0.1587,
        0.1252], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,260][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0069, 0.0322, 0.0342, 0.0610, 0.0483, 0.0645, 0.0852, 0.1631, 0.1705,
        0.3340], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,264][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1282, 0.0876, 0.0729, 0.1601, 0.0893, 0.0845, 0.0665, 0.0774, 0.0960,
        0.1374], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,268][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0693, 0.0952, 0.0940, 0.0532, 0.1711, 0.0520, 0.0608, 0.1321, 0.0788,
        0.1220, 0.0716], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,271][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5944, 0.0162, 0.0506, 0.0291, 0.0131, 0.0361, 0.0791, 0.0135, 0.0736,
        0.0545, 0.0399], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,271][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.1875e-11, 1.0524e-09, 3.3946e-07, 1.2240e-07, 1.3874e-05, 1.2898e-05,
        9.2454e-05, 2.5976e-03, 7.1102e-03, 1.5957e-01, 8.3060e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,272][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.8415e-03, 3.4063e-04, 5.2858e-02, 4.3121e-04, 2.1228e-01, 9.4737e-03,
        4.9938e-02, 4.5381e-01, 2.1155e-01, 4.7830e-03, 1.6993e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,272][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0241, 0.1889, 0.0562, 0.0930, 0.0430, 0.0468, 0.1657, 0.0313, 0.0171,
        0.2738, 0.0599], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,272][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0375, 0.0010, 0.0124, 0.0035, 0.0197, 0.0092, 0.0124, 0.0148, 0.1069,
        0.2974, 0.4854], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,273][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1786, 0.0958, 0.1074, 0.0891, 0.1003, 0.1179, 0.0848, 0.0653, 0.0530,
        0.0501, 0.0577], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,273][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0640, 0.0977, 0.0591, 0.1271, 0.0613, 0.0684, 0.0901, 0.0589, 0.0796,
        0.1421, 0.1517], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,274][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0298, 0.0655, 0.0679, 0.0644, 0.0552, 0.2560, 0.1142, 0.1085, 0.0891,
        0.0979, 0.0515], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,275][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0039, 0.0252, 0.1159, 0.0216, 0.1905, 0.0625, 0.0941, 0.1464, 0.1417,
        0.1449, 0.0533], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,278][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0045, 0.0252, 0.0275, 0.0394, 0.0374, 0.0454, 0.0602, 0.1029, 0.1220,
        0.2471, 0.2883], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,282][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0994, 0.0991, 0.0748, 0.0982, 0.0896, 0.0909, 0.0641, 0.0529, 0.0896,
        0.1450, 0.0965], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,285][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0470, 0.0888, 0.0795, 0.0843, 0.1153, 0.0386, 0.0370, 0.0804, 0.0662,
        0.1328, 0.1200, 0.1100], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,289][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.3423, 0.0355, 0.0614, 0.0668, 0.0133, 0.0920, 0.0793, 0.0161, 0.0447,
        0.0836, 0.0828, 0.0822], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,291][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([9.0424e-12, 2.5602e-10, 1.8664e-08, 1.6573e-07, 1.1920e-06, 1.8828e-06,
        1.8766e-05, 1.2543e-04, 1.0074e-03, 2.2968e-02, 7.8666e-01, 1.8921e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,295][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0017, 0.0006, 0.3849, 0.0054, 0.1767, 0.0098, 0.0553, 0.0825, 0.2243,
        0.0069, 0.0199, 0.0321], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,298][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0237, 0.1060, 0.0103, 0.1077, 0.0061, 0.0840, 0.0323, 0.3746, 0.0113,
        0.1298, 0.0853, 0.0289], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,300][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([2.9225e-04, 1.1678e-02, 5.2244e-03, 2.0138e-02, 6.2768e-03, 9.7446e-03,
        3.3796e-02, 6.0256e-03, 1.9066e-02, 3.8330e-01, 4.8516e-01, 1.9298e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,300][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1724, 0.0787, 0.0920, 0.0770, 0.1027, 0.0996, 0.0705, 0.0672, 0.0598,
        0.0486, 0.0538, 0.0777], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,301][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0624, 0.0969, 0.0449, 0.1214, 0.0524, 0.0657, 0.0770, 0.0569, 0.0653,
        0.1490, 0.1406, 0.0675], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,301][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0263, 0.0645, 0.0253, 0.0955, 0.0269, 0.2987, 0.0679, 0.0915, 0.0891,
        0.0899, 0.0863, 0.0380], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,302][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0083, 0.0307, 0.0719, 0.0301, 0.0978, 0.0639, 0.0942, 0.1046, 0.0873,
        0.1363, 0.0653, 0.2098], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,302][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0026, 0.0169, 0.0160, 0.0276, 0.0272, 0.0340, 0.0457, 0.0816, 0.1020,
        0.2265, 0.2377, 0.1821], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,302][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0890, 0.0764, 0.0995, 0.0643, 0.0854, 0.0734, 0.0426, 0.0709, 0.0960,
        0.1043, 0.0636, 0.1347], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,303][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0352, 0.0682, 0.0710, 0.0739, 0.0544, 0.0446, 0.0428, 0.1127, 0.0777,
        0.0953, 0.1006, 0.1522, 0.0714], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,305][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.2899, 0.0396, 0.0812, 0.0322, 0.0149, 0.1024, 0.0606, 0.0106, 0.0750,
        0.0855, 0.0379, 0.1537, 0.0166], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,307][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([3.3963e-12, 1.2572e-10, 1.6154e-08, 3.6766e-08, 6.3072e-08, 2.0203e-06,
        3.6305e-06, 1.3079e-04, 4.4220e-04, 5.3607e-03, 1.3907e-01, 4.4145e-01,
        4.1354e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,308][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([8.2153e-04, 1.7619e-04, 4.5822e-02, 2.2456e-03, 8.2586e-03, 8.2251e-03,
        1.9674e-02, 2.4216e-01, 1.3593e-01, 1.1289e-03, 7.4043e-03, 4.9950e-01,
        2.8650e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,312][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0299, 0.1007, 0.0644, 0.1530, 0.0074, 0.0688, 0.1159, 0.0332, 0.0701,
        0.1436, 0.1170, 0.0912, 0.0047], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,316][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0006, 0.0124, 0.0044, 0.0222, 0.0039, 0.0076, 0.0339, 0.0070, 0.0234,
        0.3058, 0.4668, 0.0589, 0.0531], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,320][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1224, 0.0761, 0.0792, 0.0817, 0.0842, 0.0946, 0.0732, 0.0710, 0.0627,
        0.0521, 0.0573, 0.0775, 0.0679], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,323][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0533, 0.0790, 0.0408, 0.1170, 0.0448, 0.0672, 0.0770, 0.0505, 0.0647,
        0.1386, 0.1411, 0.0721, 0.0538], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,327][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0272, 0.0518, 0.0377, 0.0915, 0.0151, 0.2503, 0.0979, 0.0983, 0.0846,
        0.0813, 0.0779, 0.0739, 0.0123], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,329][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0054, 0.0212, 0.0522, 0.0193, 0.0474, 0.0383, 0.0629, 0.0779, 0.0574,
        0.1091, 0.0543, 0.2080, 0.2466], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,329][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0017, 0.0108, 0.0128, 0.0238, 0.0203, 0.0292, 0.0382, 0.0615, 0.0750,
        0.1465, 0.2160, 0.1740, 0.1903], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,330][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0855, 0.0578, 0.0553, 0.0895, 0.0562, 0.0745, 0.0600, 0.0712, 0.0851,
        0.0847, 0.0898, 0.1298, 0.0607], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,330][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0447, 0.0570, 0.0477, 0.0489, 0.0957, 0.0425, 0.0307, 0.0771, 0.0684,
        0.0714, 0.0699, 0.1382, 0.1369, 0.0710], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,331][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.2237, 0.0279, 0.0600, 0.0448, 0.0198, 0.0464, 0.0593, 0.0215, 0.0740,
        0.0645, 0.0601, 0.1394, 0.0186, 0.1400], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,331][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([5.7354e-13, 1.3835e-11, 1.3398e-09, 6.3050e-09, 5.1297e-08, 2.1251e-07,
        3.8799e-07, 4.3247e-06, 3.5984e-05, 1.6386e-03, 4.8378e-02, 1.2916e-01,
        6.3982e-01, 1.8096e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,332][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([4.2980e-03, 2.9136e-04, 2.3458e-02, 7.8594e-03, 5.3549e-02, 5.6759e-04,
        2.6384e-03, 1.3506e-01, 1.1629e-01, 6.0752e-03, 5.4690e-02, 3.2047e-01,
        2.7425e-01, 5.0607e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,332][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1170, 0.1093, 0.0182, 0.1250, 0.0110, 0.0808, 0.0666, 0.1102, 0.0124,
        0.1254, 0.0949, 0.1064, 0.0071, 0.0156], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,334][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0021, 0.0015, 0.0032, 0.0041, 0.0051, 0.0038, 0.0062, 0.0042, 0.0090,
        0.2829, 0.3592, 0.0428, 0.1011, 0.1748], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,336][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1277, 0.0743, 0.0823, 0.0709, 0.0829, 0.0916, 0.0709, 0.0540, 0.0480,
        0.0453, 0.0514, 0.0589, 0.0744, 0.0676], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,340][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0519, 0.0787, 0.0417, 0.1019, 0.0470, 0.0578, 0.0723, 0.0509, 0.0623,
        0.1226, 0.1226, 0.0746, 0.0546, 0.0610], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,344][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0316, 0.0868, 0.0515, 0.0798, 0.0472, 0.1144, 0.0532, 0.0884, 0.0681,
        0.1005, 0.0681, 0.0896, 0.0440, 0.0768], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,347][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0024, 0.0131, 0.0420, 0.0107, 0.0568, 0.0228, 0.0351, 0.0497, 0.0454,
        0.0728, 0.0260, 0.1879, 0.3569, 0.0784], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,351][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0017, 0.0110, 0.0114, 0.0208, 0.0167, 0.0221, 0.0328, 0.0499, 0.0548,
        0.1337, 0.1628, 0.1187, 0.1453, 0.2182], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,355][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0672, 0.0536, 0.0919, 0.0461, 0.0743, 0.0505, 0.0434, 0.0791, 0.0756,
        0.0831, 0.0508, 0.1593, 0.0812, 0.0440], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,358][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0459, 0.0498, 0.0442, 0.0487, 0.0720, 0.0353, 0.0301, 0.0727, 0.0521,
        0.0673, 0.0727, 0.1496, 0.1015, 0.0813, 0.0769], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,358][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5294, 0.0157, 0.0405, 0.0279, 0.0110, 0.0241, 0.0531, 0.0090, 0.0518,
        0.0435, 0.0334, 0.0612, 0.0103, 0.0604, 0.0288], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,359][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.6120e-13, 1.1463e-12, 9.2223e-11, 4.1287e-10, 4.9843e-09, 1.6329e-08,
        4.4820e-08, 1.0849e-06, 6.2872e-06, 8.2672e-05, 2.6609e-03, 5.8236e-03,
        5.4586e-02, 2.0349e-01, 7.3335e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,359][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.5798e-03, 1.9053e-04, 3.7753e-02, 2.8939e-03, 2.3503e-02, 1.5309e-03,
        1.9215e-02, 1.4756e-01, 8.3912e-02, 2.3565e-03, 1.5706e-02, 3.0096e-01,
        1.3099e-01, 2.2957e-01, 2.2845e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,360][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0386, 0.0637, 0.0358, 0.1061, 0.0248, 0.0980, 0.0605, 0.0976, 0.1206,
        0.0992, 0.0831, 0.0477, 0.0174, 0.0701, 0.0368], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,360][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.9268e-03, 5.1350e-05, 1.0144e-03, 1.5968e-04, 1.1480e-03, 3.7906e-04,
        4.2385e-04, 6.8223e-04, 5.5418e-03, 2.1467e-02, 4.4913e-02, 1.9442e-02,
        2.6593e-02, 2.2735e-01, 6.4391e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,361][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1340, 0.0699, 0.0800, 0.0658, 0.0783, 0.0841, 0.0612, 0.0507, 0.0434,
        0.0395, 0.0443, 0.0563, 0.0645, 0.0645, 0.0636], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,362][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0443, 0.0725, 0.0394, 0.0927, 0.0400, 0.0488, 0.0631, 0.0427, 0.0531,
        0.1109, 0.1128, 0.0678, 0.0475, 0.0610, 0.1034], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,365][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0147, 0.0410, 0.0477, 0.0669, 0.0441, 0.1791, 0.0491, 0.0444, 0.0553,
        0.0565, 0.0579, 0.0576, 0.0383, 0.2277, 0.0196], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,369][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0013, 0.0071, 0.0292, 0.0062, 0.0485, 0.0179, 0.0261, 0.0382, 0.0349,
        0.0513, 0.0195, 0.1520, 0.3792, 0.0978, 0.0908], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,372][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0017, 0.0079, 0.0084, 0.0136, 0.0117, 0.0162, 0.0201, 0.0358, 0.0400,
        0.0805, 0.1016, 0.0915, 0.0951, 0.1686, 0.3073], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,376][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0597, 0.0701, 0.0396, 0.0995, 0.0478, 0.0624, 0.0422, 0.0421, 0.0492,
        0.1145, 0.1035, 0.0825, 0.0507, 0.0672, 0.0690], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,417][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:37,417][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,417][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,418][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,418][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,418][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,419][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,421][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,424][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,427][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,430][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,433][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,434][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,435][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4549, 0.5451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,435][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2847, 0.7153], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,435][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,436][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3802, 0.6198], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,436][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,436][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,437][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,437][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3195, 0.6805], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,438][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,440][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,442][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9940, 0.0060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,446][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,450][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.1366, 0.5204, 0.3430], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,453][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.0054, 0.3924, 0.6023], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,455][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([6.3813e-06, 7.6263e-02, 9.2373e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,459][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.2012, 0.3104, 0.4884], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,461][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([2.0973e-04, 5.0300e-02, 9.4949e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,464][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([0.0010, 0.4665, 0.5325], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,464][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.0783, 0.1286, 0.7931], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,464][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.2004, 0.4607, 0.3389], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,465][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.0047, 0.2741, 0.7213], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,465][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([1.6574e-04, 4.6764e-01, 5.3220e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,465][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.0078, 0.0524, 0.9398], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,466][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.0310, 0.5785, 0.3905], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,466][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0416, 0.1379, 0.2888, 0.5317], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,466][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0257, 0.0363, 0.9358, 0.0022], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,467][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([6.3549e-07, 4.9635e-03, 5.4858e-01, 4.4645e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,468][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1129, 0.2253, 0.4725, 0.1894], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,471][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0010, 0.0672, 0.5572, 0.3746], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,473][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.4481e-04, 6.1114e-02, 2.9146e-01, 6.4708e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,477][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0607, 0.0720, 0.4189, 0.4484], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,481][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1570, 0.3259, 0.2785, 0.2386], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,485][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0020, 0.0978, 0.3637, 0.5365], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,487][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.9384e-05, 3.1421e-02, 3.6971e-01, 5.9885e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,491][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7598, 0.0027, 0.1374, 0.1001], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,493][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0210, 0.4339, 0.2633, 0.2819], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,493][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0157, 0.0683, 0.1630, 0.5208, 0.2322], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,494][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0019, 0.5093, 0.2862, 0.0139, 0.1887], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,494][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([1.6378e-07, 1.3647e-03, 9.1003e-02, 4.5290e-01, 4.5473e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,494][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0683, 0.1196, 0.2144, 0.1092, 0.4885], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,495][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([3.1737e-05, 6.0111e-03, 3.7287e-01, 1.1613e-01, 5.0496e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,495][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([4.0124e-05, 1.2004e-02, 4.4356e-02, 5.2108e-01, 4.2252e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,496][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0296, 0.0612, 0.1877, 0.3384, 0.3831], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,496][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1256, 0.2791, 0.2088, 0.2169, 0.1696], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,496][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([3.0634e-04, 1.7500e-02, 1.5472e-01, 3.9079e-01, 4.3668e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,497][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([5.4681e-06, 1.3495e-02, 6.1209e-02, 4.9647e-01, 4.2882e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,498][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([1.9109e-06, 1.6358e-04, 2.6598e-03, 8.2385e-03, 9.8894e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,502][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0127, 0.2369, 0.1500, 0.2391, 0.3613], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,505][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0088, 0.0494, 0.0667, 0.3571, 0.1664, 0.3516], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,509][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0173, 0.0263, 0.2088, 0.0147, 0.2776, 0.4552], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,511][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.4205e-08, 1.4010e-04, 1.3685e-02, 9.9644e-02, 7.1506e-01, 1.7147e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,515][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0433, 0.0837, 0.1804, 0.0767, 0.3810, 0.2349], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,518][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([4.7228e-05, 1.3518e-02, 1.9997e-02, 2.5353e-01, 1.6535e-01, 5.4755e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,520][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([2.1099e-05, 5.6249e-03, 2.1067e-02, 1.7505e-01, 5.1370e-01, 2.8454e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,523][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0223, 0.0479, 0.1527, 0.2499, 0.2899, 0.2373], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,525][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0983, 0.2267, 0.1727, 0.1664, 0.1396, 0.1964], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,525][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([1.2495e-04, 1.3999e-02, 2.7210e-02, 1.7380e-01, 4.2113e-01, 3.6374e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,526][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.2435e-06, 4.0709e-03, 2.0040e-02, 1.6637e-01, 4.2469e-01, 3.8483e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,526][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.5688e-04, 3.2073e-05, 1.8767e-03, 2.2180e-03, 3.5595e-01, 6.3976e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,526][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0113, 0.2285, 0.1247, 0.1420, 0.2770, 0.2165], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,527][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0098, 0.0378, 0.0845, 0.1946, 0.1652, 0.2630, 0.2451],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,527][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0061, 0.0036, 0.0793, 0.0063, 0.1741, 0.7298, 0.0007],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,528][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.1822e-08, 2.9597e-05, 1.8380e-03, 3.3037e-02, 8.3414e-02, 6.5222e-01,
        2.2946e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,528][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0403, 0.0726, 0.1453, 0.0691, 0.3100, 0.2127, 0.1500],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,528][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([5.0084e-05, 5.2280e-03, 1.3941e-02, 8.4441e-02, 8.2870e-02, 5.0497e-01,
        3.0850e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,529][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.1287e-05, 2.4085e-03, 1.3807e-02, 7.9591e-02, 2.2411e-01, 3.4351e-01,
        3.3655e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,532][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0153, 0.0236, 0.1072, 0.1426, 0.2166, 0.1541, 0.3406],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,535][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0885, 0.1877, 0.1551, 0.1409, 0.1213, 0.1603, 0.1461],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,537][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([6.0565e-05, 2.9642e-03, 1.9293e-02, 6.4142e-02, 1.3925e-01, 6.2971e-01,
        1.4458e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,540][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.2767e-06, 1.5875e-03, 1.5355e-02, 5.1052e-02, 2.1794e-01, 3.6793e-01,
        3.4613e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,542][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.7042e-02, 5.4599e-05, 3.8483e-03, 3.8034e-03, 2.7834e-01, 4.9334e-01,
        1.7357e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,546][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0113, 0.1637, 0.0951, 0.1225, 0.2161, 0.1663, 0.2250],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,550][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0055, 0.0213, 0.0473, 0.1013, 0.1203, 0.1007, 0.2203, 0.3833],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,553][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.2134, 0.1916, 0.1444, 0.1654, 0.0517, 0.0888, 0.0554, 0.0892],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,555][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.6988e-10, 8.8071e-07, 2.3045e-04, 5.0607e-04, 2.2770e-02, 3.3647e-02,
        1.4091e-01, 8.0194e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,556][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0301, 0.0545, 0.1049, 0.0534, 0.2293, 0.1623, 0.1121, 0.2534],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,556][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([9.4186e-06, 4.6394e-04, 1.0300e-02, 1.5160e-02, 5.6107e-03, 2.4456e-01,
        1.8719e-01, 5.3671e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,556][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([2.2733e-06, 3.7159e-04, 2.9602e-03, 1.6768e-02, 3.9265e-02, 1.0072e-01,
        2.6333e-01, 5.7658e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,557][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0129, 0.0186, 0.0397, 0.0820, 0.0841, 0.1037, 0.2256, 0.4335],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,557][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0706, 0.1651, 0.1230, 0.1252, 0.1005, 0.1420, 0.1249, 0.1487],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,557][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([2.5138e-05, 9.8116e-04, 5.5127e-03, 1.2428e-02, 5.6882e-02, 1.4762e-01,
        1.5050e-01, 6.2606e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,559][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([2.2169e-07, 1.6473e-04, 1.9247e-03, 7.3090e-03, 2.4371e-02, 6.9220e-02,
        1.5882e-01, 7.3819e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,560][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([3.5709e-07, 1.8830e-07, 6.2611e-06, 2.7009e-05, 3.6342e-03, 1.1021e-02,
        3.6782e-03, 9.8163e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,563][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0106, 0.1234, 0.0614, 0.0838, 0.1385, 0.1006, 0.1381, 0.3435],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,567][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0038, 0.0122, 0.0294, 0.0663, 0.0623, 0.0916, 0.1423, 0.4916, 0.1005],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,571][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0020, 0.0037, 0.1547, 0.0038, 0.4312, 0.1744, 0.0042, 0.0315, 0.1944],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,573][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([1.0307e-10, 1.3917e-07, 2.0239e-05, 8.0950e-05, 2.2264e-03, 2.2521e-03,
        1.3276e-02, 5.4710e-01, 4.3505e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,577][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0241, 0.0413, 0.0771, 0.0419, 0.1750, 0.1238, 0.0879, 0.2010, 0.2278],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,579][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([8.2914e-07, 1.4688e-04, 2.4299e-03, 3.6057e-03, 1.9051e-02, 3.5345e-02,
        3.5543e-02, 7.3520e-01, 1.6867e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,582][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.3713e-06, 1.5069e-04, 8.3630e-04, 5.5391e-03, 1.4899e-02, 2.1984e-02,
        7.2698e-02, 4.7000e-01, 4.1389e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,584][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0096, 0.0097, 0.0341, 0.0520, 0.0719, 0.0568, 0.1651, 0.3536, 0.2472],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,585][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0608, 0.1418, 0.1045, 0.1110, 0.0887, 0.1307, 0.1140, 0.1359, 0.1124],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,585][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.1536e-05, 5.4473e-04, 3.9452e-03, 1.0327e-02, 1.8962e-02, 1.4399e-01,
        1.0575e-01, 4.9760e-01, 2.1887e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,585][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([4.6480e-08, 6.5221e-05, 7.5255e-04, 2.5452e-03, 1.0171e-02, 1.8805e-02,
        3.3976e-02, 7.0725e-01, 2.2643e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,586][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([4.0495e-06, 4.1695e-07, 8.8209e-06, 1.9481e-05, 1.4608e-03, 2.4879e-03,
        9.2184e-04, 7.5465e-02, 9.1963e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,586][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0073, 0.0973, 0.0411, 0.0718, 0.0903, 0.0854, 0.1249, 0.2491, 0.2328],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,587][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0046, 0.0043, 0.0190, 0.0640, 0.0387, 0.0919, 0.1176, 0.2069, 0.1737,
        0.2793], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,587][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0057, 0.0025, 0.0358, 0.0018, 0.0144, 0.5925, 0.0018, 0.0763, 0.2679,
        0.0012], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,588][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.3708e-11, 4.6804e-09, 4.4550e-06, 3.2516e-05, 2.5894e-04, 5.4393e-04,
        2.2514e-03, 1.1396e-01, 1.9556e-01, 6.8739e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,590][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0151, 0.0309, 0.0741, 0.0279, 0.1577, 0.0985, 0.0707, 0.1826, 0.2266,
        0.1159], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,592][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.9301e-06, 6.3374e-05, 3.6714e-03, 3.2763e-03, 9.0462e-03, 1.4583e-02,
        3.7761e-02, 1.2445e-01, 3.8842e-01, 4.1872e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,594][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.8399e-07, 6.8071e-06, 9.1907e-05, 9.8762e-04, 1.3812e-03, 4.8019e-03,
        1.7592e-02, 6.2762e-02, 1.7041e-01, 7.4196e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,598][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0063, 0.0063, 0.0286, 0.0558, 0.0635, 0.0622, 0.1159, 0.2564, 0.1965,
        0.2085], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,602][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0610, 0.1264, 0.1079, 0.0977, 0.0850, 0.1151, 0.1028, 0.1170, 0.1030,
        0.0840], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,604][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.1606e-05, 9.1703e-05, 6.1579e-04, 4.0678e-03, 2.8669e-03, 3.9471e-02,
        4.0657e-02, 1.2304e-01, 2.9082e-01, 4.9836e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,607][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([3.3708e-08, 4.9031e-06, 1.6432e-04, 6.1797e-04, 2.2353e-03, 4.9992e-03,
        1.8363e-02, 9.9812e-02, 2.6522e-01, 6.0859e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,609][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([5.9863e-02, 3.0493e-06, 9.8460e-05, 7.8511e-05, 1.8662e-03, 1.9571e-03,
        1.0501e-03, 1.1523e-02, 7.2001e-01, 2.0355e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,612][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0065, 0.0651, 0.0392, 0.0505, 0.0826, 0.0613, 0.0853, 0.2096, 0.1918,
        0.2080], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,614][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0023, 0.0028, 0.0076, 0.0121, 0.0153, 0.0355, 0.0425, 0.0571, 0.0763,
        0.1931, 0.5554], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,614][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.9124e-03, 3.3289e-03, 4.4889e-02, 4.4022e-04, 2.0819e-02, 2.8691e-01,
        5.8992e-04, 1.8797e-02, 6.1917e-01, 1.7861e-03, 3.5761e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,615][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.1875e-11, 1.0524e-09, 3.3946e-07, 1.2240e-07, 1.3874e-05, 1.2898e-05,
        9.2454e-05, 2.5976e-03, 7.1102e-03, 1.5957e-01, 8.3060e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,615][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0123, 0.0261, 0.0628, 0.0213, 0.1463, 0.0895, 0.0591, 0.1708, 0.2155,
        0.1069, 0.0894], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,616][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.6855e-06, 4.8757e-05, 3.5292e-04, 2.8245e-04, 2.0998e-03, 1.2814e-03,
        7.0984e-03, 7.6609e-03, 1.7909e-02, 3.3537e-01, 6.2789e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,616][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.4388e-07, 1.9339e-06, 2.1112e-05, 2.5944e-05, 2.3645e-04, 6.5992e-04,
        3.3220e-03, 9.3603e-03, 3.3588e-02, 3.5599e-01, 5.9680e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,616][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0045, 0.0050, 0.0241, 0.0261, 0.0369, 0.0361, 0.0656, 0.1203, 0.1114,
        0.1272, 0.4429], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,618][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0591, 0.1166, 0.1040, 0.0895, 0.0828, 0.1084, 0.0960, 0.1054, 0.0976,
        0.0767, 0.0639], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,620][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.8092e-06, 4.2767e-05, 1.6713e-04, 2.6965e-04, 7.0904e-04, 9.5558e-03,
        8.9276e-03, 2.9851e-02, 5.2150e-02, 2.7414e-01, 6.2418e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,622][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1329e-08, 1.8148e-06, 4.0135e-05, 3.8542e-05, 4.1213e-04, 1.0803e-03,
        2.8439e-03, 2.0018e-02, 4.7186e-02, 2.5789e-01, 6.7049e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,624][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([6.6400e-03, 1.3522e-06, 3.7449e-05, 2.8597e-05, 1.0151e-03, 9.2045e-04,
        5.0922e-04, 7.3490e-03, 4.4228e-01, 1.3856e-01, 4.0266e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,628][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0071, 0.0681, 0.0363, 0.0344, 0.0729, 0.0555, 0.0693, 0.1670, 0.1579,
        0.1987, 0.1329], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,632][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0009, 0.0016, 0.0030, 0.0104, 0.0069, 0.0132, 0.0158, 0.0374, 0.0577,
        0.1288, 0.4962, 0.2280], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,636][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0179, 0.0733, 0.0910, 0.2002, 0.1001, 0.2546, 0.0063, 0.0444, 0.0739,
        0.0220, 0.1120, 0.0044], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,638][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([9.0424e-12, 2.5602e-10, 1.8664e-08, 1.6573e-07, 1.1920e-06, 1.8828e-06,
        1.8766e-05, 1.2543e-04, 1.0074e-03, 2.2968e-02, 7.8666e-01, 1.8921e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,641][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0125, 0.0219, 0.0445, 0.0203, 0.1132, 0.0723, 0.0490, 0.1250, 0.1526,
        0.0849, 0.0776, 0.2262], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,643][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([3.8973e-07, 7.1846e-06, 6.0899e-05, 1.8190e-04, 1.8770e-04, 1.0264e-03,
        1.1070e-03, 1.6506e-01, 2.9215e-03, 5.9845e-02, 3.9895e-01, 3.7064e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,643][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([4.6350e-08, 8.8518e-07, 7.0070e-06, 3.0977e-05, 1.0437e-04, 1.9595e-04,
        7.0748e-04, 2.5816e-03, 1.0068e-02, 1.2285e-01, 6.4677e-01, 2.1668e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,644][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0021, 0.0030, 0.0116, 0.0181, 0.0223, 0.0284, 0.0497, 0.0833, 0.0776,
        0.1005, 0.3256, 0.2776], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,644][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0478, 0.1154, 0.0837, 0.0859, 0.0717, 0.1050, 0.0884, 0.1045, 0.0882,
        0.0808, 0.0625, 0.0663], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,645][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([1.0298e-06, 2.6232e-05, 5.5339e-05, 2.5984e-04, 4.1223e-04, 1.9658e-03,
        2.7740e-03, 9.8234e-03, 2.2548e-02, 1.2961e-01, 6.0165e-01, 2.3088e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,645][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([3.0499e-09, 1.0902e-06, 1.0103e-05, 3.0536e-05, 1.2971e-04, 2.9902e-04,
        8.9985e-04, 6.9448e-03, 1.3850e-02, 1.0515e-01, 5.1682e-01, 3.5586e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,646][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([3.7973e-08, 1.5172e-08, 2.0050e-07, 3.8065e-07, 3.3775e-05, 3.6459e-05,
        1.8784e-05, 1.1250e-03, 1.4207e-02, 1.3427e-03, 5.5342e-03, 9.7770e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,646][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0067, 0.0651, 0.0333, 0.0331, 0.0652, 0.0497, 0.0608, 0.1510, 0.1449,
        0.1790, 0.1184, 0.0928], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:37,648][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0008, 0.0011, 0.0024, 0.0084, 0.0035, 0.0090, 0.0213, 0.0214, 0.0241,
        0.0911, 0.4167, 0.2156, 0.1846], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,650][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0013, 0.2070, 0.2032, 0.0061, 0.1109, 0.0252, 0.0041, 0.0053, 0.2656,
        0.0582, 0.0031, 0.0396, 0.0704], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,653][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([3.3963e-12, 1.2572e-10, 1.6154e-08, 3.6766e-08, 6.3072e-08, 2.0203e-06,
        3.6305e-06, 1.3079e-04, 4.4220e-04, 5.3607e-03, 1.3907e-01, 4.4145e-01,
        4.1354e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,657][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0058, 0.0100, 0.0207, 0.0092, 0.0549, 0.0359, 0.0243, 0.0650, 0.0834,
        0.0478, 0.0439, 0.1422, 0.4570], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,659][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([1.5687e-07, 2.7849e-06, 1.6878e-04, 4.9700e-05, 1.9145e-04, 9.0701e-05,
        6.2285e-04, 7.0359e-04, 1.2232e-02, 1.9047e-02, 1.0408e-01, 2.7382e-01,
        5.8900e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,661][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([1.4335e-08, 3.3463e-07, 1.8283e-06, 1.3965e-05, 1.1300e-05, 6.9974e-05,
        4.2659e-04, 1.7121e-03, 4.2169e-03, 4.4892e-02, 2.8132e-01, 3.7445e-01,
        2.9289e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,665][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0013, 0.0027, 0.0073, 0.0140, 0.0131, 0.0206, 0.0293, 0.0566, 0.0533,
        0.0799, 0.2297, 0.2838, 0.2084], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,669][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0474, 0.1026, 0.0788, 0.0816, 0.0647, 0.1018, 0.0837, 0.0949, 0.0880,
        0.0752, 0.0593, 0.0671, 0.0549], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,671][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([5.6608e-07, 3.7875e-06, 4.2336e-05, 8.1320e-05, 9.6892e-05, 1.1012e-03,
        1.2758e-03, 5.9670e-03, 1.1371e-02, 3.1777e-02, 1.9198e-01, 4.6871e-01,
        2.8758e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,673][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([2.4698e-09, 4.2949e-07, 2.8316e-06, 1.3759e-05, 1.5508e-05, 1.4418e-04,
        4.3838e-04, 3.5316e-03, 3.3400e-03, 3.0696e-02, 1.8190e-01, 4.6469e-01,
        3.1523e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,673][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([4.4200e-07, 2.8942e-08, 4.1929e-07, 6.3158e-07, 3.6399e-05, 3.7810e-05,
        2.0420e-05, 8.0806e-04, 1.3873e-02, 1.2284e-03, 4.7018e-03, 8.4656e-01,
        1.3273e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,674][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0035, 0.0336, 0.0201, 0.0267, 0.0410, 0.0382, 0.0499, 0.1217, 0.1045,
        0.1138, 0.1061, 0.0749, 0.2658], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:37,674][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0005, 0.0010, 0.0012, 0.0061, 0.0023, 0.0164, 0.0117, 0.0173, 0.0270,
        0.0686, 0.2838, 0.2854, 0.1092, 0.1696], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,674][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([4.8747e-03, 3.0815e-02, 1.4941e-01, 1.5328e-03, 2.2607e-01, 2.1260e-01,
        7.2933e-05, 3.3906e-02, 1.3042e-01, 1.7537e-03, 5.4572e-04, 2.6521e-02,
        1.0945e-01, 7.2030e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,675][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([5.7354e-13, 1.3835e-11, 1.3398e-09, 6.3050e-09, 5.1297e-08, 2.1251e-07,
        3.8799e-07, 4.3247e-06, 3.5984e-05, 1.6386e-03, 4.8378e-02, 1.2916e-01,
        6.3982e-01, 1.8096e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,676][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0063, 0.0118, 0.0263, 0.0108, 0.0605, 0.0369, 0.0252, 0.0661, 0.0783,
        0.0414, 0.0388, 0.1252, 0.3742, 0.0981], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,678][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([2.1606e-07, 3.5489e-06, 9.8274e-06, 5.4784e-05, 5.4915e-05, 2.0067e-04,
        4.5183e-04, 8.3311e-04, 1.6392e-03, 2.6475e-02, 1.5494e-01, 3.6478e-01,
        1.6111e-01, 2.8944e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,679][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([2.0757e-08, 3.7604e-07, 1.0199e-06, 8.5401e-06, 1.7066e-05, 2.1334e-05,
        1.6243e-04, 8.4404e-04, 7.0324e-04, 4.0603e-02, 1.8139e-01, 1.2882e-01,
        4.8142e-01, 1.6601e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,683][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0015, 0.0018, 0.0080, 0.0112, 0.0140, 0.0135, 0.0264, 0.0422, 0.0344,
        0.0539, 0.1880, 0.2492, 0.2381, 0.1178], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,687][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0427, 0.0944, 0.0755, 0.0735, 0.0634, 0.0897, 0.0788, 0.0930, 0.0796,
        0.0685, 0.0544, 0.0635, 0.0547, 0.0683], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,690][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([7.8054e-07, 8.3290e-06, 2.7378e-05, 7.1582e-05, 1.4183e-04, 3.9825e-04,
        5.5457e-04, 3.4176e-03, 3.4325e-03, 4.5823e-02, 1.3601e-01, 1.6949e-01,
        3.5761e-01, 2.8302e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,692][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.4823e-09, 1.8987e-07, 1.8041e-06, 7.6779e-06, 2.0325e-05, 2.7753e-05,
        1.1858e-04, 6.5714e-04, 2.1631e-03, 3.1382e-02, 1.4176e-01, 1.6368e-01,
        4.9850e-01, 1.6168e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,694][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([2.1897e-06, 5.9511e-09, 1.3383e-07, 1.3937e-07, 8.9574e-06, 1.2354e-05,
        5.4700e-06, 1.9313e-04, 7.1324e-03, 9.5568e-04, 3.1776e-03, 4.5202e-01,
        1.0284e-01, 4.3366e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,697][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0057, 0.0501, 0.0224, 0.0234, 0.0401, 0.0342, 0.0418, 0.1000, 0.0790,
        0.1218, 0.0778, 0.0729, 0.2143, 0.1165], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:37,699][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.1499e-04, 3.2164e-04, 5.6045e-04, 1.9738e-03, 1.3033e-03, 2.4446e-03,
        3.0227e-03, 5.5877e-03, 8.9704e-03, 2.5707e-02, 1.0477e-01, 1.5334e-01,
        7.5187e-02, 1.5160e-01, 4.6489e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,701][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0086, 0.0342, 0.0388, 0.0208, 0.1164, 0.2011, 0.0124, 0.0443, 0.3153,
        0.0287, 0.0132, 0.0256, 0.0889, 0.0107, 0.0409], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,702][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.6120e-13, 1.1463e-12, 9.2223e-11, 4.1287e-10, 4.9843e-09, 1.6329e-08,
        4.4820e-08, 1.0849e-06, 6.2872e-06, 8.2672e-05, 2.6609e-03, 5.8236e-03,
        5.4586e-02, 2.0349e-01, 7.3335e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,702][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0054, 0.0099, 0.0236, 0.0094, 0.0540, 0.0359, 0.0232, 0.0609, 0.0733,
        0.0383, 0.0343, 0.1147, 0.3553, 0.0973, 0.0647], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,703][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.3177e-08, 6.1479e-07, 2.8876e-06, 5.2636e-06, 1.6658e-05, 1.2729e-04,
        4.3818e-05, 4.8254e-04, 2.5034e-03, 2.7778e-03, 1.3031e-02, 3.9180e-02,
        5.7588e-02, 6.7347e-01, 2.1077e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,703][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.0523e-08, 5.2342e-08, 2.7716e-07, 1.5733e-06, 2.1200e-06, 7.0316e-06,
        2.2530e-05, 1.0998e-04, 2.0145e-04, 5.3282e-03, 3.1435e-02, 3.4468e-02,
        6.7831e-02, 1.3122e-01, 7.2937e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,704][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0015, 0.0015, 0.0054, 0.0070, 0.0082, 0.0085, 0.0193, 0.0242, 0.0267,
        0.0399, 0.1100, 0.1249, 0.1194, 0.1240, 0.3795], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,704][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0442, 0.0914, 0.0763, 0.0703, 0.0610, 0.0829, 0.0732, 0.0828, 0.0734,
        0.0620, 0.0505, 0.0605, 0.0524, 0.0665, 0.0525], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,705][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.4925e-07, 1.2840e-06, 6.1427e-06, 1.0271e-05, 1.5868e-05, 1.3319e-04,
        9.3140e-05, 1.1627e-04, 7.2813e-04, 7.3564e-03, 2.8365e-02, 3.1150e-02,
        3.8644e-02, 5.9818e-01, 2.9520e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,706][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.4043e-10, 4.0200e-08, 5.5596e-07, 9.0889e-07, 4.3147e-06, 4.3922e-06,
        1.9763e-05, 1.9059e-04, 3.5053e-04, 3.6518e-03, 1.5228e-02, 4.6538e-02,
        1.0119e-01, 1.4907e-01, 6.8376e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,708][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.9556e-04, 6.0076e-09, 1.7643e-07, 9.2155e-08, 3.8439e-06, 3.0065e-06,
        1.7864e-06, 1.7574e-05, 2.5889e-03, 1.0236e-03, 2.5054e-03, 1.5220e-01,
        5.6686e-02, 2.6479e-01, 5.1979e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,712][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0058, 0.0343, 0.0170, 0.0198, 0.0340, 0.0262, 0.0325, 0.0771, 0.0629,
        0.0853, 0.0682, 0.0586, 0.1876, 0.1058, 0.1850], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:37,713][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:37,716][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10039],
        [28640],
        [14185],
        [25479],
        [25175],
        [25282],
        [30779],
        [32858],
        [31162],
        [23759],
        [23848],
        [28343],
        [30434],
        [26148],
        [35926]], device='cuda:0')
[2024-07-24 10:20:37,719][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10448],
        [29432],
        [17386],
        [33627],
        [28167],
        [28203],
        [40393],
        [43493],
        [41074],
        [36259],
        [37066],
        [25303],
        [41805],
        [29680],
        [40029]], device='cuda:0')
[2024-07-24 10:20:37,721][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[35952],
        [34373],
        [32873],
        [31450],
        [31387],
        [32460],
        [33882],
        [34773],
        [34907],
        [35098],
        [34593],
        [33473],
        [34072],
        [34737],
        [34758]], device='cuda:0')
[2024-07-24 10:20:37,724][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12972],
        [12927],
        [ 6915],
        [ 7820],
        [ 3544],
        [ 5814],
        [ 6114],
        [ 6790],
        [ 5420],
        [ 5918],
        [ 6088],
        [ 4857],
        [ 5393],
        [ 6425],
        [ 7215]], device='cuda:0')
[2024-07-24 10:20:37,726][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[37299],
        [40377],
        [29792],
        [39113],
        [41477],
        [30327],
        [10480],
        [13762],
        [18662],
        [41749],
        [40984],
        [40100],
        [28163],
        [21324],
        [40025]], device='cuda:0')
[2024-07-24 10:20:37,729][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26587],
        [26390],
        [ 7716],
        [ 7872],
        [ 8009],
        [ 9435],
        [ 9278],
        [ 6296],
        [ 3057],
        [ 3518],
        [ 2860],
        [ 4004],
        [12231],
        [11902],
        [17406]], device='cuda:0')
[2024-07-24 10:20:37,731][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[28111],
        [37397],
        [29591],
        [35158],
        [31708],
        [36729],
        [35793],
        [34380],
        [33007],
        [28375],
        [33670],
        [34272],
        [29360],
        [30781],
        [26364]], device='cuda:0')
[2024-07-24 10:20:37,734][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[18836],
        [22645],
        [41755],
        [32651],
        [38093],
        [29406],
        [21976],
        [27791],
        [30143],
        [34030],
        [39643],
        [39310],
        [38856],
        [37983],
        [34502]], device='cuda:0')
[2024-07-24 10:20:37,735][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[30810],
        [26626],
        [26170],
        [24205],
        [24708],
        [23102],
        [23395],
        [24426],
        [25266],
        [25197],
        [24694],
        [25078],
        [25316],
        [25252],
        [25208]], device='cuda:0')
[2024-07-24 10:20:37,736][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[12632],
        [ 1753],
        [  960],
        [ 1951],
        [ 2161],
        [ 2280],
        [ 2001],
        [ 1999],
        [ 2286],
        [ 1960],
        [ 2401],
        [ 2528],
        [ 2550],
        [ 2576],
        [ 2502]], device='cuda:0')
[2024-07-24 10:20:37,737][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35310],
        [32542],
        [31216],
        [30490],
        [30048],
        [26104],
        [24248],
        [26458],
        [27824],
        [29470],
        [29730],
        [27533],
        [29638],
        [31175],
        [31211]], device='cuda:0')
[2024-07-24 10:20:37,738][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 5705],
        [ 3692],
        [10920],
        [ 9989],
        [13595],
        [14548],
        [13823],
        [12841],
        [13728],
        [13650],
        [12752],
        [12785],
        [16944],
        [19810],
        [18529]], device='cuda:0')
[2024-07-24 10:20:37,739][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[6189],
        [9252],
        [5095],
        [4177],
        [4307],
        [5509],
        [7636],
        [7061],
        [7310],
        [6583],
        [5149],
        [4676],
        [4130],
        [5576],
        [7037]], device='cuda:0')
[2024-07-24 10:20:37,741][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24368],
        [24543],
        [33265],
        [32660],
        [36141],
        [36869],
        [31557],
        [31379],
        [30103],
        [28013],
        [28524],
        [28903],
        [29072],
        [30539],
        [25969]], device='cuda:0')
[2024-07-24 10:20:37,743][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9923],
        [24781],
        [13372],
        [28044],
        [13421],
        [17280],
        [23784],
        [16680],
        [38723],
        [17310],
        [15699],
        [34559],
        [16710],
        [29744],
        [24913]], device='cuda:0')
[2024-07-24 10:20:37,745][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23393],
        [ 7059],
        [ 5544],
        [ 8152],
        [ 8565],
        [11856],
        [11946],
        [ 9253],
        [ 7466],
        [ 5897],
        [ 6232],
        [ 6770],
        [ 7244],
        [ 6917],
        [ 7496]], device='cuda:0')
[2024-07-24 10:20:37,747][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[43624],
        [35964],
        [19606],
        [18536],
        [19515],
        [26076],
        [30618],
        [33017],
        [20687],
        [27208],
        [19563],
        [27718],
        [22485],
        [21275],
        [24822]], device='cuda:0')
[2024-07-24 10:20:37,750][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15561],
        [11950],
        [ 2347],
        [ 2763],
        [ 9211],
        [ 8645],
        [ 7023],
        [ 3299],
        [ 5660],
        [ 7563],
        [ 5558],
        [ 7802],
        [20080],
        [17827],
        [24695]], device='cuda:0')
[2024-07-24 10:20:37,752][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17037],
        [16836],
        [18261],
        [18293],
        [20055],
        [19190],
        [18410],
        [17955],
        [18214],
        [18200],
        [18154],
        [18475],
        [20018],
        [19782],
        [19638]], device='cuda:0')
[2024-07-24 10:20:37,755][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12606],
        [ 4913],
        [19121],
        [ 9538],
        [14887],
        [ 6707],
        [ 5828],
        [12748],
        [15251],
        [ 2064],
        [ 3849],
        [ 5198],
        [10695],
        [ 5733],
        [11189]], device='cuda:0')
[2024-07-24 10:20:37,757][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14389],
        [10715],
        [21767],
        [27991],
        [29212],
        [29069],
        [24020],
        [28258],
        [26465],
        [14004],
        [16566],
        [28944],
        [28796],
        [23784],
        [17892]], device='cuda:0')
[2024-07-24 10:20:37,760][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 3648],
        [ 4162],
        [16609],
        [17852],
        [12862],
        [21976],
        [19930],
        [22853],
        [19332],
        [21220],
        [19077],
        [23727],
        [18224],
        [20760],
        [25198]], device='cuda:0')
[2024-07-24 10:20:37,762][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[11230],
        [14126],
        [14019],
        [13913],
        [14060],
        [14975],
        [14665],
        [15182],
        [15207],
        [15114],
        [15112],
        [15476],
        [15462],
        [15751],
        [15763]], device='cuda:0')
[2024-07-24 10:20:37,765][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 9015],
        [12338],
        [ 7097],
        [13637],
        [ 9378],
        [ 2341],
        [ 2074],
        [ 8356],
        [10183],
        [15819],
        [16540],
        [15491],
        [11585],
        [ 7658],
        [ 6427]], device='cuda:0')
[2024-07-24 10:20:37,768][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11083],
        [10721],
        [10522],
        [10061],
        [10752],
        [11273],
        [10463],
        [ 9479],
        [10284],
        [ 9733],
        [10000],
        [10949],
        [11634],
        [11940],
        [10816]], device='cuda:0')
[2024-07-24 10:20:37,768][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[26201],
        [26519],
        [12731],
        [35451],
        [23803],
        [21417],
        [21503],
        [10882],
        [12280],
        [14295],
        [20226],
        [16138],
        [16756],
        [20387],
        [19950]], device='cuda:0')
[2024-07-24 10:20:37,769][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[27393],
        [31081],
        [36603],
        [35064],
        [38227],
        [38705],
        [36709],
        [39026],
        [37611],
        [37153],
        [35808],
        [35241],
        [36688],
        [36424],
        [34615]], device='cuda:0')
[2024-07-24 10:20:37,770][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[20722],
        [26285],
        [26081],
        [19740],
        [19232],
        [21476],
        [22781],
        [19422],
        [22626],
        [26748],
        [25449],
        [19883],
        [16414],
        [20516],
        [17752]], device='cuda:0')
[2024-07-24 10:20:37,772][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4682],
        [18309],
        [16936],
        [20833],
        [18039],
        [14199],
        [11437],
        [16402],
        [10314],
        [12037],
        [29391],
        [20740],
        [21766],
        [13166],
        [14097]], device='cuda:0')
[2024-07-24 10:20:37,773][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500],
        [31500]], device='cuda:0')
[2024-07-24 10:20:37,806][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:37,807][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,808][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,808][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,808][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,809][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,809][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,809][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,810][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,811][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,811][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,811][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,812][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:37,812][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9717, 0.0283], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,812][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4794, 0.5206], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,813][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4747, 0.5253], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,813][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0161, 0.9839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,813][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6395, 0.3605], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,813][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2307, 0.7693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,814][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4382, 0.5618], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,814][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9070, 0.0930], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,814][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4037, 0.5963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,815][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9863, 0.0137], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,815][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4869, 0.5131], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,815][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9922, 0.0078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:37,816][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.9650, 0.0100, 0.0250], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,816][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.3265, 0.3601, 0.3134], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,816][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.2632, 0.2054, 0.5314], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,817][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.0139, 0.3870, 0.5991], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,817][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.5137, 0.2703, 0.2161], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,817][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.0854, 0.3136, 0.6009], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,818][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.2773, 0.3595, 0.3632], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,818][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.5065, 0.0282, 0.4653], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,818][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.2566, 0.3379, 0.4056], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,820][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.9936, 0.0012, 0.0052], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,822][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.2959, 0.3173, 0.3868], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,826][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.9781, 0.0161, 0.0059], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:37,830][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8574, 0.0271, 0.0278, 0.0877], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,833][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2260, 0.2477, 0.2329, 0.2934], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,837][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1299, 0.1390, 0.5489, 0.1822], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,841][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0058, 0.1856, 0.3061, 0.5024], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,844][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3439, 0.1952, 0.2156, 0.2453], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,844][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0509, 0.1428, 0.4522, 0.3541], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,845][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1903, 0.2488, 0.3134, 0.2474], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,845][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.8280e-03, 1.2069e-05, 9.9799e-01, 1.7395e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,845][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1804, 0.2523, 0.3107, 0.2566], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,846][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9370, 0.0073, 0.0408, 0.0148], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,846][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2310, 0.2449, 0.2642, 0.2599], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,846][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9570, 0.0138, 0.0139, 0.0153], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:37,848][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.9793, 0.0035, 0.0028, 0.0103, 0.0041], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,851][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.1803, 0.1939, 0.1827, 0.2665, 0.1765], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,855][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0854, 0.0748, 0.2156, 0.1250, 0.4993], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,859][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0038, 0.1420, 0.2153, 0.3862, 0.2526], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,862][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.2992, 0.1558, 0.1839, 0.2163, 0.1448], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,866][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0361, 0.1124, 0.2905, 0.2679, 0.2932], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,870][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1509, 0.2005, 0.2127, 0.2089, 0.2271], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,872][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([1.5371e-02, 7.2208e-04, 9.7238e-01, 1.0268e-02, 1.2594e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,873][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.1474, 0.1988, 0.2357, 0.2025, 0.2156], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,873][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.9535, 0.0017, 0.0075, 0.0024, 0.0348], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,873][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.1742, 0.1945, 0.2198, 0.2132, 0.1983], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,874][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.9072, 0.0203, 0.0264, 0.0214, 0.0248], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:37,874][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.7989, 0.0249, 0.0134, 0.0724, 0.0068, 0.0836], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,874][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1566, 0.1566, 0.1534, 0.2007, 0.1507, 0.1820], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,875][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0317, 0.0488, 0.1581, 0.0793, 0.4786, 0.2036], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,875][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0018, 0.0742, 0.1483, 0.2174, 0.1662, 0.3921], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,875][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2323, 0.1260, 0.1455, 0.1635, 0.1525, 0.1802], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,877][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0253, 0.0700, 0.1997, 0.1740, 0.2320, 0.2990], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,880][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1374, 0.1727, 0.1953, 0.1657, 0.1979, 0.1309], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,882][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([4.1168e-03, 4.1683e-04, 6.6349e-01, 2.1336e-02, 3.1058e-01, 6.1470e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,886][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1222, 0.1730, 0.2023, 0.1693, 0.1836, 0.1496], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,890][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.9225, 0.0023, 0.0061, 0.0042, 0.0227, 0.0422], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,893][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1508, 0.1631, 0.1849, 0.1755, 0.1617, 0.1640], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,897][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.9207, 0.0139, 0.0107, 0.0342, 0.0044, 0.0161], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:37,902][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7903, 0.0176, 0.0194, 0.0501, 0.0058, 0.0236, 0.0932],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,902][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1343, 0.1357, 0.1310, 0.1645, 0.1269, 0.1574, 0.1501],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,903][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0377, 0.0403, 0.1389, 0.0589, 0.3555, 0.2090, 0.1597],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,903][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0016, 0.0599, 0.1015, 0.1524, 0.1103, 0.2727, 0.3016],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,903][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1867, 0.1088, 0.1237, 0.1430, 0.1262, 0.1787, 0.1329],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,904][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0292, 0.0644, 0.1590, 0.1227, 0.1658, 0.2196, 0.2393],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,904][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1152, 0.1470, 0.1577, 0.1501, 0.1612, 0.1277, 0.1411],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,904][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([3.3123e-03, 1.4935e-04, 4.6007e-01, 2.6267e-03, 5.3242e-01, 1.1167e-03,
        3.1289e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,906][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1042, 0.1454, 0.1737, 0.1464, 0.1569, 0.1314, 0.1420],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,909][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.8370, 0.0012, 0.0093, 0.0050, 0.0330, 0.0789, 0.0356],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,913][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1260, 0.1316, 0.1515, 0.1467, 0.1426, 0.1417, 0.1599],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,917][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.9542, 0.0062, 0.0071, 0.0114, 0.0038, 0.0116, 0.0058],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:37,920][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.8300, 0.0165, 0.0067, 0.0390, 0.0045, 0.0189, 0.0375, 0.0469],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,924][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1118, 0.1171, 0.1085, 0.1520, 0.1101, 0.1438, 0.1413, 0.1155],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,928][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0213, 0.0301, 0.1050, 0.0523, 0.2951, 0.2193, 0.1597, 0.1171],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,931][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0009, 0.0455, 0.0769, 0.1267, 0.0881, 0.2316, 0.2557, 0.1746],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,931][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1821, 0.0912, 0.1271, 0.1285, 0.1170, 0.1582, 0.1183, 0.0777],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,932][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0091, 0.0318, 0.1056, 0.1231, 0.1302, 0.2302, 0.3245, 0.0456],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,932][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1016, 0.1312, 0.1362, 0.1334, 0.1354, 0.1031, 0.1383, 0.1209],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,933][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0162, 0.0011, 0.5742, 0.1526, 0.1753, 0.0679, 0.0095, 0.0031],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,933][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0930, 0.1308, 0.1486, 0.1293, 0.1363, 0.1137, 0.1211, 0.1272],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,933][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([9.2288e-01, 2.2482e-04, 1.1330e-03, 9.0889e-04, 8.6129e-03, 1.5322e-02,
        1.1250e-02, 3.9668e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,935][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1120, 0.1191, 0.1332, 0.1271, 0.1251, 0.1170, 0.1332, 0.1333],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,937][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([9.7152e-01, 4.7172e-04, 5.8577e-04, 9.6870e-04, 2.6348e-04, 7.2174e-04,
        2.2886e-03, 2.3183e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:37,940][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.9218, 0.0074, 0.0038, 0.0192, 0.0016, 0.0054, 0.0143, 0.0109, 0.0156],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,944][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0954, 0.1023, 0.1000, 0.1411, 0.0961, 0.1368, 0.1317, 0.1070, 0.0895],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,947][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0218, 0.0220, 0.0838, 0.0396, 0.2321, 0.1842, 0.1467, 0.1033, 0.1666],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,951][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0007, 0.0403, 0.0607, 0.1130, 0.0710, 0.2225, 0.2499, 0.1682, 0.0737],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,955][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1779, 0.0860, 0.1076, 0.1218, 0.1047, 0.1536, 0.0995, 0.0854, 0.0636],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,958][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0159, 0.0420, 0.1174, 0.1118, 0.1246, 0.1925, 0.2142, 0.0500, 0.1317],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,960][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0895, 0.1234, 0.1253, 0.1234, 0.1318, 0.0920, 0.1248, 0.1174, 0.0723],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,960][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0103, 0.0007, 0.4178, 0.0112, 0.2886, 0.0619, 0.0157, 0.1925, 0.0012],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,961][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0823, 0.1156, 0.1326, 0.1163, 0.1217, 0.1017, 0.1079, 0.1135, 0.1085],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,961][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([9.5278e-01, 8.6533e-05, 1.1614e-03, 2.8790e-04, 7.7462e-03, 6.5239e-03,
        3.2960e-03, 1.0174e-02, 1.7946e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,962][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0931, 0.1062, 0.1309, 0.1148, 0.1136, 0.1045, 0.1313, 0.1153, 0.0903],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,962][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([8.7049e-01, 5.0998e-04, 5.6929e-04, 7.1372e-04, 1.1507e-04, 7.3106e-04,
        1.8368e-03, 1.1665e-01, 8.3855e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:37,962][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7833, 0.0157, 0.0118, 0.0496, 0.0056, 0.0170, 0.0349, 0.0349, 0.0132,
        0.0341], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,963][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0829, 0.0915, 0.0947, 0.1210, 0.0887, 0.1175, 0.1091, 0.0955, 0.0895,
        0.1097], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,965][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0430, 0.0370, 0.1269, 0.0326, 0.2438, 0.1494, 0.0873, 0.0901, 0.1527,
        0.0373], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,967][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0007, 0.0374, 0.0521, 0.0927, 0.0559, 0.1915, 0.2146, 0.1321, 0.0543,
        0.1687], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,971][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1453, 0.0825, 0.0890, 0.1096, 0.0910, 0.1353, 0.0972, 0.0676, 0.0631,
        0.1194], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,975][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0121, 0.0319, 0.1095, 0.0864, 0.1144, 0.1628, 0.1995, 0.0492, 0.1307,
        0.1035], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,979][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0741, 0.1001, 0.1234, 0.1066, 0.1216, 0.0872, 0.1143, 0.1009, 0.0757,
        0.0960], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,981][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([3.6788e-04, 1.7330e-06, 4.3338e-01, 1.8512e-04, 2.9107e-01, 3.5830e-04,
        1.1041e-02, 5.0986e-02, 2.1257e-01, 3.8774e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,985][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0726, 0.1032, 0.1219, 0.1021, 0.1098, 0.0918, 0.0980, 0.1045, 0.0992,
        0.0968], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,987][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.2710e-01, 5.2068e-05, 1.4170e-03, 7.1199e-04, 4.8889e-03, 4.9389e-03,
        2.3301e-03, 9.9413e-03, 1.5967e-02, 3.2655e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,990][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0914, 0.0981, 0.1097, 0.1082, 0.0973, 0.1009, 0.1145, 0.1056, 0.0707,
        0.1037], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,990][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.3798e-01, 1.7895e-04, 3.7196e-04, 6.8863e-04, 1.3069e-04, 4.0655e-04,
        1.7692e-03, 3.5259e-02, 8.6665e-03, 1.4544e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:37,990][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6668, 0.0185, 0.0201, 0.0622, 0.0059, 0.0189, 0.0409, 0.0381, 0.0163,
        0.0494, 0.0627], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,991][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0792, 0.0869, 0.0851, 0.1016, 0.0831, 0.1058, 0.0957, 0.0816, 0.0792,
        0.1012, 0.1005], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,991][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0275, 0.0259, 0.0907, 0.0344, 0.2286, 0.1463, 0.0881, 0.0926, 0.1709,
        0.0402, 0.0548], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,992][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0009, 0.0357, 0.0513, 0.0848, 0.0547, 0.1637, 0.1838, 0.1197, 0.0508,
        0.1476, 0.1069], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,992][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1269, 0.0746, 0.0838, 0.0963, 0.0888, 0.1205, 0.0837, 0.0587, 0.0573,
        0.1094, 0.1000], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,994][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0093, 0.0296, 0.0915, 0.0769, 0.1043, 0.1477, 0.1946, 0.0427, 0.1161,
        0.1002, 0.0871], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,996][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0680, 0.0908, 0.1115, 0.0938, 0.1083, 0.0837, 0.1069, 0.0932, 0.0704,
        0.0904, 0.0830], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:37,999][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([6.0362e-04, 1.9677e-06, 4.6451e-01, 3.9590e-05, 8.8119e-02, 7.4980e-04,
        1.0097e-03, 5.7172e-02, 3.8745e-01, 1.2200e-04, 2.1884e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,003][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0666, 0.0965, 0.1114, 0.0941, 0.1012, 0.0848, 0.0900, 0.0964, 0.0920,
        0.0883, 0.0787], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,005][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.1061e-01, 5.1065e-05, 5.2421e-04, 1.8273e-04, 1.9982e-03, 3.0889e-03,
        1.4348e-03, 3.1990e-03, 8.0484e-03, 2.5524e-02, 4.5335e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,009][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0865, 0.0888, 0.0972, 0.0954, 0.0872, 0.0930, 0.1013, 0.0973, 0.0681,
        0.0927, 0.0924], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,011][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.4975e-01, 1.0115e-04, 2.8526e-04, 1.2814e-04, 1.0172e-04, 3.4642e-04,
        1.0317e-03, 1.2617e-02, 7.6964e-03, 1.3579e-02, 1.4366e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,015][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.8689, 0.0082, 0.0046, 0.0179, 0.0023, 0.0063, 0.0120, 0.0167, 0.0062,
        0.0161, 0.0163, 0.0243], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,019][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0703, 0.0773, 0.0742, 0.1032, 0.0743, 0.1005, 0.0883, 0.0784, 0.0672,
        0.0967, 0.0989, 0.0708], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,019][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0305, 0.0251, 0.0850, 0.0381, 0.1691, 0.1062, 0.0703, 0.0871, 0.1389,
        0.0407, 0.0614, 0.1478], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,019][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0005, 0.0225, 0.0355, 0.0713, 0.0433, 0.1565, 0.1798, 0.1125, 0.0408,
        0.1346, 0.0987, 0.1040], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,020][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1204, 0.0654, 0.0908, 0.0897, 0.0803, 0.0999, 0.0784, 0.0628, 0.0587,
        0.0963, 0.0927, 0.0645], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,020][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0066, 0.0253, 0.0570, 0.0850, 0.0823, 0.1574, 0.1997, 0.0325, 0.0933,
        0.1051, 0.1054, 0.0505], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,021][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0634, 0.0883, 0.0939, 0.0937, 0.0956, 0.0779, 0.0954, 0.0887, 0.0594,
        0.0856, 0.0854, 0.0729], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,021][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([1.1038e-02, 2.6340e-04, 3.3832e-01, 2.3193e-02, 7.4581e-02, 2.2617e-02,
        3.2718e-02, 1.3775e-01, 9.8083e-02, 1.3237e-02, 9.3339e-02, 1.5486e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,022][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0642, 0.0878, 0.0988, 0.0859, 0.0917, 0.0764, 0.0816, 0.0863, 0.0836,
        0.0820, 0.0751, 0.0867], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,023][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([8.9272e-01, 5.5400e-05, 9.3522e-04, 1.9375e-04, 8.8422e-03, 2.6091e-03,
        1.1751e-03, 4.5388e-03, 6.9468e-03, 1.1543e-02, 1.8359e-02, 5.2079e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,025][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0781, 0.0823, 0.0914, 0.0909, 0.0843, 0.0841, 0.0948, 0.0899, 0.0629,
        0.0821, 0.0878, 0.0715], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,027][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([9.2260e-01, 2.5254e-04, 8.1259e-04, 4.5476e-04, 3.1067e-04, 3.8089e-04,
        8.4707e-04, 1.4037e-02, 6.1298e-03, 1.2226e-02, 1.6339e-02, 2.5607e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,031][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.9473, 0.0031, 0.0025, 0.0082, 0.0031, 0.0021, 0.0056, 0.0061, 0.0021,
        0.0059, 0.0062, 0.0048, 0.0030], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,035][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0670, 0.0702, 0.0670, 0.0974, 0.0645, 0.0896, 0.0854, 0.0746, 0.0636,
        0.0888, 0.0962, 0.0758, 0.0600], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,039][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0244, 0.0185, 0.0687, 0.0315, 0.1377, 0.0763, 0.0634, 0.0689, 0.1089,
        0.0362, 0.0632, 0.1406, 0.1617], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,042][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0004, 0.0261, 0.0382, 0.0687, 0.0484, 0.1321, 0.1369, 0.1092, 0.0512,
        0.1355, 0.0895, 0.1382, 0.0255], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,046][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1206, 0.0622, 0.0742, 0.0878, 0.0576, 0.1009, 0.0757, 0.0589, 0.0489,
        0.0950, 0.0909, 0.0665, 0.0607], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,048][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0068, 0.0256, 0.0689, 0.0664, 0.0720, 0.1777, 0.1726, 0.0283, 0.0993,
        0.0949, 0.0753, 0.0522, 0.0601], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,049][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0609, 0.0824, 0.0833, 0.0872, 0.0931, 0.0668, 0.0855, 0.0766, 0.0499,
        0.0770, 0.0818, 0.0700, 0.0857], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,049][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([2.6867e-03, 6.6203e-05, 1.5894e-01, 1.2809e-03, 1.5183e-04, 4.3092e-03,
        3.0258e-03, 3.4782e-02, 8.7966e-03, 1.2061e-03, 3.5547e-03, 7.8079e-01,
        4.1691e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,049][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0587, 0.0789, 0.0908, 0.0799, 0.0837, 0.0713, 0.0758, 0.0788, 0.0760,
        0.0750, 0.0684, 0.0791, 0.0837], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,050][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([9.5688e-01, 1.4513e-05, 9.2762e-05, 2.8768e-05, 4.5689e-04, 2.7292e-04,
        2.2269e-04, 2.0038e-04, 4.5571e-04, 1.5368e-03, 2.5268e-03, 3.5222e-03,
        3.3793e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,050][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0653, 0.0755, 0.0863, 0.0829, 0.0785, 0.0811, 0.0882, 0.0779, 0.0606,
        0.0759, 0.0820, 0.0676, 0.0781], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,051][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([9.4098e-01, 1.7930e-04, 5.7942e-04, 2.8504e-04, 2.8460e-04, 3.8302e-04,
        7.8381e-04, 1.4459e-03, 4.7032e-03, 4.6189e-03, 8.1480e-03, 2.2636e-02,
        1.4969e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,053][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.7976, 0.0105, 0.0090, 0.0253, 0.0027, 0.0111, 0.0266, 0.0147, 0.0098,
        0.0229, 0.0253, 0.0171, 0.0026, 0.0247], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,056][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0606, 0.0649, 0.0613, 0.0883, 0.0623, 0.0815, 0.0822, 0.0700, 0.0550,
        0.0838, 0.0903, 0.0695, 0.0594, 0.0710], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,059][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0157, 0.0132, 0.0611, 0.0221, 0.1463, 0.0665, 0.0618, 0.0511, 0.0903,
        0.0216, 0.0389, 0.1199, 0.1505, 0.1412], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,063][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0004, 0.0204, 0.0365, 0.0659, 0.0484, 0.1288, 0.1437, 0.1049, 0.0469,
        0.1252, 0.0829, 0.1171, 0.0223, 0.0566], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,068][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0938, 0.0550, 0.0712, 0.0724, 0.0682, 0.0798, 0.0657, 0.0535, 0.0506,
        0.0781, 0.0761, 0.0600, 0.0715, 0.1039], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,071][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0087, 0.0229, 0.0672, 0.0582, 0.0825, 0.1171, 0.1302, 0.0302, 0.0897,
        0.0738, 0.0701, 0.0522, 0.0755, 0.1218], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,075][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0544, 0.0802, 0.0800, 0.0787, 0.0883, 0.0591, 0.0822, 0.0726, 0.0476,
        0.0765, 0.0753, 0.0684, 0.0850, 0.0516], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,077][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([5.7495e-04, 8.8348e-05, 3.2727e-02, 1.5819e-02, 5.8072e-02, 8.2143e-04,
        1.3005e-01, 6.4062e-03, 3.6551e-02, 1.7501e-02, 1.0791e-01, 3.6555e-01,
        2.2781e-01, 1.1879e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,077][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0538, 0.0743, 0.0858, 0.0739, 0.0791, 0.0653, 0.0692, 0.0737, 0.0712,
        0.0681, 0.0624, 0.0740, 0.0793, 0.0698], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,078][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([9.2311e-01, 4.8174e-06, 4.7480e-05, 1.6660e-05, 2.7728e-04, 1.7645e-04,
        9.0408e-05, 2.1022e-04, 2.5457e-04, 1.8623e-03, 2.4433e-03, 1.6639e-02,
        4.6330e-02, 8.5414e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,078][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0658, 0.0724, 0.0831, 0.0773, 0.0715, 0.0731, 0.0813, 0.0730, 0.0563,
        0.0750, 0.0764, 0.0623, 0.0726, 0.0601], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,079][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([9.7603e-01, 2.4701e-05, 1.8178e-05, 4.5782e-05, 7.9906e-06, 3.4059e-05,
        4.9850e-05, 7.1809e-04, 5.9287e-04, 9.6034e-04, 1.4365e-03, 1.4854e-02,
        8.8441e-04, 4.3415e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,079][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5725, 0.0194, 0.0157, 0.0407, 0.0074, 0.0204, 0.0368, 0.0330, 0.0188,
        0.0419, 0.0423, 0.0343, 0.0072, 0.0210, 0.0885], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,080][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0592, 0.0628, 0.0608, 0.0775, 0.0584, 0.0781, 0.0709, 0.0626, 0.0579,
        0.0739, 0.0780, 0.0606, 0.0572, 0.0767, 0.0655], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,081][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0198, 0.0140, 0.0726, 0.0184, 0.1333, 0.0834, 0.0508, 0.0569, 0.0986,
        0.0185, 0.0246, 0.0984, 0.1387, 0.1273, 0.0448], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,084][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0006, 0.0213, 0.0369, 0.0619, 0.0441, 0.1196, 0.1348, 0.0955, 0.0416,
        0.1040, 0.0781, 0.0918, 0.0231, 0.0501, 0.0966], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,088][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0910, 0.0542, 0.0579, 0.0707, 0.0601, 0.0938, 0.0656, 0.0485, 0.0433,
        0.0764, 0.0716, 0.0543, 0.0603, 0.0944, 0.0579], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,091][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0066, 0.0204, 0.0632, 0.0576, 0.0739, 0.1147, 0.1492, 0.0295, 0.0921,
        0.0793, 0.0659, 0.0429, 0.0628, 0.1087, 0.0333], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,095][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0484, 0.0690, 0.0797, 0.0735, 0.0808, 0.0595, 0.0750, 0.0695, 0.0471,
        0.0676, 0.0671, 0.0620, 0.0793, 0.0584, 0.0631], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,097][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.0886e-04, 3.4645e-06, 8.4437e-02, 1.1858e-04, 9.7396e-02, 9.3458e-05,
        4.2962e-03, 4.1615e-03, 1.9375e-01, 6.0253e-04, 1.2694e-03, 1.1117e-01,
        4.9249e-01, 9.6089e-03, 3.9878e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,101][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0489, 0.0686, 0.0804, 0.0690, 0.0733, 0.0620, 0.0661, 0.0698, 0.0669,
        0.0650, 0.0585, 0.0688, 0.0735, 0.0656, 0.0637], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,103][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([7.4438e-01, 4.7186e-06, 8.3967e-05, 1.7552e-05, 4.5250e-04, 3.2839e-04,
        2.1792e-04, 2.1955e-04, 2.5388e-03, 3.4915e-03, 5.9946e-03, 2.3546e-02,
        9.0979e-02, 1.2113e-01, 6.6124e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,106][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0615, 0.0674, 0.0749, 0.0725, 0.0656, 0.0741, 0.0769, 0.0747, 0.0533,
        0.0704, 0.0710, 0.0592, 0.0648, 0.0559, 0.0577], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,106][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.1863e-01, 2.7051e-05, 4.4115e-05, 4.1244e-05, 2.8225e-05, 2.1201e-05,
        1.2071e-04, 1.7067e-03, 1.9346e-03, 2.1345e-03, 2.9194e-03, 9.8282e-03,
        5.0325e-03, 4.6510e-02, 1.1020e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,150][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:38,153][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,156][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,159][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,162][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,162][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,162][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,163][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,163][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,163][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,164][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,164][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,164][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,166][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5773, 0.4227], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,168][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4184, 0.5816], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,172][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0456, 0.9544], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,176][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1105, 0.8895], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,179][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5638, 0.4362], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,183][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4308, 0.5692], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,187][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9967, 0.0033], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,190][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3791, 0.6209], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,190][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3929, 0.6071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,191][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9957, 0.0043], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,191][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7039, 0.2961], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,191][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9922, 0.0078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,192][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.4210, 0.3160, 0.2630], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,192][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.2594, 0.3544, 0.3862], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,192][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.0193, 0.3301, 0.6506], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,193][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([2.9087e-01, 6.3156e-06, 7.0912e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,193][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.3833, 0.3078, 0.3089], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,195][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([0.2455, 0.3468, 0.4078], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,197][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.9758, 0.0088, 0.0154], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,201][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.2553, 0.3899, 0.3548], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,205][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.2415, 0.3616, 0.3969], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,208][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.9794, 0.0096, 0.0110], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,212][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.4960, 0.2173, 0.2867], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,216][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.9781, 0.0161, 0.0059], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,219][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3322, 0.2558, 0.2153, 0.1966], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,219][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1800, 0.2502, 0.2812, 0.2886], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,220][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0148, 0.2457, 0.5022, 0.2372], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,220][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.1664e-05, 1.4069e-05, 9.9990e-01, 3.8873e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,220][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2806, 0.2280, 0.2366, 0.2548], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,221][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1722, 0.2299, 0.2898, 0.3081], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,221][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9510, 0.0051, 0.0417, 0.0022], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,221][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1603, 0.2915, 0.2793, 0.2689], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,223][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1596, 0.2523, 0.2921, 0.2960], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,226][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9511, 0.0252, 0.0146, 0.0091], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,230][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3890, 0.1914, 0.2118, 0.2078], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,234][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9570, 0.0138, 0.0139, 0.0153], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,237][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.2771, 0.2107, 0.1753, 0.1606, 0.1763], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,241][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.1344, 0.1975, 0.2186, 0.2280, 0.2215], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,245][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0176, 0.1584, 0.3240, 0.1962, 0.3038], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,247][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([6.9537e-02, 7.4687e-07, 2.1338e-01, 2.6188e-05, 7.1706e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,248][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.2310, 0.1825, 0.1859, 0.1999, 0.2006], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,248][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.1330, 0.1852, 0.2286, 0.2517, 0.2016], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,248][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.9224, 0.0174, 0.0263, 0.0098, 0.0240], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,249][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1317, 0.2278, 0.2165, 0.2126, 0.2114], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,249][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1207, 0.1969, 0.2185, 0.2368, 0.2272], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,249][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.8964, 0.0182, 0.0230, 0.0129, 0.0495], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,250][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.3228, 0.1420, 0.1810, 0.1915, 0.1627], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,250][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.9072, 0.0203, 0.0264, 0.0214, 0.0248], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,250][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2338, 0.1842, 0.1523, 0.1381, 0.1519, 0.1397], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,252][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1187, 0.1640, 0.1811, 0.1881, 0.1808, 0.1673], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,255][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0088, 0.1108, 0.2904, 0.1520, 0.2484, 0.1896], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,257][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([1.0411e-02, 6.3366e-06, 5.8327e-01, 4.9942e-05, 3.8232e-01, 2.3945e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,261][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1801, 0.1526, 0.1536, 0.1703, 0.1692, 0.1742], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,265][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1059, 0.1407, 0.1808, 0.1939, 0.1635, 0.2151], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,268][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.8652, 0.0079, 0.0622, 0.0108, 0.0424, 0.0115], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,272][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1282, 0.1842, 0.1765, 0.1641, 0.1702, 0.1768], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,276][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1001, 0.1582, 0.1833, 0.1891, 0.1859, 0.1834], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,276][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.8646, 0.0486, 0.0088, 0.0127, 0.0354, 0.0299], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,277][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3240, 0.1155, 0.1321, 0.1397, 0.1137, 0.1750], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,277][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.9207, 0.0139, 0.0107, 0.0342, 0.0044, 0.0161], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,278][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2001, 0.1577, 0.1340, 0.1197, 0.1324, 0.1206, 0.1355],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,278][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1037, 0.1386, 0.1518, 0.1569, 0.1528, 0.1424, 0.1539],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,278][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0092, 0.0981, 0.2358, 0.1386, 0.2094, 0.1981, 0.1108],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,279][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.5967e-01, 1.1784e-05, 4.8853e-01, 5.4676e-05, 3.1348e-01, 2.0310e-02,
        1.7955e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,280][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1465, 0.1300, 0.1319, 0.1458, 0.1463, 0.1479, 0.1515],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,283][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0934, 0.1176, 0.1469, 0.1532, 0.1329, 0.1728, 0.1832],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,287][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.9681, 0.0018, 0.0094, 0.0028, 0.0074, 0.0071, 0.0034],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,291][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0965, 0.1483, 0.1503, 0.1361, 0.1435, 0.1507, 0.1747],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,294][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0882, 0.1330, 0.1559, 0.1584, 0.1570, 0.1546, 0.1529],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,298][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8216, 0.0114, 0.0090, 0.0200, 0.0229, 0.0914, 0.0236],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,302][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2310, 0.1111, 0.1229, 0.1270, 0.1101, 0.1568, 0.1411],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,305][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.9542, 0.0062, 0.0071, 0.0114, 0.0038, 0.0116, 0.0058],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,305][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1832, 0.1377, 0.1156, 0.1038, 0.1139, 0.1046, 0.1207, 0.1204],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,305][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0792, 0.1208, 0.1348, 0.1405, 0.1354, 0.1275, 0.1373, 0.1245],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,306][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0100, 0.0750, 0.1787, 0.0990, 0.1477, 0.1514, 0.1000, 0.2384],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,306][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([2.0257e-03, 2.7152e-11, 2.5666e-05, 3.3015e-09, 2.2889e-04, 5.6205e-06,
        1.0815e-04, 9.9761e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,307][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1362, 0.1080, 0.1136, 0.1233, 0.1238, 0.1256, 0.1210, 0.1485],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,307][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0736, 0.1010, 0.1258, 0.1439, 0.1144, 0.1618, 0.1805, 0.0990],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,307][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([9.7367e-01, 2.1622e-04, 1.2823e-03, 3.2288e-04, 6.8894e-04, 1.1004e-03,
        1.6257e-03, 2.1098e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,309][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0726, 0.1219, 0.1229, 0.1182, 0.1210, 0.1374, 0.1632, 0.1429],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,311][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0653, 0.1159, 0.1310, 0.1471, 0.1372, 0.1411, 0.1367, 0.1256],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,313][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([9.1333e-01, 2.7257e-03, 8.5426e-04, 2.9478e-03, 5.4611e-03, 1.3144e-02,
        9.6361e-03, 5.1902e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,316][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2427, 0.0812, 0.1006, 0.1051, 0.0874, 0.1277, 0.1254, 0.1297],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,319][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([9.7152e-01, 4.7172e-04, 5.8577e-04, 9.6870e-04, 2.6348e-04, 7.2174e-04,
        2.2886e-03, 2.3183e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,323][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1663, 0.1260, 0.1056, 0.0960, 0.1041, 0.0949, 0.1091, 0.1093, 0.0887],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,327][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0686, 0.1085, 0.1221, 0.1285, 0.1215, 0.1165, 0.1270, 0.1127, 0.0947],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,330][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0085, 0.0588, 0.1426, 0.0749, 0.1148, 0.1148, 0.0790, 0.1921, 0.2146],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,332][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([2.2878e-03, 9.2390e-12, 9.3787e-06, 1.1512e-09, 2.4545e-05, 4.1632e-06,
        3.0673e-05, 8.9287e-01, 1.0477e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,334][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1196, 0.0989, 0.1015, 0.1120, 0.1126, 0.1155, 0.1134, 0.1360, 0.0904],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,334][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0646, 0.0896, 0.1144, 0.1293, 0.1019, 0.1438, 0.1612, 0.0896, 0.1056],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,335][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([9.5510e-01, 2.2760e-04, 1.5226e-03, 2.1333e-04, 9.0246e-04, 5.3242e-04,
        8.8607e-04, 3.3028e-02, 7.5831e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,335][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0624, 0.1075, 0.1045, 0.0987, 0.1047, 0.1179, 0.1477, 0.1328, 0.1239],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,335][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0547, 0.1007, 0.1134, 0.1309, 0.1208, 0.1290, 0.1254, 0.1139, 0.1111],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,336][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([9.5333e-01, 6.6536e-04, 1.2071e-03, 8.4031e-04, 6.5225e-03, 6.9168e-03,
        2.0340e-03, 1.3023e-02, 1.5463e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,336][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2155, 0.0684, 0.0816, 0.0899, 0.0722, 0.1052, 0.1071, 0.1062, 0.1538],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,337][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([8.7049e-01, 5.0998e-04, 5.6929e-04, 7.1372e-04, 1.1507e-04, 7.3106e-04,
        1.8368e-03, 1.1665e-01, 8.3855e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,340][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1497, 0.1141, 0.0959, 0.0875, 0.0957, 0.0888, 0.1000, 0.0994, 0.0814,
        0.0875], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,343][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0679, 0.0969, 0.1110, 0.1148, 0.1090, 0.1039, 0.1126, 0.1015, 0.0859,
        0.0965], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,347][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0071, 0.0612, 0.1349, 0.0658, 0.0883, 0.0917, 0.0648, 0.1636, 0.1971,
        0.1254], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,349][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([4.1298e-04, 3.7394e-11, 4.3167e-05, 1.4592e-09, 2.8683e-05, 1.9449e-06,
        1.7544e-05, 9.7440e-01, 2.0941e-02, 4.1535e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,353][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1051, 0.0874, 0.0909, 0.1017, 0.1028, 0.1053, 0.1068, 0.1201, 0.0842,
        0.0957], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,356][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0607, 0.0806, 0.1016, 0.1102, 0.0922, 0.1231, 0.1352, 0.0817, 0.0938,
        0.1209], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,358][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.7385e-01, 4.8480e-05, 1.0106e-03, 1.3096e-04, 4.5548e-04, 3.3358e-04,
        3.1049e-04, 1.1251e-02, 6.8620e-03, 5.7441e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,362][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0439, 0.0942, 0.0974, 0.0892, 0.0922, 0.1057, 0.1306, 0.1249, 0.1149,
        0.1068], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,363][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0564, 0.0917, 0.1070, 0.1125, 0.1083, 0.1105, 0.1087, 0.1032, 0.1015,
        0.1003], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,363][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([9.6506e-01, 1.1385e-04, 6.2714e-04, 1.0922e-03, 1.9606e-03, 1.5011e-03,
        9.3210e-04, 8.1222e-03, 6.5678e-03, 1.4019e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,363][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1436, 0.0724, 0.0767, 0.0803, 0.0653, 0.0887, 0.0889, 0.0976, 0.1348,
        0.1517], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,364][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.3798e-01, 1.7895e-04, 3.7196e-04, 6.8863e-04, 1.3069e-04, 4.0655e-04,
        1.7692e-03, 3.5259e-02, 8.6665e-03, 1.4544e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,364][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1311, 0.1028, 0.0894, 0.0809, 0.0889, 0.0820, 0.0910, 0.0911, 0.0760,
        0.0822, 0.0847], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,365][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0651, 0.0882, 0.0993, 0.1023, 0.0988, 0.0916, 0.0992, 0.0930, 0.0801,
        0.0871, 0.0954], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,365][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0057, 0.0497, 0.1093, 0.0557, 0.0878, 0.0908, 0.0586, 0.1510, 0.1837,
        0.1192, 0.0886], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,366][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.9784e-02, 3.2910e-10, 1.2818e-04, 3.1805e-09, 9.8074e-05, 1.3483e-06,
        1.6048e-05, 8.1317e-01, 4.0721e-02, 1.7579e-02, 7.8501e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,368][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0907, 0.0788, 0.0801, 0.0906, 0.0907, 0.0948, 0.0957, 0.1097, 0.0765,
        0.0877, 0.1046], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,371][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0536, 0.0722, 0.0907, 0.0983, 0.0831, 0.1116, 0.1227, 0.0746, 0.0831,
        0.1081, 0.1020], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,373][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.7900e-01, 2.5967e-05, 4.7550e-04, 1.2993e-05, 3.0486e-04, 1.9039e-04,
        1.9701e-04, 5.2698e-03, 4.1267e-03, 6.5914e-03, 3.8054e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,377][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0477, 0.0851, 0.0898, 0.0815, 0.0847, 0.0911, 0.1113, 0.1128, 0.1091,
        0.1015, 0.0854], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,380][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0558, 0.0848, 0.0987, 0.1003, 0.0998, 0.0967, 0.0948, 0.0941, 0.0944,
        0.0889, 0.0914], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,383][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.4800e-01, 2.2019e-04, 1.3238e-04, 1.2237e-04, 3.7211e-04, 9.3609e-04,
        5.1155e-04, 2.4111e-03, 3.2950e-03, 2.1881e-02, 2.2115e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,386][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1131, 0.0699, 0.0709, 0.0722, 0.0613, 0.0824, 0.0793, 0.0930, 0.1281,
        0.1292, 0.1005], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,389][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.4975e-01, 1.0115e-04, 2.8526e-04, 1.2814e-04, 1.0172e-04, 3.4642e-04,
        1.0317e-03, 1.2617e-02, 7.6964e-03, 1.3579e-02, 1.4366e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,392][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1250, 0.0953, 0.0814, 0.0735, 0.0808, 0.0748, 0.0844, 0.0833, 0.0674,
        0.0751, 0.0772, 0.0818], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,394][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0543, 0.0798, 0.0904, 0.0936, 0.0904, 0.0851, 0.0924, 0.0862, 0.0735,
        0.0802, 0.0894, 0.0846], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,394][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0064, 0.0411, 0.0891, 0.0563, 0.0830, 0.0780, 0.0510, 0.1285, 0.1514,
        0.1040, 0.0878, 0.1232], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,394][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([4.0967e-02, 3.3239e-13, 9.6642e-08, 2.9898e-11, 3.2712e-07, 7.3110e-08,
        4.3209e-07, 9.5278e-03, 5.9842e-04, 5.8076e-04, 9.8585e-03, 9.3847e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,395][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0907, 0.0718, 0.0754, 0.0821, 0.0820, 0.0865, 0.0845, 0.1004, 0.0692,
        0.0751, 0.0890, 0.0932], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,395][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0445, 0.0657, 0.0796, 0.0967, 0.0745, 0.1075, 0.1203, 0.0663, 0.0757,
        0.1070, 0.1007, 0.0615], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,396][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([9.4878e-01, 1.7980e-04, 7.2622e-04, 1.6515e-04, 5.5323e-04, 8.6272e-04,
        3.1827e-04, 8.2596e-03, 4.6487e-03, 1.1372e-02, 1.0428e-02, 1.3711e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,396][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0372, 0.0811, 0.0801, 0.0767, 0.0785, 0.0925, 0.1109, 0.0942, 0.0990,
        0.0947, 0.0897, 0.0655], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,396][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0480, 0.0772, 0.0869, 0.0942, 0.0899, 0.0895, 0.0888, 0.0835, 0.0836,
        0.0837, 0.0881, 0.0865], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,397][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([8.2483e-01, 6.6660e-04, 1.3615e-03, 8.4706e-04, 6.8002e-03, 3.7764e-03,
        1.1476e-03, 1.5236e-02, 1.4962e-02, 3.1685e-02, 4.1558e-02, 5.7129e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,400][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1333, 0.0512, 0.0616, 0.0638, 0.0548, 0.0724, 0.0721, 0.0800, 0.1045,
        0.1190, 0.0942, 0.0930], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,402][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([9.2260e-01, 2.5254e-04, 8.1259e-04, 4.5476e-04, 3.1067e-04, 3.8089e-04,
        8.4707e-04, 1.4037e-02, 6.1298e-03, 1.2226e-02, 1.6339e-02, 2.5607e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,405][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.1138, 0.0887, 0.0753, 0.0685, 0.0751, 0.0692, 0.0774, 0.0779, 0.0640,
        0.0697, 0.0718, 0.0766, 0.0720], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,409][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0504, 0.0739, 0.0826, 0.0871, 0.0832, 0.0784, 0.0856, 0.0796, 0.0679,
        0.0744, 0.0832, 0.0786, 0.0751], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,413][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0056, 0.0319, 0.0718, 0.0484, 0.0721, 0.0749, 0.0461, 0.1124, 0.1414,
        0.0905, 0.0769, 0.1178, 0.1102], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,415][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([2.5810e-02, 2.8532e-13, 1.6490e-07, 2.6891e-11, 4.5303e-07, 4.4739e-08,
        4.8670e-07, 7.5601e-04, 1.0648e-04, 9.3450e-05, 2.0492e-03, 1.4657e-01,
        8.2462e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,419][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0820, 0.0695, 0.0708, 0.0757, 0.0751, 0.0781, 0.0761, 0.0921, 0.0666,
        0.0725, 0.0807, 0.0829, 0.0779], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,422][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0423, 0.0614, 0.0772, 0.0866, 0.0682, 0.1024, 0.1128, 0.0605, 0.0730,
        0.1015, 0.0918, 0.0592, 0.0631], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,423][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.6651e-01, 8.1029e-05, 2.4325e-04, 4.8298e-05, 1.2840e-04, 9.5287e-05,
        8.9540e-05, 1.9527e-03, 8.3806e-04, 2.6151e-03, 4.9749e-03, 3.5743e-03,
        1.8848e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,423][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0407, 0.0724, 0.0731, 0.0684, 0.0701, 0.0821, 0.1019, 0.0934, 0.0872,
        0.0845, 0.0820, 0.0691, 0.0752], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,424][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0422, 0.0699, 0.0785, 0.0866, 0.0829, 0.0843, 0.0829, 0.0791, 0.0790,
        0.0787, 0.0814, 0.0808, 0.0736], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,424][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([9.1369e-01, 2.4744e-04, 3.6056e-04, 2.6492e-04, 7.5390e-04, 7.6323e-04,
        6.8157e-04, 1.5185e-03, 2.1775e-03, 9.6864e-03, 1.4328e-02, 1.1090e-02,
        4.4434e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,425][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0974, 0.0478, 0.0591, 0.0608, 0.0541, 0.0762, 0.0696, 0.0781, 0.1111,
        0.1100, 0.0893, 0.0841, 0.0621], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,425][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([9.4098e-01, 1.7930e-04, 5.7942e-04, 2.8504e-04, 2.8460e-04, 3.8302e-04,
        7.8381e-04, 1.4459e-03, 4.7032e-03, 4.6189e-03, 8.1480e-03, 2.2636e-02,
        1.4969e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,425][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1112, 0.0857, 0.0702, 0.0644, 0.0697, 0.0639, 0.0725, 0.0729, 0.0598,
        0.0653, 0.0677, 0.0717, 0.0664, 0.0587], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,426][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0487, 0.0703, 0.0778, 0.0804, 0.0770, 0.0727, 0.0792, 0.0722, 0.0621,
        0.0687, 0.0770, 0.0719, 0.0697, 0.0723], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,428][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0058, 0.0304, 0.0636, 0.0442, 0.0671, 0.0665, 0.0426, 0.1003, 0.1190,
        0.0825, 0.0708, 0.1026, 0.1043, 0.1004], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,430][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.2477e-02, 1.5442e-13, 1.9678e-07, 6.3286e-12, 2.2034e-07, 2.6627e-09,
        8.6294e-08, 4.9277e-04, 6.0083e-05, 4.6933e-05, 7.6070e-04, 2.1965e-01,
        6.7347e-01, 9.3039e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,432][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0775, 0.0640, 0.0651, 0.0707, 0.0703, 0.0726, 0.0728, 0.0858, 0.0603,
        0.0657, 0.0765, 0.0787, 0.0712, 0.0688], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,436][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0424, 0.0570, 0.0731, 0.0799, 0.0660, 0.0901, 0.1006, 0.0572, 0.0675,
        0.0902, 0.0848, 0.0561, 0.0616, 0.0737], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,439][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([9.8351e-01, 8.2048e-06, 6.2160e-05, 7.7259e-06, 4.2585e-05, 1.0291e-05,
        1.1882e-05, 3.1616e-04, 2.7374e-04, 1.0554e-03, 9.5498e-04, 1.3060e-03,
        1.0643e-02, 1.7984e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,443][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0447, 0.0701, 0.0676, 0.0631, 0.0664, 0.0726, 0.0904, 0.0882, 0.0796,
        0.0795, 0.0748, 0.0645, 0.0728, 0.0657], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,446][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0380, 0.0645, 0.0738, 0.0808, 0.0768, 0.0779, 0.0769, 0.0729, 0.0731,
        0.0717, 0.0756, 0.0763, 0.0675, 0.0744], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,448][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([9.5449e-01, 5.9613e-05, 3.4418e-05, 3.9711e-05, 1.3173e-04, 8.8356e-05,
        4.9365e-05, 2.6811e-04, 1.3007e-04, 3.0762e-03, 2.9210e-03, 2.3440e-02,
        1.1740e-02, 3.5301e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,452][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1200, 0.0440, 0.0509, 0.0533, 0.0449, 0.0612, 0.0593, 0.0655, 0.0912,
        0.0999, 0.0780, 0.0765, 0.0510, 0.1043], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,452][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([9.7603e-01, 2.4701e-05, 1.8178e-05, 4.5782e-05, 7.9906e-06, 3.4059e-05,
        4.9850e-05, 7.1809e-04, 5.9287e-04, 9.6034e-04, 1.4365e-03, 1.4854e-02,
        8.8441e-04, 4.3415e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,453][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0995, 0.0779, 0.0666, 0.0601, 0.0668, 0.0610, 0.0684, 0.0689, 0.0571,
        0.0618, 0.0637, 0.0680, 0.0641, 0.0560, 0.0600], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,453][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0465, 0.0644, 0.0715, 0.0733, 0.0706, 0.0672, 0.0727, 0.0670, 0.0583,
        0.0639, 0.0701, 0.0659, 0.0651, 0.0677, 0.0758], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,454][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0044, 0.0287, 0.0637, 0.0392, 0.0555, 0.0562, 0.0370, 0.0927, 0.1105,
        0.0770, 0.0623, 0.0922, 0.0878, 0.0984, 0.0942], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,454][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.1772e-02, 1.5831e-14, 8.3122e-09, 8.1545e-13, 2.3001e-08, 2.1619e-09,
        5.4319e-08, 7.5032e-05, 1.7147e-05, 9.1125e-06, 2.1234e-04, 5.4257e-02,
        1.4582e-01, 9.7018e-02, 6.7082e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,456][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0648, 0.0570, 0.0582, 0.0646, 0.0655, 0.0661, 0.0671, 0.0817, 0.0566,
        0.0612, 0.0723, 0.0779, 0.0666, 0.0653, 0.0751], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,458][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0410, 0.0545, 0.0683, 0.0746, 0.0608, 0.0848, 0.0936, 0.0558, 0.0641,
        0.0822, 0.0784, 0.0523, 0.0568, 0.0686, 0.0641], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,460][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8261e-01, 2.7643e-06, 3.9913e-05, 2.5710e-06, 1.9387e-05, 9.3077e-06,
        7.2661e-06, 2.1665e-04, 1.8275e-04, 4.1762e-04, 4.6331e-04, 1.0302e-03,
        7.2093e-03, 4.4014e-03, 3.3869e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,464][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0406, 0.0640, 0.0663, 0.0603, 0.0624, 0.0674, 0.0798, 0.0790, 0.0771,
        0.0725, 0.0666, 0.0587, 0.0669, 0.0623, 0.0761], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,468][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0378, 0.0600, 0.0707, 0.0740, 0.0722, 0.0713, 0.0705, 0.0688, 0.0684,
        0.0653, 0.0679, 0.0703, 0.0630, 0.0681, 0.0716], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,470][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.9970e-01, 2.7685e-05, 3.2925e-05, 2.4855e-05, 9.7815e-05, 1.3415e-04,
        7.6605e-05, 1.2885e-04, 2.4038e-03, 3.8167e-03, 4.8319e-03, 1.1283e-02,
        1.3713e-02, 1.6061e-01, 3.1154e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,474][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0964, 0.0443, 0.0467, 0.0498, 0.0409, 0.0557, 0.0545, 0.0611, 0.0835,
        0.0887, 0.0706, 0.0735, 0.0453, 0.0955, 0.0935], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,476][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.1863e-01, 2.7051e-05, 4.4115e-05, 4.1244e-05, 2.8225e-05, 2.1201e-05,
        1.2071e-04, 1.7067e-03, 1.9346e-03, 2.1345e-03, 2.9194e-03, 9.8282e-03,
        5.0325e-03, 4.6510e-02, 1.1020e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,477][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:38,480][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10400],
        [28921],
        [19396],
        [31494],
        [28655],
        [27886],
        [37953],
        [32706],
        [37582],
        [38972],
        [36800],
        [29109],
        [23027],
        [28727],
        [42950]], device='cuda:0')
[2024-07-24 10:20:38,482][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10493],
        [31718],
        [24432],
        [32192],
        [32431],
        [32024],
        [37826],
        [38654],
        [39813],
        [34057],
        [30822],
        [32680],
        [35699],
        [33714],
        [39870]], device='cuda:0')
[2024-07-24 10:20:38,483][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12574],
        [12752],
        [12668],
        [12660],
        [12625],
        [13138],
        [13008],
        [12802],
        [12649],
        [12856],
        [12971],
        [12681],
        [12670],
        [12849],
        [13631]], device='cuda:0')
[2024-07-24 10:20:38,484][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[6643],
        [6643],
        [5051],
        [6533],
        [5735],
        [6069],
        [5755],
        [6214],
        [6279],
        [6375],
        [6654],
        [7300],
        [7031],
        [6708],
        [6774]], device='cuda:0')
[2024-07-24 10:20:38,485][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14545],
        [15526],
        [16270],
        [16610],
        [13526],
        [14282],
        [14936],
        [16063],
        [16457],
        [15742],
        [14627],
        [12213],
        [10030],
        [10301],
        [10474]], device='cuda:0')
[2024-07-24 10:20:38,486][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36203],
        [35054],
        [42310],
        [40613],
        [42752],
        [42395],
        [41149],
        [41517],
        [41379],
        [41827],
        [41039],
        [41102],
        [41534],
        [41682],
        [41391]], device='cuda:0')
[2024-07-24 10:20:38,487][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[16579],
        [17088],
        [18382],
        [20305],
        [21486],
        [21124],
        [22098],
        [22948],
        [22553],
        [22371],
        [22224],
        [22335],
        [22530],
        [22732],
        [22771]], device='cuda:0')
[2024-07-24 10:20:38,488][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[46576],
        [45753],
        [43448],
        [43101],
        [45143],
        [45884],
        [46222],
        [46462],
        [46990],
        [46981],
        [46821],
        [47132],
        [47339],
        [47843],
        [47771]], device='cuda:0')
[2024-07-24 10:20:38,491][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29274],
        [35052],
        [35097],
        [36035],
        [36931],
        [36548],
        [35615],
        [35488],
        [35440],
        [35836],
        [35670],
        [35611],
        [36080],
        [35988],
        [35973]], device='cuda:0')
[2024-07-24 10:20:38,492][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[16482],
        [20004],
        [43747],
        [48736],
        [48735],
        [47709],
        [45649],
        [48834],
        [47405],
        [47065],
        [47331],
        [45936],
        [13027],
        [25803],
        [36794]], device='cuda:0')
[2024-07-24 10:20:38,494][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3639],
        [ 5085],
        [ 7100],
        [ 8665],
        [ 9476],
        [ 9938],
        [10299],
        [10085],
        [10344],
        [10912],
        [11332],
        [11488],
        [11474],
        [11654],
        [11838]], device='cuda:0')
[2024-07-24 10:20:38,496][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[5354],
        [5682],
        [5495],
        [7216],
        [5139],
        [6610],
        [8888],
        [6997],
        [5897],
        [6832],
        [7787],
        [9223],
        [4966],
        [5332],
        [8452]], device='cuda:0')
[2024-07-24 10:20:38,499][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 6206],
        [ 6442],
        [10043],
        [10207],
        [ 9368],
        [ 9599],
        [11048],
        [10633],
        [10678],
        [10009],
        [10143],
        [ 9661],
        [ 9099],
        [ 9323],
        [ 9136]], device='cuda:0')
[2024-07-24 10:20:38,501][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30575],
        [30635],
        [30768],
        [31394],
        [32933],
        [31815],
        [31076],
        [30985],
        [32264],
        [31228],
        [31272],
        [31717],
        [31929],
        [30851],
        [30523]], device='cuda:0')
[2024-07-24 10:20:38,504][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 2181],
        [ 4134],
        [ 2857],
        [ 5123],
        [  457],
        [ 1834],
        [21806],
        [ 1309],
        [ 3000],
        [22654],
        [23971],
        [11711],
        [  952],
        [ 5242],
        [24675]], device='cuda:0')
[2024-07-24 10:20:38,506][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[40683],
        [42660],
        [43818],
        [44324],
        [44674],
        [45096],
        [45212],
        [45254],
        [45480],
        [45503],
        [45520],
        [45466],
        [45536],
        [45579],
        [45559]], device='cuda:0')
[2024-07-24 10:20:38,509][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26386],
        [27703],
        [24912],
        [24717],
        [24190],
        [24427],
        [24234],
        [24589],
        [24546],
        [24454],
        [24437],
        [24299],
        [24107],
        [23992],
        [23824]], device='cuda:0')
[2024-07-24 10:20:38,511][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29195],
        [21966],
        [26855],
        [26099],
        [27516],
        [28788],
        [28668],
        [28558],
        [29647],
        [28618],
        [28276],
        [29909],
        [29962],
        [29706],
        [29159]], device='cuda:0')
[2024-07-24 10:20:38,514][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31884],
        [19907],
        [27877],
        [27072],
        [20818],
        [23464],
        [22392],
        [ 7889],
        [ 7888],
        [ 7866],
        [ 9483],
        [20906],
        [23713],
        [20423],
        [15295]], device='cuda:0')
[2024-07-24 10:20:38,516][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[42421],
        [43713],
        [44869],
        [45065],
        [45193],
        [45251],
        [44959],
        [43867],
        [43490],
        [43375],
        [43269],
        [43023],
        [42933],
        [42939],
        [42721]], device='cuda:0')
[2024-07-24 10:20:38,517][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17651],
        [21205],
        [25472],
        [25534],
        [25509],
        [23395],
        [23370],
        [22829],
        [22110],
        [21898],
        [22155],
        [22682],
        [23159],
        [23688],
        [23383]], device='cuda:0')
[2024-07-24 10:20:38,518][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[2198],
        [2179],
        [2313],
        [2650],
        [2708],
        [3625],
        [2473],
        [2441],
        [2571],
        [2303],
        [2251],
        [2502],
        [2428],
        [2311],
        [2366]], device='cuda:0')
[2024-07-24 10:20:38,519][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[24279],
        [13925],
        [16806],
        [17289],
        [16575],
        [15387],
        [13816],
        [14753],
        [15787],
        [15517],
        [15015],
        [14483],
        [14858],
        [15338],
        [14944]], device='cuda:0')
[2024-07-24 10:20:38,520][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 918],
        [1698],
        [1958],
        [1962],
        [1960],
        [1732],
        [1618],
        [1708],
        [1909],
        [1930],
        [1875],
        [1802],
        [1835],
        [1781],
        [1724]], device='cuda:0')
[2024-07-24 10:20:38,521][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14172],
        [13974],
        [13696],
        [12703],
        [12746],
        [11786],
        [13145],
        [13561],
        [13638],
        [13430],
        [12821],
        [10345],
        [13461],
        [13766],
        [17856]], device='cuda:0')
[2024-07-24 10:20:38,524][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20366],
        [25540],
        [27837],
        [29587],
        [29791],
        [29183],
        [29160],
        [27752],
        [26671],
        [26849],
        [26643],
        [25850],
        [25583],
        [25634],
        [25539]], device='cuda:0')
[2024-07-24 10:20:38,525][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1635],
        [1644],
        [1654],
        [1637],
        [1670],
        [1636],
        [1632],
        [1752],
        [2483],
        [1815],
        [1684],
        [1691],
        [1644],
        [1628],
        [1521]], device='cuda:0')
[2024-07-24 10:20:38,527][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[29289],
        [30459],
        [26153],
        [25262],
        [26697],
        [26160],
        [27254],
        [28201],
        [27176],
        [28091],
        [28397],
        [29060],
        [27553],
        [27970],
        [27030]], device='cuda:0')
[2024-07-24 10:20:38,529][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27582],
        [10074],
        [12061],
        [15481],
        [17425],
        [16187],
        [ 8545],
        [20494],
        [17717],
        [16807],
        [17750],
        [ 8011],
        [18316],
        [13645],
        [14838]], device='cuda:0')
[2024-07-24 10:20:38,532][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709],
        [24709]], device='cuda:0')
[2024-07-24 10:20:38,567][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:38,567][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,568][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,568][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,568][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,569][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,569][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,569][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,570][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,572][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,575][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,577][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,577][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,577][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0487, 0.9513], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,578][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7689, 0.2311], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,578][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3268, 0.6732], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,578][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9942, 0.0058], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,579][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4758, 0.5242], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,579][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1671, 0.8329], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,579][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2934, 0.7066], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,579][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8773, 0.1227], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,580][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7891, 0.2109], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,580][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8567, 0.1433], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,580][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2467, 0.7533], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,581][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,581][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.0104, 0.5030, 0.4866], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,581][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.6826, 0.2285, 0.0890], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,582][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.1687, 0.3462, 0.4851], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,582][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.8815, 0.0324, 0.0861], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,582][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.3062, 0.3323, 0.3615], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,583][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.0943, 0.5844, 0.3213], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,583][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.1280, 0.4600, 0.4120], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,583][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.6760, 0.0966, 0.2274], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,584][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.8070, 0.1308, 0.0622], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,584][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.7355, 0.1206, 0.1439], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,584][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.1269, 0.4284, 0.4447], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,585][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([1.0787e-04, 5.5647e-01, 4.4342e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,585][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0092, 0.3185, 0.4150, 0.2574], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,585][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3964, 0.2800, 0.1385, 0.1852], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,586][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1140, 0.2598, 0.3647, 0.2615], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,586][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9177, 0.0082, 0.0637, 0.0104], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,586][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2214, 0.2408, 0.2614, 0.2764], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,587][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0381, 0.3793, 0.2021, 0.3805], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,587][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0780, 0.2557, 0.3429, 0.3234], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,590][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5731, 0.0808, 0.1907, 0.1554], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,590][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5395, 0.1715, 0.0750, 0.2140], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,590][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6901, 0.0961, 0.1175, 0.0963], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,591][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0851, 0.2956, 0.3096, 0.3097], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,591][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.7617e-04, 2.8010e-01, 6.2146e-01, 9.8066e-02], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,591][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0087, 0.2519, 0.2675, 0.2321, 0.2398], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,592][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.3899, 0.1988, 0.0877, 0.2613, 0.0623], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,592][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0958, 0.1911, 0.2693, 0.2023, 0.2416], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,594][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.7885, 0.0203, 0.0634, 0.0590, 0.0688], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,596][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1783, 0.1932, 0.2092, 0.2205, 0.1989], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,600][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0535, 0.2875, 0.1713, 0.3215, 0.1662], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,603][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0591, 0.2278, 0.2226, 0.2945, 0.1959], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,607][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.4523, 0.0742, 0.1805, 0.1303, 0.1626], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,611][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.5377, 0.1230, 0.0564, 0.1739, 0.1090], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,614][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.6249, 0.0812, 0.0993, 0.0816, 0.1130], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,618][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0688, 0.2296, 0.2355, 0.2388, 0.2273], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,618][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([1.7647e-07, 2.8079e-03, 2.8676e-03, 2.2079e-03, 9.9212e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,618][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0083, 0.2111, 0.2263, 0.1923, 0.2054, 0.1567], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,619][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.3440, 0.1557, 0.0449, 0.1786, 0.0452, 0.2315], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,619][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0717, 0.1555, 0.2173, 0.1611, 0.1961, 0.1982], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,619][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.8279, 0.0170, 0.0595, 0.0344, 0.0533, 0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,620][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1472, 0.1572, 0.1705, 0.1780, 0.1631, 0.1840], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,620][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0317, 0.2264, 0.1466, 0.2990, 0.1528, 0.1436], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,620][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0503, 0.1539, 0.2120, 0.2060, 0.2282, 0.1496], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,621][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4453, 0.0546, 0.1303, 0.1082, 0.1012, 0.1604], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,622][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.4590, 0.1317, 0.0562, 0.1579, 0.1047, 0.0906], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,625][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.5662, 0.0752, 0.0924, 0.0755, 0.1085, 0.0822], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,628][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0589, 0.1841, 0.1898, 0.1922, 0.1842, 0.1909], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,630][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([4.8125e-07, 4.4042e-04, 1.6599e-03, 5.0011e-04, 6.0870e-01, 3.8870e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,634][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0061, 0.1812, 0.2112, 0.1496, 0.1863, 0.1498, 0.1158],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,637][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2237, 0.1280, 0.0629, 0.1286, 0.0588, 0.3405, 0.0574],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,641][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0621, 0.1332, 0.1844, 0.1351, 0.1666, 0.1652, 0.1535],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,644][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.7597, 0.0255, 0.0707, 0.0478, 0.0426, 0.0225, 0.0312],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,647][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1255, 0.1327, 0.1456, 0.1507, 0.1390, 0.1560, 0.1503],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,647][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0229, 0.2172, 0.1276, 0.2506, 0.1377, 0.1351, 0.1089],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,647][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0377, 0.1331, 0.1733, 0.1879, 0.1887, 0.1580, 0.1213],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,648][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.4240, 0.0441, 0.1105, 0.0888, 0.0809, 0.1263, 0.1254],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,648][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4011, 0.1124, 0.0468, 0.1412, 0.0917, 0.0773, 0.1295],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,649][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.5342, 0.0709, 0.0857, 0.0709, 0.1001, 0.0767, 0.0615],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,649][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0508, 0.1547, 0.1597, 0.1612, 0.1549, 0.1596, 0.1592],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,649][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.3218e-07, 7.7250e-04, 1.2684e-03, 5.0840e-04, 3.8982e-01, 4.1547e-01,
        1.9217e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,651][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0048, 0.1644, 0.1797, 0.1466, 0.1468, 0.1239, 0.1129, 0.1210],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,653][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1303, 0.1226, 0.0164, 0.1606, 0.0219, 0.2646, 0.1229, 0.1607],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,656][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0496, 0.1151, 0.1723, 0.1213, 0.1538, 0.1517, 0.1369, 0.0992],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,659][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.8342, 0.0141, 0.0262, 0.0306, 0.0204, 0.0114, 0.0480, 0.0153],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,663][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1076, 0.1145, 0.1255, 0.1322, 0.1187, 0.1339, 0.1307, 0.1370],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,666][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0197, 0.1907, 0.1141, 0.2433, 0.1180, 0.1229, 0.1112, 0.0802],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,670][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0363, 0.1206, 0.1494, 0.1684, 0.1653, 0.1299, 0.1209, 0.1093],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,673][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.3187, 0.0490, 0.1135, 0.0927, 0.0937, 0.1317, 0.1197, 0.0810],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,675][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.3334, 0.1062, 0.0337, 0.1236, 0.0769, 0.0711, 0.1164, 0.1386],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,676][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.4921, 0.0689, 0.0836, 0.0687, 0.0948, 0.0745, 0.0594, 0.0581],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,676][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0373, 0.1356, 0.1390, 0.1412, 0.1341, 0.1394, 0.1375, 0.1359],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,676][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.8355e-08, 3.0717e-04, 4.0365e-04, 3.0029e-04, 1.2455e-01, 1.9188e-01,
        1.5161e-01, 5.3094e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,677][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0033, 0.1331, 0.1593, 0.1111, 0.1230, 0.1043, 0.0897, 0.1195, 0.1567],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,677][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1883, 0.0816, 0.0248, 0.1254, 0.0269, 0.2646, 0.0873, 0.1471, 0.0539],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,678][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0472, 0.1063, 0.1519, 0.1083, 0.1354, 0.1342, 0.1236, 0.0918, 0.1014],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,678][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.7443, 0.0178, 0.0359, 0.0354, 0.0460, 0.0139, 0.0556, 0.0281, 0.0229],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,679][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0935, 0.1016, 0.1125, 0.1186, 0.1062, 0.1204, 0.1177, 0.1259, 0.1035],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,682][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0160, 0.1741, 0.1005, 0.2114, 0.0980, 0.1050, 0.0870, 0.0858, 0.1223],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,685][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0278, 0.1086, 0.1186, 0.1478, 0.1342, 0.1390, 0.0990, 0.1213, 0.1037],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,689][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.2827, 0.0455, 0.1124, 0.0854, 0.1011, 0.1253, 0.1164, 0.0741, 0.0571],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,693][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.4637, 0.0700, 0.0200, 0.0902, 0.0501, 0.0493, 0.0896, 0.1081, 0.0591],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,696][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.4391, 0.0650, 0.0800, 0.0663, 0.0915, 0.0715, 0.0577, 0.0567, 0.0721],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,700][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0317, 0.1191, 0.1239, 0.1248, 0.1187, 0.1234, 0.1233, 0.1207, 0.1145],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,702][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.0923e-08, 1.2658e-04, 4.8631e-04, 1.3320e-04, 1.6788e-01, 1.5179e-01,
        1.1202e-01, 4.1341e-01, 1.5415e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:38,705][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0028, 0.1029, 0.1408, 0.0867, 0.1320, 0.0882, 0.0813, 0.1104, 0.1626,
        0.0923], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,705][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1488, 0.0668, 0.0351, 0.0721, 0.0310, 0.3028, 0.0630, 0.1476, 0.1140,
        0.0188], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,705][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0416, 0.0934, 0.1385, 0.0978, 0.1233, 0.1223, 0.1118, 0.0816, 0.0949,
        0.0948], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,706][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7796, 0.0078, 0.0588, 0.0165, 0.0386, 0.0107, 0.0382, 0.0176, 0.0274,
        0.0050], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,706][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0860, 0.0927, 0.1016, 0.1065, 0.0961, 0.1080, 0.1043, 0.1120, 0.0921,
        0.1007], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,707][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0222, 0.1285, 0.0809, 0.1840, 0.0825, 0.0869, 0.0933, 0.0766, 0.1122,
        0.1331], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,707][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0276, 0.0826, 0.1194, 0.1229, 0.1244, 0.1140, 0.0934, 0.1032, 0.1133,
        0.0992], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,707][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2726, 0.0405, 0.0960, 0.0775, 0.0775, 0.1145, 0.1087, 0.0635, 0.0476,
        0.1015], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,709][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2681, 0.0785, 0.0344, 0.0907, 0.0608, 0.0533, 0.0865, 0.1009, 0.0777,
        0.1491], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,712][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4146, 0.0600, 0.0739, 0.0596, 0.0834, 0.0650, 0.0523, 0.0509, 0.0672,
        0.0732], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,716][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0322, 0.1056, 0.1090, 0.1098, 0.1046, 0.1091, 0.1086, 0.1066, 0.1022,
        0.1123], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,718][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([5.3253e-08, 3.3844e-04, 2.7416e-04, 1.3262e-04, 9.6761e-02, 1.3155e-01,
        8.3779e-02, 4.1362e-01, 1.5786e-01, 1.1568e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:38,722][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0032, 0.0998, 0.1217, 0.0814, 0.1145, 0.0862, 0.0786, 0.1010, 0.1414,
        0.0924, 0.0798], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,725][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0636, 0.0854, 0.0427, 0.0688, 0.0445, 0.2724, 0.0932, 0.1255, 0.1238,
        0.0426, 0.0375], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,729][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0384, 0.0879, 0.1295, 0.0892, 0.1156, 0.1135, 0.1037, 0.0758, 0.0868,
        0.0883, 0.0711], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,733][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6863, 0.0113, 0.0849, 0.0146, 0.0504, 0.0156, 0.0444, 0.0319, 0.0416,
        0.0079, 0.0109], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,734][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0788, 0.0849, 0.0916, 0.0961, 0.0871, 0.0978, 0.0941, 0.1024, 0.0837,
        0.0910, 0.0924], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,734][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0121, 0.1284, 0.0680, 0.1366, 0.0680, 0.0760, 0.0803, 0.0605, 0.0974,
        0.1295, 0.1432], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,734][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0207, 0.0773, 0.1075, 0.1000, 0.1140, 0.1054, 0.0867, 0.0995, 0.1102,
        0.0958, 0.0830], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,735][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2261, 0.0397, 0.0933, 0.0766, 0.0690, 0.1065, 0.1015, 0.0579, 0.0443,
        0.0954, 0.0897], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,735][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2658, 0.0715, 0.0245, 0.0831, 0.0501, 0.0472, 0.0779, 0.0880, 0.0668,
        0.1400, 0.0849], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,736][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4072, 0.0530, 0.0666, 0.0531, 0.0761, 0.0594, 0.0476, 0.0455, 0.0603,
        0.0662, 0.0649], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,736][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0287, 0.0953, 0.0988, 0.0989, 0.0947, 0.0978, 0.0978, 0.0956, 0.0918,
        0.1006, 0.1000], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,736][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.8465e-08, 3.2868e-04, 2.9541e-04, 1.2227e-04, 1.0788e-01, 1.3983e-01,
        7.7495e-02, 4.2412e-01, 1.3483e-01, 8.6494e-02, 2.8606e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:38,738][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0036, 0.0982, 0.1063, 0.0872, 0.0905, 0.0799, 0.0692, 0.0826, 0.1102,
        0.0960, 0.0828, 0.0936], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,741][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0848, 0.0733, 0.0145, 0.1241, 0.0251, 0.2773, 0.0882, 0.1334, 0.0724,
        0.0344, 0.0608, 0.0116], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,745][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0354, 0.0783, 0.1194, 0.0867, 0.1068, 0.1075, 0.0957, 0.0698, 0.0811,
        0.0788, 0.0654, 0.0751], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,748][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.5316, 0.0175, 0.0420, 0.0428, 0.0532, 0.0143, 0.0984, 0.0516, 0.0435,
        0.0173, 0.0372, 0.0506], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,752][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0714, 0.0770, 0.0837, 0.0890, 0.0791, 0.0908, 0.0883, 0.0934, 0.0756,
        0.0848, 0.0866, 0.0801], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,756][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0123, 0.1126, 0.0641, 0.1447, 0.0632, 0.0747, 0.0645, 0.0476, 0.0832,
        0.1111, 0.1464, 0.0757], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,759][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0188, 0.0773, 0.0935, 0.1023, 0.0969, 0.1005, 0.0751, 0.0895, 0.1051,
        0.0929, 0.0857, 0.0623], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,763][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.2289, 0.0395, 0.0817, 0.0635, 0.0688, 0.0943, 0.0871, 0.0584, 0.0429,
        0.0845, 0.0708, 0.0796], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,763][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.2441, 0.0715, 0.0242, 0.0798, 0.0490, 0.0445, 0.0775, 0.0900, 0.0645,
        0.1312, 0.0755, 0.0482], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,764][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.3484, 0.0513, 0.0640, 0.0526, 0.0733, 0.0577, 0.0464, 0.0452, 0.0576,
        0.0649, 0.0650, 0.0737], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,764][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0244, 0.0870, 0.0888, 0.0905, 0.0862, 0.0901, 0.0894, 0.0874, 0.0832,
        0.0927, 0.0922, 0.0881], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,765][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([4.0522e-08, 2.9236e-04, 1.2547e-04, 1.2551e-04, 3.4562e-02, 1.3266e-01,
        5.2020e-02, 2.9245e-01, 1.2491e-01, 6.1230e-02, 1.9504e-02, 2.8213e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:38,765][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0021, 0.0896, 0.0949, 0.0825, 0.0864, 0.0701, 0.0700, 0.0769, 0.1019,
        0.0840, 0.0773, 0.0894, 0.0749], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,765][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0972, 0.0696, 0.0333, 0.1093, 0.0246, 0.2880, 0.0748, 0.1200, 0.0749,
        0.0326, 0.0462, 0.0138, 0.0158], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,766][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0339, 0.0752, 0.1118, 0.0781, 0.1001, 0.0986, 0.0890, 0.0652, 0.0752,
        0.0740, 0.0606, 0.0703, 0.0679], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,767][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.4350, 0.0137, 0.0455, 0.0415, 0.0588, 0.0226, 0.0586, 0.0437, 0.0442,
        0.0152, 0.0480, 0.0956, 0.0776], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,770][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0665, 0.0717, 0.0780, 0.0827, 0.0743, 0.0840, 0.0820, 0.0883, 0.0713,
        0.0782, 0.0792, 0.0749, 0.0689], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,774][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0151, 0.0989, 0.0585, 0.1190, 0.0588, 0.0763, 0.0642, 0.0508, 0.0796,
        0.0980, 0.1274, 0.0959, 0.0573], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,778][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0176, 0.0764, 0.0775, 0.1024, 0.0665, 0.1114, 0.0691, 0.0862, 0.0868,
        0.0895, 0.0837, 0.0662, 0.0667], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,781][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1532, 0.0363, 0.0775, 0.0610, 0.0665, 0.0932, 0.0818, 0.0601, 0.0438,
        0.0817, 0.0716, 0.0751, 0.0981], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,785][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.3152, 0.0670, 0.0188, 0.0753, 0.0430, 0.0381, 0.0683, 0.0795, 0.0422,
        0.1235, 0.0718, 0.0406, 0.0168], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,789][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.3485, 0.0461, 0.0578, 0.0463, 0.0633, 0.0502, 0.0403, 0.0389, 0.0512,
        0.0564, 0.0556, 0.0674, 0.0782], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,792][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0219, 0.0801, 0.0821, 0.0839, 0.0794, 0.0829, 0.0823, 0.0800, 0.0768,
        0.0857, 0.0856, 0.0800, 0.0793], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,792][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([2.2648e-08, 2.8396e-04, 1.4238e-04, 1.4740e-04, 2.7838e-02, 1.4556e-01,
        5.5444e-02, 2.4417e-01, 1.1616e-01, 6.0152e-02, 1.7664e-02, 2.0087e-01,
        1.3156e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:38,793][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0013, 0.0772, 0.1041, 0.0661, 0.0891, 0.0637, 0.0576, 0.0810, 0.0996,
        0.0738, 0.0648, 0.0899, 0.0776, 0.0541], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,793][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1330, 0.0673, 0.0184, 0.0943, 0.0256, 0.2216, 0.0554, 0.1759, 0.0481,
        0.0301, 0.0504, 0.0164, 0.0163, 0.0472], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,794][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0322, 0.0696, 0.0998, 0.0712, 0.0904, 0.0891, 0.0819, 0.0619, 0.0683,
        0.0700, 0.0584, 0.0672, 0.0639, 0.0761], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,794][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.3901, 0.0155, 0.0809, 0.0279, 0.0952, 0.0104, 0.0443, 0.0380, 0.0508,
        0.0137, 0.0347, 0.0456, 0.1481, 0.0049], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,795][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0613, 0.0663, 0.0727, 0.0766, 0.0691, 0.0785, 0.0764, 0.0811, 0.0667,
        0.0728, 0.0735, 0.0691, 0.0638, 0.0719], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,795][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0118, 0.0956, 0.0514, 0.1254, 0.0569, 0.0593, 0.0595, 0.0456, 0.0784,
        0.0982, 0.1338, 0.0890, 0.0546, 0.0406], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,797][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0184, 0.0615, 0.0856, 0.0848, 0.0907, 0.0784, 0.0618, 0.0776, 0.0798,
        0.0769, 0.0720, 0.0658, 0.0947, 0.0522], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,799][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.1911, 0.0302, 0.0681, 0.0539, 0.0587, 0.0789, 0.0737, 0.0461, 0.0358,
        0.0712, 0.0605, 0.0647, 0.0855, 0.0815], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,803][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2690, 0.0739, 0.0207, 0.0780, 0.0432, 0.0416, 0.0651, 0.0747, 0.0463,
        0.1186, 0.0729, 0.0428, 0.0175, 0.0358], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,807][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.3233, 0.0425, 0.0534, 0.0432, 0.0620, 0.0473, 0.0378, 0.0372, 0.0486,
        0.0543, 0.0537, 0.0633, 0.0775, 0.0560], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,810][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0214, 0.0738, 0.0763, 0.0772, 0.0736, 0.0768, 0.0768, 0.0742, 0.0714,
        0.0789, 0.0788, 0.0744, 0.0732, 0.0733], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,813][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([5.9820e-09, 5.1748e-05, 8.1425e-05, 4.5481e-05, 2.7425e-02, 5.9333e-02,
        2.8177e-02, 1.3243e-01, 4.4447e-02, 2.5464e-02, 9.1459e-03, 2.7423e-01,
        1.6746e-01, 2.3171e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:38,817][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0018, 0.0696, 0.0907, 0.0597, 0.0899, 0.0617, 0.0556, 0.0709, 0.1076,
        0.0640, 0.0584, 0.0869, 0.0783, 0.0626, 0.0422], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,821][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0794, 0.0700, 0.0315, 0.0762, 0.0415, 0.1776, 0.0661, 0.1181, 0.1068,
        0.0281, 0.0378, 0.0196, 0.0262, 0.0902, 0.0310], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,821][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0288, 0.0650, 0.0987, 0.0676, 0.0889, 0.0867, 0.0778, 0.0570, 0.0659,
        0.0648, 0.0521, 0.0617, 0.0589, 0.0721, 0.0539], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,822][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4402, 0.0216, 0.0625, 0.0318, 0.0528, 0.0189, 0.0590, 0.0373, 0.0555,
        0.0181, 0.0291, 0.0548, 0.0774, 0.0098, 0.0312], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,822][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0578, 0.0623, 0.0681, 0.0714, 0.0647, 0.0725, 0.0703, 0.0754, 0.0612,
        0.0671, 0.0685, 0.0650, 0.0593, 0.0665, 0.0698], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,823][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0122, 0.0874, 0.0510, 0.1184, 0.0556, 0.0540, 0.0539, 0.0442, 0.0795,
        0.0907, 0.1284, 0.0817, 0.0544, 0.0373, 0.0512], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,823][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0179, 0.0568, 0.0790, 0.0827, 0.0812, 0.0759, 0.0618, 0.0697, 0.0756,
        0.0701, 0.0698, 0.0624, 0.0807, 0.0596, 0.0568], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,823][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1742, 0.0277, 0.0663, 0.0520, 0.0497, 0.0737, 0.0714, 0.0407, 0.0320,
        0.0666, 0.0591, 0.0567, 0.0777, 0.0748, 0.0773], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,825][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2818, 0.0613, 0.0193, 0.0748, 0.0416, 0.0381, 0.0622, 0.0693, 0.0433,
        0.1098, 0.0663, 0.0401, 0.0155, 0.0316, 0.0448], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,828][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3042, 0.0404, 0.0518, 0.0417, 0.0583, 0.0444, 0.0357, 0.0343, 0.0448,
        0.0500, 0.0502, 0.0586, 0.0722, 0.0523, 0.0612], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,832][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0198, 0.0690, 0.0713, 0.0715, 0.0685, 0.0708, 0.0706, 0.0696, 0.0659,
        0.0724, 0.0726, 0.0696, 0.0683, 0.0680, 0.0720], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,834][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9891e-08, 1.1854e-04, 9.7343e-05, 5.1646e-05, 2.6469e-02, 6.4821e-02,
        2.4779e-02, 1.2188e-01, 5.5952e-02, 3.4692e-02, 1.0601e-02, 2.1671e-01,
        1.7199e-01, 2.6411e-01, 7.7352e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:38,870][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:38,871][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,871][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,872][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,872][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,872][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,873][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,873][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,873][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,873][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,874][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,874][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,874][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:38,875][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2483, 0.7517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,877][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2863, 0.7137], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,880][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2860, 0.7140], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,884][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9739, 0.0261], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,887][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8776, 0.1224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,891][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2129, 0.7871], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,895][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7037, 0.2963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,899][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0536, 0.9464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,900][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5677, 0.4323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,901][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0838, 0.9162], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,901][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4540, 0.5460], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,901][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0031, 0.9969], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:38,902][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.3003, 0.5428, 0.1569], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,902][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.1370, 0.4508, 0.4122], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,902][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.1518, 0.4065, 0.4417], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,903][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.3647, 0.1002, 0.5351], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,903][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.6856, 0.1456, 0.1688], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,903][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([0.4282, 0.4920, 0.0798], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,905][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.5954, 0.2678, 0.1368], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,908][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.0085, 0.2296, 0.7619], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,912][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.3339, 0.2826, 0.3835], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,916][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.0343, 0.4920, 0.4737], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,919][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.1767, 0.3955, 0.4278], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,921][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([3.4884e-07, 1.0000e+00, 6.2865e-07], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:38,925][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0166, 0.7518, 0.1934, 0.0382], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,929][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0933, 0.3080, 0.3024, 0.2962], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,930][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1099, 0.2802, 0.2802, 0.3296], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,930][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0497, 0.0020, 0.9435, 0.0048], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,931][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3957, 0.1785, 0.1642, 0.2616], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,931][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0512, 0.8340, 0.0857, 0.0291], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,931][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4980, 0.2586, 0.1373, 0.1061], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,932][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0094, 0.1503, 0.5594, 0.2809], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,932][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2794, 0.2150, 0.2996, 0.2061], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,932][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0312, 0.3258, 0.3369, 0.3061], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,933][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2387, 0.2264, 0.3530, 0.1819], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,934][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.7662e-08, 1.0000e+00, 4.3385e-06, 2.8321e-07], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:38,936][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0441, 0.6628, 0.1819, 0.0791, 0.0321], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,937][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0852, 0.2258, 0.2581, 0.2394, 0.1915], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,937][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0790, 0.2105, 0.2291, 0.2509, 0.2305], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,938][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.1267, 0.0221, 0.1601, 0.1232, 0.5680], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,938][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.3753, 0.1323, 0.1600, 0.1848, 0.1476], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,942][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.3376, 0.5506, 0.0427, 0.0361, 0.0330], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,946][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.4052, 0.2644, 0.1211, 0.1282, 0.0812], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,950][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0060, 0.1319, 0.3431, 0.2610, 0.2579], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,954][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.1897, 0.1424, 0.2893, 0.1731, 0.2054], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,957][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0172, 0.2445, 0.2633, 0.2486, 0.2263], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,961][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.1175, 0.1760, 0.2785, 0.1483, 0.2798], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,961][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([6.1072e-04, 9.9674e-01, 1.8460e-05, 2.6268e-03, 6.0071e-07],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:38,962][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0163, 0.6534, 0.1551, 0.1255, 0.0310, 0.0187], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,962][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1200, 0.1793, 0.1747, 0.2001, 0.1594, 0.1666], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,962][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0641, 0.1593, 0.1811, 0.1957, 0.1782, 0.2215], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,963][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0073, 0.0076, 0.4199, 0.0475, 0.5164, 0.0014], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,963][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1907, 0.1268, 0.1292, 0.1685, 0.1206, 0.2642], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,963][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0768, 0.6327, 0.0905, 0.0948, 0.0777, 0.0275], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,964][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3887, 0.2063, 0.1289, 0.1034, 0.1058, 0.0669], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,965][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0060, 0.1718, 0.3049, 0.1910, 0.1806, 0.1457], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,968][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1522, 0.1278, 0.1902, 0.1260, 0.1828, 0.2210], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,972][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0200, 0.1889, 0.1920, 0.1870, 0.1793, 0.2329], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,976][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1459, 0.2089, 0.2897, 0.1169, 0.1349, 0.1036], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,978][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.9582e-02, 7.2699e-01, 2.0110e-01, 2.3652e-04, 5.2075e-02, 1.3016e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:38,982][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0071, 0.5349, 0.2371, 0.0986, 0.0308, 0.0788, 0.0127],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,986][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0835, 0.1522, 0.1636, 0.1584, 0.1436, 0.1500, 0.1487],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,990][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0573, 0.1385, 0.1498, 0.1602, 0.1503, 0.1834, 0.1604],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,990][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0312, 0.0171, 0.2676, 0.2565, 0.4087, 0.0162, 0.0027],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,991][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1281, 0.0890, 0.1164, 0.1526, 0.1061, 0.1897, 0.2180],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,991][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0793, 0.5791, 0.1143, 0.0703, 0.1154, 0.0286, 0.0129],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,992][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5138, 0.1675, 0.0752, 0.0756, 0.0680, 0.0573, 0.0426],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,992][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0073, 0.1263, 0.2346, 0.1629, 0.1499, 0.1220, 0.1969],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,992][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1294, 0.1112, 0.1617, 0.1088, 0.1562, 0.2363, 0.0964],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,993][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0155, 0.1612, 0.1719, 0.1530, 0.1550, 0.2026, 0.1409],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,993][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0968, 0.1727, 0.2474, 0.1105, 0.1763, 0.0732, 0.1232],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,993][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.0090e-02, 9.7958e-01, 1.9425e-04, 1.0419e-04, 6.2889e-06, 2.1778e-05,
        1.3557e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:38,995][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0629, 0.4325, 0.2247, 0.1077, 0.0242, 0.0396, 0.0154, 0.0929],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:38,998][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0658, 0.1309, 0.1280, 0.1425, 0.1120, 0.1258, 0.1535, 0.1417],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,002][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0389, 0.1073, 0.1271, 0.1434, 0.1280, 0.1765, 0.1407, 0.1381],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,006][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0636, 0.0223, 0.2055, 0.3354, 0.1214, 0.0314, 0.0568, 0.1637],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,009][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1803, 0.0816, 0.0827, 0.1179, 0.0849, 0.1307, 0.2082, 0.1138],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,013][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2662, 0.3606, 0.0604, 0.1216, 0.1082, 0.0264, 0.0219, 0.0347],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,017][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.6504, 0.1097, 0.0559, 0.0509, 0.0497, 0.0367, 0.0313, 0.0154],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,020][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0064, 0.1720, 0.2394, 0.1379, 0.1503, 0.1151, 0.1587, 0.0202],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,020][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1220, 0.0938, 0.1333, 0.0972, 0.1217, 0.1983, 0.0967, 0.1370],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,020][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0089, 0.1484, 0.1413, 0.1424, 0.1269, 0.1836, 0.1379, 0.1106],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,021][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1106, 0.1526, 0.1628, 0.1096, 0.0755, 0.0567, 0.1101, 0.2221],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,021][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([3.1901e-06, 1.3428e-01, 1.0277e-04, 2.6036e-04, 8.5801e-05, 1.3172e-03,
        2.2136e-03, 8.6174e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,022][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0865, 0.5624, 0.0940, 0.0642, 0.0086, 0.0387, 0.0106, 0.0644, 0.0707],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,022][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0353, 0.1114, 0.1280, 0.1220, 0.1050, 0.1153, 0.1382, 0.1388, 0.1059],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,022][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0342, 0.0964, 0.1044, 0.1167, 0.1118, 0.1428, 0.1192, 0.1240, 0.1506],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,024][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0246, 0.0095, 0.1795, 0.0438, 0.6224, 0.0111, 0.0145, 0.0607, 0.0340],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,027][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.2195, 0.0743, 0.0773, 0.1071, 0.0733, 0.1142, 0.1571, 0.0806, 0.0966],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,030][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1358, 0.4016, 0.0719, 0.0834, 0.0480, 0.0228, 0.0248, 0.0923, 0.1192],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,034][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.6187, 0.1107, 0.0548, 0.0530, 0.0443, 0.0451, 0.0353, 0.0214, 0.0167],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,038][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0066, 0.1343, 0.1997, 0.1358, 0.1387, 0.1102, 0.1556, 0.0255, 0.0936],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,042][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0932, 0.0758, 0.1310, 0.0779, 0.1317, 0.1532, 0.0652, 0.1144, 0.1576],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,045][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0085, 0.1227, 0.1293, 0.1277, 0.1178, 0.1591, 0.1261, 0.1126, 0.0963],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,049][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0812, 0.1059, 0.1582, 0.0998, 0.0721, 0.0446, 0.1265, 0.1736, 0.1380],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,049][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([2.0295e-03, 7.5723e-03, 1.4630e-05, 1.4694e-05, 3.2396e-06, 4.0790e-04,
        1.9307e-05, 7.1766e-01, 2.7228e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,050][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0158, 0.2112, 0.0482, 0.0208, 0.0037, 0.0143, 0.0047, 0.0298, 0.0124,
        0.6391], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,050][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0482, 0.0980, 0.1022, 0.1034, 0.1005, 0.1021, 0.1131, 0.1122, 0.1239,
        0.0964], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,051][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0359, 0.0884, 0.0936, 0.1073, 0.0958, 0.1220, 0.1057, 0.1058, 0.1266,
        0.1189], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,051][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([5.9456e-03, 2.1077e-04, 3.0642e-01, 3.6128e-03, 3.1593e-01, 2.2851e-03,
        4.3703e-03, 2.7262e-02, 3.3370e-01, 2.6315e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,051][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2951, 0.0426, 0.0607, 0.0827, 0.0671, 0.0854, 0.1444, 0.0739, 0.0762,
        0.0720], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,052][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0933, 0.2418, 0.0707, 0.0601, 0.0381, 0.0205, 0.0170, 0.0484, 0.0843,
        0.3259], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,053][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6301, 0.1014, 0.0528, 0.0454, 0.0470, 0.0307, 0.0244, 0.0169, 0.0188,
        0.0325], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,056][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0107, 0.1119, 0.1957, 0.1174, 0.1233, 0.1020, 0.1273, 0.0327, 0.0939,
        0.0851], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,059][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1005, 0.0784, 0.1144, 0.0768, 0.1149, 0.1427, 0.0667, 0.1070, 0.1127,
        0.0858], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,063][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0094, 0.1138, 0.1195, 0.1100, 0.1036, 0.1512, 0.1104, 0.1005, 0.0961,
        0.0856], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,067][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0881, 0.1140, 0.1420, 0.0688, 0.0793, 0.0349, 0.0839, 0.1609, 0.1118,
        0.1163], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,069][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([5.0999e-05, 1.2580e-01, 4.4185e-05, 9.4200e-07, 3.8785e-07, 1.2956e-05,
        5.3403e-09, 4.1478e-04, 5.3763e-01, 3.3605e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,072][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0108, 0.1607, 0.0215, 0.0108, 0.0017, 0.0117, 0.0041, 0.0226, 0.0087,
        0.5552, 0.1924], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,076][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0315, 0.0916, 0.0922, 0.0905, 0.0917, 0.0851, 0.1090, 0.0984, 0.1058,
        0.1006, 0.1036], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,079][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0302, 0.0791, 0.0809, 0.0979, 0.0818, 0.1110, 0.0970, 0.1017, 0.1189,
        0.1121, 0.0895], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,079][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0119, 0.0006, 0.2988, 0.0013, 0.2537, 0.0043, 0.0025, 0.0724, 0.3506,
        0.0009, 0.0028], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,079][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1730, 0.0497, 0.0628, 0.0933, 0.0650, 0.0831, 0.1229, 0.0679, 0.0688,
        0.0738, 0.1397], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,080][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0658, 0.2435, 0.0356, 0.0139, 0.0214, 0.0189, 0.0117, 0.0201, 0.0626,
        0.3452, 0.1615], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,080][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5887, 0.1108, 0.0535, 0.0416, 0.0457, 0.0310, 0.0262, 0.0191, 0.0207,
        0.0347, 0.0280], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,081][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0066, 0.0659, 0.1547, 0.1090, 0.0978, 0.0746, 0.1202, 0.0271, 0.0783,
        0.0792, 0.1866], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,081][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0930, 0.0765, 0.1096, 0.0712, 0.1039, 0.1393, 0.0596, 0.1063, 0.1090,
        0.0818, 0.0498], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,081][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0104, 0.1039, 0.1076, 0.0983, 0.0949, 0.1389, 0.1015, 0.0905, 0.0830,
        0.0818, 0.0892], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,083][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0902, 0.0805, 0.1193, 0.0692, 0.0909, 0.0313, 0.0797, 0.1689, 0.0892,
        0.1023, 0.0783], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,085][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.7201e-03, 7.1556e-01, 1.5492e-05, 4.7825e-07, 1.5343e-08, 1.5951e-07,
        5.2839e-10, 2.3004e-05, 4.3949e-02, 2.3570e-01, 3.1807e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,088][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0235, 0.1724, 0.0277, 0.0227, 0.0030, 0.0079, 0.0035, 0.0252, 0.0106,
        0.4098, 0.2289, 0.0647], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,092][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0307, 0.0862, 0.0772, 0.0965, 0.0817, 0.0852, 0.1034, 0.1006, 0.0813,
        0.0901, 0.1069, 0.0604], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,096][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0242, 0.0714, 0.0762, 0.0881, 0.0758, 0.1066, 0.0870, 0.0935, 0.1128,
        0.0995, 0.0794, 0.0856], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,099][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0096, 0.0033, 0.0245, 0.0165, 0.0678, 0.0038, 0.0171, 0.2534, 0.1136,
        0.0081, 0.0317, 0.4504], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,104][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.2069, 0.0586, 0.0529, 0.0820, 0.0445, 0.0742, 0.0955, 0.0561, 0.0464,
        0.0762, 0.1308, 0.0760], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,108][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0273, 0.1938, 0.0231, 0.0246, 0.0236, 0.0095, 0.0075, 0.0114, 0.0230,
        0.3946, 0.2199, 0.0418], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,108][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.4692, 0.1175, 0.0620, 0.0584, 0.0447, 0.0391, 0.0386, 0.0233, 0.0251,
        0.0513, 0.0495, 0.0212], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,109][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0028, 0.0768, 0.1900, 0.0986, 0.1106, 0.0712, 0.0969, 0.0143, 0.0497,
        0.0555, 0.1401, 0.0936], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,109][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0894, 0.0632, 0.1133, 0.0716, 0.0872, 0.1324, 0.0664, 0.0854, 0.1056,
        0.0887, 0.0537, 0.0431], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,110][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0058, 0.0924, 0.0888, 0.0928, 0.0835, 0.1273, 0.1030, 0.0774, 0.0779,
        0.0768, 0.0841, 0.0901], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,110][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0528, 0.0914, 0.1011, 0.0681, 0.0600, 0.0381, 0.0876, 0.1303, 0.0945,
        0.1018, 0.0652, 0.1091], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,110][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([9.6375e-01, 6.3770e-03, 2.3151e-06, 2.5426e-05, 6.1785e-07, 5.4754e-07,
        5.1103e-09, 1.3827e-03, 3.4478e-03, 1.0937e-02, 1.2988e-04, 1.3944e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,111][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0242, 0.1157, 0.0218, 0.0119, 0.0026, 0.0094, 0.0036, 0.0128, 0.0060,
        0.5796, 0.1641, 0.0210, 0.0273], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,113][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0365, 0.0739, 0.0985, 0.0838, 0.0731, 0.0870, 0.0906, 0.0962, 0.0817,
        0.0752, 0.0855, 0.0565, 0.0615], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,115][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0242, 0.0663, 0.0723, 0.0803, 0.0728, 0.0980, 0.0804, 0.0835, 0.1116,
        0.0926, 0.0740, 0.0812, 0.0629], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,119][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0096, 0.0015, 0.0126, 0.0083, 0.0385, 0.0040, 0.0038, 0.0267, 0.0242,
        0.0021, 0.0130, 0.7934, 0.0624], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,123][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.1480, 0.0602, 0.0592, 0.0716, 0.0542, 0.0774, 0.0907, 0.0461, 0.0456,
        0.0775, 0.1363, 0.0525, 0.0807], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,127][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.4180, 0.1460, 0.0092, 0.0112, 0.0044, 0.0093, 0.0057, 0.0082, 0.0112,
        0.1682, 0.1348, 0.0328, 0.0408], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,131][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.3721, 0.1411, 0.0567, 0.0554, 0.0377, 0.0492, 0.0402, 0.0278, 0.0245,
        0.0578, 0.0510, 0.0404, 0.0460], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,135][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0026, 0.0541, 0.1217, 0.0967, 0.0853, 0.0635, 0.0983, 0.0161, 0.0618,
        0.0605, 0.1497, 0.0737, 0.1160], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,137][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0632, 0.0530, 0.1111, 0.0634, 0.0841, 0.1441, 0.0574, 0.0751, 0.0988,
        0.0670, 0.0496, 0.0590, 0.0742], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,138][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0051, 0.0838, 0.0935, 0.0855, 0.0784, 0.1157, 0.0914, 0.0750, 0.0796,
        0.0667, 0.0763, 0.0825, 0.0665], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,138][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0389, 0.0668, 0.1049, 0.0590, 0.1214, 0.0532, 0.0665, 0.0784, 0.0701,
        0.1008, 0.0640, 0.0659, 0.1100], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,139][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([7.2863e-05, 9.9791e-03, 9.4563e-08, 7.9642e-06, 3.2104e-10, 9.0082e-07,
        1.5483e-09, 3.5985e-06, 1.4302e-03, 6.3924e-02, 7.1999e-04, 9.2247e-01,
        1.3937e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,139][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0633, 0.2114, 0.0592, 0.0186, 0.0031, 0.0038, 0.0017, 0.0338, 0.0044,
        0.3920, 0.1440, 0.0217, 0.0229, 0.0200], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,140][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0333, 0.0684, 0.0688, 0.0780, 0.0643, 0.0782, 0.0839, 0.0997, 0.0784,
        0.0775, 0.0891, 0.0596, 0.0568, 0.0642], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,140][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0199, 0.0544, 0.0645, 0.0712, 0.0649, 0.0877, 0.0704, 0.0753, 0.0981,
        0.0803, 0.0680, 0.0697, 0.0567, 0.1190], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,141][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.6377e-03, 7.0362e-04, 8.2767e-02, 5.5075e-03, 2.7160e-01, 3.5468e-04,
        7.7857e-04, 9.4560e-03, 5.3239e-02, 1.0215e-03, 1.1995e-02, 1.7627e-01,
        3.8455e-01, 1.2487e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,142][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0990, 0.0665, 0.0574, 0.0678, 0.0457, 0.0877, 0.0926, 0.0500, 0.0491,
        0.0765, 0.1258, 0.0511, 0.0663, 0.0643], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,145][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0902, 0.1706, 0.0122, 0.0207, 0.0087, 0.0042, 0.0037, 0.0076, 0.0278,
        0.2501, 0.2501, 0.0458, 0.0849, 0.0236], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,149][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.5102, 0.1023, 0.0386, 0.0366, 0.0291, 0.0251, 0.0217, 0.0157, 0.0135,
        0.0428, 0.0350, 0.0262, 0.0353, 0.0679], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,153][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0024, 0.0656, 0.1245, 0.0855, 0.0763, 0.0595, 0.0816, 0.0129, 0.0481,
        0.0474, 0.1153, 0.0705, 0.0827, 0.1277], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,156][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0591, 0.0556, 0.0783, 0.0529, 0.0879, 0.1172, 0.0463, 0.0733, 0.1009,
        0.0623, 0.0413, 0.0569, 0.0764, 0.0915], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,160][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0052, 0.0839, 0.0847, 0.0809, 0.0795, 0.1035, 0.0778, 0.0642, 0.0705,
        0.0589, 0.0707, 0.0861, 0.0695, 0.0646], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,164][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0571, 0.0788, 0.0990, 0.0432, 0.0621, 0.0304, 0.0534, 0.1195, 0.0719,
        0.0869, 0.0465, 0.1013, 0.0565, 0.0934], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,167][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([4.5442e-05, 8.5072e-06, 7.2869e-08, 2.4198e-09, 1.1939e-08, 1.0140e-09,
        7.0169e-11, 3.2429e-06, 1.0515e-03, 7.7670e-05, 1.9338e-06, 3.1927e-02,
        8.1184e-02, 8.8570e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,167][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0215, 0.1104, 0.0154, 0.0087, 0.0021, 0.0050, 0.0015, 0.0079, 0.0079,
        0.3528, 0.1609, 0.0148, 0.0354, 0.0430, 0.2128], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,168][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0231, 0.0649, 0.0704, 0.0693, 0.0689, 0.0629, 0.0754, 0.0752, 0.0836,
        0.0699, 0.0766, 0.0559, 0.0597, 0.0694, 0.0750], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,168][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0222, 0.0561, 0.0594, 0.0684, 0.0601, 0.0785, 0.0686, 0.0720, 0.0880,
        0.0780, 0.0625, 0.0680, 0.0515, 0.1045, 0.0623], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,169][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0037, 0.0008, 0.0229, 0.0041, 0.0654, 0.0011, 0.0012, 0.0305, 0.2624,
        0.0022, 0.0118, 0.4764, 0.1094, 0.0010, 0.0072], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,169][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0806, 0.0532, 0.0556, 0.0791, 0.0542, 0.0679, 0.0857, 0.0531, 0.0502,
        0.0555, 0.0972, 0.0591, 0.0613, 0.0600, 0.0874], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,170][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1093, 0.1569, 0.0139, 0.0106, 0.0110, 0.0054, 0.0031, 0.0062, 0.0243,
        0.2079, 0.1376, 0.0335, 0.1305, 0.0724, 0.0773], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,171][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5198, 0.0870, 0.0320, 0.0333, 0.0223, 0.0261, 0.0182, 0.0126, 0.0123,
        0.0310, 0.0268, 0.0238, 0.0254, 0.0562, 0.0729], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,174][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0030, 0.0522, 0.1123, 0.0731, 0.0661, 0.0514, 0.0759, 0.0124, 0.0446,
        0.0514, 0.1299, 0.0654, 0.0835, 0.1167, 0.0621], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,178][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0689, 0.0571, 0.0745, 0.0578, 0.0787, 0.1098, 0.0462, 0.0764, 0.0844,
        0.0648, 0.0423, 0.0522, 0.0617, 0.0889, 0.0362], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,182][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0056, 0.0710, 0.0832, 0.0723, 0.0739, 0.0936, 0.0737, 0.0651, 0.0672,
        0.0569, 0.0667, 0.0734, 0.0655, 0.0636, 0.0685], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,185][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0598, 0.0743, 0.0852, 0.0523, 0.0595, 0.0266, 0.0653, 0.1218, 0.0738,
        0.0742, 0.0542, 0.0725, 0.0522, 0.0724, 0.0560], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,188][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.0860e-10, 1.3660e-06, 6.7795e-11, 1.9782e-11, 1.1357e-12, 5.2959e-11,
        1.3218e-12, 2.5289e-09, 1.2328e-05, 3.3479e-06, 3.2305e-08, 8.5755e-05,
        7.0568e-05, 9.9981e-01, 1.4006e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,189][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:39,191][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9276],
        [12157],
        [25699],
        [17871],
        [24902],
        [15264],
        [25891],
        [21887],
        [30990],
        [20802],
        [18839],
        [18353],
        [21493],
        [12676],
        [32624]], device='cuda:0')
[2024-07-24 10:20:39,194][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9384],
        [17755],
        [31996],
        [24783],
        [26343],
        [20998],
        [34678],
        [27627],
        [32447],
        [34608],
        [29609],
        [19101],
        [20313],
        [20799],
        [37132]], device='cuda:0')
[2024-07-24 10:20:39,196][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[32586],
        [38420],
        [37305],
        [38453],
        [39387],
        [39575],
        [39433],
        [39385],
        [39434],
        [39169],
        [39239],
        [39471],
        [39484],
        [39558],
        [39586]], device='cuda:0')
[2024-07-24 10:20:39,199][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18011],
        [20249],
        [18824],
        [17697],
        [16972],
        [19860],
        [20309],
        [20434],
        [20317],
        [20758],
        [19941],
        [19911],
        [19910],
        [19806],
        [18644]], device='cuda:0')
[2024-07-24 10:20:39,200][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[33711],
        [34424],
        [41623],
        [43982],
        [45291],
        [46887],
        [47589],
        [47573],
        [47932],
        [48159],
        [48187],
        [48036],
        [47970],
        [48111],
        [48072]], device='cuda:0')
[2024-07-24 10:20:39,201][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 4592],
        [ 4792],
        [ 5498],
        [ 5077],
        [11074],
        [ 8718],
        [13812],
        [11321],
        [17508],
        [12434],
        [19038],
        [34479],
        [35811],
        [31413],
        [34833]], device='cuda:0')
[2024-07-24 10:20:39,202][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[20263],
        [20917],
        [20164],
        [18939],
        [18513],
        [17624],
        [17472],
        [16861],
        [16774],
        [17285],
        [17424],
        [17283],
        [17259],
        [17225],
        [17362]], device='cuda:0')
[2024-07-24 10:20:39,203][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24523],
        [43605],
        [43371],
        [43116],
        [41184],
        [42060],
        [43284],
        [44027],
        [43844],
        [44255],
        [43963],
        [43308],
        [42814],
        [42860],
        [43289]], device='cuda:0')
[2024-07-24 10:20:39,205][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[43083],
        [27862],
        [26160],
        [26576],
        [27357],
        [27825],
        [27899],
        [27953],
        [28175],
        [27329],
        [26876],
        [26416],
        [26486],
        [27033],
        [26549]], device='cuda:0')
[2024-07-24 10:20:39,207][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[18431],
        [17938],
        [16679],
        [16213],
        [15798],
        [16196],
        [16386],
        [16430],
        [16365],
        [16412],
        [16270],
        [16328],
        [16052],
        [16231],
        [16369]], device='cuda:0')
[2024-07-24 10:20:39,208][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[1315],
        [1821],
        [1840],
        [2179],
        [2090],
        [2404],
        [2328],
        [2499],
        [2322],
        [2674],
        [2492],
        [2472],
        [2319],
        [2470],
        [2489]], device='cuda:0')
[2024-07-24 10:20:39,210][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41003],
        [41424],
        [42656],
        [42875],
        [43497],
        [43838],
        [44014],
        [44113],
        [44320],
        [44359],
        [44381],
        [44480],
        [44572],
        [44716],
        [44811]], device='cuda:0')
[2024-07-24 10:20:39,213][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[7367],
        [5442],
        [5452],
        [4427],
        [4839],
        [4356],
        [3742],
        [4035],
        [3777],
        [3349],
        [3106],
        [3103],
        [3172],
        [3118],
        [3061]], device='cuda:0')
[2024-07-24 10:20:39,215][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14148],
        [15737],
        [17603],
        [18841],
        [12784],
        [14015],
        [15544],
        [16661],
        [17112],
        [17974],
        [17725],
        [17931],
        [17621],
        [17809],
        [18003]], device='cuda:0')
[2024-07-24 10:20:39,218][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6690],
        [ 3188],
        [ 2536],
        [ 5972],
        [ 8220],
        [25570],
        [14428],
        [11773],
        [ 9401],
        [ 3399],
        [ 2406],
        [ 7519],
        [ 8114],
        [ 9761],
        [16152]], device='cuda:0')
[2024-07-24 10:20:39,221][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[27003],
        [12249],
        [13034],
        [10563],
        [10510],
        [10137],
        [ 9711],
        [ 8159],
        [ 8815],
        [ 5770],
        [ 5386],
        [ 5528],
        [ 5478],
        [ 6111],
        [ 4914]], device='cuda:0')
[2024-07-24 10:20:39,223][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[32438],
        [27161],
        [23093],
        [24583],
        [22030],
        [23081],
        [23724],
        [24612],
        [23760],
        [24335],
        [25674],
        [26578],
        [24787],
        [25609],
        [25185]], device='cuda:0')
[2024-07-24 10:20:39,226][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23345],
        [16072],
        [12677],
        [11461],
        [11612],
        [10987],
        [11377],
        [11137],
        [10250],
        [10023],
        [ 9921],
        [10285],
        [10443],
        [10650],
        [10878]], device='cuda:0')
[2024-07-24 10:20:39,228][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14243],
        [14770],
        [13898],
        [12722],
        [22317],
        [19296],
        [20041],
        [27586],
        [23058],
        [21427],
        [23971],
        [23066],
        [20730],
        [27392],
        [20416]], device='cuda:0')
[2024-07-24 10:20:39,231][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31792],
        [41612],
        [39537],
        [33864],
        [34851],
        [29768],
        [28093],
        [27410],
        [28396],
        [31234],
        [34587],
        [37306],
        [38639],
        [36721],
        [35219]], device='cuda:0')
[2024-07-24 10:20:39,234][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12803],
        [26358],
        [25726],
        [25738],
        [24901],
        [23267],
        [22790],
        [19462],
        [21331],
        [26844],
        [29033],
        [27881],
        [26240],
        [26170],
        [26318]], device='cuda:0')
[2024-07-24 10:20:39,235][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10991],
        [ 6783],
        [ 5864],
        [ 5426],
        [ 4821],
        [ 4616],
        [ 4879],
        [ 4958],
        [ 4927],
        [ 4769],
        [ 4592],
        [ 4244],
        [ 3920],
        [ 4300],
        [ 4229]], device='cuda:0')
[2024-07-24 10:20:39,235][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[20540],
        [31577],
        [33412],
        [34685],
        [34904],
        [34082],
        [32489],
        [32836],
        [32115],
        [31391],
        [29425],
        [29732],
        [28884],
        [28634],
        [27881]], device='cuda:0')
[2024-07-24 10:20:39,236][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[42360],
        [40438],
        [41064],
        [41369],
        [42077],
        [40439],
        [40235],
        [41240],
        [41827],
        [41745],
        [41690],
        [41686],
        [41861],
        [42159],
        [41913]], device='cuda:0')
[2024-07-24 10:20:39,237][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17742],
        [12987],
        [ 5959],
        [ 5384],
        [ 3550],
        [ 5338],
        [ 5234],
        [ 5640],
        [ 5684],
        [ 5921],
        [ 5942],
        [ 5880],
        [ 5294],
        [ 5198],
        [ 5206]], device='cuda:0')
[2024-07-24 10:20:39,239][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17968],
        [ 7792],
        [ 6935],
        [ 7105],
        [ 8033],
        [ 6729],
        [ 6526],
        [ 6773],
        [ 5356],
        [ 5331],
        [ 5513],
        [ 5166],
        [ 5557],
        [ 4933],
        [ 5080]], device='cuda:0')
[2024-07-24 10:20:39,240][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[49506],
        [45881],
        [45784],
        [45784],
        [45806],
        [46527],
        [46243],
        [47908],
        [47653],
        [47189],
        [47208],
        [49508],
        [48383],
        [50019],
        [50027]], device='cuda:0')
[2024-07-24 10:20:39,242][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14426],
        [20216],
        [22921],
        [25539],
        [24355],
        [25490],
        [26034],
        [25271],
        [25751],
        [26884],
        [25302],
        [26096],
        [25708],
        [21597],
        [23810]], device='cuda:0')
[2024-07-24 10:20:39,243][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27251],
        [10053],
        [17452],
        [10051],
        [19326],
        [ 3898],
        [ 6600],
        [ 5700],
        [12235],
        [14370],
        [18654],
        [30806],
        [33332],
        [ 9432],
        [12227]], device='cuda:0')
[2024-07-24 10:20:39,246][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313],
        [16313]], device='cuda:0')
[2024-07-24 10:20:39,283][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:39,286][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,289][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,291][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,295][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,298][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,298][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,298][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,298][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,299][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,299][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,299][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,300][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,300][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1727, 0.8273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,300][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6122, 0.3878], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,301][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9691, 0.0309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,301][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9042, 0.0958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,301][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3887, 0.6113], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,302][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7241, 0.2759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,302][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.9973e-01, 2.7486e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,302][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9461, 0.0539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,303][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1275, 0.8725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,303][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,303][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1032, 0.8968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,303][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9052, 0.0948], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,304][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.2540, 0.3873, 0.3587], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,304][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.6652, 0.1766, 0.1582], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,304][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.8829, 0.0567, 0.0604], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,307][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.9363, 0.0540, 0.0097], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,312][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.2190, 0.4563, 0.3247], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,316][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.7648, 0.1397, 0.0955], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,316][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.5919, 0.4035, 0.0046], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,316][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.9531, 0.0338, 0.0130], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,317][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.0809, 0.4309, 0.4882], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,317][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.9468, 0.0217, 0.0315], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,317][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.0501, 0.4104, 0.5395], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,317][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.8431, 0.0861, 0.0708], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,318][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1823, 0.3236, 0.3356, 0.1586], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,318][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0167, 0.0651, 0.0578, 0.8604], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,318][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7756, 0.0419, 0.1336, 0.0490], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,319][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5121, 0.3651, 0.0651, 0.0577], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,319][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1373, 0.2720, 0.2809, 0.3098], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,321][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2321, 0.2760, 0.2549, 0.2370], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,323][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.7735e-01, 5.4148e-04, 2.1988e-02, 1.2272e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,325][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9273, 0.0377, 0.0177, 0.0173], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,329][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0410, 0.3105, 0.3534, 0.2951], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,333][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9802, 0.0020, 0.0152, 0.0026], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,337][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0520, 0.2637, 0.3190, 0.3653], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,341][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8380, 0.0736, 0.0481, 0.0403], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,345][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.1142, 0.2746, 0.2654, 0.1244, 0.2215], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,345][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.4827, 0.0997, 0.0601, 0.2428, 0.1147], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,345][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.6102, 0.0722, 0.1053, 0.1446, 0.0677], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,346][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.6294, 0.2457, 0.0474, 0.0605, 0.0170], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,346][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1210, 0.2392, 0.1763, 0.2970, 0.1665], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,346][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.5564, 0.1358, 0.1012, 0.1072, 0.0993], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,347][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.6188, 0.1420, 0.0507, 0.1767, 0.0119], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,347][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.8874, 0.0408, 0.0188, 0.0232, 0.0298], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,347][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0390, 0.2312, 0.2605, 0.2214, 0.2479], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,347][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.9046, 0.0139, 0.0474, 0.0204, 0.0138], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,349][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0245, 0.1950, 0.2683, 0.2384, 0.2739], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,352][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.6342, 0.1335, 0.0997, 0.0669, 0.0656], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,356][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1246, 0.2253, 0.2576, 0.0941, 0.2173, 0.0811], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,360][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0214, 0.0460, 0.0349, 0.3581, 0.0409, 0.4986], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,363][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.5884, 0.0488, 0.1100, 0.0683, 0.0706, 0.1138], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,367][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1980, 0.4909, 0.1370, 0.1003, 0.0550, 0.0187], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,371][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0936, 0.1864, 0.1568, 0.2329, 0.1671, 0.1632], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,374][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2702, 0.1721, 0.1461, 0.1408, 0.1394, 0.1314], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,374][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.9300, 0.0223, 0.0065, 0.0166, 0.0219, 0.0026], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,374][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.8665, 0.0373, 0.0281, 0.0192, 0.0194, 0.0295], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,374][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0227, 0.1900, 0.2159, 0.1827, 0.2068, 0.1818], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,375][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.9556, 0.0036, 0.0228, 0.0056, 0.0106, 0.0018], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,375][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0235, 0.1567, 0.1781, 0.2037, 0.1924, 0.2456], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,375][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.8000, 0.0668, 0.0417, 0.0449, 0.0233, 0.0234], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,376][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0981, 0.2579, 0.2247, 0.0970, 0.1726, 0.0792, 0.0705],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,376][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0113, 0.0861, 0.0748, 0.1837, 0.0776, 0.3391, 0.2273],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,376][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4587, 0.0505, 0.1411, 0.0853, 0.0863, 0.1316, 0.0465],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,377][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1852, 0.4757, 0.1242, 0.1199, 0.0612, 0.0258, 0.0081],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,378][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0711, 0.1585, 0.1456, 0.1969, 0.1527, 0.1558, 0.1196],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,381][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2775, 0.1457, 0.1197, 0.1143, 0.1148, 0.1097, 0.1184],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,385][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.6128, 0.0090, 0.0317, 0.0101, 0.3251, 0.0107, 0.0006],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,389][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7794, 0.0446, 0.0329, 0.0291, 0.0236, 0.0645, 0.0260],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,392][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0199, 0.1593, 0.1813, 0.1527, 0.1733, 0.1542, 0.1594],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,396][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.9546, 0.0038, 0.0205, 0.0044, 0.0094, 0.0024, 0.0049],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,400][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0341, 0.1287, 0.1663, 0.1463, 0.1626, 0.1701, 0.1919],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,403][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.7917, 0.0533, 0.0327, 0.0378, 0.0190, 0.0151, 0.0504],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,403][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1080, 0.2521, 0.1724, 0.0922, 0.1492, 0.0639, 0.0717, 0.0905],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,403][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0335, 0.1038, 0.0565, 0.1564, 0.0313, 0.1601, 0.1213, 0.3370],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,404][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.5011, 0.0348, 0.0811, 0.0688, 0.0571, 0.1063, 0.0645, 0.0864],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,404][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2280, 0.4611, 0.1335, 0.0927, 0.0497, 0.0154, 0.0078, 0.0119],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,404][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0573, 0.1405, 0.1244, 0.1919, 0.1346, 0.1351, 0.1400, 0.0762],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,404][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.4057, 0.1031, 0.0780, 0.0815, 0.0769, 0.0746, 0.0789, 0.1014],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,405][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.7510, 0.0380, 0.0041, 0.0533, 0.0139, 0.1140, 0.0240, 0.0018],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,405][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.7417, 0.0393, 0.0291, 0.0229, 0.0248, 0.0425, 0.0201, 0.0795],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,407][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0175, 0.1359, 0.1551, 0.1311, 0.1482, 0.1330, 0.1387, 0.1405],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,409][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.9127, 0.0078, 0.0322, 0.0120, 0.0129, 0.0041, 0.0126, 0.0055],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,413][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0103, 0.1157, 0.1242, 0.1591, 0.1222, 0.1472, 0.2069, 0.1145],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,417][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.4373, 0.1183, 0.0869, 0.0850, 0.0530, 0.0395, 0.0899, 0.0901],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,420][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1685, 0.1528, 0.1835, 0.0612, 0.1518, 0.0524, 0.0435, 0.0615, 0.1248],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,424][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0119, 0.0940, 0.0393, 0.1226, 0.0424, 0.2192, 0.1835, 0.1752, 0.1118],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,428][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.4664, 0.0348, 0.0738, 0.0734, 0.0416, 0.0944, 0.0593, 0.1142, 0.0421],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,431][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.3559, 0.4186, 0.0932, 0.0623, 0.0282, 0.0147, 0.0058, 0.0140, 0.0073],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,432][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0542, 0.1301, 0.1031, 0.1849, 0.1183, 0.1228, 0.1313, 0.0791, 0.0762],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,432][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.2705, 0.1081, 0.0824, 0.0816, 0.0813, 0.0773, 0.0841, 0.1068, 0.1080],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,432][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.4260, 0.1312, 0.0472, 0.1324, 0.0622, 0.0227, 0.1321, 0.0441, 0.0021],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,432][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.7259, 0.0312, 0.0117, 0.0208, 0.0128, 0.0394, 0.0208, 0.0943, 0.0431],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,433][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0156, 0.1214, 0.1373, 0.1162, 0.1305, 0.1171, 0.1220, 0.1241, 0.1159],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,433][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.9696, 0.0026, 0.0111, 0.0035, 0.0043, 0.0015, 0.0036, 0.0022, 0.0016],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,433][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0178, 0.0966, 0.1259, 0.1194, 0.1268, 0.1285, 0.1549, 0.0866, 0.1435],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,434][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3075, 0.1136, 0.0950, 0.0945, 0.0597, 0.0502, 0.1174, 0.0918, 0.0702],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,434][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0613, 0.2107, 0.1465, 0.0733, 0.1273, 0.0698, 0.0515, 0.0564, 0.1165,
        0.0867], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,436][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0021, 0.0420, 0.0282, 0.3045, 0.0169, 0.2285, 0.0889, 0.0552, 0.0309,
        0.2027], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,438][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4254, 0.0247, 0.1002, 0.0423, 0.0481, 0.1074, 0.0454, 0.1094, 0.0678,
        0.0292], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,442][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3123, 0.4201, 0.0760, 0.0763, 0.0402, 0.0209, 0.0064, 0.0144, 0.0145,
        0.0189], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,446][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0514, 0.1033, 0.1055, 0.1335, 0.1139, 0.1141, 0.1174, 0.0731, 0.0888,
        0.0990], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,449][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1359, 0.1008, 0.0904, 0.0879, 0.0889, 0.0867, 0.0927, 0.1083, 0.1103,
        0.0980], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,452][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([4.3549e-01, 2.7531e-04, 8.6201e-02, 3.3441e-04, 3.6158e-01, 9.4156e-03,
        2.2814e-02, 2.8202e-02, 5.5245e-02, 4.3922e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,456][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6205, 0.0377, 0.0226, 0.0256, 0.0174, 0.0544, 0.0275, 0.0926, 0.0546,
        0.0471], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,460][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0144, 0.1089, 0.1232, 0.1039, 0.1174, 0.1045, 0.1087, 0.1106, 0.1030,
        0.1053], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,460][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9655, 0.0025, 0.0112, 0.0024, 0.0050, 0.0013, 0.0026, 0.0027, 0.0026,
        0.0041], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,461][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0166, 0.0910, 0.1112, 0.1078, 0.1040, 0.1200, 0.1410, 0.0815, 0.1011,
        0.1257], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,461][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6471, 0.0577, 0.0406, 0.0385, 0.0243, 0.0165, 0.0407, 0.0335, 0.0287,
        0.0724], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,461][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0472, 0.1942, 0.1525, 0.0628, 0.1349, 0.0630, 0.0402, 0.0506, 0.1204,
        0.0744, 0.0598], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,462][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0039, 0.0384, 0.0341, 0.2971, 0.0164, 0.2457, 0.0693, 0.0569, 0.0217,
        0.1041, 0.1126], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,462][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2671, 0.0340, 0.1262, 0.0403, 0.0618, 0.1147, 0.0493, 0.1380, 0.0850,
        0.0472, 0.0365], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,462][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2548, 0.4883, 0.0622, 0.0679, 0.0404, 0.0182, 0.0073, 0.0113, 0.0110,
        0.0223, 0.0164], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,463][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0336, 0.0955, 0.1010, 0.1103, 0.1085, 0.1057, 0.1016, 0.0705, 0.0864,
        0.0967, 0.0901], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,464][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0926, 0.0958, 0.0874, 0.0813, 0.0851, 0.0803, 0.0866, 0.1023, 0.1053,
        0.0938, 0.0894], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,466][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([5.9638e-01, 3.3488e-04, 1.6876e-02, 7.4301e-05, 3.0602e-01, 2.0515e-02,
        2.8047e-03, 9.3652e-03, 4.6974e-02, 5.7090e-04, 8.7949e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,469][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5668, 0.0477, 0.0151, 0.0299, 0.0121, 0.0661, 0.0332, 0.0895, 0.0448,
        0.0577, 0.0371], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,473][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0123, 0.0999, 0.1129, 0.0946, 0.1073, 0.0955, 0.0996, 0.1018, 0.0938,
        0.0960, 0.0865], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,477][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9603, 0.0024, 0.0115, 0.0026, 0.0045, 0.0014, 0.0032, 0.0029, 0.0025,
        0.0038, 0.0047], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,480][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0182, 0.0754, 0.0931, 0.0942, 0.0888, 0.1039, 0.1174, 0.0742, 0.0969,
        0.1110, 0.1268], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,485][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6323, 0.0614, 0.0355, 0.0330, 0.0200, 0.0125, 0.0285, 0.0277, 0.0245,
        0.0556, 0.0690], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,489][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0593, 0.1791, 0.1200, 0.0587, 0.0945, 0.0502, 0.0463, 0.0474, 0.0988,
        0.0777, 0.0525, 0.1155], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,489][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0382, 0.0618, 0.0375, 0.1307, 0.0757, 0.1677, 0.0907, 0.0383, 0.0523,
        0.1244, 0.0692, 0.1135], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,490][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.3040, 0.0299, 0.0692, 0.0566, 0.0398, 0.0882, 0.0627, 0.1067, 0.0684,
        0.0526, 0.0587, 0.0630], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,490][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.2301, 0.3361, 0.1185, 0.0916, 0.0523, 0.0229, 0.0125, 0.0175, 0.0172,
        0.0415, 0.0415, 0.0183], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,490][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0296, 0.0976, 0.0770, 0.1259, 0.0767, 0.0984, 0.0887, 0.0616, 0.0716,
        0.1007, 0.1036, 0.0686], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,491][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.3237, 0.0752, 0.0545, 0.0597, 0.0547, 0.0566, 0.0580, 0.0703, 0.0765,
        0.0631, 0.0585, 0.0492], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,491][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([1.1187e-01, 5.0169e-02, 3.5001e-02, 8.5467e-02, 6.5742e-02, 1.4460e-01,
        1.8721e-01, 1.6989e-02, 2.9400e-03, 1.8061e-01, 1.1923e-01, 1.7396e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,491][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.5020, 0.0497, 0.0218, 0.0260, 0.0165, 0.0589, 0.0333, 0.1162, 0.0515,
        0.0553, 0.0386, 0.0300], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,492][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0133, 0.0898, 0.1016, 0.0859, 0.0966, 0.0863, 0.0899, 0.0921, 0.0854,
        0.0874, 0.0790, 0.0928], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,492][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.9227, 0.0030, 0.0184, 0.0050, 0.0060, 0.0025, 0.0065, 0.0037, 0.0037,
        0.0080, 0.0123, 0.0082], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,494][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0036, 0.0619, 0.0670, 0.0993, 0.0726, 0.0919, 0.1413, 0.0570, 0.0705,
        0.1213, 0.1627, 0.0510], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,496][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.4235, 0.0601, 0.0391, 0.0488, 0.0243, 0.0222, 0.0622, 0.0475, 0.0296,
        0.0846, 0.0847, 0.0733], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,500][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0496, 0.1706, 0.1306, 0.0713, 0.1049, 0.0487, 0.0394, 0.0386, 0.0777,
        0.0547, 0.0447, 0.0854, 0.0836], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,505][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0309, 0.0603, 0.0373, 0.1476, 0.0604, 0.1915, 0.0696, 0.0338, 0.0573,
        0.1167, 0.0590, 0.0572, 0.0785], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,508][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.1954, 0.0328, 0.0498, 0.0705, 0.0295, 0.1114, 0.0604, 0.1391, 0.0516,
        0.0632, 0.0739, 0.0931, 0.0292], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,512][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.5112, 0.2344, 0.0459, 0.0655, 0.0179, 0.0197, 0.0075, 0.0117, 0.0084,
        0.0216, 0.0223, 0.0213, 0.0125], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,516][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0391, 0.0916, 0.0677, 0.1150, 0.0624, 0.0903, 0.0916, 0.0620, 0.0661,
        0.0872, 0.0968, 0.0724, 0.0577], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,519][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.2218, 0.0776, 0.0589, 0.0602, 0.0585, 0.0561, 0.0597, 0.0758, 0.0777,
        0.0659, 0.0608, 0.0549, 0.0721], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,519][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.2178, 0.0476, 0.0272, 0.0828, 0.0066, 0.0518, 0.1564, 0.0789, 0.0370,
        0.1269, 0.1449, 0.0116, 0.0105], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,519][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.5881, 0.0279, 0.0095, 0.0183, 0.0168, 0.0584, 0.0350, 0.0870, 0.0434,
        0.0507, 0.0277, 0.0266, 0.0106], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,520][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.0142, 0.0828, 0.0916, 0.0784, 0.0876, 0.0795, 0.0821, 0.0837, 0.0782,
        0.0798, 0.0731, 0.0850, 0.0841], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,520][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.8915, 0.0048, 0.0148, 0.0073, 0.0047, 0.0024, 0.0067, 0.0032, 0.0051,
        0.0135, 0.0211, 0.0146, 0.0103], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,520][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0072, 0.0596, 0.0887, 0.0730, 0.0927, 0.0969, 0.1087, 0.0505, 0.0736,
        0.0944, 0.1145, 0.0502, 0.0900], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,521][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.3545, 0.1003, 0.0514, 0.0412, 0.0319, 0.0260, 0.0551, 0.0588, 0.0244,
        0.0844, 0.0713, 0.0463, 0.0546], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,521][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0605, 0.1465, 0.1251, 0.0514, 0.1019, 0.0361, 0.0344, 0.0374, 0.0805,
        0.0545, 0.0409, 0.0940, 0.0761, 0.0607], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,523][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0391, 0.0460, 0.0360, 0.1272, 0.0309, 0.2244, 0.0943, 0.0537, 0.0353,
        0.0914, 0.0436, 0.0413, 0.0591, 0.0776], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,525][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2404, 0.0257, 0.0896, 0.0504, 0.0509, 0.0732, 0.0401, 0.1027, 0.0529,
        0.0434, 0.0551, 0.0841, 0.0564, 0.0352], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,529][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1970, 0.5288, 0.0766, 0.0629, 0.0251, 0.0146, 0.0049, 0.0110, 0.0062,
        0.0158, 0.0191, 0.0151, 0.0162, 0.0067], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,533][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0334, 0.0813, 0.0689, 0.1081, 0.0738, 0.0785, 0.0724, 0.0507, 0.0570,
        0.0867, 0.0944, 0.0637, 0.0690, 0.0620], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,537][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1675, 0.0759, 0.0596, 0.0611, 0.0579, 0.0569, 0.0604, 0.0744, 0.0765,
        0.0644, 0.0611, 0.0551, 0.0720, 0.0573], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,541][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.2758, 0.0642, 0.0083, 0.0623, 0.0644, 0.0084, 0.0161, 0.0260, 0.0186,
        0.1660, 0.1606, 0.0055, 0.1222, 0.0016], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,545][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.6780, 0.0369, 0.0104, 0.0233, 0.0102, 0.0443, 0.0208, 0.0573, 0.0231,
        0.0327, 0.0203, 0.0176, 0.0047, 0.0204], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,547][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0105, 0.0759, 0.0857, 0.0728, 0.0817, 0.0724, 0.0755, 0.0775, 0.0722,
        0.0739, 0.0669, 0.0786, 0.0778, 0.0785], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,548][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.8851, 0.0048, 0.0212, 0.0070, 0.0054, 0.0031, 0.0069, 0.0045, 0.0052,
        0.0123, 0.0142, 0.0139, 0.0096, 0.0070], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,548][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0068, 0.0559, 0.0664, 0.0712, 0.0745, 0.0837, 0.1021, 0.0482, 0.0699,
        0.0883, 0.1067, 0.0462, 0.0700, 0.1103], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,549][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.5129, 0.0473, 0.0334, 0.0367, 0.0236, 0.0177, 0.0374, 0.0327, 0.0313,
        0.0652, 0.0594, 0.0438, 0.0274, 0.0313], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,549][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0680, 0.1168, 0.0985, 0.0483, 0.0875, 0.0432, 0.0354, 0.0464, 0.0804,
        0.0535, 0.0403, 0.0964, 0.0727, 0.0622, 0.0505], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,549][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0332, 0.0527, 0.0232, 0.1426, 0.0241, 0.1672, 0.1014, 0.0495, 0.0477,
        0.1266, 0.0793, 0.0324, 0.0434, 0.0493, 0.0275], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,550][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2164, 0.0263, 0.0950, 0.0405, 0.0473, 0.0754, 0.0418, 0.1047, 0.0567,
        0.0427, 0.0398, 0.0726, 0.0503, 0.0496, 0.0409], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,550][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3878, 0.3427, 0.0525, 0.0631, 0.0294, 0.0106, 0.0055, 0.0065, 0.0078,
        0.0161, 0.0139, 0.0182, 0.0219, 0.0093, 0.0146], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,550][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0233, 0.0701, 0.0681, 0.0906, 0.0783, 0.0774, 0.0716, 0.0491, 0.0605,
        0.0753, 0.0755, 0.0603, 0.0723, 0.0653, 0.0623], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,552][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1010, 0.0708, 0.0604, 0.0588, 0.0587, 0.0569, 0.0613, 0.0746, 0.0755,
        0.0649, 0.0621, 0.0583, 0.0717, 0.0584, 0.0666], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,554][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.8231e-01, 1.1548e-03, 3.5750e-02, 7.4064e-04, 2.4293e-01, 1.1229e-02,
        1.3735e-02, 4.7685e-02, 3.1241e-02, 3.0388e-03, 9.0877e-04, 5.3175e-03,
        4.1951e-01, 4.1256e-03, 3.2407e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,557][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.7174, 0.0273, 0.0091, 0.0164, 0.0092, 0.0301, 0.0148, 0.0397, 0.0275,
        0.0285, 0.0196, 0.0134, 0.0050, 0.0303, 0.0119], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,561][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0096, 0.0712, 0.0800, 0.0677, 0.0764, 0.0677, 0.0704, 0.0722, 0.0668,
        0.0682, 0.0617, 0.0734, 0.0728, 0.0728, 0.0691], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,565][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.9261, 0.0027, 0.0147, 0.0033, 0.0041, 0.0017, 0.0039, 0.0031, 0.0030,
        0.0053, 0.0068, 0.0095, 0.0063, 0.0049, 0.0047], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,568][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0076, 0.0520, 0.0659, 0.0676, 0.0660, 0.0752, 0.0949, 0.0500, 0.0710,
        0.0822, 0.0955, 0.0479, 0.0596, 0.0950, 0.0695], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,573][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4728, 0.0521, 0.0350, 0.0318, 0.0240, 0.0146, 0.0341, 0.0335, 0.0282,
        0.0599, 0.0608, 0.0420, 0.0328, 0.0236, 0.0549], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,603][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:39,606][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,610][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,613][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,615][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,617][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,617][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,618][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,618][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,618][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,619][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,619][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,619][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:39,620][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9454, 0.0546], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,620][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1327, 0.8673], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,621][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7056, 0.2944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,624][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9108, 0.0892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,628][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8331, 0.1669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,631][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9763, 0.0237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,635][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8276, 0.1724], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,639][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1253, 0.8747], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,643][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1868, 0.8132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,647][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2282, 0.7718], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,647][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2343, 0.7657], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,647][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9879, 0.0121], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:39,647][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.8571, 0.0496, 0.0933], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,648][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.0281, 0.4035, 0.5684], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,648][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.8499, 0.1372, 0.0129], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,648][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.9614, 0.0287, 0.0099], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,649][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.7521, 0.2296, 0.0183], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,649][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([9.9894e-01, 8.6484e-04, 1.9740e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,649][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.6916, 0.1863, 0.1220], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,649][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.0581, 0.4524, 0.4894], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,650][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.0843, 0.5140, 0.4017], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,651][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.1285, 0.4268, 0.4447], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,654][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.1057, 0.3967, 0.4976], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,656][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([9.9736e-01, 2.2121e-03, 4.2516e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:39,660][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9512, 0.0125, 0.0301, 0.0062], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,664][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0142, 0.0765, 0.8427, 0.0666], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,668][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1985, 0.7009, 0.0633, 0.0373], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,672][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5013, 0.3336, 0.1117, 0.0533], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,676][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2863, 0.6064, 0.0554, 0.0519], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,676][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9383, 0.0394, 0.0157, 0.0066], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,677][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6354, 0.1395, 0.1119, 0.1132], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,677][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0523, 0.3011, 0.3077, 0.3389], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,677][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0483, 0.2038, 0.5761, 0.1717], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,677][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0708, 0.3136, 0.3328, 0.2828], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,678][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1023, 0.2773, 0.3302, 0.2902], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,678][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9815, 0.0136, 0.0013, 0.0036], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:39,678][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.7843, 0.0418, 0.0777, 0.0298, 0.0663], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,679][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0124, 0.1991, 0.3456, 0.1850, 0.2579], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,679][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.2957, 0.6028, 0.0433, 0.0453, 0.0128], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,681][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.6686, 0.1998, 0.0691, 0.0472, 0.0154], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,683][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.2613, 0.5963, 0.0543, 0.0706, 0.0175], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,686][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.9447e-01, 3.3780e-03, 1.0620e-03, 7.5520e-04, 3.3475e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,690][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.5600, 0.1358, 0.1078, 0.1221, 0.0744], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,694][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0375, 0.2221, 0.2404, 0.2543, 0.2458], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,697][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0494, 0.1898, 0.2742, 0.2501, 0.2365], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,701][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0703, 0.2313, 0.2471, 0.2172, 0.2341], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,705][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0592, 0.2068, 0.2725, 0.2060, 0.2555], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,706][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([9.9349e-01, 4.4638e-03, 5.9079e-04, 7.9271e-04, 6.6348e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:39,706][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.9070, 0.0157, 0.0347, 0.0081, 0.0244, 0.0102], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,706][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0297, 0.1152, 0.2779, 0.1144, 0.3352, 0.1277], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,707][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0235, 0.7131, 0.1070, 0.0956, 0.0538, 0.0070], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,707][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1864, 0.4285, 0.2131, 0.0959, 0.0581, 0.0180], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,707][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0594, 0.6176, 0.1364, 0.1173, 0.0432, 0.0261], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,708][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9480, 0.0246, 0.0088, 0.0061, 0.0084, 0.0040], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,708][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4141, 0.1455, 0.1084, 0.1249, 0.0833, 0.1239], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,708][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0337, 0.1895, 0.1945, 0.2136, 0.1879, 0.1808], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,710][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0533, 0.1633, 0.2194, 0.1804, 0.2783, 0.1054], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,712][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0467, 0.1929, 0.2055, 0.1769, 0.1990, 0.1790], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,717][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0456, 0.1774, 0.1979, 0.1878, 0.1910, 0.2002], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,721][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.9778, 0.0117, 0.0012, 0.0045, 0.0012, 0.0037], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:39,724][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.9156, 0.0116, 0.0283, 0.0061, 0.0197, 0.0078, 0.0110],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,728][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0057, 0.0903, 0.2822, 0.0817, 0.1972, 0.2922, 0.0507],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,732][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0501, 0.6163, 0.0888, 0.1512, 0.0714, 0.0142, 0.0080],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,735][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1507, 0.4330, 0.2027, 0.1152, 0.0666, 0.0247, 0.0071],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,735][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0418, 0.6085, 0.1338, 0.1084, 0.0466, 0.0443, 0.0165],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,735][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9655, 0.0153, 0.0099, 0.0033, 0.0030, 0.0021, 0.0010],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,736][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3483, 0.1231, 0.0968, 0.1123, 0.0838, 0.1180, 0.1176],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,736][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0291, 0.1564, 0.1648, 0.1779, 0.1610, 0.1576, 0.1532],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,736][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0392, 0.1232, 0.2139, 0.1495, 0.2470, 0.1743, 0.0528],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,736][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0404, 0.1627, 0.1742, 0.1509, 0.1682, 0.1541, 0.1496],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,737][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0609, 0.1431, 0.1797, 0.1439, 0.1632, 0.1595, 0.1498],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,737][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.9701, 0.0155, 0.0017, 0.0044, 0.0015, 0.0034, 0.0034],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:39,739][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.9219, 0.0103, 0.0267, 0.0051, 0.0166, 0.0061, 0.0083, 0.0050],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,741][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0192, 0.0903, 0.1719, 0.0866, 0.1949, 0.1844, 0.1450, 0.1076],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,746][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1571, 0.5319, 0.0944, 0.1351, 0.0480, 0.0199, 0.0110, 0.0026],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,750][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1923, 0.4210, 0.2194, 0.0850, 0.0523, 0.0141, 0.0062, 0.0096],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,753][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0989, 0.5549, 0.1118, 0.1284, 0.0599, 0.0229, 0.0122, 0.0109],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,755][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([9.3017e-01, 3.6921e-02, 1.0561e-02, 7.7109e-03, 4.8357e-03, 3.7702e-03,
        5.2262e-03, 8.0357e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,759][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.3531, 0.1022, 0.0714, 0.0947, 0.0568, 0.1107, 0.1063, 0.1048],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,763][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0224, 0.1365, 0.1417, 0.1597, 0.1388, 0.1278, 0.1352, 0.1378],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,764][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0304, 0.1078, 0.1970, 0.1531, 0.2036, 0.1484, 0.0861, 0.0736],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,764][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0281, 0.1470, 0.1564, 0.1319, 0.1493, 0.1346, 0.1327, 0.1199],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,765][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0344, 0.1347, 0.1571, 0.1381, 0.1458, 0.1377, 0.1272, 0.1249],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,765][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([9.8885e-01, 7.2717e-03, 3.8318e-04, 1.4416e-03, 4.4272e-04, 6.5754e-04,
        5.4658e-04, 4.0675e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:39,765][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.8931, 0.0127, 0.0309, 0.0072, 0.0207, 0.0083, 0.0112, 0.0062, 0.0096],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,765][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0035, 0.0353, 0.1521, 0.0435, 0.2465, 0.1225, 0.1114, 0.1233, 0.1620],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,766][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1199, 0.6732, 0.0573, 0.0856, 0.0366, 0.0082, 0.0057, 0.0025, 0.0108],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,766][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.3544, 0.3645, 0.1559, 0.0585, 0.0303, 0.0137, 0.0048, 0.0109, 0.0069],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,766][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0999, 0.6217, 0.0651, 0.1046, 0.0350, 0.0252, 0.0150, 0.0087, 0.0249],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,767][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.9579, 0.0145, 0.0066, 0.0045, 0.0055, 0.0040, 0.0027, 0.0014, 0.0029],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,768][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.3171, 0.1005, 0.0773, 0.0903, 0.0584, 0.0949, 0.1023, 0.1066, 0.0526],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,771][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0215, 0.1144, 0.1338, 0.1348, 0.1315, 0.1134, 0.1177, 0.1246, 0.1083],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,775][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0183, 0.0963, 0.1579, 0.1275, 0.2001, 0.1294, 0.0750, 0.1202, 0.0753],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,779][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0219, 0.1322, 0.1411, 0.1184, 0.1369, 0.1241, 0.1234, 0.1105, 0.0914],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,782][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0348, 0.1118, 0.1417, 0.1166, 0.1306, 0.1168, 0.1136, 0.0993, 0.1348],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,785][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([9.8453e-01, 7.5301e-03, 8.2855e-04, 1.5750e-03, 8.9858e-04, 1.2437e-03,
        9.4989e-04, 3.9011e-04, 2.0583e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:39,789][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9104, 0.0098, 0.0254, 0.0052, 0.0173, 0.0063, 0.0084, 0.0040, 0.0064,
        0.0068], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,793][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0017, 0.0094, 0.1722, 0.0132, 0.1655, 0.1596, 0.0494, 0.0874, 0.3267,
        0.0149], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,794][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0684, 0.6956, 0.0577, 0.0818, 0.0359, 0.0107, 0.0060, 0.0024, 0.0221,
        0.0194], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,794][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3033, 0.3721, 0.1361, 0.0740, 0.0445, 0.0196, 0.0056, 0.0118, 0.0137,
        0.0192], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,794][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0549, 0.6540, 0.0666, 0.0672, 0.0237, 0.0288, 0.0155, 0.0145, 0.0378,
        0.0369], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,795][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.6871e-01, 1.0358e-02, 5.6049e-03, 3.6135e-03, 3.4798e-03, 2.5169e-03,
        2.1839e-03, 8.9000e-04, 8.3175e-04, 1.8076e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,795][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3460, 0.0726, 0.0664, 0.0661, 0.0514, 0.0849, 0.0949, 0.0944, 0.0513,
        0.0720], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,795][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0190, 0.1036, 0.1133, 0.1204, 0.1059, 0.1012, 0.1080, 0.1158, 0.0999,
        0.1129], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,796][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0137, 0.0504, 0.1681, 0.0885, 0.1957, 0.1286, 0.0825, 0.1142, 0.1192,
        0.0392], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,796][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0209, 0.1183, 0.1282, 0.1081, 0.1240, 0.1132, 0.1105, 0.1006, 0.0863,
        0.0899], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,798][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0360, 0.1048, 0.1263, 0.1050, 0.1102, 0.1090, 0.1064, 0.0948, 0.1011,
        0.1064], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,800][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.7003e-01, 1.0478e-02, 9.7759e-04, 2.8778e-03, 1.1045e-03, 2.2141e-03,
        1.9887e-03, 4.3701e-04, 1.5879e-03, 8.3037e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:39,802][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9133, 0.0087, 0.0236, 0.0046, 0.0155, 0.0056, 0.0076, 0.0035, 0.0056,
        0.0059, 0.0062], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,807][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0016, 0.0125, 0.1689, 0.0091, 0.1451, 0.1694, 0.0468, 0.0770, 0.3456,
        0.0153, 0.0087], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,811][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0442, 0.7598, 0.0466, 0.0560, 0.0318, 0.0071, 0.0044, 0.0015, 0.0140,
        0.0160, 0.0185], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,814][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2789, 0.4101, 0.1120, 0.0674, 0.0463, 0.0180, 0.0068, 0.0101, 0.0110,
        0.0228, 0.0166], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,818][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0837, 0.6123, 0.0608, 0.0570, 0.0303, 0.0266, 0.0162, 0.0108, 0.0350,
        0.0331, 0.0341], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,820][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.5885e-01, 1.6112e-02, 6.8293e-03, 3.1962e-03, 5.7137e-03, 2.4083e-03,
        1.8537e-03, 8.3286e-04, 8.8125e-04, 1.3982e-03, 1.9212e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,822][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3389, 0.0723, 0.0575, 0.0595, 0.0499, 0.0835, 0.0806, 0.0849, 0.0512,
        0.0694, 0.0523], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,823][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0164, 0.0932, 0.0986, 0.1058, 0.0948, 0.0935, 0.0966, 0.0993, 0.0858,
        0.1018, 0.1142], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,823][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0130, 0.0591, 0.1666, 0.0513, 0.1778, 0.1313, 0.0731, 0.1098, 0.1200,
        0.0573, 0.0405], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,823][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0228, 0.1062, 0.1144, 0.0983, 0.1110, 0.1015, 0.0988, 0.0917, 0.0812,
        0.0834, 0.0906], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,824][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0389, 0.0917, 0.1109, 0.0934, 0.1001, 0.1008, 0.0933, 0.0883, 0.0952,
        0.0954, 0.0920], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,824][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.6898e-01, 8.6147e-03, 6.4467e-04, 2.3508e-03, 6.3291e-04, 1.5162e-03,
        1.1767e-03, 2.4623e-04, 1.0692e-03, 6.2921e-03, 8.4739e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:39,824][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.7471, 0.0224, 0.0496, 0.0142, 0.0382, 0.0173, 0.0217, 0.0106, 0.0162,
        0.0190, 0.0192, 0.0247], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,825][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0021, 0.0528, 0.1031, 0.0403, 0.0807, 0.1433, 0.0760, 0.0947, 0.2467,
        0.0634, 0.0419, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,825][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0425, 0.5462, 0.0630, 0.1088, 0.0481, 0.0156, 0.0146, 0.0049, 0.0260,
        0.0425, 0.0654, 0.0223], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,827][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2670, 0.2642, 0.1747, 0.0834, 0.0536, 0.0208, 0.0106, 0.0143, 0.0154,
        0.0376, 0.0369, 0.0213], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,829][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0482, 0.5555, 0.0564, 0.1014, 0.0341, 0.0252, 0.0159, 0.0092, 0.0157,
        0.0506, 0.0632, 0.0246], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,831][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.7423e-01, 6.2169e-03, 5.1921e-03, 2.1986e-03, 3.5376e-03, 1.2675e-03,
        1.3068e-03, 4.7430e-04, 5.5647e-04, 1.1866e-03, 1.7014e-03, 2.1332e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,836][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.2729, 0.0789, 0.0610, 0.0731, 0.0464, 0.0880, 0.0850, 0.0812, 0.0423,
        0.0756, 0.0588, 0.0368], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,839][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0130, 0.0826, 0.0899, 0.0954, 0.0901, 0.0823, 0.0873, 0.0898, 0.0761,
        0.0920, 0.1067, 0.0947], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,843][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0088, 0.0606, 0.0937, 0.1020, 0.1164, 0.1253, 0.0854, 0.0868, 0.0921,
        0.0647, 0.0840, 0.0802], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,847][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0215, 0.0981, 0.1063, 0.0901, 0.1015, 0.0921, 0.0909, 0.0847, 0.0740,
        0.0766, 0.0828, 0.0815], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,850][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0159, 0.0855, 0.0978, 0.0962, 0.0948, 0.0894, 0.0910, 0.0752, 0.0806,
        0.0935, 0.0974, 0.0827], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,852][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([9.4754e-01, 1.4021e-02, 6.0829e-04, 4.6303e-03, 8.1417e-04, 2.6549e-03,
        1.9966e-03, 5.2241e-04, 2.3441e-03, 7.5680e-03, 5.4145e-03, 1.1885e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:39,852][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.7167, 0.0215, 0.0445, 0.0146, 0.0354, 0.0187, 0.0224, 0.0118, 0.0168,
        0.0187, 0.0190, 0.0233, 0.0368], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,853][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0010, 0.0304, 0.0543, 0.0232, 0.0374, 0.1053, 0.0450, 0.1333, 0.3858,
        0.0487, 0.0260, 0.0770, 0.0327], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,853][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.1307, 0.6759, 0.0287, 0.0620, 0.0156, 0.0048, 0.0058, 0.0013, 0.0120,
        0.0149, 0.0228, 0.0127, 0.0128], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,853][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.5493, 0.1930, 0.0701, 0.0572, 0.0180, 0.0168, 0.0060, 0.0088, 0.0072,
        0.0187, 0.0190, 0.0233, 0.0126], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,854][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.1677, 0.5181, 0.0483, 0.0709, 0.0192, 0.0212, 0.0104, 0.0094, 0.0206,
        0.0348, 0.0378, 0.0336, 0.0080], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,854][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.7751e-01, 7.3414e-03, 2.3298e-03, 1.6837e-03, 7.6525e-04, 2.5335e-03,
        1.1900e-03, 4.6986e-04, 4.1074e-04, 1.3949e-03, 2.1292e-03, 1.2463e-03,
        9.9160e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,854][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.2478, 0.0768, 0.0603, 0.0704, 0.0381, 0.0805, 0.0821, 0.0882, 0.0413,
        0.0785, 0.0589, 0.0449, 0.0321], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,856][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.0136, 0.0749, 0.0844, 0.0861, 0.0867, 0.0763, 0.0802, 0.0832, 0.0702,
        0.0817, 0.0949, 0.0812, 0.0867], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,860][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.0121, 0.0554, 0.0806, 0.0797, 0.0698, 0.1223, 0.0671, 0.0919, 0.1100,
        0.0677, 0.0699, 0.1224, 0.0511], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,863][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0210, 0.0889, 0.0961, 0.0826, 0.0907, 0.0863, 0.0845, 0.0776, 0.0679,
        0.0715, 0.0772, 0.0762, 0.0796], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,867][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0202, 0.0762, 0.1027, 0.0767, 0.0967, 0.0870, 0.0763, 0.0643, 0.0769,
        0.0763, 0.0767, 0.0725, 0.0976], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,869][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([9.7763e-01, 6.2769e-03, 4.7347e-04, 1.1827e-03, 6.9679e-04, 1.1387e-03,
        8.0587e-04, 4.2049e-04, 7.2544e-04, 4.6923e-03, 3.0982e-03, 1.5191e-03,
        1.3382e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:39,873][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.7879, 0.0163, 0.0356, 0.0095, 0.0258, 0.0113, 0.0146, 0.0073, 0.0112,
        0.0121, 0.0124, 0.0161, 0.0266, 0.0133], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,877][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0048, 0.0288, 0.1560, 0.0255, 0.1511, 0.0704, 0.0401, 0.0655, 0.1168,
        0.0356, 0.0228, 0.1052, 0.1486, 0.0289], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,880][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0372, 0.7011, 0.0535, 0.0753, 0.0337, 0.0056, 0.0037, 0.0008, 0.0111,
        0.0186, 0.0267, 0.0109, 0.0190, 0.0030], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,881][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.2016, 0.4661, 0.1338, 0.0616, 0.0280, 0.0135, 0.0042, 0.0087, 0.0059,
        0.0157, 0.0181, 0.0180, 0.0179, 0.0069], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,881][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0520, 0.6018, 0.0613, 0.0870, 0.0267, 0.0140, 0.0092, 0.0060, 0.0121,
        0.0320, 0.0419, 0.0253, 0.0113, 0.0192], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,882][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.9026, 0.0128, 0.0087, 0.0037, 0.0087, 0.0051, 0.0044, 0.0020, 0.0038,
        0.0075, 0.0078, 0.0156, 0.0101, 0.0071], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,882][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2210, 0.0740, 0.0560, 0.0707, 0.0440, 0.0718, 0.0756, 0.0846, 0.0426,
        0.0746, 0.0572, 0.0405, 0.0372, 0.0504], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,882][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0130, 0.0725, 0.0788, 0.0826, 0.0784, 0.0715, 0.0706, 0.0760, 0.0682,
        0.0789, 0.0899, 0.0790, 0.0773, 0.0633], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,883][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0241, 0.0670, 0.1003, 0.0790, 0.1100, 0.0753, 0.0418, 0.0718, 0.0672,
        0.0648, 0.0686, 0.1253, 0.0830, 0.0216], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,883][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0186, 0.0831, 0.0895, 0.0755, 0.0867, 0.0785, 0.0771, 0.0713, 0.0627,
        0.0655, 0.0705, 0.0701, 0.0766, 0.0746], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,883][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0179, 0.0720, 0.0814, 0.0730, 0.0812, 0.0752, 0.0733, 0.0628, 0.0750,
        0.0728, 0.0734, 0.0652, 0.0795, 0.0973], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,884][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([9.6401e-01, 9.6561e-03, 5.2087e-04, 2.1579e-03, 9.1942e-04, 2.0590e-03,
        1.3334e-03, 3.2529e-04, 2.3034e-03, 5.1294e-03, 3.3262e-03, 2.6902e-03,
        1.3119e-03, 4.2586e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:39,887][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7833, 0.0148, 0.0336, 0.0088, 0.0252, 0.0106, 0.0138, 0.0070, 0.0106,
        0.0112, 0.0116, 0.0157, 0.0248, 0.0126, 0.0164], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,890][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0040, 0.0160, 0.1236, 0.0127, 0.0807, 0.1373, 0.0468, 0.0537, 0.2286,
        0.0179, 0.0137, 0.0473, 0.0873, 0.1028, 0.0275], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,894][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1175, 0.6976, 0.0308, 0.0417, 0.0211, 0.0042, 0.0040, 0.0008, 0.0087,
        0.0126, 0.0167, 0.0101, 0.0156, 0.0040, 0.0146], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,898][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4259, 0.2885, 0.0877, 0.0545, 0.0292, 0.0092, 0.0044, 0.0049, 0.0066,
        0.0140, 0.0120, 0.0198, 0.0214, 0.0083, 0.0135], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,901][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1612, 0.4501, 0.0410, 0.0596, 0.0247, 0.0233, 0.0132, 0.0069, 0.0207,
        0.0312, 0.0379, 0.0316, 0.0115, 0.0501, 0.0368], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,903][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.8485e-01, 4.7823e-03, 2.1305e-03, 9.9714e-04, 1.0306e-03, 7.9098e-04,
        5.1569e-04, 1.8897e-04, 2.1491e-04, 3.8979e-04, 7.3204e-04, 1.5431e-03,
        7.1520e-04, 7.1234e-04, 4.1053e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,907][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2198, 0.0648, 0.0540, 0.0550, 0.0426, 0.0705, 0.0715, 0.0774, 0.0410,
        0.0637, 0.0464, 0.0400, 0.0367, 0.0501, 0.0664], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,909][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0113, 0.0662, 0.0709, 0.0752, 0.0694, 0.0657, 0.0686, 0.0731, 0.0653,
        0.0734, 0.0824, 0.0718, 0.0685, 0.0623, 0.0757], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,910][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0103, 0.0424, 0.1103, 0.0613, 0.1146, 0.0802, 0.0474, 0.0730, 0.0925,
        0.0440, 0.0530, 0.1131, 0.0857, 0.0450, 0.0271], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,910][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0172, 0.0773, 0.0838, 0.0712, 0.0809, 0.0735, 0.0720, 0.0672, 0.0593,
        0.0606, 0.0655, 0.0652, 0.0710, 0.0697, 0.0657], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,911][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0206, 0.0641, 0.0791, 0.0667, 0.0732, 0.0705, 0.0697, 0.0635, 0.0704,
        0.0682, 0.0667, 0.0655, 0.0724, 0.0872, 0.0622], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,911][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.7495e-01, 5.9073e-03, 3.8015e-04, 1.4689e-03, 4.6278e-04, 1.0385e-03,
        8.7866e-04, 2.2885e-04, 8.9546e-04, 4.3375e-03, 3.8611e-03, 1.3343e-03,
        8.8200e-04, 1.1487e-03, 2.2253e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:39,912][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:39,913][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9443],
        [ 6980],
        [31989],
        [ 7647],
        [12020],
        [ 8812],
        [26578],
        [ 9433],
        [20127],
        [17585],
        [11374],
        [16111],
        [14280],
        [12538],
        [12235]], device='cuda:0')
[2024-07-24 10:20:39,914][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9298],
        [11098],
        [41435],
        [15680],
        [26078],
        [15400],
        [29286],
        [21539],
        [34117],
        [24037],
        [17344],
        [14697],
        [26134],
        [16481],
        [32238]], device='cuda:0')
[2024-07-24 10:20:39,915][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39527],
        [21864],
        [24866],
        [23100],
        [23327],
        [23771],
        [23669],
        [23082],
        [24855],
        [23321],
        [23146],
        [21782],
        [22236],
        [22356],
        [22405]], device='cuda:0')
[2024-07-24 10:20:39,918][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23739],
        [25406],
        [23579],
        [12947],
        [18473],
        [10308],
        [11128],
        [10633],
        [11167],
        [12145],
        [11801],
        [12181],
        [12436],
        [11700],
        [12441]], device='cuda:0')
[2024-07-24 10:20:39,919][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2188],
        [2454],
        [2945],
        [3164],
        [3810],
        [4064],
        [4329],
        [3748],
        [3888],
        [4239],
        [4627],
        [4252],
        [4421],
        [4496],
        [4746]], device='cuda:0')
[2024-07-24 10:20:39,921][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6453],
        [12300],
        [ 9731],
        [28753],
        [25143],
        [32962],
        [32961],
        [32764],
        [31811],
        [32781],
        [34131],
        [34080],
        [29650],
        [34401],
        [32066]], device='cuda:0')
[2024-07-24 10:20:39,924][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 245],
        [ 689],
        [ 428],
        [ 943],
        [1076],
        [1457],
        [1844],
        [2219],
        [2329],
        [2404],
        [2855],
        [3097],
        [2860],
        [2777],
        [2693]], device='cuda:0')
[2024-07-24 10:20:39,926][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[13717],
        [18303],
        [17358],
        [34387],
        [22273],
        [32017],
        [31853],
        [26817],
        [32370],
        [38413],
        [40276],
        [30579],
        [35032],
        [37402],
        [40437]], device='cuda:0')
[2024-07-24 10:20:39,929][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 5837],
        [ 5831],
        [ 6715],
        [ 5587],
        [ 4670],
        [ 4027],
        [ 1577],
        [ 8924],
        [ 7477],
        [ 1875],
        [ 1306],
        [12440],
        [10610],
        [ 3455],
        [ 1595]], device='cuda:0')
[2024-07-24 10:20:39,931][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[6254],
        [5472],
        [5744],
        [5582],
        [5209],
        [5483],
        [5878],
        [5173],
        [5271],
        [6902],
        [7490],
        [7919],
        [7107],
        [6265],
        [6027]], device='cuda:0')
[2024-07-24 10:20:39,934][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22029],
        [17849],
        [19252],
        [20096],
        [20808],
        [22062],
        [23127],
        [23043],
        [22601],
        [22954],
        [23055],
        [23462],
        [23366],
        [23714],
        [23919]], device='cuda:0')
[2024-07-24 10:20:39,936][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[48520],
        [48513],
        [47808],
        [48288],
        [46863],
        [47916],
        [47882],
        [46999],
        [48133],
        [48068],
        [47969],
        [47214],
        [46359],
        [46224],
        [47312]], device='cuda:0')
[2024-07-24 10:20:39,939][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[7308],
        [5140],
        [1460],
        [1811],
        [1300],
        [1493],
        [1537],
        [1670],
        [1862],
        [2029],
        [2123],
        [2263],
        [1838],
        [1905],
        [1962]], device='cuda:0')
[2024-07-24 10:20:39,941][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33571],
        [22850],
        [12185],
        [13236],
        [ 4614],
        [10658],
        [10865],
        [ 4056],
        [ 3525],
        [ 6084],
        [ 5107],
        [ 4014],
        [ 3203],
        [ 4183],
        [ 3796]], device='cuda:0')
[2024-07-24 10:20:39,944][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[42781],
        [ 9917],
        [ 4343],
        [ 6155],
        [ 4405],
        [13626],
        [25253],
        [ 6703],
        [15449],
        [15159],
        [16774],
        [26616],
        [12798],
        [26151],
        [ 9361]], device='cuda:0')
[2024-07-24 10:20:39,945][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29010],
        [28284],
        [26216],
        [28418],
        [23721],
        [27496],
        [27715],
        [27883],
        [27111],
        [27551],
        [27607],
        [21628],
        [20794],
        [23301],
        [23116]], device='cuda:0')
[2024-07-24 10:20:39,945][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 3984],
        [ 9623],
        [ 8642],
        [ 7485],
        [ 6990],
        [ 6331],
        [ 6639],
        [ 6619],
        [ 7254],
        [ 8560],
        [ 8792],
        [ 9311],
        [10416],
        [ 8272],
        [ 9300]], device='cuda:0')
[2024-07-24 10:20:39,946][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[25962],
        [32102],
        [27367],
        [33357],
        [33927],
        [32510],
        [32627],
        [32925],
        [33354],
        [33255],
        [33556],
        [32355],
        [33710],
        [33092],
        [33840]], device='cuda:0')
[2024-07-24 10:20:39,947][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 7836],
        [ 6592],
        [ 6991],
        [17510],
        [13930],
        [22835],
        [22708],
        [23053],
        [20873],
        [21185],
        [20751],
        [23749],
        [18483],
        [21535],
        [19942]], device='cuda:0')
[2024-07-24 10:20:39,948][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20955],
        [17953],
        [18209],
        [10619],
        [ 9950],
        [ 9569],
        [ 9695],
        [ 9230],
        [ 9559],
        [10007],
        [ 9721],
        [ 8852],
        [ 9807],
        [ 9073],
        [ 9659]], device='cuda:0')
[2024-07-24 10:20:39,950][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19829],
        [19843],
        [19820],
        [19614],
        [19773],
        [19422],
        [19529],
        [19731],
        [19578],
        [19633],
        [19572],
        [19689],
        [19779],
        [20242],
        [19762]], device='cuda:0')
[2024-07-24 10:20:39,952][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27667],
        [24570],
        [20901],
        [21738],
        [21833],
        [22546],
        [21459],
        [21485],
        [21174],
        [21574],
        [21920],
        [21071],
        [20734],
        [20567],
        [20770]], device='cuda:0')
[2024-07-24 10:20:39,953][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[7426],
        [1188],
        [2031],
        [1692],
        [1762],
        [1611],
        [1443],
        [1353],
        [1304],
        [1271],
        [1273],
        [1266],
        [1323],
        [1253],
        [1249]], device='cuda:0')
[2024-07-24 10:20:39,955][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[28515],
        [ 6441],
        [ 7803],
        [ 8497],
        [ 9286],
        [ 9037],
        [ 8965],
        [ 8684],
        [ 7767],
        [ 7087],
        [ 7111],
        [ 8488],
        [ 8213],
        [ 8339],
        [ 7670]], device='cuda:0')
[2024-07-24 10:20:39,958][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[13893],
        [27422],
        [25125],
        [25577],
        [25518],
        [25833],
        [25859],
        [25894],
        [25943],
        [26217],
        [26474],
        [26780],
        [27011],
        [26965],
        [27113]], device='cuda:0')
[2024-07-24 10:20:39,960][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21397],
        [12965],
        [16757],
        [14616],
        [17490],
        [16437],
        [16703],
        [16239],
        [17037],
        [16068],
        [15446],
        [14557],
        [16062],
        [16417],
        [16320]], device='cuda:0')
[2024-07-24 10:20:39,963][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[35962],
        [36585],
        [36171],
        [37077],
        [36467],
        [37518],
        [38043],
        [36701],
        [37201],
        [38408],
        [38855],
        [40006],
        [38164],
        [39247],
        [38433]], device='cuda:0')
[2024-07-24 10:20:39,965][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21663],
        [26568],
        [28570],
        [27507],
        [28075],
        [26511],
        [26682],
        [27017],
        [27479],
        [27140],
        [27140],
        [27598],
        [28154],
        [27381],
        [27714]], device='cuda:0')
[2024-07-24 10:20:39,968][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23546],
        [31565],
        [28829],
        [23465],
        [28844],
        [23401],
        [23634],
        [29435],
        [20958],
        [25863],
        [24141],
        [28804],
        [27638],
        [23877],
        [24424]], device='cuda:0')
[2024-07-24 10:20:39,970][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283],
        [16283]], device='cuda:0')
[2024-07-24 10:20:40,006][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:40,007][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,007][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,007][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,008][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,008][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,008][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,009][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,010][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,012][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,015][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,017][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,017][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,017][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9776, 0.0224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,018][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1880, 0.8120], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,018][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4969, 0.5031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,018][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3235, 0.6765], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,019][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9440, 0.0560], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,019][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5499, 0.4501], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,019][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9670, 0.0330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,031][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7506, 0.2494], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,034][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6361, 0.3639], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,038][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7477, 0.2523], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,042][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9488, 0.0512], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,045][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3785, 0.6215], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,045][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.9761, 0.0143, 0.0096], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,045][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.0504, 0.4567, 0.4929], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,045][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.3532, 0.3461, 0.3006], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,046][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.1631, 0.4246, 0.4123], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,046][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.9819, 0.0091, 0.0089], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,046][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.6885, 0.2418, 0.0697], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,046][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.9880, 0.0094, 0.0026], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,047][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.7763, 0.2177, 0.0060], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,047][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.9630, 0.0152, 0.0219], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,049][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.2863, 0.1600, 0.5537], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,051][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.9849, 0.0138, 0.0013], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,055][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.3848, 0.4867, 0.1285], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,059][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9479, 0.0209, 0.0081, 0.0231], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,062][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0516, 0.2935, 0.3804, 0.2744], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,066][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3087, 0.2677, 0.2250, 0.1987], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,070][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1198, 0.2896, 0.2507, 0.3399], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,073][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9104, 0.0340, 0.0312, 0.0243], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,073][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1584, 0.7059, 0.1005, 0.0351], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,073][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9666, 0.0202, 0.0059, 0.0073], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,074][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1942, 0.7566, 0.0203, 0.0288], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,074][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2669, 0.4565, 0.2573, 0.0193], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,074][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2159, 0.0924, 0.5760, 0.1157], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,075][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9767, 0.0202, 0.0017, 0.0014], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,075][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2498, 0.2780, 0.3808, 0.0913], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,075][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.9529, 0.0141, 0.0074, 0.0181, 0.0075], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,075][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0308, 0.2354, 0.2783, 0.2231, 0.2324], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,076][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.2808, 0.2325, 0.1915, 0.1691, 0.1261], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,077][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0827, 0.2250, 0.2121, 0.2760, 0.2042], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,080][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.9720, 0.0075, 0.0056, 0.0062, 0.0087], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,084][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.3156, 0.5496, 0.0785, 0.0427, 0.0137], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,088][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.9835, 0.0090, 0.0024, 0.0030, 0.0021], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,091][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.5516, 0.4109, 0.0109, 0.0220, 0.0046], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,096][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.6613, 0.2219, 0.0823, 0.0219, 0.0125], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,100][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.1827, 0.0899, 0.4034, 0.1292, 0.1948], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,102][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([9.8156e-01, 1.5649e-02, 1.3895e-03, 1.0616e-03, 3.4354e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,103][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.3809, 0.3724, 0.0503, 0.1148, 0.0816], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,103][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8466, 0.0387, 0.0194, 0.0345, 0.0256, 0.0351], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,103][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0286, 0.1911, 0.2219, 0.1812, 0.1929, 0.1843], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,103][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2335, 0.2045, 0.1741, 0.1524, 0.1154, 0.1201], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,104][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0684, 0.1796, 0.1792, 0.2226, 0.1831, 0.1672], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,104][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.9185, 0.0193, 0.0152, 0.0116, 0.0175, 0.0179], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,104][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0333, 0.7182, 0.1447, 0.0724, 0.0211, 0.0102], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,105][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.9668, 0.0146, 0.0043, 0.0053, 0.0037, 0.0053], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,106][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0593, 0.7877, 0.0572, 0.0516, 0.0293, 0.0150], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,109][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0942, 0.5306, 0.2889, 0.0388, 0.0362, 0.0111], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,113][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3427, 0.0517, 0.2461, 0.0706, 0.2269, 0.0620], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,115][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.5648e-01, 3.6824e-02, 3.0139e-03, 2.3933e-03, 6.8649e-04, 6.0078e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,118][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0302, 0.3445, 0.2275, 0.1441, 0.2131, 0.0407], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,122][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6783, 0.0517, 0.0204, 0.0755, 0.0451, 0.0909, 0.0382],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,126][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0189, 0.1609, 0.1962, 0.1516, 0.1676, 0.1567, 0.1480],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,130][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2280, 0.1783, 0.1476, 0.1337, 0.0998, 0.1040, 0.1085],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,131][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0619, 0.1553, 0.1471, 0.1904, 0.1554, 0.1552, 0.1346],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,132][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8845, 0.0183, 0.0137, 0.0136, 0.0146, 0.0243, 0.0311],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,132][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0296, 0.7111, 0.1368, 0.0812, 0.0240, 0.0122, 0.0051],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,132][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.9571, 0.0167, 0.0049, 0.0060, 0.0042, 0.0058, 0.0053],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,133][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0508, 0.8001, 0.0294, 0.0645, 0.0170, 0.0184, 0.0199],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,133][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2374, 0.3818, 0.2662, 0.0451, 0.0423, 0.0222, 0.0050],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,133][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1404, 0.0686, 0.2813, 0.0947, 0.2480, 0.1075, 0.0596],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,134][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.7803e-01, 1.8536e-02, 1.4724e-03, 1.1624e-03, 3.4832e-04, 2.8046e-04,
        1.7520e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,134][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0444, 0.1345, 0.1500, 0.1030, 0.4605, 0.0644, 0.0431],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,134][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.6611, 0.0570, 0.0202, 0.0658, 0.0414, 0.0828, 0.0395, 0.0320],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,136][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0167, 0.1392, 0.1729, 0.1310, 0.1452, 0.1399, 0.1326, 0.1225],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,138][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1736, 0.1655, 0.1350, 0.1232, 0.0884, 0.0977, 0.1031, 0.1134],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,142][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0592, 0.1281, 0.1252, 0.1583, 0.1299, 0.1281, 0.1178, 0.1532],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,146][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.8036, 0.0211, 0.0174, 0.0177, 0.0249, 0.0283, 0.0382, 0.0488],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,150][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0309, 0.7459, 0.1122, 0.0700, 0.0279, 0.0077, 0.0038, 0.0016],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,154][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.9704, 0.0099, 0.0028, 0.0035, 0.0024, 0.0035, 0.0033, 0.0042],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,157][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0800, 0.8125, 0.0211, 0.0439, 0.0104, 0.0127, 0.0155, 0.0040],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,161][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.6796, 0.1511, 0.1005, 0.0219, 0.0216, 0.0143, 0.0057, 0.0054],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,161][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0745, 0.0731, 0.2728, 0.0967, 0.2083, 0.1094, 0.0992, 0.0660],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,162][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([9.5915e-01, 3.1373e-02, 2.6151e-03, 2.0085e-03, 7.0758e-04, 5.4715e-04,
        3.3859e-04, 3.2614e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,162][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1685, 0.1521, 0.1023, 0.0934, 0.3859, 0.0332, 0.0378, 0.0266],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,162][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3628, 0.0660, 0.0212, 0.1454, 0.0620, 0.1550, 0.0732, 0.0903, 0.0241],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,163][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0125, 0.1261, 0.1521, 0.1174, 0.1287, 0.1208, 0.1175, 0.1152, 0.1097],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,163][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1576, 0.1491, 0.1221, 0.1089, 0.0789, 0.0867, 0.0913, 0.1011, 0.1042],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,163][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0413, 0.1155, 0.1095, 0.1463, 0.1102, 0.1105, 0.1083, 0.1392, 0.1192],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,164][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.8310, 0.0183, 0.0099, 0.0149, 0.0190, 0.0256, 0.0379, 0.0366, 0.0069],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,164][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0707, 0.7544, 0.0839, 0.0551, 0.0146, 0.0079, 0.0033, 0.0017, 0.0082],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,166][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.9674, 0.0095, 0.0027, 0.0034, 0.0023, 0.0035, 0.0032, 0.0038, 0.0043],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,169][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0568, 0.8499, 0.0175, 0.0461, 0.0092, 0.0097, 0.0079, 0.0016, 0.0012],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,172][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.6214, 0.2220, 0.0861, 0.0200, 0.0130, 0.0078, 0.0061, 0.0087, 0.0150],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,176][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0917, 0.0546, 0.2761, 0.0744, 0.1852, 0.0933, 0.0614, 0.0849, 0.0784],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,179][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([9.5784e-01, 3.2357e-02, 2.5169e-03, 1.9850e-03, 6.2256e-04, 5.2134e-04,
        3.1196e-04, 2.9918e-03, 8.5346e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,182][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1194, 0.3251, 0.1022, 0.0974, 0.2141, 0.0600, 0.0317, 0.0269, 0.0232],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,186][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3222, 0.0873, 0.0310, 0.0937, 0.0689, 0.1378, 0.0645, 0.0875, 0.0251,
        0.0818], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,189][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0183, 0.1104, 0.1364, 0.1033, 0.1136, 0.1131, 0.1078, 0.1037, 0.1009,
        0.0926], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,193][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1563, 0.1305, 0.1070, 0.0979, 0.0718, 0.0772, 0.0789, 0.0888, 0.0957,
        0.0958], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,193][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0484, 0.1016, 0.0915, 0.1213, 0.0968, 0.1041, 0.0945, 0.1221, 0.1038,
        0.1158], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,194][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6719, 0.0328, 0.0253, 0.0248, 0.0312, 0.0417, 0.0527, 0.0653, 0.0153,
        0.0390], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,194][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0486, 0.7143, 0.1260, 0.0584, 0.0165, 0.0098, 0.0031, 0.0016, 0.0077,
        0.0142], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,194][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9504, 0.0128, 0.0037, 0.0048, 0.0033, 0.0045, 0.0041, 0.0049, 0.0057,
        0.0058], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,195][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0558, 0.8307, 0.0287, 0.0403, 0.0110, 0.0101, 0.0108, 0.0032, 0.0017,
        0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,195][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1282, 0.4039, 0.3283, 0.0251, 0.0372, 0.0151, 0.0061, 0.0169, 0.0281,
        0.0109], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,195][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0874, 0.0357, 0.2481, 0.0545, 0.1800, 0.0909, 0.0671, 0.0686, 0.1249,
        0.0428], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,196][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.6975e-01, 2.2966e-02, 1.7476e-03, 1.3707e-03, 4.0775e-04, 3.4539e-04,
        2.2826e-04, 2.0977e-03, 5.2774e-04, 5.6093e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,196][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0283, 0.0729, 0.2743, 0.0263, 0.3689, 0.0306, 0.0166, 0.0265, 0.0737,
        0.0819], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,198][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2537, 0.0684, 0.0214, 0.0750, 0.0555, 0.1647, 0.0848, 0.0863, 0.0284,
        0.1057, 0.0560], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,200][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0170, 0.0982, 0.1259, 0.0910, 0.1047, 0.1038, 0.1001, 0.0937, 0.0947,
        0.0860, 0.0849], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,204][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1385, 0.1188, 0.0981, 0.0911, 0.0665, 0.0716, 0.0736, 0.0820, 0.0879,
        0.0880, 0.0838], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,209][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0377, 0.0934, 0.0816, 0.1114, 0.0828, 0.0899, 0.0867, 0.1128, 0.0898,
        0.1088, 0.1053], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,212][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6576, 0.0320, 0.0271, 0.0231, 0.0310, 0.0337, 0.0422, 0.0620, 0.0167,
        0.0335, 0.0411], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,216][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0831, 0.6815, 0.1053, 0.0495, 0.0218, 0.0123, 0.0038, 0.0015, 0.0096,
        0.0168, 0.0147], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,220][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.9483, 0.0119, 0.0034, 0.0045, 0.0032, 0.0042, 0.0038, 0.0047, 0.0053,
        0.0055, 0.0052], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,223][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([6.2902e-02, 8.7027e-01, 1.2680e-02, 2.6169e-02, 6.3126e-03, 5.7798e-03,
        6.5347e-03, 1.7325e-03, 6.4263e-04, 5.1302e-03, 1.8489e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,223][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0993, 0.4748, 0.2645, 0.0200, 0.0424, 0.0149, 0.0068, 0.0199, 0.0256,
        0.0133, 0.0187], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,223][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2532, 0.0299, 0.2012, 0.0373, 0.1522, 0.0670, 0.0443, 0.0521, 0.1084,
        0.0383, 0.0161], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,224][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.7085e-01, 2.0958e-02, 1.7832e-03, 1.4547e-03, 4.3954e-04, 4.0466e-04,
        2.5404e-04, 2.2800e-03, 5.8629e-04, 5.9307e-04, 3.9141e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,224][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0509, 0.0656, 0.2594, 0.0163, 0.3764, 0.0257, 0.0150, 0.0172, 0.0475,
        0.0559, 0.0701], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,224][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.3948, 0.0732, 0.0279, 0.0792, 0.0490, 0.0967, 0.0627, 0.0443, 0.0157,
        0.0711, 0.0519, 0.0335], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,225][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0117, 0.0934, 0.1112, 0.0880, 0.0941, 0.0939, 0.0931, 0.0872, 0.0856,
        0.0805, 0.0815, 0.0798], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,225][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1313, 0.1108, 0.0915, 0.0845, 0.0612, 0.0666, 0.0714, 0.0778, 0.0826,
        0.0832, 0.0807, 0.0585], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,225][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0288, 0.0805, 0.0773, 0.1035, 0.0735, 0.0848, 0.0813, 0.1017, 0.0863,
        0.1015, 0.0983, 0.0827], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,226][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.6747, 0.0232, 0.0150, 0.0196, 0.0237, 0.0278, 0.0416, 0.0578, 0.0128,
        0.0317, 0.0416, 0.0305], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,227][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0486, 0.6089, 0.1192, 0.0720, 0.0280, 0.0163, 0.0074, 0.0041, 0.0107,
        0.0336, 0.0286, 0.0226], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,230][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.9723, 0.0066, 0.0017, 0.0022, 0.0014, 0.0021, 0.0020, 0.0023, 0.0026,
        0.0027, 0.0024, 0.0018], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,234][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0928, 0.7081, 0.0160, 0.0763, 0.0124, 0.0192, 0.0285, 0.0085, 0.0059,
        0.0186, 0.0111, 0.0027], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,238][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.2758, 0.2288, 0.1391, 0.0401, 0.0310, 0.0360, 0.0212, 0.0453, 0.0462,
        0.0294, 0.0583, 0.0489], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,241][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0394, 0.0455, 0.2352, 0.0694, 0.1405, 0.0913, 0.0639, 0.0617, 0.1114,
        0.0542, 0.0377, 0.0498], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,244][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([9.7672e-01, 1.7747e-02, 1.2566e-03, 9.5955e-04, 3.3600e-04, 2.5053e-04,
        1.7278e-04, 1.4262e-03, 3.7098e-04, 3.4391e-04, 2.4431e-04, 1.7511e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,248][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0396, 0.1434, 0.0780, 0.0695, 0.1289, 0.0353, 0.0355, 0.0180, 0.0169,
        0.1565, 0.2147, 0.0636], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,252][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.5336, 0.0325, 0.0145, 0.0604, 0.0232, 0.0743, 0.0390, 0.0471, 0.0108,
        0.0665, 0.0540, 0.0279, 0.0163], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,252][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0111, 0.0855, 0.1018, 0.0813, 0.0858, 0.0870, 0.0823, 0.0811, 0.0786,
        0.0734, 0.0755, 0.0770, 0.0797], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,253][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.1203, 0.1072, 0.0877, 0.0791, 0.0583, 0.0628, 0.0667, 0.0732, 0.0756,
        0.0767, 0.0743, 0.0555, 0.0626], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,253][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0286, 0.0760, 0.0722, 0.0936, 0.0695, 0.0758, 0.0708, 0.0945, 0.0804,
        0.0916, 0.0889, 0.0858, 0.0722], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,254][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.7744, 0.0128, 0.0107, 0.0119, 0.0155, 0.0228, 0.0316, 0.0325, 0.0078,
        0.0196, 0.0219, 0.0160, 0.0224], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,254][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.1294, 0.6000, 0.0847, 0.0693, 0.0197, 0.0140, 0.0042, 0.0024, 0.0091,
        0.0239, 0.0219, 0.0165, 0.0049], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,254][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.9741, 0.0059, 0.0016, 0.0020, 0.0013, 0.0019, 0.0017, 0.0020, 0.0023,
        0.0023, 0.0021, 0.0014, 0.0013], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,255][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.2249, 0.6845, 0.0116, 0.0372, 0.0066, 0.0110, 0.0091, 0.0018, 0.0011,
        0.0070, 0.0029, 0.0014, 0.0010], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,255][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.4839, 0.2637, 0.0950, 0.0277, 0.0272, 0.0127, 0.0064, 0.0088, 0.0118,
        0.0105, 0.0139, 0.0252, 0.0133], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,255][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0607, 0.0394, 0.1733, 0.0577, 0.0747, 0.0845, 0.0586, 0.0649, 0.1413,
        0.0492, 0.0314, 0.0798, 0.0846], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,256][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([9.7725e-01, 1.7070e-02, 1.2243e-03, 8.2575e-04, 3.3695e-04, 2.4125e-04,
        1.5101e-04, 1.3347e-03, 3.8027e-04, 3.9266e-04, 2.5423e-04, 1.6724e-04,
        3.7170e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,259][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0758, 0.0994, 0.0217, 0.0621, 0.0821, 0.0546, 0.0375, 0.0077, 0.0081,
        0.2017, 0.2652, 0.0446, 0.0394], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,262][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.4582, 0.0769, 0.0275, 0.0630, 0.0383, 0.0645, 0.0265, 0.0313, 0.0139,
        0.0629, 0.0435, 0.0325, 0.0218, 0.0391], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,266][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0084, 0.0782, 0.1009, 0.0759, 0.0812, 0.0791, 0.0767, 0.0750, 0.0738,
        0.0680, 0.0721, 0.0706, 0.0757, 0.0643], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,270][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1001, 0.0980, 0.0827, 0.0735, 0.0553, 0.0592, 0.0635, 0.0699, 0.0715,
        0.0739, 0.0716, 0.0533, 0.0602, 0.0673], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,273][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0253, 0.0729, 0.0685, 0.0882, 0.0667, 0.0722, 0.0667, 0.0851, 0.0783,
        0.0864, 0.0841, 0.0760, 0.0680, 0.0616], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,277][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.6346, 0.0235, 0.0172, 0.0190, 0.0239, 0.0326, 0.0511, 0.0488, 0.0096,
        0.0312, 0.0340, 0.0271, 0.0329, 0.0145], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,281][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0135, 0.7672, 0.0738, 0.0486, 0.0127, 0.0071, 0.0025, 0.0009, 0.0048,
        0.0186, 0.0185, 0.0129, 0.0041, 0.0149], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,282][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.9519, 0.0089, 0.0025, 0.0031, 0.0022, 0.0032, 0.0031, 0.0037, 0.0040,
        0.0039, 0.0036, 0.0026, 0.0021, 0.0052], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,282][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0330, 0.8592, 0.0129, 0.0364, 0.0062, 0.0125, 0.0087, 0.0026, 0.0013,
        0.0083, 0.0036, 0.0014, 0.0013, 0.0124], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,282][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0343, 0.6694, 0.1570, 0.0245, 0.0207, 0.0073, 0.0038, 0.0055, 0.0104,
        0.0124, 0.0182, 0.0195, 0.0089, 0.0082], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,283][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0299, 0.0373, 0.2043, 0.0489, 0.1394, 0.0621, 0.0426, 0.0510, 0.0641,
        0.0381, 0.0292, 0.0598, 0.1477, 0.0459], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,283][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([9.7609e-01, 1.6611e-02, 1.4546e-03, 1.1320e-03, 3.9497e-04, 3.1395e-04,
        1.8982e-04, 1.6446e-03, 5.0066e-04, 4.5533e-04, 3.2480e-04, 2.0847e-04,
        4.2401e-04, 2.5595e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,284][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0322, 0.2632, 0.0983, 0.0460, 0.0775, 0.0192, 0.0161, 0.0125, 0.0168,
        0.1166, 0.1637, 0.0547, 0.0208, 0.0624], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,284][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5067, 0.0544, 0.0152, 0.0508, 0.0338, 0.0580, 0.0336, 0.0296, 0.0115,
        0.0477, 0.0358, 0.0279, 0.0214, 0.0448, 0.0288], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,284][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0100, 0.0747, 0.0944, 0.0692, 0.0758, 0.0755, 0.0723, 0.0724, 0.0699,
        0.0641, 0.0653, 0.0646, 0.0699, 0.0610, 0.0609], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,285][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1083, 0.0898, 0.0743, 0.0675, 0.0496, 0.0531, 0.0556, 0.0628, 0.0662,
        0.0658, 0.0636, 0.0469, 0.0537, 0.0607, 0.0820], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,287][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0257, 0.0691, 0.0618, 0.0823, 0.0612, 0.0682, 0.0641, 0.0811, 0.0679,
        0.0812, 0.0778, 0.0700, 0.0630, 0.0588, 0.0676], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,289][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5097, 0.0243, 0.0233, 0.0229, 0.0351, 0.0401, 0.0506, 0.0628, 0.0179,
        0.0392, 0.0448, 0.0352, 0.0396, 0.0199, 0.0346], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,293][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1095, 0.6573, 0.0640, 0.0509, 0.0161, 0.0097, 0.0031, 0.0011, 0.0059,
        0.0135, 0.0136, 0.0137, 0.0041, 0.0227, 0.0148], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,297][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.9539, 0.0078, 0.0022, 0.0027, 0.0019, 0.0027, 0.0026, 0.0031, 0.0035,
        0.0036, 0.0033, 0.0024, 0.0020, 0.0047, 0.0035], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,299][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.2357e-01, 8.1720e-01, 7.0980e-03, 2.0443e-02, 5.0118e-03, 5.2923e-03,
        5.1310e-03, 1.0159e-03, 5.0229e-04, 3.8948e-03, 1.5434e-03, 5.4680e-04,
        9.7457e-04, 5.4775e-03, 2.2966e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,302][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1482, 0.4727, 0.1536, 0.0213, 0.0317, 0.0142, 0.0058, 0.0141, 0.0212,
        0.0095, 0.0196, 0.0433, 0.0234, 0.0186, 0.0027], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,306][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0310, 0.0357, 0.1796, 0.0426, 0.1169, 0.0647, 0.0439, 0.0467, 0.0942,
        0.0384, 0.0258, 0.0443, 0.1300, 0.0730, 0.0333], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,309][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.6315e-01, 2.5928e-02, 2.0319e-03, 1.4812e-03, 5.4882e-04, 4.1850e-04,
        2.6989e-04, 2.6902e-03, 7.4725e-04, 6.6476e-04, 4.3768e-04, 3.0668e-04,
        5.9604e-04, 3.4290e-04, 3.9105e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,311][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0524, 0.0610, 0.1469, 0.0176, 0.2455, 0.0208, 0.0085, 0.0124, 0.0273,
        0.0473, 0.0945, 0.0432, 0.0711, 0.0867, 0.0648], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,336][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:40,337][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,337][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,337][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,338][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,338][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,338][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,339][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,339][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,339][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,340][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,340][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,340][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,340][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9855, 0.0145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,341][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2835, 0.7165], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,341][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9671, 0.0329], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,341][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9776, 0.0224], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,342][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9997e-01, 2.5531e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,342][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5464, 0.4536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,342][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9936e-01, 6.4427e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,343][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8452, 0.1548], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,343][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9478, 0.0522], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,343][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0157, 0.9843], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,344][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9961e-01, 3.9383e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,344][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3896, 0.6104], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,344][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.9903, 0.0082, 0.0015], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,345][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.5430, 0.2931, 0.1639], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,345][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.9737, 0.0101, 0.0162], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,345][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([9.9856e-01, 1.2282e-03, 2.1522e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,346][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([1.0000e+00, 2.4899e-06, 1.1281e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,346][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([0.6812, 0.2453, 0.0735], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,346][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([9.9994e-01, 3.7696e-05, 2.4570e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,347][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.9178, 0.0710, 0.0112], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,347][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.9876, 0.0114, 0.0010], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,347][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.9041, 0.0670, 0.0289], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,350][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([9.9998e-01, 1.4240e-05, 3.5851e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,354][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.4005, 0.4709, 0.1286], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,360][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8586, 0.1310, 0.0075, 0.0030], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,362][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0226, 0.7871, 0.1669, 0.0233], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,362][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9041, 0.0364, 0.0506, 0.0089], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,362][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9301, 0.0543, 0.0101, 0.0054], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,363][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9993e-01, 4.8942e-05, 8.6834e-06, 9.0293e-06], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,363][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1650, 0.6950, 0.1026, 0.0374], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,363][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9952e-01, 2.9234e-04, 7.4282e-05, 1.1418e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,364][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3367, 0.5572, 0.0681, 0.0380], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,364][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5161, 0.4497, 0.0238, 0.0105], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,364][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0100, 0.5242, 0.3013, 0.1645], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,364][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9952e-01, 3.3295e-04, 3.7163e-05, 1.0516e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,365][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0392, 0.7615, 0.1780, 0.0213], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,366][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([9.3297e-01, 5.9015e-02, 5.2278e-03, 2.1945e-03, 5.8772e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,370][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0857, 0.7043, 0.1692, 0.0173, 0.0234], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,376][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.9335, 0.0220, 0.0283, 0.0058, 0.0103], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,378][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([9.7954e-01, 1.5041e-02, 2.0220e-03, 2.4467e-03, 9.4928e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,382][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([9.9997e-01, 2.1095e-05, 3.8287e-06, 4.5035e-06, 4.8155e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,387][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.3265, 0.5337, 0.0800, 0.0452, 0.0146], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,388][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.9990e-01, 3.7572e-05, 2.2990e-05, 1.7056e-05, 2.0051e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,389][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.7773, 0.1740, 0.0251, 0.0161, 0.0074], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,389][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.8025, 0.1815, 0.0062, 0.0086, 0.0012], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,389][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.6016, 0.1955, 0.0820, 0.0636, 0.0573], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,390][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([9.9973e-01, 9.4216e-05, 1.5934e-05, 7.9384e-05, 8.3502e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,390][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0730, 0.7975, 0.0769, 0.0390, 0.0137], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,390][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3061, 0.5874, 0.0732, 0.0183, 0.0119, 0.0031], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,390][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0054, 0.7562, 0.1578, 0.0327, 0.0393, 0.0086], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,391][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.8351, 0.0506, 0.0662, 0.0158, 0.0269, 0.0055], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,391][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6606, 0.2029, 0.0583, 0.0389, 0.0224, 0.0170], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,392][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([9.9914e-01, 3.9410e-04, 7.2844e-05, 6.4679e-05, 1.4819e-04, 1.7681e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,397][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0348, 0.7083, 0.1469, 0.0761, 0.0223, 0.0115], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,400][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([9.9896e-01, 4.0486e-04, 9.9328e-05, 1.9131e-04, 9.8232e-05, 2.4871e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,405][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0926, 0.6262, 0.1553, 0.0566, 0.0534, 0.0159], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,410][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0412, 0.8566, 0.0554, 0.0363, 0.0088, 0.0017], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,415][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0126, 0.2108, 0.1441, 0.1708, 0.2485, 0.2131], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,415][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([9.9800e-01, 6.9416e-04, 8.0245e-05, 2.7537e-04, 2.5304e-04, 6.9989e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,415][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0027, 0.7015, 0.2259, 0.0344, 0.0323, 0.0032], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,415][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4180, 0.5064, 0.0352, 0.0226, 0.0102, 0.0052, 0.0024],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,416][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0142, 0.7619, 0.0903, 0.0618, 0.0438, 0.0209, 0.0070],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,416][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.8791, 0.0431, 0.0442, 0.0122, 0.0154, 0.0037, 0.0024],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,416][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.7315, 0.1610, 0.0364, 0.0282, 0.0137, 0.0222, 0.0069],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,417][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.9957e-01, 1.1364e-04, 1.4627e-05, 1.7356e-05, 3.8832e-05, 1.1540e-04,
        1.3503e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,417][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0306, 0.7006, 0.1390, 0.0852, 0.0253, 0.0137, 0.0057],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,417][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9876e-01, 3.0914e-04, 1.0274e-04, 1.9425e-04, 9.2445e-05, 2.3489e-04,
        3.0363e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,421][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0790, 0.6319, 0.1063, 0.0849, 0.0451, 0.0224, 0.0303],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,425][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0918, 0.7768, 0.0625, 0.0522, 0.0123, 0.0036, 0.0008],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,431][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0339, 0.2237, 0.1656, 0.1331, 0.1452, 0.1553, 0.1432],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,433][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.9848e-01, 2.1890e-04, 2.0896e-05, 1.0849e-04, 8.2263e-05, 2.4836e-04,
        8.3618e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,439][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0030, 0.7360, 0.1467, 0.0538, 0.0516, 0.0068, 0.0021],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,441][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([4.0659e-01, 5.4087e-01, 2.4606e-02, 1.2940e-02, 8.5459e-03, 3.7631e-03,
        2.3422e-03, 3.4485e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,441][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0138, 0.7617, 0.1443, 0.0271, 0.0428, 0.0049, 0.0027, 0.0027],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,442][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.7886, 0.0660, 0.1000, 0.0121, 0.0248, 0.0045, 0.0028, 0.0011],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,442][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.8217, 0.1110, 0.0212, 0.0200, 0.0102, 0.0102, 0.0038, 0.0018],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,442][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([9.9978e-01, 7.3211e-05, 1.2136e-05, 6.1951e-06, 3.2908e-05, 4.0581e-05,
        5.4551e-05, 2.8578e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,443][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0325, 0.7353, 0.1144, 0.0737, 0.0293, 0.0088, 0.0042, 0.0017],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,443][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([9.9949e-01, 1.4461e-04, 4.4341e-05, 7.0750e-05, 3.0234e-05, 8.5182e-05,
        1.0128e-04, 3.4769e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,443][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1767, 0.6295, 0.0724, 0.0532, 0.0252, 0.0149, 0.0215, 0.0065],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,444][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.3062, 0.5964, 0.0381, 0.0441, 0.0099, 0.0034, 0.0013, 0.0007],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,444][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0296, 0.1436, 0.0583, 0.0937, 0.0623, 0.1086, 0.2369, 0.2670],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,445][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([9.9976e-01, 3.0278e-05, 3.0517e-06, 1.2399e-05, 8.3797e-06, 3.2847e-05,
        8.5172e-05, 7.2295e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,447][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([5.1871e-03, 7.7179e-01, 1.3282e-01, 4.0724e-02, 4.3755e-02, 3.1229e-03,
        1.9300e-03, 6.7369e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,453][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.4049, 0.5343, 0.0211, 0.0184, 0.0084, 0.0038, 0.0023, 0.0008, 0.0058],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,458][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0350, 0.7333, 0.1288, 0.0361, 0.0466, 0.0075, 0.0030, 0.0020, 0.0077],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,463][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.8946, 0.0311, 0.0365, 0.0080, 0.0136, 0.0034, 0.0023, 0.0009, 0.0097],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,467][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.9086, 0.0609, 0.0095, 0.0062, 0.0042, 0.0050, 0.0014, 0.0016, 0.0025],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,468][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([9.9988e-01, 3.6937e-05, 7.0863e-06, 6.7980e-06, 1.8626e-05, 1.8569e-05,
        2.7894e-05, 2.2547e-06, 1.4181e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,468][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0734, 0.7405, 0.0872, 0.0592, 0.0158, 0.0092, 0.0038, 0.0019, 0.0089],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,468][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([9.9968e-01, 7.1325e-05, 2.3925e-05, 4.6016e-05, 2.3883e-05, 5.8162e-05,
        5.2884e-05, 1.8694e-05, 2.3856e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,469][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1607, 0.6517, 0.0716, 0.0602, 0.0256, 0.0118, 0.0123, 0.0028, 0.0031],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,469][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.4408, 0.5064, 0.0197, 0.0242, 0.0038, 0.0013, 0.0009, 0.0006, 0.0024],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,469][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0325, 0.1366, 0.0552, 0.0681, 0.0944, 0.0821, 0.0732, 0.1364, 0.3217],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,470][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([9.9948e-01, 4.6782e-05, 3.9191e-06, 2.4267e-05, 1.2673e-05, 5.2345e-05,
        1.6023e-04, 1.1025e-04, 1.1037e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,470][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0070, 0.8445, 0.0804, 0.0352, 0.0223, 0.0044, 0.0018, 0.0010, 0.0033],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,470][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([4.8760e-01, 4.7396e-01, 1.5837e-02, 7.1129e-03, 4.0905e-03, 2.0482e-03,
        1.3181e-03, 4.0811e-04, 3.7873e-03, 3.8360e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,473][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0042, 0.8641, 0.0750, 0.0161, 0.0142, 0.0079, 0.0028, 0.0014, 0.0034,
        0.0108], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,474][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8565, 0.0402, 0.0511, 0.0114, 0.0166, 0.0028, 0.0018, 0.0012, 0.0112,
        0.0073], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,474][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7972, 0.1174, 0.0241, 0.0153, 0.0075, 0.0144, 0.0046, 0.0032, 0.0074,
        0.0088], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,474][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9964e-01, 9.6677e-05, 1.4663e-05, 1.2289e-05, 3.7042e-05, 5.6490e-05,
        6.8335e-05, 4.4924e-06, 3.7012e-06, 6.4537e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,475][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0502, 0.7011, 0.1287, 0.0620, 0.0177, 0.0112, 0.0035, 0.0018, 0.0082,
        0.0157], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,477][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9864e-01, 2.9010e-04, 8.7198e-05, 1.4769e-04, 8.2429e-05, 1.6849e-04,
        1.7994e-04, 5.4432e-05, 3.9519e-05, 3.1417e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,482][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1405, 0.5852, 0.1245, 0.0535, 0.0328, 0.0119, 0.0170, 0.0061, 0.0044,
        0.0242], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,488][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1359, 0.7570, 0.0585, 0.0275, 0.0089, 0.0021, 0.0008, 0.0010, 0.0037,
        0.0045], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,492][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0134, 0.1481, 0.0773, 0.0512, 0.1432, 0.0706, 0.0684, 0.1008, 0.2079,
        0.1191], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,496][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9882e-01, 6.9388e-05, 7.9657e-06, 5.2451e-05, 3.1590e-05, 1.1311e-04,
        4.1460e-04, 1.9477e-04, 1.3955e-04, 1.6157e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,496][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0049, 0.7647, 0.1318, 0.0304, 0.0381, 0.0060, 0.0022, 0.0010, 0.0046,
        0.0165], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,497][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([6.0929e-01, 3.5989e-01, 7.8252e-03, 5.7930e-03, 2.4823e-03, 2.6077e-03,
        1.7960e-03, 4.3460e-04, 3.1866e-03, 4.3043e-03, 2.3921e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,497][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0103, 0.8762, 0.0497, 0.0158, 0.0119, 0.0097, 0.0036, 0.0016, 0.0030,
        0.0115, 0.0068], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,497][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.0017e-01, 2.9296e-02, 3.0961e-02, 7.7160e-03, 1.0268e-02, 2.3257e-03,
        1.4641e-03, 8.5894e-04, 8.0638e-03, 5.2327e-03, 3.6434e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,498][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8853, 0.0638, 0.0131, 0.0079, 0.0041, 0.0083, 0.0032, 0.0017, 0.0031,
        0.0053, 0.0043], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,498][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9986e-01, 4.2704e-05, 6.4830e-06, 4.8437e-06, 1.5071e-05, 1.4932e-05,
        2.2510e-05, 1.0398e-06, 1.1135e-06, 2.1664e-05, 8.7329e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,498][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0861, 0.6665, 0.1075, 0.0526, 0.0231, 0.0140, 0.0043, 0.0016, 0.0102,
        0.0183, 0.0158], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,499][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9908e-01, 1.7060e-04, 5.0644e-05, 9.9290e-05, 4.5089e-05, 1.2303e-04,
        1.0228e-04, 3.0180e-05, 2.8185e-05, 1.7276e-04, 9.7609e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,499][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2206, 0.5879, 0.0695, 0.0395, 0.0241, 0.0080, 0.0133, 0.0038, 0.0021,
        0.0205, 0.0107], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,502][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1463, 0.7655, 0.0419, 0.0196, 0.0088, 0.0019, 0.0008, 0.0010, 0.0029,
        0.0045, 0.0070], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,507][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0089, 0.1678, 0.0697, 0.0564, 0.1004, 0.0602, 0.0489, 0.0921, 0.1544,
        0.0986, 0.1427], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,511][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9948e-01, 3.1138e-05, 2.6172e-06, 1.8389e-05, 1.1674e-05, 5.2818e-05,
        1.8625e-04, 9.3667e-05, 3.9193e-05, 5.3470e-05, 2.6619e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,513][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.3647e-03, 7.7461e-01, 1.1632e-01, 2.4840e-02, 3.7400e-02, 5.3857e-03,
        1.8790e-03, 6.0209e-04, 3.7821e-03, 1.4302e-02, 1.3522e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,519][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.4423, 0.4526, 0.0246, 0.0204, 0.0104, 0.0064, 0.0062, 0.0010, 0.0064,
        0.0138, 0.0099, 0.0060], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,523][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0087, 0.6910, 0.1147, 0.0352, 0.0319, 0.0166, 0.0100, 0.0029, 0.0102,
        0.0329, 0.0335, 0.0124], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,523][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.8810, 0.0310, 0.0303, 0.0086, 0.0109, 0.0032, 0.0019, 0.0012, 0.0084,
        0.0083, 0.0048, 0.0103], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,524][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.5499, 0.1837, 0.0410, 0.0447, 0.0223, 0.0367, 0.0136, 0.0124, 0.0250,
        0.0253, 0.0233, 0.0221], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,524][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([9.9788e-01, 4.4874e-04, 3.4662e-05, 1.0051e-04, 8.7502e-05, 1.5370e-04,
        3.8632e-04, 2.4833e-05, 1.2712e-05, 4.0872e-04, 1.5890e-04, 3.0695e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,525][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0505, 0.5900, 0.1207, 0.0757, 0.0293, 0.0183, 0.0081, 0.0043, 0.0112,
        0.0361, 0.0302, 0.0255], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,525][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([9.9782e-01, 2.8486e-04, 7.3036e-05, 2.1254e-04, 6.9883e-05, 2.5759e-04,
        2.7141e-04, 8.0150e-05, 7.8703e-05, 3.9124e-04, 1.6303e-04, 3.0178e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,525][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.2326, 0.4221, 0.0697, 0.0761, 0.0323, 0.0185, 0.0386, 0.0123, 0.0119,
        0.0419, 0.0321, 0.0118], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,526][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1705, 0.6425, 0.0392, 0.0573, 0.0104, 0.0063, 0.0035, 0.0036, 0.0083,
        0.0151, 0.0320, 0.0112], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,526][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1189, 0.0260, 0.0494, 0.0320, 0.0743, 0.0668, 0.0516, 0.0700, 0.1319,
        0.0793, 0.1347, 0.1651], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,527][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([9.9426e-01, 2.3219e-04, 2.4179e-05, 1.2744e-04, 1.0358e-04, 3.6878e-04,
        9.8836e-04, 6.1923e-04, 5.2794e-04, 4.3525e-04, 2.3205e-04, 2.0847e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,531][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0064, 0.6676, 0.1056, 0.0602, 0.0332, 0.0090, 0.0038, 0.0013, 0.0055,
        0.0449, 0.0467, 0.0158], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,534][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([7.7305e-01, 1.9124e-01, 6.9382e-03, 6.7985e-03, 1.4941e-03, 1.6373e-03,
        1.4706e-03, 4.4330e-04, 1.5296e-03, 5.4532e-03, 4.0128e-03, 4.9224e-03,
        1.0134e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,540][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0304, 0.7495, 0.1168, 0.0178, 0.0208, 0.0085, 0.0036, 0.0020, 0.0064,
        0.0183, 0.0114, 0.0103, 0.0042], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,544][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.8985, 0.0252, 0.0259, 0.0063, 0.0076, 0.0024, 0.0019, 0.0009, 0.0057,
        0.0058, 0.0033, 0.0106, 0.0060], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,550][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.8725, 0.0579, 0.0085, 0.0113, 0.0045, 0.0125, 0.0033, 0.0021, 0.0032,
        0.0071, 0.0069, 0.0076, 0.0025], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,551][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([9.9951e-01, 8.9942e-05, 1.2802e-05, 1.9075e-05, 1.3361e-05, 5.8465e-05,
        9.6913e-05, 4.5840e-06, 2.8201e-06, 7.7255e-05, 2.4783e-05, 5.9816e-05,
        2.7661e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,551][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.1347, 0.5787, 0.0865, 0.0731, 0.0208, 0.0159, 0.0046, 0.0026, 0.0097,
        0.0260, 0.0233, 0.0189, 0.0052], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,551][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.9917e-01, 9.0735e-05, 5.5538e-05, 6.7267e-05, 6.9390e-05, 1.0010e-04,
        6.6275e-05, 1.9223e-05, 2.6602e-05, 1.0949e-04, 5.0091e-05, 4.7157e-05,
        1.3299e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,552][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.6275, 0.2654, 0.0300, 0.0243, 0.0101, 0.0074, 0.0090, 0.0017, 0.0014,
        0.0104, 0.0054, 0.0040, 0.0035], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,552][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([6.0903e-01, 3.4210e-01, 1.2173e-02, 1.9235e-02, 4.2106e-03, 1.1804e-03,
        5.5415e-04, 3.3019e-04, 1.0422e-03, 2.5405e-03, 3.7530e-03, 2.7294e-03,
        1.1284e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,552][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1629, 0.0892, 0.0314, 0.0469, 0.0373, 0.1307, 0.0473, 0.0626, 0.0647,
        0.0762, 0.1281, 0.0696, 0.0531], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,553][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([9.9779e-01, 7.7768e-05, 8.1954e-06, 5.2295e-05, 4.4265e-05, 1.5891e-04,
        4.3098e-04, 2.5608e-04, 1.5941e-04, 1.9941e-04, 8.4816e-05, 4.8374e-04,
        2.5051e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,553][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([2.4984e-02, 7.3776e-01, 5.3754e-02, 5.4691e-02, 1.8665e-02, 1.0940e-02,
        4.0325e-03, 7.1080e-04, 3.0417e-03, 3.6180e-02, 3.6338e-02, 1.4649e-02,
        4.2527e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,554][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([1.9901e-01, 7.2302e-01, 2.9549e-02, 1.2300e-02, 7.0563e-03, 2.1696e-03,
        9.2164e-04, 3.1553e-04, 3.3656e-03, 7.0399e-03, 5.0845e-03, 5.1835e-03,
        2.6095e-03, 2.3783e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,557][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([4.2736e-03, 8.5435e-01, 6.8314e-02, 1.7602e-02, 1.4153e-02, 5.4093e-03,
        2.7970e-03, 8.1383e-04, 2.8139e-03, 1.0697e-02, 8.0172e-03, 3.4015e-03,
        1.6491e-03, 5.7062e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,563][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.8503, 0.0327, 0.0429, 0.0076, 0.0135, 0.0028, 0.0017, 0.0009, 0.0086,
        0.0077, 0.0050, 0.0128, 0.0090, 0.0046], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,567][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.3747, 0.3309, 0.0632, 0.0351, 0.0211, 0.0306, 0.0116, 0.0071, 0.0176,
        0.0212, 0.0168, 0.0267, 0.0111, 0.0324], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,571][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([9.9838e-01, 2.3401e-04, 2.5412e-05, 4.1187e-05, 7.3439e-05, 1.4136e-04,
        2.8901e-04, 1.6133e-05, 1.1137e-05, 2.1378e-04, 4.6332e-05, 2.1406e-04,
        1.4993e-04, 1.6466e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,576][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0143, 0.7489, 0.0766, 0.0523, 0.0137, 0.0083, 0.0028, 0.0010, 0.0052,
        0.0206, 0.0201, 0.0151, 0.0044, 0.0166], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,577][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([9.9558e-01, 3.1951e-04, 1.1262e-04, 2.4935e-04, 1.3963e-04, 2.8920e-04,
        2.8191e-04, 6.9143e-05, 9.8910e-05, 4.1021e-04, 1.5869e-04, 2.2562e-04,
        2.7276e-04, 1.7915e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,578][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0789, 0.6622, 0.0616, 0.0505, 0.0192, 0.0161, 0.0142, 0.0052, 0.0035,
        0.0272, 0.0163, 0.0088, 0.0096, 0.0268], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,578][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([4.0625e-02, 8.9140e-01, 2.3661e-02, 2.0739e-02, 4.0958e-03, 8.8124e-04,
        4.3200e-04, 2.8051e-04, 1.1628e-03, 3.7377e-03, 6.0835e-03, 2.7572e-03,
        1.0309e-03, 3.1162e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,578][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0075, 0.0291, 0.0223, 0.0215, 0.0425, 0.0491, 0.0395, 0.0473, 0.1471,
        0.0720, 0.1575, 0.1562, 0.1021, 0.1062], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,579][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([9.9703e-01, 1.3181e-04, 1.1873e-05, 7.2636e-05, 4.2513e-05, 1.9625e-04,
        4.8515e-04, 2.8232e-04, 2.0698e-04, 2.2707e-04, 1.1863e-04, 6.7723e-04,
        2.0389e-04, 3.1638e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,579][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([3.1835e-03, 8.4724e-01, 6.7109e-02, 2.6101e-02, 1.2397e-02, 2.0839e-03,
        7.0045e-04, 3.1774e-04, 1.4023e-03, 1.2673e-02, 1.2584e-02, 7.0815e-03,
        2.0842e-03, 5.0477e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,579][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.2956e-01, 2.4649e-01, 4.1930e-03, 3.8890e-03, 1.6685e-03, 9.8543e-04,
        8.0591e-04, 1.4597e-04, 1.2183e-03, 2.2145e-03, 1.6847e-03, 3.3365e-03,
        9.0019e-04, 1.8154e-03, 1.0877e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,580][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.4189e-02, 8.8213e-01, 2.9072e-02, 1.1560e-02, 7.9535e-03, 5.8575e-03,
        2.2022e-03, 5.9257e-04, 1.7322e-03, 7.8376e-03, 4.4121e-03, 2.9863e-03,
        1.0306e-03, 4.0167e-03, 4.4294e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,581][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.0344e-01, 2.5328e-02, 2.5186e-02, 5.2122e-03, 7.3757e-03, 1.8155e-03,
        1.0114e-03, 7.7666e-04, 5.7387e-03, 4.4573e-03, 2.6909e-03, 7.4455e-03,
        5.0510e-03, 2.9957e-03, 1.4768e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,585][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.3830e-01, 3.0585e-02, 5.2315e-03, 3.4388e-03, 1.8211e-03, 3.7356e-03,
        1.0107e-03, 6.6274e-04, 1.3213e-03, 2.5170e-03, 2.1611e-03, 2.6802e-03,
        1.2994e-03, 3.1360e-03, 2.0952e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,587][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9982e-01, 3.4191e-05, 4.6835e-06, 4.3854e-06, 1.2862e-05, 1.4297e-05,
        2.3456e-05, 1.0934e-06, 1.3810e-06, 2.0615e-05, 7.1524e-06, 1.5552e-05,
        2.5926e-05, 1.2983e-05, 4.4799e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,593][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1131, 0.6369, 0.0659, 0.0540, 0.0172, 0.0111, 0.0035, 0.0012, 0.0064,
        0.0149, 0.0147, 0.0157, 0.0045, 0.0251, 0.0159], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,596][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9932e-01, 4.9376e-05, 1.9312e-05, 3.9245e-05, 2.3735e-05, 5.5208e-05,
        4.4485e-05, 8.9367e-06, 1.4960e-05, 7.0511e-05, 3.4223e-05, 3.5741e-05,
        4.4762e-05, 1.9790e-04, 3.9796e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,602][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3895, 0.4580, 0.0364, 0.0247, 0.0167, 0.0060, 0.0089, 0.0018, 0.0013,
        0.0132, 0.0072, 0.0040, 0.0084, 0.0122, 0.0116], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,604][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.9043e-01, 5.5030e-01, 1.6808e-02, 1.5027e-02, 4.5387e-03, 1.2380e-03,
        4.6019e-04, 4.2300e-04, 1.5645e-03, 2.1263e-03, 4.6687e-03, 3.9902e-03,
        1.6547e-03, 4.8504e-03, 1.9240e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,604][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0363, 0.0939, 0.0388, 0.0357, 0.0844, 0.0382, 0.0412, 0.0598, 0.0759,
        0.0642, 0.0847, 0.1009, 0.0960, 0.0543, 0.0958], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,604][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.9927e-01, 3.4166e-05, 2.5247e-06, 1.6210e-05, 8.6259e-06, 3.7297e-05,
        1.3003e-04, 8.2310e-05, 3.6883e-05, 3.8583e-05, 2.1121e-05, 1.0923e-04,
        4.7863e-05, 1.0585e-04, 6.0031e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,605][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.8134e-02, 7.8740e-01, 7.8314e-02, 2.4162e-02, 2.5692e-02, 3.8754e-03,
        1.1144e-03, 4.5318e-04, 3.1443e-03, 1.0699e-02, 1.4067e-02, 6.6302e-03,
        4.7178e-03, 1.0027e-02, 1.1571e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,606][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:40,607][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 8668],
        [ 1782],
        [18051],
        [  787],
        [ 2699],
        [ 1587],
        [ 7832],
        [ 1764],
        [ 2660],
        [ 2946],
        [ 2699],
        [ 2046],
        [ 3259],
        [ 1548],
        [ 1006]], device='cuda:0')
[2024-07-24 10:20:40,608][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8959],
        [ 3752],
        [37860],
        [ 3690],
        [ 7596],
        [ 3354],
        [15348],
        [ 3917],
        [ 9941],
        [ 9390],
        [ 4823],
        [ 6804],
        [ 8919],
        [ 5345],
        [ 4343]], device='cuda:0')
[2024-07-24 10:20:40,611][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12780],
        [14327],
        [14397],
        [15889],
        [15451],
        [20901],
        [26615],
        [27552],
        [32442],
        [33011],
        [32351],
        [31510],
        [28766],
        [31517],
        [30109]], device='cuda:0')
[2024-07-24 10:20:40,613][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18691],
        [12860],
        [ 5225],
        [ 3993],
        [ 3807],
        [ 4633],
        [ 4631],
        [ 5514],
        [ 5467],
        [ 5672],
        [ 5273],
        [ 6057],
        [ 5739],
        [ 5513],
        [ 5331]], device='cuda:0')
[2024-07-24 10:20:40,616][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[1148],
        [1385],
        [1500],
        [1546],
        [1450],
        [1328],
        [1267],
        [1295],
        [1285],
        [1297],
        [1299],
        [1296],
        [1296],
        [1243],
        [1249]], device='cuda:0')
[2024-07-24 10:20:40,619][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[520],
        [567],
        [874],
        [906],
        [795],
        [831],
        [763],
        [733],
        [733],
        [708],
        [717],
        [795],
        [783],
        [778],
        [723]], device='cuda:0')
[2024-07-24 10:20:40,621][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31151],
        [24645],
        [29622],
        [20739],
        [27657],
        [20796],
        [15887],
        [10617],
        [11682],
        [ 6807],
        [ 6853],
        [ 7099],
        [ 9436],
        [ 6472],
        [ 5647]], device='cuda:0')
[2024-07-24 10:20:40,624][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[5085],
        [4546],
        [4332],
        [6362],
        [6098],
        [7083],
        [7107],
        [7003],
        [6576],
        [6943],
        [7043],
        [7874],
        [7321],
        [7134],
        [7005]], device='cuda:0')
[2024-07-24 10:20:40,626][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18473],
        [19856],
        [18836],
        [19456],
        [18949],
        [19349],
        [19667],
        [19321],
        [19287],
        [19674],
        [19681],
        [19183],
        [19118],
        [19444],
        [19366]], device='cuda:0')
[2024-07-24 10:20:40,629][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 5222],
        [12355],
        [11807],
        [20871],
        [16281],
        [21198],
        [20044],
        [20481],
        [20759],
        [20802],
        [21176],
        [17769],
        [19078],
        [20241],
        [20563]], device='cuda:0')
[2024-07-24 10:20:40,632][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22112],
        [23412],
        [22352],
        [23465],
        [22345],
        [22821],
        [22214],
        [21437],
        [21841],
        [22048],
        [21863],
        [18603],
        [20852],
        [22763],
        [21864]], device='cuda:0')
[2024-07-24 10:20:40,634][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[14729],
        [ 3729],
        [   80],
        [   74],
        [  173],
        [  262],
        [  228],
        [  239],
        [  246],
        [  269],
        [  309],
        [  300],
        [  373],
        [  304],
        [  324]], device='cuda:0')
[2024-07-24 10:20:40,637][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[35020],
        [33053],
        [34397],
        [34065],
        [34259],
        [33342],
        [34133],
        [33461],
        [33409],
        [33822],
        [33865],
        [34088],
        [34113],
        [34054],
        [33600]], device='cuda:0')
[2024-07-24 10:20:40,638][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13958],
        [ 8593],
        [10366],
        [15180],
        [12092],
        [17800],
        [24686],
        [23992],
        [19238],
        [29681],
        [29177],
        [25066],
        [25864],
        [23251],
        [31426]], device='cuda:0')
[2024-07-24 10:20:40,638][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10645],
        [22832],
        [28479],
        [28199],
        [37558],
        [40727],
        [41849],
        [24665],
        [23177],
        [29113],
        [44422],
        [37085],
        [37330],
        [36997],
        [39083]], device='cuda:0')
[2024-07-24 10:20:40,639][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35638],
        [36293],
        [36080],
        [42629],
        [38810],
        [49671],
        [49680],
        [49713],
        [49694],
        [49631],
        [49182],
        [49590],
        [46340],
        [49726],
        [47573]], device='cuda:0')
[2024-07-24 10:20:40,640][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14650],
        [ 5255],
        [ 6597],
        [ 7219],
        [ 6861],
        [ 6586],
        [ 5732],
        [ 6449],
        [ 6076],
        [ 6193],
        [ 5995],
        [ 6205],
        [ 6405],
        [ 6090],
        [ 5858]], device='cuda:0')
[2024-07-24 10:20:40,641][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[8801],
        [3652],
        [4046],
        [2307],
        [2185],
        [4339],
        [2923],
        [5763],
        [2564],
        [3803],
        [2665],
        [3488],
        [2849],
        [4713],
        [2785]], device='cuda:0')
[2024-07-24 10:20:40,644][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3417],
        [ 4730],
        [ 3496],
        [ 9109],
        [ 4529],
        [21323],
        [20388],
        [17683],
        [12390],
        [20049],
        [15081],
        [29434],
        [18048],
        [28897],
        [ 9924]], device='cuda:0')
[2024-07-24 10:20:40,647][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12531],
        [12534],
        [12531],
        [12535],
        [12534],
        [12564],
        [12552],
        [12541],
        [12536],
        [12543],
        [12532],
        [12623],
        [12547],
        [12584],
        [12531]], device='cuda:0')
[2024-07-24 10:20:40,649][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23653],
        [14057],
        [13942],
        [15827],
        [15641],
        [16431],
        [16451],
        [16222],
        [16061],
        [16465],
        [16505],
        [17073],
        [16543],
        [16120],
        [16097]], device='cuda:0')
[2024-07-24 10:20:40,652][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32280],
        [32174],
        [32272],
        [32229],
        [32273],
        [32171],
        [32153],
        [32228],
        [32252],
        [32101],
        [32159],
        [31997],
        [32181],
        [31683],
        [32181]], device='cuda:0')
[2024-07-24 10:20:40,654][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17374],
        [22646],
        [18419],
        [38827],
        [25288],
        [41547],
        [41746],
        [40962],
        [40996],
        [41388],
        [40613],
        [40869],
        [33021],
        [42001],
        [38755]], device='cuda:0')
[2024-07-24 10:20:40,657][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33087],
        [32008],
        [32854],
        [41766],
        [33683],
        [42883],
        [42939],
        [43167],
        [42840],
        [42790],
        [42996],
        [43687],
        [40965],
        [43197],
        [42930]], device='cuda:0')
[2024-07-24 10:20:40,660][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11114],
        [ 7745],
        [ 7094],
        [ 7421],
        [ 6234],
        [ 8514],
        [ 6863],
        [ 5412],
        [ 6312],
        [ 7374],
        [ 6599],
        [ 5118],
        [ 5026],
        [ 5100],
        [ 6030]], device='cuda:0')
[2024-07-24 10:20:40,662][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23664],
        [23712],
        [23663],
        [23703],
        [23675],
        [23695],
        [23711],
        [23673],
        [23678],
        [23692],
        [23677],
        [23714],
        [23714],
        [23753],
        [23695]], device='cuda:0')
[2024-07-24 10:20:40,665][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10080],
        [10902],
        [11260],
        [13137],
        [12105],
        [13004],
        [12132],
        [12306],
        [12252],
        [12358],
        [12249],
        [11014],
        [11057],
        [12018],
        [11611]], device='cuda:0')
[2024-07-24 10:20:40,667][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26667],
        [32523],
        [33821],
        [21845],
        [29734],
        [13398],
        [14820],
        [13594],
        [16707],
        [13928],
        [15946],
        [14554],
        [20011],
        [14391],
        [19683]], device='cuda:0')
[2024-07-24 10:20:40,670][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41307],
        [41493],
        [40905],
        [34882],
        [41805],
        [18421],
        [21218],
        [28563],
        [30925],
        [29576],
        [22110],
        [22084],
        [37096],
        [19435],
        [32104]], device='cuda:0')
[2024-07-24 10:20:40,671][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556],
        [6556]], device='cuda:0')
[2024-07-24 10:20:40,709][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:40,709][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,710][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,710][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,710][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,711][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,711][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,711][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,711][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,712][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,712][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,712][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,713][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:40,713][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0551, 0.9449], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,713][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0208, 0.9792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,714][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,714][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4570, 0.5430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,714][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9725, 0.0275], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,715][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9995e-01, 5.4365e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,718][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2993, 0.7007], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,721][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0763, 0.9237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,722][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,722][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3758, 0.6242], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,722][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6010, 0.3990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,722][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3275, 0.6725], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:40,723][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.0393, 0.4941, 0.4666], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,723][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.0162, 0.5196, 0.4642], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,723][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.0014, 0.8639, 0.1346], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,724][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.4714, 0.2978, 0.2309], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,724][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([9.9468e-01, 4.4752e-03, 8.4768e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,724][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([9.9998e-01, 1.3724e-05, 9.2720e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,724][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.1648, 0.4083, 0.4269], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,725][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.0596, 0.5448, 0.3956], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,730][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.9813, 0.0135, 0.0052], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,736][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.2743, 0.2718, 0.4539], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,740][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.1970, 0.6293, 0.1737], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,746][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.2270, 0.3554, 0.4176], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:40,748][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0202, 0.3312, 0.3506, 0.2980], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,748][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0057, 0.3491, 0.2977, 0.3474], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,749][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0010, 0.6031, 0.1896, 0.2063], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,749][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1783, 0.3334, 0.2447, 0.2437], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,749][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8883, 0.0952, 0.0053, 0.0113], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,749][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9998e-01, 1.5734e-05, 4.8739e-06, 1.3745e-06], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,750][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1186, 0.2877, 0.3010, 0.2927], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,750][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0477, 0.2884, 0.2076, 0.4563], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,750][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8219, 0.1689, 0.0027, 0.0066], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,751][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1019, 0.2200, 0.5468, 0.1313], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,751][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0326, 0.4956, 0.3783, 0.0936], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,754][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1211, 0.2782, 0.3308, 0.2699], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:40,759][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0182, 0.2474, 0.2504, 0.2559, 0.2281], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,764][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0084, 0.2613, 0.2192, 0.2626, 0.2485], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,769][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0018, 0.5970, 0.1021, 0.1992, 0.0999], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,774][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.2866, 0.2165, 0.1687, 0.1739, 0.1543], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,775][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([9.7118e-01, 2.0434e-02, 1.5894e-03, 6.3946e-03, 4.0571e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,775][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([9.9991e-01, 4.8944e-05, 1.7782e-05, 1.0916e-05, 8.8043e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,775][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0828, 0.2206, 0.2308, 0.2284, 0.2374], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,776][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0179, 0.1819, 0.1229, 0.5036, 0.1737], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,776][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.8762, 0.1021, 0.0051, 0.0141, 0.0025], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,776][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.1749, 0.1781, 0.2631, 0.1189, 0.2650], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,777][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0631, 0.4265, 0.1768, 0.2604, 0.0733], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,777][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.1094, 0.1920, 0.2257, 0.1925, 0.2804], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:40,777][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0141, 0.2022, 0.2040, 0.2048, 0.1832, 0.1917], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,777][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0031, 0.2136, 0.1723, 0.1950, 0.1918, 0.2241], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,781][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0005, 0.4341, 0.0806, 0.1919, 0.2355, 0.0574], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,785][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0987, 0.2179, 0.1854, 0.1793, 0.1831, 0.1356], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,791][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4515, 0.4682, 0.0174, 0.0562, 0.0055, 0.0011], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,793][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.9973e-01, 1.6344e-04, 5.0178e-05, 2.1533e-05, 1.5692e-05, 2.2342e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,799][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0741, 0.1821, 0.1865, 0.1823, 0.1864, 0.1887], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,801][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0309, 0.1824, 0.1371, 0.3241, 0.1477, 0.1778], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,801][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0543, 0.7716, 0.0546, 0.0756, 0.0396, 0.0044], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,802][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0736, 0.1153, 0.3181, 0.0736, 0.3148, 0.1046], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,802][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0482, 0.3522, 0.2927, 0.1338, 0.1505, 0.0226], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,802][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0636, 0.1552, 0.1911, 0.1511, 0.2329, 0.2061], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:40,803][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0092, 0.1699, 0.1704, 0.1709, 0.1529, 0.1659, 0.1607],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,803][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0021, 0.1808, 0.1517, 0.1647, 0.1578, 0.1822, 0.1607],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,803][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0005, 0.3898, 0.0828, 0.1832, 0.1493, 0.0749, 0.1195],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,804][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0779, 0.1905, 0.1647, 0.1617, 0.1651, 0.1241, 0.1159],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,804][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4479, 0.4514, 0.0147, 0.0726, 0.0088, 0.0022, 0.0024],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,805][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9941e-01, 3.6174e-04, 6.1993e-05, 4.5124e-05, 2.0988e-05, 6.5849e-05,
        3.2159e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,810][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0647, 0.1514, 0.1580, 0.1537, 0.1578, 0.1594, 0.1550],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,815][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0328, 0.1579, 0.1237, 0.2373, 0.1338, 0.1290, 0.1854],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,820][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2708, 0.5805, 0.0134, 0.0923, 0.0215, 0.0195, 0.0019],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,825][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0605, 0.1080, 0.2762, 0.0685, 0.2832, 0.1052, 0.0985],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,828][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0472, 0.4642, 0.1893, 0.1155, 0.1408, 0.0265, 0.0163],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,828][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0482, 0.1339, 0.1656, 0.1310, 0.1995, 0.1731, 0.1486],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:40,828][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0081, 0.1498, 0.1515, 0.1533, 0.1411, 0.1495, 0.1583, 0.0885],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,829][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0034, 0.1404, 0.1117, 0.1440, 0.1304, 0.1612, 0.1498, 0.1591],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,829][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0011, 0.3762, 0.0633, 0.1514, 0.1319, 0.0524, 0.1586, 0.0652],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,829][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0967, 0.1689, 0.1309, 0.1531, 0.1328, 0.1022, 0.1002, 0.1151],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,829][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1938, 0.6611, 0.0198, 0.1095, 0.0081, 0.0037, 0.0027, 0.0014],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,830][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([9.9863e-01, 5.9887e-04, 1.9853e-04, 1.2929e-04, 9.1303e-05, 2.2358e-04,
        8.8776e-05, 3.8507e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,830][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0505, 0.1296, 0.1373, 0.1339, 0.1419, 0.1439, 0.1397, 0.1231],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,830][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0123, 0.1158, 0.0787, 0.2074, 0.0851, 0.1123, 0.1537, 0.2346],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,834][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1436, 0.7171, 0.0141, 0.0784, 0.0328, 0.0087, 0.0022, 0.0031],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,838][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0533, 0.0934, 0.2290, 0.0628, 0.2619, 0.0974, 0.0932, 0.1089],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,844][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0201, 0.5092, 0.1910, 0.0709, 0.1814, 0.0126, 0.0109, 0.0039],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,848][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0457, 0.1136, 0.1270, 0.1103, 0.1618, 0.1491, 0.1257, 0.1668],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:40,854][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0059, 0.1364, 0.1414, 0.1439, 0.1320, 0.1347, 0.1482, 0.0895, 0.0680],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,854][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0033, 0.1264, 0.1076, 0.1242, 0.1208, 0.1323, 0.1236, 0.1449, 0.1168],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,855][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0016, 0.2503, 0.0557, 0.1388, 0.1391, 0.0867, 0.1760, 0.0887, 0.0631],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,855][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1078, 0.1498, 0.1221, 0.1277, 0.1157, 0.0880, 0.0826, 0.0941, 0.1122],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,855][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2603, 0.6565, 0.0103, 0.0601, 0.0045, 0.0023, 0.0015, 0.0010, 0.0035],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,856][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.9983e-01, 7.2498e-05, 2.1349e-05, 1.5638e-05, 9.0816e-06, 2.9736e-05,
        1.4391e-05, 4.6912e-06, 4.9527e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,856][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0470, 0.1141, 0.1214, 0.1189, 0.1268, 0.1272, 0.1241, 0.1093, 0.1111],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,856][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0092, 0.0994, 0.0626, 0.1749, 0.0659, 0.1007, 0.1390, 0.1758, 0.1725],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,857][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.6134, 0.3147, 0.0069, 0.0404, 0.0118, 0.0032, 0.0010, 0.0038, 0.0049],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,857][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0577, 0.0816, 0.2261, 0.0503, 0.2274, 0.0806, 0.0750, 0.0939, 0.1074],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,860][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0221, 0.2301, 0.2798, 0.1021, 0.1833, 0.0370, 0.0711, 0.0373, 0.0372],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,865][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0563, 0.0892, 0.1066, 0.0952, 0.1325, 0.1279, 0.1125, 0.1396, 0.1402],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:40,870][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0052, 0.1164, 0.1354, 0.1162, 0.1207, 0.1248, 0.1230, 0.0809, 0.0762,
        0.1011], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,875][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0015, 0.1135, 0.1007, 0.1084, 0.1035, 0.1154, 0.0972, 0.1285, 0.1006,
        0.1307], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,881][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0003, 0.1283, 0.0633, 0.0993, 0.1242, 0.0611, 0.1598, 0.0896, 0.1095,
        0.1646], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,881][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0584, 0.1322, 0.1155, 0.1150, 0.1143, 0.0898, 0.0823, 0.0909, 0.1136,
        0.0880], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,881][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([1.2613e-01, 7.2627e-01, 2.5727e-02, 7.9087e-02, 7.1217e-03, 2.1021e-03,
        1.6998e-03, 7.1591e-04, 3.2567e-03, 2.7884e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,882][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9954e-01, 2.7956e-04, 6.1981e-05, 2.3513e-05, 1.4901e-05, 3.2835e-05,
        1.3697e-05, 8.8099e-06, 9.8369e-06, 1.2858e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,882][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0424, 0.1047, 0.1101, 0.1070, 0.1115, 0.1117, 0.1094, 0.0994, 0.1028,
        0.1011], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,882][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0144, 0.0891, 0.0711, 0.1326, 0.0680, 0.0756, 0.1033, 0.1391, 0.1435,
        0.1632], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,883][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4689, 0.4363, 0.0150, 0.0325, 0.0108, 0.0083, 0.0016, 0.0109, 0.0120,
        0.0037], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,883][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0431, 0.0771, 0.2285, 0.0420, 0.2073, 0.0760, 0.0696, 0.0868, 0.1056,
        0.0640], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,883][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0604, 0.2564, 0.2296, 0.0628, 0.1360, 0.0384, 0.0656, 0.0488, 0.0685,
        0.0335], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,884][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0338, 0.0928, 0.1112, 0.0890, 0.1259, 0.1124, 0.0920, 0.1173, 0.1301,
        0.0955], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:40,887][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0052, 0.1090, 0.1185, 0.0992, 0.1088, 0.1136, 0.1133, 0.0760, 0.0712,
        0.0975, 0.0876], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,892][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0015, 0.0995, 0.0910, 0.1025, 0.0938, 0.0981, 0.0817, 0.1143, 0.0902,
        0.1109, 0.1164], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,897][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0006, 0.1437, 0.0501, 0.0610, 0.1159, 0.0432, 0.1157, 0.0551, 0.0936,
        0.1829, 0.1384], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,902][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0569, 0.1230, 0.1046, 0.1103, 0.1026, 0.0787, 0.0730, 0.0806, 0.1051,
        0.0838, 0.0814], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,908][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1988, 0.6349, 0.0321, 0.0739, 0.0078, 0.0022, 0.0020, 0.0007, 0.0042,
        0.0207, 0.0227], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,908][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9982e-01, 1.1066e-04, 2.2090e-05, 8.4415e-06, 6.8220e-06, 8.6943e-06,
        4.3018e-06, 3.3602e-06, 3.9844e-06, 4.0187e-06, 4.4136e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,908][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0424, 0.0954, 0.0981, 0.0958, 0.1003, 0.1001, 0.0989, 0.0905, 0.0925,
        0.0921, 0.0937], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,909][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0144, 0.0771, 0.0622, 0.1025, 0.0638, 0.0552, 0.0767, 0.1248, 0.1230,
        0.1289, 0.1713], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,909][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7070, 0.2202, 0.0044, 0.0196, 0.0076, 0.0094, 0.0028, 0.0099, 0.0085,
        0.0070, 0.0035], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,909][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0455, 0.0757, 0.2023, 0.0419, 0.1836, 0.0719, 0.0665, 0.0801, 0.0952,
        0.0644, 0.0728], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,910][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0295, 0.2900, 0.2133, 0.0517, 0.1337, 0.0415, 0.0515, 0.0578, 0.0704,
        0.0385, 0.0220], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,910][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0323, 0.0797, 0.0989, 0.0788, 0.1160, 0.1034, 0.0877, 0.1078, 0.1222,
        0.0873, 0.0859], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:40,911][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0049, 0.0933, 0.1023, 0.0996, 0.0998, 0.1056, 0.1148, 0.0706, 0.0586,
        0.0900, 0.0864, 0.0741], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,912][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0023, 0.0853, 0.0682, 0.0924, 0.0804, 0.0939, 0.0877, 0.1019, 0.0747,
        0.0975, 0.1010, 0.1146], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,916][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0004, 0.1618, 0.0353, 0.0679, 0.0536, 0.0451, 0.0878, 0.0356, 0.0493,
        0.2334, 0.1526, 0.0773], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,922][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0868, 0.1074, 0.0917, 0.0972, 0.0906, 0.0742, 0.0692, 0.0738, 0.0888,
        0.0745, 0.0735, 0.0723], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,927][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1534, 0.5479, 0.0356, 0.1133, 0.0126, 0.0057, 0.0055, 0.0013, 0.0063,
        0.0468, 0.0515, 0.0200], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,931][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.9873e-01, 5.8488e-04, 1.0151e-04, 8.6749e-05, 4.8620e-05, 1.2486e-04,
        5.8357e-05, 2.5100e-05, 3.4841e-05, 6.0166e-05, 8.1471e-05, 6.3821e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,935][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0348, 0.0864, 0.0907, 0.0893, 0.0926, 0.0928, 0.0908, 0.0812, 0.0842,
        0.0832, 0.0864, 0.0874], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,935][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0078, 0.0583, 0.0417, 0.1147, 0.0517, 0.0684, 0.0986, 0.1158, 0.1016,
        0.1313, 0.1541, 0.0560], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,935][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.2998, 0.3389, 0.0126, 0.0868, 0.0209, 0.0387, 0.0124, 0.0450, 0.0460,
        0.0324, 0.0166, 0.0499], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,936][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0594, 0.0691, 0.1529, 0.0439, 0.1494, 0.0713, 0.0628, 0.0750, 0.0789,
        0.0588, 0.0659, 0.1125], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,936][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1000, 0.2040, 0.1319, 0.0868, 0.1357, 0.0477, 0.0402, 0.0197, 0.0531,
        0.0392, 0.0439, 0.0977], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,937][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0320, 0.0672, 0.0804, 0.0699, 0.1043, 0.0939, 0.0810, 0.1051, 0.1125,
        0.0795, 0.0784, 0.0958], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:40,937][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0064, 0.0871, 0.0878, 0.0946, 0.0810, 0.0943, 0.1031, 0.0678, 0.0541,
        0.0849, 0.0865, 0.0749, 0.0776], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,937][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.0024, 0.0789, 0.0618, 0.0826, 0.0707, 0.0883, 0.0771, 0.0964, 0.0715,
        0.0928, 0.0936, 0.1088, 0.0753], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,938][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.0005, 0.1586, 0.0325, 0.0562, 0.0291, 0.0602, 0.0791, 0.0481, 0.0583,
        0.1895, 0.1253, 0.1372, 0.0252], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,939][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.0758, 0.1017, 0.0826, 0.0939, 0.0790, 0.0721, 0.0645, 0.0638, 0.0798,
        0.0758, 0.0742, 0.0664, 0.0705], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,945][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.7702, 0.1110, 0.0062, 0.0343, 0.0024, 0.0015, 0.0026, 0.0009, 0.0027,
        0.0258, 0.0308, 0.0100, 0.0016], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,948][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([9.9973e-01, 9.6746e-05, 2.0338e-05, 1.5559e-05, 9.8159e-06, 4.9387e-05,
        1.3997e-05, 5.9054e-06, 7.9382e-06, 1.3572e-05, 1.5846e-05, 1.8537e-05,
        4.6808e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,953][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0331, 0.0785, 0.0826, 0.0813, 0.0848, 0.0849, 0.0835, 0.0744, 0.0754,
        0.0772, 0.0790, 0.0811, 0.0843], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,958][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0059, 0.0479, 0.0332, 0.1046, 0.0433, 0.0672, 0.0932, 0.0978, 0.0944,
        0.1240, 0.1613, 0.0518, 0.0754], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,962][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([7.2233e-01, 1.2799e-01, 3.7450e-03, 4.9685e-02, 6.7932e-03, 9.4253e-03,
        3.2820e-03, 1.0071e-02, 1.6186e-02, 1.4565e-02, 6.0692e-03, 2.9288e-02,
        5.6893e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,962][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0575, 0.0673, 0.1204, 0.0449, 0.1222, 0.0646, 0.0573, 0.0639, 0.0732,
        0.0577, 0.0621, 0.0982, 0.1108], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,963][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0168, 0.2436, 0.1260, 0.1107, 0.0521, 0.0453, 0.0529, 0.0211, 0.1025,
        0.0429, 0.0544, 0.0976, 0.0342], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,963][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0345, 0.0698, 0.0776, 0.0669, 0.0947, 0.0851, 0.0754, 0.0907, 0.0952,
        0.0754, 0.0740, 0.0761, 0.0845], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:40,963][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0033, 0.0839, 0.0934, 0.0863, 0.0853, 0.0892, 0.0904, 0.0578, 0.0486,
        0.0799, 0.0763, 0.0661, 0.0849, 0.0547], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,964][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0013, 0.0672, 0.0580, 0.0700, 0.0657, 0.0799, 0.0709, 0.0868, 0.0686,
        0.0850, 0.0812, 0.1019, 0.0702, 0.0934], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,964][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0003, 0.1259, 0.0247, 0.0592, 0.0705, 0.0270, 0.0628, 0.0455, 0.0329,
        0.1887, 0.1351, 0.1286, 0.0661, 0.0326], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,964][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0493, 0.1007, 0.0883, 0.0885, 0.0846, 0.0622, 0.0593, 0.0581, 0.0809,
        0.0655, 0.0647, 0.0655, 0.0694, 0.0629], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,965][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([9.1725e-02, 7.7644e-01, 1.4124e-02, 5.1021e-02, 5.4257e-03, 1.7461e-03,
        1.2830e-03, 4.5577e-04, 2.4903e-03, 1.9186e-02, 2.0846e-02, 8.3492e-03,
        1.7496e-03, 5.1623e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,965][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([9.9972e-01, 1.4762e-04, 2.8567e-05, 1.4492e-05, 8.0691e-06, 2.1623e-05,
        1.0334e-05, 4.4600e-06, 3.5977e-06, 9.1839e-06, 1.0626e-05, 1.2937e-05,
        2.6740e-06, 4.4830e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,965][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0293, 0.0741, 0.0781, 0.0755, 0.0782, 0.0787, 0.0771, 0.0689, 0.0710,
        0.0709, 0.0734, 0.0740, 0.0777, 0.0729], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,969][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0077, 0.0468, 0.0359, 0.0954, 0.0409, 0.0530, 0.0831, 0.1012, 0.1005,
        0.1176, 0.1484, 0.0490, 0.0677, 0.0525], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,971][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([1.3819e-01, 7.7643e-01, 3.4497e-03, 2.7047e-02, 7.7011e-03, 4.0694e-03,
        7.2192e-04, 1.8141e-03, 2.7052e-03, 3.3158e-03, 1.1845e-03, 1.5203e-02,
        2.5247e-04, 1.7917e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,977][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0298, 0.0598, 0.1402, 0.0350, 0.1335, 0.0519, 0.0460, 0.0517, 0.0640,
        0.0454, 0.0508, 0.0952, 0.1142, 0.0824], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,982][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0358, 0.1782, 0.1227, 0.0704, 0.1090, 0.0193, 0.0370, 0.0215, 0.0347,
        0.0437, 0.0417, 0.1633, 0.0746, 0.0481], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,988][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0274, 0.0576, 0.0664, 0.0592, 0.0851, 0.0761, 0.0679, 0.0859, 0.0899,
        0.0683, 0.0677, 0.0808, 0.0814, 0.0861], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:40,990][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0026, 0.0762, 0.0904, 0.0745, 0.0808, 0.0839, 0.0835, 0.0561, 0.0495,
        0.0725, 0.0665, 0.0680, 0.0795, 0.0566, 0.0593], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,990][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0013, 0.0659, 0.0561, 0.0691, 0.0608, 0.0695, 0.0581, 0.0760, 0.0610,
        0.0783, 0.0802, 0.0891, 0.0634, 0.0830, 0.0882], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,990][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0003, 0.1215, 0.0346, 0.0498, 0.0618, 0.0278, 0.0756, 0.0371, 0.0498,
        0.1493, 0.1129, 0.0991, 0.0509, 0.0498, 0.0798], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,991][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0572, 0.0841, 0.0755, 0.0753, 0.0747, 0.0578, 0.0556, 0.0588, 0.0801,
        0.0631, 0.0642, 0.0615, 0.0644, 0.0602, 0.0675], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,991][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([6.6141e-01, 2.4339e-01, 8.5297e-03, 2.7903e-02, 3.5725e-03, 1.1874e-03,
        1.4507e-03, 4.9358e-04, 2.1058e-03, 1.5947e-02, 1.6499e-02, 7.1971e-03,
        1.2821e-03, 3.2564e-03, 5.7690e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,992][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9980e-01, 9.7943e-05, 1.8439e-05, 1.0024e-05, 7.7123e-06, 1.4320e-05,
        7.6583e-06, 4.1778e-06, 5.5727e-06, 6.4282e-06, 7.4709e-06, 1.1790e-05,
        2.8218e-06, 4.6696e-06, 4.2378e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,992][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0275, 0.0683, 0.0710, 0.0698, 0.0733, 0.0733, 0.0719, 0.0653, 0.0662,
        0.0656, 0.0678, 0.0699, 0.0733, 0.0687, 0.0682], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,992][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0099, 0.0524, 0.0396, 0.0863, 0.0465, 0.0475, 0.0727, 0.0893, 0.0867,
        0.0999, 0.1251, 0.0528, 0.0726, 0.0484, 0.0702], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,993][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.7935e-01, 1.2013e-01, 1.0063e-03, 7.9572e-03, 3.4967e-03, 4.2689e-03,
        1.2567e-03, 3.0329e-03, 2.7301e-03, 4.0394e-03, 2.0740e-03, 2.1310e-02,
        5.4560e-04, 4.6196e-02, 2.6147e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:40,996][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0364, 0.0514, 0.1176, 0.0306, 0.1096, 0.0511, 0.0448, 0.0559, 0.0630,
        0.0446, 0.0508, 0.0899, 0.0993, 0.0825, 0.0724], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,000][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0514, 0.2099, 0.1480, 0.0703, 0.0718, 0.0357, 0.0412, 0.0215, 0.0404,
        0.0351, 0.0404, 0.0794, 0.0495, 0.0564, 0.0489], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,006][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0251, 0.0531, 0.0658, 0.0547, 0.0814, 0.0738, 0.0643, 0.0784, 0.0866,
        0.0615, 0.0606, 0.0739, 0.0763, 0.0833, 0.0611], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,054][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:41,057][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,061][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,066][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,070][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,073][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,074][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,074][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,074][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,074][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,075][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,075][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,075][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,076][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7042, 0.2958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,076][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9952e-01, 4.7538e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,076][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([8.9473e-05, 9.9991e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,076][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8294, 0.1706], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,077][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6422, 0.3578], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,078][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9998e-01, 1.5306e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,080][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9970e-01, 2.9854e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,086][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9029, 0.0971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,091][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9361, 0.0639], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,096][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7286, 0.2714], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,101][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0049, 0.9951], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,101][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9939e-01, 6.1029e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,101][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.3966, 0.5517, 0.0517], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,101][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([9.9983e-01, 1.0332e-04, 7.1203e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,102][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.0233, 0.6367, 0.3400], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,102][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.9493, 0.0418, 0.0089], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,102][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.8211, 0.1601, 0.0188], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,102][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([9.9999e-01, 3.7568e-06, 1.6753e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,103][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([9.9988e-01, 7.3953e-05, 4.5082e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,103][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.9956, 0.0026, 0.0018], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,106][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.9473, 0.0401, 0.0126], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,112][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.8165, 0.1441, 0.0394], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,117][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.3852, 0.1446, 0.4703], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,121][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([9.9997e-01, 1.5128e-05, 1.5232e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,125][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0102, 0.9438, 0.0406, 0.0055], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,127][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9538e-01, 2.5757e-03, 9.8301e-04, 1.0618e-03], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,127][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.0064e-04, 4.9784e-01, 2.0119e-01, 3.0087e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,128][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2693, 0.6501, 0.0647, 0.0159], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,128][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0630, 0.8659, 0.0402, 0.0309], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,128][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9997e-01, 2.5011e-05, 3.4765e-06, 2.0467e-06], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,128][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9936e-01, 3.3218e-04, 1.7763e-04, 1.3176e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,129][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.9041, 0.0531, 0.0240, 0.0188], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,129][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2917, 0.6642, 0.0209, 0.0232], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,129][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0568, 0.7654, 0.1573, 0.0205], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,130][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.6312e-04, 1.8494e-01, 5.7687e-01, 2.3803e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,130][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.9915e-01, 4.2329e-04, 2.2152e-04, 2.0557e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,131][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0249, 0.9270, 0.0198, 0.0232, 0.0051], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,135][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9970e-01, 8.0711e-05, 4.5458e-05, 4.7461e-05, 1.2680e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,140][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0046, 0.2506, 0.1280, 0.3255, 0.2914], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,146][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.6658, 0.2927, 0.0226, 0.0141, 0.0047], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,150][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.1907, 0.6843, 0.0526, 0.0646, 0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,154][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.9995e-01, 3.4801e-05, 7.2681e-06, 5.5087e-06, 2.4028e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,154][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.9963e-01, 1.1842e-04, 6.3913e-05, 8.9226e-05, 9.9039e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,154][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([9.9393e-01, 2.8712e-03, 9.9263e-04, 1.6562e-03, 5.5428e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,155][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.6216, 0.3168, 0.0227, 0.0341, 0.0048], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,155][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.1004, 0.7871, 0.0757, 0.0280, 0.0087], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,155][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0226, 0.1231, 0.3490, 0.1698, 0.3355], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,156][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([9.9987e-01, 2.8074e-05, 1.5324e-05, 2.0445e-05, 6.9937e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,156][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([1.0481e-03, 8.7304e-01, 8.7993e-02, 1.6487e-02, 2.0948e-02, 4.8221e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,156][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.9878, 0.0043, 0.0012, 0.0018, 0.0031, 0.0019], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,157][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([1.9922e-04, 3.6818e-01, 1.0249e-01, 2.2648e-01, 1.8141e-01, 1.2124e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,160][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0312, 0.7677, 0.1294, 0.0402, 0.0279, 0.0036], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,166][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0052, 0.8904, 0.0494, 0.0429, 0.0108, 0.0012], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,168][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([9.9920e-01, 4.8666e-04, 1.2371e-04, 6.6175e-05, 7.1255e-05, 5.6242e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,172][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([9.9357e-01, 2.1095e-03, 7.9266e-04, 8.8309e-04, 9.3816e-04, 1.7099e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,177][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.8848, 0.0494, 0.0301, 0.0199, 0.0102, 0.0056], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,180][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0066, 0.8660, 0.0575, 0.0549, 0.0135, 0.0015], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,181][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0030, 0.7090, 0.2262, 0.0367, 0.0244, 0.0007], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,181][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([4.0515e-04, 5.7191e-02, 1.7720e-01, 1.3052e-01, 5.4996e-01, 8.4724e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,181][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.9843, 0.0029, 0.0014, 0.0016, 0.0056, 0.0043], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,182][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([3.2608e-04, 8.9923e-01, 5.4125e-02, 2.4163e-02, 2.0749e-02, 1.2975e-03,
        1.1328e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,182][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9159e-01, 2.6980e-03, 5.4258e-04, 1.0931e-03, 1.1557e-03, 1.2675e-03,
        1.6501e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,182][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0017, 0.2035, 0.0739, 0.2336, 0.1836, 0.1218, 0.1818],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,183][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0430, 0.8061, 0.0700, 0.0511, 0.0230, 0.0056, 0.0012],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,183][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0129, 0.8891, 0.0356, 0.0464, 0.0123, 0.0025, 0.0011],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,183][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.9923e-01, 4.6945e-04, 5.7414e-05, 5.3263e-05, 4.2959e-05, 8.4612e-05,
        6.4287e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,184][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9496e-01, 1.2505e-03, 4.6035e-04, 6.9842e-04, 5.9855e-04, 1.2621e-03,
        7.7169e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,187][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.9756, 0.0093, 0.0060, 0.0042, 0.0021, 0.0014, 0.0012],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,189][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.8205e-02, 8.6505e-01, 2.9927e-02, 7.1039e-02, 1.0681e-02, 4.4287e-03,
        6.6536e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,193][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.6261e-03, 8.4497e-01, 9.2137e-02, 4.1186e-02, 1.6827e-02, 1.7580e-03,
        4.9601e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,198][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0012, 0.0887, 0.2130, 0.1497, 0.3061, 0.1101, 0.1312],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,201][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.9585e-01, 6.1820e-04, 3.2887e-04, 4.0302e-04, 9.7766e-04, 8.8363e-04,
        9.3386e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,204][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([1.9122e-04, 9.3960e-01, 1.9865e-02, 2.7685e-02, 1.1812e-02, 6.2878e-04,
        1.0430e-04, 1.1768e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,208][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([9.9954e-01, 1.3340e-04, 4.5470e-05, 5.5676e-05, 7.7111e-05, 4.4560e-05,
        7.6968e-05, 2.2539e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,208][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0077, 0.1737, 0.0284, 0.0806, 0.0521, 0.0418, 0.1008, 0.5149],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,208][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([5.8237e-02, 8.5015e-01, 3.7174e-02, 3.6817e-02, 1.4302e-02, 2.2585e-03,
        4.5029e-04, 6.1072e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,208][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([3.3198e-03, 9.3566e-01, 1.7174e-02, 3.7799e-02, 4.2988e-03, 9.3539e-04,
        5.2492e-04, 2.8374e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,209][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([9.9943e-01, 3.3035e-04, 6.1471e-05, 3.8134e-05, 4.1967e-05, 5.6742e-05,
        3.8307e-05, 4.1347e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,209][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([9.9816e-01, 4.1491e-04, 2.7012e-04, 1.6004e-04, 3.1035e-04, 3.2912e-04,
        2.6427e-04, 8.6935e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,209][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([9.9061e-01, 3.5367e-03, 2.2791e-03, 1.4027e-03, 8.5087e-04, 3.0029e-04,
        4.2245e-04, 5.9467e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,210][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([7.7947e-03, 8.9090e-01, 2.8726e-02, 5.6410e-02, 1.2972e-02, 2.2836e-03,
        6.1343e-04, 3.0441e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,210][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([6.7009e-04, 9.1678e-01, 3.6877e-02, 3.3709e-02, 1.0501e-02, 9.4695e-04,
        2.4560e-04, 2.6795e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,213][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0056, 0.1654, 0.0973, 0.1783, 0.1107, 0.0878, 0.2712, 0.0836],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,217][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([9.9762e-01, 2.5082e-04, 1.7985e-04, 1.9276e-04, 3.5857e-04, 4.1624e-04,
        4.9310e-04, 4.8555e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,220][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([5.9038e-04, 9.2312e-01, 3.6738e-02, 2.1457e-02, 1.6345e-02, 5.4567e-04,
        8.6986e-05, 1.1762e-04, 9.9513e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,223][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([9.9963e-01, 9.1394e-05, 3.0219e-05, 4.7477e-05, 8.6180e-05, 2.5856e-05,
        6.3426e-05, 2.0212e-05, 8.5734e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,228][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0008, 0.1394, 0.0225, 0.0903, 0.0654, 0.0299, 0.0523, 0.1367, 0.4625],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,232][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([9.3347e-02, 8.2651e-01, 3.8807e-02, 2.6763e-02, 1.0908e-02, 1.5455e-03,
        3.4273e-04, 4.1626e-04, 1.3589e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,234][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([6.9036e-03, 9.2650e-01, 2.2314e-02, 3.5716e-02, 5.5006e-03, 9.3456e-04,
        4.6624e-04, 2.2145e-04, 1.4460e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,234][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([9.9968e-01, 2.0488e-04, 2.4721e-05, 2.2102e-05, 1.3738e-05, 2.2274e-05,
        1.7763e-05, 2.2084e-06, 7.3976e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,235][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([9.9887e-01, 1.8942e-04, 1.0036e-04, 1.0592e-04, 1.6178e-04, 2.0927e-04,
        1.6963e-04, 6.9708e-05, 1.2876e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,235][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([9.8484e-01, 5.9250e-03, 2.1653e-03, 1.7502e-03, 6.1418e-04, 5.4470e-04,
        5.2800e-04, 1.0118e-03, 2.6175e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,235][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([4.3271e-02, 8.3147e-01, 3.0461e-02, 7.5117e-02, 1.3755e-02, 2.1350e-03,
        5.7803e-04, 5.1570e-04, 2.6945e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,236][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([2.7078e-03, 8.8577e-01, 6.8856e-02, 2.7071e-02, 1.1959e-02, 9.2025e-04,
        3.1044e-04, 4.6718e-04, 1.9353e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,236][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0031, 0.0892, 0.1295, 0.1050, 0.3450, 0.0543, 0.1316, 0.0365, 0.1059],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,236][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([9.9857e-01, 1.4549e-04, 6.8366e-05, 8.4944e-05, 2.2551e-04, 2.8682e-04,
        2.1881e-04, 2.4237e-04, 1.5651e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,237][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([3.5574e-04, 9.3291e-01, 4.9848e-02, 7.9432e-03, 6.3007e-03, 3.9581e-04,
        5.0978e-05, 8.8867e-05, 1.2827e-03, 8.2067e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,237][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9061e-01, 1.7991e-03, 8.4658e-04, 7.4928e-04, 1.7356e-03, 8.3117e-04,
        1.0519e-03, 2.3887e-04, 1.5247e-04, 1.9837e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,240][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0007, 0.1354, 0.0400, 0.0979, 0.1030, 0.0396, 0.0530, 0.0913, 0.2726,
        0.1665], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,243][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.0028e-01, 7.9037e-01, 5.4313e-02, 3.0675e-02, 1.4438e-02, 2.9598e-03,
        5.8793e-04, 4.1572e-04, 1.3850e-03, 4.5779e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,246][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([4.5213e-03, 9.2497e-01, 2.8419e-02, 2.8125e-02, 5.9374e-03, 1.4451e-03,
        5.9010e-04, 2.6171e-04, 1.9219e-03, 3.8057e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,249][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9929e-01, 4.6503e-04, 6.9185e-05, 3.1296e-05, 3.2284e-05, 4.2490e-05,
        2.7060e-05, 6.5297e-06, 1.7929e-05, 1.7399e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,253][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9237e-01, 1.5944e-03, 8.1560e-04, 6.2834e-04, 7.5479e-04, 1.0769e-03,
        8.3966e-04, 2.8852e-04, 6.8012e-04, 9.4868e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,257][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9530, 0.0141, 0.0098, 0.0042, 0.0031, 0.0013, 0.0014, 0.0021, 0.0045,
        0.0064], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,261][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([3.4080e-02, 8.5682e-01, 4.2597e-02, 5.0020e-02, 6.5907e-03, 2.7111e-03,
        7.9340e-04, 8.1378e-04, 3.3495e-03, 2.2223e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,261][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.2052e-03, 8.7384e-01, 8.3304e-02, 2.2231e-02, 9.2185e-03, 1.2256e-03,
        4.0477e-04, 4.9426e-04, 1.5086e-03, 3.5699e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,262][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.1343e-04, 6.5124e-02, 2.8964e-01, 5.3019e-02, 3.8386e-01, 3.2035e-02,
        4.1022e-02, 2.2686e-02, 6.7433e-02, 4.4976e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,262][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9493e-01, 4.8182e-04, 3.8793e-04, 2.4485e-04, 9.1797e-04, 6.8494e-04,
        5.1738e-04, 5.0514e-04, 2.7064e-04, 1.0589e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,262][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([5.7408e-04, 9.5249e-01, 3.0819e-02, 5.8438e-03, 6.0693e-03, 3.7466e-04,
        6.9473e-05, 8.5828e-05, 1.2737e-03, 1.1061e-03, 1.2968e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,263][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9329e-01, 9.7909e-04, 6.6159e-04, 6.7467e-04, 1.2911e-03, 4.1018e-04,
        6.5354e-04, 1.9767e-04, 1.1659e-04, 1.1280e-03, 5.9729e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,263][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0012, 0.0832, 0.0170, 0.0853, 0.0746, 0.0320, 0.0400, 0.0734, 0.2355,
        0.1165, 0.2412], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,263][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.4801e-01, 7.5604e-01, 4.2078e-02, 3.0899e-02, 1.1167e-02, 2.2058e-03,
        4.9103e-04, 3.2694e-04, 1.0858e-03, 4.2034e-03, 3.4914e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,264][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.0643e-03, 9.1243e-01, 3.3367e-02, 3.0500e-02, 6.7379e-03, 1.5574e-03,
        6.7522e-04, 2.2253e-04, 2.0259e-03, 3.2063e-03, 3.2181e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,267][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9979e-01, 1.3901e-04, 1.5682e-05, 1.1103e-05, 1.0207e-05, 1.0200e-05,
        7.6624e-06, 1.3974e-06, 4.8749e-06, 4.8408e-06, 2.1876e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,271][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9716e-01, 5.3862e-04, 2.7709e-04, 1.8426e-04, 3.2646e-04, 3.6934e-04,
        3.3077e-04, 1.0427e-04, 2.2332e-04, 3.1975e-04, 1.6354e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,273][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.7922e-01, 6.1940e-03, 2.2489e-03, 1.6659e-03, 9.3851e-04, 5.3231e-04,
        5.3976e-04, 7.4855e-04, 1.6236e-03, 2.3886e-03, 3.9045e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,277][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.3647e-02, 8.2124e-01, 2.2940e-02, 4.0105e-02, 6.0707e-03, 3.3327e-03,
        9.8552e-04, 6.1068e-04, 2.3166e-03, 2.5688e-03, 6.1853e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,279][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([8.0006e-03, 8.6825e-01, 7.5082e-02, 2.7678e-02, 9.5293e-03, 1.3937e-03,
        4.6266e-04, 5.2522e-04, 1.5656e-03, 5.1542e-03, 2.3538e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,285][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0005, 0.0734, 0.2638, 0.0831, 0.3419, 0.0284, 0.0370, 0.0202, 0.0456,
        0.0490, 0.0571], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,287][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.9867e-01, 1.0201e-04, 8.3577e-05, 6.2305e-05, 2.3811e-04, 1.7511e-04,
        1.4288e-04, 1.0640e-04, 8.1839e-05, 2.1841e-04, 1.1934e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,287][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([9.0444e-04, 8.4694e-01, 5.9287e-02, 4.5237e-02, 2.8825e-02, 1.6126e-03,
        3.0466e-04, 4.0236e-04, 3.6596e-03, 4.5938e-03, 7.4524e-03, 7.8725e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,288][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([9.9535e-01, 6.8566e-04, 1.2218e-04, 3.0677e-04, 5.5950e-04, 2.9639e-04,
        8.9303e-04, 3.4650e-04, 8.4221e-05, 7.2939e-04, 2.6771e-04, 3.5651e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,288][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0044, 0.0535, 0.0248, 0.0693, 0.0637, 0.0526, 0.0446, 0.1239, 0.1813,
        0.1417, 0.1816, 0.0586], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,288][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.1331, 0.6533, 0.0725, 0.0532, 0.0322, 0.0088, 0.0019, 0.0015, 0.0047,
        0.0139, 0.0111, 0.0138], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,289][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0038, 0.8122, 0.0453, 0.0792, 0.0195, 0.0041, 0.0026, 0.0009, 0.0052,
        0.0105, 0.0115, 0.0052], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,289][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.9860e-01, 7.0842e-04, 5.2608e-05, 8.0977e-05, 5.1458e-05, 8.0805e-05,
        7.8259e-05, 1.2990e-05, 4.2051e-05, 5.3862e-05, 2.6022e-05, 2.0907e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,289][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([9.9429e-01, 6.1593e-04, 3.0242e-04, 3.6767e-04, 4.5725e-04, 6.7119e-04,
        4.7969e-04, 1.9307e-04, 3.8496e-04, 4.5311e-04, 2.6213e-04, 1.5205e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,290][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([9.7666e-01, 5.3165e-03, 2.0049e-03, 2.2404e-03, 1.5802e-03, 7.3050e-04,
        1.1290e-03, 1.6814e-03, 2.0077e-03, 2.9468e-03, 2.8711e-03, 8.3057e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,293][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0097, 0.7591, 0.0509, 0.0861, 0.0179, 0.0102, 0.0028, 0.0028, 0.0149,
        0.0085, 0.0187, 0.0184], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,297][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0025, 0.7706, 0.1008, 0.0723, 0.0188, 0.0043, 0.0011, 0.0020, 0.0046,
        0.0134, 0.0067, 0.0029], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,302][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0245, 0.0484, 0.1756, 0.0725, 0.2064, 0.0644, 0.0926, 0.0472, 0.0900,
        0.0771, 0.0599, 0.0413], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,305][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([9.9364e-01, 3.4612e-04, 3.1978e-04, 3.1460e-04, 9.7260e-04, 7.6828e-04,
        7.3412e-04, 3.5246e-04, 2.6318e-04, 1.0631e-03, 4.6231e-04, 7.6814e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,308][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([3.0757e-03, 9.0223e-01, 2.8691e-02, 3.2601e-02, 1.3911e-02, 1.5462e-03,
        2.9510e-04, 5.8769e-04, 2.5292e-03, 5.3191e-03, 6.8819e-03, 1.2688e-03,
        1.0656e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,311][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([9.9700e-01, 3.1178e-04, 1.1707e-04, 2.0555e-04, 3.5631e-04, 3.6372e-04,
        3.6694e-04, 8.0427e-05, 3.7954e-05, 4.1854e-04, 1.4588e-04, 2.2242e-04,
        3.6873e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,314][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0013, 0.0458, 0.0138, 0.0695, 0.0662, 0.0605, 0.0460, 0.0965, 0.1071,
        0.1115, 0.2169, 0.0455, 0.1196], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,314][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.3075, 0.5614, 0.0334, 0.0465, 0.0117, 0.0054, 0.0009, 0.0007, 0.0022,
        0.0099, 0.0105, 0.0084, 0.0015], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,314][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0655, 0.7204, 0.0519, 0.0928, 0.0148, 0.0036, 0.0030, 0.0013, 0.0077,
        0.0139, 0.0172, 0.0051, 0.0027], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,315][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.9907e-01, 3.9149e-04, 4.5579e-05, 4.7443e-05, 2.0256e-05, 1.1983e-04,
        4.9809e-05, 9.8411e-06, 3.0325e-05, 4.4677e-05, 1.5791e-05, 1.5013e-04,
        8.0474e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,315][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.9410e-01, 3.5519e-04, 1.6029e-04, 2.4885e-04, 2.6393e-04, 6.9409e-04,
        5.6484e-04, 1.3956e-04, 2.6490e-04, 4.7405e-04, 2.4546e-04, 2.2650e-03,
        2.2453e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,315][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([9.6106e-01, 7.6162e-03, 1.9128e-03, 3.1745e-03, 1.2539e-03, 1.6363e-03,
        1.3316e-03, 1.6112e-03, 3.9706e-03, 4.8941e-03, 7.0684e-03, 7.2425e-04,
        3.7452e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,316][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.2568, 0.5211, 0.0271, 0.1131, 0.0129, 0.0067, 0.0021, 0.0013, 0.0084,
        0.0071, 0.0160, 0.0262, 0.0012], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,317][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0156, 0.8412, 0.0541, 0.0488, 0.0106, 0.0027, 0.0009, 0.0011, 0.0036,
        0.0116, 0.0049, 0.0034, 0.0015], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,323][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0105, 0.0694, 0.1409, 0.0899, 0.1570, 0.1016, 0.0786, 0.0550, 0.0428,
        0.0558, 0.0739, 0.0340, 0.0905], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,325][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([9.9892e-01, 6.3112e-05, 2.8220e-05, 3.4730e-05, 1.2299e-04, 1.2566e-04,
        9.8497e-05, 7.5274e-05, 2.7663e-05, 1.0880e-04, 4.6758e-05, 9.7744e-05,
        2.4744e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,329][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([1.2710e-03, 9.6113e-01, 2.2553e-02, 7.3253e-03, 4.9615e-03, 1.9906e-04,
        2.3618e-05, 2.3539e-05, 3.0768e-04, 5.6597e-04, 7.0099e-04, 1.0700e-04,
        1.7631e-04, 6.5923e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,332][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([9.8544e-01, 8.7085e-04, 3.0501e-04, 4.3794e-04, 1.2555e-03, 7.9876e-04,
        2.2712e-03, 4.8358e-04, 2.3328e-04, 2.1908e-03, 4.4219e-04, 1.6599e-03,
        2.8569e-03, 7.5209e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,335][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.0323e-04, 2.5024e-02, 7.6458e-03, 3.8735e-02, 3.7046e-02, 2.4272e-02,
        4.4352e-02, 7.8965e-02, 1.3992e-01, 1.0418e-01, 2.3725e-01, 4.7484e-02,
        1.3443e-01, 8.0586e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,338][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.6553e-02, 8.8145e-01, 4.4854e-02, 2.7910e-02, 1.0560e-02, 1.3967e-03,
        2.8471e-04, 2.0263e-04, 8.7604e-04, 3.8513e-03, 3.1868e-03, 4.0367e-03,
        1.0026e-03, 3.8377e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,339][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([1.0812e-03, 9.5387e-01, 1.4968e-02, 1.9240e-02, 4.3568e-03, 5.3140e-04,
        2.1271e-04, 5.4905e-05, 5.7129e-04, 1.4384e-03, 1.4847e-03, 7.2641e-04,
        3.4142e-04, 1.1276e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,340][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([9.9904e-01, 5.6951e-04, 5.5706e-05, 3.4753e-05, 2.9401e-05, 4.3253e-05,
        2.6741e-05, 4.8429e-06, 1.1063e-05, 2.1050e-05, 6.7405e-06, 1.1011e-04,
        7.7283e-06, 3.4281e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,340][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([9.9157e-01, 7.5386e-04, 2.6289e-04, 3.3776e-04, 3.8782e-04, 6.8204e-04,
        4.7525e-04, 1.7250e-04, 3.8277e-04, 5.5602e-04, 3.1387e-04, 2.5737e-03,
        3.8823e-04, 1.1423e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,340][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.9172, 0.0112, 0.0076, 0.0066, 0.0024, 0.0020, 0.0027, 0.0039, 0.0100,
        0.0104, 0.0150, 0.0020, 0.0069, 0.0021], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,341][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([7.4291e-03, 9.1884e-01, 1.0992e-02, 4.0732e-02, 5.9652e-03, 1.4245e-03,
        3.0851e-04, 1.8696e-04, 1.0788e-03, 1.4924e-03, 2.7768e-03, 4.8076e-03,
        2.7095e-04, 3.6937e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,341][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([4.5965e-04, 9.0789e-01, 5.5048e-02, 2.1434e-02, 8.4970e-03, 4.0662e-04,
        1.1695e-04, 1.1106e-04, 5.2210e-04, 2.2588e-03, 9.8957e-04, 8.3550e-04,
        6.4996e-04, 7.8159e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,341][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0006, 0.0421, 0.0632, 0.0729, 0.2284, 0.0452, 0.0932, 0.0314, 0.0471,
        0.0599, 0.0756, 0.0493, 0.1425, 0.0485], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,342][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([9.8989e-01, 3.4390e-04, 2.2601e-04, 2.4995e-04, 8.9539e-04, 7.2187e-04,
        7.0918e-04, 5.2043e-04, 2.8764e-04, 8.5079e-04, 5.5951e-04, 1.2772e-03,
        3.2285e-03, 2.3732e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,342][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.6363e-03, 9.5868e-01, 1.6849e-02, 7.5694e-03, 5.9020e-03, 3.1106e-04,
        6.0140e-05, 6.6773e-05, 7.7710e-04, 1.0489e-03, 1.6169e-03, 2.7877e-04,
        4.6107e-04, 1.8519e-03, 2.8946e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,343][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9874e-01, 1.3747e-04, 6.4144e-05, 8.9841e-05, 1.4911e-04, 7.5104e-05,
        1.2170e-04, 2.7960e-05, 1.6199e-05, 1.6642e-04, 6.4400e-05, 7.9557e-05,
        2.0003e-04, 2.8078e-05, 4.4964e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,348][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0020, 0.0638, 0.0125, 0.0453, 0.0675, 0.0208, 0.0273, 0.0807, 0.1506,
        0.0812, 0.1300, 0.0482, 0.1231, 0.0348, 0.1123], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,351][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.0122e-01, 6.1727e-01, 2.5701e-02, 2.1451e-02, 8.0559e-03, 1.7379e-03,
        4.0716e-04, 2.1805e-04, 9.7966e-04, 4.2333e-03, 4.5468e-03, 4.2381e-03,
        1.1024e-03, 4.4580e-03, 4.3873e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,354][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.6432e-02, 9.1556e-01, 1.8909e-02, 2.5004e-02, 6.5984e-03, 1.2305e-03,
        8.1345e-04, 1.3744e-04, 1.9431e-03, 3.3876e-03, 3.1012e-03, 1.3756e-03,
        7.9181e-04, 2.5098e-03, 2.2107e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,358][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9980e-01, 9.4118e-05, 7.8323e-06, 8.8498e-06, 7.1151e-06, 1.1617e-05,
        8.2201e-06, 1.0165e-06, 5.9746e-06, 5.0587e-06, 2.1621e-06, 3.4044e-05,
        2.7747e-06, 9.3059e-06, 1.3030e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,360][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9760e-01, 2.1668e-04, 1.1700e-04, 8.1335e-05, 1.6115e-04, 1.7003e-04,
        1.4941e-04, 5.5186e-05, 9.9857e-05, 1.3494e-04, 7.5460e-05, 7.2590e-04,
        1.2722e-04, 1.9937e-04, 8.4025e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,364][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.9481e-01, 1.3202e-03, 4.2214e-04, 3.4997e-04, 2.1934e-04, 1.2152e-04,
        1.5297e-04, 1.7665e-04, 2.8536e-04, 4.8825e-04, 5.8963e-04, 2.0217e-04,
        5.3363e-04, 1.0551e-04, 2.1986e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,366][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.8631e-01, 6.9444e-01, 1.1699e-02, 4.1224e-02, 5.9480e-03, 3.7610e-03,
        1.0725e-03, 4.8772e-04, 2.4932e-03, 3.1219e-03, 8.6407e-03, 1.6481e-02,
        8.7212e-04, 1.6651e-02, 6.7985e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,366][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.1105e-02, 9.0291e-01, 3.6165e-02, 2.5405e-02, 6.9379e-03, 1.7054e-03,
        4.2713e-04, 4.3539e-04, 1.0155e-03, 4.4998e-03, 2.1771e-03, 1.6517e-03,
        7.4106e-04, 2.5159e-03, 2.3045e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,366][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0048, 0.0774, 0.1408, 0.0644, 0.3048, 0.0258, 0.0435, 0.0197, 0.0343,
        0.0415, 0.0422, 0.0287, 0.1295, 0.0142, 0.0285], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,367][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([9.9918e-01, 4.8473e-05, 2.5167e-05, 2.1263e-05, 1.1220e-04, 5.1166e-05,
        5.0138e-05, 4.1219e-05, 2.3865e-05, 5.4381e-05, 2.6319e-05, 1.0795e-04,
        1.9899e-04, 1.2042e-05, 5.0558e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,368][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:41,369][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10287],
        [   29],
        [14784],
        [    2],
        [  446],
        [   11],
        [   32],
        [  120],
        [  125],
        [    5],
        [    4],
        [   47],
        [  706],
        [   79],
        [    3]], device='cuda:0')
[2024-07-24 10:20:41,370][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9170],
        [  513],
        [27778],
        [   52],
        [ 1822],
        [  267],
        [  574],
        [  634],
        [  572],
        [  140],
        [   78],
        [  135],
        [ 2290],
        [  241],
        [   28]], device='cuda:0')
[2024-07-24 10:20:41,373][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[42902],
        [16599],
        [14520],
        [16122],
        [15732],
        [18990],
        [18999],
        [20081],
        [21148],
        [21614],
        [22016],
        [22497],
        [22134],
        [22167],
        [22323]], device='cuda:0')
[2024-07-24 10:20:41,375][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[25784],
        [12848],
        [17891],
        [16283],
        [16709],
        [17268],
        [17467],
        [16409],
        [15628],
        [15383],
        [15302],
        [14907],
        [14975],
        [14851],
        [14456]], device='cuda:0')
[2024-07-24 10:20:41,378][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[34823],
        [28535],
        [37921],
        [41107],
        [36513],
        [35440],
        [37081],
        [36650],
        [36079],
        [36099],
        [34600],
        [33920],
        [33760],
        [33091],
        [34352]], device='cuda:0')
[2024-07-24 10:20:41,380][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[5618],
        [1569],
        [1154],
        [2642],
        [2318],
        [2917],
        [3129],
        [3301],
        [3852],
        [4038],
        [3923],
        [3594],
        [3620],
        [3729],
        [3845]], device='cuda:0')
[2024-07-24 10:20:41,383][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3841],
        [ 4235],
        [ 3835],
        [ 6273],
        [ 3718],
        [18307],
        [17456],
        [19778],
        [21019],
        [20755],
        [19447],
        [16691],
        [ 6398],
        [21639],
        [12364]], device='cuda:0')
[2024-07-24 10:20:41,385][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43004],
        [43002],
        [43004],
        [43004],
        [43003],
        [42999],
        [42997],
        [43002],
        [43005],
        [43000],
        [43004],
        [43002],
        [43003],
        [42999],
        [43004]], device='cuda:0')
[2024-07-24 10:20:41,388][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[4004],
        [2039],
        [1462],
        [1406],
        [1395],
        [1386],
        [1448],
        [1412],
        [1380],
        [1391],
        [1428],
        [1432],
        [1465],
        [1397],
        [1412]], device='cuda:0')
[2024-07-24 10:20:41,390][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42909],
        [36334],
        [43951],
        [44522],
        [45057],
        [45653],
        [45199],
        [44517],
        [44252],
        [44046],
        [43271],
        [42986],
        [42927],
        [43063],
        [43155]], device='cuda:0')
[2024-07-24 10:20:41,393][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[36002],
        [35905],
        [36369],
        [33567],
        [35177],
        [25293],
        [25709],
        [24465],
        [29506],
        [27455],
        [31198],
        [26445],
        [32353],
        [23505],
        [32439]], device='cuda:0')
[2024-07-24 10:20:41,395][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31559],
        [ 7322],
        [ 6668],
        [ 5633],
        [ 7378],
        [ 7522],
        [ 6796],
        [ 7783],
        [ 8512],
        [ 8295],
        [ 8218],
        [ 7480],
        [ 7644],
        [ 7981],
        [ 8486]], device='cuda:0')
[2024-07-24 10:20:41,398][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11911],
        [ 8047],
        [  711],
        [   31],
        [  318],
        [   49],
        [  259],
        [  279],
        [   57],
        [  118],
        [  171],
        [  440],
        [  676],
        [  587],
        [  424]], device='cuda:0')
[2024-07-24 10:20:41,399][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41097],
        [38665],
        [47996],
        [47505],
        [48071],
        [47046],
        [46632],
        [45116],
        [43255],
        [43922],
        [43835],
        [42559],
        [43270],
        [42144],
        [42208]], device='cuda:0')
[2024-07-24 10:20:41,400][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[4391],
        [ 425],
        [ 745],
        [ 553],
        [1177],
        [1238],
        [1273],
        [ 440],
        [1145],
        [ 148],
        [1104],
        [1691],
        [3101],
        [ 990],
        [ 832]], device='cuda:0')
[2024-07-24 10:20:41,401][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12936],
        [12072],
        [12707],
        [14685],
        [14503],
        [15297],
        [15044],
        [14701],
        [14864],
        [14878],
        [14706],
        [15051],
        [14681],
        [14640],
        [14561]], device='cuda:0')
[2024-07-24 10:20:41,402][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[32065],
        [31991],
        [32038],
        [31249],
        [32016],
        [29892],
        [30664],
        [31987],
        [32003],
        [30458],
        [30931],
        [31315],
        [31557],
        [29483],
        [31845]], device='cuda:0')
[2024-07-24 10:20:41,403][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[16474],
        [31396],
        [30553],
        [26574],
        [28762],
        [28686],
        [26360],
        [19743],
        [33447],
        [34984],
        [34120],
        [30271],
        [31776],
        [33921],
        [34095]], device='cuda:0')
[2024-07-24 10:20:41,405][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[2058],
        [ 816],
        [1642],
        [1433],
        [ 723],
        [2189],
        [1979],
        [1854],
        [1788],
        [1807],
        [1679],
        [1920],
        [1294],
        [1916],
        [1313]], device='cuda:0')
[2024-07-24 10:20:41,408][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10123],
        [15675],
        [19764],
        [11787],
        [11628],
        [11550],
        [11492],
        [11584],
        [11600],
        [11632],
        [11590],
        [10852],
        [10639],
        [11724],
        [11593]], device='cuda:0')
[2024-07-24 10:20:41,410][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[24969],
        [24969],
        [24968],
        [24968],
        [24966],
        [24893],
        [24904],
        [24914],
        [24946],
        [24909],
        [24955],
        [24820],
        [24862],
        [24879],
        [24947]], device='cuda:0')
[2024-07-24 10:20:41,413][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[35755],
        [35798],
        [35765],
        [35850],
        [35799],
        [36627],
        [36423],
        [35967],
        [35901],
        [36763],
        [36109],
        [36484],
        [36472],
        [36789],
        [36044]], device='cuda:0')
[2024-07-24 10:20:41,415][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[20532],
        [15978],
        [19871],
        [14051],
        [19613],
        [13754],
        [16983],
        [19011],
        [17990],
        [14396],
        [17473],
        [17040],
        [15345],
        [13012],
        [19718]], device='cuda:0')
[2024-07-24 10:20:41,418][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38855],
        [39215],
        [38383],
        [22286],
        [30146],
        [19426],
        [19610],
        [19128],
        [20055],
        [19680],
        [20270],
        [22587],
        [27374],
        [19013],
        [23108]], device='cuda:0')
[2024-07-24 10:20:41,420][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37705],
        [43032],
        [42582],
        [43342],
        [42566],
        [42911],
        [42273],
        [42126],
        [42322],
        [42509],
        [42300],
        [41528],
        [41684],
        [42294],
        [42012]], device='cuda:0')
[2024-07-24 10:20:41,423][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[31612],
        [39528],
        [31360],
        [34964],
        [24069],
        [20492],
        [30845],
        [40711],
        [28284],
        [22819],
        [24236],
        [31728],
        [32965],
        [30614],
        [24975]], device='cuda:0')
[2024-07-24 10:20:41,425][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[8511],
        [8483],
        [8509],
        [8491],
        [8512],
        [8483],
        [8490],
        [8498],
        [8504],
        [8484],
        [8510],
        [8469],
        [8504],
        [8415],
        [8501]], device='cuda:0')
[2024-07-24 10:20:41,428][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18620],
        [11399],
        [ 9852],
        [17468],
        [17097],
        [20293],
        [19312],
        [18239],
        [18094],
        [19723],
        [19088],
        [18067],
        [17775],
        [19797],
        [18057]], device='cuda:0')
[2024-07-24 10:20:41,431][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[43297],
        [49249],
        [49656],
        [48946],
        [49061],
        [47847],
        [47325],
        [48453],
        [47451],
        [49529],
        [47651],
        [47521],
        [45486],
        [48153],
        [48462]], device='cuda:0')
[2024-07-24 10:20:41,431][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180],
        [6180]], device='cuda:0')
[2024-07-24 10:20:41,461][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:41,461][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,462][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,462][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,462][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,463][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,463][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,463][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,464][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,464][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,464][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,465][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,465][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,465][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9943, 0.0057], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,465][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.6750e-05, 9.9997e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,466][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9976, 0.0024], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,466][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9418, 0.0582], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,466][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1296, 0.8704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,467][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9965e-01, 3.5188e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,467][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3435, 0.6565], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,467][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0033, 0.9967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,468][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,468][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7821, 0.2179], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,469][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6975, 0.3025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,469][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1989, 0.8011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,469][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.9918, 0.0057, 0.0025], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,470][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([1.9416e-05, 2.6778e-01, 7.3220e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,470][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.9954, 0.0017, 0.0029], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,470][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.9307, 0.0181, 0.0513], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,471][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.1198, 0.7627, 0.1175], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,471][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([9.9971e-01, 2.1789e-04, 7.1738e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,471][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.1711, 0.4056, 0.4234], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,472][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.0010, 0.5081, 0.4909], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,472][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([9.9933e-01, 3.4625e-04, 3.2181e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,472][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.9176, 0.0440, 0.0384], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,473][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.6671, 0.2020, 0.1309], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,473][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.1172, 0.7011, 0.1817], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,473][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9906, 0.0051, 0.0030, 0.0013], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,474][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([3.3963e-06, 2.5830e-01, 5.7361e-01, 1.6809e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,474][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9624e-01, 1.1585e-03, 2.2433e-03, 3.5701e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,474][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3823, 0.1806, 0.1935, 0.2435], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,475][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0019, 0.9674, 0.0170, 0.0137], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,475][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9703, 0.0270, 0.0015, 0.0012], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,475][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2416, 0.2161, 0.2985, 0.2437], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,476][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([4.3118e-04, 2.7180e-01, 5.7842e-01, 1.4935e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,476][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.8448e-01, 7.1534e-03, 7.9123e-03, 4.5383e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,480][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.8185, 0.1350, 0.0337, 0.0128], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,485][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3904, 0.3229, 0.1517, 0.1349], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,487][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0087, 0.7756, 0.1592, 0.0565], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,488][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.9836, 0.0073, 0.0023, 0.0012, 0.0057], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,488][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([2.2963e-05, 1.9738e-01, 5.0521e-01, 1.5313e-01, 1.4425e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,489][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.9882, 0.0021, 0.0030, 0.0011, 0.0057], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,489][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.6828, 0.0784, 0.1515, 0.0474, 0.0400], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,489][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0027, 0.9365, 0.0187, 0.0383, 0.0038], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,490][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([9.7227e-01, 2.3738e-02, 1.4588e-03, 2.4042e-03, 1.2470e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,490][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1109, 0.1961, 0.2251, 0.2866, 0.1813], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,490][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0005, 0.3197, 0.3243, 0.2030, 0.1526], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,491][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([9.9529e-01, 2.6078e-03, 1.7015e-03, 1.5811e-04, 2.4062e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,494][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.7373, 0.0957, 0.0433, 0.0251, 0.0985], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,497][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.4130, 0.2449, 0.1124, 0.1221, 0.1076], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,501][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0353, 0.7065, 0.1235, 0.0926, 0.0421], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,503][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.8193e-01, 4.3365e-03, 1.9740e-03, 8.5945e-04, 4.1691e-03, 6.7286e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,505][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([4.2891e-06, 2.3751e-01, 4.6025e-01, 1.4293e-01, 1.1386e-01, 4.5447e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,508][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.9630, 0.0072, 0.0118, 0.0028, 0.0135, 0.0016], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,512][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2165, 0.1519, 0.3469, 0.1373, 0.0914, 0.0559], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,515][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([7.3088e-05, 9.2591e-01, 2.7999e-02, 3.7495e-02, 8.1788e-03, 3.4061e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,517][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.4991, 0.3851, 0.0556, 0.0512, 0.0075, 0.0015], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,517][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0677, 0.1665, 0.1918, 0.1757, 0.1737, 0.2245], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,518][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([2.5277e-04, 1.7633e-01, 3.7926e-01, 1.3595e-01, 1.7662e-01, 1.3157e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,518][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([9.2796e-01, 3.2940e-02, 3.0867e-02, 2.1503e-03, 5.1728e-03, 9.0600e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,518][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.7734, 0.0622, 0.0258, 0.0155, 0.0501, 0.0730], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,519][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1489, 0.3358, 0.1670, 0.1542, 0.1096, 0.0845], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,519][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0046, 0.6603, 0.1430, 0.1179, 0.0619, 0.0123], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,519][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.4892e-01, 1.3265e-02, 5.1749e-03, 2.7959e-03, 9.6661e-03, 2.0115e-02,
        6.0488e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,520][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.6308e-05, 1.8143e-01, 4.1705e-01, 1.4067e-01, 1.1122e-01, 4.3407e-02,
        1.0621e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,522][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.9620, 0.0072, 0.0127, 0.0025, 0.0128, 0.0014, 0.0014],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,524][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0803, 0.1815, 0.3255, 0.1739, 0.0805, 0.0938, 0.0645],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,526][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([6.7749e-05, 9.1404e-01, 3.0216e-02, 4.5324e-02, 8.3506e-03, 1.8020e-03,
        1.9856e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,531][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5036, 0.3747, 0.0433, 0.0642, 0.0097, 0.0035, 0.0010],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,535][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0623, 0.1477, 0.1614, 0.1615, 0.1293, 0.1902, 0.1475],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,538][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0009, 0.2233, 0.2786, 0.1606, 0.1721, 0.1487, 0.0157],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,540][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([8.7909e-01, 5.6984e-02, 4.9093e-02, 3.6066e-03, 8.7226e-03, 2.0335e-03,
        4.7068e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,544][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4985, 0.2335, 0.0454, 0.0245, 0.0953, 0.0735, 0.0293],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,546][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0942, 0.3239, 0.1457, 0.1715, 0.1103, 0.0995, 0.0549],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,547][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0029, 0.7023, 0.1213, 0.1000, 0.0490, 0.0189, 0.0055],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,547][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.6488e-01, 9.2508e-03, 3.5531e-03, 1.8064e-03, 6.8267e-03, 1.3353e-02,
        2.2349e-05, 3.0739e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,547][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8463e-06, 1.8215e-01, 3.8255e-01, 1.6592e-01, 1.0464e-01, 4.0351e-02,
        1.1690e-01, 7.4968e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,548][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([9.8607e-01, 1.9652e-03, 3.5526e-03, 7.8294e-04, 5.6083e-03, 3.9510e-04,
        4.8209e-04, 1.1454e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,548][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.7390, 0.1022, 0.0635, 0.0343, 0.0119, 0.0270, 0.0178, 0.0043],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,549][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([2.1756e-04, 8.9913e-01, 3.0632e-02, 5.4762e-02, 1.4431e-02, 6.5650e-04,
        1.5391e-04, 2.0559e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,549][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([1.0237e-01, 7.6054e-01, 1.6655e-02, 1.1043e-01, 6.1397e-03, 2.6095e-03,
        1.2272e-03, 3.5243e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,549][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1032, 0.1090, 0.1236, 0.1287, 0.0995, 0.1562, 0.1344, 0.1453],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,550][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([2.4315e-04, 2.1633e-01, 2.7053e-01, 1.0656e-01, 1.7862e-01, 2.0257e-01,
        1.7310e-02, 7.8391e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,552][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([9.6207e-01, 1.8902e-02, 1.4947e-02, 1.1568e-03, 2.5205e-03, 3.2074e-04,
        7.7557e-05, 7.2786e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,555][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.4824, 0.1214, 0.0412, 0.0267, 0.0865, 0.1136, 0.0548, 0.0734],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,558][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2413, 0.2048, 0.1034, 0.1412, 0.0907, 0.1079, 0.0562, 0.0546],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,560][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([6.0935e-04, 7.8047e-01, 1.1652e-01, 5.7347e-02, 3.2017e-02, 9.5181e-03,
        1.7228e-03, 1.7972e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,563][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([9.5234e-01, 1.2625e-02, 3.8218e-03, 1.9828e-03, 7.7560e-03, 1.9107e-02,
        2.1858e-05, 4.6847e-04, 1.8823e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,565][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([2.5991e-06, 1.7359e-01, 4.2952e-01, 1.3024e-01, 1.1818e-01, 3.6192e-02,
        9.5230e-02, 6.9958e-03, 1.0038e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,567][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.9385e-01, 6.7655e-04, 1.4413e-03, 2.7919e-04, 2.1793e-03, 1.5374e-04,
        1.7863e-04, 4.6144e-04, 7.8236e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,571][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.4051, 0.2332, 0.1396, 0.1024, 0.0294, 0.0410, 0.0301, 0.0078, 0.0114],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,574][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([2.0806e-04, 9.3482e-01, 1.5241e-02, 4.5903e-02, 3.2061e-03, 3.8826e-04,
        8.6013e-05, 3.3228e-05, 1.1230e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,576][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([4.7655e-01, 4.4386e-01, 1.7959e-02, 5.6163e-02, 3.3602e-03, 1.2439e-03,
        6.3551e-04, 3.6516e-05, 1.9805e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,576][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0554, 0.0838, 0.1127, 0.1082, 0.0872, 0.1415, 0.1219, 0.1428, 0.1464],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,576][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([1.5946e-04, 2.0432e-01, 3.1976e-01, 1.0844e-01, 1.2334e-01, 1.3742e-01,
        1.9901e-02, 1.7548e-02, 6.9115e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,577][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([9.7894e-01, 9.1305e-03, 9.8050e-03, 5.8148e-04, 1.3556e-03, 1.4768e-04,
        3.3469e-05, 2.8132e-06, 7.2962e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,577][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.8051, 0.0493, 0.0117, 0.0071, 0.0311, 0.0407, 0.0170, 0.0184, 0.0195],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,578][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.3511, 0.1849, 0.0898, 0.1088, 0.0736, 0.0730, 0.0424, 0.0372, 0.0392],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,578][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0020, 0.7541, 0.0785, 0.1064, 0.0366, 0.0084, 0.0028, 0.0039, 0.0072],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,578][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.5347e-01, 9.9769e-03, 5.2288e-03, 3.4805e-03, 9.4554e-03, 1.3448e-02,
        6.1061e-05, 6.4304e-04, 1.9161e-03, 2.3161e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,579][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.8775e-06, 1.5444e-01, 3.7781e-01, 1.2822e-01, 1.0368e-01, 3.7695e-02,
        8.8510e-02, 6.7758e-03, 1.3394e-02, 8.9471e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,580][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9383e-01, 8.5711e-04, 1.6927e-03, 2.3425e-04, 2.0283e-03, 1.1400e-04,
        1.2345e-04, 3.0232e-04, 6.5996e-04, 1.6117e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,583][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0684, 0.1427, 0.2436, 0.1279, 0.0698, 0.1047, 0.0463, 0.0294, 0.0614,
        0.1058], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,585][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([5.4463e-05, 9.5807e-01, 2.0271e-02, 1.7500e-02, 2.6928e-03, 4.6542e-04,
        7.1398e-05, 4.4374e-05, 1.6539e-04, 6.6136e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,587][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([2.4236e-01, 6.4961e-01, 6.0957e-02, 3.6335e-02, 5.5000e-03, 1.8332e-03,
        5.6099e-04, 5.4268e-05, 3.6626e-04, 2.4240e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,592][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0413, 0.0742, 0.1117, 0.0829, 0.0888, 0.1258, 0.1144, 0.1349, 0.1254,
        0.1005], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,596][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0005, 0.0962, 0.2827, 0.0606, 0.1110, 0.1213, 0.0188, 0.0068, 0.1392,
        0.1628], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,598][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.0183e-01, 4.0160e-02, 4.9495e-02, 1.8705e-03, 5.2620e-03, 8.3856e-04,
        1.6258e-04, 4.6910e-05, 9.4530e-05, 2.3852e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,601][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4668, 0.1374, 0.0364, 0.0153, 0.0940, 0.0945, 0.0370, 0.0547, 0.0355,
        0.0282], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,605][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1132, 0.2516, 0.1299, 0.1349, 0.0875, 0.0798, 0.0443, 0.0441, 0.0478,
        0.0671], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,605][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0008, 0.7153, 0.1802, 0.0489, 0.0339, 0.0068, 0.0017, 0.0029, 0.0033,
        0.0061], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,606][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.4875e-01, 8.6662e-03, 5.6911e-03, 2.9355e-03, 1.1034e-02, 1.4606e-02,
        6.8906e-05, 6.5198e-04, 2.2606e-03, 2.3749e-03, 2.9563e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,606][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([5.8303e-06, 1.5091e-01, 3.2763e-01, 1.0504e-01, 1.0034e-01, 2.9295e-02,
        6.3940e-02, 6.7734e-03, 1.2711e-02, 6.5217e-02, 1.3813e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,607][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.7448e-01, 4.0903e-03, 6.6171e-03, 1.2114e-03, 7.2311e-03, 6.0776e-04,
        6.3511e-04, 1.2846e-03, 2.4672e-03, 8.0922e-04, 5.6122e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,607][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1472, 0.0830, 0.1720, 0.1119, 0.0536, 0.0853, 0.0453, 0.0306, 0.0598,
        0.1024, 0.1089], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,607][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([7.4586e-05, 9.4896e-01, 2.3750e-02, 1.9656e-02, 3.6530e-03, 6.3957e-04,
        1.0267e-04, 4.9527e-05, 2.0599e-04, 1.2033e-03, 1.7047e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,608][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.4693e-01, 5.7340e-01, 3.8919e-02, 2.7928e-02, 4.4620e-03, 1.6785e-03,
        7.4780e-04, 5.1639e-05, 3.2183e-04, 3.1417e-03, 2.4172e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,609][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0574, 0.0634, 0.1066, 0.0636, 0.0868, 0.1102, 0.1068, 0.1291, 0.1230,
        0.0850, 0.0680], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,612][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0005, 0.0992, 0.2497, 0.0452, 0.1148, 0.1082, 0.0187, 0.0098, 0.0828,
        0.2126, 0.0586], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,614][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.6221e-01, 1.5878e-02, 1.7701e-02, 9.2607e-04, 2.5241e-03, 4.0554e-04,
        9.3935e-05, 1.7063e-05, 2.9770e-05, 1.1910e-04, 9.8185e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,618][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4370, 0.1470, 0.0331, 0.0111, 0.1021, 0.1003, 0.0366, 0.0583, 0.0399,
        0.0289, 0.0056], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,621][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0887, 0.2675, 0.1101, 0.1251, 0.0693, 0.0661, 0.0399, 0.0432, 0.0389,
        0.0638, 0.0876], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,625][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0032, 0.7538, 0.1230, 0.0571, 0.0292, 0.0095, 0.0029, 0.0032, 0.0028,
        0.0076, 0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,628][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([9.5115e-01, 1.0628e-02, 4.1838e-03, 2.6455e-03, 8.4710e-03, 1.3712e-02,
        3.0653e-05, 5.5116e-04, 1.4688e-03, 2.7366e-03, 2.9018e-03, 1.5203e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,630][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([4.5110e-06, 1.1160e-01, 3.1380e-01, 1.1765e-01, 9.6382e-02, 3.4198e-02,
        7.4258e-02, 7.9083e-03, 1.3202e-02, 6.9486e-02, 1.2853e-01, 3.2992e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,632][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([9.6744e-01, 3.2837e-03, 5.4100e-03, 1.5530e-03, 9.0555e-03, 8.6091e-04,
        9.1433e-04, 2.2474e-03, 3.2854e-03, 9.4225e-04, 8.8151e-04, 4.1227e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,635][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.3301, 0.0845, 0.2077, 0.1019, 0.0711, 0.0500, 0.0254, 0.0247, 0.0217,
        0.0390, 0.0208, 0.0231], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,635][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([1.5893e-04, 8.8142e-01, 1.8397e-02, 7.7459e-02, 9.2260e-03, 1.9363e-03,
        4.9856e-04, 2.6742e-04, 6.4744e-04, 2.9153e-03, 5.7468e-03, 1.3307e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,635][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([1.5236e-01, 6.1292e-01, 6.1165e-02, 1.2261e-01, 1.5604e-02, 5.4788e-03,
        3.1444e-03, 3.6490e-04, 2.1003e-03, 1.0233e-02, 9.2254e-03, 4.7903e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,636][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0390, 0.0716, 0.0824, 0.0837, 0.0650, 0.1022, 0.0861, 0.1140, 0.1009,
        0.0945, 0.0939, 0.0667], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,636][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0008, 0.1024, 0.1504, 0.0804, 0.0931, 0.1401, 0.0257, 0.0074, 0.0622,
        0.1691, 0.0883, 0.0801], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,637][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([9.2689e-01, 3.3870e-02, 2.6116e-02, 3.3784e-03, 5.9562e-03, 1.3387e-03,
        3.3258e-04, 1.4052e-04, 1.9825e-04, 3.7695e-04, 4.1070e-04, 9.8980e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,637][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.3154, 0.1120, 0.0318, 0.0299, 0.0555, 0.1159, 0.0628, 0.0667, 0.0432,
        0.0566, 0.0201, 0.0902], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,638][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0921, 0.1730, 0.0837, 0.1182, 0.0766, 0.0841, 0.0506, 0.0502, 0.0664,
        0.0730, 0.0840, 0.0480], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,639][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0092, 0.6831, 0.0757, 0.1015, 0.0376, 0.0159, 0.0066, 0.0119, 0.0112,
        0.0138, 0.0114, 0.0221], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,641][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([9.3703e-01, 9.6859e-03, 2.8784e-03, 1.6615e-03, 7.0220e-03, 1.4237e-02,
        2.4055e-05, 3.1318e-04, 1.3928e-03, 2.7443e-03, 2.0248e-03, 9.6544e-04,
        2.0017e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,643][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([1.9293e-05, 1.0804e-01, 2.5326e-01, 9.4036e-02, 8.5734e-02, 2.9214e-02,
        6.3843e-02, 8.8340e-03, 1.2159e-02, 5.9576e-02, 1.0981e-01, 3.0553e-02,
        1.4492e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,646][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([9.7161e-01, 2.0132e-03, 3.9038e-03, 9.7952e-04, 7.3044e-03, 6.0358e-04,
        6.8286e-04, 1.6192e-03, 2.7868e-03, 7.4123e-04, 5.6475e-04, 3.6153e-03,
        3.5704e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,649][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.2450, 0.0746, 0.1905, 0.1124, 0.0459, 0.0561, 0.0431, 0.0319, 0.0224,
        0.0786, 0.0386, 0.0314, 0.0296], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,651][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([4.2287e-04, 8.9762e-01, 2.2766e-02, 5.8927e-02, 7.3165e-03, 1.6376e-03,
        2.5819e-04, 1.0660e-04, 3.2489e-04, 3.7105e-03, 6.0757e-03, 5.7879e-04,
        2.5499e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,653][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([5.6384e-01, 3.0571e-01, 2.4441e-02, 7.3342e-02, 4.9125e-03, 3.2306e-03,
        2.0848e-03, 2.7501e-04, 9.9351e-04, 8.2923e-03, 7.9188e-03, 4.3596e-03,
        5.9434e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,657][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0218, 0.0610, 0.0725, 0.0899, 0.0582, 0.0911, 0.0832, 0.1059, 0.1007,
        0.0989, 0.1078, 0.0522, 0.0566], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,661][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0003, 0.1068, 0.0988, 0.0669, 0.0863, 0.0956, 0.0194, 0.0185, 0.1156,
        0.1254, 0.0619, 0.1363, 0.0682], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,664][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([9.6855e-01, 1.7695e-02, 7.8718e-03, 1.5060e-03, 1.8560e-03, 7.4505e-04,
        2.3655e-04, 6.4719e-05, 7.1607e-05, 2.6757e-04, 2.1532e-04, 6.6831e-04,
        2.5078e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,664][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.4514, 0.0704, 0.0311, 0.0180, 0.0817, 0.0755, 0.0296, 0.0336, 0.0403,
        0.0472, 0.0144, 0.0366, 0.0702], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,665][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.1010, 0.1709, 0.0696, 0.1034, 0.0657, 0.0753, 0.0514, 0.0524, 0.0553,
        0.0767, 0.0896, 0.0530, 0.0358], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,665][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.0070, 0.5737, 0.0917, 0.1225, 0.0481, 0.0237, 0.0074, 0.0135, 0.0114,
        0.0243, 0.0273, 0.0416, 0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,666][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([8.7044e-01, 1.7665e-02, 6.8463e-03, 3.4873e-03, 1.4567e-02, 3.6870e-02,
        6.0606e-05, 6.8782e-04, 2.7520e-03, 3.3682e-03, 3.2541e-03, 1.8761e-03,
        2.7588e-02, 1.0535e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,666][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([3.1430e-06, 1.0007e-01, 2.4723e-01, 8.9985e-02, 7.2421e-02, 3.0326e-02,
        6.5922e-02, 5.9893e-03, 9.8463e-03, 6.3240e-02, 1.2396e-01, 2.6540e-02,
        1.3599e-01, 2.8482e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,666][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([9.6565e-01, 2.8993e-03, 5.2542e-03, 1.1491e-03, 8.0876e-03, 6.7415e-04,
        7.2359e-04, 1.8268e-03, 2.9691e-03, 7.8643e-04, 6.2763e-04, 4.0744e-03,
        3.6096e-03, 1.6712e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,667][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0446, 0.1276, 0.4402, 0.0705, 0.0592, 0.0432, 0.0218, 0.0148, 0.0385,
        0.0467, 0.0283, 0.0160, 0.0142, 0.0342], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,668][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([2.9614e-05, 9.6604e-01, 1.0181e-02, 2.0257e-02, 1.3127e-03, 1.9064e-04,
        3.0699e-05, 1.4912e-05, 5.3107e-05, 4.5801e-04, 7.5952e-04, 8.5570e-05,
        2.6146e-05, 5.5950e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,669][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([9.2381e-02, 8.2668e-01, 2.6353e-02, 4.2881e-02, 4.3069e-03, 1.1027e-03,
        3.1462e-04, 2.8240e-05, 1.8838e-04, 1.7327e-03, 1.5831e-03, 1.3118e-03,
        1.6162e-04, 9.7316e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,673][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0134, 0.0649, 0.0790, 0.0696, 0.0651, 0.0846, 0.0739, 0.1030, 0.0917,
        0.0814, 0.0707, 0.0484, 0.0563, 0.0980], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,675][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([8.5676e-05, 1.2479e-01, 1.7643e-01, 5.0844e-02, 8.1467e-02, 6.8340e-02,
        9.2565e-03, 5.1603e-03, 5.1211e-02, 1.8533e-01, 5.9006e-02, 8.5224e-02,
        8.0930e-02, 2.1925e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,677][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([7.8765e-01, 1.2118e-01, 6.9288e-02, 5.4832e-03, 8.9558e-03, 2.3483e-03,
        4.2957e-04, 1.1870e-04, 1.4138e-04, 5.5392e-04, 4.3198e-04, 1.3614e-03,
        8.4802e-04, 1.2058e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,680][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.4457, 0.0609, 0.0250, 0.0123, 0.0443, 0.1101, 0.0242, 0.0385, 0.0278,
        0.0319, 0.0112, 0.0521, 0.0442, 0.0717], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,684][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0587, 0.2291, 0.1009, 0.1125, 0.0708, 0.0641, 0.0369, 0.0353, 0.0362,
        0.0556, 0.0721, 0.0379, 0.0337, 0.0562], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,689][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0023, 0.7960, 0.0718, 0.0589, 0.0243, 0.0055, 0.0018, 0.0039, 0.0041,
        0.0062, 0.0062, 0.0101, 0.0020, 0.0069], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,691][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.0413e-01, 1.0628e-02, 5.6748e-03, 2.8651e-03, 1.2641e-02, 1.5389e-02,
        5.8296e-05, 5.4653e-04, 2.2170e-03, 2.5422e-03, 2.7638e-03, 2.0144e-03,
        2.7996e-02, 8.2976e-03, 2.2321e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,693][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.2148e-05, 1.0157e-01, 2.2034e-01, 8.3740e-02, 6.5392e-02, 2.9400e-02,
        5.4731e-02, 7.4644e-03, 1.3557e-02, 6.1631e-02, 1.0169e-01, 2.7827e-02,
        1.1082e-01, 2.6899e-02, 9.4913e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,694][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.8202e-01, 1.7055e-03, 3.0808e-03, 5.2580e-04, 3.9503e-03, 3.1249e-04,
        3.4114e-04, 7.5540e-04, 1.4072e-03, 3.7099e-04, 3.0689e-04, 2.2062e-03,
        1.7020e-03, 7.6110e-04, 5.5408e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,694][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0763, 0.0677, 0.1173, 0.1070, 0.0447, 0.1013, 0.0488, 0.0310, 0.0485,
        0.0919, 0.0717, 0.0532, 0.0270, 0.0780, 0.0356], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,695][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.5621e-04, 9.5463e-01, 1.2759e-02, 1.7036e-02, 2.8709e-03, 6.8099e-04,
        1.1286e-04, 2.9994e-05, 1.2304e-04, 1.6755e-03, 2.7936e-03, 4.8020e-04,
        1.6032e-04, 2.6400e-03, 3.8510e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,695][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.0395e-01, 7.1660e-01, 2.3902e-02, 3.2353e-02, 3.9037e-03, 1.5271e-03,
        7.8591e-04, 3.1829e-05, 2.3059e-04, 3.6102e-03, 3.3647e-03, 1.2959e-03,
        3.3468e-04, 3.4301e-03, 4.6749e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,696][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0139, 0.0520, 0.0861, 0.0575, 0.0676, 0.0776, 0.0673, 0.1059, 0.0897,
        0.0683, 0.0614, 0.0488, 0.0613, 0.0917, 0.0510], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,696][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0003, 0.0623, 0.1748, 0.0372, 0.0900, 0.0906, 0.0102, 0.0045, 0.0687,
        0.1438, 0.0532, 0.0980, 0.1188, 0.0225, 0.0252], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,697][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.6897e-01, 1.6898e-02, 1.0329e-02, 8.3595e-04, 1.6411e-03, 3.6437e-04,
        8.9397e-05, 1.1087e-05, 1.9577e-05, 9.7693e-05, 7.8891e-05, 2.3166e-04,
        1.6497e-04, 1.9509e-04, 7.2495e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,699][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2748, 0.1018, 0.0420, 0.0153, 0.0909, 0.0891, 0.0368, 0.0438, 0.0344,
        0.0377, 0.0119, 0.0721, 0.0795, 0.0336, 0.0364], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,702][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0646, 0.1912, 0.0826, 0.0978, 0.0615, 0.0600, 0.0366, 0.0388, 0.0402,
        0.0602, 0.0746, 0.0396, 0.0310, 0.0575, 0.0636], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,705][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0055, 0.7235, 0.1179, 0.0490, 0.0295, 0.0138, 0.0030, 0.0035, 0.0033,
        0.0087, 0.0075, 0.0101, 0.0029, 0.0108, 0.0109], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,759][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:41,759][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,760][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,760][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,760][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,761][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,761][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,761][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,761][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,762][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,762][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,762][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,763][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:41,765][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9943e-01, 5.6805e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,768][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0119, 0.9881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,770][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9998e-01, 1.6923e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,774][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,776][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1296, 0.8704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,777][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9923e-01, 7.7201e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,777][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9958e-01, 4.2453e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,777][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4979, 0.5021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,777][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.9978e-01, 2.1826e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,778][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9790, 0.0210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,778][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9407, 0.0593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,778][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1989, 0.8011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:41,779][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([9.9957e-01, 3.9649e-04, 3.5468e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,779][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.0591, 0.2837, 0.6572], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,779][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([1.0000e+00, 1.4392e-06, 3.8548e-07], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,779][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.9960, 0.0015, 0.0025], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,781][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.1198, 0.7627, 0.1175], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,783][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([9.9943e-01, 4.2792e-04, 1.3777e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,785][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([9.9993e-01, 1.9930e-05, 5.2386e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,788][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.0756, 0.8868, 0.0376], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,791][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([9.9978e-01, 7.2192e-05, 1.5197e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,795][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.9804, 0.0151, 0.0045], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,799][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.9729, 0.0210, 0.0060], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,802][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.1172, 0.7011, 0.1817], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:41,804][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9693e-01, 1.7823e-03, 1.7527e-04, 1.1145e-03], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,806][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([3.6082e-04, 1.9722e-01, 6.6613e-01, 1.3629e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,806][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9996e-01, 2.0091e-05, 5.7025e-06, 1.3151e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,807][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9410, 0.0248, 0.0179, 0.0162], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,807][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0019, 0.9674, 0.0170, 0.0137], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,807][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9528, 0.0425, 0.0029, 0.0018], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,807][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9578e-01, 7.0079e-04, 3.1856e-03, 3.2866e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,808][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0037, 0.9897, 0.0031, 0.0035], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,808][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.9542e-01, 1.7039e-03, 2.7609e-03, 1.1610e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,808][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9271, 0.0580, 0.0110, 0.0039], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,809][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7344, 0.2104, 0.0355, 0.0197], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,809][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0087, 0.7756, 0.1592, 0.0565], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:41,810][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([9.9798e-01, 1.1240e-03, 1.1631e-04, 7.0289e-04, 7.3841e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,813][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0799, 0.1756, 0.3031, 0.2492, 0.1922], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,815][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([9.9995e-01, 1.4733e-05, 4.7730e-06, 1.5681e-05, 1.8458e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,818][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.9857, 0.0041, 0.0055, 0.0023, 0.0023], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,822][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.0027, 0.9365, 0.0187, 0.0383, 0.0038], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,824][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.5845e-01, 3.5348e-02, 2.5653e-03, 3.3982e-03, 2.3383e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,826][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.9962e-01, 9.7026e-05, 1.5713e-04, 6.8638e-05, 5.8086e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,829][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([1.7876e-03, 9.7360e-01, 5.5960e-03, 1.8232e-02, 7.8521e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,831][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([9.9895e-01, 5.0653e-04, 4.7828e-04, 3.2213e-05, 3.6789e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,835][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.9415, 0.0459, 0.0089, 0.0026, 0.0011], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,836][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.8426, 0.1209, 0.0158, 0.0120, 0.0088], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,836][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0353, 0.7065, 0.1235, 0.0926, 0.0421], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:41,836][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([9.8694e-01, 7.1221e-03, 9.8268e-04, 4.1693e-03, 4.7762e-04, 3.1028e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,837][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0007, 0.1555, 0.4458, 0.1528, 0.2316, 0.0136], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,837][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([9.9870e-01, 3.5883e-04, 2.0334e-04, 1.9347e-04, 3.9695e-04, 1.4361e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,837][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.7299, 0.0857, 0.0980, 0.0473, 0.0301, 0.0090], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,837][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([7.3088e-05, 9.2591e-01, 2.7999e-02, 3.7495e-02, 8.1788e-03, 3.4061e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,838][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4284, 0.4301, 0.0752, 0.0532, 0.0109, 0.0022], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,838][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([9.9335e-01, 9.6065e-04, 3.6559e-03, 4.8388e-04, 1.4163e-03, 1.3117e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,838][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([1.1143e-04, 9.6850e-01, 1.2908e-02, 1.5765e-02, 2.5899e-03, 1.2298e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,839][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([9.7290e-01, 1.3161e-02, 1.1463e-02, 8.9687e-04, 1.3585e-03, 2.2137e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,842][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.5913, 0.2865, 0.0818, 0.0265, 0.0108, 0.0031], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,845][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2344, 0.5251, 0.1104, 0.0692, 0.0508, 0.0102], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,849][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0046, 0.6603, 0.1430, 0.1179, 0.0619, 0.0123], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:41,851][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([7.4077e-01, 7.8265e-03, 1.0027e-03, 3.6958e-03, 5.3376e-04, 3.8997e-04,
        2.4578e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,855][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0122, 0.1650, 0.3204, 0.2589, 0.1822, 0.0275, 0.0338],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,858][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.9817e-01, 4.6275e-04, 2.0973e-04, 2.4852e-04, 4.9380e-04, 2.8455e-04,
        1.3553e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,862][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4203, 0.1991, 0.1627, 0.1164, 0.0538, 0.0268, 0.0208],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,865][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([6.7749e-05, 9.1404e-01, 3.0216e-02, 4.5324e-02, 8.3506e-03, 1.8020e-03,
        1.9856e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,865][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4615, 0.3980, 0.0566, 0.0643, 0.0137, 0.0047, 0.0012],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,865][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9732e-01, 4.1168e-04, 1.1355e-03, 3.2780e-04, 4.5775e-04, 1.3867e-04,
        2.0930e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,866][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([5.8708e-05, 9.6327e-01, 6.9989e-03, 2.5477e-02, 3.7484e-03, 4.1123e-04,
        3.1763e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,866][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.5354e-01, 2.3431e-02, 1.8289e-02, 1.5834e-03, 2.4308e-03, 5.8352e-04,
        1.4602e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,866][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.4276, 0.3770, 0.1268, 0.0390, 0.0174, 0.0061, 0.0061],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,866][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1743, 0.5896, 0.0941, 0.0744, 0.0500, 0.0132, 0.0044],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,867][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0029, 0.7023, 0.1213, 0.1000, 0.0490, 0.0189, 0.0055],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:41,867][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([8.9459e-01, 5.0835e-03, 5.1291e-04, 1.5545e-03, 3.9056e-04, 1.2249e-04,
        9.2782e-02, 4.9658e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,867][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.3088, 0.1708, 0.2053, 0.1971, 0.0748, 0.0103, 0.0225, 0.0102],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,868][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.9879e-01, 2.7546e-04, 1.3057e-04, 1.9332e-04, 3.5046e-04, 1.4024e-04,
        8.3367e-05, 3.4421e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,869][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([9.8061e-01, 8.3960e-03, 5.1257e-03, 2.7555e-03, 1.1557e-03, 1.0815e-03,
        6.5874e-04, 2.1797e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,870][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([2.1756e-04, 8.9913e-01, 3.0632e-02, 5.4762e-02, 1.4431e-02, 6.5650e-04,
        1.5391e-04, 2.0559e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,872][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([1.1652e-01, 7.4036e-01, 2.2623e-02, 1.0738e-01, 8.4965e-03, 3.2164e-03,
        1.3580e-03, 4.2025e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,874][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([9.9996e-01, 7.5111e-06, 2.0134e-05, 4.7362e-06, 6.1980e-06, 1.6242e-06,
        3.2555e-06, 1.5230e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,876][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([5.0319e-05, 9.6557e-01, 3.7154e-03, 2.8669e-02, 1.8253e-03, 1.4434e-04,
        2.4593e-05, 2.8233e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,878][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([9.8861e-01, 5.3408e-03, 4.8789e-03, 4.0601e-04, 6.6392e-04, 7.6621e-05,
        1.9014e-05, 1.0830e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,881][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([7.8678e-01, 1.6009e-01, 3.4897e-02, 1.0920e-02, 5.1600e-03, 1.1683e-03,
        8.7885e-04, 1.0216e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,885][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.6080, 0.2825, 0.0391, 0.0373, 0.0240, 0.0067, 0.0015, 0.0010],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,887][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([6.0935e-04, 7.8047e-01, 1.1652e-01, 5.7347e-02, 3.2017e-02, 9.5181e-03,
        1.7228e-03, 1.7972e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:41,890][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([9.2328e-01, 1.8195e-03, 1.3628e-04, 7.4857e-04, 1.0589e-04, 4.6742e-05,
        7.1726e-02, 1.9988e-03, 1.4070e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,893][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0768, 0.1616, 0.3063, 0.2505, 0.1214, 0.0143, 0.0269, 0.0115, 0.0306],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,894][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.9994e-01, 1.1423e-05, 5.2170e-06, 1.1990e-05, 1.3255e-05, 8.0584e-06,
        6.0956e-06, 1.3170e-06, 4.1175e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,895][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([9.1565e-01, 3.7403e-02, 1.7102e-02, 1.5880e-02, 5.2605e-03, 3.7629e-03,
        2.8849e-03, 8.8385e-04, 1.1724e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,895][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([2.0806e-04, 9.3482e-01, 1.5241e-02, 4.5903e-02, 3.2061e-03, 3.8826e-04,
        8.6013e-05, 3.3228e-05, 1.1230e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,895][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([4.2447e-01, 4.8372e-01, 2.5527e-02, 5.8334e-02, 5.0597e-03, 1.7309e-03,
        7.8524e-04, 4.8617e-05, 3.1730e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,896][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([9.9985e-01, 1.6228e-05, 6.8424e-05, 1.3916e-05, 1.9618e-05, 4.4406e-06,
        9.3888e-06, 3.7670e-06, 1.1164e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,896][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([2.1424e-04, 9.6938e-01, 4.8707e-03, 2.3655e-02, 1.6909e-03, 1.1231e-04,
        1.9357e-05, 6.6944e-06, 5.3019e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,896][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.9344e-01, 2.4227e-03, 3.5048e-03, 2.0254e-04, 3.8041e-04, 4.0609e-05,
        9.8233e-06, 4.5907e-07, 1.1650e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,897][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([9.1959e-01, 6.1178e-02, 1.2538e-02, 4.3929e-03, 1.3067e-03, 4.4408e-04,
        3.7321e-04, 3.8223e-05, 1.3620e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,897][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([6.3771e-01, 2.6396e-01, 3.3836e-02, 3.6169e-02, 1.8566e-02, 5.0740e-03,
        1.4673e-03, 5.9195e-04, 2.6257e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,897][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0020, 0.7541, 0.0785, 0.1064, 0.0366, 0.0084, 0.0028, 0.0039, 0.0072],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:41,898][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([8.0629e-01, 7.1428e-03, 8.6894e-04, 2.3791e-03, 4.0255e-04, 1.7802e-04,
        1.7439e-01, 5.8259e-03, 3.7882e-04, 2.1384e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,901][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0040, 0.2220, 0.4594, 0.0965, 0.1426, 0.0099, 0.0115, 0.0075, 0.0179,
        0.0288], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,903][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9919e-01, 1.6348e-04, 8.7067e-05, 1.0548e-04, 2.2494e-04, 7.8602e-05,
        5.9751e-05, 9.5211e-06, 4.1821e-05, 3.5445e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,906][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5016, 0.1565, 0.1185, 0.0855, 0.0474, 0.0261, 0.0159, 0.0088, 0.0138,
        0.0259], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,908][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([5.4463e-05, 9.5807e-01, 2.0271e-02, 1.7500e-02, 2.6928e-03, 4.6542e-04,
        7.1398e-05, 4.4374e-05, 1.6539e-04, 6.6136e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,911][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.2056e-01, 6.5050e-01, 7.7602e-02, 3.7081e-02, 7.7267e-03, 2.4518e-03,
        6.9423e-04, 7.1774e-05, 5.5886e-04, 2.7495e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,913][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9029e-01, 1.0442e-03, 5.0841e-03, 4.6886e-04, 9.4237e-04, 1.3546e-04,
        2.2678e-04, 2.7247e-04, 2.2784e-04, 1.3075e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,915][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([8.9941e-05, 9.8344e-01, 7.2135e-03, 7.9680e-03, 8.7716e-04, 1.1762e-04,
        1.5153e-05, 1.3212e-05, 7.1628e-05, 1.9690e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,918][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.4928e-01, 2.2195e-02, 2.4987e-02, 1.0797e-03, 1.9709e-03, 2.9502e-04,
        6.1114e-05, 1.3566e-05, 2.0888e-05, 9.2374e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,922][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4244, 0.3908, 0.1232, 0.0346, 0.0143, 0.0044, 0.0037, 0.0005, 0.0010,
        0.0031], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,924][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1908, 0.5406, 0.1166, 0.0630, 0.0486, 0.0115, 0.0035, 0.0014, 0.0040,
        0.0201], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,924][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0008, 0.7153, 0.1802, 0.0489, 0.0339, 0.0068, 0.0017, 0.0029, 0.0033,
        0.0061], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:41,924][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([8.6978e-01, 6.5233e-03, 6.3795e-04, 2.3573e-03, 2.8318e-04, 1.5704e-04,
        1.1282e-01, 3.2929e-03, 3.5586e-04, 1.5634e-03, 2.2315e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,925][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0097, 0.1947, 0.4349, 0.0888, 0.1666, 0.0142, 0.0140, 0.0090, 0.0203,
        0.0252, 0.0225], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,925][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9984e-01, 3.3239e-05, 1.7318e-05, 1.8831e-05, 4.5882e-05, 1.3362e-05,
        1.3924e-05, 1.6965e-06, 7.4135e-06, 8.5172e-06, 4.3061e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,926][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6753, 0.0782, 0.0632, 0.0626, 0.0256, 0.0187, 0.0127, 0.0073, 0.0102,
        0.0221, 0.0242], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,926][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([7.4586e-05, 9.4896e-01, 2.3750e-02, 1.9656e-02, 3.6530e-03, 6.3957e-04,
        1.0267e-04, 4.9527e-05, 2.0599e-04, 1.2033e-03, 1.7047e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,926][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.0671e-01, 5.9853e-01, 5.0145e-02, 2.8847e-02, 6.0738e-03, 2.1497e-03,
        8.5260e-04, 6.1298e-05, 4.5715e-04, 3.3793e-03, 2.8002e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,927][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9553e-01, 6.0368e-04, 1.7822e-03, 2.1384e-04, 4.2506e-04, 1.0654e-04,
        1.0995e-04, 1.0643e-04, 1.1453e-04, 6.4447e-04, 3.6458e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,927][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([2.1192e-04, 9.8445e-01, 5.4262e-03, 7.7374e-03, 1.1502e-03, 1.5888e-04,
        2.8525e-05, 1.6263e-05, 8.8861e-05, 3.0590e-04, 4.2933e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,928][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.8437e-01, 6.6705e-03, 7.4129e-03, 4.3993e-04, 8.4109e-04, 1.3486e-04,
        3.4984e-05, 4.4931e-06, 6.8239e-06, 4.5793e-05, 3.6822e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,929][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([7.2440e-01, 2.0577e-01, 3.3523e-02, 1.9510e-02, 5.5523e-03, 2.7602e-03,
        2.4859e-03, 2.8360e-04, 5.8284e-04, 2.3551e-03, 2.7767e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,933][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2797, 0.4791, 0.0866, 0.0638, 0.0344, 0.0107, 0.0040, 0.0013, 0.0031,
        0.0199, 0.0173], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,936][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0032, 0.7538, 0.1230, 0.0571, 0.0292, 0.0095, 0.0029, 0.0032, 0.0028,
        0.0076, 0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:41,938][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([7.3809e-01, 6.2005e-03, 6.4367e-04, 2.4271e-03, 3.5607e-04, 2.5256e-04,
        2.3420e-01, 1.1047e-02, 4.9763e-04, 1.7095e-03, 2.4979e-03, 2.0758e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,942][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0754, 0.1408, 0.2410, 0.1318, 0.2198, 0.0263, 0.0330, 0.0095, 0.0265,
        0.0452, 0.0349, 0.0158], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,944][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([9.9726e-01, 3.8404e-04, 2.7502e-04, 2.6135e-04, 5.4735e-04, 2.7715e-04,
        1.4130e-04, 3.8242e-05, 9.3629e-05, 7.4174e-05, 3.7181e-05, 6.0655e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,947][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.7424, 0.0505, 0.0590, 0.0555, 0.0321, 0.0132, 0.0081, 0.0075, 0.0065,
        0.0096, 0.0074, 0.0080], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,950][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([1.5893e-04, 8.8142e-01, 1.8397e-02, 7.7459e-02, 9.2260e-03, 1.9363e-03,
        4.9856e-04, 2.6742e-04, 6.4744e-04, 2.9153e-03, 5.7468e-03, 1.3307e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,952][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([1.4776e-01, 6.0838e-01, 7.4898e-02, 1.1196e-01, 1.9271e-02, 6.2677e-03,
        3.2068e-03, 3.9063e-04, 2.6124e-03, 1.0039e-02, 9.8855e-03, 5.3316e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,954][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([9.9440e-01, 5.2263e-04, 1.8558e-03, 4.4568e-04, 7.0498e-04, 1.1086e-04,
        2.2896e-04, 1.7655e-04, 2.0352e-04, 6.4647e-04, 4.1135e-04, 2.9153e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,956][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([1.1597e-04, 9.4117e-01, 5.8870e-03, 4.2397e-02, 4.5145e-03, 6.2870e-04,
        1.1731e-04, 9.7852e-05, 3.5702e-04, 1.6223e-03, 2.5945e-03, 4.9578e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,956][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([9.7757e-01, 1.0684e-02, 8.0098e-03, 1.2247e-03, 1.6027e-03, 3.3353e-04,
        8.7917e-05, 2.7063e-05, 3.4886e-05, 1.0754e-04, 1.0992e-04, 2.0567e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,956][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([7.1849e-01, 1.7241e-01, 5.0819e-02, 2.8160e-02, 1.3476e-02, 2.5660e-03,
        2.7306e-03, 5.0357e-04, 9.7941e-04, 2.9775e-03, 3.3739e-03, 3.5074e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,957][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.3548, 0.3955, 0.0650, 0.0710, 0.0448, 0.0148, 0.0048, 0.0023, 0.0064,
        0.0191, 0.0128, 0.0087], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,957][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0092, 0.6831, 0.0757, 0.1015, 0.0376, 0.0159, 0.0066, 0.0119, 0.0112,
        0.0138, 0.0114, 0.0221], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:41,958][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([7.9264e-01, 3.2326e-03, 5.3577e-04, 1.8272e-03, 2.5385e-04, 7.5071e-05,
        1.8899e-01, 4.2820e-03, 3.1242e-04, 1.4337e-03, 2.2630e-03, 1.2937e-03,
        2.8616e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,958][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.0651, 0.1229, 0.1846, 0.1467, 0.1443, 0.0297, 0.0248, 0.0297, 0.0454,
        0.0679, 0.0510, 0.0218, 0.0662], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,958][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([9.9869e-01, 1.4921e-04, 6.5124e-05, 1.3947e-04, 2.1741e-04, 8.3605e-05,
        7.5229e-05, 2.1872e-05, 5.6314e-05, 5.2055e-05, 2.9299e-05, 2.9249e-04,
        1.3073e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,960][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.8686, 0.0235, 0.0269, 0.0271, 0.0105, 0.0067, 0.0055, 0.0048, 0.0029,
        0.0064, 0.0054, 0.0058, 0.0058], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,962][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([4.2287e-04, 8.9762e-01, 2.2766e-02, 5.8927e-02, 7.3165e-03, 1.6376e-03,
        2.5819e-04, 1.0660e-04, 3.2489e-04, 3.7105e-03, 6.0757e-03, 5.7879e-04,
        2.5499e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,964][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([5.1987e-01, 3.3364e-01, 3.2870e-02, 7.4846e-02, 6.8088e-03, 4.1815e-03,
        2.3419e-03, 3.1932e-04, 1.3796e-03, 8.8479e-03, 9.0357e-03, 5.1350e-03,
        7.2299e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,966][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([9.9548e-01, 5.3101e-04, 7.0301e-04, 2.9940e-04, 2.9421e-04, 1.3026e-04,
        2.5851e-04, 2.3142e-04, 1.7765e-04, 8.4475e-04, 3.2319e-04, 2.0720e-04,
        5.1720e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,969][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([1.6095e-04, 9.2539e-01, 8.7229e-03, 5.0891e-02, 4.3254e-03, 8.2988e-04,
        1.1124e-04, 1.5536e-04, 5.3191e-04, 2.7564e-03, 4.8397e-03, 1.1698e-03,
        1.1335e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,971][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([9.9330e-01, 3.6879e-03, 1.9216e-03, 3.1930e-04, 3.0644e-04, 1.3301e-04,
        4.3334e-05, 8.8371e-06, 1.0310e-05, 6.2561e-05, 4.9513e-05, 1.2049e-04,
        3.4717e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,973][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([7.9227e-01, 1.4423e-01, 2.9301e-02, 1.3934e-02, 4.7429e-03, 2.7481e-03,
        2.4147e-03, 5.0611e-04, 1.0723e-03, 2.4511e-03, 2.3673e-03, 3.3303e-03,
        6.3340e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,976][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.5073, 0.2890, 0.0391, 0.0548, 0.0298, 0.0130, 0.0046, 0.0022, 0.0073,
        0.0225, 0.0152, 0.0101, 0.0051], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,980][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0070, 0.5737, 0.0917, 0.1225, 0.0481, 0.0237, 0.0074, 0.0135, 0.0114,
        0.0243, 0.0273, 0.0416, 0.0078], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:41,983][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([8.2821e-01, 5.5909e-03, 4.0994e-04, 2.1394e-03, 1.3001e-04, 1.2320e-04,
        1.4906e-01, 4.8373e-03, 3.3220e-04, 1.5044e-03, 1.8762e-03, 1.9727e-03,
        1.3312e-03, 2.4785e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,985][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0044, 0.1201, 0.3558, 0.0923, 0.1863, 0.0193, 0.0312, 0.0072, 0.0115,
        0.0392, 0.0264, 0.0253, 0.0697, 0.0112], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,985][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([9.9920e-01, 1.4502e-04, 1.0075e-04, 7.3868e-05, 1.2905e-04, 4.4572e-05,
        3.3539e-05, 8.3321e-06, 2.4229e-05, 2.5993e-05, 1.4432e-05, 1.2207e-04,
        6.1507e-05, 1.6370e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,986][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.3771, 0.1656, 0.1985, 0.0859, 0.0476, 0.0215, 0.0132, 0.0090, 0.0129,
        0.0192, 0.0143, 0.0086, 0.0111, 0.0155], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,986][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([2.9614e-05, 9.6604e-01, 1.0181e-02, 2.0257e-02, 1.3127e-03, 1.9064e-04,
        3.0699e-05, 1.4912e-05, 5.3107e-05, 4.5801e-04, 7.5952e-04, 8.5570e-05,
        2.6146e-05, 5.5950e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,986][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([8.6138e-02, 8.2152e-01, 3.5196e-02, 4.2068e-02, 5.9553e-03, 1.4113e-03,
        3.7691e-04, 3.5921e-05, 2.8265e-04, 1.9400e-03, 1.9263e-03, 1.6163e-03,
        2.1293e-04, 1.3160e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,987][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([9.9601e-01, 3.5274e-04, 1.1905e-03, 1.0742e-04, 4.3667e-04, 2.5780e-05,
        4.3156e-05, 5.6966e-05, 1.3481e-04, 3.3230e-04, 1.8227e-04, 1.0555e-04,
        9.4260e-04, 8.0498e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,987][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([5.4659e-05, 9.9274e-01, 1.5553e-03, 4.8247e-03, 4.7154e-04, 4.4577e-05,
        3.6373e-06, 1.1180e-06, 6.7275e-06, 7.3718e-05, 8.8292e-05, 3.8002e-05,
        3.8327e-06, 9.3713e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,987][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([9.0220e-01, 6.1784e-02, 2.8283e-02, 2.6513e-03, 2.8115e-03, 7.6899e-04,
        1.3927e-04, 2.8002e-05, 2.7310e-05, 1.9213e-04, 1.4187e-04, 3.4253e-04,
        2.1660e-04, 4.1340e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,988][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([5.2143e-01, 3.2987e-01, 8.3801e-02, 2.8058e-02, 1.4342e-02, 3.2189e-03,
        2.9823e-03, 3.2358e-04, 7.7872e-04, 3.2598e-03, 2.9787e-03, 3.0892e-03,
        1.3158e-03, 4.5510e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,988][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([1.2177e-01, 6.3412e-01, 8.6315e-02, 6.1678e-02, 3.7075e-02, 8.3237e-03,
        2.6781e-03, 6.2801e-04, 2.3627e-03, 1.3219e-02, 9.6745e-03, 5.5126e-03,
        4.5318e-03, 1.2114e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,990][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0023, 0.7960, 0.0718, 0.0589, 0.0243, 0.0055, 0.0018, 0.0039, 0.0041,
        0.0062, 0.0062, 0.0101, 0.0020, 0.0069], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:41,992][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.8228e-01, 4.1638e-03, 3.8591e-04, 1.4196e-03, 1.5083e-04, 9.5972e-05,
        1.0054e-01, 2.9811e-03, 1.9089e-04, 9.4163e-04, 1.3760e-03, 1.3160e-03,
        1.5598e-03, 1.9737e-03, 6.2299e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,995][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1147, 0.1190, 0.3599, 0.0690, 0.1526, 0.0145, 0.0150, 0.0085, 0.0145,
        0.0239, 0.0139, 0.0199, 0.0530, 0.0057, 0.0158], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:41,997][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9953e-01, 6.8047e-05, 4.1625e-05, 3.5556e-05, 8.9104e-05, 1.7356e-05,
        2.0497e-05, 2.5210e-06, 1.4121e-05, 1.6021e-05, 9.5452e-06, 7.2412e-05,
        6.4388e-05, 9.4240e-06, 7.6049e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,001][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6989, 0.0611, 0.0365, 0.0561, 0.0197, 0.0206, 0.0133, 0.0074, 0.0070,
        0.0183, 0.0160, 0.0123, 0.0103, 0.0114, 0.0112], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,004][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.5621e-04, 9.5463e-01, 1.2759e-02, 1.7036e-02, 2.8709e-03, 6.8099e-04,
        1.1286e-04, 2.9994e-05, 1.2304e-04, 1.6755e-03, 2.7936e-03, 4.8020e-04,
        1.6032e-04, 2.6400e-03, 3.8510e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,006][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.0171e-01, 7.0790e-01, 3.0642e-02, 3.1832e-02, 5.3012e-03, 1.9336e-03,
        8.9267e-04, 3.8840e-05, 3.3542e-04, 3.8270e-03, 3.8506e-03, 1.5791e-03,
        4.1578e-04, 4.3314e-03, 5.4075e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,008][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9806e-01, 1.9356e-04, 5.3647e-04, 6.7317e-05, 1.7700e-04, 4.2843e-05,
        5.1961e-05, 3.5444e-05, 3.5839e-05, 1.9458e-04, 8.9054e-05, 8.5005e-05,
        2.3522e-04, 5.3418e-05, 1.4282e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,010][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.8287e-04, 9.8696e-01, 1.7551e-03, 8.3142e-03, 6.1471e-04, 1.2384e-04,
        1.8497e-05, 5.9008e-06, 3.6545e-05, 2.5467e-04, 3.8942e-04, 1.7759e-04,
        1.5966e-05, 7.1353e-04, 4.3928e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,013][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.8669e-01, 7.0895e-03, 4.5668e-03, 4.3796e-04, 6.7024e-04, 1.4800e-04,
        4.0075e-05, 3.5100e-06, 6.0927e-06, 5.1571e-05, 3.8487e-05, 7.9611e-05,
        5.8407e-05, 8.7513e-05, 3.6464e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,015][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.5527e-01, 1.7443e-01, 2.9550e-02, 1.7988e-02, 5.2333e-03, 2.1689e-03,
        2.1552e-03, 2.7158e-04, 4.4039e-04, 2.1013e-03, 2.6304e-03, 2.3760e-03,
        7.4882e-04, 2.9067e-03, 1.7312e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,015][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3999, 0.3939, 0.0497, 0.0449, 0.0266, 0.0088, 0.0033, 0.0011, 0.0029,
        0.0192, 0.0142, 0.0068, 0.0050, 0.0119, 0.0117], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,016][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0055, 0.7235, 0.1179, 0.0490, 0.0295, 0.0138, 0.0030, 0.0035, 0.0033,
        0.0087, 0.0075, 0.0101, 0.0029, 0.0108, 0.0109], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,017][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:42,018][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[5725],
        [  65],
        [2043],
        [   7],
        [ 100],
        [  14],
        [  20],
        [   6],
        [  21],
        [   1],
        [   1],
        [   6],
        [  35],
        [  17],
        [   4]], device='cuda:0')
[2024-07-24 10:20:42,019][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7106],
        [   17],
        [11339],
        [    2],
        [  174],
        [    1],
        [    1],
        [    1],
        [    2],
        [    1],
        [    1],
        [    1],
        [   72],
        [    3],
        [    1]], device='cuda:0')
[2024-07-24 10:20:42,020][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 9352],
        [ 9601],
        [ 9737],
        [ 9783],
        [10345],
        [10205],
        [11725],
        [10960],
        [11427],
        [11592],
        [11821],
        [11635],
        [13284],
        [16052],
        [15120]], device='cuda:0')
[2024-07-24 10:20:42,023][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[24163],
        [12774],
        [18860],
        [19157],
        [18624],
        [18567],
        [19380],
        [19458],
        [19276],
        [19508],
        [19893],
        [20200],
        [18853],
        [19433],
        [19116]], device='cuda:0')
[2024-07-24 10:20:42,024][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[3318],
        [3310],
        [3316],
        [3314],
        [3313],
        [3313],
        [3302],
        [3301],
        [3296],
        [3302],
        [3246],
        [3180],
        [3169],
        [3128],
        [3220]], device='cuda:0')
[2024-07-24 10:20:42,026][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26825],
        [27511],
        [31281],
        [29515],
        [32440],
        [33319],
        [34455],
        [33668],
        [32549],
        [36808],
        [37440],
        [36505],
        [37292],
        [36775],
        [39313]], device='cuda:0')
[2024-07-24 10:20:42,029][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[21680],
        [21126],
        [20116],
        [21117],
        [21187],
        [21018],
        [21051],
        [21011],
        [21268],
        [21063],
        [21022],
        [21397],
        [21258],
        [21201],
        [21161]], device='cuda:0')
[2024-07-24 10:20:42,031][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[18067],
        [18061],
        [18061],
        [18345],
        [18351],
        [21261],
        [21533],
        [23139],
        [22163],
        [21746],
        [21713],
        [21964],
        [21112],
        [22491],
        [22086]], device='cuda:0')
[2024-07-24 10:20:42,034][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[8038],
        [4387],
        [2462],
        [3003],
        [2231],
        [2435],
        [2521],
        [2699],
        [3528],
        [3459],
        [3432],
        [3647],
        [3223],
        [2910],
        [2762]], device='cuda:0')
[2024-07-24 10:20:42,036][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31062],
        [28416],
        [17458],
        [17296],
        [22628],
        [21837],
        [24517],
        [24714],
        [23488],
        [23777],
        [24875],
        [28529],
        [29125],
        [26393],
        [26316]], device='cuda:0')
[2024-07-24 10:20:42,039][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22617],
        [22666],
        [22826],
        [27783],
        [23881],
        [41827],
        [47004],
        [33562],
        [29579],
        [46485],
        [34906],
        [40594],
        [29566],
        [48752],
        [30611]], device='cuda:0')
[2024-07-24 10:20:42,042][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24643],
        [13166],
        [19505],
        [14688],
        [10746],
        [ 8941],
        [ 8032],
        [ 9005],
        [14579],
        [11007],
        [11064],
        [11674],
        [11978],
        [11545],
        [11679]], device='cuda:0')
[2024-07-24 10:20:42,044][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[48852],
        [39792],
        [30318],
        [24292],
        [24446],
        [20078],
        [20555],
        [21270],
        [24058],
        [20872],
        [21678],
        [22562],
        [22635],
        [20905],
        [22009]], device='cuda:0')
[2024-07-24 10:20:42,047][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35440],
        [43426],
        [49584],
        [48740],
        [47118],
        [47035],
        [46542],
        [47352],
        [44474],
        [48990],
        [47506],
        [43693],
        [42985],
        [45279],
        [47222]], device='cuda:0')
[2024-07-24 10:20:42,049][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5903],
        [ 7480],
        [ 1199],
        [ 5486],
        [ 5858],
        [12815],
        [16711],
        [19847],
        [14830],
        [ 1863],
        [ 4057],
        [11846],
        [ 3999],
        [ 6169],
        [ 5678]], device='cuda:0')
[2024-07-24 10:20:42,050][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[32368],
        [32324],
        [32325],
        [31975],
        [32117],
        [30269],
        [ 5987],
        [14469],
        [18244],
        [ 7758],
        [11759],
        [ 5663],
        [ 7085],
        [ 8589],
        [12738]], device='cuda:0')
[2024-07-24 10:20:42,051][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[5578],
        [1978],
        [2453],
        [2793],
        [2322],
        [2212],
        [2264],
        [2635],
        [2479],
        [2208],
        [2149],
        [2143],
        [2454],
        [2328],
        [2434]], device='cuda:0')
[2024-07-24 10:20:42,052][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[30071],
        [30071],
        [30071],
        [30066],
        [30067],
        [30035],
        [30027],
        [30039],
        [30066],
        [30059],
        [30061],
        [30007],
        [30064],
        [30069],
        [30073]], device='cuda:0')
[2024-07-24 10:20:42,053][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[30398],
        [30111],
        [30050],
        [23151],
        [28891],
        [ 7113],
        [ 4437],
        [28283],
        [19838],
        [ 5168],
        [ 7037],
        [ 7668],
        [14811],
        [ 4496],
        [ 7475]], device='cuda:0')
[2024-07-24 10:20:42,054][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[40320],
        [45657],
        [46888],
        [45565],
        [45942],
        [46043],
        [46170],
        [46323],
        [45994],
        [45677],
        [45779],
        [46512],
        [46325],
        [45591],
        [45681]], device='cuda:0')
[2024-07-24 10:20:42,055][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23785],
        [23774],
        [23774],
        [23523],
        [23504],
        [34940],
        [34455],
        [38770],
        [35532],
        [37764],
        [37032],
        [38417],
        [33358],
        [38867],
        [38118]], device='cuda:0')
[2024-07-24 10:20:42,058][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24519],
        [24526],
        [24514],
        [24032],
        [24493],
        [23750],
        [24285],
        [24517],
        [24508],
        [23542],
        [24143],
        [24078],
        [24285],
        [24158],
        [24391]], device='cuda:0')
[2024-07-24 10:20:42,059][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[17133],
        [23876],
        [22383],
        [22332],
        [22387],
        [22288],
        [22450],
        [22459],
        [22422],
        [22305],
        [22344],
        [22620],
        [22644],
        [22340],
        [22394]], device='cuda:0')
[2024-07-24 10:20:42,061][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20089],
        [20101],
        [20096],
        [20362],
        [20143],
        [21606],
        [22962],
        [20675],
        [20440],
        [23344],
        [20930],
        [21230],
        [20423],
        [27028],
        [20786]], device='cuda:0')
[2024-07-24 10:20:42,064][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26868],
        [27334],
        [27498],
        [29304],
        [28735],
        [33160],
        [32252],
        [32995],
        [29546],
        [32198],
        [33321],
        [33403],
        [32658],
        [32339],
        [32786]], device='cuda:0')
[2024-07-24 10:20:42,066][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21598],
        [20455],
        [21747],
        [14546],
        [18233],
        [10140],
        [ 9525],
        [11719],
        [11963],
        [ 9971],
        [ 9750],
        [ 9822],
        [10287],
        [ 9275],
        [ 9831]], device='cuda:0')
[2024-07-24 10:20:42,069][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25655],
        [37235],
        [29848],
        [31464],
        [32854],
        [32171],
        [33061],
        [33049],
        [34536],
        [30323],
        [32909],
        [34768],
        [34408],
        [34918],
        [33333]], device='cuda:0')
[2024-07-24 10:20:42,071][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[15965],
        [ 7107],
        [ 7332],
        [ 9284],
        [ 8436],
        [ 9294],
        [12068],
        [ 7491],
        [ 9123],
        [11144],
        [10585],
        [11359],
        [10872],
        [10339],
        [11112]], device='cuda:0')
[2024-07-24 10:20:42,074][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39128],
        [37027],
        [25133],
        [44570],
        [28633],
        [45029],
        [45252],
        [24529],
        [33026],
        [47785],
        [47418],
        [38854],
        [36777],
        [45109],
        [43053]], device='cuda:0')
[2024-07-24 10:20:42,076][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539],
        [19539]], device='cuda:0')
[2024-07-24 10:20:42,112][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:42,116][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,116][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,117][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,117][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,117][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,118][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,118][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,118][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,119][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,119][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,119][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,119][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,120][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9996e-01, 3.9691e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,120][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8741, 0.1259], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,120][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9998e-01, 2.0708e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,121][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9995e-01, 4.8619e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,121][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([9.9965e-01, 3.4706e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,121][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9949e-01, 5.1128e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,122][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0357, 0.9643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,122][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8888, 0.1112], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,122][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9932, 0.0068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,131][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0134, 0.9866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,131][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4685, 0.5315], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,132][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9986, 0.0014], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,132][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([9.9987e-01, 4.7295e-05, 7.9039e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,132][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.7491, 0.0333, 0.2176], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,133][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([9.9992e-01, 1.9684e-05, 5.6835e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,133][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([9.9985e-01, 1.4781e-04, 6.2769e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,133][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([9.9960e-01, 2.0885e-04, 1.8629e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,134][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([9.9952e-01, 1.7557e-04, 3.0154e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,137][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.0179, 0.2850, 0.6972], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,139][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.9111, 0.0378, 0.0511], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,143][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.9897, 0.0046, 0.0057], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,147][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.0611, 0.4091, 0.5298], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,151][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.4452, 0.5016, 0.0532], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,155][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.8387, 0.0740, 0.0873], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,157][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9937e-01, 2.4241e-04, 2.3759e-04, 1.4639e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,159][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4126, 0.1424, 0.3711, 0.0739], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,160][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9962e-01, 1.7450e-04, 1.7806e-04, 3.0492e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,160][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9446e-01, 5.3536e-03, 1.0051e-05, 1.7912e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,160][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([9.9590e-01, 1.2246e-03, 2.2766e-03, 6.0286e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,161][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9781e-01, 1.1429e-03, 8.5886e-04, 1.8810e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,161][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0007, 0.2226, 0.6785, 0.0981], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,161][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1736, 0.3850, 0.3611, 0.0803], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,161][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9617, 0.0136, 0.0196, 0.0052], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,162][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0009, 0.2995, 0.1128, 0.5868], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,162][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0147, 0.9620, 0.0037, 0.0196], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,162][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9802, 0.0012, 0.0125, 0.0061], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,163][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([9.9931e-01, 1.8343e-04, 2.1396e-04, 9.3957e-05, 1.9699e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,163][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.5130, 0.0598, 0.2706, 0.0475, 0.1091], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,164][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([9.9990e-01, 3.3925e-05, 4.3426e-05, 9.4431e-06, 1.7516e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,165][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([9.8849e-01, 9.2608e-03, 3.2142e-05, 2.1997e-03, 2.1782e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,167][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([9.9814e-01, 6.7027e-04, 5.4218e-04, 1.7973e-04, 4.7149e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,169][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([9.9838e-01, 7.0695e-04, 6.2575e-04, 1.3240e-04, 1.5443e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,173][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0033, 0.1442, 0.3685, 0.1205, 0.3634], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,176][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.4721, 0.2382, 0.1629, 0.0866, 0.0403], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,180][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.9524, 0.0225, 0.0151, 0.0064, 0.0035], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,184][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0023, 0.1427, 0.1443, 0.4671, 0.2436], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,187][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([0.0109, 0.8704, 0.0057, 0.1091, 0.0039], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,189][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.8412, 0.0260, 0.0222, 0.0498, 0.0607], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,189][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.9558e-01, 1.4538e-03, 1.1295e-03, 6.5508e-04, 1.0529e-03, 1.3339e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,189][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.3398, 0.1126, 0.3512, 0.0488, 0.1226, 0.0250], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,190][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([9.9822e-01, 7.3109e-04, 7.3205e-04, 8.7863e-05, 2.0413e-04, 2.7962e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,190][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([8.5544e-01, 1.3008e-01, 7.5675e-04, 1.3027e-02, 6.5735e-04, 4.4648e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,190][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([9.8838e-01, 2.4224e-03, 5.0770e-03, 1.3725e-03, 2.0659e-03, 6.8592e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,191][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.9152e-01, 3.8594e-03, 2.7807e-03, 5.8851e-04, 7.8306e-04, 4.6561e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,191][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([2.0028e-04, 1.1984e-01, 4.3974e-01, 5.7845e-02, 3.7173e-01, 1.0646e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,191][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0440, 0.2517, 0.3855, 0.1779, 0.1218, 0.0191], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,192][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.7968, 0.0721, 0.0967, 0.0150, 0.0162, 0.0032], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,192][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0009, 0.0954, 0.0859, 0.2406, 0.3115, 0.2655], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,193][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([4.5611e-04, 8.8189e-01, 1.5259e-02, 9.2698e-02, 9.2579e-03, 4.4030e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,195][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.7984, 0.0215, 0.0232, 0.0276, 0.1055, 0.0238], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,197][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9096e-01, 3.2918e-03, 2.5010e-03, 1.1289e-03, 1.8063e-03, 2.4988e-04,
        6.4743e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,200][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4207, 0.1784, 0.2254, 0.0602, 0.0676, 0.0335, 0.0142],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,203][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.9209e-01, 2.7697e-03, 3.5456e-03, 4.0256e-04, 9.9539e-04, 1.3831e-04,
        5.4118e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,205][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.8775e-01, 9.5988e-02, 1.8902e-04, 1.5404e-02, 4.7027e-04, 1.3597e-04,
        6.1516e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,207][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.8575e-01, 3.3019e-03, 5.1086e-03, 1.8404e-03, 2.2290e-03, 9.1507e-04,
        8.5815e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,209][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.8536e-01, 6.7611e-03, 4.5300e-03, 1.0950e-03, 1.1476e-03, 7.2108e-04,
        3.8095e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,212][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.3661e-04, 1.7445e-01, 4.7466e-01, 5.3448e-02, 2.8265e-01, 9.8959e-03,
        4.6666e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,216][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0356, 0.2666, 0.3184, 0.2174, 0.1067, 0.0489, 0.0063],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,218][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([7.3049e-01, 1.0222e-01, 1.2672e-01, 2.0920e-02, 1.5935e-02, 3.2712e-03,
        4.4302e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,218][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0010, 0.1056, 0.0555, 0.2470, 0.1614, 0.3476, 0.0818],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,218][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.8244e-04, 8.6210e-01, 7.1768e-03, 1.1919e-01, 9.5040e-03, 1.6342e-03,
        1.1098e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,219][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.7107, 0.0211, 0.0404, 0.0225, 0.1548, 0.0337, 0.0167],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,219][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.9883e-01, 2.2219e-04, 3.3940e-04, 1.9734e-04, 3.6979e-04, 2.9364e-05,
        1.2745e-05, 2.7394e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,219][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.5494, 0.0304, 0.3725, 0.0071, 0.0339, 0.0020, 0.0019, 0.0028],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,220][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([9.9563e-01, 1.2101e-03, 2.2248e-03, 2.8908e-04, 5.6851e-04, 6.0211e-05,
        1.7223e-05, 5.8561e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,220][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([5.8219e-01, 3.2697e-01, 5.7428e-04, 8.8603e-02, 1.4312e-03, 1.2645e-04,
        1.0513e-04, 1.6077e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,220][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([9.9974e-01, 7.7384e-05, 1.0631e-04, 3.0085e-05, 1.7439e-05, 9.0081e-06,
        1.7840e-05, 4.8767e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,221][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([9.9912e-01, 4.8718e-04, 2.1714e-04, 5.7732e-05, 6.9679e-05, 2.2784e-05,
        1.2796e-05, 7.9058e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,222][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0039, 0.1649, 0.5046, 0.0644, 0.2028, 0.0156, 0.0053, 0.0383],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,225][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0214, 0.4788, 0.2244, 0.1696, 0.0860, 0.0152, 0.0028, 0.0018],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,227][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([7.0031e-01, 9.6963e-02, 1.6015e-01, 1.0367e-02, 2.8506e-02, 2.5889e-03,
        4.9363e-04, 6.2073e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,231][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0011, 0.1627, 0.0398, 0.0873, 0.0524, 0.0736, 0.0279, 0.5551],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,233][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([7.8667e-04, 8.6218e-01, 2.0017e-03, 1.2779e-01, 6.8010e-03, 3.9696e-04,
        4.1518e-05, 8.6014e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,236][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.4568, 0.0338, 0.0361, 0.0545, 0.1700, 0.0710, 0.0581, 0.1197],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,238][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([9.9974e-01, 6.4508e-05, 6.5634e-05, 5.2676e-05, 6.3794e-05, 5.3310e-06,
        1.9756e-06, 2.7360e-07, 1.9545e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,242][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.4913, 0.0426, 0.3421, 0.0180, 0.0708, 0.0078, 0.0073, 0.0112, 0.0089],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,244][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.9978e-01, 6.0688e-05, 1.0770e-04, 1.5347e-05, 3.3352e-05, 3.5865e-06,
        1.5773e-06, 3.0701e-08, 3.4083e-08], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,247][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([7.1537e-01, 2.3718e-01, 3.3913e-04, 4.6530e-02, 4.9088e-04, 4.6899e-05,
        3.9375e-05, 1.3175e-06, 1.5955e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,247][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([9.9957e-01, 8.2439e-05, 2.0838e-04, 3.4033e-05, 4.6583e-05, 1.6086e-05,
        2.2307e-05, 5.9165e-06, 1.1516e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,247][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.9844e-01, 1.0107e-03, 2.0715e-04, 1.1788e-04, 8.1037e-05, 6.0799e-05,
        3.8683e-05, 1.4012e-05, 3.4532e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,248][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0106, 0.1611, 0.3241, 0.0981, 0.2440, 0.0197, 0.0103, 0.0503, 0.0817],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,248][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0813, 0.4291, 0.1716, 0.2175, 0.0749, 0.0171, 0.0026, 0.0016, 0.0043],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,248][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([9.4723e-01, 1.9407e-02, 2.5128e-02, 3.7991e-03, 3.2872e-03, 7.4409e-04,
        8.2232e-05, 9.0716e-05, 2.3396e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,249][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0005, 0.1051, 0.0257, 0.1016, 0.0387, 0.0624, 0.0528, 0.5022, 0.1109],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,249][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([7.9159e-04, 8.7707e-01, 4.7553e-03, 1.1043e-01, 6.4606e-03, 4.0737e-04,
        6.7388e-05, 2.6425e-06, 1.5791e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,249][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.6200, 0.0166, 0.0205, 0.0234, 0.0661, 0.0238, 0.0424, 0.0467, 0.1405],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,250][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.7155e-01, 7.8775e-03, 8.9164e-03, 4.1901e-03, 5.0686e-03, 1.2015e-03,
        2.7297e-04, 5.6320e-05, 2.1378e-04, 6.5766e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,251][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1159, 0.1895, 0.4994, 0.0471, 0.0906, 0.0142, 0.0071, 0.0144, 0.0119,
        0.0100], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,253][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.7822e-01, 6.4583e-03, 1.1544e-02, 1.1517e-03, 1.9546e-03, 3.3380e-04,
        1.0777e-04, 6.4703e-06, 9.2943e-06, 2.1206e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,255][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([7.3771e-01, 2.4525e-01, 7.0807e-04, 1.5276e-02, 5.1490e-04, 8.5627e-05,
        6.5466e-05, 7.6468e-06, 5.6154e-06, 3.7895e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,257][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([9.7872e-01, 3.6653e-03, 7.3098e-03, 2.1613e-03, 3.5637e-03, 1.1350e-03,
        1.2684e-03, 2.8835e-04, 4.5630e-04, 1.4287e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,260][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.6843e-01, 1.4611e-02, 8.6750e-03, 2.0426e-03, 1.9863e-03, 1.0427e-03,
        6.0276e-04, 1.4680e-04, 7.7149e-04, 1.6892e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,262][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([9.5878e-05, 1.4662e-01, 4.4769e-01, 4.4248e-02, 2.5576e-01, 6.0757e-03,
        2.6028e-03, 2.6913e-02, 5.8879e-02, 1.1114e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,265][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0106, 0.3495, 0.3744, 0.1457, 0.0949, 0.0164, 0.0027, 0.0017, 0.0020,
        0.0022], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,267][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([6.3738e-01, 1.2395e-01, 1.9627e-01, 2.0368e-02, 1.4384e-02, 2.5493e-03,
        3.0517e-04, 2.5170e-04, 1.2926e-03, 3.2564e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,269][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([8.6081e-05, 3.3389e-02, 1.3475e-02, 7.7357e-02, 3.9455e-02, 4.9412e-02,
        2.5813e-02, 6.2089e-01, 1.2707e-01, 1.3062e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,272][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.3233e-04, 9.7079e-01, 5.1783e-03, 2.1680e-02, 1.6990e-03, 3.0661e-04,
        2.2164e-05, 9.7331e-07, 8.7225e-06, 1.8115e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,276][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6150, 0.0015, 0.0070, 0.0045, 0.0672, 0.0182, 0.0267, 0.0840, 0.1722,
        0.0039], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,276][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.8676e-01, 2.7016e-03, 4.0104e-03, 1.9590e-03, 3.0590e-03, 5.2885e-04,
        1.4743e-04, 2.1091e-05, 6.1997e-05, 3.7002e-04, 3.7942e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,276][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4028, 0.1703, 0.2648, 0.0440, 0.0618, 0.0131, 0.0058, 0.0100, 0.0080,
        0.0079, 0.0115], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,277][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9630e-01, 1.3621e-03, 1.5920e-03, 2.2349e-04, 3.7298e-04, 5.3840e-05,
        2.5392e-05, 8.7023e-07, 1.0591e-06, 4.3880e-05, 2.1867e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,277][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.1002e-01, 8.4177e-02, 1.0380e-04, 4.8492e-03, 1.5562e-04, 3.7559e-05,
        4.6135e-05, 2.5194e-06, 1.7751e-06, 2.5674e-04, 3.5165e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,277][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([9.9021e-01, 1.4794e-03, 3.0459e-03, 1.0716e-03, 1.3769e-03, 6.2102e-04,
        7.1506e-04, 8.8745e-05, 2.1412e-04, 5.5087e-04, 6.2780e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,278][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.6784e-01, 1.2483e-02, 6.4415e-03, 2.0958e-03, 2.0591e-03, 1.0235e-03,
        6.5068e-04, 1.2336e-04, 4.9765e-04, 2.1775e-03, 4.6032e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,278][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([2.5366e-04, 1.8775e-01, 3.5611e-01, 6.4830e-02, 2.9159e-01, 1.0875e-02,
        4.6016e-03, 2.1019e-02, 3.7629e-02, 1.2569e-02, 1.2770e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,278][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0488, 0.3731, 0.3344, 0.1231, 0.0883, 0.0171, 0.0042, 0.0027, 0.0025,
        0.0029, 0.0029], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,280][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([8.7474e-01, 5.6192e-02, 4.8501e-02, 9.8280e-03, 4.7509e-03, 1.4201e-03,
        2.0737e-04, 1.1280e-04, 4.7182e-04, 1.9294e-03, 1.8431e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,281][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.9467e-04, 2.6516e-02, 9.9868e-03, 6.2629e-02, 4.1023e-02, 6.0657e-02,
        2.2341e-02, 6.2217e-01, 1.0769e-01, 8.3881e-03, 3.8004e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,283][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([4.1249e-04, 9.6486e-01, 4.6855e-03, 2.5752e-02, 2.0832e-03, 5.1439e-04,
        5.0974e-05, 1.6539e-06, 1.7173e-05, 4.9518e-04, 1.1259e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,287][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8152, 0.0016, 0.0090, 0.0056, 0.0362, 0.0106, 0.0164, 0.0281, 0.0628,
        0.0056, 0.0089], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,289][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([9.9276e-01, 1.5680e-03, 1.6753e-03, 1.2337e-03, 1.1263e-03, 3.0264e-04,
        8.7204e-05, 1.0081e-04, 1.3739e-04, 2.5919e-04, 2.2245e-04, 5.2374e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,293][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.5944, 0.0928, 0.1397, 0.0302, 0.0408, 0.0152, 0.0099, 0.0252, 0.0141,
        0.0142, 0.0107, 0.0129], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,295][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([9.9779e-01, 5.9263e-04, 5.0750e-04, 4.4299e-04, 2.5253e-04, 1.3746e-04,
        5.3169e-05, 8.3745e-06, 3.8041e-06, 8.1497e-05, 3.4843e-05, 9.7579e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,298][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([7.2907e-01, 1.7316e-01, 5.0978e-04, 8.8613e-02, 1.2239e-03, 4.1709e-04,
        3.7347e-04, 5.4524e-05, 6.9977e-05, 2.1698e-03, 4.2055e-03, 1.3627e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,300][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([9.7677e-01, 3.3104e-03, 4.5093e-03, 2.7586e-03, 2.1470e-03, 1.5755e-03,
        1.7693e-03, 6.2098e-04, 5.5778e-04, 1.5314e-03, 1.4313e-03, 3.0150e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,302][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.8588e-01, 3.3213e-03, 2.2343e-03, 1.1247e-03, 8.5649e-04, 7.6412e-04,
        5.5255e-04, 2.2477e-04, 7.4301e-04, 1.1569e-03, 2.1339e-03, 1.0050e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,305][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0006, 0.1909, 0.2854, 0.0777, 0.2553, 0.0130, 0.0078, 0.0546, 0.0760,
        0.0170, 0.0181, 0.0037], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,305][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0321, 0.3075, 0.2484, 0.1994, 0.1304, 0.0309, 0.0074, 0.0067, 0.0069,
        0.0063, 0.0078, 0.0160], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,305][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([8.5335e-01, 5.1239e-02, 4.6487e-02, 1.7669e-02, 1.2096e-02, 2.5906e-03,
        4.0357e-04, 4.0437e-04, 1.8377e-03, 3.7699e-03, 3.0757e-03, 7.0807e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,306][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0009, 0.0238, 0.0136, 0.0959, 0.0366, 0.0670, 0.0228, 0.5744, 0.1077,
        0.0114, 0.0397, 0.0063], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,306][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([3.4104e-04, 7.9993e-01, 7.7934e-03, 1.7008e-01, 1.1051e-02, 1.8092e-03,
        2.5555e-04, 1.7794e-05, 1.5864e-04, 2.1143e-03, 6.2533e-03, 1.9395e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,306][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.2203, 0.0509, 0.0412, 0.0333, 0.0483, 0.0420, 0.0226, 0.0315, 0.1329,
        0.2024, 0.1125, 0.0620], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,307][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([9.8821e-01, 2.1557e-03, 2.2298e-03, 2.0616e-03, 2.0619e-03, 6.4351e-04,
        1.0987e-04, 1.1512e-04, 3.5385e-04, 4.7596e-04, 3.4060e-04, 8.1251e-04,
        4.2647e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,307][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.3288, 0.1234, 0.2670, 0.0553, 0.0915, 0.0173, 0.0099, 0.0327, 0.0131,
        0.0120, 0.0166, 0.0152, 0.0171], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,307][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([9.9878e-01, 4.0555e-04, 3.1359e-04, 1.3120e-04, 1.2324e-04, 7.9196e-05,
        2.3813e-05, 3.9205e-06, 2.3756e-06, 4.5638e-05, 2.2601e-05, 5.0224e-05,
        1.7863e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,308][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([8.1665e-01, 7.3257e-02, 2.8238e-04, 9.5636e-02, 1.2233e-03, 6.7074e-04,
        6.8149e-04, 2.6990e-04, 1.5918e-04, 3.8620e-03, 6.9689e-03, 2.6669e-04,
        6.9183e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,310][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([9.8643e-01, 2.4331e-03, 2.3954e-03, 1.0445e-03, 1.2796e-03, 6.3975e-04,
        6.4985e-04, 3.1171e-04, 4.4132e-04, 8.2689e-04, 8.2674e-04, 1.5333e-03,
        1.1835e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,311][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([9.8536e-01, 3.6731e-03, 2.9120e-03, 1.1006e-03, 1.0907e-03, 7.3453e-04,
        3.6370e-04, 1.4556e-04, 8.3540e-04, 7.5514e-04, 2.0176e-03, 5.7325e-04,
        4.4141e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,315][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0013, 0.1470, 0.1902, 0.1125, 0.1752, 0.0329, 0.0123, 0.1139, 0.1300,
        0.0254, 0.0270, 0.0056, 0.0266], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,319][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1170, 0.2696, 0.1346, 0.2391, 0.0888, 0.0473, 0.0134, 0.0112, 0.0085,
        0.0118, 0.0118, 0.0383, 0.0086], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,321][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([7.0742e-01, 1.1352e-01, 9.9030e-02, 2.4198e-02, 1.9580e-02, 4.6970e-03,
        4.5643e-04, 1.2313e-03, 2.5763e-03, 7.3760e-03, 6.2469e-03, 1.1637e-02,
        2.0302e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,325][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0014, 0.0144, 0.0078, 0.0629, 0.0237, 0.0740, 0.0249, 0.5987, 0.0549,
        0.0094, 0.0392, 0.0078, 0.0810], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,327][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([1.0548e-03, 7.0975e-01, 3.3163e-03, 2.4901e-01, 7.9266e-03, 3.3830e-03,
        4.6492e-04, 4.2442e-05, 2.9099e-04, 6.7182e-03, 1.7150e-02, 7.3055e-04,
        1.5977e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,331][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.3787, 0.0242, 0.0151, 0.0368, 0.0333, 0.0191, 0.0251, 0.0132, 0.0598,
        0.1345, 0.1668, 0.0385, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,334][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([9.8756e-01, 4.0588e-03, 2.0835e-03, 1.5976e-03, 1.9871e-03, 3.5040e-04,
        1.0174e-04, 4.6330e-05, 1.2482e-04, 4.0409e-04, 1.8452e-04, 4.9342e-04,
        3.2236e-04, 6.8536e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,334][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.2077, 0.1626, 0.2744, 0.0550, 0.1114, 0.0209, 0.0126, 0.0341, 0.0184,
        0.0191, 0.0155, 0.0321, 0.0291, 0.0071], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,335][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([9.9347e-01, 2.3135e-03, 1.9944e-03, 4.4226e-04, 8.0369e-04, 3.3609e-04,
        1.0851e-04, 1.5776e-05, 1.0656e-05, 1.7372e-04, 4.7588e-05, 1.6860e-04,
        5.7561e-05, 5.8845e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,335][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([5.0152e-01, 4.8209e-01, 2.7650e-04, 1.5135e-02, 3.0187e-04, 4.1986e-05,
        1.6649e-05, 8.3064e-07, 1.2371e-06, 2.1623e-04, 2.9321e-04, 8.1476e-06,
        2.8147e-06, 9.5509e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,335][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([9.3656e-01, 8.5109e-03, 2.1090e-02, 5.9400e-03, 8.6966e-03, 2.7603e-03,
        2.1420e-03, 9.0016e-04, 1.7848e-03, 2.1400e-03, 2.0165e-03, 2.4865e-03,
        3.2152e-03, 1.7621e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,336][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([9.5808e-01, 1.2691e-02, 5.9614e-03, 2.6374e-03, 2.1220e-03, 1.5042e-03,
        1.1074e-03, 2.2498e-04, 8.7350e-04, 2.8058e-03, 2.9001e-03, 1.2830e-03,
        9.0573e-04, 6.9016e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,336][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([1.0253e-04, 1.3411e-01, 3.0585e-01, 5.8128e-02, 2.8698e-01, 1.0529e-02,
        5.0646e-03, 6.3238e-02, 6.1291e-02, 1.4896e-02, 1.2410e-02, 2.4609e-03,
        3.8368e-02, 6.5627e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,336][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0235, 0.3652, 0.3154, 0.1562, 0.0967, 0.0135, 0.0019, 0.0011, 0.0023,
        0.0022, 0.0032, 0.0077, 0.0030, 0.0082], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,337][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([8.1998e-01, 7.2317e-02, 6.6351e-02, 1.3349e-02, 9.7544e-03, 1.8782e-03,
        3.1981e-04, 3.2637e-04, 1.1854e-03, 3.7968e-03, 2.8363e-03, 5.9916e-03,
        6.6514e-04, 1.2469e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,337][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([2.0162e-04, 1.8582e-02, 8.5738e-03, 5.6420e-02, 2.5889e-02, 5.3206e-02,
        3.2471e-02, 5.2210e-01, 1.3593e-01, 1.2643e-02, 4.9153e-02, 6.2245e-03,
        6.5213e-02, 1.3399e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,338][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([7.2210e-05, 9.6611e-01, 2.5466e-03, 2.8737e-02, 1.4163e-03, 1.5769e-04,
        9.0590e-06, 2.2248e-07, 2.8302e-06, 1.4649e-04, 3.4926e-04, 1.2427e-05,
        6.1041e-06, 4.3054e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,339][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0689, 0.0301, 0.0434, 0.0354, 0.0459, 0.0493, 0.0248, 0.0725, 0.1227,
        0.1079, 0.1493, 0.0477, 0.0661, 0.1360], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,341][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.8144e-01, 2.8345e-03, 3.5221e-03, 1.9436e-03, 3.9834e-03, 7.9534e-04,
        1.9372e-04, 5.6333e-05, 1.2959e-04, 5.9615e-04, 5.3343e-04, 9.1229e-04,
        6.8317e-04, 1.7731e-03, 6.0286e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,344][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5615, 0.1279, 0.1689, 0.0276, 0.0413, 0.0076, 0.0043, 0.0096, 0.0078,
        0.0052, 0.0074, 0.0076, 0.0078, 0.0031, 0.0123], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,346][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.9546e-01, 1.8753e-03, 1.3649e-03, 3.4999e-04, 4.1852e-04, 1.7249e-04,
        6.0206e-05, 3.5587e-06, 3.2564e-06, 8.1230e-05, 3.2408e-05, 9.3005e-05,
        2.8170e-05, 3.6553e-05, 2.4324e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,349][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.9923e-01, 9.3482e-02, 3.9039e-05, 5.2507e-03, 9.7899e-05, 4.0496e-05,
        4.0576e-05, 1.7465e-06, 1.7145e-06, 3.6721e-04, 5.5622e-04, 1.4091e-05,
        7.5164e-06, 1.8870e-04, 6.8073e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,351][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.8494e-01, 1.9920e-03, 2.2936e-03, 1.4922e-03, 1.5625e-03, 9.4588e-04,
        1.0711e-03, 1.9558e-04, 4.1206e-04, 7.7537e-04, 7.8266e-04, 1.2386e-03,
        1.1393e-03, 6.8113e-04, 4.7604e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,353][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.6587e-01, 1.0355e-02, 6.4878e-03, 1.5448e-03, 1.9682e-03, 9.9134e-04,
        6.1405e-04, 8.9135e-05, 4.9724e-04, 1.5564e-03, 3.2103e-03, 5.7148e-04,
        6.4766e-04, 3.6053e-03, 1.9894e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,357][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0007, 0.1916, 0.2896, 0.0679, 0.2291, 0.0167, 0.0067, 0.0483, 0.0652,
        0.0171, 0.0171, 0.0031, 0.0298, 0.0074, 0.0098], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,361][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1077, 0.3410, 0.2573, 0.1165, 0.0973, 0.0220, 0.0067, 0.0025, 0.0021,
        0.0043, 0.0042, 0.0151, 0.0064, 0.0120, 0.0048], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,364][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([8.7948e-01, 4.3494e-02, 5.4136e-02, 6.9073e-03, 6.1733e-03, 1.2047e-03,
        1.7206e-04, 1.8829e-04, 5.8048e-04, 1.5565e-03, 1.4247e-03, 2.3734e-03,
        4.6505e-04, 8.6567e-04, 9.7927e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,364][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.6132e-04, 8.9232e-03, 3.7773e-03, 3.2034e-02, 2.1524e-02, 3.4454e-02,
        1.6806e-02, 6.9593e-01, 6.3162e-02, 6.3311e-03, 2.3967e-02, 4.2747e-03,
        6.9942e-02, 7.5431e-03, 1.0667e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,365][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.7955e-04, 9.5793e-01, 1.1833e-03, 2.9154e-02, 1.1434e-03, 4.5749e-04,
        6.3000e-05, 1.4978e-06, 1.2788e-05, 8.8583e-04, 2.0116e-03, 5.8620e-05,
        3.6561e-05, 3.5501e-03, 2.9311e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,365][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.4313, 0.0063, 0.0208, 0.0119, 0.0680, 0.0133, 0.0189, 0.0535, 0.0700,
        0.0373, 0.0380, 0.0297, 0.0911, 0.0953, 0.0147], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,409][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:42,412][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,416][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,416][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,417][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,417][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,417][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,418][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,418][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,418][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,419][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,419][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,419][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,420][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9996e-01, 3.9691e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,420][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8741, 0.1259], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,420][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9998e-01, 2.0708e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,421][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.9995e-01, 4.8619e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,421][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9965e-01, 3.4706e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,421][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.9949e-01, 5.1128e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,421][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0357, 0.9643], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,422][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8888, 0.1112], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,422][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9932, 0.0068], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,422][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,423][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4685, 0.5315], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,423][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8769, 0.1231], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,423][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([9.9987e-01, 4.7295e-05, 7.9039e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,424][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.7491, 0.0333, 0.2176], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,424][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([9.9992e-01, 1.9684e-05, 5.6835e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,424][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([9.9985e-01, 1.4781e-04, 6.2769e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,425][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([9.9960e-01, 2.0885e-04, 1.8629e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,425][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([9.9952e-01, 1.7557e-04, 3.0154e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,425][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.0179, 0.2850, 0.6972], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,426][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.9111, 0.0378, 0.0511], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,426][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.9897, 0.0046, 0.0057], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,426][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.0046, 0.1456, 0.8498], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,427][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.4452, 0.5016, 0.0532], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,427][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.9818, 0.0073, 0.0109], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,428][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.9937e-01, 2.4241e-04, 2.3759e-04, 1.4639e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,429][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4126, 0.1424, 0.3711, 0.0739], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,429][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9962e-01, 1.7450e-04, 1.7806e-04, 3.0492e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,429][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.9446e-01, 5.3536e-03, 1.0051e-05, 1.7912e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,429][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9590e-01, 1.2246e-03, 2.2766e-03, 6.0286e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,430][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.9781e-01, 1.1429e-03, 8.5886e-04, 1.8810e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,430][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0007, 0.2226, 0.6785, 0.0981], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,430][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1736, 0.3850, 0.3611, 0.0803], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,430][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9617, 0.0136, 0.0196, 0.0052], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,431][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([3.1083e-05, 2.0061e-01, 6.2077e-01, 1.7858e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,432][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0147, 0.9620, 0.0037, 0.0196], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,434][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8556, 0.0702, 0.0384, 0.0359], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,434][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([9.9931e-01, 1.8343e-04, 2.1396e-04, 9.3957e-05, 1.9699e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,436][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.5130, 0.0598, 0.2706, 0.0475, 0.1091], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,437][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([9.9990e-01, 3.3925e-05, 4.3426e-05, 9.4431e-06, 1.7516e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,438][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([9.8849e-01, 9.2608e-03, 3.2142e-05, 2.1997e-03, 2.1782e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,439][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([9.9814e-01, 6.7027e-04, 5.4218e-04, 1.7973e-04, 4.7149e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,439][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.9838e-01, 7.0695e-04, 6.2575e-04, 1.3240e-04, 1.5443e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,441][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0033, 0.1442, 0.3685, 0.1205, 0.3634], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,442][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.4721, 0.2382, 0.1629, 0.0866, 0.0403], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,444][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.9524, 0.0225, 0.0151, 0.0064, 0.0035], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,444][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([4.1126e-04, 1.3449e-01, 4.2658e-01, 2.5709e-01, 1.8143e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,446][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([0.0109, 0.8704, 0.0057, 0.1091, 0.0039], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,447][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.9824, 0.0077, 0.0026, 0.0041, 0.0031], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,448][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([9.9558e-01, 1.4538e-03, 1.1295e-03, 6.5508e-04, 1.0529e-03, 1.3339e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,450][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.3398, 0.1126, 0.3512, 0.0488, 0.1226, 0.0250], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,451][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([9.9822e-01, 7.3109e-04, 7.3205e-04, 8.7863e-05, 2.0413e-04, 2.7962e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,451][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([8.5544e-01, 1.3008e-01, 7.5675e-04, 1.3027e-02, 6.5735e-04, 4.4648e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,451][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([9.8838e-01, 2.4224e-03, 5.0770e-03, 1.3725e-03, 2.0659e-03, 6.8592e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,452][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([9.9152e-01, 3.8594e-03, 2.7807e-03, 5.8851e-04, 7.8306e-04, 4.6561e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,452][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([2.0028e-04, 1.1984e-01, 4.3974e-01, 5.7845e-02, 3.7173e-01, 1.0646e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,452][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0440, 0.2517, 0.3855, 0.1779, 0.1218, 0.0191], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,452][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7968, 0.0721, 0.0967, 0.0150, 0.0162, 0.0032], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,453][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.5110e-05, 1.0888e-01, 4.5615e-01, 8.0806e-02, 3.0276e-01, 5.1375e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,453][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([4.5611e-04, 8.8189e-01, 1.5259e-02, 9.2698e-02, 9.2579e-03, 4.4030e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,453][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.7966, 0.0627, 0.0283, 0.0256, 0.0274, 0.0593], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,454][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.9096e-01, 3.2918e-03, 2.5010e-03, 1.1289e-03, 1.8063e-03, 2.4988e-04,
        6.4743e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,454][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4207, 0.1784, 0.2254, 0.0602, 0.0676, 0.0335, 0.0142],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,455][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.9209e-01, 2.7697e-03, 3.5456e-03, 4.0256e-04, 9.9539e-04, 1.3831e-04,
        5.4118e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,456][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.8775e-01, 9.5988e-02, 1.8902e-04, 1.5404e-02, 4.7027e-04, 1.3597e-04,
        6.1516e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,457][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.8575e-01, 3.3019e-03, 5.1086e-03, 1.8404e-03, 2.2290e-03, 9.1507e-04,
        8.5815e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,458][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.8536e-01, 6.7611e-03, 4.5300e-03, 1.0950e-03, 1.1476e-03, 7.2108e-04,
        3.8095e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,459][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.3661e-04, 1.7445e-01, 4.7466e-01, 5.3448e-02, 2.8265e-01, 9.8959e-03,
        4.6666e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,460][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0356, 0.2666, 0.3184, 0.2174, 0.1067, 0.0489, 0.0063],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,461][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([7.3049e-01, 1.0222e-01, 1.2672e-01, 2.0920e-02, 1.5935e-02, 3.2712e-03,
        4.4302e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,462][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.5979e-05, 1.9660e-01, 4.8270e-01, 1.0139e-01, 1.6264e-01, 4.4524e-02,
        1.2120e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,462][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.8244e-04, 8.6210e-01, 7.1768e-03, 1.1919e-01, 9.5040e-03, 1.6342e-03,
        1.1098e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,464][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.8151, 0.0508, 0.0164, 0.0236, 0.0177, 0.0376, 0.0388],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,465][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([9.9883e-01, 2.2219e-04, 3.3940e-04, 1.9734e-04, 3.6979e-04, 2.9364e-05,
        1.2745e-05, 2.7394e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,466][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.5494, 0.0304, 0.3725, 0.0071, 0.0339, 0.0020, 0.0019, 0.0028],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,467][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.9563e-01, 1.2101e-03, 2.2248e-03, 2.8908e-04, 5.6851e-04, 6.0211e-05,
        1.7223e-05, 5.8561e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,468][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([5.8219e-01, 3.2697e-01, 5.7428e-04, 8.8603e-02, 1.4312e-03, 1.2645e-04,
        1.0513e-04, 1.6077e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,469][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([9.9974e-01, 7.7384e-05, 1.0631e-04, 3.0085e-05, 1.7439e-05, 9.0081e-06,
        1.7840e-05, 4.8767e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,470][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([9.9912e-01, 4.8718e-04, 2.1714e-04, 5.7732e-05, 6.9679e-05, 2.2784e-05,
        1.2796e-05, 7.9058e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,471][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0039, 0.1649, 0.5046, 0.0644, 0.2028, 0.0156, 0.0053, 0.0383],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,472][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0214, 0.4788, 0.2244, 0.1696, 0.0860, 0.0152, 0.0028, 0.0018],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,473][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([7.0031e-01, 9.6963e-02, 1.6015e-01, 1.0367e-02, 2.8506e-02, 2.5889e-03,
        4.9363e-04, 6.2073e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,475][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0005, 0.1820, 0.3600, 0.1031, 0.1058, 0.0693, 0.0292, 0.1501],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,476][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([7.8667e-04, 8.6218e-01, 2.0017e-03, 1.2779e-01, 6.8010e-03, 3.9696e-04,
        4.1518e-05, 8.6014e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,477][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.8718, 0.0154, 0.0062, 0.0080, 0.0081, 0.0127, 0.0165, 0.0612],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,478][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([9.9974e-01, 6.4508e-05, 6.5634e-05, 5.2676e-05, 6.3794e-05, 5.3310e-06,
        1.9756e-06, 2.7360e-07, 1.9545e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,479][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.4913, 0.0426, 0.3421, 0.0180, 0.0708, 0.0078, 0.0073, 0.0112, 0.0089],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,480][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.9978e-01, 6.0688e-05, 1.0770e-04, 1.5347e-05, 3.3352e-05, 3.5865e-06,
        1.5773e-06, 3.0701e-08, 3.4083e-08], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,481][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([7.1537e-01, 2.3718e-01, 3.3913e-04, 4.6530e-02, 4.9088e-04, 4.6899e-05,
        3.9375e-05, 1.3175e-06, 1.5955e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,482][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([9.9957e-01, 8.2439e-05, 2.0838e-04, 3.4033e-05, 4.6583e-05, 1.6086e-05,
        2.2307e-05, 5.9165e-06, 1.1516e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,483][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([9.9844e-01, 1.0107e-03, 2.0715e-04, 1.1788e-04, 8.1037e-05, 6.0799e-05,
        3.8683e-05, 1.4012e-05, 3.4532e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,484][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0106, 0.1611, 0.3241, 0.0981, 0.2440, 0.0197, 0.0103, 0.0503, 0.0817],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,486][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0813, 0.4291, 0.1716, 0.2175, 0.0749, 0.0171, 0.0026, 0.0016, 0.0043],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,487][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.4723e-01, 1.9407e-02, 2.5128e-02, 3.7991e-03, 3.2872e-03, 7.4409e-04,
        8.2232e-05, 9.0716e-05, 2.3396e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,488][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0003, 0.2463, 0.2808, 0.1287, 0.0842, 0.0514, 0.0371, 0.1049, 0.0663],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,489][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([7.9159e-04, 8.7707e-01, 4.7553e-03, 1.1043e-01, 6.4606e-03, 4.0737e-04,
        6.7388e-05, 2.6425e-06, 1.5791e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,490][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.9197, 0.0064, 0.0030, 0.0062, 0.0052, 0.0084, 0.0108, 0.0306, 0.0098],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,491][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.7155e-01, 7.8775e-03, 8.9164e-03, 4.1901e-03, 5.0686e-03, 1.2015e-03,
        2.7297e-04, 5.6320e-05, 2.1378e-04, 6.5766e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,493][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1159, 0.1895, 0.4994, 0.0471, 0.0906, 0.0142, 0.0071, 0.0144, 0.0119,
        0.0100], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,494][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.7822e-01, 6.4583e-03, 1.1544e-02, 1.1517e-03, 1.9546e-03, 3.3380e-04,
        1.0777e-04, 6.4703e-06, 9.2943e-06, 2.1206e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,494][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([7.3771e-01, 2.4525e-01, 7.0807e-04, 1.5276e-02, 5.1490e-04, 8.5627e-05,
        6.5466e-05, 7.6468e-06, 5.6154e-06, 3.7895e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,495][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.7872e-01, 3.6653e-03, 7.3098e-03, 2.1613e-03, 3.5637e-03, 1.1350e-03,
        1.2684e-03, 2.8835e-04, 4.5630e-04, 1.4287e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,496][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([9.6843e-01, 1.4611e-02, 8.6750e-03, 2.0426e-03, 1.9863e-03, 1.0427e-03,
        6.0276e-04, 1.4680e-04, 7.7149e-04, 1.6892e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,497][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.5878e-05, 1.4662e-01, 4.4769e-01, 4.4248e-02, 2.5576e-01, 6.0757e-03,
        2.6028e-03, 2.6913e-02, 5.8879e-02, 1.1114e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,499][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0106, 0.3495, 0.3744, 0.1457, 0.0949, 0.0164, 0.0027, 0.0017, 0.0020,
        0.0022], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,499][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([6.3738e-01, 1.2395e-01, 1.9627e-01, 2.0368e-02, 1.4384e-02, 2.5493e-03,
        3.0517e-04, 2.5170e-04, 1.2926e-03, 3.2564e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,500][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.1121e-05, 1.5728e-01, 4.0055e-01, 8.0629e-02, 1.5969e-01, 2.1665e-02,
        9.8889e-03, 7.9950e-02, 7.4567e-02, 1.5776e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,501][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.3233e-04, 9.7079e-01, 5.1783e-03, 2.1680e-02, 1.6990e-03, 3.0661e-04,
        2.2164e-05, 9.7331e-07, 8.7225e-06, 1.8115e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,503][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4535, 0.0859, 0.0567, 0.0392, 0.0410, 0.0629, 0.0562, 0.1227, 0.0406,
        0.0412], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,504][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.8676e-01, 2.7016e-03, 4.0104e-03, 1.9590e-03, 3.0590e-03, 5.2885e-04,
        1.4743e-04, 2.1091e-05, 6.1997e-05, 3.7002e-04, 3.7942e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,505][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4028, 0.1703, 0.2648, 0.0440, 0.0618, 0.0131, 0.0058, 0.0100, 0.0080,
        0.0079, 0.0115], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,506][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9630e-01, 1.3621e-03, 1.5920e-03, 2.2349e-04, 3.7298e-04, 5.3840e-05,
        2.5392e-05, 8.7023e-07, 1.0591e-06, 4.3880e-05, 2.1867e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,507][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.1002e-01, 8.4177e-02, 1.0380e-04, 4.8492e-03, 1.5562e-04, 3.7559e-05,
        4.6135e-05, 2.5194e-06, 1.7751e-06, 2.5674e-04, 3.5165e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,508][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9021e-01, 1.4794e-03, 3.0459e-03, 1.0716e-03, 1.3769e-03, 6.2102e-04,
        7.1506e-04, 8.8745e-05, 2.1412e-04, 5.5087e-04, 6.2780e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,509][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.6784e-01, 1.2483e-02, 6.4415e-03, 2.0958e-03, 2.0591e-03, 1.0235e-03,
        6.5068e-04, 1.2336e-04, 4.9765e-04, 2.1775e-03, 4.6032e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,510][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([2.5366e-04, 1.8775e-01, 3.5611e-01, 6.4830e-02, 2.9159e-01, 1.0875e-02,
        4.6016e-03, 2.1019e-02, 3.7629e-02, 1.2569e-02, 1.2770e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,511][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0488, 0.3731, 0.3344, 0.1231, 0.0883, 0.0171, 0.0042, 0.0027, 0.0025,
        0.0029, 0.0029], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,512][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([8.7474e-01, 5.6192e-02, 4.8501e-02, 9.8280e-03, 4.7509e-03, 1.4201e-03,
        2.0737e-04, 1.1280e-04, 4.7182e-04, 1.9294e-03, 1.8431e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,513][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.8979e-05, 1.4719e-01, 3.1799e-01, 8.6703e-02, 1.5182e-01, 3.3478e-02,
        1.1321e-02, 9.8010e-02, 8.6483e-02, 1.6167e-02, 5.0778e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,514][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.1249e-04, 9.6486e-01, 4.6855e-03, 2.5752e-02, 2.0832e-03, 5.1439e-04,
        5.0974e-05, 1.6539e-06, 1.7173e-05, 4.9518e-04, 1.1259e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,514][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5878, 0.0479, 0.0362, 0.0284, 0.0329, 0.0525, 0.0416, 0.1035, 0.0230,
        0.0237, 0.0225], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,515][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([9.9276e-01, 1.5680e-03, 1.6753e-03, 1.2337e-03, 1.1263e-03, 3.0264e-04,
        8.7204e-05, 1.0081e-04, 1.3739e-04, 2.5919e-04, 2.2245e-04, 5.2374e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,515][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.5944, 0.0928, 0.1397, 0.0302, 0.0408, 0.0152, 0.0099, 0.0252, 0.0141,
        0.0142, 0.0107, 0.0129], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,515][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([9.9779e-01, 5.9263e-04, 5.0750e-04, 4.4299e-04, 2.5253e-04, 1.3746e-04,
        5.3169e-05, 8.3745e-06, 3.8041e-06, 8.1497e-05, 3.4843e-05, 9.7579e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,516][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([7.2907e-01, 1.7316e-01, 5.0978e-04, 8.8613e-02, 1.2239e-03, 4.1709e-04,
        3.7347e-04, 5.4524e-05, 6.9977e-05, 2.1698e-03, 4.2055e-03, 1.3627e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,516][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([9.7677e-01, 3.3104e-03, 4.5093e-03, 2.7586e-03, 2.1470e-03, 1.5755e-03,
        1.7693e-03, 6.2098e-04, 5.5778e-04, 1.5314e-03, 1.4313e-03, 3.0150e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,516][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.8588e-01, 3.3213e-03, 2.2343e-03, 1.1247e-03, 8.5649e-04, 7.6412e-04,
        5.5255e-04, 2.2477e-04, 7.4301e-04, 1.1569e-03, 2.1339e-03, 1.0050e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,517][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0006, 0.1909, 0.2854, 0.0777, 0.2553, 0.0130, 0.0078, 0.0546, 0.0760,
        0.0170, 0.0181, 0.0037], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,517][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0321, 0.3075, 0.2484, 0.1994, 0.1304, 0.0309, 0.0074, 0.0067, 0.0069,
        0.0063, 0.0078, 0.0160], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,518][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([8.5335e-01, 5.1239e-02, 4.6487e-02, 1.7669e-02, 1.2096e-02, 2.5906e-03,
        4.0357e-04, 4.0437e-04, 1.8377e-03, 3.7699e-03, 3.0757e-03, 7.0807e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,519][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.3579e-04, 1.2188e-01, 2.7906e-01, 1.3108e-01, 1.2614e-01, 4.7027e-02,
        1.6275e-02, 1.0331e-01, 9.6999e-02, 1.8918e-02, 4.5928e-02, 1.3245e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,519][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([3.4104e-04, 7.9993e-01, 7.7934e-03, 1.7008e-01, 1.1051e-02, 1.8092e-03,
        2.5555e-04, 1.7794e-05, 1.5864e-04, 2.1143e-03, 6.2533e-03, 1.9395e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,521][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.6684, 0.0204, 0.0156, 0.0134, 0.0199, 0.0350, 0.0350, 0.1097, 0.0256,
        0.0138, 0.0130, 0.0301], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,522][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([9.8821e-01, 2.1557e-03, 2.2298e-03, 2.0616e-03, 2.0619e-03, 6.4351e-04,
        1.0987e-04, 1.1512e-04, 3.5385e-04, 4.7596e-04, 3.4060e-04, 8.1251e-04,
        4.2647e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,523][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.3288, 0.1234, 0.2670, 0.0553, 0.0915, 0.0173, 0.0099, 0.0327, 0.0131,
        0.0120, 0.0166, 0.0152, 0.0171], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,524][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([9.9878e-01, 4.0555e-04, 3.1359e-04, 1.3120e-04, 1.2324e-04, 7.9196e-05,
        2.3813e-05, 3.9205e-06, 2.3756e-06, 4.5638e-05, 2.2601e-05, 5.0224e-05,
        1.7863e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,525][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([8.1665e-01, 7.3257e-02, 2.8238e-04, 9.5636e-02, 1.2233e-03, 6.7074e-04,
        6.8149e-04, 2.6990e-04, 1.5918e-04, 3.8620e-03, 6.9689e-03, 2.6669e-04,
        6.9183e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,525][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([9.8643e-01, 2.4331e-03, 2.3954e-03, 1.0445e-03, 1.2796e-03, 6.3975e-04,
        6.4985e-04, 3.1171e-04, 4.4132e-04, 8.2689e-04, 8.2674e-04, 1.5333e-03,
        1.1835e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,526][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([9.8536e-01, 3.6731e-03, 2.9120e-03, 1.1006e-03, 1.0907e-03, 7.3453e-04,
        3.6370e-04, 1.4556e-04, 8.3540e-04, 7.5514e-04, 2.0176e-03, 5.7325e-04,
        4.4141e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,528][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0013, 0.1470, 0.1902, 0.1125, 0.1752, 0.0329, 0.0123, 0.1139, 0.1300,
        0.0254, 0.0270, 0.0056, 0.0266], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,529][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.1170, 0.2696, 0.1346, 0.2391, 0.0888, 0.0473, 0.0134, 0.0112, 0.0085,
        0.0118, 0.0118, 0.0383, 0.0086], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,530][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([7.0742e-01, 1.1352e-01, 9.9030e-02, 2.4198e-02, 1.9580e-02, 4.6970e-03,
        4.5643e-04, 1.2313e-03, 2.5763e-03, 7.3760e-03, 6.2469e-03, 1.1637e-02,
        2.0302e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,531][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0003, 0.0816, 0.1618, 0.1263, 0.0567, 0.0741, 0.0208, 0.1602, 0.0620,
        0.0233, 0.0777, 0.0159, 0.1394], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,532][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([1.0548e-03, 7.0975e-01, 3.3163e-03, 2.4901e-01, 7.9266e-03, 3.3830e-03,
        4.6492e-04, 4.2442e-05, 2.9099e-04, 6.7182e-03, 1.7150e-02, 7.3055e-04,
        1.5977e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,534][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.8547, 0.0216, 0.0089, 0.0092, 0.0064, 0.0128, 0.0091, 0.0436, 0.0103,
        0.0051, 0.0068, 0.0087, 0.0029], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,535][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([9.8756e-01, 4.0588e-03, 2.0835e-03, 1.5976e-03, 1.9871e-03, 3.5040e-04,
        1.0174e-04, 4.6330e-05, 1.2482e-04, 4.0409e-04, 1.8452e-04, 4.9342e-04,
        3.2236e-04, 6.8536e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,536][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.2077, 0.1626, 0.2744, 0.0550, 0.1114, 0.0209, 0.0126, 0.0341, 0.0184,
        0.0191, 0.0155, 0.0321, 0.0291, 0.0071], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,537][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([9.9347e-01, 2.3135e-03, 1.9944e-03, 4.4226e-04, 8.0369e-04, 3.3609e-04,
        1.0851e-04, 1.5776e-05, 1.0656e-05, 1.7372e-04, 4.7588e-05, 1.6860e-04,
        5.7561e-05, 5.8845e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,538][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([5.0152e-01, 4.8209e-01, 2.7650e-04, 1.5135e-02, 3.0187e-04, 4.1986e-05,
        1.6649e-05, 8.3064e-07, 1.2371e-06, 2.1623e-04, 2.9321e-04, 8.1476e-06,
        2.8147e-06, 9.5509e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,539][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([9.3656e-01, 8.5109e-03, 2.1090e-02, 5.9400e-03, 8.6966e-03, 2.7603e-03,
        2.1420e-03, 9.0016e-04, 1.7848e-03, 2.1400e-03, 2.0165e-03, 2.4865e-03,
        3.2152e-03, 1.7621e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,540][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([9.5808e-01, 1.2691e-02, 5.9614e-03, 2.6374e-03, 2.1220e-03, 1.5042e-03,
        1.1074e-03, 2.2498e-04, 8.7350e-04, 2.8058e-03, 2.9001e-03, 1.2830e-03,
        9.0573e-04, 6.9016e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,541][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([1.0253e-04, 1.3411e-01, 3.0585e-01, 5.8128e-02, 2.8698e-01, 1.0529e-02,
        5.0646e-03, 6.3238e-02, 6.1291e-02, 1.4896e-02, 1.2410e-02, 2.4609e-03,
        3.8368e-02, 6.5627e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,542][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0235, 0.3652, 0.3154, 0.1562, 0.0967, 0.0135, 0.0019, 0.0011, 0.0023,
        0.0022, 0.0032, 0.0077, 0.0030, 0.0082], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,543][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([8.1998e-01, 7.2317e-02, 6.6351e-02, 1.3349e-02, 9.7544e-03, 1.8782e-03,
        3.1981e-04, 3.2637e-04, 1.1854e-03, 3.7968e-03, 2.8363e-03, 5.9916e-03,
        6.6514e-04, 1.2469e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,544][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.8614e-05, 1.2898e-01, 2.9428e-01, 6.8347e-02, 1.1948e-01, 1.8486e-02,
        1.1165e-02, 7.1377e-02, 5.0980e-02, 1.4834e-02, 3.7290e-02, 7.8928e-03,
        1.6764e-01, 9.2218e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,545][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([7.2210e-05, 9.6611e-01, 2.5466e-03, 2.8737e-02, 1.4163e-03, 1.5769e-04,
        9.0590e-06, 2.2248e-07, 2.8302e-06, 1.4649e-04, 3.4926e-04, 1.2427e-05,
        6.1041e-06, 4.3054e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,546][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.5509, 0.0342, 0.0311, 0.0223, 0.0244, 0.0302, 0.0266, 0.1264, 0.0289,
        0.0261, 0.0288, 0.0408, 0.0178, 0.0116], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,547][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.8144e-01, 2.8345e-03, 3.5221e-03, 1.9436e-03, 3.9834e-03, 7.9534e-04,
        1.9372e-04, 5.6333e-05, 1.2959e-04, 5.9615e-04, 5.3343e-04, 9.1229e-04,
        6.8317e-04, 1.7731e-03, 6.0286e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,549][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.5615, 0.1279, 0.1689, 0.0276, 0.0413, 0.0076, 0.0043, 0.0096, 0.0078,
        0.0052, 0.0074, 0.0076, 0.0078, 0.0031, 0.0123], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,550][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9546e-01, 1.8753e-03, 1.3649e-03, 3.4999e-04, 4.1852e-04, 1.7249e-04,
        6.0206e-05, 3.5587e-06, 3.2564e-06, 8.1230e-05, 3.2408e-05, 9.3005e-05,
        2.8170e-05, 3.6553e-05, 2.4324e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,551][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.9923e-01, 9.3482e-02, 3.9039e-05, 5.2507e-03, 9.7899e-05, 4.0496e-05,
        4.0576e-05, 1.7465e-06, 1.7145e-06, 3.6721e-04, 5.5622e-04, 1.4091e-05,
        7.5164e-06, 1.8870e-04, 6.8073e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,551][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8494e-01, 1.9920e-03, 2.2936e-03, 1.4922e-03, 1.5625e-03, 9.4588e-04,
        1.0711e-03, 1.9558e-04, 4.1206e-04, 7.7537e-04, 7.8266e-04, 1.2386e-03,
        1.1393e-03, 6.8113e-04, 4.7604e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,552][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.6587e-01, 1.0355e-02, 6.4878e-03, 1.5448e-03, 1.9682e-03, 9.9134e-04,
        6.1405e-04, 8.9135e-05, 4.9724e-04, 1.5564e-03, 3.2103e-03, 5.7148e-04,
        6.4766e-04, 3.6053e-03, 1.9894e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,554][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0007, 0.1916, 0.2896, 0.0679, 0.2291, 0.0167, 0.0067, 0.0483, 0.0652,
        0.0171, 0.0171, 0.0031, 0.0298, 0.0074, 0.0098], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,555][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1077, 0.3410, 0.2573, 0.1165, 0.0973, 0.0220, 0.0067, 0.0025, 0.0021,
        0.0043, 0.0042, 0.0151, 0.0064, 0.0120, 0.0048], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,556][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([8.7948e-01, 4.3494e-02, 5.4136e-02, 6.9073e-03, 6.1733e-03, 1.2047e-03,
        1.7206e-04, 1.8829e-04, 5.8048e-04, 1.5565e-03, 1.4247e-03, 2.3734e-03,
        4.6505e-04, 8.6567e-04, 9.7927e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,557][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.5380e-05, 1.0531e-01, 2.3348e-01, 6.6461e-02, 1.0423e-01, 2.5885e-02,
        9.9041e-03, 9.1902e-02, 5.7292e-02, 1.3953e-02, 4.2993e-02, 8.6339e-03,
        1.9130e-01, 1.0547e-02, 3.8026e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,558][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.7955e-04, 9.5793e-01, 1.1833e-03, 2.9154e-02, 1.1434e-03, 4.5749e-04,
        6.3000e-05, 1.4978e-06, 1.2788e-05, 8.8583e-04, 2.0116e-03, 5.8620e-05,
        3.6561e-05, 3.5501e-03, 2.9311e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,560][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7463, 0.0241, 0.0205, 0.0100, 0.0164, 0.0248, 0.0197, 0.0665, 0.0109,
        0.0106, 0.0104, 0.0168, 0.0081, 0.0042, 0.0107], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,561][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:42,562][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1937],
        [  40],
        [   1],
        [ 206],
        [   4],
        [  21],
        [1284],
        [ 723],
        [ 901],
        [   3],
        [   7],
        [ 100],
        [   2],
        [  15],
        [   9]], device='cuda:0')
[2024-07-24 10:20:42,564][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1008],
        [  22],
        [   1],
        [  51],
        [   4],
        [  19],
        [ 794],
        [ 132],
        [ 303],
        [   1],
        [   4],
        [  77],
        [   2],
        [   9],
        [   6]], device='cuda:0')
[2024-07-24 10:20:42,565][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[49816],
        [49817],
        [49818],
        [49819],
        [49819],
        [49823],
        [49821],
        [49821],
        [49818],
        [49842],
        [49840],
        [49828],
        [49826],
        [49808],
        [49821]], device='cuda:0')
[2024-07-24 10:20:42,567][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[8454],
        [6117],
        [9014],
        [8392],
        [7496],
        [7704],
        [6697],
        [9367],
        [8524],
        [8519],
        [7692],
        [6938],
        [7636],
        [7715],
        [7420]], device='cuda:0')
[2024-07-24 10:20:42,568][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16195],
        [16197],
        [16214],
        [16252],
        [16212],
        [16459],
        [17428],
        [16961],
        [16232],
        [20242],
        [16753],
        [16332],
        [16303],
        [16873],
        [16673]], device='cuda:0')
[2024-07-24 10:20:42,569][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[31919],
        [31919],
        [31920],
        [32108],
        [32361],
        [37299],
        [36205],
        [43378],
        [41274],
        [40569],
        [35329],
        [41340],
        [39285],
        [43685],
        [35700]], device='cuda:0')
[2024-07-24 10:20:42,571][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10898],
        [10828],
        [10818],
        [10018],
        [10518],
        [ 8813],
        [ 8420],
        [10848],
        [10821],
        [ 7545],
        [ 9217],
        [ 7183],
        [ 8618],
        [ 3811],
        [ 8431]], device='cuda:0')
[2024-07-24 10:20:42,572][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15628],
        [15601],
        [15507],
        [15232],
        [15291],
        [14045],
        [13025],
        [15497],
        [15430],
        [10650],
        [10871],
        [13303],
        [13058],
        [10225],
        [10742]], device='cuda:0')
[2024-07-24 10:20:42,573][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[47877],
        [46622],
        [50257],
        [50257],
        [50251],
        [50253],
        [50254],
        [50254],
        [50246],
        [50254],
        [50250],
        [50239],
        [50107],
        [50244],
        [50240]], device='cuda:0')
[2024-07-24 10:20:42,575][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28366],
        [38482],
        [34305],
        [40292],
        [43460],
        [43276],
        [43981],
        [43979],
        [44547],
        [42792],
        [42849],
        [44657],
        [45319],
        [43500],
        [43843]], device='cuda:0')
[2024-07-24 10:20:42,576][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[33493],
        [31462],
        [35407],
        [39066],
        [33765],
        [46086],
        [45855],
        [48542],
        [40157],
        [48406],
        [38566],
        [35615],
        [36231],
        [39100],
        [43339]], device='cuda:0')
[2024-07-24 10:20:42,578][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25538],
        [39573],
        [50257],
        [47675],
        [47724],
        [45822],
        [45994],
        [40803],
        [34946],
        [30181],
        [30003],
        [31172],
        [31170],
        [27910],
        [28631]], device='cuda:0')
[2024-07-24 10:20:42,579][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27903],
        [12492],
        [12769],
        [10527],
        [11097],
        [11025],
        [11176],
        [11201],
        [11081],
        [10519],
        [10548],
        [11650],
        [12459],
        [10548],
        [10631]], device='cuda:0')
[2024-07-24 10:20:42,580][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23887],
        [24036],
        [20272],
        [22527],
        [21020],
        [18500],
        [15535],
        [17783],
        [24668],
        [25452],
        [23324],
        [29683],
        [27850],
        [26398],
        [21477]], device='cuda:0')
[2024-07-24 10:20:42,581][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26723],
        [22183],
        [23685],
        [21280],
        [26751],
        [20118],
        [19497],
        [24557],
        [23261],
        [23589],
        [22403],
        [25221],
        [29401],
        [27517],
        [22737]], device='cuda:0')
[2024-07-24 10:20:42,582][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[1398],
        [1399],
        [1398],
        [1397],
        [1397],
        [1375],
        [1384],
        [1386],
        [1398],
        [1450],
        [1375],
        [1358],
        [1341],
        [1376],
        [1360]], device='cuda:0')
[2024-07-24 10:20:42,583][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[33683],
        [19893],
        [19732],
        [15717],
        [11153],
        [11152],
        [11316],
        [16400],
        [13728],
        [12846],
        [12460],
        [12810],
        [11316],
        [10559],
        [12314]], device='cuda:0')
[2024-07-24 10:20:42,584][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37472],
        [37472],
        [37469],
        [37484],
        [37473],
        [37553],
        [37828],
        [37622],
        [37478],
        [38415],
        [37667],
        [37665],
        [37565],
        [37924],
        [37790]], device='cuda:0')
[2024-07-24 10:20:42,585][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13908],
        [13904],
        [13900],
        [13682],
        [13416],
        [ 8639],
        [ 9572],
        [ 7243],
        [ 6336],
        [ 6534],
        [10479],
        [ 6244],
        [ 7211],
        [ 8612],
        [10082]], device='cuda:0')
[2024-07-24 10:20:42,587][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[4489],
        [4492],
        [4488],
        [4409],
        [4442],
        [4177],
        [4150],
        [4487],
        [4478],
        [4025],
        [4227],
        [4207],
        [4254],
        [3743],
        [4193]], device='cuda:0')
[2024-07-24 10:20:42,588][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9217],
        [ 9216],
        [ 9256],
        [ 9328],
        [ 9314],
        [ 9673],
        [ 9976],
        [ 9260],
        [ 9261],
        [10818],
        [10964],
        [ 9905],
        [10005],
        [11454],
        [11257]], device='cuda:0')
[2024-07-24 10:20:42,589][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7414],
        [7952],
        [ 387],
        [ 499],
        [ 676],
        [ 525],
        [ 470],
        [ 429],
        [ 576],
        [ 414],
        [ 572],
        [ 632],
        [ 796],
        [ 484],
        [ 563]], device='cuda:0')
[2024-07-24 10:20:42,590][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8714],
        [ 9207],
        [ 6389],
        [13105],
        [12202],
        [11945],
        [13584],
        [17533],
        [18416],
        [13367],
        [14131],
        [15457],
        [18330],
        [14463],
        [14718]], device='cuda:0')
[2024-07-24 10:20:42,592][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25360],
        [23201],
        [22342],
        [15271],
        [13739],
        [ 9403],
        [13194],
        [13128],
        [12683],
        [15756],
        [ 7662],
        [ 7631],
        [15035],
        [ 8844],
        [ 6903]], device='cuda:0')
[2024-07-24 10:20:42,593][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12015],
        [21400],
        [31470],
        [30958],
        [22908],
        [20620],
        [24212],
        [24984],
        [22403],
        [24019],
        [21926],
        [21062],
        [19329],
        [19759],
        [19039]], device='cuda:0')
[2024-07-24 10:20:42,594][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[7445],
        [2560],
        [1964],
        [4057],
        [4224],
        [4118],
        [4257],
        [4331],
        [4270],
        [4089],
        [4113],
        [4423],
        [4870],
        [4142],
        [4163]], device='cuda:0')
[2024-07-24 10:20:42,596][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[8371],
        [9741],
        [8077],
        [8225],
        [8239],
        [6740],
        [7340],
        [8427],
        [8929],
        [6358],
        [6522],
        [7095],
        [8434],
        [6753],
        [6977]], device='cuda:0')
[2024-07-24 10:20:42,597][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43415],
        [45169],
        [46779],
        [46414],
        [46888],
        [48540],
        [48064],
        [47802],
        [47797],
        [48169],
        [48332],
        [48739],
        [48089],
        [48796],
        [48550]], device='cuda:0')
[2024-07-24 10:20:42,599][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26729],
        [35066],
        [47549],
        [41170],
        [40043],
        [45769],
        [44672],
        [49281],
        [46515],
        [46305],
        [37174],
        [41593],
        [34150],
        [39158],
        [34491]], device='cuda:0')
[2024-07-24 10:20:42,600][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521],
        [14521]], device='cuda:0')
[2024-07-24 10:20:42,646][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:42,647][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,647][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,647][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,647][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,648][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,648][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,648][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,648][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,649][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,649][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,649][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,649][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,650][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9807, 0.0193], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,650][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.8677e-04, 9.9901e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,650][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7951, 0.2049], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,650][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9763, 0.0237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,651][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9819, 0.0181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,652][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1590, 0.8410], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,653][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8480, 0.1520], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,655][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7247, 0.2753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,656][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4140, 0.5860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,658][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1936, 0.8064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,659][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0256, 0.9744], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,661][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8790, 0.1210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,661][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.4014, 0.1231, 0.4755], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,662][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([8.3060e-05, 7.6097e-02, 9.2382e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,662][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.5055, 0.1453, 0.3492], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,662][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([0.9723, 0.0194, 0.0083], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,663][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.9915, 0.0037, 0.0048], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,663][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([0.3707, 0.5665, 0.0628], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,663][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.3700, 0.1858, 0.4442], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,663][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.2624, 0.1642, 0.5734], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,664][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([0.9063, 0.0382, 0.0554], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,664][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([0.4388, 0.4069, 0.1542], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,664][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.0057, 0.9857, 0.0087], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,665][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([0.8950, 0.0920, 0.0130], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,665][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7045, 0.1458, 0.0850, 0.0647], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,666][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.1078e-06, 1.3007e-01, 8.4920e-01, 2.0724e-02], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,667][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4026, 0.1133, 0.3473, 0.1368], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,669][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7416, 0.1146, 0.1131, 0.0307], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,670][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7782, 0.1051, 0.0673, 0.0494], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,671][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0466, 0.8836, 0.0012, 0.0686], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,673][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6286, 0.1351, 0.1696, 0.0667], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,674][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3493, 0.1531, 0.2372, 0.2604], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,676][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2685, 0.5283, 0.1185, 0.0847], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,677][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0121, 0.9042, 0.0024, 0.0812], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,678][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0006, 0.5591, 0.0035, 0.4368], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,680][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9232, 0.0377, 0.0020, 0.0371], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,681][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0352, 0.2891, 0.3872, 0.0902, 0.1982], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,682][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([2.8070e-05, 1.3845e-01, 6.2334e-01, 4.8827e-02, 1.8935e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,683][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.3307, 0.0705, 0.1759, 0.1076, 0.3153], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,685][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.8912, 0.0662, 0.0202, 0.0144, 0.0081], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,686][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.9421, 0.0267, 0.0107, 0.0194, 0.0011], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,688][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([0.0015, 0.6154, 0.0018, 0.3773, 0.0040], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,689][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.1982, 0.1768, 0.3276, 0.0432, 0.2541], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,690][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.1342, 0.0982, 0.1626, 0.1151, 0.4899], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,692][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.8869, 0.0212, 0.0497, 0.0104, 0.0317], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,693][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([0.0021, 0.5184, 0.0028, 0.4714, 0.0053], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,694][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([2.7902e-04, 5.2183e-01, 2.3364e-03, 4.7427e-01, 1.2796e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,695][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.8410, 0.0823, 0.0094, 0.0633, 0.0041], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,697][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1700, 0.2182, 0.3157, 0.0337, 0.2057, 0.0567], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,698][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([7.7746e-07, 1.0183e-01, 5.5758e-01, 1.0781e-02, 3.2931e-01, 5.0247e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,699][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1855, 0.0827, 0.2156, 0.0865, 0.2859, 0.1438], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,700][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1434, 0.4417, 0.1462, 0.0899, 0.1344, 0.0444], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,702][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1119, 0.2222, 0.2037, 0.2030, 0.0421, 0.2172], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,703][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([1.7363e-04, 5.8723e-01, 2.5800e-03, 3.9757e-01, 1.0713e-02, 1.7328e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,704][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1739, 0.1559, 0.2502, 0.0497, 0.1354, 0.2348], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,705][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0389, 0.2155, 0.2385, 0.1840, 0.1298, 0.1934], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,707][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0528, 0.6800, 0.0781, 0.0486, 0.0810, 0.0595], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,708][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.4792e-05, 7.9719e-01, 9.4396e-03, 1.6533e-01, 2.7785e-02, 2.3866e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,709][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.6485e-05, 5.8461e-01, 2.3806e-03, 4.0247e-01, 1.3579e-03, 9.0764e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,710][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.9200, 0.0397, 0.0045, 0.0208, 0.0015, 0.0135], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,711][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2711, 0.1762, 0.2437, 0.0286, 0.2141, 0.0621, 0.0043],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,712][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.3530e-07, 1.2423e-01, 6.7216e-01, 1.1473e-02, 1.9177e-01, 2.0154e-04,
        1.6237e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,714][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0966, 0.0861, 0.1993, 0.0906, 0.2502, 0.1538, 0.1233],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,715][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1428, 0.4739, 0.1386, 0.1221, 0.0685, 0.0370, 0.0171],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,717][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1218, 0.2795, 0.1408, 0.2197, 0.0357, 0.1611, 0.0414],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,718][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.0830e-03, 4.5248e-01, 4.0808e-04, 5.2223e-01, 1.3652e-02, 9.6364e-03,
        5.0267e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,719][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2297, 0.1393, 0.2014, 0.0341, 0.1557, 0.2243, 0.0156],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,720][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0489, 0.1557, 0.1589, 0.1608, 0.0889, 0.1525, 0.2343],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,722][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1457, 0.4201, 0.1599, 0.0478, 0.1546, 0.0354, 0.0365],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,723][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.1163e-04, 5.6155e-01, 2.2406e-03, 3.9957e-01, 3.4598e-02, 1.6878e-03,
        2.4162e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,724][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.7938e-04, 6.0406e-01, 7.6436e-03, 3.3749e-01, 3.9560e-03, 1.7799e-02,
        2.8572e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,725][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.6592e-01, 1.5117e-02, 1.7027e-03, 8.5208e-03, 8.7093e-04, 7.0651e-03,
        8.0494e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,725][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1042, 0.5113, 0.2187, 0.0298, 0.1028, 0.0232, 0.0030, 0.0071],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,725][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([6.0630e-05, 1.0136e-01, 7.2720e-01, 9.4875e-03, 1.6057e-01, 3.2898e-04,
        3.5377e-04, 6.3528e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,726][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2677, 0.0540, 0.1243, 0.0542, 0.1709, 0.1279, 0.0938, 0.1072],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,726][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.4199, 0.3269, 0.1299, 0.0568, 0.0243, 0.0204, 0.0066, 0.0152],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,726][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2660, 0.2081, 0.1441, 0.2435, 0.0329, 0.0736, 0.0290, 0.0027],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,727][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([3.3498e-04, 3.4790e-01, 1.3805e-04, 6.4003e-01, 8.2636e-03, 3.1840e-03,
        1.4750e-04, 5.3769e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,727][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1089, 0.1479, 0.2259, 0.0371, 0.1061, 0.1342, 0.0157, 0.2242],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,727][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0710, 0.0841, 0.1180, 0.1063, 0.0761, 0.1226, 0.1357, 0.2862],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,728][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.5233, 0.2018, 0.1130, 0.0264, 0.0857, 0.0268, 0.0105, 0.0126],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,728][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([3.1994e-05, 2.6170e-01, 1.4087e-04, 7.1876e-01, 1.8526e-02, 6.2843e-04,
        2.1141e-04, 1.4183e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,729][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0007, 0.4947, 0.0051, 0.4252, 0.0039, 0.0188, 0.0472, 0.0044],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,730][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([9.9610e-01, 2.6582e-03, 1.9358e-04, 4.5130e-04, 6.1604e-05, 3.7625e-04,
        1.4627e-04, 1.2553e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,731][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1428, 0.2106, 0.2578, 0.0238, 0.1510, 0.0305, 0.0025, 0.0154, 0.1656],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,732][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([7.0619e-05, 1.5245e-01, 4.8913e-01, 3.1451e-02, 3.0995e-01, 9.3158e-04,
        8.9460e-04, 1.4239e-03, 1.3705e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,734][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1974, 0.0432, 0.1048, 0.0517, 0.1633, 0.1199, 0.0924, 0.1157, 0.1118],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,735][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.5019, 0.2217, 0.0755, 0.0495, 0.0558, 0.0366, 0.0199, 0.0175, 0.0216],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,736][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.5503, 0.1664, 0.0250, 0.1398, 0.0057, 0.0776, 0.0278, 0.0066, 0.0009],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,737][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.8591e-05, 3.9048e-01, 4.3154e-04, 5.9626e-01, 1.0800e-02, 1.7583e-03,
        2.1664e-04, 9.3047e-06, 2.5534e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,738][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0768, 0.0173, 0.0897, 0.0070, 0.0340, 0.0404, 0.0061, 0.0957, 0.6328],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,740][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1116, 0.0353, 0.0587, 0.0448, 0.0666, 0.0674, 0.1041, 0.1361, 0.3753],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,741][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.4259, 0.2550, 0.0647, 0.0332, 0.1345, 0.0338, 0.0259, 0.0085, 0.0186],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,742][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([1.4674e-05, 3.4637e-01, 6.1431e-04, 6.3789e-01, 1.4825e-02, 1.3742e-04,
        8.8370e-05, 1.6064e-06, 6.3599e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,744][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0021, 0.4251, 0.0048, 0.4627, 0.0043, 0.0337, 0.0604, 0.0057, 0.0012],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,745][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([9.7809e-01, 1.1276e-02, 2.1887e-03, 2.7911e-03, 4.3403e-04, 2.1303e-03,
        8.4193e-04, 2.5025e-04, 2.0009e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,746][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1537, 0.1577, 0.1479, 0.0304, 0.1811, 0.0686, 0.0076, 0.0235, 0.2122,
        0.0173], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,747][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.7300e-07, 7.3265e-02, 6.8327e-01, 9.3301e-03, 2.2812e-01, 1.2762e-04,
        7.9781e-05, 4.2274e-04, 4.8574e-03, 5.3299e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,748][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0824, 0.0584, 0.1153, 0.0513, 0.1739, 0.1108, 0.0954, 0.1276, 0.1325,
        0.0524], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,750][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0455, 0.3870, 0.2996, 0.0638, 0.1088, 0.0296, 0.0081, 0.0217, 0.0262,
        0.0096], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,751][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0380, 0.4377, 0.0995, 0.2213, 0.0277, 0.0732, 0.0230, 0.0033, 0.0032,
        0.0730], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,752][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.5741e-04, 8.3166e-01, 1.0338e-03, 1.5990e-01, 4.0199e-03, 2.4261e-03,
        1.4291e-04, 5.2876e-06, 1.6676e-05, 6.3519e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,754][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1000, 0.0113, 0.0285, 0.0034, 0.0276, 0.0293, 0.0041, 0.0607, 0.7216,
        0.0135], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,755][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0387, 0.0673, 0.0746, 0.0684, 0.0682, 0.0967, 0.1175, 0.1279, 0.1876,
        0.1531], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,757][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0384, 0.5761, 0.1123, 0.0281, 0.1350, 0.0242, 0.0215, 0.0128, 0.0101,
        0.0417], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,757][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.0549e-04, 8.6145e-01, 4.1154e-03, 1.2345e-01, 1.0274e-02, 3.2100e-04,
        7.4304e-05, 6.6074e-07, 2.5051e-05, 1.8610e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,759][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0007, 0.4723, 0.0079, 0.4048, 0.0048, 0.0200, 0.0431, 0.0048, 0.0014,
        0.0401], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,760][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.2782e-01, 1.7626e-02, 3.2244e-03, 8.7441e-03, 2.0495e-03, 7.4898e-03,
        7.1410e-04, 2.8482e-03, 2.4265e-02, 5.2146e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,761][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1460, 0.1379, 0.0777, 0.0527, 0.1197, 0.1305, 0.0104, 0.0383, 0.2123,
        0.0373, 0.0373], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,762][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.9640e-06, 1.2399e-01, 6.1341e-01, 1.4644e-02, 2.4033e-01, 1.7795e-04,
        1.4091e-04, 8.5042e-04, 5.2980e-03, 7.9010e-04, 3.6731e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,763][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1242, 0.0428, 0.0956, 0.0427, 0.1476, 0.1089, 0.0985, 0.1123, 0.1330,
        0.0390, 0.0555], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,765][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0903, 0.4843, 0.1841, 0.0725, 0.0604, 0.0282, 0.0070, 0.0217, 0.0254,
        0.0082, 0.0179], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,766][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0769, 0.3657, 0.0978, 0.1682, 0.0270, 0.0932, 0.0268, 0.0056, 0.0036,
        0.0660, 0.0692], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,767][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.1673e-03, 8.3237e-01, 7.5988e-04, 1.5078e-01, 3.6964e-03, 2.9106e-03,
        3.1857e-04, 9.8217e-06, 3.9169e-05, 2.2170e-03, 5.7250e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,768][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0594, 0.0064, 0.0177, 0.0035, 0.0162, 0.0309, 0.0041, 0.0372, 0.7985,
        0.0170, 0.0091], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,770][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0509, 0.0475, 0.0488, 0.0697, 0.0507, 0.0701, 0.1374, 0.0846, 0.1719,
        0.1317, 0.1367], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,771][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0578, 0.5375, 0.0499, 0.0283, 0.1180, 0.0357, 0.0340, 0.0121, 0.0140,
        0.0577, 0.0551], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,772][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.5778e-04, 8.5712e-01, 1.5560e-03, 1.3418e-01, 5.1670e-03, 3.1807e-04,
        1.1295e-04, 9.3747e-07, 3.4646e-05, 3.9489e-04, 6.6063e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,774][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0007, 0.4999, 0.0068, 0.3180, 0.0045, 0.0253, 0.0451, 0.0044, 0.0015,
        0.0323, 0.0616], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,775][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.7811, 0.0330, 0.0043, 0.0197, 0.0049, 0.0329, 0.0030, 0.0115, 0.0706,
        0.0145, 0.0247], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,777][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0961, 0.2460, 0.1743, 0.0490, 0.1214, 0.0594, 0.0030, 0.0132, 0.1069,
        0.0211, 0.0221, 0.0875], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,778][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([2.5828e-05, 1.0079e-01, 6.3391e-01, 1.8284e-02, 2.1873e-01, 1.2072e-03,
        5.3805e-04, 2.3197e-03, 2.1561e-02, 1.4445e-03, 5.1202e-04, 6.7849e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,779][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0903, 0.0338, 0.0946, 0.0328, 0.1288, 0.0897, 0.0599, 0.0937, 0.1019,
        0.0522, 0.0646, 0.1577], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,780][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.4884, 0.2608, 0.0727, 0.0337, 0.0194, 0.0371, 0.0057, 0.0240, 0.0296,
        0.0074, 0.0124, 0.0087], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,782][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1027, 0.1712, 0.0150, 0.1962, 0.0032, 0.1418, 0.0306, 0.0293, 0.0052,
        0.1365, 0.1133, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,783][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([3.2872e-05, 2.1020e-01, 7.0328e-04, 7.4052e-01, 1.7987e-02, 7.1177e-03,
        1.1548e-03, 1.0861e-04, 4.3571e-04, 6.8126e-03, 1.4233e-02, 7.0272e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,784][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0613, 0.0181, 0.0659, 0.0104, 0.0370, 0.0542, 0.0074, 0.0521, 0.5629,
        0.0318, 0.0253, 0.0734], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,786][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0159, 0.0503, 0.0550, 0.0513, 0.0327, 0.0445, 0.0516, 0.1071, 0.1170,
        0.1316, 0.1193, 0.2239], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,787][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.4968, 0.1297, 0.0567, 0.0163, 0.0860, 0.0428, 0.0287, 0.0244, 0.0160,
        0.0217, 0.0259, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,788][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([3.9200e-05, 2.9280e-01, 1.8062e-03, 6.3237e-01, 6.5307e-02, 1.3507e-03,
        8.1844e-04, 6.4219e-06, 3.5087e-04, 1.8909e-03, 3.0397e-03, 2.2381e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,788][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0010, 0.3137, 0.0034, 0.4074, 0.0029, 0.0322, 0.0606, 0.0043, 0.0010,
        0.0530, 0.1199, 0.0007], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,789][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.7585, 0.0492, 0.0137, 0.0300, 0.0039, 0.0347, 0.0080, 0.0110, 0.0398,
        0.0127, 0.0260, 0.0126], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:42,789][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.0100, 0.2010, 0.2344, 0.0489, 0.1239, 0.0530, 0.0037, 0.0079, 0.1284,
        0.0154, 0.0189, 0.0382, 0.1164], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,789][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([2.9195e-05, 2.0629e-01, 5.3477e-01, 5.2256e-02, 1.4493e-01, 1.2176e-03,
        1.2716e-03, 5.7964e-03, 4.4588e-02, 2.9168e-03, 1.3921e-03, 1.2743e-03,
        3.2705e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,790][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([0.1372, 0.0225, 0.0491, 0.0282, 0.0842, 0.0652, 0.0477, 0.0922, 0.0831,
        0.0395, 0.0542, 0.1133, 0.1837], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,790][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([0.4401, 0.2851, 0.0702, 0.0491, 0.0155, 0.0242, 0.0060, 0.0255, 0.0393,
        0.0066, 0.0164, 0.0199, 0.0020], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,790][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.4752, 0.0879, 0.0168, 0.0686, 0.0024, 0.0949, 0.0226, 0.0082, 0.0049,
        0.0777, 0.0900, 0.0494, 0.0014], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,791][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([2.3075e-04, 2.4656e-01, 3.2987e-04, 6.5152e-01, 8.0073e-03, 1.1555e-02,
        2.1879e-03, 3.8113e-04, 3.3950e-04, 1.3850e-02, 6.3054e-02, 1.8764e-03,
        1.0769e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,791][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.0301, 0.0155, 0.0360, 0.0029, 0.0230, 0.0249, 0.0018, 0.0350, 0.6841,
        0.0116, 0.0057, 0.0335, 0.0959], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,793][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0165, 0.0452, 0.0467, 0.0418, 0.1188, 0.0715, 0.0577, 0.0949, 0.1174,
        0.0991, 0.0785, 0.0604, 0.1516], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,794][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([0.5589, 0.0532, 0.1250, 0.0158, 0.1012, 0.0280, 0.0144, 0.0348, 0.0091,
        0.0141, 0.0203, 0.0179, 0.0074], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,795][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([3.3125e-04, 2.3485e-01, 7.0813e-04, 7.3438e-01, 1.7286e-02, 1.1750e-03,
        6.6210e-04, 7.7149e-05, 1.0731e-03, 2.5380e-03, 6.4676e-03, 3.9925e-04,
        5.8712e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,796][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([5.4640e-04, 4.3082e-01, 3.2448e-03, 3.7682e-01, 1.8637e-03, 1.5929e-02,
        2.6227e-02, 4.0926e-03, 8.7197e-04, 4.4148e-02, 9.4831e-02, 4.3063e-04,
        1.6807e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,797][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([0.6263, 0.1156, 0.0166, 0.0604, 0.0048, 0.0290, 0.0063, 0.0099, 0.0291,
        0.0240, 0.0600, 0.0125, 0.0056], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:42,799][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1295, 0.1325, 0.1600, 0.0192, 0.0876, 0.0334, 0.0026, 0.0131, 0.0989,
        0.0112, 0.0150, 0.0780, 0.1264, 0.0927], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,799][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.9213e-07, 7.2280e-02, 6.0213e-01, 1.2476e-02, 3.0393e-01, 2.3303e-04,
        1.3431e-04, 8.4949e-04, 4.9208e-03, 3.6244e-04, 1.5100e-04, 1.4692e-04,
        2.2086e-03, 1.8085e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,801][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0174, 0.0337, 0.0881, 0.0325, 0.1089, 0.0694, 0.0443, 0.0774, 0.0850,
        0.0391, 0.0490, 0.0774, 0.1756, 0.1024], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,802][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0331, 0.4125, 0.2043, 0.0702, 0.1451, 0.0257, 0.0072, 0.0175, 0.0169,
        0.0071, 0.0111, 0.0228, 0.0126, 0.0139], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,804][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0631, 0.2317, 0.0897, 0.2054, 0.0122, 0.1112, 0.0188, 0.0093, 0.0027,
        0.1038, 0.0921, 0.0403, 0.0042, 0.0157], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,805][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([3.9106e-05, 8.0050e-01, 6.0707e-04, 1.9089e-01, 3.1675e-03, 1.6419e-03,
        7.4330e-05, 1.6400e-06, 3.8628e-06, 4.7386e-04, 1.6702e-03, 3.3254e-05,
        6.0698e-06, 8.8964e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,806][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0431, 0.0095, 0.0327, 0.0034, 0.0144, 0.0278, 0.0021, 0.0513, 0.4122,
        0.0114, 0.0084, 0.0447, 0.0784, 0.2606], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,808][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0095, 0.0684, 0.0649, 0.0532, 0.0397, 0.0570, 0.0470, 0.0928, 0.1351,
        0.1179, 0.0952, 0.0930, 0.0286, 0.0976], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,809][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0340, 0.2710, 0.1457, 0.0205, 0.2418, 0.0265, 0.0269, 0.0268, 0.0065,
        0.0316, 0.0259, 0.0444, 0.0370, 0.0614], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,810][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.0236e-05, 9.4908e-01, 4.0397e-04, 4.8300e-02, 1.7114e-03, 7.1527e-05,
        1.2310e-05, 3.3664e-08, 1.6078e-06, 6.5462e-05, 1.1974e-04, 2.6946e-06,
        5.5459e-07, 2.1803e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,811][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([9.7237e-05, 3.4149e-01, 2.2116e-03, 4.5611e-01, 1.6383e-03, 1.8339e-02,
        2.8936e-02, 3.0306e-03, 4.8166e-04, 3.1597e-02, 1.1525e-01, 2.4733e-04,
        1.0996e-04, 4.6851e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,812][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([9.1875e-01, 2.4279e-02, 5.6987e-03, 7.2284e-03, 8.3949e-04, 9.2870e-03,
        1.5356e-03, 2.4437e-03, 1.2091e-02, 3.9054e-03, 7.6824e-03, 2.3423e-03,
        1.2375e-03, 2.6770e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:42,813][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0888, 0.1197, 0.0834, 0.0326, 0.1110, 0.0601, 0.0052, 0.0154, 0.1287,
        0.0169, 0.0206, 0.0848, 0.1280, 0.0884, 0.0164], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,814][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.1117e-05, 1.2537e-01, 5.8099e-01, 1.2692e-02, 2.6507e-01, 3.3320e-04,
        2.1805e-04, 1.2214e-03, 9.3631e-03, 8.7946e-04, 4.1691e-04, 2.4881e-04,
        2.4616e-03, 1.7832e-04, 5.3724e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,816][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0262, 0.0320, 0.0785, 0.0366, 0.1091, 0.0680, 0.0550, 0.0766, 0.0751,
        0.0337, 0.0445, 0.0712, 0.1612, 0.0833, 0.0490], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,817][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1703, 0.4685, 0.1406, 0.0586, 0.0338, 0.0297, 0.0053, 0.0163, 0.0195,
        0.0077, 0.0160, 0.0080, 0.0038, 0.0099, 0.0121], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,819][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0961, 0.3282, 0.0388, 0.1175, 0.0125, 0.1029, 0.0181, 0.0045, 0.0043,
        0.0902, 0.0577, 0.0417, 0.0055, 0.0421, 0.0399], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,820][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.4752e-03, 8.3510e-01, 1.7793e-04, 1.1480e-01, 1.9091e-03, 2.7317e-03,
        3.2379e-04, 5.0334e-06, 1.2323e-05, 3.3377e-03, 9.6804e-03, 1.0936e-04,
        4.5175e-05, 5.3944e-03, 1.9898e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,821][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0557, 0.0050, 0.0189, 0.0026, 0.0143, 0.0211, 0.0023, 0.0270, 0.5450,
        0.0131, 0.0080, 0.0326, 0.0767, 0.1716, 0.0061], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,823][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0202, 0.0394, 0.0515, 0.0545, 0.0463, 0.0457, 0.0591, 0.0718, 0.1306,
        0.0915, 0.0880, 0.0934, 0.0355, 0.0658, 0.1066], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,824][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1814, 0.2904, 0.0718, 0.0160, 0.1116, 0.0304, 0.0303, 0.0140, 0.0074,
        0.0327, 0.0390, 0.0316, 0.0132, 0.0469, 0.0834], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,825][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.9866e-03, 8.4854e-01, 4.1186e-04, 1.3294e-01, 2.7936e-03, 3.9108e-04,
        1.3182e-04, 5.3917e-07, 2.5192e-05, 1.1727e-03, 1.7162e-03, 3.9922e-05,
        1.5380e-05, 4.5705e-03, 5.2741e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,826][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.3063e-04, 4.4685e-01, 5.3975e-03, 3.6418e-01, 4.3958e-03, 1.4952e-02,
        2.8083e-02, 3.6731e-03, 9.3050e-04, 3.9753e-02, 7.9783e-02, 3.8003e-04,
        3.5221e-04, 5.7182e-04, 1.0468e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,827][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3460, 0.0972, 0.0232, 0.0700, 0.0094, 0.0426, 0.0024, 0.0486, 0.1968,
        0.0358, 0.0622, 0.0137, 0.0187, 0.0193, 0.0141], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:42,874][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:42,875][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,876][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,877][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,879][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,880][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,880][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,880][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,880][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,881][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,881][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,881][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,882][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:42,882][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1356, 0.8644], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,882][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.8677e-04, 9.9901e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,883][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7141, 0.2859], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,883][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9763, 0.0237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,883][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9819, 0.0181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,884][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1590, 0.8410], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,885][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1618, 0.8382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,886][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([9.9959e-01, 4.1030e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,887][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4140, 0.5860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,888][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1936, 0.8064], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,889][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9968, 0.0032], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,889][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9324, 0.0676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:42,890][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.1154, 0.1983, 0.6863], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,890][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([8.3060e-05, 7.6097e-02, 9.2382e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,890][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.9006, 0.0561, 0.0433], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,892][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.9723, 0.0194, 0.0083], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,893][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([0.9915, 0.0037, 0.0048], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,894][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([0.3707, 0.5665, 0.0628], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,896][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([0.0209, 0.2968, 0.6823], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,897][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([9.9915e-01, 8.3893e-05, 7.6642e-04], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,898][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.9063, 0.0382, 0.0554], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,899][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([0.4388, 0.4069, 0.1542], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,900][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([9.8680e-01, 5.9978e-05, 1.3135e-02], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,902][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([0.0222, 0.4633, 0.5145], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:42,903][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0063, 0.2475, 0.7108, 0.0354], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,904][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.1078e-06, 1.3007e-01, 8.4920e-01, 2.0724e-02], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,905][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1387, 0.2572, 0.2648, 0.3394], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,907][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7416, 0.1146, 0.1131, 0.0307], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,908][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7782, 0.1051, 0.0673, 0.0494], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,909][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0466, 0.8836, 0.0012, 0.0686], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,911][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0190, 0.3547, 0.5754, 0.0510], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,912][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.8527e-01, 4.0090e-03, 9.8970e-03, 8.1933e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,913][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2685, 0.5283, 0.1185, 0.0847], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,915][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0121, 0.9042, 0.0024, 0.0812], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,916][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.4467e-01, 7.6483e-03, 8.4756e-01, 1.2596e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,917][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0512, 0.2666, 0.4795, 0.2028], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:42,918][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0988, 0.3311, 0.4149, 0.0434, 0.1118], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,919][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([2.8070e-05, 1.3845e-01, 6.2334e-01, 4.8827e-02, 1.8935e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,921][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.4449, 0.1683, 0.0636, 0.3084, 0.0149], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,922][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.8912, 0.0662, 0.0202, 0.0144, 0.0081], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,923][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.9421, 0.0267, 0.0107, 0.0194, 0.0011], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,925][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0015, 0.6154, 0.0018, 0.3773, 0.0040], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,926][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0077, 0.4146, 0.3421, 0.0565, 0.1791], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,927][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([9.9601e-01, 9.8284e-04, 2.5876e-03, 1.2451e-04, 2.9259e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,928][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.8869, 0.0212, 0.0497, 0.0104, 0.0317], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,928][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([0.0021, 0.5184, 0.0028, 0.4714, 0.0053], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,928][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([8.5698e-01, 7.9123e-04, 1.3320e-01, 3.0067e-05, 8.9933e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,929][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([0.0111, 0.3485, 0.2564, 0.1479, 0.2361], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:42,929][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([3.7882e-04, 1.4191e-01, 5.7881e-01, 1.0077e-02, 2.6556e-01, 3.2651e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,929][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([7.7746e-07, 1.0183e-01, 5.5758e-01, 1.0781e-02, 3.2931e-01, 5.0247e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,930][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0100, 0.3487, 0.3620, 0.1860, 0.0755, 0.0178], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,930][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1434, 0.4417, 0.1462, 0.0899, 0.1344, 0.0444], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,931][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1119, 0.2222, 0.2037, 0.2030, 0.0421, 0.2172], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,931][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.7363e-04, 5.8723e-01, 2.5800e-03, 3.9757e-01, 1.0713e-02, 1.7328e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,932][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0008, 0.3179, 0.3972, 0.0290, 0.2474, 0.0077], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,934][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.8522, 0.0466, 0.0562, 0.0086, 0.0212, 0.0153], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,935][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0528, 0.6800, 0.0781, 0.0486, 0.0810, 0.0595], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,936][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.4792e-05, 7.9719e-01, 9.4396e-03, 1.6533e-01, 2.7785e-02, 2.3866e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,937][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([3.9902e-02, 1.4907e-02, 8.7957e-01, 1.5390e-04, 6.5452e-02, 1.4139e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,938][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0082, 0.2743, 0.2045, 0.0856, 0.3674, 0.0599], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:42,938][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.8923e-05, 2.0169e-01, 6.4898e-01, 7.4884e-03, 1.3999e-01, 1.6969e-03,
        9.1964e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,939][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.3530e-07, 1.2423e-01, 6.7216e-01, 1.1473e-02, 1.9177e-01, 2.0154e-04,
        1.6237e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,941][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0054, 0.4170, 0.2896, 0.2194, 0.0541, 0.0079, 0.0067],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,942][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1428, 0.4739, 0.1386, 0.1221, 0.0685, 0.0370, 0.0171],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,944][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1218, 0.2795, 0.1408, 0.2197, 0.0357, 0.1611, 0.0414],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,945][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.0830e-03, 4.5248e-01, 4.0808e-04, 5.2223e-01, 1.3652e-02, 9.6364e-03,
        5.0267e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,945][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.4806e-04, 4.4541e-01, 4.3315e-01, 2.2878e-02, 9.5475e-02, 2.2674e-03,
        5.7108e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,947][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4026, 0.2062, 0.2702, 0.0263, 0.0649, 0.0173, 0.0125],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,948][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1457, 0.4201, 0.1599, 0.0478, 0.1546, 0.0354, 0.0365],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,949][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.1163e-04, 5.6155e-01, 2.2406e-03, 3.9957e-01, 3.4598e-02, 1.6878e-03,
        2.4162e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,950][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.6240e-03, 1.8074e-02, 9.3816e-01, 1.3138e-04, 3.8002e-02, 5.6453e-06,
        3.4186e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,951][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0019, 0.3407, 0.2899, 0.0816, 0.2553, 0.0261, 0.0045],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:42,953][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0010, 0.4274, 0.3628, 0.0248, 0.1728, 0.0079, 0.0005, 0.0028],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,954][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([6.0630e-05, 1.0136e-01, 7.2720e-01, 9.4875e-03, 1.6057e-01, 3.2898e-04,
        3.5377e-04, 6.3528e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,955][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.4174, 0.2481, 0.1354, 0.1191, 0.0285, 0.0141, 0.0149, 0.0224],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,957][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.4199, 0.3269, 0.1299, 0.0568, 0.0243, 0.0204, 0.0066, 0.0152],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,958][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.2660, 0.2081, 0.1441, 0.2435, 0.0329, 0.0736, 0.0290, 0.0027],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,959][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([3.3498e-04, 3.4790e-01, 1.3805e-04, 6.4003e-01, 8.2636e-03, 3.1840e-03,
        1.4750e-04, 5.3769e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,961][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0046, 0.3843, 0.4309, 0.0296, 0.1228, 0.0073, 0.0026, 0.0180],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,961][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([9.6372e-01, 1.6136e-02, 5.2362e-03, 3.4142e-03, 3.1267e-03, 4.1266e-03,
        3.5181e-03, 7.2634e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,963][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.5233, 0.2018, 0.1130, 0.0264, 0.0857, 0.0268, 0.0105, 0.0126],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,964][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([3.1994e-05, 2.6170e-01, 1.4087e-04, 7.1876e-01, 1.8526e-02, 6.2843e-04,
        2.1141e-04, 1.4183e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,965][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([5.5199e-02, 1.4600e-02, 9.1061e-01, 2.8352e-04, 1.7844e-02, 2.0727e-05,
        1.1315e-05, 1.4346e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,966][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.2483, 0.1463, 0.2498, 0.0806, 0.2075, 0.0291, 0.0251, 0.0133],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:42,968][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0190, 0.4732, 0.2340, 0.0339, 0.1931, 0.0261, 0.0012, 0.0027, 0.0169],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,969][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([7.0619e-05, 1.5245e-01, 4.8913e-01, 3.1451e-02, 3.0995e-01, 9.3158e-04,
        8.9460e-04, 1.4239e-03, 1.3705e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,970][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.2604, 0.1906, 0.1487, 0.2104, 0.0264, 0.0222, 0.0245, 0.0537, 0.0632],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,971][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.5019, 0.2217, 0.0755, 0.0495, 0.0558, 0.0366, 0.0199, 0.0175, 0.0216],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,973][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.5503, 0.1664, 0.0250, 0.1398, 0.0057, 0.0776, 0.0278, 0.0066, 0.0009],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,974][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.8591e-05, 3.9048e-01, 4.3154e-04, 5.9626e-01, 1.0800e-02, 1.7583e-03,
        2.1664e-04, 9.3047e-06, 2.5534e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,975][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0489, 0.3273, 0.3374, 0.0522, 0.1485, 0.0290, 0.0069, 0.0205, 0.0292],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,976][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([9.8876e-01, 4.0732e-03, 2.5483e-03, 6.2503e-04, 1.0137e-03, 1.6596e-03,
        1.0192e-03, 5.6149e-05, 2.4206e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,978][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.4259, 0.2550, 0.0647, 0.0332, 0.1345, 0.0338, 0.0259, 0.0085, 0.0186],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,979][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.4674e-05, 3.4637e-01, 6.1431e-04, 6.3789e-01, 1.4825e-02, 1.3742e-04,
        8.8370e-05, 1.6064e-06, 6.3599e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,979][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([5.7375e-01, 8.5787e-03, 3.7799e-01, 2.7199e-04, 1.8297e-02, 3.7644e-05,
        3.1830e-05, 2.8813e-03, 1.8169e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,981][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3785, 0.0665, 0.1572, 0.0873, 0.1507, 0.0541, 0.0772, 0.0241, 0.0043],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:42,982][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([8.5141e-05, 1.6774e-01, 6.1300e-01, 9.2079e-03, 2.0479e-01, 1.7784e-03,
        8.4272e-05, 3.2328e-04, 2.4156e-03, 5.7735e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,983][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.7300e-07, 7.3265e-02, 6.8327e-01, 9.3301e-03, 2.2812e-01, 1.2762e-04,
        7.9781e-05, 4.2274e-04, 4.8574e-03, 5.3299e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,984][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0051, 0.2822, 0.3571, 0.1524, 0.0397, 0.0081, 0.0061, 0.0415, 0.0860,
        0.0218], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,986][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0455, 0.3870, 0.2996, 0.0638, 0.1088, 0.0296, 0.0081, 0.0217, 0.0262,
        0.0096], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,987][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0380, 0.4377, 0.0995, 0.2213, 0.0277, 0.0732, 0.0230, 0.0033, 0.0032,
        0.0730], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,988][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.5741e-04, 8.3166e-01, 1.0338e-03, 1.5990e-01, 4.0199e-03, 2.4261e-03,
        1.4291e-04, 5.2876e-06, 1.6676e-05, 6.3519e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,989][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.2969e-04, 2.0518e-01, 6.4502e-01, 1.9813e-02, 1.0032e-01, 2.0551e-03,
        4.3361e-04, 5.3112e-03, 1.7065e-02, 4.6740e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,990][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([7.1346e-01, 6.3398e-02, 1.4984e-01, 6.7738e-03, 3.1527e-02, 7.6828e-03,
        6.0731e-03, 5.4883e-04, 1.7000e-03, 1.8992e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,991][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0384, 0.5761, 0.1123, 0.0281, 0.1350, 0.0242, 0.0215, 0.0128, 0.0101,
        0.0417], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,991][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.0549e-04, 8.6145e-01, 4.1154e-03, 1.2345e-01, 1.0274e-02, 3.2100e-04,
        7.4304e-05, 6.6074e-07, 2.5051e-05, 1.8610e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,991][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.4407e-02, 1.1247e-02, 9.2290e-01, 1.6127e-04, 4.2019e-02, 7.3458e-06,
        4.9417e-06, 1.0078e-03, 8.2423e-03, 3.3635e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,992][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.3967e-05, 1.6223e-01, 4.0414e-01, 6.1623e-02, 3.1983e-01, 5.6047e-03,
        3.4792e-03, 2.3064e-02, 1.5845e-02, 4.0821e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:42,992][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([6.0548e-04, 2.0063e-01, 6.0376e-01, 1.4435e-02, 1.6999e-01, 3.2273e-03,
        2.2947e-04, 9.9389e-04, 3.9131e-03, 1.1198e-03, 1.1024e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,993][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.9640e-06, 1.2399e-01, 6.1341e-01, 1.4644e-02, 2.4033e-01, 1.7795e-04,
        1.4091e-04, 8.5042e-04, 5.2980e-03, 7.9010e-04, 3.6731e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,993][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0208, 0.2696, 0.2424, 0.1823, 0.0397, 0.0181, 0.0103, 0.0672, 0.0797,
        0.0239, 0.0460], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,993][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0903, 0.4843, 0.1841, 0.0725, 0.0604, 0.0282, 0.0070, 0.0217, 0.0254,
        0.0082, 0.0179], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,994][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0769, 0.3657, 0.0978, 0.1682, 0.0270, 0.0932, 0.0268, 0.0056, 0.0036,
        0.0660, 0.0692], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,995][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.1673e-03, 8.3237e-01, 7.5988e-04, 1.5078e-01, 3.6964e-03, 2.9106e-03,
        3.1857e-04, 9.8217e-06, 3.9169e-05, 2.2170e-03, 5.7250e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,997][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0011, 0.2123, 0.5822, 0.0284, 0.1452, 0.0035, 0.0010, 0.0060, 0.0101,
        0.0057, 0.0046], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,997][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([7.8577e-01, 5.8712e-02, 8.1966e-02, 6.4941e-03, 2.2216e-02, 7.6470e-03,
        5.3709e-03, 6.1305e-04, 1.2889e-03, 1.3524e-02, 1.6396e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:42,999][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0578, 0.5375, 0.0499, 0.0283, 0.1180, 0.0357, 0.0340, 0.0121, 0.0140,
        0.0577, 0.0551], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,000][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.5778e-04, 8.5712e-01, 1.5560e-03, 1.3418e-01, 5.1670e-03, 3.1807e-04,
        1.1295e-04, 9.3747e-07, 3.4646e-05, 3.9489e-04, 6.6063e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,001][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.7653e-02, 2.3926e-02, 8.9112e-01, 3.9889e-04, 3.9056e-02, 2.1093e-05,
        1.4469e-05, 1.2903e-03, 6.4262e-03, 1.0004e-05, 8.2398e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,002][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0005, 0.2458, 0.3071, 0.0972, 0.2633, 0.0136, 0.0075, 0.0242, 0.0186,
        0.0087, 0.0135], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,004][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0065, 0.3751, 0.3424, 0.0325, 0.1735, 0.0096, 0.0006, 0.0052, 0.0188,
        0.0033, 0.0025, 0.0299], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,005][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([2.5828e-05, 1.0079e-01, 6.3391e-01, 1.8284e-02, 2.1873e-01, 1.2072e-03,
        5.3805e-04, 2.3197e-03, 2.1561e-02, 1.4445e-03, 5.1202e-04, 6.7849e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,006][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0467, 0.2872, 0.1702, 0.1706, 0.0187, 0.0407, 0.0112, 0.0811, 0.0621,
        0.0294, 0.0563, 0.0258], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,008][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.4884, 0.2608, 0.0727, 0.0337, 0.0194, 0.0371, 0.0057, 0.0240, 0.0296,
        0.0074, 0.0124, 0.0087], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,009][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.1027, 0.1712, 0.0150, 0.1962, 0.0032, 0.1418, 0.0306, 0.0293, 0.0052,
        0.1365, 0.1133, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,010][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([3.2872e-05, 2.1020e-01, 7.0328e-04, 7.4052e-01, 1.7987e-02, 7.1177e-03,
        1.1548e-03, 1.0861e-04, 4.3571e-04, 6.8126e-03, 1.4233e-02, 7.0272e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,012][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0020, 0.2545, 0.3348, 0.0505, 0.1137, 0.0225, 0.0036, 0.0590, 0.1070,
        0.0173, 0.0167, 0.0185], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,013][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.7499, 0.0628, 0.0631, 0.0104, 0.0205, 0.0253, 0.0081, 0.0021, 0.0046,
        0.0222, 0.0280, 0.0029], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,014][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.4968, 0.1297, 0.0567, 0.0163, 0.0860, 0.0428, 0.0287, 0.0244, 0.0160,
        0.0217, 0.0259, 0.0550], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,015][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([3.9200e-05, 2.9280e-01, 1.8062e-03, 6.3237e-01, 6.5307e-02, 1.3507e-03,
        8.1844e-04, 6.4219e-06, 3.5087e-04, 1.8909e-03, 3.0397e-03, 2.2381e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,016][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([2.4736e-01, 1.9683e-02, 6.7824e-01, 3.1671e-04, 3.3126e-02, 3.5781e-05,
        2.3872e-05, 3.6035e-03, 1.7429e-02, 7.5116e-06, 6.5328e-05, 1.1293e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,018][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0019, 0.1617, 0.0570, 0.1760, 0.0890, 0.0622, 0.0287, 0.0956, 0.0344,
        0.0237, 0.0176, 0.2522], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,019][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.0055, 0.4855, 0.2747, 0.0464, 0.0776, 0.0197, 0.0011, 0.0062, 0.0149,
        0.0070, 0.0044, 0.0513, 0.0056], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,020][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([2.9195e-05, 2.0629e-01, 5.3477e-01, 5.2256e-02, 1.4493e-01, 1.2176e-03,
        1.2716e-03, 5.7964e-03, 4.4588e-02, 2.9168e-03, 1.3921e-03, 1.2743e-03,
        3.2705e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,021][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.1068, 0.1988, 0.0862, 0.2151, 0.0095, 0.0169, 0.0106, 0.1520, 0.1205,
        0.0216, 0.0452, 0.0135, 0.0032], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,023][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.4401, 0.2851, 0.0702, 0.0491, 0.0155, 0.0242, 0.0060, 0.0255, 0.0393,
        0.0066, 0.0164, 0.0199, 0.0020], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,024][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([0.4752, 0.0879, 0.0168, 0.0686, 0.0024, 0.0949, 0.0226, 0.0082, 0.0049,
        0.0777, 0.0900, 0.0494, 0.0014], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,025][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([2.3075e-04, 2.4656e-01, 3.2987e-04, 6.5152e-01, 8.0073e-03, 1.1555e-02,
        2.1879e-03, 3.8113e-04, 3.3950e-04, 1.3850e-02, 6.3054e-02, 1.8764e-03,
        1.0769e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,027][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([0.0009, 0.3794, 0.2399, 0.0480, 0.0899, 0.0119, 0.0032, 0.0660, 0.0891,
        0.0203, 0.0137, 0.0200, 0.0177], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,028][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([8.8406e-01, 3.0407e-02, 6.8384e-02, 2.2944e-03, 4.9704e-03, 1.5859e-03,
        9.0569e-04, 1.6859e-04, 1.5525e-03, 2.1475e-03, 1.9527e-03, 1.9538e-04,
        1.3783e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,029][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([0.5589, 0.0532, 0.1250, 0.0158, 0.1012, 0.0280, 0.0144, 0.0348, 0.0091,
        0.0141, 0.0203, 0.0179, 0.0074], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,030][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([3.3125e-04, 2.3485e-01, 7.0813e-04, 7.3438e-01, 1.7286e-02, 1.1750e-03,
        6.6210e-04, 7.7149e-05, 1.0731e-03, 2.5380e-03, 6.4676e-03, 3.9925e-04,
        5.8712e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,031][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([8.3053e-01, 3.1565e-03, 1.3843e-01, 1.0935e-04, 9.9879e-03, 1.0427e-05,
        1.2403e-05, 3.8581e-03, 1.3783e-02, 3.3489e-06, 3.2079e-05, 4.2030e-05,
        4.5218e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,032][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([3.5201e-05, 2.8367e-01, 1.2758e-01, 8.6589e-02, 7.3676e-02, 1.9785e-02,
        9.1466e-03, 2.3367e-01, 7.2502e-02, 2.0288e-02, 1.2267e-02, 3.9359e-02,
        2.1425e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,033][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([8.7447e-05, 1.4617e-01, 5.0695e-01, 9.6810e-03, 3.2170e-01, 2.7856e-03,
        1.3537e-04, 5.7317e-04, 2.2671e-03, 5.2646e-04, 3.8581e-04, 2.4042e-03,
        5.4661e-03, 8.6951e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,034][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.9213e-07, 7.2280e-02, 6.0213e-01, 1.2476e-02, 3.0393e-01, 2.3303e-04,
        1.3431e-04, 8.4949e-04, 4.9208e-03, 3.6244e-04, 1.5100e-04, 1.4692e-04,
        2.2086e-03, 1.8085e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,035][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0009, 0.2410, 0.4394, 0.1558, 0.0509, 0.0044, 0.0033, 0.0275, 0.0219,
        0.0132, 0.0252, 0.0042, 0.0065, 0.0058], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,037][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0331, 0.4125, 0.2043, 0.0702, 0.1451, 0.0257, 0.0072, 0.0175, 0.0169,
        0.0071, 0.0111, 0.0228, 0.0126, 0.0139], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,038][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0631, 0.2317, 0.0897, 0.2054, 0.0122, 0.1112, 0.0188, 0.0093, 0.0027,
        0.1038, 0.0921, 0.0403, 0.0042, 0.0157], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,039][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([3.9106e-05, 8.0050e-01, 6.0707e-04, 1.9089e-01, 3.1675e-03, 1.6419e-03,
        7.4330e-05, 1.6400e-06, 3.8628e-06, 4.7386e-04, 1.6702e-03, 3.3254e-05,
        6.0698e-06, 8.8964e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,040][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([2.0610e-04, 2.5196e-01, 4.7906e-01, 2.1518e-02, 1.9192e-01, 3.7391e-03,
        8.1656e-04, 7.7462e-03, 1.8284e-02, 4.7683e-03, 3.5868e-03, 2.2733e-03,
        1.1240e-02, 2.8809e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,041][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([1.0633e-01, 1.3779e-01, 5.8648e-01, 1.3730e-02, 9.8004e-02, 7.6355e-03,
        2.7171e-03, 2.7067e-04, 1.4993e-03, 9.3513e-03, 6.5462e-03, 6.4453e-04,
        2.5485e-02, 3.5185e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,043][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0340, 0.2710, 0.1457, 0.0205, 0.2418, 0.0265, 0.0269, 0.0268, 0.0065,
        0.0316, 0.0259, 0.0444, 0.0370, 0.0614], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,044][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.0236e-05, 9.4908e-01, 4.0397e-04, 4.8300e-02, 1.7114e-03, 7.1527e-05,
        1.2310e-05, 3.3664e-08, 1.6078e-06, 6.5462e-05, 1.1974e-04, 2.6946e-06,
        5.5459e-07, 2.1803e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,045][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([8.7767e-02, 2.6974e-02, 7.3582e-01, 2.8221e-04, 1.2809e-01, 2.8865e-05,
        2.7857e-05, 5.9914e-03, 1.4596e-02, 6.8184e-06, 5.5877e-05, 5.6433e-05,
        2.1128e-04, 8.6380e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,046][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([5.4870e-05, 1.5034e-01, 2.2136e-01, 6.4311e-02, 3.9101e-01, 6.4583e-03,
        2.0449e-03, 2.3127e-02, 1.8466e-02, 5.9560e-03, 5.3874e-03, 2.5945e-02,
        7.3687e-02, 1.1858e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,047][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.1533e-04, 2.6113e-01, 5.5818e-01, 1.3122e-02, 1.4379e-01, 5.9579e-03,
        2.6626e-04, 6.3059e-04, 2.5177e-03, 1.2597e-03, 1.2146e-03, 4.9216e-03,
        2.7247e-03, 2.4524e-03, 1.4178e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,048][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.1117e-05, 1.2537e-01, 5.8099e-01, 1.2692e-02, 2.6507e-01, 3.3320e-04,
        2.1805e-04, 1.2214e-03, 9.3631e-03, 8.7946e-04, 4.1691e-04, 2.4881e-04,
        2.4616e-03, 1.7832e-04, 5.3724e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,049][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0537, 0.2204, 0.2287, 0.1443, 0.0337, 0.0247, 0.0120, 0.0586, 0.0754,
        0.0232, 0.0490, 0.0205, 0.0075, 0.0164, 0.0317], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,051][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1703, 0.4685, 0.1406, 0.0586, 0.0338, 0.0297, 0.0053, 0.0163, 0.0195,
        0.0077, 0.0160, 0.0080, 0.0038, 0.0099, 0.0121], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,052][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0961, 0.3282, 0.0388, 0.1175, 0.0125, 0.1029, 0.0181, 0.0045, 0.0043,
        0.0902, 0.0577, 0.0417, 0.0055, 0.0421, 0.0399], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,053][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.4752e-03, 8.3510e-01, 1.7793e-04, 1.1480e-01, 1.9091e-03, 2.7317e-03,
        3.2379e-04, 5.0334e-06, 1.2323e-05, 3.3377e-03, 9.6804e-03, 1.0936e-04,
        4.5175e-05, 5.3944e-03, 1.9898e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,054][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0008, 0.2260, 0.5101, 0.0225, 0.1754, 0.0048, 0.0012, 0.0090, 0.0160,
        0.0073, 0.0045, 0.0027, 0.0123, 0.0023, 0.0050], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,054][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.1101e-01, 1.9948e-02, 3.5207e-02, 1.7812e-03, 1.0134e-02, 2.2211e-03,
        1.3641e-03, 1.3477e-04, 5.1535e-04, 3.0716e-03, 4.1488e-03, 3.1217e-04,
        5.2045e-03, 8.6307e-04, 4.0817e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,055][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1814, 0.2904, 0.0718, 0.0160, 0.1116, 0.0304, 0.0303, 0.0140, 0.0074,
        0.0327, 0.0390, 0.0316, 0.0132, 0.0469, 0.0834], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,055][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.9866e-03, 8.4854e-01, 4.1186e-04, 1.3294e-01, 2.7936e-03, 3.9108e-04,
        1.3182e-04, 5.3917e-07, 2.5192e-05, 1.1727e-03, 1.7162e-03, 3.9922e-05,
        1.5380e-05, 4.5705e-03, 5.2741e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,055][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.8407e-01, 2.2275e-02, 7.4175e-01, 1.9685e-04, 4.3376e-02, 1.9030e-05,
        1.6202e-05, 1.6999e-03, 6.3301e-03, 5.5462e-06, 6.8637e-05, 3.9127e-05,
        9.8849e-05, 4.7964e-05, 1.1349e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,056][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.8545e-04, 2.8482e-01, 2.2766e-01, 9.4439e-02, 1.6529e-01, 1.1757e-02,
        5.1298e-03, 2.6148e-02, 1.8606e-02, 1.4949e-02, 1.2508e-02, 3.3012e-02,
        5.2721e-02, 1.2065e-02, 4.0713e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,057][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:43,059][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[672],
        [ 56],
        [  1],
        [ 89],
        [  6],
        [  4],
        [581],
        [130],
        [534],
        [  1],
        [  7],
        [ 21],
        [  2],
        [ 31],
        [ 13]], device='cuda:0')
[2024-07-24 10:20:43,060][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[459],
        [ 37],
        [  1],
        [ 72],
        [  5],
        [  4],
        [645],
        [119],
        [514],
        [  2],
        [  6],
        [ 20],
        [  1],
        [ 26],
        [  9]], device='cuda:0')
[2024-07-24 10:20:43,061][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[43899],
        [40901],
        [   32],
        [ 1793],
        [  140],
        [  179],
        [  256],
        [  553],
        [  280],
        [  709],
        [ 1719],
        [  566],
        [  320],
        [  536],
        [  981]], device='cuda:0')
[2024-07-24 10:20:43,063][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 6606],
        [21991],
        [49330],
        [49087],
        [47015],
        [45159],
        [47502],
        [48105],
        [43894],
        [47489],
        [46580],
        [46990],
        [45899],
        [46093],
        [45984]], device='cuda:0')
[2024-07-24 10:20:43,064][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[44228],
        [35269],
        [  117],
        [  231],
        [ 1229],
        [ 1117],
        [ 1576],
        [ 2198],
        [ 3300],
        [ 3507],
        [ 4186],
        [ 3647],
        [ 3241],
        [ 2686],
        [ 2975]], device='cuda:0')
[2024-07-24 10:20:43,066][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15170],
        [16071],
        [16214],
        [23129],
        [19371],
        [24061],
        [26335],
        [25670],
        [25919],
        [24796],
        [26095],
        [27154],
        [27435],
        [24395],
        [26755]], device='cuda:0')
[2024-07-24 10:20:43,067][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17455],
        [15682],
        [16718],
        [ 7388],
        [13169],
        [ 8223],
        [ 8043],
        [ 8045],
        [ 8000],
        [ 6987],
        [ 6809],
        [ 7543],
        [ 7535],
        [ 7274],
        [ 7129]], device='cuda:0')
[2024-07-24 10:20:43,069][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[29155],
        [26340],
        [27864],
        [25967],
        [24781],
        [24800],
        [24142],
        [23384],
        [23691],
        [25659],
        [25641],
        [22789],
        [22595],
        [25494],
        [25744]], device='cuda:0')
[2024-07-24 10:20:43,070][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27545],
        [12362],
        [  397],
        [ 1657],
        [  540],
        [  831],
        [  948],
        [ 2204],
        [12064],
        [16247],
        [17224],
        [11779],
        [12562],
        [ 9468],
        [11593]], device='cuda:0')
[2024-07-24 10:20:43,071][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[36096],
        [  214],
        [40105],
        [ 6381],
        [ 5068],
        [ 2826],
        [ 1496],
        [ 2024],
        [ 1214],
        [  630],
        [  402],
        [  666],
        [  634],
        [  614],
        [  589]], device='cuda:0')
[2024-07-24 10:20:43,073][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[33127],
        [30940],
        [34407],
        [32599],
        [37483],
        [32908],
        [35939],
        [36319],
        [37563],
        [34716],
        [34907],
        [39557],
        [38962],
        [39666],
        [38219]], device='cuda:0')
[2024-07-24 10:20:43,074][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[32045],
        [27049],
        [25568],
        [26360],
        [26679],
        [26453],
        [26739],
        [26529],
        [26608],
        [26395],
        [26442],
        [26869],
        [26797],
        [26314],
        [26664]], device='cuda:0')
[2024-07-24 10:20:43,076][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[38572],
        [33276],
        [32872],
        [27399],
        [26894],
        [27912],
        [28746],
        [27890],
        [27499],
        [27869],
        [29166],
        [28161],
        [28324],
        [27342],
        [28408]], device='cuda:0')
[2024-07-24 10:20:43,077][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16186],
        [14046],
        [13421],
        [15442],
        [14371],
        [15344],
        [15888],
        [16133],
        [15851],
        [16289],
        [18490],
        [16939],
        [16676],
        [15874],
        [22402]], device='cuda:0')
[2024-07-24 10:20:43,079][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22500],
        [15466],
        [26621],
        [12922],
        [24973],
        [24051],
        [14141],
        [24905],
        [20956],
        [13305],
        [11061],
        [27973],
        [23985],
        [12693],
        [17202]], device='cuda:0')
[2024-07-24 10:20:43,080][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22115],
        [39853],
        [42046],
        [42333],
        [41312],
        [41545],
        [41826],
        [41285],
        [41623],
        [41699],
        [41816],
        [41876],
        [41825],
        [41484],
        [41820]], device='cuda:0')
[2024-07-24 10:20:43,081][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39155],
        [31955],
        [37503],
        [37406],
        [39502],
        [41118],
        [39629],
        [39253],
        [40963],
        [40014],
        [40173],
        [39916],
        [38875],
        [40835],
        [40451]], device='cuda:0')
[2024-07-24 10:20:43,083][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38984],
        [43688],
        [41851],
        [41039],
        [41553],
        [40305],
        [40644],
        [41639],
        [43160],
        [42315],
        [43058],
        [43740],
        [45615],
        [41086],
        [43510]], device='cuda:0')
[2024-07-24 10:20:43,084][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[42775],
        [39893],
        [39024],
        [24021],
        [30663],
        [25996],
        [26051],
        [25601],
        [28398],
        [24800],
        [26083],
        [28723],
        [28836],
        [26050],
        [26430]], device='cuda:0')
[2024-07-24 10:20:43,086][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15371],
        [15037],
        [14886],
        [13783],
        [12948],
        [25462],
        [26449],
        [25088],
        [21190],
        [30274],
        [30874],
        [31269],
        [26901],
        [31290],
        [31083]], device='cuda:0')
[2024-07-24 10:20:43,087][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17004],
        [11187],
        [12245],
        [12044],
        [16798],
        [17206],
        [19424],
        [21311],
        [20537],
        [13387],
        [13316],
        [23355],
        [22562],
        [13855],
        [13088]], device='cuda:0')
[2024-07-24 10:20:43,088][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[35210],
        [39354],
        [38637],
        [38974],
        [39264],
        [38689],
        [39369],
        [38990],
        [39565],
        [37987],
        [37970],
        [40757],
        [41069],
        [38680],
        [38623]], device='cuda:0')
[2024-07-24 10:20:43,090][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[38238],
        [38232],
        [38244],
        [38474],
        [38307],
        [40588],
        [37260],
        [38726],
        [38397],
        [39219],
        [40134],
        [39785],
        [39575],
        [32739],
        [39892]], device='cuda:0')
[2024-07-24 10:20:43,091][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23156],
        [16490],
        [22587],
        [17478],
        [22003],
        [16342],
        [16448],
        [18522],
        [17110],
        [15572],
        [15683],
        [19321],
        [20031],
        [16166],
        [16695]], device='cuda:0')
[2024-07-24 10:20:43,093][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[32890],
        [20647],
        [28542],
        [19661],
        [20214],
        [20370],
        [20806],
        [20677],
        [20537],
        [19847],
        [19723],
        [21754],
        [20706],
        [19557],
        [19757]], device='cuda:0')
[2024-07-24 10:20:43,094][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34606],
        [34492],
        [36386],
        [49675],
        [47684],
        [49474],
        [49588],
        [49634],
        [49333],
        [49583],
        [49549],
        [49487],
        [47941],
        [49019],
        [49470]], device='cuda:0')
[2024-07-24 10:20:43,095][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[35816],
        [33349],
        [23347],
        [26073],
        [22963],
        [20594],
        [21867],
        [21258],
        [20966],
        [19802],
        [20613],
        [17784],
        [14192],
        [18531],
        [20675]], device='cuda:0')
[2024-07-24 10:20:43,097][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[1724],
        [1456],
        [1467],
        [1213],
        [1090],
        [1048],
        [1068],
        [1095],
        [ 961],
        [1112],
        [1034],
        [ 834],
        [ 905],
        [1280],
        [1006]], device='cuda:0')
[2024-07-24 10:20:43,098][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[13688],
        [28973],
        [ 7153],
        [10950],
        [12396],
        [11616],
        [14197],
        [ 5603],
        [15253],
        [12703],
        [16116],
        [ 4348],
        [11328],
        [23748],
        [15686]], device='cuda:0')
[2024-07-24 10:20:43,100][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855],
        [31855]], device='cuda:0')
[2024-07-24 10:20:43,165][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:43,166][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,167][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,168][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,169][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,170][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,172][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,173][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,174][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,175][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,176][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,177][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,178][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,180][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2017, 0.7983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,181][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8760, 0.1240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,182][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9971, 0.0029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,184][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9951, 0.0049], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,185][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2297, 0.7703], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,186][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.8656e-05, 9.9990e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,187][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,189][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0019, 0.9981], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,190][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.0000e+00, 2.3265e-08], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,191][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.9999e-01, 6.2595e-06], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,191][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9925, 0.0075], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,191][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.0000e+00, 2.4496e-07], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,192][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Shannon] are: tensor([0.4876, 0.0461, 0.4663], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,192][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Shannon] are: tensor([0.9126, 0.0446, 0.0427], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,192][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Shannon] are: tensor([0.9471, 0.0038, 0.0492], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,193][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Shannon] are: tensor([8.7107e-01, 1.2888e-01, 4.5029e-05], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,193][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Shannon] are: tensor([0.2216, 0.1785, 0.5999], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,193][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Shannon] are: tensor([1.6414e-08, 1.1061e-03, 9.9889e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,194][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Shannon] are: tensor([0.9003, 0.0017, 0.0981], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,194][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Shannon] are: tensor([0.0016, 0.4457, 0.5528], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,195][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Shannon] are: tensor([2.4512e-05, 6.3446e-02, 9.3653e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,195][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Shannon] are: tensor([1.0000e+00, 2.5642e-07, 1.5158e-06], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,197][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Shannon] are: tensor([0.7658, 0.2275, 0.0067], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,198][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Shannon] are: tensor([1.0000e+00, 1.6353e-06, 3.3530e-07], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,199][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0592, 0.1299, 0.2988, 0.5121], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,200][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2950, 0.1366, 0.3819, 0.1866], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,202][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3548, 0.0278, 0.6017, 0.0156], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,203][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9390e-01, 5.9604e-03, 7.9053e-05, 5.6534e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,204][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0219, 0.1725, 0.4998, 0.3058], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,205][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([7.0561e-06, 3.8457e-02, 9.5563e-01, 5.9030e-03], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,206][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3407, 0.0032, 0.6477, 0.0084], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,208][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0010, 0.3359, 0.3612, 0.3019], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,208][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.8429e-01, 2.4772e-04, 1.3696e-02, 1.7688e-03], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,209][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9448e-01, 1.6614e-03, 3.8429e-03, 2.0230e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,211][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2077, 0.7237, 0.0095, 0.0591], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,211][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9999e-01, 4.3843e-06, 1.5196e-07, 9.3197e-07], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,213][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.7077, 0.0132, 0.1847, 0.0179, 0.0765], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,214][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.7811, 0.0782, 0.0310, 0.0481, 0.0616], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,215][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([8.8778e-01, 5.4835e-03, 7.4756e-02, 6.1645e-04, 3.1368e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,216][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([3.4344e-01, 6.5489e-01, 4.2514e-05, 1.6248e-03, 3.7036e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,218][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.1025, 0.1036, 0.3196, 0.1476, 0.3267], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,218][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([3.5363e-08, 1.0844e-02, 9.7218e-01, 2.7876e-04, 1.6701e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,220][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.9232, 0.0052, 0.0506, 0.0029, 0.0182], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,221][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([0.0010, 0.2961, 0.2411, 0.3043, 0.1575], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,222][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([9.4803e-05, 3.6620e-02, 2.9533e-01, 5.4334e-02, 6.1362e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,223][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([9.9907e-01, 6.8870e-05, 2.6161e-04, 4.3689e-07, 6.0137e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,224][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([2.8860e-02, 3.0537e-01, 3.2326e-04, 6.5409e-01, 1.1355e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,225][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([9.9986e-01, 1.1376e-04, 1.2103e-05, 4.7106e-06, 5.3281e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,226][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1036, 0.0289, 0.1132, 0.1266, 0.0305, 0.5972], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,228][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.5602, 0.0311, 0.1127, 0.0207, 0.2510, 0.0242], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,229][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([6.8193e-01, 9.4436e-03, 1.7224e-01, 6.2920e-04, 1.3326e-01, 2.5011e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,230][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([8.5950e-01, 1.4003e-01, 2.3399e-04, 1.6654e-04, 5.2917e-05, 1.6340e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,231][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0120, 0.0875, 0.3215, 0.1279, 0.2395, 0.2116], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,232][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([8.3803e-09, 6.4584e-02, 3.7617e-01, 7.4322e-03, 5.5182e-01, 7.6479e-08],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,233][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.8333, 0.0010, 0.0986, 0.0025, 0.0609, 0.0036], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,234][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([2.9210e-05, 2.8905e-01, 9.5829e-02, 3.9075e-01, 1.2822e-01, 9.6125e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,235][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([7.0524e-03, 3.5279e-02, 4.2098e-01, 5.2029e-02, 4.8453e-01, 1.2666e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,236][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([9.9827e-01, 5.9116e-05, 6.2491e-04, 5.1986e-07, 1.0441e-03, 5.5584e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,237][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0406, 0.2247, 0.0228, 0.0999, 0.1026, 0.5093], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,238][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([9.9998e-01, 1.2752e-05, 1.9915e-06, 7.1397e-07, 1.2654e-06, 2.5785e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,240][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0633, 0.0743, 0.0470, 0.2757, 0.0164, 0.1535, 0.3698],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,241][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2136, 0.0209, 0.1433, 0.0143, 0.5739, 0.0165, 0.0175],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,243][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2618, 0.0171, 0.3991, 0.0037, 0.3100, 0.0065, 0.0018],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,244][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([2.8930e-01, 6.9410e-01, 1.7139e-04, 1.6164e-02, 3.1811e-05, 2.2041e-04,
        1.9186e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,245][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0085, 0.0829, 0.2481, 0.1137, 0.1935, 0.1899, 0.1633],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,246][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.7452e-09, 8.3782e-04, 9.2648e-01, 7.2485e-06, 7.2671e-02, 1.5376e-10,
        4.6526e-10], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,247][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([4.0785e-01, 3.7857e-04, 1.9805e-01, 1.1266e-03, 3.8867e-01, 2.9469e-03,
        9.7418e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,248][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([4.4487e-05, 2.2750e-01, 2.4866e-01, 2.8429e-01, 1.9349e-01, 2.4030e-02,
        2.1984e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,249][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([4.2575e-07, 5.2325e-01, 5.8882e-02, 3.0177e-01, 1.1255e-01, 1.0114e-03,
        2.5396e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,249][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.9718e-01, 1.1246e-04, 9.3534e-04, 6.2570e-07, 1.7033e-03, 1.1588e-05,
        6.1015e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,251][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0022, 0.3293, 0.0049, 0.2369, 0.0321, 0.2964, 0.0981],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,252][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9866e-01, 7.7729e-04, 2.4956e-04, 3.1447e-05, 6.0789e-05, 6.8695e-05,
        1.5341e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,253][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0400, 0.0786, 0.1832, 0.3216, 0.0224, 0.1047, 0.2319, 0.0176],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,254][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.8225, 0.0178, 0.0186, 0.0101, 0.0943, 0.0081, 0.0218, 0.0066],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,254][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.8323, 0.0477, 0.0579, 0.0016, 0.0397, 0.0093, 0.0077, 0.0038],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,255][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([4.9492e-01, 5.0391e-01, 3.9471e-05, 9.4658e-04, 8.9500e-06, 1.5786e-04,
        1.2213e-05, 8.4795e-11], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,255][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0570, 0.0825, 0.2680, 0.0709, 0.1791, 0.1548, 0.1269, 0.0607],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,255][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([7.6984e-07, 3.0593e-02, 5.7756e-01, 3.9322e-03, 3.8707e-01, 4.1980e-07,
        1.6573e-06, 8.4037e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,256][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.9653, 0.0045, 0.0133, 0.0026, 0.0069, 0.0021, 0.0041, 0.0011],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,256][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0006, 0.2989, 0.1275, 0.3203, 0.1099, 0.0547, 0.0669, 0.0211],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,256][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([2.7179e-05, 7.3122e-02, 4.8458e-01, 5.2563e-02, 3.7385e-01, 2.8136e-04,
        4.1207e-03, 1.1455e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,257][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([9.9998e-01, 1.4873e-06, 1.2024e-05, 1.1098e-09, 9.1031e-06, 4.2837e-08,
        9.8700e-07, 9.9913e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,258][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1282, 0.0881, 0.0027, 0.0454, 0.0186, 0.6443, 0.0710, 0.0016],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,259][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([9.9818e-01, 1.7598e-03, 1.3283e-05, 6.1997e-06, 1.8972e-06, 1.0784e-05,
        2.3939e-05, 5.4599e-08], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,260][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0185, 0.0961, 0.0830, 0.2601, 0.0116, 0.1647, 0.1704, 0.0097, 0.1859],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,262][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.7563, 0.0141, 0.0176, 0.0089, 0.0399, 0.0109, 0.0383, 0.0081, 0.1059],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,263][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.7661e-01, 1.1700e-03, 1.7012e-02, 4.0652e-05, 3.8864e-03, 4.9294e-04,
        2.5253e-04, 3.2336e-04, 2.0936e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,263][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([1.3082e-01, 8.6783e-01, 4.0655e-05, 1.3020e-03, 4.2909e-07, 4.1886e-06,
        2.9795e-06, 1.3458e-10, 1.4642e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,265][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2256, 0.0520, 0.2070, 0.0407, 0.1577, 0.1205, 0.0903, 0.0352, 0.0709],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,266][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2095e-08, 3.3395e-03, 9.7396e-01, 7.7952e-04, 2.1097e-02, 5.6065e-09,
        1.1489e-07, 8.1040e-04, 1.0621e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,267][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([9.9034e-01, 8.6543e-04, 1.3102e-03, 3.8039e-04, 8.3887e-04, 7.0572e-04,
        5.0531e-03, 3.0100e-04, 2.0898e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,268][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([8.9151e-05, 2.0605e-01, 1.6411e-01, 3.0436e-01, 9.4297e-02, 7.9083e-02,
        1.0466e-01, 1.9482e-02, 2.7872e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,269][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([6.6622e-12, 7.8736e-01, 1.3383e-01, 5.0197e-02, 2.8394e-02, 8.6478e-05,
        3.3275e-05, 1.0518e-04, 1.4370e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,269][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([9.9995e-01, 1.5200e-06, 1.1849e-05, 2.3134e-09, 1.2362e-05, 2.0205e-07,
        3.0004e-06, 1.0128e-07, 1.7470e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,270][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([1.2743e-02, 1.2175e-01, 1.6443e-04, 2.0506e-01, 3.9692e-03, 4.8966e-01,
        1.5866e-01, 7.1471e-04, 7.2882e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,271][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([9.9997e-01, 2.4288e-05, 3.0749e-06, 1.5658e-07, 2.9352e-07, 2.6283e-07,
        1.5240e-06, 1.1103e-09, 1.6908e-08], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,273][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0008, 0.0197, 0.0088, 0.1602, 0.0026, 0.0537, 0.6375, 0.0013, 0.0039,
        0.1115], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,274][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0380, 0.0192, 0.0432, 0.0156, 0.2162, 0.0111, 0.0155, 0.0099, 0.6245,
        0.0067], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,276][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1117, 0.0117, 0.3577, 0.0013, 0.4864, 0.0056, 0.0022, 0.0046, 0.0183,
        0.0006], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,276][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.4325e-02, 8.9452e-01, 8.2553e-04, 9.4107e-03, 7.7318e-05, 4.3218e-04,
        2.8682e-05, 4.0837e-08, 2.0923e-05, 3.6337e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,278][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0135, 0.0631, 0.2152, 0.0725, 0.1546, 0.1534, 0.1285, 0.0626, 0.1023,
        0.0341], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,279][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([2.7175e-10, 3.4109e-03, 9.1212e-01, 9.6212e-05, 8.4327e-02, 1.4788e-09,
        3.9921e-09, 2.3848e-05, 1.3706e-05, 2.8632e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,280][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1698, 0.0016, 0.2929, 0.0024, 0.4267, 0.0045, 0.0046, 0.0253, 0.0676,
        0.0047], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,281][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([4.4943e-05, 1.4682e-01, 1.9286e-01, 2.2504e-01, 2.9467e-01, 1.9623e-02,
        2.9775e-02, 6.9893e-03, 2.2958e-02, 6.1218e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,282][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([2.9176e-06, 4.5431e-01, 5.5467e-02, 3.7713e-01, 1.0805e-01, 7.5611e-04,
        2.5265e-03, 1.3615e-03, 6.4402e-05, 3.3208e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,283][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.8897e-01, 1.0789e-03, 3.8236e-03, 3.6067e-06, 3.2592e-03, 3.7482e-05,
        1.8064e-04, 1.0628e-05, 2.6313e-03, 4.5975e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,284][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.0094e-03, 4.7674e-01, 1.3130e-03, 1.8058e-01, 1.3685e-02, 1.3797e-01,
        2.4852e-02, 4.7785e-05, 3.2676e-05, 1.6278e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,285][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9801e-01, 1.6039e-03, 1.1640e-04, 2.4067e-05, 5.4219e-05, 6.9736e-05,
        9.4246e-05, 2.2237e-07, 3.4402e-06, 2.6380e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,286][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0170, 0.0531, 0.0532, 0.1239, 0.0205, 0.1251, 0.2746, 0.0174, 0.0160,
        0.1222, 0.1770], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,288][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0237, 0.0107, 0.0307, 0.0110, 0.1652, 0.0077, 0.0243, 0.0056, 0.7044,
        0.0056, 0.0112], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,289][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1018, 0.0347, 0.1624, 0.0044, 0.6049, 0.0271, 0.0161, 0.0074, 0.0275,
        0.0038, 0.0098], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,290][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([8.0343e-01, 1.9196e-01, 1.9093e-04, 2.1737e-03, 6.9922e-05, 7.6002e-04,
        9.7603e-05, 4.0177e-08, 1.9805e-05, 3.1324e-04, 9.8621e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,292][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0061, 0.0546, 0.1521, 0.0865, 0.1365, 0.1433, 0.1487, 0.0728, 0.1046,
        0.0409, 0.0539], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,293][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.5111e-09, 8.9673e-03, 8.6617e-01, 2.0726e-04, 1.2463e-01, 1.0382e-09,
        2.9330e-09, 7.7367e-06, 1.1071e-05, 2.6224e-06, 4.3632e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,294][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3538, 0.0028, 0.3419, 0.0060, 0.1510, 0.0076, 0.0079, 0.0184, 0.0917,
        0.0112, 0.0076], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,295][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([2.4449e-05, 1.5836e-01, 1.1094e-01, 2.8766e-01, 2.0834e-01, 1.5400e-02,
        2.2855e-02, 3.3650e-03, 1.0901e-02, 5.0157e-02, 1.3199e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,296][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([7.8356e-06, 3.5068e-01, 6.1795e-02, 3.1576e-01, 2.3776e-01, 3.1536e-03,
        1.5338e-02, 4.6107e-03, 2.0369e-04, 1.3096e-03, 9.3785e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,297][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9200e-01, 4.9707e-04, 1.7418e-03, 2.7575e-06, 1.4239e-03, 3.5676e-05,
        1.3000e-04, 8.2795e-06, 4.1538e-03, 4.4411e-06, 3.3124e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,298][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([4.7152e-04, 6.1642e-01, 1.5346e-03, 1.4374e-01, 2.6913e-02, 9.1006e-02,
        2.3479e-02, 3.1438e-05, 9.3918e-06, 6.0695e-02, 3.5698e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,299][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9862e-01, 3.7655e-04, 3.0955e-05, 1.8914e-05, 2.8486e-05, 2.2223e-04,
        4.1605e-04, 7.9903e-07, 6.1820e-06, 7.9585e-05, 2.0496e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,300][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0148, 0.0247, 0.0895, 0.0684, 0.0541, 0.3046, 0.2403, 0.0018, 0.0629,
        0.0445, 0.0933, 0.0010], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,302][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.1431, 0.0207, 0.0647, 0.0139, 0.1943, 0.0153, 0.0399, 0.0162, 0.4287,
        0.0106, 0.0199, 0.0327], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,303][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([7.5710e-01, 7.9200e-03, 1.2539e-01, 3.4689e-04, 9.2403e-02, 2.9032e-03,
        1.7177e-03, 2.2999e-03, 3.2587e-03, 6.0590e-04, 1.7966e-03, 4.2606e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,304][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.1979e-01, 8.2882e-01, 2.3101e-04, 2.7826e-02, 3.7211e-05, 6.7039e-04,
        4.8942e-04, 1.0001e-07, 2.2259e-05, 2.9335e-03, 1.9182e-02, 1.3659e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,305][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0368, 0.0510, 0.2005, 0.0652, 0.1520, 0.1225, 0.1221, 0.0513, 0.0739,
        0.0311, 0.0513, 0.0425], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,306][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([7.1616e-09, 4.0082e-02, 9.0145e-01, 2.0137e-03, 5.5525e-02, 7.5526e-08,
        6.2586e-07, 4.2033e-04, 1.2338e-04, 5.8736e-05, 1.0534e-04, 2.1912e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,308][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.7372, 0.0078, 0.0067, 0.0253, 0.0167, 0.0106, 0.0804, 0.0081, 0.0058,
        0.0495, 0.0456, 0.0063], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,309][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([2.9586e-05, 1.9639e-01, 9.5980e-02, 2.7052e-01, 1.7997e-01, 2.9733e-02,
        5.1245e-02, 6.0131e-03, 1.1508e-02, 5.6051e-02, 8.9247e-02, 1.3308e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,310][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([2.7526e-05, 3.9965e-03, 8.6584e-02, 1.0119e-02, 1.5812e-01, 2.9837e-05,
        6.6194e-04, 2.1884e-02, 6.1946e-04, 1.4710e-05, 6.5371e-04, 7.1729e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,310][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([9.9093e-01, 1.2271e-05, 1.2476e-04, 1.5160e-07, 2.7961e-04, 3.0114e-06,
        2.1767e-05, 2.0183e-06, 1.4029e-04, 6.1567e-07, 5.4057e-07, 8.4832e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,312][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([1.7669e-03, 2.2856e-01, 1.9886e-04, 1.8575e-01, 8.4909e-03, 2.8485e-01,
        1.3748e-01, 4.4109e-05, 4.7231e-04, 8.9812e-02, 6.1314e-02, 1.2561e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,312][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([9.9949e-01, 2.9885e-04, 3.0723e-05, 8.9854e-06, 8.2301e-06, 3.1107e-05,
        7.5955e-05, 5.7135e-07, 1.4206e-06, 1.4261e-05, 3.9133e-05, 4.3535e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,314][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Kelly] are: tensor([0.2889, 0.0204, 0.1600, 0.0509, 0.1119, 0.0782, 0.0816, 0.0053, 0.0396,
        0.0343, 0.0872, 0.0015, 0.0402], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,315][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Kelly] are: tensor([0.2262, 0.0236, 0.0075, 0.0116, 0.0145, 0.0215, 0.0509, 0.0108, 0.5391,
        0.0169, 0.0261, 0.0311, 0.0202], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,317][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Kelly] are: tensor([8.7693e-01, 6.8595e-03, 3.9623e-02, 2.4644e-04, 7.0253e-03, 1.8792e-03,
        1.0878e-03, 3.9204e-03, 1.6111e-02, 1.5026e-03, 2.5112e-03, 2.3129e-02,
        1.9170e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,317][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Kelly] are: tensor([5.6239e-02, 9.2693e-01, 2.2440e-05, 6.9726e-03, 1.4837e-06, 1.8447e-04,
        9.3681e-05, 4.9442e-09, 1.8295e-06, 2.2911e-03, 7.2677e-03, 1.9532e-07,
        1.1123e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,317][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Kelly] are: tensor([0.0376, 0.0500, 0.1507, 0.0588, 0.1319, 0.0989, 0.1008, 0.0517, 0.0707,
        0.0295, 0.0466, 0.0365, 0.1363], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,318][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Kelly] are: tensor([1.5556e-09, 1.1445e-02, 9.7801e-01, 1.2732e-04, 8.9390e-03, 1.6969e-10,
        3.4564e-09, 3.7938e-05, 4.4471e-06, 5.5723e-07, 2.8550e-06, 9.7855e-05,
        1.3363e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,318][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Kelly] are: tensor([0.9188, 0.0032, 0.0217, 0.0016, 0.0056, 0.0061, 0.0030, 0.0026, 0.0146,
        0.0056, 0.0051, 0.0033, 0.0089], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,319][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Kelly] are: tensor([1.7617e-04, 1.9579e-01, 1.9547e-01, 2.4859e-01, 8.5736e-02, 5.5349e-02,
        4.0473e-02, 7.6599e-03, 2.0049e-02, 3.8580e-02, 7.8533e-02, 1.2938e-02,
        2.0660e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,319][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Kelly] are: tensor([7.3584e-09, 1.7599e-01, 5.9924e-02, 8.0382e-02, 6.1434e-02, 5.6856e-04,
        9.9870e-04, 5.0677e-03, 7.9428e-05, 2.1572e-05, 1.7257e-04, 6.0115e-01,
        1.4210e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,319][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Kelly] are: tensor([9.8123e-01, 7.9032e-05, 1.5518e-04, 2.7140e-07, 3.0477e-04, 4.8407e-06,
        3.2259e-05, 3.8377e-06, 3.6270e-04, 2.1141e-06, 1.3177e-06, 1.6507e-02,
        1.3137e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,320][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Kelly] are: tensor([1.4577e-04, 9.0598e-02, 3.4921e-05, 4.0958e-01, 1.5371e-03, 2.7764e-02,
        4.0347e-01, 1.6837e-05, 3.9495e-06, 2.2268e-02, 4.4226e-02, 3.7689e-05,
        3.1274e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,321][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Kelly] are: tensor([9.9953e-01, 3.1802e-04, 3.1344e-05, 7.9849e-06, 9.6316e-06, 1.4025e-05,
        5.2726e-05, 2.3153e-07, 5.9028e-07, 6.4969e-06, 2.2733e-05, 2.4677e-06,
        3.5225e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,322][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0633, 0.0328, 0.0989, 0.1027, 0.0294, 0.1984, 0.1372, 0.0034, 0.0334,
        0.0212, 0.0564, 0.0011, 0.0072, 0.2147], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,323][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1000, 0.0061, 0.0321, 0.0039, 0.0613, 0.0081, 0.0057, 0.0050, 0.5775,
        0.0038, 0.0112, 0.0263, 0.1139, 0.0451], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,324][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([3.9363e-01, 7.8585e-04, 2.4735e-01, 8.6700e-05, 9.2426e-02, 8.1900e-04,
        1.5319e-04, 5.6056e-04, 4.1853e-03, 7.5141e-05, 3.6123e-04, 3.4098e-03,
        2.5449e-01, 1.6636e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,325][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([9.7712e-02, 9.0060e-01, 5.2235e-05, 8.8729e-04, 1.3615e-06, 6.2402e-06,
        8.5928e-07, 9.9003e-10, 8.4662e-07, 1.0917e-04, 6.2297e-04, 5.1502e-08,
        1.2759e-07, 8.4910e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,327][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0250, 0.0476, 0.1974, 0.0438, 0.1119, 0.1048, 0.0789, 0.0415, 0.0715,
        0.0221, 0.0357, 0.0329, 0.1298, 0.0571], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,328][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([2.8878e-11, 1.3152e-03, 9.2808e-01, 2.6079e-05, 6.3016e-02, 1.3808e-10,
        1.5897e-09, 1.9474e-05, 1.3348e-06, 3.0551e-07, 1.0323e-06, 4.7849e-05,
        7.4952e-03, 1.1904e-10], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,329][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.7624, 0.0021, 0.0650, 0.0031, 0.0246, 0.0065, 0.0123, 0.0121, 0.0089,
        0.0060, 0.0117, 0.0071, 0.0570, 0.0210], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,330][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([8.2658e-06, 1.4710e-01, 1.4679e-01, 2.8931e-01, 1.2286e-01, 2.3661e-02,
        4.4406e-02, 4.6347e-03, 8.8682e-03, 4.9603e-02, 1.2076e-01, 4.9870e-03,
        2.6360e-02, 1.0648e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,331][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([2.8114e-06, 6.4492e-02, 1.7771e-01, 3.5635e-02, 1.4317e-01, 1.3632e-04,
        3.4738e-04, 5.8314e-03, 1.0314e-04, 1.4245e-05, 2.6332e-04, 4.5046e-01,
        1.2168e-01, 1.5307e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,332][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([9.8319e-01, 1.0520e-04, 1.0254e-03, 4.6181e-07, 1.2005e-03, 2.9868e-05,
        2.8103e-05, 1.5493e-05, 2.4332e-03, 2.8188e-06, 1.5586e-06, 6.7016e-03,
        4.2266e-03, 1.0438e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,333][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([1.0351e-04, 2.7889e-01, 6.8896e-04, 3.3984e-01, 3.8929e-02, 2.4164e-02,
        7.1315e-02, 1.3524e-05, 1.4663e-05, 1.2886e-01, 8.1730e-02, 1.1872e-04,
        1.1103e-02, 2.4231e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,334][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([9.9981e-01, 1.0192e-04, 4.7546e-05, 9.2427e-07, 5.6202e-06, 4.3602e-06,
        6.7560e-06, 3.5645e-08, 8.2740e-07, 1.1367e-06, 4.1209e-06, 1.3358e-06,
        2.1210e-06, 1.4786e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,336][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0050, 0.0346, 0.0076, 0.1282, 0.0043, 0.0637, 0.4502, 0.0030, 0.0186,
        0.1011, 0.1116, 0.0006, 0.0017, 0.0609, 0.0089], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,337][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0101, 0.0100, 0.0468, 0.0122, 0.1213, 0.0068, 0.0134, 0.0053, 0.6171,
        0.0039, 0.0085, 0.0096, 0.1078, 0.0066, 0.0206], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,338][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0788, 0.0191, 0.3267, 0.0031, 0.3040, 0.0069, 0.0022, 0.0021, 0.0078,
        0.0011, 0.0041, 0.0105, 0.2265, 0.0041, 0.0030], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,340][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.5149e-01, 7.3662e-01, 2.0789e-04, 7.8617e-03, 5.1123e-05, 3.3307e-04,
        2.2494e-05, 3.4776e-08, 1.3268e-05, 5.1228e-04, 2.4276e-03, 7.4269e-07,
        8.8296e-06, 9.8388e-05, 3.5853e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,341][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0099, 0.0406, 0.1318, 0.0599, 0.1165, 0.1046, 0.0994, 0.0517, 0.0742,
        0.0256, 0.0375, 0.0264, 0.1246, 0.0445, 0.0530], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,342][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.6236e-09, 1.0133e-02, 9.3602e-01, 2.3547e-04, 4.4993e-02, 1.1496e-09,
        1.0134e-08, 2.2653e-05, 2.5313e-06, 2.8928e-06, 7.7692e-06, 1.2748e-04,
        8.4489e-03, 4.1466e-10, 5.5581e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,343][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1069, 0.0018, 0.2379, 0.0039, 0.2102, 0.0053, 0.0056, 0.0208, 0.0314,
        0.0089, 0.0040, 0.0026, 0.3424, 0.0029, 0.0155], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,344][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.4356e-05, 1.5027e-01, 1.7002e-01, 2.2372e-01, 1.4162e-01, 2.4775e-02,
        2.9717e-02, 3.4760e-03, 1.4250e-02, 3.8409e-02, 1.0940e-01, 7.1536e-03,
        3.4752e-02, 1.1565e-02, 4.0827e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,345][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.1192e-05, 2.5186e-02, 1.3654e-01, 3.0279e-02, 1.6464e-01, 3.9711e-05,
        6.2947e-04, 9.1416e-03, 7.0466e-04, 2.5319e-05, 1.1663e-03, 3.1019e-01,
        3.1322e-01, 6.8280e-05, 8.1419e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,346][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.8610e-01, 1.0912e-03, 2.0408e-03, 9.0377e-06, 2.2625e-03, 5.2714e-05,
        1.6082e-04, 1.6280e-05, 1.7039e-03, 1.1812e-05, 9.1309e-06, 3.1242e-03,
        2.1629e-03, 1.1872e-03, 6.5052e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,347][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.4877e-03, 4.0354e-01, 5.7583e-05, 3.0958e-01, 7.6618e-03, 7.6192e-02,
        2.3285e-02, 2.2157e-06, 2.4729e-06, 1.0723e-01, 5.2391e-02, 9.7582e-05,
        1.5222e-03, 2.9257e-03, 1.3026e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,348][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9978e-01, 8.0683e-05, 6.1326e-06, 4.0410e-06, 9.9831e-06, 2.8993e-05,
        2.4297e-05, 5.8006e-08, 1.2990e-06, 5.5813e-06, 1.7644e-05, 1.6598e-06,
        5.3834e-06, 1.6781e-05, 1.4736e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,413][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:43,415][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,416][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,417][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,418][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,419][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,421][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,422][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,423][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,424][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,425][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,426][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,427][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:43,429][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2017, 0.7983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,430][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9965, 0.0035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,432][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0215, 0.9785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,433][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,434][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0167, 0.9833], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,436][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3450, 0.6550], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,437][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9644, 0.0356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,439][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8235, 0.1765], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,439][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.0669e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,441][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2670, 0.7330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,442][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9925, 0.0075], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,444][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9525, 0.0475], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:43,445][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Shannon] are: tensor([0.4876, 0.0461, 0.4663], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,447][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Shannon] are: tensor([0.4626, 0.0008, 0.5366], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,448][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Shannon] are: tensor([0.0199, 0.6461, 0.3340], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,448][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Shannon] are: tensor([0.1763, 0.4948, 0.3288], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,449][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Shannon] are: tensor([3.4175e-04, 4.1050e-03, 9.9555e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,449][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Shannon] are: tensor([0.0137, 0.0068, 0.9795], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,449][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Shannon] are: tensor([1.4417e-03, 4.5728e-05, 9.9851e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,450][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Shannon] are: tensor([0.2920, 0.1267, 0.5813], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,450][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Shannon] are: tensor([0.0088, 0.9893, 0.0019], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,450][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Shannon] are: tensor([1.2781e-05, 2.6457e-06, 9.9998e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,451][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Shannon] are: tensor([0.7658, 0.2275, 0.0067], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,451][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Shannon] are: tensor([2.4023e-04, 1.2781e-03, 9.9848e-01], device='cuda:0') for source tokens [Then, Shannon]
[2024-07-24 10:20:43,453][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0592, 0.1299, 0.2988, 0.5121], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,453][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.7160e-02, 3.0397e-04, 9.8247e-01, 6.3327e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,454][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([4.2612e-04, 1.4793e-02, 9.8448e-01, 3.0139e-04], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,456][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1977, 0.0483, 0.7517, 0.0023], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,457][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.3521e-04, 2.4029e-02, 7.0040e-01, 2.7544e-01], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,458][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0457, 0.0413, 0.8942, 0.0188], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,459][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([4.7219e-05, 2.1871e-05, 9.9993e-01, 7.7392e-07], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,460][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4812, 0.0922, 0.4218, 0.0048], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,461][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([3.4016e-07, 7.9242e-01, 2.0431e-01, 3.2761e-03], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,462][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.2983e-06, 2.6949e-05, 9.9997e-01, 4.4732e-07], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,463][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2077, 0.7237, 0.0095, 0.0591], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,464][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.1730e-02, 2.5284e-03, 9.5567e-01, 7.3565e-05], device='cuda:0') for source tokens [Then, Shannon and]
[2024-07-24 10:20:43,465][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.7077, 0.0132, 0.1847, 0.0179, 0.0765], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,467][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([0.7217, 0.0031, 0.1663, 0.0008, 0.1080], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,468][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([0.0161, 0.3361, 0.6049, 0.0053, 0.0376], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,470][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([0.0094, 0.5830, 0.0688, 0.3213, 0.0175], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,470][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([1.8691e-04, 7.6771e-03, 2.5865e-01, 6.4933e-02, 6.6855e-01],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,472][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([0.0075, 0.0182, 0.8566, 0.0018, 0.1160], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,473][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([1.3535e-02, 1.0666e-03, 9.7942e-01, 2.9393e-04, 5.6798e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,474][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([0.4561, 0.1559, 0.2846, 0.0103, 0.0931], device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,475][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([5.8202e-04, 9.7108e-01, 2.3492e-03, 2.5984e-02, 1.1312e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,476][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([5.4845e-06, 7.8496e-06, 9.9923e-01, 1.8996e-07, 7.5581e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,477][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([2.8860e-02, 3.0537e-01, 3.2326e-04, 6.5409e-01, 1.1355e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,478][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([3.0403e-04, 1.3663e-02, 9.6285e-01, 2.4960e-04, 2.2936e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly]
[2024-07-24 10:20:43,479][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1036, 0.0289, 0.1132, 0.1266, 0.0305, 0.5972], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,480][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.7656e-03, 1.8742e-03, 1.4580e-01, 7.8512e-04, 8.4919e-01, 5.8230e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,481][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([6.0374e-05, 5.0611e-02, 3.1274e-01, 3.3288e-03, 6.3008e-01, 3.1812e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,482][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([3.1165e-02, 1.0137e-01, 5.0533e-01, 6.4375e-03, 3.5519e-01, 5.0515e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,483][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([1.7666e-05, 2.4008e-02, 3.5780e-01, 2.1753e-01, 3.6528e-01, 3.5368e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,483][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([9.8103e-05, 1.6432e-02, 5.6692e-02, 7.6703e-03, 9.1898e-01, 1.3224e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,484][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([3.2354e-04, 3.5091e-04, 9.5071e-01, 3.4487e-05, 4.8562e-02, 1.9504e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,486][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0076, 0.4018, 0.1247, 0.0369, 0.3377, 0.0913], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,487][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([7.4040e-07, 9.8363e-01, 1.3798e-02, 2.3043e-03, 2.1337e-04, 5.3806e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,487][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.8579e-05, 2.1673e-04, 9.8085e-01, 6.5786e-06, 1.8870e-02, 3.0910e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,489][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0406, 0.2247, 0.0228, 0.0999, 0.1026, 0.5093], device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,490][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([7.9815e-05, 6.7793e-03, 9.4335e-01, 8.3555e-05, 4.9640e-02, 6.4920e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had]
[2024-07-24 10:20:43,491][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0633, 0.0743, 0.0470, 0.2757, 0.0164, 0.1535, 0.3698],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,492][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.3918e-05, 5.0294e-05, 9.0667e-02, 1.0813e-05, 9.0923e-01, 7.4830e-06,
        2.9073e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,493][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.0484e-06, 3.6051e-02, 6.6296e-01, 1.0619e-03, 2.9978e-01, 1.5299e-04,
        3.6946e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,495][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0008, 0.1728, 0.2363, 0.2478, 0.3319, 0.0054, 0.0050],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,495][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.3456e-06, 6.6656e-03, 7.0673e-01, 1.3409e-01, 1.3968e-01, 1.1351e-02,
        1.4750e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,496][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.3159e-04, 1.4047e-03, 5.5684e-01, 7.7274e-05, 4.4144e-01, 2.8161e-06,
        1.0740e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,497][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([7.0689e-06, 2.0345e-05, 9.8149e-01, 1.6380e-06, 1.8477e-02, 1.7744e-07,
        2.8821e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,498][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.1749e-03, 1.9106e-01, 4.1086e-01, 9.4825e-03, 3.8547e-01, 1.8874e-03,
        5.9162e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,499][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.8662e-06, 9.7557e-01, 1.0827e-05, 2.4278e-02, 7.2084e-09, 1.4024e-04,
        2.2574e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,500][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.2805e-06, 1.2735e-06, 9.9965e-01, 2.3956e-08, 3.4962e-04, 9.7162e-09,
        4.3893e-11], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,501][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0022, 0.3293, 0.0049, 0.2369, 0.0321, 0.2964, 0.0981],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,502][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.6813e-06, 5.5229e-04, 9.8850e-01, 4.2354e-05, 1.0824e-02, 7.0389e-05,
        1.2912e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a]
[2024-07-24 10:20:43,504][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0400, 0.0786, 0.1832, 0.3216, 0.0224, 0.1047, 0.2319, 0.0176],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,505][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([3.9961e-01, 8.3109e-03, 2.6587e-01, 4.9695e-03, 3.1001e-01, 1.0753e-02,
        3.8512e-04, 8.6958e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,505][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([1.0766e-02, 1.1890e-01, 3.8397e-01, 1.1742e-02, 4.4331e-01, 2.8260e-02,
        2.2966e-04, 2.8326e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,507][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0211, 0.0103, 0.1235, 0.0352, 0.6853, 0.0271, 0.0952, 0.0023],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,508][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0006, 0.0125, 0.2399, 0.0919, 0.5855, 0.0244, 0.0249, 0.0203],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,509][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([8.1116e-02, 1.8281e-02, 1.0611e-01, 1.1261e-02, 7.8036e-01, 1.4085e-03,
        1.2839e-04, 1.3345e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,510][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([1.4601e-02, 1.9225e-03, 9.3483e-01, 5.3957e-04, 4.6641e-02, 7.3912e-04,
        9.6490e-06, 7.1263e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,511][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([8.2210e-01, 7.5132e-02, 4.5930e-02, 1.0700e-02, 3.5785e-02, 8.9900e-03,
        3.5794e-04, 1.0027e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,511][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([5.9276e-06, 8.9763e-01, 9.9652e-03, 8.9333e-02, 1.1101e-04, 1.8383e-03,
        7.5444e-05, 1.0397e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,512][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([2.2354e-03, 5.9853e-04, 9.3486e-01, 1.2076e-04, 6.1839e-02, 2.5072e-04,
        7.8998e-07, 9.8163e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,512][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1282, 0.0881, 0.0027, 0.0454, 0.0186, 0.6443, 0.0710, 0.0016],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,512][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([6.4777e-02, 7.3342e-03, 6.9254e-01, 2.8005e-03, 2.0402e-01, 2.1425e-02,
        7.0906e-03, 1.5146e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long]
[2024-07-24 10:20:43,513][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0185, 0.0961, 0.0830, 0.2601, 0.0116, 0.1647, 0.1704, 0.0097, 0.1859],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,513][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0292, 0.0021, 0.4029, 0.0018, 0.5520, 0.0058, 0.0009, 0.0006, 0.0047],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,513][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([2.5033e-04, 1.1908e-01, 6.3733e-01, 6.0077e-03, 1.7859e-01, 1.3930e-02,
        6.6612e-05, 7.5686e-03, 3.7176e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,514][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0850, 0.1957, 0.1922, 0.0647, 0.2951, 0.0034, 0.1287, 0.0342, 0.0010],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,515][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([1.7778e-05, 4.1658e-03, 2.5975e-01, 1.6583e-02, 6.7424e-01, 5.2462e-03,
        1.1470e-02, 1.1741e-02, 1.6785e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,515][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2791e-02, 1.5436e-02, 7.1949e-01, 1.6502e-02, 2.2472e-01, 2.9809e-04,
        6.5687e-05, 2.6923e-03, 8.0088e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,516][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([2.0514e-03, 7.4366e-04, 9.5964e-01, 1.5933e-04, 3.2829e-02, 3.2006e-04,
        5.7050e-06, 6.4695e-04, 3.6076e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,518][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0073, 0.2142, 0.4662, 0.0445, 0.1165, 0.1123, 0.0050, 0.0091, 0.0248],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,518][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.3591e-06, 9.9299e-01, 6.2203e-05, 5.5007e-03, 2.5327e-08, 8.1153e-04,
        8.8569e-09, 5.4638e-06, 6.2431e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,519][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([2.0745e-03, 7.4882e-05, 9.6331e-01, 3.7960e-06, 3.4165e-02, 5.6560e-06,
        4.5411e-07, 1.3416e-05, 3.5649e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,520][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([1.2743e-02, 1.2175e-01, 1.6443e-04, 2.0506e-01, 3.9692e-03, 4.8966e-01,
        1.5866e-01, 7.1471e-04, 7.2882e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,521][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([3.3377e-05, 2.2242e-03, 7.1972e-01, 5.9321e-04, 2.7529e-01, 8.0824e-04,
        1.1331e-03, 1.9237e-04, 4.8683e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument]
[2024-07-24 10:20:43,523][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0008, 0.0197, 0.0088, 0.1602, 0.0026, 0.0537, 0.6375, 0.0013, 0.0039,
        0.1115], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,524][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.6252e-05, 4.2215e-05, 1.1913e-01, 1.0979e-05, 8.8077e-01, 3.7142e-06,
        1.5114e-07, 1.6694e-07, 2.7208e-05, 1.8334e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,525][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([5.2546e-07, 1.1089e-02, 3.6109e-01, 1.4699e-04, 6.2674e-01, 5.5950e-05,
        8.2473e-08, 2.1294e-05, 8.1051e-04, 4.3061e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,525][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.2202e-03, 1.2487e-01, 5.5458e-01, 4.1848e-02, 2.4679e-01, 1.0705e-03,
        1.0435e-03, 3.9684e-04, 5.5087e-04, 2.5637e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,526][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([3.4598e-07, 5.8418e-03, 7.4407e-01, 2.0837e-02, 2.1575e-01, 7.0924e-04,
        7.2675e-03, 1.7561e-03, 1.1059e-04, 3.6533e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,527][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.7049e-05, 5.0153e-03, 3.6138e-01, 7.5919e-04, 6.2009e-01, 5.1335e-05,
        1.3081e-06, 3.1428e-05, 1.2390e-02, 2.6002e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,528][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([7.5037e-07, 1.5616e-05, 9.9166e-01, 4.1702e-07, 8.3013e-03, 9.7153e-08,
        1.1968e-09, 1.5503e-06, 1.8762e-05, 3.2850e-08], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,529][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.7996e-04, 5.0564e-02, 1.8102e-01, 4.4406e-03, 7.5686e-01, 7.2602e-04,
        4.2611e-05, 2.3592e-04, 4.4980e-03, 1.4387e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,530][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([5.5698e-09, 9.9202e-01, 5.6170e-05, 1.8024e-03, 4.3226e-08, 2.9404e-05,
        2.3623e-09, 7.0141e-08, 1.1786e-04, 5.9697e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,531][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.9546e-08, 9.1690e-07, 9.9673e-01, 5.5126e-09, 1.3137e-03, 6.5659e-09,
        3.0460e-11, 1.0256e-08, 1.9544e-03, 5.0305e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,532][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.0094e-03, 4.7674e-01, 1.3130e-03, 1.8058e-01, 1.3685e-02, 1.3797e-01,
        2.4852e-02, 4.7785e-05, 3.2676e-05, 1.6278e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,533][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.0282e-05, 6.4391e-04, 8.4387e-01, 7.6215e-05, 1.5537e-01, 1.9944e-05,
        9.8325e-07, 1.6910e-06, 1.5117e-07, 4.4678e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument,]
[2024-07-24 10:20:43,534][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0170, 0.0531, 0.0532, 0.1239, 0.0205, 0.1251, 0.2746, 0.0174, 0.0160,
        0.1222, 0.1770], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,535][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.4498e-06, 3.7170e-04, 1.4918e-01, 9.1711e-05, 8.5032e-01, 5.7839e-06,
        8.6318e-07, 1.7850e-07, 1.3508e-05, 1.3601e-06, 6.3062e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,536][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([8.8135e-07, 7.1261e-02, 5.2460e-01, 1.9143e-03, 3.9920e-01, 3.4238e-04,
        1.3576e-06, 2.1201e-04, 1.7116e-03, 3.5274e-04, 3.9668e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,537][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([5.4755e-03, 2.9985e-01, 3.1320e-01, 7.5901e-02, 1.8827e-01, 6.7769e-03,
        1.1457e-02, 8.7710e-04, 2.4294e-04, 8.1233e-02, 1.6717e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,538][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([4.2892e-07, 1.4053e-02, 7.0844e-01, 7.1550e-02, 1.7715e-01, 3.3309e-03,
        2.8970e-03, 6.5061e-04, 4.1982e-04, 6.3347e-03, 1.5168e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,539][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([2.4072e-05, 6.5269e-03, 3.7915e-01, 8.1348e-04, 6.0903e-01, 8.9502e-06,
        4.7426e-07, 8.9531e-06, 4.2625e-03, 1.1329e-04, 5.9693e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,540][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.3611e-06, 6.9914e-05, 9.9507e-01, 1.2990e-06, 4.8480e-03, 1.1669e-07,
        1.6884e-09, 2.1454e-06, 1.1906e-05, 3.4831e-08, 9.4867e-08],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,541][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.3284e-04, 1.2052e-01, 9.3970e-02, 1.3332e-02, 7.5315e-01, 8.6662e-04,
        7.1202e-05, 1.3230e-04, 1.8037e-03, 2.5477e-03, 1.3474e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,542][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([6.8463e-09, 9.9709e-01, 1.1082e-05, 2.2379e-03, 5.4977e-09, 2.7808e-06,
        5.6100e-11, 8.2752e-08, 1.7055e-05, 6.3585e-04, 4.1501e-07],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,543][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.4927e-07, 1.3203e-05, 9.9738e-01, 1.0889e-07, 2.2360e-03, 3.4988e-08,
        9.8615e-10, 3.5493e-08, 3.6937e-04, 5.3498e-08, 2.8506e-08],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,544][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.7152e-04, 6.1642e-01, 1.5346e-03, 1.4374e-01, 2.6913e-02, 9.1006e-02,
        2.3479e-02, 3.1438e-05, 9.3918e-06, 6.0695e-02, 3.5698e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,544][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.8517e-05, 6.8061e-03, 9.5442e-01, 2.3957e-04, 3.7925e-02, 4.8181e-04,
        2.1028e-05, 3.0077e-05, 2.3805e-07, 1.4781e-05, 1.5764e-05],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and]
[2024-07-24 10:20:43,546][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0148, 0.0247, 0.0895, 0.0684, 0.0541, 0.3046, 0.2403, 0.0018, 0.0629,
        0.0445, 0.0933, 0.0010], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,547][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([4.8248e-04, 7.2499e-03, 5.0247e-01, 1.2475e-03, 4.8627e-01, 2.9146e-04,
        3.7851e-05, 2.9846e-05, 8.5046e-04, 3.4586e-05, 6.2789e-05, 9.7011e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,548][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([4.7829e-06, 1.5704e-02, 8.7947e-01, 2.2657e-03, 9.0733e-02, 1.5442e-03,
        2.2990e-05, 2.0191e-04, 6.9549e-03, 5.4905e-04, 9.0967e-04, 1.6422e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,549][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0014, 0.2481, 0.1521, 0.1945, 0.0970, 0.0040, 0.0375, 0.0032, 0.0051,
        0.1146, 0.1299, 0.0127], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,550][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([1.3504e-06, 3.2502e-02, 2.3611e-01, 1.0074e-01, 5.4149e-01, 3.4014e-03,
        1.2675e-02, 8.7437e-03, 4.4767e-04, 7.5395e-03, 5.2047e-02, 4.3021e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,551][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([2.9519e-04, 5.2613e-02, 5.5061e-01, 1.0089e-02, 3.2652e-01, 5.6889e-04,
        8.6512e-05, 9.3574e-04, 5.2673e-02, 2.5522e-03, 1.6922e-03, 1.3602e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,552][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([2.7832e-04, 1.9294e-03, 9.6202e-01, 2.0648e-04, 3.4496e-02, 3.4048e-05,
        3.4427e-06, 3.2893e-05, 4.2622e-04, 5.3815e-06, 1.9115e-05, 5.4911e-04],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,553][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([1.1937e-04, 1.4666e-01, 5.5473e-02, 2.0893e-02, 7.4925e-01, 4.8107e-03,
        5.1032e-04, 4.0508e-04, 1.7154e-03, 3.2807e-03, 5.4163e-03, 1.1463e-02],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,554][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([2.7505e-08, 9.7574e-01, 5.7303e-05, 1.8607e-02, 1.2066e-07, 1.2688e-04,
        2.6508e-08, 1.7286e-07, 1.1225e-03, 4.3259e-03, 2.1353e-05, 1.0370e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,555][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.4035e-06, 2.2455e-05, 9.9791e-01, 2.6808e-07, 1.1452e-03, 1.9612e-07,
        6.4335e-09, 1.0386e-06, 9.1315e-04, 4.9728e-08, 2.2253e-08, 9.4336e-06],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,556][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([1.7669e-03, 2.2856e-01, 1.9886e-04, 1.8575e-01, 8.4909e-03, 2.8485e-01,
        1.3748e-01, 4.4109e-05, 4.7231e-04, 8.9812e-02, 6.1314e-02, 1.2561e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,557][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.1688e-05, 2.1217e-02, 8.9805e-01, 2.3294e-03, 7.1976e-02, 3.1850e-03,
        7.2285e-04, 5.8393e-05, 1.6711e-05, 3.8452e-04, 6.8826e-04, 1.3583e-03],
       device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards]
[2024-07-24 10:20:43,559][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Kelly] are: tensor([0.2889, 0.0204, 0.1600, 0.0509, 0.1119, 0.0782, 0.0816, 0.0053, 0.0396,
        0.0343, 0.0872, 0.0015, 0.0402], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,560][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Kelly] are: tensor([5.0863e-02, 1.4650e-02, 5.6207e-01, 3.4966e-03, 3.2486e-01, 3.8882e-03,
        7.4678e-04, 6.3606e-04, 1.1252e-02, 4.5165e-05, 1.1945e-04, 1.1588e-02,
        1.5792e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,560][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Kelly] are: tensor([1.0018e-03, 4.5797e-01, 3.4518e-01, 1.1635e-02, 2.8915e-02, 6.1111e-03,
        1.2129e-04, 5.2477e-03, 7.0985e-02, 5.3250e-03, 7.2038e-03, 5.4113e-02,
        6.1875e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,562][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Kelly] are: tensor([3.8568e-05, 6.4425e-02, 3.0445e-03, 1.1756e-01, 1.9745e-03, 8.6372e-03,
        1.3762e-01, 1.8696e-02, 1.4588e-03, 3.1682e-01, 3.2290e-01, 4.0672e-03,
        2.7530e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,562][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Kelly] are: tensor([9.4147e-06, 6.5664e-03, 1.7478e-01, 4.9719e-02, 5.4603e-01, 1.4080e-02,
        1.2367e-03, 1.4494e-02, 1.0650e-02, 1.3531e-03, 1.1245e-02, 2.5556e-02,
        1.4428e-01], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,563][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Kelly] are: tensor([1.6626e-04, 1.6634e-02, 9.0669e-01, 8.5411e-04, 6.1472e-02, 1.9533e-06,
        4.6453e-07, 6.8599e-05, 1.4395e-03, 2.7764e-05, 6.1541e-05, 7.2168e-04,
        1.1867e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,564][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Kelly] are: tensor([7.4106e-04, 1.5653e-03, 9.8712e-01, 4.8743e-04, 4.3234e-03, 2.7622e-04,
        2.8056e-06, 1.7962e-03, 3.0998e-03, 6.5998e-06, 4.6333e-05, 2.8832e-04,
        2.4819e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,565][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Kelly] are: tensor([1.6116e-02, 2.4180e-01, 5.8178e-01, 2.5996e-02, 8.0544e-02, 2.9294e-02,
        4.7387e-04, 6.2336e-04, 7.9001e-03, 8.9258e-04, 4.4662e-03, 5.9217e-03,
        4.1862e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,566][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Kelly] are: tensor([7.8014e-05, 9.5290e-01, 6.7179e-05, 4.1259e-02, 3.7770e-08, 9.4649e-04,
        3.6328e-08, 2.1982e-05, 4.1615e-04, 4.2855e-03, 2.5417e-05, 2.7487e-06,
        3.5171e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,567][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Kelly] are: tensor([3.7142e-07, 3.8356e-06, 9.9939e-01, 6.4656e-08, 5.3512e-04, 1.3309e-08,
        8.4846e-10, 8.6108e-08, 4.4952e-05, 5.6989e-09, 7.0528e-09, 3.4600e-06,
        2.4111e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,568][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Kelly] are: tensor([1.4577e-04, 9.0598e-02, 3.4921e-05, 4.0958e-01, 1.5371e-03, 2.7764e-02,
        4.0347e-01, 1.6837e-05, 3.9495e-06, 2.2268e-02, 4.4226e-02, 3.7689e-05,
        3.1274e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,569][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Kelly] are: tensor([7.5895e-06, 1.2731e-02, 7.9134e-01, 6.5670e-04, 1.2482e-01, 5.9331e-04,
        2.2371e-02, 8.0195e-03, 1.7825e-06, 1.2802e-03, 3.0408e-03, 7.6403e-03,
        2.7497e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly]
[2024-07-24 10:20:43,570][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0633, 0.0328, 0.0989, 0.1027, 0.0294, 0.1984, 0.1372, 0.0034, 0.0334,
        0.0212, 0.0564, 0.0011, 0.0072, 0.2147], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,571][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.5787e-05, 5.0897e-04, 2.0645e-01, 2.2296e-04, 7.8103e-01, 3.3084e-05,
        1.4485e-06, 2.0137e-05, 6.7611e-04, 3.4885e-06, 2.9768e-05, 2.7704e-04,
        1.0650e-02, 8.1119e-05], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,572][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([3.2087e-07, 2.5646e-02, 7.0224e-01, 1.3993e-03, 2.4541e-01, 3.3573e-04,
        2.7187e-06, 8.3518e-04, 7.3425e-03, 6.2356e-04, 4.7299e-04, 1.1035e-03,
        1.3788e-02, 7.9292e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,573][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.3928e-04, 2.7285e-01, 2.8695e-02, 1.6223e-01, 3.4830e-02, 8.8592e-04,
        1.5600e-03, 1.1736e-04, 5.4918e-04, 2.7949e-01, 1.8550e-01, 1.0268e-03,
        2.1491e-02, 1.0637e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,574][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([4.1931e-07, 1.7269e-03, 1.3060e-01, 1.4914e-02, 7.0924e-01, 2.2185e-03,
        1.3660e-03, 9.5811e-03, 3.0100e-04, 1.0151e-03, 6.8537e-03, 2.9329e-03,
        1.1556e-01, 3.6895e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,574][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([2.2353e-06, 1.2479e-03, 4.2958e-01, 1.8711e-04, 4.9278e-01, 1.4220e-06,
        1.6390e-07, 2.3293e-05, 3.9371e-04, 9.3921e-06, 1.5926e-05, 2.9955e-04,
        7.5464e-02, 1.4310e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,575][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([2.6074e-06, 1.4129e-04, 9.6049e-01, 2.2424e-05, 3.8665e-02, 1.9327e-06,
        1.2575e-07, 3.5760e-05, 1.7257e-05, 3.4955e-07, 1.5598e-06, 1.5858e-05,
        6.0475e-04, 1.4568e-06], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,575][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([9.2812e-06, 1.6225e-01, 3.6003e-01, 2.3557e-02, 3.9880e-01, 2.8831e-03,
        3.0328e-04, 3.7732e-04, 1.5238e-03, 2.9523e-03, 1.3852e-02, 1.0047e-03,
        2.4850e-02, 7.6003e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,576][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([3.7328e-07, 9.9594e-01, 6.0147e-06, 3.2629e-03, 8.5958e-09, 2.3951e-05,
        2.4812e-10, 4.7855e-08, 5.5246e-06, 7.5587e-04, 1.5802e-06, 5.0879e-08,
        1.2878e-10, 9.3316e-08], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,576][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([5.9458e-09, 4.0487e-07, 9.9945e-01, 1.6725e-09, 5.3948e-04, 1.6572e-09,
        4.3327e-11, 8.2022e-09, 6.5951e-06, 2.3958e-10, 2.4536e-10, 9.3140e-07,
        4.9107e-06, 4.7184e-09], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,577][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([1.0351e-04, 2.7889e-01, 6.8896e-04, 3.3984e-01, 3.8929e-02, 2.4164e-02,
        7.1315e-02, 1.3524e-05, 1.4663e-05, 1.2886e-01, 8.1730e-02, 1.1872e-04,
        1.1103e-02, 2.4231e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,577][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([1.4578e-07, 8.0774e-03, 7.4545e-01, 6.2176e-04, 2.3276e-01, 3.0942e-05,
        6.3070e-05, 1.9461e-05, 5.4215e-07, 8.6214e-05, 2.6634e-04, 1.5463e-04,
        1.2363e-02, 1.0171e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said]
[2024-07-24 10:20:43,579][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0050, 0.0346, 0.0076, 0.1282, 0.0043, 0.0637, 0.4502, 0.0030, 0.0186,
        0.1011, 0.1116, 0.0006, 0.0017, 0.0609, 0.0089], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,580][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.3508e-05, 2.7121e-04, 2.1838e-01, 6.5045e-05, 7.7322e-01, 1.1037e-05,
        9.7356e-07, 2.6550e-07, 1.2695e-05, 5.3364e-07, 4.1430e-06, 3.6065e-05,
        7.9489e-03, 6.4211e-06, 6.7027e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,581][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.9911e-06, 4.0351e-02, 7.1676e-01, 1.5246e-03, 2.2445e-01, 1.2315e-03,
        3.3422e-06, 1.6985e-04, 1.9811e-03, 2.6480e-04, 4.0371e-04, 1.8856e-03,
        1.0259e-02, 3.1729e-04, 3.9465e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,582][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.6140e-04, 4.1029e-01, 8.5294e-02, 9.4447e-02, 1.1696e-01, 5.5871e-03,
        5.2144e-03, 2.2802e-04, 4.3516e-04, 1.3279e-01, 4.3724e-02, 6.1270e-03,
        3.5875e-02, 2.5353e-02, 3.6811e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,583][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.2501e-06, 8.0036e-03, 6.3480e-01, 2.9132e-02, 2.4106e-01, 2.0775e-03,
        1.5917e-03, 1.3842e-03, 3.2599e-04, 1.3539e-03, 5.4708e-03, 1.9566e-03,
        3.3931e-02, 1.1813e-03, 3.7728e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,583][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.2823e-05, 1.2452e-02, 6.6597e-01, 1.0597e-03, 2.6137e-01, 1.8371e-05,
        1.6366e-06, 2.0992e-05, 1.3308e-03, 1.1903e-04, 1.0512e-04, 7.0837e-04,
        5.6557e-02, 1.5609e-05, 1.7442e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,584][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.2866e-05, 5.3642e-05, 9.9528e-01, 1.5775e-06, 4.5277e-03, 7.9332e-07,
        6.7098e-09, 4.9933e-06, 7.5384e-06, 4.8564e-08, 1.7809e-07, 6.3022e-06,
        1.0100e-04, 3.2887e-07, 9.8710e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,585][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.2411e-03, 9.5545e-02, 3.9083e-01, 8.4099e-03, 4.4365e-01, 2.1624e-03,
        8.3912e-05, 5.8950e-05, 2.1133e-03, 6.6140e-04, 6.9864e-03, 1.6955e-03,
        3.9415e-02, 5.5832e-03, 1.5728e-03], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,586][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.6980e-09, 9.9599e-01, 2.9173e-06, 2.7774e-03, 1.2696e-09, 4.0486e-06,
        9.1866e-11, 9.0230e-09, 1.3146e-05, 1.2114e-03, 1.0441e-06, 4.8655e-08,
        3.4043e-11, 5.0257e-08, 9.5228e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,587][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6585e-06, 1.1254e-05, 9.9874e-01, 1.0932e-07, 9.6991e-04, 5.8042e-08,
        1.7495e-09, 3.1125e-08, 2.2784e-04, 2.2795e-08, 2.5973e-08, 1.2663e-05,
        3.7958e-05, 1.9053e-07, 3.6845e-07], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,588][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.4877e-03, 4.0354e-01, 5.7583e-05, 3.0958e-01, 7.6618e-03, 7.6192e-02,
        2.3285e-02, 2.2157e-06, 2.4729e-06, 1.0723e-01, 5.2391e-02, 9.7582e-05,
        1.5222e-03, 2.9257e-03, 1.3026e-02], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,589][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.1770e-06, 3.6959e-03, 8.8340e-01, 1.5614e-04, 1.0794e-01, 2.1692e-05,
        3.7334e-06, 4.3970e-06, 1.7902e-07, 2.1761e-05, 2.6570e-05, 6.5920e-05,
        4.4703e-03, 1.2233e-05, 1.7227e-04], device='cuda:0') for source tokens [Then, Shannon and Kelly had a long argument, and afterwards Kelly said to]
[2024-07-24 10:20:43,590][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:43,592][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[795],
        [254],
        [  1],
        [ 31],
        [  2],
        [  1],
        [ 13],
        [ 10],
        [ 63],
        [  1],
        [  4],
        [  7],
        [  1],
        [  4],
        [  1]], device='cuda:0')
[2024-07-24 10:20:43,594][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[854],
        [109],
        [  1],
        [ 43],
        [  2],
        [  1],
        [ 46],
        [ 16],
        [ 99],
        [  2],
        [  8],
        [ 14],
        [  2],
        [ 10],
        [  6]], device='cuda:0')
[2024-07-24 10:20:43,595][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16232],
        [18935],
        [ 2583],
        [ 8579],
        [ 5401],
        [ 6092],
        [ 8211],
        [ 7536],
        [ 8976],
        [ 8080],
        [ 8718],
        [ 7104],
        [ 6799],
        [ 7027],
        [ 8530]], device='cuda:0')
[2024-07-24 10:20:43,596][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[10622],
        [28207],
        [11006],
        [16042],
        [16381],
        [ 2695],
        [ 1725],
        [ 6914],
        [14351],
        [10567],
        [13351],
        [11656],
        [24801],
        [10797],
        [ 9806]], device='cuda:0')
[2024-07-24 10:20:43,598][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[5329],
        [5437],
        [ 120],
        [   1],
        [  20],
        [   2],
        [   4],
        [ 146],
        [1061],
        [   7],
        [ 114],
        [   4],
        [ 338],
        [  12],
        [  16]], device='cuda:0')
[2024-07-24 10:20:43,599][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8527],
        [ 8517],
        [10656],
        [ 8489],
        [14378],
        [10814],
        [14284],
        [13899],
        [14783],
        [14723],
        [11520],
        [14509],
        [14839],
        [14832],
        [14480]], device='cuda:0')
[2024-07-24 10:20:43,601][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[11410],
        [29262],
        [26864],
        [24648],
        [24248],
        [24470],
        [22595],
        [22821],
        [22001],
        [22019],
        [21011],
        [21405],
        [20859],
        [22044],
        [21235]], device='cuda:0')
[2024-07-24 10:20:43,602][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[49031],
        [43482],
        [ 6869],
        [ 7583],
        [ 7120],
        [16764],
        [ 7187],
        [11545],
        [ 6993],
        [ 7311],
        [ 7688],
        [ 7907],
        [ 7103],
        [ 7179],
        [ 7264]], device='cuda:0')
[2024-07-24 10:20:43,604][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 9807],
        [ 9971],
        [  192],
        [    1],
        [ 1087],
        [  244],
        [  303],
        [ 5216],
        [ 9422],
        [  139],
        [    7],
        [11854],
        [ 3073],
        [  790],
        [  360]], device='cuda:0')
[2024-07-24 10:20:43,605][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[30051],
        [ 6166],
        [ 2779],
        [ 6657],
        [ 5474],
        [10778],
        [ 5301],
        [11283],
        [12783],
        [ 5554],
        [11443],
        [12583],
        [11244],
        [13389],
        [10643]], device='cuda:0')
[2024-07-24 10:20:43,606][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10489],
        [10489],
        [ 5420],
        [10475],
        [ 5437],
        [ 5434],
        [ 5658],
        [ 5443],
        [ 5651],
        [ 5662],
        [ 5619],
        [ 5544],
        [ 5589],
        [ 5507],
        [ 5457]], device='cuda:0')
[2024-07-24 10:20:43,608][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22458],
        [22458],
        [22458],
        [21922],
        [22571],
        [22633],
        [22742],
        [22461],
        [22465],
        [22899],
        [22840],
        [24720],
        [27068],
        [25964],
        [24559]], device='cuda:0')
[2024-07-24 10:20:43,609][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[39108],
        [38407],
        [ 9090],
        [ 4426],
        [ 1912],
        [  357],
        [  902],
        [  661],
        [  760],
        [ 2617],
        [ 2849],
        [ 1442],
        [ 1526],
        [ 2456],
        [ 2703]], device='cuda:0')
[2024-07-24 10:20:43,611][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[5000],
        [5000],
        [5000],
        [5000],
        [5001],
        [5001],
        [4955],
        [4986],
        [5001],
        [4969],
        [4959],
        [4988],
        [4991],
        [4996],
        [4996]], device='cuda:0')
[2024-07-24 10:20:43,612][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24247],
        [24046],
        [17742],
        [20426],
        [19919],
        [11942],
        [13465],
        [11429],
        [16072],
        [19503],
        [20489],
        [11161],
        [19676],
        [16214],
        [16853]], device='cuda:0')
[2024-07-24 10:20:43,613][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23794],
        [22106],
        [16899],
        [19941],
        [18440],
        [14524],
        [18710],
        [18813],
        [19116],
        [19113],
        [19016],
        [17163],
        [18143],
        [16698],
        [19018]], device='cuda:0')
[2024-07-24 10:20:43,615][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[28800],
        [28622],
        [15830],
        [15399],
        [14304],
        [10086],
        [ 9779],
        [12502],
        [11682],
        [ 9910],
        [10086],
        [12183],
        [12822],
        [10336],
        [10401]], device='cuda:0')
[2024-07-24 10:20:43,616][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33193],
        [29976],
        [27182],
        [25899],
        [26549],
        [19858],
        [23121],
        [21368],
        [25410],
        [19736],
        [21691],
        [25386],
        [29535],
        [23821],
        [24115]], device='cuda:0')
[2024-07-24 10:20:43,618][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8235],
        [ 8061],
        [ 6394],
        [ 7641],
        [ 6444],
        [ 8003],
        [ 6605],
        [10246],
        [ 7060],
        [ 7587],
        [ 6794],
        [ 6627],
        [ 7587],
        [ 6897],
        [ 6743]], device='cuda:0')
[2024-07-24 10:20:43,619][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30806],
        [32514],
        [30857],
        [28454],
        [20005],
        [27793],
        [30241],
        [21755],
        [20054],
        [31252],
        [30696],
        [22755],
        [17598],
        [13355],
        [30184]], device='cuda:0')
[2024-07-24 10:20:43,621][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8659],
        [ 4078],
        [24270],
        [22567],
        [20648],
        [ 4417],
        [10317],
        [ 4481],
        [16419],
        [ 6055],
        [ 6308],
        [10623],
        [21958],
        [ 7095],
        [14014]], device='cuda:0')
[2024-07-24 10:20:43,622][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24625],
        [36523],
        [ 6796],
        [ 6798],
        [ 6785],
        [ 6717],
        [ 6765],
        [ 6753],
        [ 6772],
        [ 6782],
        [ 6787],
        [ 6759],
        [ 6844],
        [ 6723],
        [ 6787]], device='cuda:0')
[2024-07-24 10:20:43,623][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31350],
        [30588],
        [35465],
        [35392],
        [36134],
        [40222],
        [39285],
        [34881],
        [38548],
        [43000],
        [42566],
        [42434],
        [36696],
        [39595],
        [40273]], device='cuda:0')
[2024-07-24 10:20:43,625][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36086],
        [23361],
        [23143],
        [25500],
        [23460],
        [23621],
        [23431],
        [23817],
        [23397],
        [23457],
        [23376],
        [23492],
        [23568],
        [23383],
        [23385]], device='cuda:0')
[2024-07-24 10:20:43,626][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22057],
        [38160],
        [39650],
        [39650],
        [39683],
        [40202],
        [39664],
        [41436],
        [40611],
        [39721],
        [39725],
        [39702],
        [39676],
        [39674],
        [39690]], device='cuda:0')
[2024-07-24 10:20:43,628][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21000],
        [21575],
        [30544],
        [33715],
        [27796],
        [25710],
        [27893],
        [21323],
        [24389],
        [29392],
        [31570],
        [26576],
        [29328],
        [29640],
        [28699]], device='cuda:0')
[2024-07-24 10:20:43,629][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12186],
        [10303],
        [ 9345],
        [ 9325],
        [ 9332],
        [ 9347],
        [ 9345],
        [ 9219],
        [ 9346],
        [ 9342],
        [ 9347],
        [ 9301],
        [ 9318],
        [ 9318],
        [ 9343]], device='cuda:0')
[2024-07-24 10:20:43,630][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11913],
        [13165],
        [11934],
        [11569],
        [15331],
        [19425],
        [17220],
        [19787],
        [16115],
        [16673],
        [16932],
        [16485],
        [13098],
        [19099],
        [15762]], device='cuda:0')
[2024-07-24 10:20:43,632][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21150],
        [19700],
        [28403],
        [23673],
        [29574],
        [33281],
        [29063],
        [32982],
        [28488],
        [23101],
        [23845],
        [31174],
        [27310],
        [27683],
        [27409]], device='cuda:0')
[2024-07-24 10:20:43,633][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394],
        [13394]], device='cuda:0')
